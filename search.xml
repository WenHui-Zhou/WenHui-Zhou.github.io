<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>effective cpp(六) 继承与面向对象设计</title>
      <link href="/2019/11/16/effective-cpp-%E5%85%AD-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/"/>
      <url>/2019/11/16/effective-cpp-%E5%85%AD-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p>2019/11/16 effective cpp 第六章 继承与面向对象设计</p><p>面向对象编程成为一个风靡一时的重要特性，关于C++在面向对象上的一些特性，将在本章进行详细的介绍。</p><ul><li>32 条款：确定你的public继承塑膜出is-a关系</li></ul><a id="more"></a><h3 id="32-条款：确定你的public继承塑膜出is-a关系"><a href="#32-条款：确定你的public继承塑膜出is-a关系" class="headerlink" title="32 条款：确定你的public继承塑膜出is-a关系"></a>32 条款：确定你的public继承塑膜出is-a关系</h3><p>作者通过一个例子表明立场，说明一个<strong>戒慎恐惧</strong>的东西，将会使人们记得异常牢固。接下来他说我们应该用同样的心态记住下面的话：</p><p><strong>public继承意味着是一种is-a关系</strong>，即子类通过public的方式继承父类，那么子类在任何场合都可以直接转变为父类。</p><p>即D以public的方式继承自B，意味着B比D表现出更一般化的概念，D比B则表现出更加的特殊化。B可以使用的地方D一定可以使用，D可以使用的地方B不一定可以使用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span>...&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">student</span>:</span><span class="keyword">public</span> Person&#123;...&#125;;</span><br></pre></td></tr></table></figure><p>上诉的代码表明是一个学生一定是一个人。任何函数希望得到一个person参数的时候，通常也愿意接受一个student对象。即给父类参数传递一个子类对象作为参数，是符合继承的观点，合法的。</p><p><strong>总结</strong></p><ul><li>public继承意味着“is-a”的关系。适用于base classes身上的每一件事情一定也适用于derived class 身上，因为每一个derived classes 对象也都是一个base classes对象。</li></ul><h3 id="33-条款：避免遮掩继承而来的名称"><a href="#33-条款：避免遮掩继承而来的名称" class="headerlink" title="33 条款：避免遮掩继承而来的名称"></a>33 条款：避免遮掩继承而来的名称</h3><p>这个内容与作用域相关，指的是在不同的作用域之中，变量的遮掩。编译器从local领域从发，向外一步步直到找到变量。</p><p>当我们在谈论继承的时候，当位于一个derived class成员函数的内指涉base class内的某物，编译器可以找出所指涉的东西，因为derived classes继承了声明与base class内的所有东西。<strong>子类的作用域嵌套在base class作用域内，子类对象可以调用父类的成员。</strong></p><p>例如下面例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">base</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf2</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">boid <span class="title">mf4</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上述例子中混合了public，private名称，以及一组成员变量和成员函数名称，包含了pure virtual，virtual，non-virtual三种，假设mf4函数实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Derived::mf4()&#123;</span><br><span class="line">  ...</span><br><span class="line">    mf2();</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 当编译器遇到mf2的时候，必须估算他所指涉的东西，编译器的做法是查找各个作用域，看看有没有mf2的声明式，首先是local，然后是外围作用域，base的作用域，最外层的global作用域。</p><p>下面我们考虑一个重载带来的问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">base</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf2</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">(<span class="keyword">double</span>)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们重载了mf1和mf3函数，base class中的mf1和mf3都被子类的函数所代替，但是此时对于父类中的重载函数将会发生错误：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Derived d;</span><br><span class="line">d.mf1(); <span class="comment">//正常调用</span></span><br><span class="line">d.mf1(x); <span class="comment">// 含参数的那个函数也被mf1函数所覆盖，因此调用出现问题</span></span><br><span class="line">d.mf3(); <span class="comment">// 正常调用</span></span><br><span class="line">d.mf3(x); <span class="comment">// 出错</span></span><br></pre></td></tr></table></figure><p>为了解决上面出现的遮掩行为造成的错误，我们可以使用using声明式来达到目的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span><span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">using</span> Base::mf1;</span><br><span class="line">  <span class="keyword">using</span> Base::mf3;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用using机制使得继承可以得到完美的实现。子类中调用d.mf3(x)将会到父类中寻找d.mf3(x)函数进行调用。</p><p><strong>这意味着你继承base class并加上重载函数，而你又希望重新定义或覆盖其中的一部分，那么你必须为那些原本会遮掩的每个名称引入一个using声明式，否则某些你希望的名称将会被遮掩。</strong></p><p>另一种情况是，当我们只希望继承父类重载的多个函数中的一个函数的时候，我们使用转交函数的方式，在子类函数中调用父类的函数，使其成为inline：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span><span class="keyword">private</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>&#123;  <span class="comment">// 转交函数，只实现了一个版本，有参数的那个版本在子类中未继承</span></span><br><span class="line">      Base::mf1();  <span class="comment">// 使其成为inline</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>子类内的名称会遮掩base classes内的名称，在public继承下从来没有人希望如此</li><li>为了让遮掩的名称重见天日，可以使用using 声明式或转交函数。</li></ul><h3 id="34-条款：区分接口继承和实现继承"><a href="#34-条款：区分接口继承和实现继承" class="headerlink" title="34 条款：区分接口继承和实现继承"></a>34 条款：区分接口继承和实现继承</h3><p>在类的继承中，可以通过三种方式进行继承：</p><ul><li>继承一个接口（pure virtual）</li><li>继承接口以及接口的部分实现，子类选择覆盖这些实现（impure virtual）</li><li>继承接口以及接口的部分实现，子类不覆盖这些实现（non-virtual）</li></ul><p><strong>成员函数的接口总是会被继承</strong></p><p>pure virtual函数最突出的特性，他们必须被任何继承了他们的具象class重新声明，而且他们在抽象class中通常没有定义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>声明一个pure virtual函数的目的是为了让derived classes只继承函数接口。</strong></p><p>对于shape::draw函数来说，这样是十分合理的，因为每个shape对象都应该有一个draw函数，同时由于shape子类形状各异，因此父类无法提供一个缺省（通用的）实现方式。</p><p>但是令人意外的是：<strong>我们可以为纯虚pure virtual函数提供一份实现代码，但是调用他的唯一途径就是明确指出class的名称。</strong>但是pure virtual依然无法创建对象。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">shape* ps = <span class="keyword">new</span> shape;</span><br><span class="line">shape* ps1 = <span class="keyword">new</span> Rectangle;</span><br><span class="line">ps1-&gt;draw();  <span class="comment">// Rectangle的draw函数</span></span><br><span class="line">ps1-&gt;shape::draw(); <span class="comment">// 调用了父类的draw函数</span></span><br></pre></td></tr></table></figure><p><strong>声明非纯impure virtual函数的目的，就是让derived classes继承该函数的接口和缺省实现。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">error</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; msg)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码表示每个class都必须支持一个“当遇到错误时可调用”的函数，但每个class可自由处理错误。如果不愿意自己处理错误的话，也可以使用父类的缺省实现。</p><p>但是这就会出现一个问题，当我们继承了一个韩非纯函数的父类的时候，我们可能会忘记实现自己的版本，此时编译器就会为了安排默认的版本，而引发错误，下面这种做法就是为了解决这个问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Airplane</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(cosnt sAirport&amp; destination)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">protected</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">defaultFly</span><span class="params">(cosnt Ariport&amp; destination)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> Airplane::defaultFly(<span class="keyword">const</span> Airport&amp; destination)&#123;</span><br><span class="line">  <span class="comment">//fly函数中的实现部分改到这里来写</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述操作将fly函数又impure设置成pure函数，意味着子类必须有自己实现的版本，在缺省的实现部分转移到defaultFly当中去，如果子类不实现fly函数则会报错，如果希望用缺省方式的话，则调用defaultFly函数。</p><p>但是上面这种做法将会导致代码的重复这种情况。</p><p>另一种做法是将默认的实现部分转移到纯虚函数的实现中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Airplane</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(cosnt Airport&amp; destination)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> Airplane::fly(cosnt Airport&amp; destination)&#123;</span><br><span class="line">  <span class="comment">//缺省行为，将飞机飞至指定的目的地</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelA</span>:</span><span class="keyword">public</span> Airplane&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(<span class="keyword">const</span> Airport&amp; destination)</span></span>&#123;</span><br><span class="line">      Airplane::fly(destination); <span class="comment">// 使用缺省的方式实现</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;；</span><br><span class="line"><span class="comment">// 如果你要自己实现fly这个函数的话，可以自己写相应的方法</span></span><br></pre></td></tr></table></figure><p>这种方式避免了再去定义一个defaultFly函数。现在的fly函数被切割成两个部分，其声明部分表现的是接口，其定义部分表现出缺省行为。</p><p><strong>声明non-virtual函数的目的就是为了令derived classes继承函数的接口及一份强制性的实现。</strong></p><p>由于non-virtual函数代表的意义是不变性凌驾于特异性之上，我们绝对不要在子类中重新定义父类中的non-virtual函数。</p><p><strong>总结</strong></p><ul><li>接口继承和实现继承不同。在public继承之下，derived classes总是继承base class的接口。</li><li>pure virtual函数只具体指定接口继承。</li><li>非纯的函数具体制定接口继承及缺省实现继承。</li><li>non-virtual函数具体指定接口继承以及强制性实现继承。</li></ul><h3 id="34-条款：考虑virtual函数与外的其他选择"><a href="#34-条款：考虑virtual函数与外的其他选择" class="headerlink" title="34 条款：考虑virtual函数与外的其他选择"></a>34 条款：考虑virtual函数与外的其他选择</h3><p>我们可以使用一些其他的方式来代替virtual的使用</p><p><strong>template method模式</strong></p><p>这种模式为将虚函数修改为public的non-virtual函数，然后其具体的实现通过定义一个private的virtual函数来实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GameCharacter</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">healthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">      ... <span class="comment">// 调用前准备</span></span><br><span class="line">      <span class="keyword">int</span> retval = dohealthValue();</span><br><span class="line">      ... <span class="comment">// 调用后处理</span></span><br><span class="line">      <span class="keyword">return</span> retval;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">dohealthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p> 上面的设计令用户通过public non-virtual成员函数佳节调用private virtual函数的模式（NVI non-virtual interface），把non-virtual函数作为一个外覆器，在调用前后都可以进行一些处理，这是这种方法的一个优点，但是缺点是我们需要定义很多private virtual函数。</p><p><strong>籍由Function Pointers实现strategy模式</strong></p><p>利用传入一个函数指针的方式，进行实际的操作。</p><p>函数指针的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">defaultHealth</span><span class="params">(<span class="keyword">const</span> GameCharacter&amp; gc)</span></span>;</span><br><span class="line"><span class="comment">//函数指针如下</span></span><br><span class="line">return_types (*func_pointer)( data_types arg1, data_types arg2, ..);</span><br><span class="line"><span class="keyword">int</span> (*defaultHealth)(<span class="keyword">const</span> GameCharacter&amp;);</span><br><span class="line"><span class="comment">//使用上面的定义之后，就可以用指针defaultHealth来调用函数了</span></span><br></pre></td></tr></table></figure><p>上述这种方法提供了某种弹性，在调用不同的类型的时候，传入不同计算方法的函数的指针，得到不同的计算方式。当我们使用了类外的方法的时候，我们可能会陷入一个陷阱中，就是这个函数只能访问类的public部分，如果我们想进一步的话，就只能降低函数的封装级别了。</p><p><strong>籍由tr1::function完成strategy模式</strong></p><p><strong>C++ Technical Report 1 （TR1</strong>）是ISO/IEC TR 19768, C++ Library Extensions（函式库扩充）的一般名称。TR1是一份文件，内容提出了对C++标准函式库的追加项目。这些追加项目包括了正则表达式、智能指针、哈希表、随机数生成器等。</p><p><strong>function 是一种通用、多态的函数封装</strong>。<strong>std::function 的实例可以对任何可以调用的目标进行存储、复制、和调用操作，这些目标包括函数、lambda 表达式、绑定表达式、以及其它函数对象等</strong>。（c++11起的版本可用）<br>　　function（和bind一样）可以实现类似函数指针的功能，却比函数指针更加灵活（体现在占位符上面），尤其是在很多成员调用同一个函数（仅仅是参数类型不同）的时候比较方便。</p><p><strong>C++中的函数签名(function signature)</strong>：包含了一个函数的信息，包括函数名、参数类型、参数个数、顺序以及它所在的类和命名空间。</p><p>function对象只要签名式满足要求，那么这个对象就可以存储任何可调用物。下面我们使用function来替代上面的函数指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GameCharacter</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> <span class="built_in">std</span>::str1::function&lt;<span class="keyword">int</span> (<span class="keyword">const</span> GameCharacter&amp;)&gt; healthCalFunc;</span><br><span class="line">    explicit GameCharacter(HealthCalcFunc hcf = defaultHealthCalc):healthFunc(hfc)&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">healthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> healthFunc(*<span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    HealthCalcFunc healthFunc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由上面代码可以看出来，我们只要传入一下接受一个const reference参数的任意函数都可以，我们可以使用函数，函数对象，成员函数等等。</p><p><strong>古典的strategy模式</strong></p><p>传统的strategy做法将一个健康的计算函数做成一个分离的继承体系中的virtual成员函数。</p><p><strong>替代方案</strong></p><p>本条条款的核心就是可以通过一下几种方式来找到virtual的替代方案：</p><ul><li>使用non-virtual interface手法，那是template method设计模式的一种特殊形式，它以public non-virtual成员函数包裹较低访问性的virtual函数。</li><li>将virtual函数替换为函数指针成员变量，这是strategy设计模式的一种分解形式。</li><li>以tr1::function成员变量替换virtual函数，因而允许使用任何可调用物来搭配一个兼容于需求的签名式。</li><li>将继承体系内的virtual函数替换为另一个继承体系内的virtual函数，这是strategy设计模式的传统实现方法。</li></ul><p><strong>总结</strong></p><ul><li><p>virtual 函数的替代方案包含NVI，以及strategy设计模式的多种形式，NVI手法是一个特殊形式的template method模式。</p></li><li><p>将机能从成员函数一道class外部函数，带来一个缺点，非成员函数无法访问class的non-public成员。</p></li><li>tr1::function对象行为就像一般函数指针，这样的对象可接纳与给定目标签名式兼容的所有可调物。</li></ul><h3 id="36-条款：绝不重新定义继承而来的non-virtual函数"><a href="#36-条款：绝不重新定义继承而来的non-virtual函数" class="headerlink" title="36 条款：绝不重新定义继承而来的non-virtual函数"></a>36 条款：绝不重新定义继承而来的non-virtual函数</h3><p>在一个类中，我们定义了non-virtual函数，意味着我们遵循设计原则，认为这个函数的不变性要大于特异性，因此我们不可以在子类中对这个函数进行覆盖。否则，将同一个元素赋值给父类和子类，将导致不同的行为，这是我们不希望看到的。</p><p><strong>总结</strong></p><ul><li>绝对不要重新定义继承而来的non-virtual函数</li></ul><h3 id="37-条款：绝不重新定义继承而来的缺省参数值"><a href="#37-条款：绝不重新定义继承而来的缺省参数值" class="headerlink" title="37 条款：绝不重新定义继承而来的缺省参数值"></a>37 条款：绝不重新定义继承而来的缺省参数值</h3><p>当我们继承一个父类的时候，如果父类中的virtual函数带有缺省值，我们选择不去重写这个缺省值。原因是：</p><p><strong>virtual函数系动态绑定，而缺省参数值确实静态绑定。</strong>因此缺省的参数值在定义的时候就会被确定，缺省值就是定义这个函数的类给赋予的。如下面代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> shapecolor&#123;red,green,blue&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = red)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> Shape&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = green)</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> rectangle::draw(Shape::shapecolor color) <span class="keyword">const</span> &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"---"</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; color;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"---"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Shape *ps = <span class="keyword">new</span> rectangle();</span><br><span class="line">rectangle* rec = <span class="keyword">new</span> rectangle();</span><br><span class="line">ps-&gt;draw();  <span class="comment">// 使用静态绑定的shape中的缺省值</span></span><br><span class="line">rec-&gt;draw(); <span class="comment">// 使用静态绑定的rectangle中的缺省值</span></span><br></pre></td></tr></table></figure><p>上述代码就可以看出矛盾，同一个对象却有不同的表现，导致缺省值的不同。上述代码的一个解决方案就是使用NVI方式，用non-virtual去调用virtual函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> shapecolor&#123;red,green,blue&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = red)</span></span>&#123;</span><br><span class="line">        doDraw(color);  </span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">doDraw</span><span class="params">(shapecolor color)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">doDraw</span><span class="params">(shapecolor color)</span> <span class="keyword">const</span></span>;  <span class="comment">// 这里不需要指定缺省的参数值</span></span><br><span class="line">&#125;；</span><br></pre></td></tr></table></figure><p>由于non-virtual函数是不会被子类覆盖。这个设计保证了参数值一定是一致的。</p><p><strong>总结</strong></p><ul><li>绝对不要重新定义一个继承而来的缺省参数值，因为缺省参数值都是静态绑定的，而virtual函数（你唯一需要覆盖的东西）是动态绑定的。</li></ul><p>###38 条款：通过符合塑模出has-a或“根据某物实现出”</p><p>has-a表现出来的是一种复合关系（composition），当某种类型的对象内含它种类型的对象，便是这种关系。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    Address ad; <span class="comment">// 其他类型的生成对象</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">  PhoneNumber num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除此之外，还有另一种关系，成为 <strong>is-implemented-in-terms-of</strong> 关系，例如我们实现一个set，直觉上我们可以继承标准库中的set，但是为了资源等考虑，我们打算另辟蹊径。我们可能就会考虑到list的实现，但是我们不能直接继承list，因为list与set不是is-a的关系。但是我们可以在函数中多次使用list结构来构造一个set，<strong>这就是根据某物实现出</strong>的这种关系。</p><p><strong>总结</strong></p><ul><li>复合的意义和public继承完全不同</li><li>在应用域，复合意味着is-a关系。在实现域，复合意味着根据某物来实现。</li></ul><h3 id="39-条款：明智而审慎地使用private继承"><a href="#39-条款：明智而审慎地使用private继承" class="headerlink" title="39 条款：明智而审慎地使用private继承"></a>39 条款：明智而审慎地使用private继承</h3><p>private继承不是一个is-a继承，而是一种子类实现需要使用父类的某些函数性质的 “implemented-in-terms-of”的关系。</p><p>对于private的选择，我们通常会考虑：<strong>当一个意欲成为derived class者想要访问一个意欲成为base class者的protected成分，或者成为重新定义一个或多个virtual函数。</strong>如果满足这个条件的话，我们会考虑使用private继承，但是很多情况下，我们使用复合，将private继承的类作为一个成员变量的方式，能够提供能多的灵活性。</p><p><strong>即：我们可以使用复合的方式来代替private的继承，保证更大的灵活性。</strong></p><p>但是如果我们追求一种更加激进的空间优化，我们会选择使用private继承来代替复合。</p><p>如果我们使用的类满足不带数据成员，没有virtual等条件，满足空白基类最优化EBO的情况下，我们应该优先考虑private继承，但是这种情况基本很少见。</p><p><strong>总结</strong></p><ul><li>private继承意味着 <strong>根据某物实现出</strong>的关系，它通常比复合的级别要低，当时当子类需要访问protected base class的成员，或需要重新定义继承而来的cirtual函数时，是合理的。</li><li>和复合不同，private继承可以造成empty base最优化，这对于严格要求“对象尺寸最小化”的程序开发者而言是很重要的。</li></ul><h3 id="40-条款：明智而审慎地使用多重继承"><a href="#40-条款：明智而审慎地使用多重继承" class="headerlink" title="40 条款：明智而审慎地使用多重继承"></a>40 条款：明智而审慎地使用多重继承</h3><p>当我们设计到多重继承的时候，在子类的使用上将会面临起义的一个问题，共同父类中相同的函数，必须通过类名的方式进行调用。</p><p>对于钻石形的继承关系，我们使用virtual来继承，使得每一个子类都有一份供自己使用的父类成员变量。但是使用virtual将会导致C++编译器在处理这类继承时，生成体积较大的对象，访问速度也比较慢，virtual继承付出的代价更加的明显，规则复杂不够直观。</p><p><strong>忠告</strong></p><ul><li><p>非必须使用virtual bases的时候不要使用它，大部分情况使用non-virtual继承</p></li><li><p>如果必须使用virtual base继承，那么尽量避免在其中放置数据，使得类小一点，以及不会出现难以察觉的赋值问题。</p></li></ul><p>但是有些时候，双重继承也有其合理的用途，保留使用多重继承的看法。如果能用单一继承代替多重继承的话，单一继承是一个非常好的选择。</p><p><strong>总结</strong></p><ul><li>多重继承比单一继承复杂，他可能导致起义性，以及对virtual继承的需要</li><li>virtual继承会增加大小，速度，初始化复杂度等成本，如果virtual base classes不带任何的数据，将会是多重继承最具有使用价值的情况。</li><li>多重继承的确有正当用途，其中一个情节涉及public继承某个interface class和private继承某个协助实现的class的两相组合。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effectie cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(五) 实现</title>
      <link href="/2019/11/10/effective-cpp-%E4%BA%94-%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/11/10/effective-cpp-%E4%BA%94-%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>2019/11/10，effective cpp第五章 实现</p><p>cpp在实现上存在着很多高效率，代码优化的细节。</p><ul><li>26 条款：经可能延后变量定义式的出现时间</li><li>27 条款：尽量少做转型动作</li><li>28 条款：避免返回handles指向对象内部成分</li><li>29 条款：为异常安全而努力是值得的</li><li>30 条款：透彻了解inlining 的里里外外</li><li>31 条款：将文件间的编译依存关系降至最低</li></ul><a id="more"></a><h3 id="26-条款：经可能延后变量定义式的出现时间"><a href="#26-条款：经可能延后变量定义式的出现时间" class="headerlink" title="26 条款：经可能延后变量定义式的出现时间"></a>26 条款：经可能延后变量定义式的出现时间</h3><p>我们定义一个变量需要承担它的构造成本以及析构成本，如果我们在程序中，由于一些判断条件未能使用到这些变量，那么将造成大量的时间浪费，于是我们应当尽量的延后变量的定义。</p><p>第二个优化的地方在于在定义变量的时候，通过调用构造函数来初始化变量，而不是通过赋值的方式。（通过赋值的方式将会浪费一次系统默认的赋值时间）</p><p>第三个优化的地方，如果我们需要在一个循环中使用变量的话，<strong>我们应该在循环的内部定义变量</strong>，除非析构与构造的成本比较高，且你的代码对效率高度敏感。</p><p><strong>总结</strong></p><ul><li>尽可能延后变量定义式的出现，这样做可以增加程序的清晰度，并改善程序的效率。</li></ul><h3 id="27-条款：尽量少做转型动作"><a href="#27-条款：尽量少做转型动作" class="headerlink" title="27 条款：尽量少做转型动作"></a>27 条款：尽量少做转型动作</h3><p>首先是结论：<strong>优良的C++代码很少使用转型</strong></p><p>C++的设计目标之一就是保证类型错误绝不可能发生，尽量保证任何转型动作尽可能少的发生。转型动作破坏了类型系统，导致一些很隐晦的错误。C++提供的转型变换如下：</p><ul><li><p><code>const_cast&lt;T&gt; (expression)</code>，通常用于对象的常量性移除，将常量去除</p></li><li><p><code>dynamic_cast&lt;T&gt;(expression)</code>，主要用于执行“安全向下转型”，用来决定某对象是否归属继承体系中的某个类型。可能耗费比较大的运行成本。</p></li><li><code>reinterpret_cast&lt;T&gt;(expression)</code>，执行低级转型，例如将point to int 转成int。</li><li><code>static_cast&lt;T&gt;(expression)</code>，用来强迫执行隐式转型，将int转成double等等。</li></ul><p>旧式的转型：</p><ul><li><code>(T)expression</code></li><li><code>T(expression)</code></li></ul><p>旧式的两种写法功能相同，建议使新式的转型方法，因为他们在代码上容易辨认，且各个转型动作目标比较窄，容易排查错误,例如只有const_cast方法才能实现对象的常量移除。</p><p>关于<code>dynamic_cast</code>方法，例如我有有些时候，希望在子类函数调用的时候先调用父类的函数，会写出下面的代码（错误的）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">special</span>:</span> <span class="keyword">public</span> window&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">onResize</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">static_cast</span>&lt;window&gt;(*<span class="keyword">this</span>).onResize();</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上诉代码将this转为window的指针，但是他调用的并不是当前对象上的函数，<strong>转型动作将产生一个this对象的base class的成分的一个副本</strong>。因此window上的onsize操作只是在一个副本上执行操作的，并不会改变this对象的内容。解决的方法是直接调用父类的onsize方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">special</span>:</span> <span class="keyword">public</span> window&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">onResize</span><span class="params">()</span></span>&#123;</span><br><span class="line">    window::onResize();</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>dynamic_cast</code>的场景通常说，我们手上只有一个base class的指针，但是想希望通过它来执行子类的一些操作：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;tr1::<span class="built_in">shared_ptr</span>&lt;window&gt;&gt; vpw;</span><br><span class="line">vpw winptr;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">for</span>(vpw::iterator iter=winptr.begin();iter!=winptr.end();++iter)&#123;</span><br><span class="line">    <span class="keyword">if</span>(special* psw=<span class="keyword">dynamic_cast</span>&lt;special*&gt;(iter-&gt;get()))</span><br><span class="line">      psw-&gt;blink();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>上面代码效率比较低，而且令人担心，因此最后直接用子类的容器存储指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;tr1::<span class="built_in">shared_ptr</span>&lt;special&gt;&gt; vpsw;</span><br><span class="line">vpsw winptr;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span>(vpsw::iterator iter = winptr.begin();iter!=winptr.end();++iter)&#123;</span><br><span class="line">  (*iter)-&gt;blink();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是上面的代码童谣失去了指向所有可能子类的可能，<strong>一个可行的解决方案就是为在base class提供一个缺省实现的blink函数声明。或者是直接用上述方式写出子类</strong></p><p>不论是哪一种写法：使用类型安全容器，或将virtual函数往继承体系上方移动，都是一个替代dynamic_cast 的可行方案。</p><p>绝对需要避免的一种写法是连串使用多个dynamic_cast，这种代码将又大又慢，同时十分的不安全。</p><p><strong>总结</strong></p><ul><li>如果可以，尽可能避免转型，特别在注重效率的代码中避免使用<code>dynamic_cast</code></li><li>如果转型是必要的，试着将它隐藏呀某个函数背后，供客户调用</li><li>宁可使用C++新式的转型，因为容易辨认，同时便于排查错误。</li></ul><h3 id="28-条款：避免返回handles指向对象内部成分"><a href="#28-条款：避免返回handles指向对象内部成分" class="headerlink" title="28 条款：避免返回handles指向对象内部成分"></a>28 条款：避免返回handles指向对象内部成分</h3><p><strong>handles指的是诸如reference，指针，迭代器这种用来取得某个对象的变量，我们应当避免直接返回指向对象内部数据或函数的handle出现。</strong></p><p>如下，我们打算实现一个矩阵类：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">point</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    point(<span class="keyword">int</span> x,<span class="keyword">int</span> y);</span><br><span class="line">  ...</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setX</span><span class="params">(<span class="keyword">int</span> val)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setY</span><span class="params">(<span class="keyword">int</span> val)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//定义角</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RectData</span>&#123;</span></span><br><span class="line">  point ulhc;</span><br><span class="line">  point lrhc;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//定义矩阵</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rectangle</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    tr1::<span class="built_in">shared_ptr</span>&lt;RectData&gt; pData;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">point&amp; <span class="title">upper</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> pData-&gt;ulhc;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>upper函数取得矩阵左上角的点，返回一个引用，这个引用指向了矩阵内部的点，就会引发一个矛盾，我们使用一个const函数，但是返回的值是private数据，且可以被修改。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> Rectangle <span class="title">rec</span><span class="params">(coord1,coord2)</span></span>;</span><br><span class="line">rec.upper().setX(<span class="number">50</span>); <span class="comment">//被修改</span></span><br></pre></td></tr></table></figure><p>从从上面我们可以得出两条结论，</p><ul><li>第一条，成员变量的封装性只能等于返回其reference的级别，即引用的级别决定了封装性。</li><li>第二条，如果const成员函数传出一个reference，后者所指的数据与对象自身有关联，而他又被存储与对象之外，那么这个函数的调用者可以修改那笔数据。</li></ul><p>一个好的解决办法就是在函数调用的时候，将返回值的内容设置成const：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> Point&amp; <span class="title">upperLeft</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> pData-&gt;ulhc;&#125;</span><br></pre></td></tr></table></figure><p>但是即使如此，如果直接返回代表对象内部数据的handle的话，有可能这个handle的生存周期比对象本身的生存周期要长，那么将导致空悬指针的发生（dangling handles）。</p><p>因此：<strong>尽量避免将对象内部的handles传出去。</strong></p><p><strong>总结</strong></p><ul><li>避免返回handles指向对象内部，遵守这个条款可以增加封装性，使得const更加像一个const，并避免虚调handles的发生。</li></ul><h3 id="29-条款：为异常安全而努力是值得的"><a href="#29-条款：为异常安全而努力是值得的" class="headerlink" title="29 条款：为异常安全而努力是值得的"></a>29 条款：为异常安全而努力是值得的</h3><p>对于一个异常安全性的函数来说，他通常有两个条件：</p><ul><li><strong>不泄漏任何资源</strong></li><li><strong>不允许数据败坏</strong>：即出现类似空指针，指向已经销毁的对象这种情况</li></ul><p>第一种情况可以通过资源管理类来完美的解决，下面专门来解决第二种情况</p><p><strong>异常安全函数</strong>提供以下三种程度的保证：</p><ul><li><strong>基本承诺：</strong>如果异常被抛出，程序内的任何事物仍然保持在有效状态下</li><li><strong>强烈承诺：</strong>如果异常被抛出，程序状态不改变，如果函数成功就完全成功，如果函数失败，就恢复到调用函数之前的状态。</li><li><strong>不抛掷保证：</strong>承诺不抛出异常，他们总能完成承诺的功能，例如一些内置类型等。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">doSomething</span><span class="params">()</span> <span class="title">throw</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p>上面的函数带有指定的空白异常，也就是说上述函数抛出异常的话，将会产生很严重的后果，但是该函数并不能提供任何异常安全的保证，异常安全的保护正完全由实现来决定。</p><p>对于异常安全来说，保证不抛出异常基本难以实现。基本上能够实现强烈承诺或基本承诺就可以满足需求了。</p><p>实现强烈承诺，即出现异常情况对象的状态不发生改变，有一个策略称为：<strong>copy and swap</strong>，即为打算修改的对象提供一份副本，并在那个副本上做一切必要的修改，如果出现异常，则原对象未发生改变，如果正常则将副本和原对象进行交换。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> pretty::changeBackground(istream&amp; imgSrc)&#123;</span><br><span class="line">  <span class="keyword">using</span> <span class="built_in">std</span>::swap;</span><br><span class="line">  <span class="function">Lock <span class="title">ml</span><span class="params">(&amp;mutex)</span></span>;    <span class="comment">// 获得mutex的副本</span></span><br><span class="line">  tr1::<span class="built_in">shared_ptr</span>&lt;PMImpl&gt; pNew(<span class="keyword">new</span> PMImpl(*pImpl)); </span><br><span class="line">  pNew-&gt;bgImage.reset(<span class="keyword">new</span> Image(imgSrc));</span><br><span class="line">  ++pNew-&gt;imageChanges;</span><br><span class="line">  swap(pImpl,pNew);  <span class="comment">// 释放mutex</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面可以看出来，对函数的异常保证将花费大量的资源，因此如果强烈保证不能满足的情况下，你就应该转向基本满足的情况。</p><p>对于一个对象来说，它的异常保证的级别取决于最差的一个异常保证函数。</p><p><strong>总结</strong></p><ul><li>异常安全函数即使发生异常也不会泄露资源或允许任何数据结构败坏，这样的函数区分为三种可能的保证：基本型，强烈型，不抛异常型</li><li>强烈保证往往能够以copy and swap实现出来</li><li>函数提供的异常安全保证，通常最高值等于其所调用的各个函数的异常安全保证种最弱的</li></ul><h3 id="30-条款：透彻了解inlining-的里里外外"><a href="#30-条款：透彻了解inlining-的里里外外" class="headerlink" title="30 条款：透彻了解inlining 的里里外外"></a>30 条款：透彻了解inlining 的里里外外</h3><p>inline函数，使用起来像函数，调用他们又不用蒙受额外的函数调用所导致的开销，编译器的最优化机制通常被设计成用来浓缩那些<strong>不含函数调用</strong>的代码，因此inline函数也会得到编译器在当前语境下的最优化处理。</p><p>但是过度使用inline同样会导致很多问题，首先是使得程序的目标码过大，导致一些效率上的损失。</p><p><strong>总之，如果inline函数的本体很小，编译器对函数本体所产出的代码可能比函数调用所产出的代码要小，这种情况将函数inlining确实可以导致较小的目标码和较高的指令高速缓存装置的击中率。</strong></p><p><strong>inline函数的做法</strong>：隐喻的做法是将函数定义在class内，自动就完成了inline的操作。明确声明的做法则是在函数前面加上inline关键字。</p><p><strong>inline函数通常一定被放置于头文件内，因为大多数的生成环境在编译过程中进行inline，需要知道函数本体长什么样子。</strong></p><p>模版类templates也通常被置于头文件内，因为它一旦被使用，编译器为了将它具体化，需要知道它长什么样子。但是templates与inline没有直接的联系，如果你觉得该templates内的函数都比较简单，可以进行inline的话，才会去定义为inline。</p><p><strong>inline是一个申请，编译器可以拒绝</strong></p><p>也就是说，一个函数最终实现方式是否是inline，取决于编译器是否同意该函数满足inline的条件。</p><p>例如大部分过于复杂（含循环，递归等）的函数，virtual声明的函数，通常都会被定义为outline函数。</p><p>有些编译器有意愿inlining某个函数，但是也可能为函数生成一个函数本体。<strong>例如程序要取得某个inline函数的地址，编译器通常必须为此函数生成一个outline函数本体。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;...&#125; <span class="comment">//假设编译器有意愿inline对f的调用</span></span><br><span class="line"><span class="keyword">void</span> (*f)()  = f;</span><br><span class="line">f(); <span class="comment">// 调用inline</span></span><br><span class="line">pf(); <span class="comment">// 调用outline的本体</span></span><br></pre></td></tr></table></figure><p>有时候，编译器会为析构函数和构造函数生成一个函数的副本，这样他们就可以获得指针指向那些需要指针的函数，但是这样一来，导致了析构函数和构造函数的赋值过程。</p><p>实际上析构函数，构造函数往往是inline糟糕的候选人，因为C++在创建对象的时候，将构造对象，析构对象，异常处理等一些操作隐藏在析构函数和构造函数内部，因此函数内部存在着很多的对象。但是对这些对象的副本往往会造成很大的资源消耗。</p><p><strong>因此，是否将构造函数和析构函数inline化，是一个慎重的考虑。</strong></p><p><strong>inline函数修改后必须重新编译</strong></p><p>此外，inline函数还存在一个问题。当我们对inline函数进行修改的时候，原来函数的本体因为已经编译进程序的内部了，无法通过函数的链接步骤实现修改，而是需要对整个程序进行重新编译。</p><p><strong>总结</strong></p><ul><li>将大多数inlining限制在小型、被频繁调用的函数身上，这可使得日后的调试过程和二进制升级更加容易，也可使潜在的代码膨胀问题最小化，使得程序速度提升最大化。</li><li>不要滥用inline，不用只因为function templates出现在头文件中就将他们声明为inline，因为很多时候，这些函数不符合inline标准，编译器还是会为他们生成outline版本</li></ul><h3 id="31-条款：将文件间的编译依存关系降至最低"><a href="#31-条款：将文件间的编译依存关系降至最低" class="headerlink" title="31 条款：将文件间的编译依存关系降至最低"></a>31 条款：将文件间的编译依存关系降至最低</h3><p>文件之间的依存关系越是复杂将会导致函数之间的耦合度越高，对修改代码带来不便。</p><p>例如你仅仅对class进行轻微的修改，但是这将导致所有用到这个文件的程序都需要进行重新编译，这一连串的编译依存关系将导致难以形容的灾难。</p><p>例如下面的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"data.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"address.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Person(<span class="keyword">const</span> <span class="built_in">string</span>&amp; name,<span class="keyword">const</span> Date&amp; birthday);</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">birthday</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> thename;</span><br><span class="line">    Data theData;</span><br><span class="line">    address add;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面的类别的私有变量中，string，Data需要用到其他的头文件来创建（实现细则），这些头文件任意一个被修改后都将导致Person class重新编译。</p><p>针对这种形式，我们可以这样做：</p><p><strong>把person分割为两个classes，一个只提供接口，另一个负责实现该接口。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Date</span>;</span>   <span class="comment">// 类的前置声明</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Address</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Person(<span class="keyword">const</span> <span class="built_in">string</span>&amp; name,<span class="keyword">const</span> Date&amp; birthday);</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">birthday</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    str1::<span class="built_in">shared_ptr</span>&lt;PersonImpl&gt; pImpl;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类PersonImpl为person类的实现，这样的话，修改Data类就不需要对Person函数进行重新编译，将person与其他类进行分离。</p><p>这个分离的关键在于：<strong>使用声明的依存性</strong>来代替<strong>定义的依存性</strong>，尽量让头文件自我满足，万一无法做到，那么让它和其他文件内的声明式相依（而不是定义式）。</p><p>下面一些准则都是这个原则下完成的：</p><ul><li>如果使用object references 或objects pointers可以完成任务，就不要使用object，即使用声明式来代替定义式。</li><li><p>尽量以class声明式代替class定义式。</p></li><li><p><strong>为声明式和定义式提供不同的头文件</strong>，为一个文件提供函数的声明，而不是而代替提供class的定义式，这样可将文件见的编译依存关系去掉。因此我们需要定义两个文件，一个是声明式，另一个是定义式。</p></li></ul><p>上面这个实现使得代码编，让Person变成一个handle class。</p><p><strong>抽象基类</strong></p><p>通过制作抽象类的方式，也可以实现这种操作。通过定义抽象类函数接口，创建不同类型的的派生类对象。</p><p>handle classes 和interface class解除了接口和实现之间的耦合关系，从而减低了文件间的编译依存关系。但是也在某种程度上使得每个对象超额付出若干的时间以及空间的成本。</p><p><strong>总结</strong></p><ul><li>支持<strong>编译依存最小化</strong>的一般构想是：相依与声明式，不要相依于定义式，基于此的构想的两个手段是 handle classes，interface classes。</li><li>程序库头文件应该以完全且仅有的声明式的形式存在，这种做法不论是否涉及templates都适用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(四) 设计与声明</title>
      <link href="/2019/11/09/effective-cpp-%E5%9B%9B-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/"/>
      <url>/2019/11/09/effective-cpp-%E5%9B%9B-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<p>2019/11/09 effective cpp 第四章</p><p>良好的cpp接口的设计以及声明是可以令软件作出其最正确的事，包括正确，高效性、封装性、维护性、延展性、以及协议一致性。</p><ul><li>18 条款：让接口容易被正确使用，不易被误用</li><li>19 条款：设计class犹如设计type</li><li>20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value</li><li>21 条款：必须放回对象时，别妄想返回其reference</li><li>22 条款：将成员变量声明为private</li><li>23 条款：宁以non-member、non-friend替换member函数</li><li>24 条款：若所有参数皆需类型转换，请为此采用non-member函数</li><li>25 条款：考虑写出一个不抛异常的swap函数</li></ul><a id="more"></a><h3 id="18-条款：让接口容易被正确使用，不易被误用"><a href="#18-条款：让接口容易被正确使用，不易被误用" class="headerlink" title="18 条款：让接口容易被正确使用，不易被误用"></a>18 条款：让接口容易被正确使用，不易被误用</h3><p>接口开发的目标在于：<strong>让接口容易被正确使用，不易被误用</strong></p><p>但是由于有时候会遇到用户传入的参数和接口能够接受的参数不同，可能会导致错误，这个时候最后通过 <strong>类型系统的方式来预防</strong>，通过导入新的类别来限制数据类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Date</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Date(<span class="keyword">const</span> Month&amp; m,<span class="keyword">const</span> Day&amp; d,<span class="keyword">const</span> Year&amp; y)&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">Date <span class="title">d</span><span class="params">(Month(<span class="number">3</span>),Day(<span class="number">30</span>),year(<span class="number">1995</span>))</span></span>;</span><br></pre></td></tr></table></figure><p>对数据的限制部分在每一个数据类型的函数内部。明智地选择合适的新类型，能够有效的防止接口被误用。</p><p>另一个预防客户错误的方式是限制类型内可做什么事情，不能做什么事情，常见的限制加上const，阻止用户自定义类型错误。</p><p>另一个准则为除非有好的理由，否则应该尽量令你的types的行为和内置的type的行为一致。例如STL中的所有类均有一个size方法，表示长度。</p><p>如果在接口内部有资源的申请，申请的资源必须在最后得到销毁。因此最好的方法就是将函数的返回值设置为shared_ptr：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1:：<span class="built_in">shared_ptr</span>&lt;invest&gt; create();</span><br></pre></td></tr></table></figure><p>此外，shared_ptr还允许绑定一个对象释放函数，当对象释放的时候，shared_ptr调用这个函数来释放对象。定义方式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;invest&gt; pInt(ptr,deleteMethod);</span><br></pre></td></tr></table></figure><p><code>str1::shared_ptr</code>会自动调用每个使用它的指针专属的删除器，避免跨DLL文件delete导致运行期的错误。<strong>shared_ptr会调用指针的专属删除器</strong>。</p><p>shared_ptr在效率和空间上是用指针的两倍大，使用辅助动态内存，比原始指针要大。</p><p><strong>总结</strong></p><ul><li>设计不容易出错的接口</li><li>保证接口之间的一致性</li><li>阻止误用，建立新类型的方式限制类型上的操作，消除客户资源管理的任务</li><li>Tr1::shared_ptr支持定制删除器，防范DLL问题</li></ul><h3 id="19-条款：设计class犹如设计type"><a href="#19-条款：设计class犹如设计type" class="headerlink" title="19 条款：设计class犹如设计type"></a>19 条款：设计class犹如设计type</h3><p>当你定义了一个新的class，也就定义了一个type，设计好的type有自然的语法和直观的语义，有一下的设计规范：</p><ul><li>新type的对象应该如何创建和销毁</li><li>对象初始化和对象的赋值该有什么样的差别</li><li>新type对象如果被传值（passed by value）该在copy函数中写实现方法</li><li>对type的合法值进行约束</li><li>新的type是否需要配合继承图系</li><li>新type需要什么样的类型转换</li><li>什么样的操作符和函数对新type是合理的</li><li>什么样的标准函数需要驳回</li><li>谁该去用新type成员</li><li>什么是新type的未声明接口</li><li>type的一般化程度</li><li>你真的需要一个新type吗</li></ul><p><strong>总结</strong></p><p>设计一个class的时候，需要充分考虑上面的问题，具体所指可以参考书本84页。</p><h3 id="20-条款：宁以-pass-by-reference-to-const-替换-pass-by-value"><a href="#20-条款：宁以-pass-by-reference-to-const-替换-pass-by-value" class="headerlink" title="20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value"></a>20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value</h3><p>C++默认以传值的方式给函数传递参数，这一过程函数参数的初值都是调用对象的构造函数来实现，当离开这个函数的时候，通过析构函数来回收这些资源，因此传值的方式将会耗费大量的资源和时间。</p><p>一个很好的优化方法就是使用const 引用的方式，这种方式没有任何的构造函数被调用。之所以使用const，是为了保证传入的参数对象不会被改变。</p><p>此外如果直接传值，对于参数类型为父类的情况，传入子类对象，会造成子类特化功能被切割，参数的行为与父类相同，但是如果使用传引用的方式，这种现象不会发生。</p><p>说到这里，我们会好奇，引用到底是个什么东西呢，其实际上运用是通过指针的方式来实现的，传递引用等同于传递指针，<strong>对于内置类型来说，传值方式会比传指针的方式更加高效。</strong> 对于int，float这些类型，直接通过传值的方式更加的高效。</p><p><strong>总结</strong></p><ul><li>尽量以传const引用的方式替换传值的方式，前者通常比较高效，避免对象切割问题</li><li>对于内置类型以及STL迭代器，函数对象来说，直接传值比较高效</li></ul><h3 id="21-条款：必须放回对象时，别妄想返回其reference"><a href="#21-条款：必须放回对象时，别妄想返回其reference" class="headerlink" title="21 条款：必须放回对象时，别妄想返回其reference"></a>21 条款：必须放回对象时，别妄想返回其reference</h3><p>当我们尝试消灭所有的传值行为的时候，我们可能会对函数的返回值下手，这种做法是不可取的。</p><p>所谓的引用，即表明它所指代的对象一定要存在，在函数中我们有两种方式创建对象：</p><p><strong>创建对象在stack内存上</strong></p><p>stack内存存放函数的参数，局部变量值，由编译器自动释放：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration&amp; <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  <span class="function">Ration <span class="title">result</span><span class="params">(lhs.n*rhs.n)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上买代码返回了一个局部变量的引用，但是由于出了这个函数，局部变量就会被销毁，因此这个reference将毫无意义。</p><p><strong>创建对象在heap内存上</strong></p><p>用户自己分配，自己销毁的资源都会分配在heap内存上，有new-delete对来管理。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration&amp; <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  Ration* result = <span class="keyword">new</span> Ration(lhs.n*rhs.n);</span><br><span class="line">  <span class="keyword">return</span> *result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面返回的引用是有意义的，但是当我们使用完这个 内存之后，由谁去销毁呢，在一些很复杂的操作里面，程序员往往无法保证资源的完全回收。</p><p><strong>使用static变量</strong></p><p>在函数内部定义static变量，该变量的生命周期是整个程序的生命周期，static变量，全局变量他们的值都是存放在同一块区域，由程序结束后统一回收。</p><p>但这又引发了另一个问题，你想要比较两个数相乘后与另外两个数相乘的大小，但是结果存放在static当中，程序只会保存一份static的结果，因此永远无法比较。</p><p>因此，<strong>如果函数要求返回一个对象，那么我们就承担返回值所产生的构造和析构成本</strong>，不要试图去放回引用。</p><p><strong>总结</strong></p><p>不要返回一个指针或引用指向一个local对象，或指向heap-allocated对象，或指向static对象，而是直接返回该对象（传值）。</p><h3 id="22-条款：将成员变量声明为private"><a href="#22-条款：将成员变量声明为private" class="headerlink" title="22 条款：将成员变量声明为private"></a>22 条款：将成员变量声明为private</h3><p>为保证成员便来那个的约束性，对用户隐藏变量，使得类中的约束条件总会收到维护。如果将一个变量声明为public，破坏了封装性，在我们修改该变量的时候，我们无法预知这个变量所涉及的一切，可能会对程序造成极大的破坏。因此保护类的封装性。protected类型与public相似，其实只有来那个两种访问权限：<strong>private（提供封装）和其他（不提供封装）</strong></p><p><strong>总结</strong></p><ul><li>切记将成员变量声明为private，这可赋予客户访问数据一致性，细微划分访问控制，允许约束条件获得保护，并 提供class作者充分的实现弹性。</li></ul><h3 id="23-条款：宁以non-member、non-friend替换member函数"><a href="#23-条款：宁以non-member、non-friend替换member函数" class="headerlink" title="23 条款：宁以non-member、non-friend替换member函数"></a>23 条款：宁以non-member、non-friend替换member函数</h3><p>这个条款的核心在于：<strong>越少的操作直接接触到数据，对类的封装性，代码的维护越好</strong>。因此如果一些操作可以由非成员函数来完成的话，就不要去写那个成员函数的版本。</p><p>越少的函数接触到数据，我们在改变数据的时候，就可以有越大的灵活度修改这个数据。</p><p>有几种方式可以去实现非类内函数来完成这个操作：</p><ul><li>例如我们指提供了一个完成基础操作的类，我们可以选择另一个类中的函数，传入这个对象，来实现你想要的操作，而不用为基础类添加成员</li><li>C++的一个常用的做法是，将non-member函数与类写在同一个命名空间中，命名空间可以跨越多个源码文件。将所有便利函数放在多个头文件内，但同属于一个命名空间，以为着用户可以轻松扩展这一组便利函数</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//头文件webbrowser.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowserStuff&#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">webbrowser</span>&#123;</span>...&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//头文件webbrowserbook.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowserbook&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 头文件webbrowsercookies.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowsercookies&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过include需要的头文件的方式来管理标准程序库，使得那一小部分系统形成编译相依的关系。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//web.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> wweb&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">web</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="built_in">string</span> <span class="title">get_name</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name;</span><br><span class="line">        &#125;</span><br><span class="line">        web(<span class="built_in">string</span> n):name(n)&#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say_hi</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="built_in">string</span> name;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//web.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"web.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span>::wweb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> web::say_hi() &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"hihi"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>宁可用non-member函数替代member函数，这可增加类的封装性，包裹性，机能扩充性。</li><li>non-member的函数通常与class定义在同一个命名空间内</li></ul><h3 id="24-条款：若所有参数皆需类型转换，请为此采用non-member函数"><a href="#24-条款：若所有参数皆需类型转换，请为此采用non-member函数" class="headerlink" title="24 条款：若所有参数皆需类型转换，请为此采用non-member函数"></a>24 条款：若所有参数皆需类型转换，请为此采用non-member函数</h3><p>当我们传入参数都需要进行类型转换的时候，如果将类函数写成如下情况：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ration</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">    <span class="keyword">const</span> Ration <span class="keyword">operator</span>* (<span class="keyword">const</span> Ration&amp; rhs) <span class="keyword">const</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Ration <span class="title">oneE</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">Ration result = oneE*<span class="number">2</span>; <span class="comment">// C++将2转换成Ration类型</span></span><br><span class="line">Ration result = <span class="number">2</span>*oneE; <span class="comment">// 编译错误，因为this不可以作为类型转换的变量</span></span><br></pre></td></tr></table></figure><p>只有当参数可位列于参数列中内，这个参数才允许隐式转换，因此一个比较好的方法就是非类内函数去实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>能够避免使用友元的情况就一定要避免使用它。</p><p><strong>总结</strong></p><p>如果需要为某个函数的所有参数进行类型的转换，那么这个函数必须是个non-member。</p><h3 id="25-条款：考虑写出一个不抛异常的swap函数"><a href="#25-条款：考虑写出一个不抛异常的swap函数" class="headerlink" title="25 条款：考虑写出一个不抛异常的swap函数"></a>25 条款：考虑写出一个不抛异常的swap函数</h3><p>swap函数的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">namspace <span class="built_in">std</span>&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a,T&amp; b)</span></span>&#123;</span><br><span class="line">    <span class="function">T <span class="title">temp</span><span class="params">(a)</span></span>;</span><br><span class="line">    a = b;</span><br><span class="line">    b = temp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只要支持copying，swap就会完成交换。但是上面这种方法需要不断的构造，析构。于是我们选择特性化swap，<strong>通过置换指针的方式就可以达到置换的效果</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(Widget&amp; other)</span></span>&#123;</span><br><span class="line">      <span class="keyword">using</span> <span class="built_in">std</span>::swap;  <span class="comment">//令std内的swap函数可见</span></span><br><span class="line">      swap(pInt,other.pInt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;  <span class="comment">//告诉编译器，这是个全特化的版本</span></span><br><span class="line">  <span class="keyword">void</span> swap&lt;Widget&gt;(Widget&amp; a,Widget&amp; b)</span><br><span class="line">  &#123;</span><br><span class="line">    a.swap(b);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此优化copy：</p><ul><li>提供一个public swap成员函数，让它高效置换你的类型的两个对象值，且不能抛出异常。（置换基本类型）。</li><li>在class或template所在命名空间中提供一个non-member swap函数，并令他调用上述的swap成员函数。</li><li>如果你正编写一个class，为你的class特化std::swap，并调用你的swap。</li></ul><p><strong>总结</strong></p><ul><li><p>当std::swap对你的类型效率不高的时候，提供一个swap成员函数，并确保不抛出异常</p></li><li><p>提供一个member swap函数，也应该提供一个non-member swap用来调用前者，对于classes也请特化std::swap。</p></li><li>调用 swap时应该针对std::swap使用using声明式，然后调用swap并且不带任何命名空间资格修饰。</li><li>为“用户定义类型”进行std::template全特化是好的但是千万不要尝试在std内部加上对std而言全新的东西。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>EncNet结合上下文的语义分割</title>
      <link href="/2019/11/06/EncNet%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
      <url>/2019/11/06/EncNet%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</url>
      
        <content type="html"><![CDATA[<p>《Context Encoding for Semantic Segmentation》是发表在2018年cvpr上的文章，文章的主要insight在于将图像中的内容信息加入到语义分割的网络中，通过一个context encoding module突出图像类别，对分类类别进行简化，降低分割的难度，提升分割的精度。</p><a id="more"></a><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>目前的分割网络主要的关注点在于pixel-level predict，即对每个像素进行类别的分类。从2016年提出的FCN分割网络开始，图像分割实现了一个端到端的分割，当时由于CNN-pooling的网络设计，使得FCN网络对数据的丢失严重。为了解决这个问题，人们提出了dilated conv以及特征金字塔等（deeplab）结构来解决这个问题，即扩大feature map的感受野的同时，保证feature map的分辨率，保留大部分的数据。</p><p>EncNet另辟蹊径，认为通过图像中给出的类别信息能够对分割种类进行缩小，找到一个比较小的子集，在该类别的子集上进行语义的分割，简化分割问题。本文给出了两个主要的贡献：</p><ol><li>本文提出了一个context encoding mudule模块，以及一个SE-Loss，一个简单的单元来利用全局的场景内容信息学到不同channel的权重，以及学到场景中所包含的类别。</li><li>EncNet，作者的第二个贡献就是提出了EncNet这个网络，能勾在许多公开的语义分割的数据集上取得state of the art的效果。</li></ol><p>下面来看一下作者具体是怎么实现的：</p><p><img src="/images/3D/encnet.png" style="zoom:40%;"></p><h3 id="Context-Encoding-Module"><a href="#Context-Encoding-Module" class="headerlink" title="Context Encoding Module"></a>Context Encoding Module</h3><p><strong>context Enocding</strong></p><p>作者通过使用一系列的卷积层（空洞卷积）去学习一个内在的语义字典的表示，将这个字典作为编码语义，为了方便使用上下文，去学习预测了一组缩放因子用于突出和类别相关的特征图。</p><p>将feature map的大小reshape成二维（WxH）x C，去学习codebook $D = {d_1,d_2,…d_k}$ ,以及一组和视觉中心平滑因子$S = {s_1,s_2,…s_k}$,编码层输出残差编码，通过soft-assignment进行聚合，$e_k = \sum_{i=1}^{N}e_{ik}$，其中$e_{ik}$ 如下：<br>$$<br>\begin{equation}<br>e_{i k}=\frac{\exp \left(-s_{k}\left|r_{i k}\right|^{2}\right)}{\sum_{j=1}^{K} \exp \left(-s_{j}\left|r_{i j}\right|^{2}\right)} r_{i k}<br>\end{equation}<br>$$<br>其中$r_{ik} = x_i - d_k$作为残差加入计算，其中$e = \sum_{k=1}^{K}\phi(e_k)$，对所有的ek进行batch normalization得到e，作为编码层的输出。</p><p><strong>feature attention</strong></p><p>通过编码层输出的e，来学习一组缩放因子，用于强调和抑制一些不同的类别。缩放因子通过全连接层进行学习，最得到一组缩放因子如下：<br>$$<br>\gamma = \sigma(We)<br>$$<br>其中w为全连接层的参数，$\sigma$为sigmoid函数，最终将得到的缩放因子与输入的深度图进行相乘得到最终权重改变后的feature map。</p><p><strong>Semantic Encoding Loss</strong></p><p>作者为了能够更好的理解图片与类别之间的关系，从图像中直接预测出图像中所包含的类别，将编码层的输出传入另一个全连接层中，GT为图片中已有的类别，通过最小化SE-Loss，即二次的交叉熵loss，判断60个类，存在或不存在的方式，来建立图像全局信息与类别之间的映射关系。最终对图像中的类别进行一个削减。</p><h3 id="Context-Encoding-Network"><a href="#Context-Encoding-Network" class="headerlink" title="Context Encoding Network"></a>Context Encoding Network</h3><p>EncNet网络的backbone使用的是resnet，同时使用了之前证明有效的dilated conv，在深度图的state3，和4阶段使用了空洞卷积：</p><p><img src="/images/3D/dilated.png" style="zoom:50%;"></p><p>在stage3位置上同样适用了SE-loss，作为一个额外的正则化的操作，encnet在FCN的基础上进行一些小的改动，通过增加一些轻微的计算量就可以达到一个很好的效果。</p><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>pixAcc：像素类别预测正确的像素除以所有像素的比例。</p><p>mIoU：每一类预测结果与GT的结果的IoU的平均值。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>看完整篇文章，这篇文章最大的亮点就是认为<strong>飞机不会出现在房间里</strong>，利用图像的feature map，与类别GT，建立一个映射，从而在做最终的逐像素的语义分割的问题时，没必要在所有的类别上做，而是直接在根据图像feature map上映射得到的类别上做，降低了语义分割的难度。</p><p>对图像整个内容信息的提取上，主要由两部分构成，一部分对不同的channel学习一个重要性权重，另一个直接通过图像内容学习一个图像中含有的类别。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之评分预测（三）</title>
      <link href="/2019/11/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89/"/>
      <url>/2019/11/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>评分问题，根据已有的评分，或者用户、物品的评分规则对物品进行评分的预测。</p><a id="more"></a><p><strong>离线实验方法</strong></p><p>评分的预测基本上都是通过离线实验进行研究的。研究者通过将数据分成训练集和测试集的方式，根据训练好的兴趣模型，对测试集进行评分。一般使用的度量方法为RMSE：<br>$$<br>\operatorname{RMSE}=\frac{\sqrt{\sum_{(u, i) \in T}\left(r_{u i}-\hat{r}_{u i}\right)^{2}}}{|\mathrm{Test}|}<br>$$</p><h3 id="评分预测算法"><a href="#评分预测算法" class="headerlink" title="评分预测算法"></a>评分预测算法</h3><h3 id="平均值"><a href="#平均值" class="headerlink" title="平均值"></a>平均值</h3><p>通过计算训练集中的全局平均值，作为测试集中的评分。</p><p><strong>用户评分平均值</strong></p><p>用户的评分平均值为用户历史评分的平均值，作为他之后评分的一个值。</p><p><strong>物品评分平均值</strong></p><p>对物品的所有评分计算平均值，作为它在训练集中的所有评分的平均值。</p><p><strong>用户分类对物品分类的平均值</strong></p><p>同类的用户对同类的物品的评分的平均值作为物品的评分。</p><p><strong>用户和物品的平均分</strong></p><p>将用户和物品按照评分从高到低分成平均分成N类。</p><p><strong>用户活跃度和物品流行度</strong></p><p>用户活跃度和物品的流程度从大到小平均分成N类。</p><h3 id="基于领域的方法"><a href="#基于领域的方法" class="headerlink" title="基于领域的方法"></a>基于领域的方法</h3><p>基于领域的方法认为一个用户对一个物品的评分需要参考和着高哟高糊兴趣相似的用户对该物品的评分。<br>$$<br>\hat{r}_{u i}=\bar{r}_{u}+\frac{\sum_{v \in S(u, K) \cap N(i)} w_{u v}\left(r_{v i}-\bar{r}_{v}\right)}{\sum_{v \in S(u, K) \cap N(i)}\left|w_{u v}\right|}<br>$$<br>其中w为用户之间的相似度，可以通过皮尔逊系数来计算：<br>$$<br>w_{u v}=\frac{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right) \cdot\left(r_{v i}-\bar{r}_{v}\right)}{\sqrt{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right)^{2} \sum_{i \in I}\left(r_{v i}-\bar{r}_{v}\right)^{2}}}<br>$$<br>基于五瓶的领域算法在预测用户对物品的评价的时候，会参考用户对相似物品评价的评分：<br>$$<br>\hat{r}_{u i}=\bar{r}_{i}+\frac{\sum_{j \in S(u, K) \cap N(u)} w_{i j}\left(r_{u j}-\bar{r}_{i}\right)}{\sum_{j \in S(i, F) \cap W(u)}\left|w_{i j}\right|}<br>$$<br>其中w为普通的优先相似度、皮尔逊系数，修正的余弦相似度三种之一，具体那种效果好，需要看具体的实验。</p><h3 id="隐语义模型与矩阵分解模型"><a href="#隐语义模型与矩阵分解模型" class="headerlink" title="隐语义模型与矩阵分解模型"></a>隐语义模型与矩阵分解模型</h3><p>评分系统可以写成一个评分矩阵R，其中每一个位置就是用户对物品的一个评分。传统的方法通过降维的方式对评分矩阵进行填充。</p><p><strong>传统的SVD分解</strong></p><p>一个直观的想法就是，补全之后的矩阵对不全之前的矩阵扰动最小，补全后的特征值和补全之前的特征值相互差异不大。</p><p>一开始可以使用全局平均值对矩阵进行填充，然后进行矩阵的SVD分解，然后选择其中特征向量topN保留，得到一个降维之后的评分矩阵。</p><p>SVD分解有一个问题，就是它本上是十分稀疏的，95%都是空的，但是通过这种方式进行填充之后变得非常的大，计算复杂度很高，难以实际应用。</p><p><strong>simon Funk SVD</strong></p><p>simon对传统的SVD进行改造，直接将评分矩阵分解成两个低维度的矩阵相乘：<br>$$<br>\hat{r}_{u i}=\sum_{f} p_{u f} q_{i f}<br>$$<br>于是通过最小化RMSE误差，加上参数的正则化项，从而得到：<br>$$<br>C(p, q)=\sum_{(u, i) \in \mathrm{Train}}\left(r_{u i}-\sum_{f=1}^{F} p_{u f} q_{i f}\right)^{2}+\lambda\left(\left|p_{u}\right|^{2}+\left|q_{i}\right|^{2}\right)<br>$$<br>通过随机梯度下降法，去学习p，q矩阵，最终得到评分表中的缺失的评分。</p><p><strong>加入偏执的LFM</strong></p><p>在上一个方法的基础上，有人提出了许多改进的方法，提出了很多偏执，对算法进行修正：<br>$$<br>\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}<br>$$<br>u为评分的全局平均数，b为用户喜好的偏执（用户评分随意或者很苛刻的情况），后一个b为物品品质的偏执（评分都很高，或都很低的情况）。</p><p><strong>加入时间信息</strong></p><p>基于领域的融合时间的模型，考虑用户评分年时间对推荐结果的影响：<br>$$<br>\begin{equation}<br>\hat{r}_{u i t}=\frac{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right) r_{u j}}{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right)}<br>\end{equation}<br>$$</p><p>$$<br>\begin{equation}<br>\begin{array}{c}{f\left(w_{i j}, \Delta t\right)=\sigma\left(\delta \cdot w_{i j} \cdot \exp \left(\frac{-|\Delta t|}{\beta}\right)+\gamma\right)} \ {\sigma(x)=\frac{1}{1+\exp (-x)}}\end{array}<br>\end{equation}<br>$$</p><p>随着$\Delta t$d的变大，影响力就会变小。</p><p><strong>模型的融合</strong></p><p>模型融合基本上分成两种方式：</p><ul><li>模型级联融合，上一个模型的输出最为下一个模型的输入，每个模型在上一个模型的基础上进行学习。</li><li>模型加权融合，用K个模型去预测最终的结果，首先将训练集A分成A1，A2，然后在A1上训练K个模型，利用A2训练集，去学习每个模型的权重。然后在B上进行最终的评分预测，这样的好处就是防止模型过拟合。</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><strong>时间上上下文信息</strong></p><p>用户的兴趣以及推荐的物品与时间的关系十分的相关，必要将时间加入到推荐算法当中去。例如在协同过滤的基础上加上时间衰减函数，如判断两个物体的相似性：<br>$$<br>\begin{equation}<br>\operatorname{sim}(i, j)=\frac{\sum_{u \in N(0) \cap N(i)} f\left(\left|t_{u i}-t_{u |}\right|\right)}{\sqrt{|N(i)||N(j)|}}<br>\end{equation}<br>$$<br>其中时间衰减函数如下：<br>$$<br>\begin{equation}<br>f\left(\left|t_{u i}-t_{u j}\right|\right)=\frac{1}{1+\alpha\left|t_{u i}-t_{u j}\right|}<br>\end{equation}<br>$$<br>当两个商品购买的时间相差比较远的话，时间衰减函数那一项就会比较小。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(三) 资源管理</title>
      <link href="/2019/11/05/effective-cpp-%E4%B8%89-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"/>
      <url>/2019/11/05/effective-cpp-%E4%B8%89-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>2019/11/05 effective cpp 第三章</p><p>CPP程序运行中，将会动态申请内存、文件描述器、互斥锁等一些重要的资源，必须及时归还系统。</p><ul><li>13 条款：以对象管理资源</li><li>14 条款：</li></ul><a id="more"></a><h3 id="13-条款：以对象管理资源"><a href="#13-条款：以对象管理资源" class="headerlink" title="13 条款：以对象管理资源"></a>13 条款：以对象管理资源</h3><p>若一个基类通过一个工厂函数，得到若干个子类的地址指针，在使用完这些子类之后，需要将他们回收，下面写一个回收的函数对他们进行回收：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123;</span><br><span class="line">  Invest* ptr = create();</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">delete</span> ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的代码可以完美的运行，但是在一些特定的情况下，如果程序在delete之前中途退出了，这将导致分配的资源无法得到释放。一个比较可靠的做法是：</p><p><strong>把资源放进对象内，当需要销毁资源的时候，使用C++的析构函数自动调用机制，确保资源的释放。</strong></p><p><strong>auto_ptr</strong></p><p>许多资源被动态分配到heap内，被用于函数内。它们应该在控制流离开那个函数的时候被释放，auto_ptr智能指针就是为此设计的一个<strong>类指针对象</strong>，由析构函数对其所指对象调用delete。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">auto_ptr</span>&lt;invest&gt; Ptr(create());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的做法体现了两条回收资源的设计：</p><ul><li><strong>获得资源后，立即放入管理对象内：</strong>资源对象创建的最佳时期就是资源获取的时机。最好的方式是获取资源的同一个语句内使用它初始化某个管理对象</li><li><strong>管理对象运用析构函数确保资源被释放：</strong>不论控制流如何离开区块，一旦对象被销毁，析构函数自动销毁所获得的资源。</li></ul><p>auto_ptr对象离开它的有效范围之后，就将自动销毁分配的资源。但是有一个缺陷，它不允许多个auto_ptr指向同一块区域，这样会造成一个对象被多次的删除。为了防止这个问题，auto_ptr中有一个特性，如果通过拷贝函数复制他们，之前的指针将会变成null，复制后的指针得到资源的唯一拥有权。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">auto_ptr</span>&lt;invest&gt; ptr1(create());</span><br><span class="line"><span class="built_in">auto_ptr</span>&lt;invest&gt; ptr2(ptr1);  <span class="comment">// 此时ptr1变成null</span></span><br></pre></td></tr></table></figure><p>auto_ptr的替代方案使用<code>tr1::shared_ptr</code>，这个对象类将持续追踪共有多少指针指向某个资源，但是在环形引用时无法打破。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123; </span><br><span class="line"> tr1::<span class="built_in">shared_ptr</span>&lt;invest&gt; ptr(create());</span><br><span class="line"> tr1::<span class="built_in">shared_ptr</span>&lt;invest&gt; ptr1(ptr); <span class="comment">// ptr，ptr1指向同一个对象</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述例子告诉我们，当我们手动释放资源的时候，容易发生错误，罐装式的资源管理类如auto_ptr, shared_ptr可以比较好的准守这条规则。</p><p><strong>总结</strong></p><ul><li>防止资源浪费，使用RAII对象，在他们的构造函数中获得资源，在析构函数中释放资源。</li><li>使用RAII中的tr1::shared_ptr，auto_ptr是两个比较好的选择，shared_ptr具有比较正常的copy。</li></ul><h3 id="14-条款：在资源管理类中小心copying行为"><a href="#14-条款：在资源管理类中小心copying行为" class="headerlink" title="14 条款：在资源管理类中小心copying行为"></a>14 条款：在资源管理类中小心copying行为</h3><p>通常使用auto_ptr,shared_ptr作为资源管理类，但是有些资源并非在heap-based，不实用使用上述的两种资源管理类，因此需要建立自己的资源管理类。</p><p>自己定义的资源管理类通常在构造函数的部分申请得到资源，在析构函数中释放资源，这种类型的资源包括了互斥锁。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lock</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>：</span><br><span class="line">    explicit Lock(Mutex* pm):mutexPtr(pm)&#123;  // 在初始化资源类的时候，初始化资源</span><br><span class="line">      lock(mutexPtr);</span><br><span class="line">  &#125;</span><br><span class="line">  ~Lock()&#123;unlock(mutexPtr);&#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">   Mutex* mutexPtr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样的，对于资源管理类来说，如果对象被复制，我们需要处理对象的复制问题。可以让它继承UnCopyable对象，禁止对象的复制。或者使用shared_ptr的方法，<strong>使用引用计数法</strong>，使用shared_ptr来定义指针。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shared_ptr</span>&lt;Mutex&gt; mutexPtr;</span><br></pre></td></tr></table></figure><p>这时候就可以不用定义虚析构函数了，当指针被回收的时候，资源就会被回收。</p><p><strong>转移底层的资源拥有权</strong></p><p>使用类似于auto_ptr的做法，copy的时候，保证资源的唯一性。</p><p><strong>总结</strong></p><ul><li>复制RAII对象（资源管理对象）需要一并复制它所管理的资源，资源的copying行为决定了RAII对象的copying行为。</li><li>普遍常见的RAII copying行为通常为：抑制copying，使用引用计数法，转移底层资源的拥有权。</li></ul><h3 id="15-条款：在资源管理类中提供对原始资源的访问"><a href="#15-条款：在资源管理类中提供对原始资源的访问" class="headerlink" title="15 条款：在资源管理类中提供对原始资源的访问"></a>15 条款：在资源管理类中提供对原始资源的访问</h3><p>资源管理类通常是我们设计来保证资源的正常申请和销毁的，但是有些情况是，我们调用一些函数的时候需要直接访问内部的资源（例如一些指针类）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Invest&gt; pInt(create()); <span class="comment">// pInt是一个资源类对象</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">daysHeld</span><span class="params">(<span class="keyword">const</span> Invest* pi)</span></span>; <span class="comment">// pi是一个invest* 对象</span></span><br></pre></td></tr></table></figure><p>当我们要调用daysHeld()函数的时候，传入的参数如果为pInt的话会发生错误，因为pInt是一个资源类对象，因此我们需要从这个资源类对象中取出其中的指针资源。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">daysHeld(pInt.get());</span><br></pre></td></tr></table></figure><p>shared_ptr,auto_ptr继承了原是指针中的<code>-&gt;,*</code>操作，并且可以通过get函数得到资源的直接访问。</p><p>当我们选择自己实现资源管理类的时候，我们也需要实现一个get函数，实现显示的函数变换。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Font</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    explicit Font(Fhandle fh):f(fh)&#123;&#125;</span><br><span class="line">    ~Font()&#123;release(fh);&#125;</span><br><span class="line">    <span class="function">FHandle <span class="title">get</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> fh;&#125; <span class="comment">// 实现直接获取资源的函数</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    FHandle fh;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过实现<code>operator FHandle() const {return fh;}</code>函数可以实现隐式的变换，但是这样容易造成错误的发生，因此建议使用显式的变换（get的方式）。</p><p><strong>总结</strong></p><ul><li>API中往往要求访问原始资源，所以每一个RAII类中应该要实现一个直接获取志愿的方法（get方法）。</li><li>对原始资源的访问可能是显式变换或者隐式的变换，一般而言显式变换比较安全。</li></ul><h3 id="16-条款：成对使用new和delete时要采取相同形式"><a href="#16-条款：成对使用new和delete时要采取相同形式" class="headerlink" title="16 条款：成对使用new和delete时要采取相同形式"></a>16 条款：成对使用new和delete时要采取相同形式</h3><p>new在被使用的时候，可以申请单个内存（<code>new int</code>）或多个内存（<code>new int[10]</code>），delete再回收内存的时候，也有回收单一内存和连续内存的区别，需要注意的是，new和delete行为必须一致（单一内存和多内存的一致。）</p><p><strong>总结</strong></p><ul><li>new中使用[]必须在delete中也使用[]（连续内存），new中不使用[]，delete中也不能使用[]（单一）。</li></ul><p>下面补充一下CPP中new和delete的用法：</p><p><strong>new的使用</strong></p><p>new负责C++中的动态内存分配，动态内存位于heap上。在不使用这段内存的时候，程序需要负责将这段内存回收掉。</p><p>new指令初始化内存，返回内存分配的初始地址：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pointer-variable = <span class="keyword">new</span> data-type;</span><br><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>;</span><br></pre></td></tr></table></figure><p>可以<strong>使用括号的方式初始化对象</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">10</span>);</span><br></pre></td></tr></table></figure><p><strong>使用中括号[]的方式分配一整块内存空间：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br></pre></td></tr></table></figure><p>传统的申请内存的方式为<code>int a[10];</code> 这个空间由编译器申请，在使用结束之后也由编译器进行回收。但是自己申请的内存会一直存在，直到自己delete处理掉。</p><p><strong>delete的使用</strong></p><p>使用delete对new申请的数组进行清空：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> p; <span class="comment">// 删除单个元素</span></span><br><span class="line"><span class="keyword">delete</span>[] p; <span class="comment">// 删除整段空间</span></span><br></pre></td></tr></table></figure><h3 id="17-条款：以独立语句将newed对象置入智能指针"><a href="#17-条款：以独立语句将newed对象置入智能指针" class="headerlink" title="17 条款：以独立语句将newed对象置入智能指针"></a>17 条款：以独立语句将newed对象置入智能指针</h3><p>可以使用智能指针的方式来管理new申请的内存：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Widget&gt; pw(<span class="keyword">new</span> Widget);</span><br></pre></td></tr></table></figure><p>存在一种情况，当我们使用资源管理类来管理内存的时候，可能会出现内存泄漏。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">process(str1::<span class="built_in">shared_ptr</span>&lt;Wdiget&gt;(<span class="keyword">new</span> Widget),priority());</span><br></pre></td></tr></table></figure><p>上面代码可能的执行顺序是(顺序不一定)：</p><ol><li>new widget</li><li>priority</li><li>Shared_ptr构造函数</li></ol><p>如果第二步抛出异常，那么造成内存泄漏，因此：<strong>newed对象应当写一个单独的语句</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Widget&gt; pw(<span class="keyword">new</span> Widget);</span><br><span class="line">process(pw,priority());</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>以单独的语句将newed对象存储在智能指针内，确保资源不会泄露。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之用户标签数据(二)</title>
      <link href="/2019/11/05/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE-%E4%BA%8C/"/>
      <url>/2019/11/05/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<p>推荐系统的目的是链接用户的兴趣和物品，通常的连接方式可以通过：</p><ol><li>推荐与用户喜欢的物品相似的物品</li><li>推荐与用户兴趣相似的人所喜欢的物品</li><li>给用户推荐那些他喜欢的特征，例如利用用户标签</li></ol><p><strong>标签是一种无层次化结构的，用来描述信息的关键词，它可以用来描述物体的语义。</strong></p><a id="more"></a><h3 id="标签系统中推荐问题"><a href="#标签系统中推荐问题" class="headerlink" title="标签系统中推荐问题"></a>标签系统中推荐问题</h3><p><strong>用户为什么进行标注</strong></p><p>用户通常会给予社会维度、功能维度、传达信息的维度上对物品进行标注。</p><p><strong>用户如何打标签</strong></p><p>用户打标注的标签同样符合一个长尾分布，一些不流行的标签呈现一个长尾。</p><p><strong>用户打什么样的标签</strong></p><ul><li>表明物品是什么</li><li>物品的种类</li><li>用户的观点</li><li>谁拥有用户</li><li>用户相关的标签</li><li>用户的任务</li><li>类型</li><li>时间，人物，地点，语言，奖项</li></ul><h3 id="基于标签的推荐系统"><a href="#基于标签的推荐系统" class="headerlink" title="基于标签的推荐系统"></a>基于标签的推荐系统</h3><p><strong>数据的设计</strong></p><p>一个用户标签的行为的数据集一般由一个三元组的集合表示：(u,i,b)表示用户u给物品i打上了标签b。将数据随机分成10份，分割的键值是用户和物品，其中9份作为训练集，1份作为测试集。</p><p><strong>实验指标</strong></p><p>准确率、召回率、覆盖率、余弦相似度、新颖性（平均热门度）</p><p><strong>一个简单的算法</strong></p><p>利用用户标签进行个性化的推荐，一个直接的想法：</p><ol><li>统计每个用户最常用的标签</li><li>对每个标签，统计被打过这个标签次数最多的物品</li><li>对每个用户找到他最常用的标签，然后给他推荐具有这些标签的最热门的物品</li></ol><p>因此可以归纳出兴趣公式：<br>$$<br>p(u, i)=\sum_{b} n_{u, b} n_{b, i}<br>$$<br>$n_{u,b}$表示用户u打过标签b的次数，$n_{b,i}$ 表示物品i被打过b标签的次数。</p><p><strong>算法的改进：TF-IDF</strong></p><p>对于热门标签，它在许多物品上都有出现过，因此上述的公式对热门标签对应的热门物品给了过大的权重，系统将会倾向于推荐热门的物品，因此将降低推荐结果的新颖性，因此对<strong>热门标签</strong>进行惩罚：<br>$$<br>p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} n_{b, i}<br>$$<br>此外对<strong>热门物品</strong>进行惩罚：<br>$$<br>p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} \frac{n_{b, i}}{\log \left(1+n_{i}^{(u)}\right)}<br>$$<br><strong>数据稀疏性</strong></p><p>对于一些新用户或新物品，用户集合中的标签数量很小，可以我们可以将与已有标签相似的标签加入到用户标签中。</p><p>可以利用基于领域的方法，当两个标签同时出现在许多物品的标签集合中时，我们就可以认为这两个标签具有较大的相似度，可以使用余弦相似性进行计算，计算的方式时两个标签的交集除以他们的各自的平方开根号。<br>$$<br>\operatorname{sim}\left(b, b^{\prime}\right)=\frac{\sum_{i \in N(b) \cap V(b)} n_{b i} n_{b ; i}}{\sqrt{\sum_{i \in N(b)} n_{b, i}^{2} \sum_{i \in N(b)} n_{b^{\prime}, i}^{2}}}<br>$$<br><strong>标签清理</strong></p><p>有许多标签仅仅反应了用户的心情（例如不好笑），不能作为用户的兴趣，我们需要对这类标签进行过滤。去除一些停止词，同义词，等等方式去除不良标签。</p><h3 id="给用户推荐标签"><a href="#给用户推荐标签" class="headerlink" title="给用户推荐标签"></a>给用户推荐标签</h3><p>给用户推荐标签指给出一些选项供用户选择，这样的好处有：</p><ul><li>方便用户输入标签</li><li>提高标签的质量</li></ul><p><strong>如何给用户推荐标签</strong></p><ul><li>给用户推荐系统中推荐最热门的标签</li><li>给用户推荐物品i上最热门的标签</li><li>给用户推荐他常用的标签</li><li><strong>结合上述两种方法的加权结果</strong>（用得最多）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp (二) 构造、析构、赋值运算</title>
      <link href="/2019/11/02/effective-cpp-%E4%BA%8C-%E6%9E%84%E9%80%A0%E3%80%81%E6%9E%90%E6%9E%84%E3%80%81%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/"/>
      <url>/2019/11/02/effective-cpp-%E4%BA%8C-%E6%9E%84%E9%80%A0%E3%80%81%E6%9E%90%E6%9E%84%E3%80%81%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<p>2019/11/02，effective cpp 第二章</p><ul><li>05条款：了解C++默默编写并调用哪些函数</li><li>06条款：若不想使用编译器自动生成的函数，就该明确拒绝</li><li>07 条款：为多态基类声明virtual 析构函数</li><li>08 条款：别让异常逃离析构函数（不传播）</li><li>09 条款：绝不在构造和析构过程中调用virtual函数</li><li>10 条款：令operator= 返回一个reference to *this</li><li>11 条款：在operator=中处理自我赋值</li><li>12 条款：复制对象时勿忘其每一个成分</li></ul><a id="more"></a><h3 id="05-条款：了解C-默默编写并调用哪些函数"><a href="#05-条款：了解C-默默编写并调用哪些函数" class="headerlink" title="05 条款：了解C++默默编写并调用哪些函数"></a>05 条款：了解C++默默编写并调用哪些函数</h3><p>在一个类中，当你自己没声明，C++编译器将会替你生成的函数有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">entry</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  entry()&#123;...&#125; <span class="comment">//默认构造函数</span></span><br><span class="line">  ~entry(<span class="keyword">const</span> entry&amp; rth)&#123;...&#125; <span class="comment">// copy 构造函数</span></span><br><span class="line">  ~entry()&#123;...&#125; <span class="comment">// 析构函数</span></span><br><span class="line">  entry&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> entry&amp; rhs)&#123;...&#125; <span class="comment">//等号运算符重载</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的四个函数，分别负责对象的创建和销毁工作。其中default和析构函数用于防止一些幕后的代码，如调用父类的构造函数等。</p><p>copy构造函数和等号函数，起到的作用是将对象内每一个元素拷贝到目标对象上。</p><p>存在一个例外，如果成员变量不可以改变值的时候，例如成员变量含引用的时候（string&amp; name;）,含有const成员的时候，由于这些类型初始化之后，不允许改变它的值，因此系统不会为这些类生成copy构造函数以及重载等号初始化。</p><p><strong>总结</strong></p><p>编译器可以暗自生成构造函数，析构函数，copy构造函数，copy assignment操作符。一些含reference，const成员的函数，将不会产生copy，等号重载这两个函数。</p><h3 id="06-条款：若不想使用编译器自动生成的函数，就该明确拒绝"><a href="#06-条款：若不想使用编译器自动生成的函数，就该明确拒绝" class="headerlink" title="06 条款：若不想使用编译器自动生成的函数，就该明确拒绝"></a>06 条款：若不想使用编译器自动生成的函数，就该明确拒绝</h3><p>某些情况你不希望对象具有copy，等号这些操作，你就该明确拒绝。<strong>可以将copy，copy assignment申明成private，并且故意不去实现他们</strong>（只有声明没有实现），这样就能有效的阻止人们调用它，同时当类的friend函数调用的时候，将返回连接错误。</p><p>此外，还可以继承一个不可拷贝的对象，如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">homeforsale</span>:</span><span class="keyword">private</span> Uncopyable&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中Uncopyable的copy和copy assignment函数声明为private，而且未提供实现，这样可以将赋值的错误转移至编译期间。</p><p><strong>总结</strong></p><p>为了阻止编译器自动添加一些函数，可将相应的成员函数声明为private并且不写实现过程。使用Uncopyable这样的base class也是一种方法。</p><h3 id="07-条款：为多态基类声明virtual-析构函数"><a href="#07-条款：为多态基类声明virtual-析构函数" class="headerlink" title="07 条款：为多态基类声明virtual 析构函数"></a>07 条款：为多态基类声明virtual 析构函数</h3><p>例如一个基类实现了计时的功能，然后它派生出去的许多类，分别代表了不同特点的时钟。因此可以设计<strong>factory工厂方法</strong>，返回指针指向一个父类的计时对象，父类对象根据子类的指针类型得到一个子类的指针对象。</p><p>当我们通过上述的方法，生成了很多basic class指针（指向派生类），当我们希望回收内存的时候，使用delete方法释放内存，这时候C++只会调用basic class的non-virtual的析构函数。因此只对属于basic class部分的成员内存进行了释放，子类的内存无法得到释放。</p><p>解决上面的问题就是<strong>将basic class的析构函数定义为virtual</strong>，这样在释放指针所指空间的内存的时候，就可以就调用相应的子类的析构函数，销毁整个对象。</p><p>通常基类都会定义virtual的函数，供不同的子类指针调用，通常这类函数都需要有一个virtual的析构函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">entry</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">virtual</span> ~entry();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不含virtual的类基本上也不会加virtual的析构函数，因为加上virtual之后函数器对象需要加上徐函数的指针表，对象的大小会增加。</p><p>也不要在程序中继承一些带有non-virtual析构函数的class，因此如何你打算回收这个对象的时候，往往没办法完全回收内存。</p><p>倘若你想要将基类设计成一个抽象类，即不能实例化的一class，你可以选择将析构函数做成一个纯虚的析构函数，并且提供一份空的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AWOV</span>&#123;</span></span><br><span class="line">  <span class="keyword">virtual</span> ~AWOV() = <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">AWOV::AWOV()&#123;&#125; <span class="comment">// 提供一份空的实现</span></span><br></pre></td></tr></table></figure><p>当执行析构的时候，最深层的派生class的析构函数最先被调用，因此调用到AWOV这个类的析构函数。</p><p><strong>总结</strong></p><ul><li>含多态性质的base class应该声明一个virtual析构函数，如果class 带有任何virtual函数，他就应该拥有一个virtual析构函数。</li><li>classes的设计目的如果不是作为base classes使用，或不是为了具备多态性，就不该声明virtual</li></ul><h3 id="08-条款：别让异常逃离析构函数（不传播）"><a href="#08-条款：别让异常逃离析构函数（不传播）" class="headerlink" title="08 条款：别让异常逃离析构函数（不传播）"></a>08 条款：别让异常逃离析构函数（不传播）</h3><p>C++你并不能禁止析构函数吐出异常，因为例如在程序销毁的时候，析构函数将会销毁其构建的所有对象，当重复的对象在销毁的时候抛出异常，那么所有的这些对象在销毁的时候，都将会抛出异常，而多于一个异常被抛出的情况，将会导致不明确的行为。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DBConn</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  ~DBConn()&#123;</span><br><span class="line">    db.close(); <span class="comment">// 在DBConn的析构函数中，将会调用db.close()，然而db.close可能会发生异常，导致不明确的事情</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>C++不喜欢析构函数吐出异常，这将导致函数的提前结束或出现不明确的行为</strong></p><p>因此，如果在析构函数中出现异常，函数应该选择吞下这个异常，而不是抛出异常。如果必须对这个异常进行处理的话，应该提供一个普通函数来处理这个异常，而不是在析构函数中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">DBConn::DBConn&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">try</span>&#123;bd.close();&#125;</span><br><span class="line">  <span class="keyword">catch</span>&#123;...&#125;&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">abort</span>(); <span class="comment">// 终止程序,主动对异常进行捕获，而不是抛出</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者在一个普通函数中进行异常的捕获</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>&#123;</span><br><span class="line">  db.close();</span><br><span class="line">  closed = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">~DBConn()&#123;</span><br><span class="line">  <span class="keyword">if</span>(!closed)&#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      db.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span>(...)&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>析构函数绝对不要吐出异常，如果一个被析构函数调用的函数可能抛出异常，那么析构函数应该去捕获异常，（try，catch）然后吞下它们或结束程序。</li><li>如果客户需要对某个函数在运行期间抛出的异常做出反应，那么class应该提供一个普通函数执行该操作。</li></ul><h3 id="09-条款：绝不在构造和析构过程中调用virtual函数"><a href="#09-条款：绝不在构造和析构过程中调用virtual函数" class="headerlink" title="09 条款：绝不在构造和析构过程中调用virtual函数"></a>09 条款：绝不在构造和析构过程中调用virtual函数</h3><p>在构造或析构函数中，如果在函数中调用虚函数，在子类的构造函数往回回溯的时候。这时候在父类中执行构造函数，构造函数内部的虚函数调用的是base class的版本，而不是子类的版本。</p><p><strong>在derived class对象的base class构造期间，对象的类型是base class，而不是derived class版本。</strong>如果使用了运行期类型信息，那么这时候也是base class的类型信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">transaction</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    transaction()&#123;</span><br><span class="line">      logtransaction(); <span class="comment">// 构造函数中的virtual函数只会使用base class（本类）的版本</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">logtransaction</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><p>在构造和析构期间不用调用virtual函数，因为这类调用从不下降至derived class（即这个版本的virtual函数不是你想要的那个。）</p><h3 id="10-条款：令operator-返回一个reference-to-this"><a href="#10-条款：令operator-返回一个reference-to-this" class="headerlink" title="10 条款：令operator= 返回一个reference to *this"></a>10 条款：令operator= 返回一个reference to *this</h3><p>关于重载等号=赋值运算符，由于赋值运算符可以连续赋值，形如：x=y=z=15，因此赋值运算符必须返回一个reference指向操作符的左侧实参，这是你为class需要遵循的协议：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    widget&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> *<span class="keyword">this</span>;       <span class="comment">// this调用=运算符，rhs为参数，返回this等于返回左边元素的引用</span></span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// 上述协议同样适用于+=，以及参数是其他类型的情况</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述写法只是一个协议，在CPP所有内置类型以及标准程序库中提供的类型都将共同准守。</p><p><strong>总结</strong></p><p>令赋值操作返回一个<code>reference to *this</code>的引用。</p><h3 id="11-条款：在operator-中处理自我赋值"><a href="#11-条款：在operator-中处理自我赋值" class="headerlink" title="11 条款：在operator=中处理自我赋值"></a>11 条款：在operator=中处理自我赋值</h3><p>自我赋值指的是自己给自己赋值的情况，这种情况通常出现在引用后指针的自我赋值上。例如一个类用来保存一个指针指向一块动态分配的位图：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bitmap</span>&#123;</span>...&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">  Bitmap* pb;</span><br><span class="line">  widget&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">    <span class="keyword">delete</span> pb;    <span class="comment">// 这种方式可能造成不安全，当pb和rhs.pb指向同一块地址的时候，两个指针的对象会被删除</span></span><br><span class="line">    pb = <span class="keyword">new</span> Bitmap(*rhs.pb);</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的危险可以使用验证是否相同的方式来化解：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">widget&amp; widget::<span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">  <span class="keyword">if</span>(*<span class="keyword">this</span> == &amp;rhs) <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">     <span class="keyword">delete</span> pb; </span><br><span class="line">    pb = <span class="keyword">new</span> Bitmap(*rhs.pb);</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//但是每次都要进行判断，效率不是很高，下面通过调换赋值的顺序，达到同样的效果</span></span><br><span class="line">widget&amp; widget::<span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">  Bitmap* pOrig = pb;</span><br><span class="line">  pb = <span class="keyword">new</span> Bitmap(*rhs.pb);  <span class="comment">// 令pb指向一块新的pb的副本地址</span></span><br><span class="line">  <span class="keyword">delete</span> pOrig;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>确保当对象自我赋值的时候，operator=有良好的行为，利用来源对象和目标对象的地址，语句的顺序等等，避免将自身对象删除。</li><li>确保当函数操作一个以上对象的时候，它的行为是正确的。</li></ul><h3 id="12-条款：复制对象时勿忘其每一个成分"><a href="#12-条款：复制对象时勿忘其每一个成分" class="headerlink" title="12 条款：复制对象时勿忘其每一个成分"></a>12 条款：复制对象时勿忘其每一个成分</h3><p>当我们为一个类写copy构造函数和copy assignment构造函数的时候，编译器则会有一个报复行为，就是当你的类中新添了成员变量的时候，而未修改copy构造函数为这个值赋值的时候，编译器也不会报错：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    Customer(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">    Customer&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;</span><br><span class="line">Customer::Customer(<span class="keyword">const</span> Customer&amp; rhs):name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  name = rhs.name;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码可以正常的执行，但是当加入一个<code>int age;</code>的成员变量的时候，如果你忘记修改了上面的copy，assignment函数，编译器也不会提醒你，因此：</p><p><strong>如果你为class添加了一个成员变量，你必须同时修改copy和assignment，否则编译器也不会提醒你。</strong></p><p>当你为一个子类函数重写copy和assignment函数的时候，这种事情仍然会发生：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span>:</span> <span class="keyword">public</span> Person&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    Customer(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">    Customer&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;</span><br><span class="line">Customer::Customer(<span class="keyword">const</span> Customer&amp; rhs):name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  name = rhs.name;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Customer继承自Person对象，现实Customer的copy的时候没有对Person对象传递参数，那么编译器将会调用default构造函数，Person的数据并不会被拷贝到新的对象中，因此：</p><p><strong>我们在重写子类的copy函数的时候，需要调用base class 的copy函数。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Customer&amp; Customer(const Customer&amp; rhs):Person(rhs),name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  Person::<span class="keyword">operator</span>=(rhs);</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此当你编写一个copying函数，请确保（1）复制多有的local变量。（2）调用所有base classes内的适当copying函数。</p><p><strong>总结</strong></p><ul><li>copying函数应当确保复制对象内的所有成员变量，以及所有base class成分</li><li>不要尝试以某个copying函数实现另一个copying函数，可以将相同代码的部分单独提取出来，放到init函数中。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之协同过滤（一）</title>
      <link href="/2019/11/02/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/11/02/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>基于领域的算法是推荐系统中最为基本的算法，这篇post主要针对其中重要的两类算法：基于用户的协同过滤，基于产品的协同过滤进行介绍。</p><a id="more"></a><h3 id="长尾效应"><a href="#长尾效应" class="headerlink" title="长尾效应"></a>长尾效应</h3><p>在需求曲线中，少量的需求会形成一条长长的尾巴，将所有非流行的需要累加起来，将会形成一个比流行市场还要庞大的市场。</p><p>长尾效应最直接的原因就是强调用户的个性化，将市场需求细分，这些小的需求市场的累积效应将形成巨大的理论。</p><p>推荐系统的一个迫切需求在于，存在信息过载以及用户需求不明显的问题，因此需要将用户感兴趣，或有潜在兴趣的商品推荐给用户。</p><h3 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h3><p>在介绍协同过滤之前，我们粗略设计一下算法的流程。</p><ul><li>将用户数据均匀成M（m = 8）份，挑选其中一份作为测试集。重复进行M次实验。（交叉验证，防止过拟合）</li><li>在训练集上训练用户兴趣模型，在测试集上进行预测，统计评测指标。</li><li>将M次实验结果的平均值作为最后的测评指标。</li></ul><h3 id="测评指标"><a href="#测评指标" class="headerlink" title="测评指标"></a>测评指标</h3><ul><li>召回率：recall = (用户感兴趣 与 推荐商品交集) / （推荐商品的总数）</li><li>准确率：precision = (用户感兴趣 与 推荐商品交集) / （用户感兴趣物品集合）</li><li>覆盖率：coverage = （推荐商品） / （总商品）</li><li>平均流行度：每个物品流行度的对数值（流行度满足长尾，取对数更加的稳定）</li><li>新颖度：新颖度可由流行度度量，负相关。</li></ul><h3 id="基于用户的协同过滤算法"><a href="#基于用户的协同过滤算法" class="headerlink" title="基于用户的协同过滤算法"></a>基于用户的协同过滤算法</h3><p>基于用户的协同过滤算法是推荐算法中最古老的算法，在1992年被提出（很年轻的领域）。主要包括两个部分：</p><ul><li>找到和目标用户兴趣相似的用户集合</li><li>找到这个集合中用户喜欢的，但目标用户中没有产生过行为的，推荐给目标用户</li></ul><p><strong>找出目标用户兴趣群</strong></p><p>如何判断两个用户的相似性，可以使用用户感兴趣物体N(u)的相似性来代替用户的相似性，使用Jaccard相似度，计算u，v用户的相似度：<br>$$<br>w_{u v}=\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}<br>$$<br>或者使用余弦相似度计算：<br>$$<br>w_{u v}=\frac{|N(u) \cap N(v)|}{\sqrt{|N(u)||N(v)|}}<br>$$<br>在具体的计算时，我们只关注两个用户之间存在交集的那部分商品：</p><ul><li><p>首先建立一个<strong>商品为表头的链表，链表上的节点是对该商品发生过行为的用户。</strong></p></li><li><p>随后建立一个<strong>用户与用户之间的相似矩阵</strong>，如果这两个用户出现在同一个链表中k次，则用户之间的数组值为k。相似矩阵作为余弦相似度的分子，总数作为分母，计算得到用户之间的相似度。</p></li><li>给目标用户提供与他相似度topK用户喜欢的产品。</li></ul><p><strong>用户相似性的改进：</strong></p><p>对于一些热门的产品，大家可能都会去购买，比如面包大家都会买，但是购买用户之间的相似性就天差地别了，换句话说，<strong>冷门商品更能说明用户兴趣</strong>，因此需要对热门商品进行惩罚：<br>$$<br>w_{u v}=\frac{\sum_{i \in N(u) \cap N(v)} \frac{1}{\log (1+|N(i)|)}}{\sqrt{|N(u)||N(v)|}}<br>$$<br>分子是u，v用户共同感兴趣的物品i，N(i)表示对i发生过行为的所有人的集合，i越热门惩罚越大。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(一) 让自己习惯cpp</title>
      <link href="/2019/10/31/effective-cpp-%EF%BC%88%E4%B8%80%EF%BC%89-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFcpp/"/>
      <url>/2019/10/31/effective-cpp-%EF%BC%88%E4%B8%80%EF%BC%89-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFcpp/</url>
      
        <content type="html"><![CDATA[<p>2019/10/31，effective cpp第一章：</p><ul><li>01条款：视c++为一个语言联邦</li><li>02条款：尽量以const, enum,inline替换 #define</li><li>03条款：尽可能使用 const</li><li>04条款：确定对象被使用前已被初始化</li></ul><a id="more"></a><h3 id="01-条款：视c-为一个语言联邦"><a href="#01-条款：视c-为一个语言联邦" class="headerlink" title="01 条款：视c++为一个语言联邦"></a>01 条款：视c++为一个语言联邦</h3><p>c++最初从c语言发展而来，最初的名称是c with classes，同时这们语言接受了很多的不同的观点，特性，和编程的设计。使得cpp有着巨大的弹性和威力，因此在cpp不同的语言领域内，将有不同的最优用法。</p><p>cpp有着四个主要的次语言：</p><ul><li>C语言，cpp很多编程上的特性继承至C语言</li><li>面向对象的C++：很多关于类的操作在这一部分引入</li><li>template C++：C++的范型编程，<strong>唯template适用</strong></li><li>STL：标准模板库，里头有着大量的容器，迭代器等</li></ul><p><strong>总结</strong></p><p>C++由上面四种次语言组成，不存在一组高效编程的守则，而是视适用的次语言而定。</p><h3 id="02-条款：-尽量以const-enum-inline替换-define"><a href="#02-条款：-尽量以const-enum-inline替换-define" class="headerlink" title="02 条款： 尽量以const, enum,inline替换 #define"></a>02 条款： 尽量以const, enum,inline替换 #define</h3><p>将cpp程序转化成机器能够看懂的语言，需要经过预处理，编译，汇编，链接这些步骤。<strong>#define</strong>在预处理阶段就会被处理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define RATIO 1.25</span><br></pre></td></tr></table></figure><p>在编译器处理源代码阶段，define定义的符号将会被移走，因此RATIO可能根本就没进入<strong>符号表。</strong>当出现错误的时候，根据报错信息将很难定位错误，因此最好将define进行替换，也就是<strong>编译器替换预处理器。</strong></p><p><strong>符号表</strong></p><p>符号表在程序的编译阶段，将函数以及变量名地址记录起来，在链接阶段，根据符号表中记录的内容，去链接程序。</p><p><strong>用const替换define</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> ratio = <span class="number">1.25</span>;</span><br></pre></td></tr></table></figure><p>由于常量的定义经常在头文件之中，因此定义常量指针的时候，通常也将指针定义成const。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> author = <span class="string">"names"</span>;</span><br></pre></td></tr></table></figure><p>当我们需要创建一个类的常量的时候，需要在声明的时候，加一个static，使得这个常量只有一份实体，而且将这个常量的定义域限制在类内。</p><p>最后可以使用enum来代替define：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span>&#123;num1 = <span class="number">1</span>,num2 = <span class="number">2</span>&#125;;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; num1 &lt;&lt; num2;</span><br></pre></td></tr></table></figure><p>enum将数字符号化，也无法取到enum的地址。</p><p>此外，使用宏定义的另外一部分作用是定义一个简单的函数，避免函数调用带来的麻烦，同时不必要制定变量的类型（需要是同一个类别的），在宏定义的时候，注意为我每一个变量添加一个括号。</p><p>但是我们完全没必要去定义define，而是使用inline去替代：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">callwith</span><span class="params">(<span class="keyword">const</span> T&amp; a ,<span class="keyword">const</span> T&amp; b)</span></span>&#123;</span><br><span class="line">  f(a&gt;b ? a:b); <span class="comment">// 谁大调用谁</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>对于单纯的变量，使用const，enum替换define</li><li>对于宏定义的函数，改成template + inline的形式</li></ul><h3 id="条款-03：尽可能使用-const"><a href="#条款-03：尽可能使用-const" class="headerlink" title="条款 03：尽可能使用 const"></a>条款 03：尽可能使用 const</h3><p>const的原则，<strong>你在可以使用它的时候就使用它</strong>，</p><p>const 是一个语义的束缚，说明内容不可修改，因此只要有这样的一种约束在，就应该声明出来，获得编译器的协助。</p><p>const声明指针的时候有以下几种方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> greeting[] = <span class="string">"hello"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* p = greeting; <span class="comment">// 指针所指内容为const</span></span><br><span class="line"><span class="keyword">char</span> <span class="keyword">const</span>* p = greeting; <span class="comment">// const在*左边，与上相同</span></span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> p = greeting; <span class="comment">// 指针为const，内容可变</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> p = greeting; <span class="comment">//指针，内容都不变</span></span><br></pre></td></tr></table></figure><p><strong>令函数的返回值为一个常量值，往往可以降低造成意外的风险</strong></p><p>函数的返回值，正常不应该作为一个变量来被其他赋值，因为这个不符合逻辑，如果可以被直接赋值的话，函数就没什么用了。因此对于大多数函数的返回值来说，可以加上const。</p><p><strong>const成员函数</strong></p><p>const成员函数指的是在一个类里头，这个函数用const进行了标注，表明这个函数是只读的不可以在函数内部对数据成员进行修改，格式如下,const在函数的最后：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position) <span class="keyword">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tex[position];</span><br><span class="line">  &#125;;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将函数定义成const，可以容易得知这个函数无法修改对象的值；同时使得操作const对象成为可能。</p><p><strong>真实程序中，const对象大多用于传参数，passed-by-pointer-to-const；passed-by-reference-to-const</strong>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">point</span><span class="params">(cosnt TextBlock&amp; ctb)</span></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; ctb[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在一些类中，const标注的函数其内部不允许对成员数据进行修改，但是也存在例外，<strong>mutable</strong>变量定义的变量将改变一些值的const属性，允许在const函数中修改：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">block</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">mutable</span> <span class="keyword">int</span> len;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">length</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> block::length() <span class="keyword">const</span></span><br><span class="line">&#123;</span><br><span class="line">  len = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">return</span> len; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>const和non-const函数允许函数进行重载，</strong>但是在使用的时候应该避免写两个函数，而是在non-const函数中，通过类型的转换来调用const类型的函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">block</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position) <span class="keyword">const</span>&#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position)&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const_cast</span>&lt;<span class="keyword">char</span>&amp;&gt;(<span class="keyword">static_cast</span>&lt;cosnt block&amp;&gt;)(*<span class="keyword">this</span>)[position];</span><br><span class="line">    <span class="comment">// const_cast 去掉const</span></span><br><span class="line">    <span class="comment">// static_cast 将this转换为const类型，调用上一个函数</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>const可以施加于任何作用域内的对象，函数参数，返回值，成员函数。</li><li>在能够使用const的时候尽量使用const，利用编译器规则为你排除错误。</li><li>编译器强制实行bitwise constness，编写程序的时候应该遵守逻辑上的const（避免const函数，有些指针是const，但是其内部的值可以修改）。</li><li>const和非const函数有本质上的相似的话，应该使用non-const的版本去调用，避免代码重复。</li></ul><h3 id="条款-04：确定对象被使用前已被初始化"><a href="#条款-04：确定对象被使用前已被初始化" class="headerlink" title="条款 04：确定对象被使用前已被初始化"></a>条款 04：确定对象被使用前已被初始化</h3><p>由于cpp是一个语言联邦，因此它并不保证所有的对象都会被初始化。因此：<strong>在使用对象之前先将对象进行初始化。</strong></p><p>特别值得注意的是，在对成员函数进行初始化时，在构造函数本体内进行的的并非初始化，而是赋值操作。<strong>cpp规定，对象的成员变量的初始化动作发生在进入构造函数本体之前。</strong>因此将成员初始化写在初始化成员列表中，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AB</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> aa;</span><br><span class="line">    <span class="keyword">int</span> bb;</span><br><span class="line">    AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b);</span><br><span class="line">&#125;</span><br><span class="line">AB::AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b)&#123;  <span class="comment">// 这种方式时赋值，初始化之后又做一遍赋值，效率很低</span></span><br><span class="line">  aa = a;</span><br><span class="line">  bb = b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 修改版本如下：</span></span><br><span class="line">AB::AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b):aa(a),bb(b)  <span class="comment">// 构造初始化表，效率比较高</span></span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外，对于不同单元内定义的static变量，他们的初始化次序是不确定的。static对象，他们的寿命从构造出来一直到函数的结束。定义在函数内部的称为local static，定义在其他地方位置的称为non-local static，由于定义在不同编译单元的non-local-static中初始化的顺序不同，如果另一个初始化单元，用到了一个未被初始化的static的话，可能会发生很不好的事情，因此：<strong>将每个non-local-static对象搬到自己的专属函数内，这些函数返回一个reference对象，然后指针直接调用这些函数。</strong>这样你在调用这个函数之前，这个变量将会被初始化。</p><p><strong>总结</strong></p><ul><li>为内置的对象进行初始化，cpp不会保证初始化</li><li>构造函数最好使用成员初始化列表的方式进行初始化，成员的次序应该于定义的顺序相同</li><li>为了免除<strong>跨编译单元初始化次序问题</strong>，最好将non-local-static变量变为local static，定义在函数内部，函数返回一个该对象的引用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastFCN: 大工不巧</title>
      <link href="/2019/10/31/FastFCN-%E5%A4%A7%E5%B7%A5%E4%B8%8D%E5%B7%A7/"/>
      <url>/2019/10/31/FastFCN-%E5%A4%A7%E5%B7%A5%E4%B8%8D%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<p>FastFCN是自动化所2019年cvpr上的一个工作，提出JPU模块，代替dilated conv，在保证网络精度的前提下，大大降低网络的计算复杂度，是的FPS得到提升。</p><p>这些年来计算机视觉得到广泛的发展，网络结构也越来越复杂，这篇文章做了一些下修改，可以说耳目一新，结构十分简单，结果十分有效。</p><a id="more"></a><h3 id="语义分割常用的提取feature-map"><a href="#语义分割常用的提取feature-map" class="headerlink" title="语义分割常用的提取feature map"></a>语义分割常用的提取feature map</h3><p><img src="/images/3D/fcn_struct.png" style="zoom:80%;"></p><p><strong>a）FCN结构：</strong>通过一个全卷积的网络，直接得到图像分割后的结果。缺点是图像中的特征丢失。</p><p><strong>b）encoder-decoder结构：</strong>encoder结构得到高层次的特征，decoder阶段通过结合多层次的特征来得到一个多尺度融合的feature map，缺点是仍然存在数据的丢失（pooling 结构）</p><p><strong>c） DilatedFCN：</strong>利用空洞卷积替换pooling层，扩大feature map感受野的同时，没有降低feature map的分辨率。但是这种结构导致了很大的计算量。</p><p>###JPU结构</p><p>作者提出JPU（joint pyramid upsampling）结构，替换DilateFCN中的空洞卷积结构，能够大大的减少内存以及时间上的消耗。</p><p><img src="/images/jpu.png" alt="image-20191101134143826" style="zoom:60%;"></p><p>###FastFCN结构 </p><p><img src="/images/fastfcn.png" alt="image-20191101134311586" style="zoom:50%;"></p><p>FastFCN的backbone采用的是原始的FCN的结构，将FCN的最后三层输入JPU模块中进行训练，最终在许多任务上都得到一个性能一致，但速度得到提升的网络。</p><p><strong>mIoU：</strong>对每一类计算真实标签和预测标签的交并比，然后对所有类别求一个平均得到最后的结果。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这篇文章对FCN的网络中的dilated conv进行了一个很小的修改，达到一个比较合理的结果，文章非常的简单，不过可能是因为过于简单的原因，文中也有许多可有可无的内容，总之，对于做工程来说，得到一个FPS比较快的网络还是比较好的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于职业生涯规划以及时间安排的一些思考</title>
      <link href="/2019/10/30/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
      <url>/2019/10/30/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 职业规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译器gcc，g++，clang，cmake，make介绍</title>
      <link href="/2019/10/27/%E7%BC%96%E8%AF%91%E5%99%A8gcc%EF%BC%8Cg-%EF%BC%8Cclang%EF%BC%8Ccmake%EF%BC%8Cmake%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/10/27/%E7%BC%96%E8%AF%91%E5%99%A8gcc%EF%BC%8Cg-%EF%BC%8Cclang%EF%BC%8Ccmake%EF%BC%8Cmake%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要介绍在mac上使用CLion编写cpp代码的时候，cpp编译以及链接的一些知识。</p><a id="more"></a><h3 id="cpp程序编译执行过程"><a href="#cpp程序编译执行过程" class="headerlink" title="cpp程序编译执行过程"></a>cpp程序编译执行过程</h3><ul><li><strong>编译</strong>：将源代码翻译成机器语言，生成目标文件<ul><li>预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。</li><li>编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。</li><li>汇编：将汇编代码翻译成目标机器代码.o文件。</li></ul></li><li><strong>链接</strong>：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。</li></ul><h3 id="cpp使用的编译器gcc，g-，clang"><a href="#cpp使用的编译器gcc，g-，clang" class="headerlink" title="cpp使用的编译器gcc，g++，clang"></a><strong>cpp使用的编译器gcc，g++，clang</strong></h3><ul><li><strong>gcc</strong>: 最开始的时候是 GNU C Compiler, 如你所知，就是一个c编译器。但是后来因为这个项目里边集成了更多其他不同语言的编译器，GCC就代表 the GNU Compiler Collection，所以表示一堆编译器的合集。</li><li><strong>g++</strong>：是GCC的c++编译器。</li><li><strong>clang</strong>：是mac上另起炉灶写的一个C语言、C++、Objective-C、Objective-C++语言的<strong>轻量级编译器</strong>。源代码发布于BSD协议下。Clang将支持其普通lambda表达式、返回类型的简化处理以及更好的处理constexpr关键字。</li></ul><p><strong>clang和gcc相比比gcc编译速度更快一些，而且错误提示更人性化。</strong></p><h3 id="make，cmake"><a href="#make，cmake" class="headerlink" title="make，cmake"></a>make，cmake</h3><p>光有gcc还不够，如果这时候我们开发的工程使用的文件很多，那就需要一个一个去编译，工作量很大。一些大型的IDE如VS studio，CLion使用clang编译器，使用cmake链接工具，对源码进行编译。</p><p><strong>make</strong></p><p>make类似于一个目录，是一个文件编译的批处理工具，本身没有编译的功能。make的作用就是告诉编译器，各种各样的编译规则，先做什么后做什么，这些规则写在makefile文件中。</p><p>make用于构建项目，其中一条很重要的规则就是依赖关系，当某些文件发生改变，直接或间接依赖这些文件的目标就要进行重新的构建。make用来构建管理文件，不一定用于编译。</p><p><strong>cmake</strong></p><p>构建一个项目需要了解构建的规则，并写出makefile文件，但是编译构建本身是个复杂过程，不同的项目构建规则会有所不同，要自己写出一个makefile文件比较困难。</p><p>cmake工具是根据平台（跨平台）和配置自动生成项目的makefile文件，然后给make使用。</p><p>cmake根据CMakeLists.txt文件（组态档）去生成makefile。在不使用CLion等这类IDE的情况下，这个CMakeLists.txt需要自己来写，下面是一个CMakeLists.txt：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.8</span>)</span><br><span class="line"><span class="keyword">project</span>(First_Code)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">11</span>)</span><br><span class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "-std=c++0x $&#123;CMAKE_CXX_FLAGS&#125; -g -ftest-coverage -fprofile-arcs")</span></span><br><span class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11")</span></span><br><span class="line"><span class="keyword">set</span>(SOURCE_FILES main.cpp <span class="keyword">test</span>.cpp assignment.cpp)</span><br><span class="line"><span class="keyword">add_executable</span>(First_Code <span class="variable">$&#123;SOURCE_FILES&#125;</span>)</span><br></pre></td></tr></table></figure><p>但是不用担心，CMakeLists.txt IDE也会负责生成。</p><h3 id="C-11"><a href="#C-11" class="headerlink" title="C++11"></a>C++11</h3><p>  C++11，（即ISO/IEC 14882:2011），是目前的C++编程语言的最新正式标准。它取代了第二版标准(第一版公开于1998年，第二版于2003年更新，分别通称C++98以及C++03，两者差异很小)。新的标准包含核心语言的新机能，而且扩展C++标准程序库。C++11新标准由C++标准委员会于2011年8月12日公布，并于2011年9月出版。此次标准为C++98发布后13年来第一次重大修正。</p><p><strong>gcc4.7以及之后，全面支持c++11。</strong></p><h3 id="MAC更换CLion编译器"><a href="#MAC更换CLion编译器" class="headerlink" title="MAC更换CLion编译器"></a>MAC更换CLion编译器</h3><p>在terminal输入<code>gcc -v</code>发现出来的是APPLE的clang编译器，由于更习惯使用GUN的gcc编译器，因此打算安装一个，同时保留原有的clang。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew search gcc // 查看有哪些gcc</span><br><span class="line">brew install gcc //安装最新版本的gcc，目前电脑上用的是gcc9.2</span><br></pre></td></tr></table></figure><p>上诉过程安装完成之后，gcc的位置在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/Cellar/gcc/9.2.0_1/bin</span><br></pre></td></tr></table></figure><p>将这个路径加入到CLion所使用的编译器上，同时修改cmake参数(preference 中修改)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D CMAKE_CXX_COMPILER=/usr/local/bin/g++-9</span><br></pre></td></tr></table></figure><h3 id="CLion-中新建项目的目录结构"><a href="#CLion-中新建项目的目录结构" class="headerlink" title="CLion 中新建项目的目录结构"></a>CLion 中新建项目的目录结构</h3><p>CLion是通过cmake来构建文件的，手动在CLion中生成cpp文件，系统件制动修改cmakeLists.txt</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp STL方法介绍</title>
      <link href="/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要目的是对cpp提供的Standard Template Library标准模板库中一些重要的方法进行学习，记录，以便今后学习。</p><a id="more"></a><h3 id="STL概述"><a href="#STL概述" class="headerlink" title="STL概述"></a>STL概述</h3><p>在开始STL之前，像大家介绍一下一个全能的头文件：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br></pre></td></tr></table></figure><p>这个头文件include了在STL中所有的头文件，方便我们使用而不用去担心这些方法所在的库。</p><p>STL库中有四类重要的部分：</p><ul><li>Algorithm：该部分提供的算法定义在容器上，用于操作容器上的元素。</li><li>containers：定义了一些常用的容器，如vector，map等等</li><li>functor：算子，是个函数，用于定制化STL函数，如sort，传入functor定制排序方式</li><li>iterator：迭代器，用于遍历整个序列</li></ul><h3 id="algorithm"><a href="#algorithm" class="headerlink" title="algorithm"></a>algorithm</h3><p><strong>sort(begin_adress,end_adress,compare)</strong></p><p>排序算法是定义在所有容器上的一个排序函数，其内部实现是快排，时间复杂度是$O(nlogn)$.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">9</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>&#125;;</span><br><span class="line">sort(arr,arr+<span class="number">10</span>); <span class="comment">//升序排序</span></span><br><span class="line">sort(arr,arr+<span class="number">10</span>,greater&lt;<span class="keyword">int</span>&gt;()); <span class="comment">// 降序排序</span></span><br><span class="line"><span class="comment">// 特殊数组的排序</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">interval</span>&#123;</span></span><br><span class="line">  <span class="keyword">int</span> val1;</span><br><span class="line">  <span class="keyword">int</span> val2;</span><br><span class="line">&#125;;</span><br><span class="line">interval arr[] = &#123;&#123;<span class="number">2</span>,<span class="number">2</span>&#125;,&#123;<span class="number">4</span>,<span class="number">3</span>&#125;,&#123;<span class="number">3</span>,<span class="number">4</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;&#125;</span><br><span class="line"><span class="keyword">bool</span> compareInterval(interval v1,interval v2)&#123;</span><br><span class="line">  <span class="keyword">return</span> v1.val1 &lt; v2.val2; <span class="comment">// 如果第一个数小的话，先排序</span></span><br><span class="line">&#125;</span><br><span class="line">sort(arr,arr+<span class="number">10</span>,compareInterval); <span class="comment">// 得到按第一个元素排序的数组</span></span><br></pre></td></tr></table></figure><p><strong>bool binary_search(start_adress,end_adress,value_find)</strong></p><p>二分搜索查找value_find这个元素，该数组已经被排序过了，复杂度为$O(logn)$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">if</span>(binary_search(arr,arr+<span class="number">10</span>,<span class="number">2</span>))&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"get it "</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>bool all_of(begin_adress,end_adress,lambda_func)</strong></p><p>该函数判断是否arr中的所有元素都满足lambda中的规则</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">STL_allof</span><span class="params">(<span class="keyword">int</span>*a)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> lens = <span class="keyword">sizeof</span>(a)/ <span class="keyword">sizeof</span>(a[<span class="number">0</span>]);</span><br><span class="line">    all_of(a,a+lens,[](<span class="keyword">int</span> x)&#123;<span class="keyword">return</span> x &gt;= <span class="number">0</span>;&#125;) ? <span class="built_in">cout</span>&lt;&lt;<span class="string">"all are positive"</span> : <span class="built_in">cout</span>&lt;&lt;<span class="string">"no all positive"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>bool any_of(begin_adress,end_adress,lambda_func)</strong></p><p>只要有一个满足要求的，就返回true</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">any_of(arr_begin,arr_end,[](<span class="keyword">int</span> x)&#123; <span class="keyword">return</span> x == <span class="number">0</span>;&#125;) <span class="comment">//返回bool</span></span><br></pre></td></tr></table></figure><p><strong>bool none_of(begin_adress,end_adress,lambda_func)</strong></p><p>所有都不满足情况的时候，返回true</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">none_of(arr_begin,arr_end,[](<span class="keyword">int</span> x)&#123; <span class="keyword">return</span> x == <span class="number">0</span>;&#125;) <span class="comment">//返回bool</span></span><br></pre></td></tr></table></figure><p><strong>copy_n(arr1,size,arr2)</strong></p><p>将arr1中的前size个元素拷贝到arr2中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> arr2[<span class="number">10</span>];</span><br><span class="line">copy_n(arr,<span class="number">10</span>,arr2);</span><br></pre></td></tr></table></figure><h3 id="containers"><a href="#containers" class="headerlink" title="containers"></a>containers</h3><p><strong>序列容器</strong></p><h4 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h4><p>向量是一个动态数组，数组的大小随着元素的个数而变化，内存空间是连续分布的，因此可以使用迭代器。向vector末尾插入元素要花费的时间是不确定的，因为有时候vector可能会扩容，此外插入和删除要花线性的时间。</p><p><strong>iterators</strong></p><p>vector是在内存上连续的一段存储空间，因此允许使用迭代器，vector的迭代器有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.begin(); <span class="comment">// 指向第一个元素</span></span><br><span class="line">vec.end(); <span class="comment">// 指向最后一个元素</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i = vec.begin();i!=vec.end();i++)&#123;...&#125;</span><br><span class="line">vec.rbegin(); <span class="comment">//指向最后一个，反向迭代</span></span><br><span class="line">vec.rend();  <span class="comment">// 指向第一个，作为后向的终点</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i = vec.rbegin();i!=vec.end();i++)&#123;...&#125;</span><br><span class="line"><span class="comment">// 此外上诉两种指针都有一个c（const）的版本，如vec.rbegin()</span></span><br><span class="line"><span class="comment">//这个版本返回的迭代器是const类型的，不可改变迭代器所指向元素的值</span></span><br></pre></td></tr></table></figure><p><strong>capacity</strong></p><p>vector是一个可变长度的向量，当vector在添加元素的时候，会选择增长向量的容量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.size(); <span class="comment">//实际长度</span></span><br><span class="line">vec.capacity(); <span class="comment">//已经分配的长度</span></span><br><span class="line">vec.max_size(); <span class="comment">// 可分配的最大长度</span></span><br><span class="line">vec.empty(); <span class="comment">// 判断是否为空</span></span><br><span class="line">vec.shrink_to_fit(); <span class="comment">// 将容量减小到容器的容量大小</span></span><br></pre></td></tr></table></figure><p><strong>访问元素</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">vec[<span class="number">1</span>];</span><br><span class="line">vec.front();</span><br><span class="line">vec.back();</span><br><span class="line">vec.at(pos);</span><br><span class="line">vec.data(); <span class="comment">// 返回指针指向第一个地址</span></span><br></pre></td></tr></table></figure><p><strong>修改元素</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.assign(val,time); <span class="comment">//vec赋值，time个val的值</span></span><br><span class="line">vec.push_back(val);</span><br><span class="line">vec.pop_back(val);</span><br><span class="line">vec.insert(insert_adress,val);</span><br><span class="line">vec.erase(adress);</span><br><span class="line">vec.clear(); <span class="comment">// 清空</span></span><br><span class="line">vec.emplace(adress,val); <span class="comment">// 插入元素，并且避免不必要的复制</span></span><br><span class="line">vec.emplace_back(val); <span class="comment">// 末尾插入</span></span><br><span class="line">vec.swap(vec2); <span class="comment">// 交换vec和vec1的元素</span></span><br></pre></td></tr></table></figure><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list是由<strong>双向链表</strong>实现的数据结构，它在空间中不连续，元素的访问速度不如vector，但是对元素的删除，插入操作十分的快速。</p><p>他的很多函数与vector类似，下面列举一下特殊的一下操作：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; ll = &#123;<span class="number">1</span>,<span class="number">7</span>,<span class="number">3</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">9</span>&#125;;</span><br><span class="line">ll.sort();</span><br><span class="line">ll.reverse();</span><br><span class="line">ll.push_front();</span><br><span class="line">ll.erase(adress) <span class="keyword">or</span> ll.erase(begin,end);</span><br><span class="line">ll.remove(val); <span class="comment">//删掉val</span></span><br><span class="line">ll.unique(); <span class="comment">// 删除重复元素</span></span><br><span class="line">ll.splice(l1.begin(),l2); <span class="comment">// 链表的拼接</span></span><br><span class="line">ll.merge(<span class="number">12</span>); <span class="comment">// 两个排序后的链表融合</span></span><br></pre></td></tr></table></figure><p><strong>deque</strong></p><p>双向队列，可以两头操作，效率比vector高，但是不一定保证地址是连续的。</p><p>deque和vector的操作基本一致，唯一的不同在于deque允许头插。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">deque</span>&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push_front(val);</span><br><span class="line">que.pop_front(val);</span><br></pre></td></tr></table></figure><p><strong>froward_list</strong></p><p>单向链表，与list类似，但只支持一个方向，同时所占用的存储空间更小。基本操作和list类似。</p><p><strong>queue</strong></p><p>单向队列，基本方法如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push(val); <span class="comment">// 插到队列尾巴</span></span><br><span class="line">que.pop();  <span class="comment">// 删除队列头部元素</span></span><br><span class="line"><span class="built_in">queue</span>.empty();</span><br><span class="line"><span class="built_in">queue</span>.size();</span><br></pre></td></tr></table></figure><p><strong>priority queue</strong></p><p>优先队列中，队头的元素是最大的，但是队列的排列顺序不是按照顺序排序的。优先队列使用起来应该很方便，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push(val);</span><br><span class="line">que.push(val);</span><br><span class="line">que.pop();</span><br><span class="line">que.top();</span><br></pre></td></tr></table></figure><p>优先队列是一种最大堆的结构。也可以用优先队列构建最小堆。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;<span class="keyword">int</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;,greater&lt;<span class="keyword">int</span>&gt;&gt; gg;</span><br></pre></td></tr></table></figure><p><strong>stack</strong></p><p>栈是先进先出的一个结构，只有一端开放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stack.empty();</span><br><span class="line">stack.push(val);</span><br><span class="line">stack.pop();</span><br><span class="line">stack.top();</span><br></pre></td></tr></table></figure><p><strong>关联容器</strong></p><p><strong>set</strong></p><p>集合容器，他要求内部元素没有重复的，他的常用的方法有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; gg;</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>,greater&lt;<span class="keyword">int</span>&gt;&gt; gg; <span class="comment">//从大到小</span></span><br><span class="line">begin();</span><br><span class="line">end();</span><br><span class="line">empty();</span><br><span class="line">gg.insert(val); <span class="comment">// set中的元素都是有序的</span></span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; gg = &#123;vec.begin(),vec.end()&#125;;</span><br><span class="line">gg.lower_bound(val); <span class="comment">//. 返回低于或等于val</span></span><br><span class="line">gg.upper_bound(val); <span class="comment">// 返回高于或等于val的第一个迭代器位置</span></span><br></pre></td></tr></table></figure><p><strong>multiset</strong></p><p>这个容器类似于set，但是和set有一个不同之处在于multiset可以允许重复。</p><p><strong>map</strong></p><p>字典，键值对。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">amap.insert(pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;(<span class="number">1</span>,<span class="number">21</span>));</span><br><span class="line">amap.insert(pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;(<span class="number">2</span>,<span class="number">23</span>));</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; amap[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">auto</span> ptr = amap.begin();</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;first&lt;&lt; <span class="string">" "</span>&lt;&lt; ptr-&gt;second;</span><br><span class="line">amap.erase(amap.begin());</span><br><span class="line">amap.erase(<span class="number">4</span>);<span class="comment">//key</span></span><br></pre></td></tr></table></figure><p><strong>multimap</strong></p><p>操作基本与map相同，不相同的是，multimap允许有相同的key。</p><p><strong>unordered_set</strong></p><p>背后使用hash表来存储，key没有顺序：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unordered_set</span>&lt;<span class="built_in">string</span>&gt; stringset;</span><br><span class="line">stringset.insert(<span class="string">"code"</span>);</span><br><span class="line">stringset.find(key); <span class="comment">//返回一个迭代器的位置</span></span><br></pre></td></tr></table></figure><p><strong>unordered_multiset</strong></p><p>与unordered_set相似，但是允许元素重复。</p><p><strong>unordered_map</strong></p><p>与map相似，但是其中的元素key的顺序不是按顺序的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">double</span>&gt; umap;</span><br><span class="line">umap['id'] = 11;</span><br><span class="line">umap.insert(make_pair(<span class="string">"e"</span>,<span class="number">2.33</span>));</span><br><span class="line">umap.find(key);</span><br></pre></td></tr></table></figure><p><strong>unordered_multimap</strong></p><p>与unordered_map相类似，但是允许有key的重复。</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp语法快速回顾</title>
      <link href="/2019/10/25/cpp%E8%AF%AD%E6%B3%95%E5%BF%AB%E9%80%9F%E5%9B%9E%E9%A1%BE/"/>
      <url>/2019/10/25/cpp%E8%AF%AD%E6%B3%95%E5%BF%AB%E9%80%9F%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>cpp的一些基本的语法的回顾，主要是一些比较小规模的语法特性的记录。</p><p>​    <a id="more"></a></p><p><strong>第一个可执行的cpp代码</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"hello world"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp程序编译执行过程</strong></p><ul><li>编译：将源代码翻译成机器语言，生成目标文件<ul><li>预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。</li><li>编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。</li><li>汇编：将汇编代码翻译成目标机器代码.o文件。</li></ul></li><li>链接：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。</li></ul><p><strong>#define宏定义</strong></p><p>宏定义用一个字符串代替一串字符串，在cpp编译的预处理阶段，将字符串的位置替换成原来的长字符串，这种设计方式的好处是1）修改代码方面。2）对一些很短的代码，如果写成一个函数，将花费大量的系统调用时间，因此宏定义可以提升代码效率，但是目标代码空间就会变大。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> pi 3.14 <span class="comment">//对象宏，定义变量</span></span></span><br><span class="line"><span class="comment">// 函数宏，这种方式直接将字符串展开，需要注意代码运算优先级的问题</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MIN(A,B) ((A) &lt; (B) ?(A):(B))</span></span><br></pre></td></tr></table></figure><p><strong>条件编译</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> NULL</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> NULL 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p><strong>#与##运算符</strong></p><p><strong>#</strong>起到将指令变成字符串的作用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MACRO(x) #x</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;MACRO(HOW ARE)&lt;&lt;<span class="built_in">endl</span>; <span class="comment">// "HOW ARE"</span></span><br></pre></td></tr></table></figure><p><strong>##</strong>起到链接前后内容的作用，将参数连在一起。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACFUNS(x,y) x##y</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;ACFUNS(<span class="string">"aa"</span>,<span class="string">"bb"</span>)&lt;&lt;<span class="built_in">endl</span>; <span class="comment">// aabb</span></span><br></pre></td></tr></table></figure><p><strong>typedef申明</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">short</span> <span class="keyword">int</span> <span class="keyword">wchar_t</span>;</span><br></pre></td></tr></table></figure><p>使用wchar_t来表示short int 这种类型，起了一个新名字。</p><p><strong>enum枚举类</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> color&#123;red,blue,black&#125; c; <span class="comment">//值为0，1，2</span></span><br><span class="line">c = blue; <span class="comment">//等于为c赋值为1</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; c; <span class="comment">// 1</span></span><br></pre></td></tr></table></figure><p><strong>声明与定义</strong></p><p>cpp语言支持分离时编译，允许将程序分割成多个模块，声明与定义分离（.h / .cpp）,静态库(lib)包含声明以及方法，动态库(.lib,dll)仅包含声明，dll中为方法。</p><p>声明的作用是在编译器链接代码的阶段，告诉程序该变量的存在。可以在多个文件中，多次声明，使用关键字：</p><p><code>extern int a;</code>声明了一个变量a。定义的过程只能有一次。</p><p><code>extern</code>关键字常用在多个文件同时使用同一个变量或者函数的时候。</p><p><strong>变量的初始值</strong></p><p>当一个变量是全局变量，系统会默认初始值为0。当变量是局部变量，系统不会赋初始值。</p><p><strong>定义常量</strong></p><p>常量不可以修改它的值，两种方式定义常量：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> WIDTH 10</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> HEIGHT = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p><strong>修饰符类型</strong></p><p>修饰符用于改变基本数据类型char，int，double的含义。可以使用的修饰符有： <code>signed,unsigned,long short</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* <span class="keyword">restrict</span> restar = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(<span class="number">10</span> * <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">制定只有restar这个指针可以指向这一块内存，其他指针都不能访问</span><br></pre></td></tr></table></figure><p><strong>存储类</strong></p><p>auto 关键字声明变量根据初始化值自动推断<strong>变量</strong>的类型，声明函数返回的<strong>占位符</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> f = <span class="number">3.14</span>;</span><br><span class="line"><span class="keyword">auto</span> s = <span class="string">"hello"</span>;</span><br></pre></td></tr></table></figure><p><strong>static</strong>告诉编译器在程序声明周期内保持局部变量的存在，在编译阶段进行赋值，其他阶段不会进行初始化操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> i = <span class="number">5</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;i&lt;&lt;<span class="string">'\n'</span>;</span><br><span class="line">    i--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">        func();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出为5，4，3，2，1.... 其中static i只会被初始化一次</span></span><br></pre></td></tr></table></figure><p><strong>thread_local</strong>关键字声明的变量仅仅可以在其上创建的线程上访问，仅仅可以用来声明变量。</p><p><code>thread_local int x;</code></p><p><strong>位运算符</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">00111100</span></span><br><span class="line">B = <span class="number">00001101</span></span><br><span class="line">A&amp;B = <span class="number">00001100</span></span><br><span class="line">A|B = <span class="number">00111101</span></span><br><span class="line">A^B = <span class="number">00110001</span></span><br><span class="line">~A = <span class="number">11000011</span></span><br><span class="line">A &lt;&lt;= <span class="number">1</span>; <span class="comment">//A = 01111000</span></span><br><span class="line">A &gt;&gt;= <span class="number">1</span>; <span class="comment">//A = 00011110</span></span><br><span class="line"><span class="keyword">sizeof</span>(A); <span class="comment">//返回A的大小</span></span><br><span class="line">b = &amp;A; <span class="comment">// 取地址</span></span><br><span class="line">c = *b; <span class="comment">// 取出b中的值</span></span><br></pre></td></tr></table></figure><p><strong>函数定义</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b)&#123;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//传参数方式可以分为传值，传指针，传地址三种</span></span><br></pre></td></tr></table></figure><p><strong>lambda表达式</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[capture](parameter)-&gt; <span class="keyword">return</span>-type&#123;body&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> s = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">auto</span> funa = [s](<span class="keyword">int</span> a,<span class="keyword">int</span> b)-&gt; <span class="keyword">int</span>&#123;<span class="keyword">return</span> a+b+s;&#125;;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; funa(<span class="number">1</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure><p><strong>数学运算</strong></p><p>数学运算的方法在<cmath>头文件中。</cmath></p><p><strong>随机数</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">j = rand()</span><br></pre></td></tr></table></figure><p><strong>数组</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>] = &#123;<span class="number">10</span>,<span class="number">10</span>,<span class="number">1</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br></pre></td></tr></table></figure><p><strong>字符串</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//c风格字符串</span></span><br><span class="line"><span class="keyword">char</span> gre[] = &#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>&#125;;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;gre;</span><br><span class="line"><span class="built_in">strcpy</span>(str1,str2); <span class="comment">// str2给str1赋值</span></span><br><span class="line"><span class="built_in">strcat</span>(str1,str2); <span class="comment">// str1+str2</span></span><br><span class="line"><span class="built_in">strcmp</span>(s1,s2);<span class="comment">//比较s1，s2</span></span><br><span class="line"><span class="built_in">strchr</span>(s1,ch); <span class="comment">// 返回指针，指针位置为ch第一次出现的位置</span></span><br><span class="line"><span class="built_in">strstr</span>(s1,s2);<span class="comment">// 放回指针，指向第一次出现s2的位置</span></span><br></pre></td></tr></table></figure><p><strong>string 字符串操作</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> a = <span class="string">"hello"</span>;</span><br><span class="line"><span class="built_in">string</span> b = <span class="string">"el"</span>;</span><br><span class="line">a.find_first_of(b); <span class="comment">// 等于a.find(b);</span></span><br><span class="line">a.find_last_of(b);</span><br><span class="line">s.size();</span><br><span class="line"><span class="keyword">if</span>(a.find(b) == <span class="built_in">string</span>::npos)&#123;</span><br><span class="line">    <span class="keyword">return</span> “dont exists”;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>指针</strong></p><p>cpp中每个变量都有一个内存位置，这个内存位置可以通过<code>&amp;</code> 取址符来得到，他表示内存中的一个地址。</p><p>指针是一个变量，它的值就是地址。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *ip;</span><br><span class="line"><span class="keyword">int</span> var = <span class="number">10</span>;</span><br><span class="line">ip = &amp;var;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; *ip; <span class="comment">//取去ip中的值</span></span><br><span class="line"><span class="keyword">int</span> *ptr[<span class="number">10</span>]; <span class="comment">//指针数组，数组中存指针</span></span><br><span class="line"><span class="comment">//指针可以允许加减，数组和指针很类似，一个定义在数组开头的指针用法和数组相同</span></span><br><span class="line"><span class="keyword">int</span> var[<span class="number">5</span>] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line"><span class="keyword">int</span> *ip = var;</span><br><span class="line">ip++;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ip[<span class="number">1</span>];</span><br></pre></td></tr></table></figure><p><strong>引用</strong></p><p>引用变量是为变量起了一个别名，引用在创建的时候必须初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>&amp; r = a;</span><br><span class="line"><span class="comment">//传参数的时候可以使用引用，不用传值，快。</span></span><br><span class="line"><span class="comment">// 函数返回类型为引用类型的时候，操作和其他类型的一样，返回一个引用，就可以对这个引用进行赋值的过一些操作了。</span></span><br></pre></td></tr></table></figure><p><strong>结构体</strong></p><p>cpp中定义数据类型使用结构体</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Book</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Book</span> <span class="title">b1</span>;</span></span><br><span class="line"><span class="comment">//使用typedef定义别名</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Book</span>&#123;</span></span><br><span class="line">      <span class="keyword">int</span> count;</span><br><span class="line">      <span class="built_in">string</span> name;</span><br><span class="line">&#125;Book;</span><br><span class="line">Book b1,b2;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; b1.name;</span><br><span class="line"><span class="comment">//指针调用</span></span><br><span class="line">Book *ptr = &amp;b1;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;name;</span><br></pre></td></tr></table></figure><p><strong>类</strong></p><p>类是cpp的核心，通常被用与用户定制自己的数据以及方法</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">      <span class="keyword">int</span> width;</span><br><span class="line">      <span class="keyword">int</span> height;</span><br><span class="line">      Box(); <span class="comment">//构造函数，函数进行定义，初始化的入口</span></span><br><span class="line">      <span class="function"><span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> width*height;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;;</span><br><span class="line">Box b1; <span class="comment">//定义了一个Box的类型变量</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt; b1.width;</span><br><span class="line">Box* ptr = &amp;b1;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;get_area();</span><br></pre></td></tr></table></figure><p><strong>拷贝构造函数</strong></p><p>利用已经存在的类对象，对新类进行初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Box b2 = b1;</span><br></pre></td></tr></table></figure><p><strong>友元函数</strong></p><p>友元函数设计的思路是说，一个非A类内的函数，希望获得完整的A类内成员的访问权限，这时候需要在A类对该函数进行一下注册，用friend最为前缀（适用于多人协作的项目）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line">  <span class="keyword">int</span> val;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">int</span> mon;</span><br><span class="line">  <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">detial</span><span class="params">(A a1)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">(A a1)</span></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; a1.val; <span class="comment">//允许访问私有变量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>this 指针</strong></p><p>成员函数均有一个隐含的this指针参数，用于指向对象。</p><p><strong>类内静态成员变量，静态函数</strong></p><p>类中允许定义static变量，该变量在所有类的对象中是共享的，该变量属于类，不属于对象，不可以在类的构造函数中初始化static变量，而是通过<code>A::变量 =  init</code>的方式进行初始化。</p><p>static声明的函数，与任何对象都没有关系，该函数与类同在，只能访问静态成员变量，与其他静态成员函数。</p><p><strong>继承</strong></p><p>我理解继承是这种大型工程中非常有灵性的一种设计，通过底层写一些通用的模版类，底下的继承类就有很好的一致性，以及少写了很多重复性的工作，此外通过子类中定制自己的成员，呈现一种放散式的结构。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">book</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> page = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">string</span> name = <span class="string">"island"</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span>&lt;&lt; <span class="keyword">this</span>.page &lt;&lt; <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">finance</span>:</span> <span class="keyword">public</span> book&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> profit = <span class="number">0</span>;</span><br><span class="line">    finance(<span class="keyword">int</span> pro);</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line">finance::finance(<span class="keyword">int</span> pro):book()&#123;</span><br><span class="line">  <span class="keyword">this</span>.profit = pro;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> finance::detail()&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span>.page &lt;&lt; <span class="keyword">this</span>.name &lt;&lt; <span class="keyword">this</span>.pro;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体来说，<strong>继承不会继承积累的构造函数，友元函数，重载运算符。</strong>从设计的角度上看，友元这一类函数会破坏类的封装性，子类不接受友元是很正确的决定，而构造函数有专门的作用，因此，不继承构造函数也是可以理解的。</p><p><strong>基类构造函数</strong></p><p>所谓的基类构造函数，构造的时候，需要对父类进行初始化，很容易理解。初始化的方式就是通过构造函数表来初始化，在构造函数定义的时候使用，成员变量也允许那时候初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">finance::finance(<span class="keyword">int</span> profit,<span class="keyword">int</span> page,<span class="built_in">string</span> name):Book(page,name),profit(profit)&#123;&#125;</span><br></pre></td></tr></table></figure><p><strong>重载运算符</strong></p><p>我认为这一步的设计思路是是我们设计的类和基础类型的变量能够使用一些类似于<strong>+，-，x，/</strong>这种方便的操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">   Box <span class="keyword">operator</span>+(Box b)&#123;</span><br><span class="line">     Box box;</span><br><span class="line">     box.width = <span class="keyword">this</span>.width + b.width;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">Box b1,b2;</span><br><span class="line">b = b1 + b2;</span><br></pre></td></tr></table></figure><p><strong>重载函数</strong></p><p>重载函数指的是同一个函数，但是随着输入的参数不同，调用的具体函数也是不同的。这样的设计思路在于，是一个函数用起来更加灵活，例如对于不同级别的类别都需要登入操作，但是入口不同。就可以利用重载的思路来实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">log</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> user = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> vip = <span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(<span class="keyword">int</span> user)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(<span class="keyword">int</span> user,<span class="keyword">int</span> vip)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>多态</strong></p><p>多态的设计思路，有这样一种情况，当子类与父类中同时有某个方法。我们可以用父类的指针来存放所有的子类的地址。但是每个子类调用一个工友的方法，各自应该有各自的方案。例如大家办护照都去公安局，但是每个人有不同的办理方案，这种情况就是多态。</p><p>要实现多态的话，在需要实现多态的函数前加上<strong>virtual</strong>关键字，告诉编译器，在编译的时候不要链接该函数，而是得到调用函数的时候，看变量的类型来确定用什么函数。这个叫<strong>做动态链接</strong>。</p><p>静态链接则是写死了，每次用父类的对象调用的都是父类的方法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> height = <span class="number">0</span>;</span><br><span class="line">    shape(<span class="keyword">int</span> w,<span class="keyword">int</span> h):width(w),height(h);</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"shape"</span> ；</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">triangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    triangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"triangle area"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">      <span class="keyword">return</span> a*b / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    rectangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"rectangle area"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">      <span class="keyword">return</span> a*b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">shape* sh;</span><br><span class="line"><span class="function">rectangle <span class="title">rec</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="function">triangle <span class="title">tri</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="comment">// 正方形面积</span></span><br><span class="line">sh = &amp;rec;</span><br><span class="line">sh-&gt;area();</span><br><span class="line"><span class="comment">// 三角形面积</span></span><br><span class="line">sh = $tri;</span><br><span class="line">sh-&gt;area();</span><br></pre></td></tr></table></figure><p><strong>虚基类virtual</strong></p><p>虚基类提出的设计思路是说，如果一个类同时继承两个类，而这两个类又同时继承自同一个父类，因此在子类这就会出现最高父类的两个拷贝。因此多继承很多时候会产生很多二义性的问题，因此在设计函数的时候要尽可能避免。出现这种情况可以用virtual进行虚继承。<code>class B : virtual public A{...}</code>。</p><p><strong>抽象类</strong></p><p>设计抽象类的设计思想是说，面向对象的系统可能会使用一个抽象基类为所有的外部应用程序提供一个适当的、通用的、标准化的接口。因此会在基类设计一个<strong>virtual</strong>抽象类，规定一下子类的接口参数的格式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">    <span class="keyword">int</span> weight;</span><br><span class="line">    shape(<span class="keyword">int</span> a,<span class="keyword">int</span> b):width(a),weight(b)&#123;&#125;</span><br><span class="line">  <span class="comment">// 提供纯虚函数接口，子类必须覆盖</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    rectangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.width*<span class="keyword">this</span>.weight;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>文件的读写</strong></p><p>文件的读写定义在两个库函数中，<strong>ifstream,ofstream</strong>，写入过程使用&lt;&lt;，读出过程使用&gt;&gt;。</p><p><strong>异常处理</strong></p><p>cpp中提供了<code>try,catch,throw</code>用来保护代码，抛出错误。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="comment">//保护代码</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(ExceptionName e1)&#123;</span><br><span class="line">  <span class="comment">//catch 内容</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(ExceptionName e2)&#123;</span><br><span class="line">  <span class="comment">// something</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//catch 模块</span></span><br><span class="line"><span class="keyword">if</span>(error)&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="string">"error message"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp动态内存</strong></p><p>栈：在函数内部声明的所有变量都将用栈来存储</p><p>堆：这部分内存程序未使用，在程序运行时可动态分配内存。</p><p>cpp允许使用<strong>new</strong>给变量分配堆内内存，返回动态内存的起始位置，同时可以使用<strong>delete</strong>将这部分内存删除。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span>* ptr = <span class="keyword">new</span> <span class="keyword">double</span>;</span><br><span class="line">*ptr = <span class="number">12.32</span>;</span><br><span class="line"><span class="comment">//数组申请空间</span></span><br><span class="line"><span class="keyword">int</span> * ptr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line"><span class="comment">//释放</span></span><br><span class="line"><span class="keyword">delete</span>[] ptr;</span><br><span class="line"><span class="comment">// 二维数组</span></span><br><span class="line"><span class="keyword">int</span> ** ptr = <span class="keyword">new</span> <span class="keyword">int</span> *[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">  ptr[i] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">Box* ptr = <span class="keyword">new</span> Box[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">delete</span> [] ptr;</span><br></pre></td></tr></table></figure><p><strong>命名空间</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> first_space&#123;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">     ...</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">first_space::func();</span><br></pre></td></tr></table></figure><p><strong>cpp模板</strong></p><p>模板指<strong>函数模板</strong>和<strong>类模板</strong>，是一种参数化类型机制，在泛型编程（泛型允许程序员使用<strong>未指定</strong>类型的变量，在<strong>实例化</strong>时作为参数指明这些类型）中十分的重要。常用的cpp模版例如<strong>vector</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//函数模板</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="comment">// 用T表示一种类型的变量</span></span><br><span class="line"><span class="function">T <span class="title">Max_val</span><span class="params">(T a,T b)</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a &gt; b ? a:b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line">Max_val(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">Max_val(<span class="number">1.2</span>,<span class="number">3.4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//类模板</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">stack</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;T&gt; elems;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(T <span class="keyword">const</span>&amp; val)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">stack</span>&lt;T&gt;:</span>:push(T <span class="keyword">const</span>&amp; val)&#123;</span><br><span class="line">  elems.push(val);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; int_stack;</span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="built_in">string</span>&gt; str_stack;</span><br></pre></td></tr></table></figure><p><strong>const&amp;</strong></p><p>在一些库函数，模板类的函数中进场发现这种传参数，传指数的方法,这种方法用引用减少数值传递过程中需要消耗的时间。返回值是const&amp;是个引用，如果是const的话，程序还需要另外开辟空间。同时这样使用可以函数返回值还可以作为左值，因此建议今后写代码带上引用。</p><p><strong>void*</strong></p><p><code>void *</code>是一种指针类型，常用在<code>函数参数、函数返回值</code>中需要兼容不同指针类型的地方。它类似于指针类型中的原始基类，所有的指针可以对它赋值，它也可以转化为任何指针类型，但是是否合理需要看函数的原始定义。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* c;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> * ptr = &amp;a;</span><br><span class="line">c = ptr;</span><br><span class="line"><span class="keyword">int</span> * d = (<span class="keyword">int</span> *) c;</span><br></pre></td></tr></table></figure><p><strong>cpp多进程/线程</strong></p><ul><li>进程：程序需要并发执行</li><li>线程：一个进程中含多个线程，线程负责同一段程序中的并发</li></ul><p>使用 POSIX 编写多线程 C++ 程序。POSIX支持linux上的并行：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">// 线程的运行函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">say_hello</span><span class="params">(<span class="keyword">void</span>* args)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Hello Runoob！"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 定义线程的 id 变量，多个变量使用数组</span></span><br><span class="line">    <span class="keyword">pthread_t</span> tids[NUM_THREADS];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//参数依次是：创建的线程id，线程参数，调用的函数，传入的函数参数</span></span><br><span class="line">        <span class="keyword">int</span> ret = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, say_hello, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (ret != <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">           <span class="built_in">cout</span> &lt;&lt; <span class="string">"pthread_create error: error_code="</span> &lt;&lt; ret &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等各个线程退出后，进程才结束，否则进程强制结束了，线程可能还没反应过来；</span></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp中的STL（standard template library）</strong></p><p>STL库中包含了许多模板类，实现了很多容器，算法以及迭代器等等。</p><ul><li>算法algorithm：这些算法类大多是作用在容器上</li><li>容器：如vector，map，set等等</li><li>迭代器</li><li>Functors：算子，类似于sort的时候用算法自定义排序的方式，作为参数传入</li></ul><p>为STL专门开一个post，日常使用和刷题都会比较经常使用：<a href="https://perper.site/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">链接</a></p><p><strong>cpp标准库</strong></p><p>这个库是继承自C语言的，包括标准函数库和标准对象库。</p><p><strong>#include</strong></p><p>cpp中include一个头文件在编译阶段等同于件这个头文件中的代码展开，因此cpp中发生相互引用时将会报错，当你在不确定是否存在相互引用的时候，建议加上include保护：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> FOLDER_METHOD_H_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FOLDER_METHOD_H_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>Google 开源风格指南中建议的include顺序：</p><p> <code>dir/foo.cc</code> 或 <code>dir/foo_test.cc</code> 的主要作用是实现或测试 <code>dir2/foo2.h</code> 的功能, <code>foo.cc</code> 中包含头文件的次序如下:</p><blockquote><ol><li><code>dir2/foo2.h</code> (优先位置, 详情如下)</li><li>C 系统文件</li><li>C++ 系统文件</li><li>其他库的 <code>.h</code> 文件</li><li>本项目内 <code>.h</code> 文件</li></ol></blockquote><p>这种优先的顺序排序保证当 <code>dir2/foo2.h</code> 遗漏某些必要的库时， <code>dir/foo.cc</code> 或 <code>dir/foo_test.cc</code> 的构建会立刻中止。因此这一条规则保证维护这些文件的人们首先看到构建中止的消息而不是维护其他包的人们。</p><p>.cpp中要包含include自己的h文件，在程序编译阶段include尽量都写在头文件中，源文件就可以很少的引用头文件。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>重新回顾了一下cpp的一些语法重点，发现这本语言相比较于其他语言来说，有很大的自由度，自由发挥的地方非常的多。同时有为写一些大工程而设计上的思路。总体来说，比较感兴趣，由于使用CLion来作为编辑器，通过一种更加原生的方式写代码，编译代码，感觉要比直接用VS studio要有深刻的理解。</p><p>这一页博客要常常回来回顾回顾！</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepLab 总结</title>
      <link href="/2019/10/22/DeepLab-%E6%80%BB%E7%BB%93/"/>
      <url>/2019/10/22/DeepLab-%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 项目总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp工程文件的总结</title>
      <link href="/2019/10/21/cpp%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/2019/10/21/cpp%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>cpp学习的第一轮，首先从以前的盲区开始杀进去，解决的第一个问题是</p><blockquote><p>人们说cpp工程文件，说的都是什么。</p></blockquote><a id="more"></a><p>打开vs，创建一个控制台的应用。（CLion用cmakeList链接文件，感觉可以学习一下）这时候会产生很多中间系统文件以及文件夹。</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读：基于RealSense和模型库的人体建模方法</title>
      <link href="/2019/10/18/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8ERealSense%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BA%93%E7%9A%84%E4%BA%BA%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/"/>
      <url>/2019/10/18/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8ERealSense%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BA%93%E7%9A%84%E4%BA%BA%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>这篇论文是张远师兄的毕业论文，主要的思路是通过深度模型预测类别，进而补全模型深度信息，然后通过学习模型参数，最终实现对人体的建模以及测量。</p><a id="more"></a><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>人体建模经历了 1. 基于回归分析的人体建模 2. 基于三维扫描人体建模 3. 基于数据库人体建模。人体建模的精度越来越高，对场景的约束越来越低。</p><p>本文通过基于RGBD信息与模型数据库的人体建模技术，提升人体建模的精度。主要的工作有：</p><ol><li><p>提出一种基于RGB数据的<strong>人体深度类别</strong>预测方法</p></li><li><p>提出一种基于深度类别信息的人体<strong>深度数据补全</strong>与优化方法</p></li><li>提出一种<strong>基于RGBD数据</strong>和<strong>模型参数</strong>的人体建模方法</li></ol><h3 id="基于RGB预测人体深度类别"><a href="#基于RGB预测人体深度类别" class="headerlink" title="基于RGB预测人体深度类别"></a>基于RGB预测人体深度类别</h3><p>基于RGB数据来预测人体的深度信息，本文提出了两阶段的网络结构，用于RGB图像中的人体深度类别预测。该部分主要分为两部分：</p><ul><li>预测图像中的人体分割</li><li><p>预测人体分割对应的深度信息</p><p>针对人体不变的局部特征和多变的全局特征，作者采用多尺度信息融合的方式提取特征，采用跳跃层结构，使用Stacked hourglass network作为基本网络，使用交叉熵作为损失函数，分别应用与人体部件分割以及深度类别的预测上。</p></li></ul><p>针对这两个问题，作者使用Varol et al.(CVPR 2017) 提到的方法对人体进行分割以及预测人体的深度类别信息。该网络深度信息预测结果不好，作者通过扩充网络，将网络修改成二阶段的网络，获取原始数据多尺度的结果之后得到一个较好的恢复结果。</p><p><img src="/images/3D/deep_predict.png" style="zoom:50%;"></p><p>左图第二行是分割信息，有图中间一列是Varol的结果，最后一列是本文结果。</p><h3 id="基于深度类别信息的人体深度数据补全与优化"><a href="#基于深度类别信息的人体深度数据补全与优化" class="headerlink" title="基于深度类别信息的人体深度数据补全与优化"></a>基于深度类别信息的人体深度数据补全与优化</h3><p>对RGB图像进行标定，作者使用realsense内部的标定算法实现标定。接下来对深度数据进行恢复，主要有两种方案，一种是基于滤波器的方法，另一种则是基于图像修复重建的方案。第一种方案难以修复比较大的空洞，第二种方案引入图像修复技术，通常会假设人体深度数据与RGB数据呈现局部线性关系，作者认为由于人的衣服颜色相同，因此不适用于这两种方案。</p><p>作者使用快速行进法（Telea 2004）(FMM)进行空洞的补全，该方法的思路是从已知的像素点和位置的像素点的边界开始计算，逐渐扩展到所有位置的像素点，求解出深度图。作者首先对其RGBD图像之后，对目标图像I上的任意一点深度，采用对周边点的一阶泰勒展开来得到。使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：<br>$$<br>I(p)=I(q)+\nabla I_{p}(q)(p-q)<br>$$<br>使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：<br>$$<br>I(p)=\frac{\sum w(p, q)\left[I(q)+s \cdot \nabla C_{p}(q)(p-q)\right]}{\sum w(p, q)}<br>$$<br>通过快速行进法，使用RGB梯度代替目标图像的梯度的方式，作者命名为GradientFMM，梯度的快速行进法。</p><p>在图像滤波上，作者使用了<strong>引导滤波</strong>的方法，对整张深度图像进行滤波。</p><h3 id="基于RGBD数据和模型参数的人体建模与测量"><a href="#基于RGBD数据和模型参数的人体建模与测量" class="headerlink" title="基于RGBD数据和模型参数的人体建模与测量"></a>基于RGBD数据和模型参数的人体建模与测量</h3><p>作者基于数据库学习出一种人体模型的参数表示方式，能够很好的表示出人体姿势的变化，从而使一个标准的人体形变后和点云数据相互拟合。随后建立一个融合点云数据和人体参数的能量优化模型，得到配准的人体三维模型。</p><p>能量函数（Bouaziz et al 2014）提出一种 能量函数泛式来解决配准问题，他包含数据匹配和参数先验能量。<br>$$<br>E = E_{match} + E_{prior}<br>$$<br>作者研究，对于刚体形变或非刚体形变本质上都是期望最大化算法。EM算法本上是一个非凸优化问题。因此上诉配准问题不一定能收敛到最优解。</p><p>作者使用SCAPE数据集，里头包含1517个男性和1531个女性在不同姿势下的模型，对于每一个人人体模型，都包含12500个顶点和25000个三角面片。对于人体的三维变形，本质上就是对人体网格的三角面片进行变形。 作者通过计算标准模型到每一块面片的参数变换的Q，R，S矩阵，得到整个数据集所有的变换矩阵。因此可以通过不用的姿势，体型参数，可以得到一组Q，R，S然后从标准的模型中，得到目标的模型。</p><p>随后利用能量函数（数据匹配能量以及人体先验能量函数）来无限的拟合人体参数模型和采集到的深度数据之间的距离，得到一个较为真实的人体模型。项目到此结束。</p><h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>做鱼类RGBD数据的三维重建工作，我觉得我的工作可能集中在深度数据的恢复，水下场景的去噪算法，光线折射的还原，空洞的补全这些部分上。对于最后和标准的三维模型去拟合这一部分的工作我可能没办法完成了。</p><p>然后使用到cpp，绘制部分的工作可以用恢复了一部分的深度数据来完成。</p><p>那么近期的工作就十分的清楚了，关注人体的恢复实验，找到一些深度学习的算法，恢复出人体，然后针对鱼进行优化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 3D重建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何读论文</title>
      <link href="/2019/10/16/%E5%A6%82%E4%BD%95%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
      <url>/2019/10/16/%E5%A6%82%E4%BD%95%E8%AF%BB%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<p>对于近期在读论文上效率比较低，读完收获比较小的问题，我从知乎上找到了一些比较好的读论文，做笔记的方法，在这里记录一下。</p><a id="more"></a><h2 id="读论文"><a href="#读论文" class="headerlink" title="读论文"></a>读论文</h2><h3 id="筛选论文，确定是否值得读"><a href="#筛选论文，确定是否值得读" class="headerlink" title="筛选论文，确定是否值得读"></a>筛选论文，确定是否值得读</h3><blockquote><p>feel free to stop reading the article at any point</p></blockquote><ol><li>拿到一篇论文先看<strong>论文题目，keywords</strong>，若你不感兴趣，you stop</li><li>阅读 <strong>abstract</strong>，你可以快速地了解整篇文章。</li><li><p>阅读 <strong>conclusion</strong>，从结论中你可以看出来这篇文章是否和你研究的问题相关。</p></li><li><p>阅读 论文 <strong>图片，表格，标题</strong>，从这些地方你可以花很少的时间，搞清楚作者是如何做这项工作的</p></li></ol><p>到这里，如果你认为这篇文章还可以继续的话，你就可以接着往下进行了。</p><h3 id="精度论文"><a href="#精度论文" class="headerlink" title="精度论文"></a>精度论文</h3><ol><li>阅读 <strong>introduction</strong>，该部分你将读到整个文章的背景，以及作者做这篇文章的主要目的。</li><li>文章的最重要的核心是 <strong>the result and the discussion</strong>，你应该在这上面花主要的时间，如果你觉得差不多了，你就可以停止了。</li><li>但是你如果觉得这篇文章和你的工作的相关性比较大的话，那你就应该dig extremely into the <strong>experience section</strong>。在这一部分你就可以清楚的知道作者是如何做这件事的。</li><li>当你阅读完这篇论文的时候，适当的做些笔记，这些笔记将会在你未来的研究中为你省下很多的时间。</li></ol><h3 id="读论文的一些tips"><a href="#读论文的一些tips" class="headerlink" title="读论文的一些tips"></a>读论文的一些tips</h3><ol><li>参考文献中信息很多，可以花时间找一些参考文献中的文章是否和你当前的问题相关，减少调研的工作量。</li><li>关注近五年的文献。</li><li>关注核心期刊、会议以及一些学科大牛。</li></ol><h3 id="如何记笔记"><a href="#如何记笔记" class="headerlink" title="如何记笔记"></a>如何记笔记</h3><p>记笔记在阅读完论文后，进行简要的记录：</p><ol><li>论文出处</li><li>论文背景</li><li>论文工作</li><li>论文创新</li><li>不足以及研究方向</li><li>自己的想法</li></ol><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p> <a href="https://www.zhihu.com/question/304334959/answer/553782865" target="_blank" rel="noopener">https://www.zhihu.com/question/304334959/answer/553782865</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>resume detail 2019/10/15</title>
      <link href="/2019/10/15/resume-detail/"/>
      <url>/2019/10/15/resume-detail/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 项目总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepMVS:Learning Multi-view Stereopsis</title>
      <link href="/2019/10/14/DeepMVS-Learning-Multi-view-Stereopsis/"/>
      <url>/2019/10/14/DeepMVS-Learning-Multi-view-Stereopsis/</url>
      
        <content type="html"><![CDATA[<p>该篇论文通过一系列的图像，生成这些图像所对应的深度信息。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 3D重建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>State of Art on 3D Reconstruction with RGB-D Cameras 三维重建综述</title>
      <link href="/2019/10/10/State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/"/>
      <url>/2019/10/10/State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p>这篇论文是发表在欧洲计算机图形学协会2018上的一篇综述文章，下面将精读这篇论文，对其中的重点内容进行记录。</p><a id="more"></a><h3 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h3><p>近些年来，基于结构光（structure light）和TOF（time of flight）方法的深度相机得到了大规模的商用，很多基于RGB-D数据的三维重建算法达到了很好的重建效果。一些具有创新性的方法得到了发展、一些基于RGB-D用于还原3D结构的方法、一些基于RGB-D研究物体其他属性的方法（材料，反射模型）也相继被提出。</p><h4 id="RGB-D-cameras-and-their-characteristics"><a href="#RGB-D-cameras-and-their-characteristics" class="headerlink" title="RGB-D cameras and their characteristics"></a>RGB-D cameras and their characteristics</h4><p>目前，深度距离检测上存在两种方法，一种为三角测距（triangulation），另一种为TOF（time of flight），三角测距可以是被动式（立体视觉），也可以是主动式（结构光）。stereo vision方法计算两张不同角度的照片的差异，而结构光同样是发射红外线，通过分析红外线的扭曲程度三角测量的方式得到深度信息。TOF方法则是通过发射红外光，通过测量接收到反射光的时间来判断物体的深度信息。</p><h4 id="static-Scene-Reconstruction（静态场景重建）"><a href="#static-Scene-Reconstruction（静态场景重建）" class="headerlink" title="static Scene Reconstruction（静态场景重建）"></a>static Scene Reconstruction（静态场景重建）</h4><p> 在线的静态场景重建直接相关的技术有SLAM（simultaneous Localization and Mapping），这个技术主要的关注点在于在未知环境中机器人的导航，主要针对离散稀疏的点云建模。另一方面，静态稠密点云的重建也引起很大的关注。</p><p>在线重建的发展使得一些如kinect Fusion算法，possion surface reconstruction（柏松重建算法）的研究成为一个热门的方向。</p><h4 id="静态场景重建的基础pipeline"><a href="#静态场景重建的基础pipeline" class="headerlink" title="静态场景重建的基础pipeline"></a>静态场景重建的基础pipeline</h4><p>第一步：深度图的预处理，噪声的消除，外部（outlier）信息的移除这些处理方法会首先对RGB-D数据进行处理。</p><p>第二步：从输入的深度图序列中提取出额外的信息，存储起来。</p><p>第三步：相机位姿的估计以及转换矩阵T的估计</p><p>第四步：深度图的融合，将所有计算出的点融合到模型M中。</p><h4 id="深度图的预处理"><a href="#深度图的预处理" class="headerlink" title="深度图的预处理"></a>深度图的预处理</h4><p>深度图中噪声的长生由多种因素影响，常用的方法有使用双边滤波的方式（bilateral filter）来过滤噪声，此外对于一些特定的模型，姿态估计等等方法也会被使用。</p><h4 id="camera-pose-Estimate"><a href="#camera-pose-Estimate" class="headerlink" title="camera pose Estimate"></a>camera pose Estimate</h4><p>对每一张RGB-D图像，计算6-DOF pose T。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>3D重建论文阅读</title>
      <link href="/2019/10/08/3D%E9%87%8D%E5%BB%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2019/10/08/3D%E9%87%8D%E5%BB%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>本篇博客的主要目的是为了记录所读的有关于三维重建的文章，对每篇文章的insight进行简要的总结。</p><a id="more"></a><h3 id="State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras"><a href="#State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras" class="headerlink" title="State of Art on 3D Reconstruction with RGB-D Cameras"></a>State of Art on 3D Reconstruction with RGB-D Cameras</h3><p>该论文是发表在eurographics 欧洲计算机图形学协会2018上，对当前的RGB-D图像三维重建进行了一个综述整理。</p><p>这是明天的任务。</p><hr><h3 id="Underwater-3-D-Scene-Reconstruction-Using-Kinect-v2-Based-on-Physical-Models-for-Refraction-and-Time-of-Flight-Correction"><a href="#Underwater-3-D-Scene-Reconstruction-Using-Kinect-v2-Based-on-Physical-Models-for-Refraction-and-Time-of-Flight-Correction" class="headerlink" title="Underwater 3-D Scene Reconstruction Using Kinect v2 Based on Physical Models for Refraction and Time of Flight Correction"></a>Underwater 3-D Scene Reconstruction Using Kinect v2 Based on Physical Models for Refraction and Time of Flight Correction</h3><p>该论文被2017年IEEE access收录，论文主要的思路是搭建一个防水装置，将kinect v2放入水中，利用kinect v2来采集RGB图像以及深度图像。然后通过<strong>水下数据采集，相机矫正，噪声过滤，TOF矫正，反射矫正</strong>等步骤恢复深度数据，最后通过kinect Fusion等到三维重建后的效果。</p><ul><li><p>数据获取采集部分采用加入防水外壳的kinect v2。</p></li><li><p>水下滤波部分，在kinect fusion算法中，针对空气中的滤波采用bilinear filter，水下环境复杂，作者采用5 x 5的median中值滤波。</p></li><li>kinect TOF矫正，由于在水下红外线的传播速度与空气中传播的速度不同，因此需要对检测到的深度信息进行矫正。水中传播的距离需要根据水中的红外线传播的速度进行修正。</li><li>水下折射矫正，kinect v2捕捉到的图像、深度信息在水下存在一定程度上的偏移，因此需要进行水下的折射矫正。</li></ul><p>在三维恢复性能比较方面，作者采用物体的三维模型或者激光采集到的三维数据作为ground truth进行对比，得出性能的优劣。</p><p>2019/10/8</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>3D重建综述</title>
      <link href="/2019/09/26/3D%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/"/>
      <url>/2019/09/26/3D%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p> 双目重建问题是一个计算机视觉领域一个比较经典的问题。通过两个固定、水平放置的相机，对同一个物体各个角度采集照片，利用成像原理预测物体的深度信息，进行三维场景的重建。</p><a id="more"></a><p><strong>亚像素：</strong>面阵摄像机的成像面以像素为最小单位，像素间距为5.2微米。在宏观上可以认为像素是连续的，但是在微观上，5.2微米之间的部分我们称为亚像素，可以利用软件恢复出来。</p><p><strong>6 DOF：</strong>六自由度，指的是刚体在三维空间中运动的自由度，特别是指刚体可以在前后、上下、左右三个相互垂直的坐标轴上平移，也可以在三个垂直的坐标轴上旋转。</p><p><strong>数据集benchmark：</strong>立体视觉是计算机视觉中最为重要的方向之一，在视差检测方面<strong><a href="http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo" target="_blank" rel="noopener">KITTI</a></strong>、 <strong><a href="http://vision.middlebury.edu/stereo/" target="_blank" rel="noopener">MiddleBury</a></strong> 提供的数据集常被作为Benchmark。</p><h3 id="Image-based-3D-Object-Reconstruction-State-of-the-Art-and-Trends-in-the-Deep-Learning-Era"><a href="#Image-based-3D-Object-Reconstruction-State-of-the-Art-and-Trends-in-the-Deep-Learning-Era" class="headerlink" title="Image-based  3D Object Reconstruction:State-of-the-Art and Trends in the Deep Learning Era"></a>Image-based  3D Object Reconstruction:State-of-the-Art and Trends in the Deep Learning Era</h3><p>3D重建问题研究上的pipeline如下：</p><p>物体【generic objects 】-&gt;数据【single images,multiple RGB】-&gt;研究方法【shape representations，network architecture，training mechanism】</p><p>此外对一些特殊的物体，例如人体、人脸等问题，也有着很多的三维重建的工作。</p><h4 id="问题的定义"><a href="#问题的定义" class="headerlink" title="问题的定义"></a>问题的定义</h4><p>数据输入为一系列的RGB图片，输出为物体的三维重建的结果。三维重建网络的含义在于学习一个预测器，通过这个预测器学习到物体的三维表达，然后与GT之间计算一个最小的重建误差。</p><p>数据的输入形式有<strong>单张图片，多张图片，视频流。</strong>此外可以添加一些额外的预测信息，例如图像的轮廓，分割的结果以及语义标签进行共同预测。</p><h4 id="encoding-state"><a href="#encoding-state" class="headerlink" title="encoding state"></a>encoding state</h4><p>该部分用于提取图片中的深层次的特征将输入I映射到一个潜在的空间中。<br>$$<br>x = h(I)<br>$$<br>对于映射函数h有以下的要求：</p><ul><li>在I空间中相似的两个物体，在x空间中仍然十分的接近。</li><li>在x空间中小小的扰动（perturbation）可以反应到I空间中的扰动。</li><li>映射函数不受相机参数、位姿的影响。</li><li>3D模型和2D图像可以映射到x空间中的同一个点，这样的目的可以消除模型的二义性。</li></ul><p>隐空间有多种类型，离散、连续、层级以及开放（disentangled）的空间。</p><p><strong>离散的隐空间</strong> </p><p>最高由Wu等将一个3D的encoding 网络引入三维重建中用于映射一个3D的体素空间。此后标准的vanilla结构的网络，以及他的变种被引入三维重建中，其他工作如pooling layer，RELU，residual networks（resnet）等也被引入三维重建中。</p><p><strong>连续的隐空间</strong></p><p>一些网络如VAE（variational Autoencoders）或者他的变种，他们的隐空间均设计成连续的。该类型网络将数据映射到高斯分布的一个空间中。利用高斯分布生成一个连续的3D表达。</p><p><strong>层级隐空间（hierarchical latent spaces）</strong> </p><p>一些工作将输入映射到层级空间中，利用特征各个尺度维度的信息，能够很好的完成任务。</p><p><strong>解构的表示空间（disentangled representation）</strong></p><p>影响图像中物体的成像因素有很多，例如相机的位姿、光照条件等等。通过不同的网络的结构，来解析表示这些部分。</p><h4 id="体素解析（volumetric-decoding）"><a href="#体素解析（volumetric-decoding）" class="headerlink" title="体素解析（volumetric decoding）"></a>体素解析（volumetric decoding）</h4><p>体素网格用来表示离散空间中3D物体的3D形状。目标是重建3D体素网格使得它能够与真实的3D物体相近。这样做的一个优点是，很多2D的网络结构可以很轻易的转化成3D的结构。</p><p><strong>二次网格：</strong> 若当前的网格属于物体则为1，否则为0</p><p><strong>概率网格：</strong> 每一个像素表示一个该像素属于物体的概率</p><p><strong>SDF体素到物体表面的距离：</strong> 体素表示该位置到物体表面距离的数值，正数表示内部负数表示外部。</p><p><strong>截断距离：</strong>定义一个截断规则，将SDF距离进行截断。</p><p>上诉四种表示方式中概率网格的表示方式最适合深度学习系统。</p><h4 id="低分辨率的3D体素重建"><a href="#低分辨率的3D体素重建" class="headerlink" title="低分辨率的3D体素重建"></a>低分辨率的3D体素重建</h4><p>在得到隐空间中的特征表达之后，需要通过一个decoder结构，恢复出物体的三维结构。常用的结构为up-convolutional network，与encoder形成一个镜像映射。使用一些3D卷积结构，从一系列图片中得到物体的三维体素表达。</p><p>之后补上：由于对这个领域实在不熟悉，需要先看几篇论文熟悉一下，才能明白作者行文过程所做的分类的含义，以免现在一知半解浪费时间，耽误好文章。</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Stanford cs231A</title>
      <link href="/2019/09/19/Stanford-cs231A/"/>
      <url>/2019/09/19/Stanford-cs231A/</url>
      
        <content type="html"><![CDATA[<p>Stanford cs231A与cs231N是分别从传统方法和深度学习方法介绍计算机视觉的一些技术与应用。这本课程适合作为计算机视觉的入门课程，分别从目标的几何学和语义学上两个角度对图像进行分析。</p><a id="more"></a><h2 id="slide-10-Active-stereo-amp-Volumetric-stereo"><a href="#slide-10-Active-stereo-amp-Volumetric-stereo" class="headerlink" title="slide 10: Active stereo &amp; Volumetric stereo"></a>slide 10: Active stereo &amp; Volumetric stereo</h2><p> <img src="/images/3D/act.png" style="zoom:43%;"></p><p>使用一个光源发射器来代替相机，能够解决两张图片之间的关联问题。</p><p>通常可以使用激光，从上到下扫描这个物体的表面，可以获得一个非常精确的三维结构信息。</p><h3 id="traditional-stereo"><a href="#traditional-stereo" class="headerlink" title="traditional stereo"></a>traditional stereo</h3><p>传统的三维成像的方法：</p><p><img src="/images/3D/tra.png" style="zoom:33%;"></p><p><img src="/images/3D/tra1.png" style="zoom:33%;"></p><p><strong>volumetric stereo</strong></p><p><img src="/images/3D/vol.png" style="zoom:33%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture10_volumetric_stereo.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/26</p><h2 id="silde-9-Detectors-and-descriptors"><a href="#silde-9-Detectors-and-descriptors" class="headerlink" title="silde 9: Detectors and descriptors"></a>silde 9: Detectors and descriptors</h2><p><strong>Detectors:</strong></p><p><strong>边缘:</strong> 图片中深度不连续，表面朝向不连续，反射、光照不连续的位置。</p><p>可以使用传统的canny算法进行边缘的检测，通常图片可以进行平滑或求导处理。</p><p><strong>角点corner/blob光斑识别：</strong>角点通常较为突出，且具有重复性，局部性。可以使用harris角点检测算法来检测。</p><p>光斑可以使用拉普拉斯或高斯来检测：</p><p><img src="/images/3D/blob.png" style="zoom:33%;"></p><p>常用的检测器SIFT：</p><p><img src="/images/3D/sift.png" style="zoom:33%;"></p><p>HOG:</p><p><img src="/images/3D/hog.png" style="zoom:33%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture9_detector_descriptors.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/25</p><h2 id="slide-8-Fitting-and-Matching"><a href="#slide-8-Fitting-and-Matching" class="headerlink" title="slide 8: Fitting and Matching"></a>slide 8: Fitting and Matching</h2><p><strong>问题定义：</strong></p><p>特征点匹配问题存在着许多难以解决的问题：</p><ul><li>nosiy</li><li>outliers（外点）</li><li>missing data</li><li>intra-class variantion</li></ul><h4 id="拟合方法"><a href="#拟合方法" class="headerlink" title="拟合方法"></a>拟合方法</h4><p><strong>least square methods：</strong></p><p><img src="/images/3D/lse.png" style="zoom:33%;"></p><p>最小二乘法用来拟合数据，可以一定程度上对较小的噪声鲁棒，但是对于较大的噪声处理效果不好。</p><p><strong>RANSAC：</strong></p><p>通常样本中包含正确数据(inliers，可以被模型描述的数据)，也包含异常数据(outliers，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。</p><p>RANSAC为Random Sample Consensus的缩写，它是根据一组包含异常数据的样本数据集，计算出数据的数学模型参数，得到有效样本数据的算法。它于1981年由Fischler和Bolles最先提出 。</p><p>RANSAC算法的输入是一组观测数据（往往含有较大的噪声或无效点），一个用于解释观测数据的参数化模型以及一些可信的参数。RANSAC通过反复选择数据中的一组随机子集来达成目标。 被选取的子集被假设为局内点，并用下述方法进行验证：</p><ul><li>随机选择一组样本子集，并假设所选择的子集都为局内点</li><li>寻找一个模型适应于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。</li><li>用1中得到的模型去测试所有的其它数据，若某个点适用于估计的模型，认为它也是局内点inlier</li><li>如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。</li><li>用所有假设的局内点去重新估计模型（譬如使用最小二乘法）</li><li>最后，通过估计局内点与模型的错误率来评估模型。</li><li>上述过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为比现有的模型更好而被选用。</li></ul><p><strong>霍夫变换：</strong></p><p>霍夫变换(Hough Transform)是图像处理中的一种<strong>特征提取技术</strong>，它通过一种投票算法检测具有特定形状的物体。该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。</p><p>起初的方法要求知道物体边界线的解析方程，但不需要有关区域位置的先验知识。这种方法的一个突出优点是分割结果的Robustness , 对数据的不完全或噪声不是非常敏感。</p><p>例如使用霍夫变换来找出图像中的直线（某些特定的形状），将原图中的每个点所在直线的参数空间画出来。当在参数空间中重叠最大的那个参数证明是所有数据都经过该参数的直线，因此可以认为参数所表示的直线为图中的直线。</p><p><img src="/images/3D/hough.png" style="zoom:33%;"></p><p>图中每一个点都将对应到一条参数空间上的曲线，找到参数重叠最大的一个参数，即是大多数数据经过的直线的参数。</p><p>解释链接：<a href="https://zhuanlan.zhihu.com/p/47649796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47649796</a></p><p>使用hough算法变换之后，能够更好的进行图片之间的匹配。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture8_fitting_matching.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/25</p><h2 id="slide-7-Multi-view-geometry"><a href="#slide-7-Multi-view-geometry" class="headerlink" title="slide 7: Multi-view geometry"></a>slide 7: Multi-view geometry</h2><p><strong>问题描述：</strong></p><p>从m张照片中的n个点中，去估计、还原出m个仿射矩阵，以及n个3D的点。</p><p><img src="/images/3D/sfm1.png" style="zoom:37%;"></p><p>三维空间中的点和图像二维上的点存在一个仿射关系：</p><p><img src="/images/3D/fang.png" style="zoom:40%;"></p><p>将三维空间中的点，通过这种映射关系映射到二维平面上。</p><h4 id="factorization-method-因式分解方法"><a href="#factorization-method-因式分解方法" class="headerlink" title="factorization  method(因式分解方法)"></a>factorization  method(因式分解方法)</h4><p><strong>centering the data:</strong></p><p>提出去图像点之间的质心：<br>$$<br>\hat{\mathbf{x}}_{i j}=\mathbf{x}_{i j}-\frac{1}{n} \sum_{k=1}^{n} \mathbf{x}_{i k}<br>$$<br>将仿射变换代人上式，得到三维空间中的质心位置：</p><p><img src="/images/3D/sfm2.png" style="zoom:37%;"></p><p>经过数据的centering之后，每张图片的质心都将会映射到3D点云的质心上，将这个质心视为世界坐标系原点，进一步简化公式：</p><p><img src="/images/3D/sfm3.png" style="zoom:40%;"></p><p>构造一个m x n的矩阵，表示不同视点拍摄的n个点的位置信息，如下：</p><p><img src="/images/3D/sfm4.png" style="zoom:43%;"></p><p>对D矩阵进行SVD分解，选取前三大的奇异值构成一个新的矩阵（当rank=3时能够最小化F模使得其更加接近D矩阵）。</p><p><img src="/images/3D/sfm5.png" style="zoom:40%;"></p><p>利用MS恢复出三维像素点云信息。</p><p>该方法的确定是难以解决视觉上的歧义、结构的相似性问题。</p><h2 id="slide-6-Stereo-立体-Systems-Multi-view-geometry"><a href="#slide-6-Stereo-立体-Systems-Multi-view-geometry" class="headerlink" title="slide 6: Stereo(立体) Systems Multi-view geometry"></a>slide 6: Stereo(立体) Systems Multi-view geometry</h2><p>接上一章，使用多视角的几何方法需要找到两个图像之间的关联点，得出他们的焦点即物体实际的位置，即得到了物体的三维点云表达。</p><p>通常的做法是将图像内物体的位置调整成水平平行的方式，关键点匹配效果好。</p><p><img src="/images/3D/para.png" style="zoom:50%;"></p><p>当特征点在同一个水平位置时更容易计算深度：</p><p><img src="/images/3D/depth.png" style="zoom:40%;"></p><h4 id="method"><a href="#method" class="headerlink" title="method"></a>method</h4><p><strong>window base correlation: </strong></p><p><img src="/images/3D/win1.png" style="zoom:40%;"></p><p>上诉方法对图片光线不敏感，匹配效果不好，改进方案如下：</p><p><img src="/images/3D/win2.png" style="zoom:40%;"></p><p>匹配问题存在很多难点，常常导致匹配错误：</p><p><img src="/images/3D/win3.png" style="zoom:40%;"></p><p>使用下述方法可以提升精度：</p><p><img src="/images/3D/win4.png" style="zoom:40%;"></p><h3 id="SFM-structure-from-motion-problem"><a href="#SFM-structure-from-motion-problem" class="headerlink" title="SFM: structure from motion problem"></a>SFM: structure from motion problem</h3><p>SFM方法通过相机的移动来确定目标和几何关系，是三维重建的一种常见方法，使用RGB图像即可对图像进行恢复。</p><p><img src="/images/3D/sfm.png" style="zoom:40%;"></p><p>SFM算法流程：</p><ul><li>特征点提取(SIFT) 特征点匹配</li><li>基础矩阵估计F（5/8点法）</li><li>本质矩阵估计E</li><li>本质矩阵分解为R和T（SVD分解）</li><li>三维点云计算（三角形法）</li><li>重投影（将三维点云重新投影到平面的方法，用于计算误差）</li><li>重构的细化与优化</li></ul><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture6_stereo_systems.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/24</p><h2 id="slide-5-Epipolar-Geometry-对极几何"><a href="#slide-5-Epipolar-Geometry-对极几何" class="headerlink" title="slide 5: Epipolar Geometry (对极几何)"></a>slide 5: Epipolar Geometry (对极几何)</h2><p>  从单张图片中重建出物体的三维结构，存在着巨大的困难。需要对物体的位置，姿态进行定位，需要从场景中的线、无穷远点判断场景的结构以及相机内参K。此外还需要一些其他先验，例如点、平面等的对应关系。由于视点的空间感很弱，因此画面存在歧义，重建难度大。</p><p><img src="/images/3D/difficult.png" style="zoom:80%;"></p><h4 id="三角测量"><a href="#三角测量" class="headerlink" title="三角测量"></a>三角测量</h4><p>通过两个视点来观察整个场景：</p><p><img src="/images/3D/triangle.png" style="zoom:80%;"></p><p>使用上诉的三角测距方法，其中两个相机的内参K已知：</p><p><img src="/images/3D/minu.png" style="zoom:80%;"></p><p>通过找到两个图片的关联点，最小化距离。</p><h4 id="Multi-stereo-view-geometry-多视角几何"><a href="#Multi-stereo-view-geometry-多视角几何" class="headerlink" title="Multi(stereo)-view geometry (多视角几何)"></a>Multi(stereo)-view geometry (多视角几何)</h4><p><strong>camera geometry：</strong>找到两张图像中的对应点，找出相机的内参矩阵，位置，以及位姿。</p><p><strong>scene geometry：</strong> 从二维图像中恢复出三维场景的结果。</p><p><img src="/images/3D/example.png" style="zoom:80%;"></p><p><strong>给出A图片中的一个点，如何从另一张图片中找出其对应点？</strong></p><p>计算两张图像中，关联点的关联关系：</p><p><img src="/images/3D/epi1.png" style="zoom:70%;"></p><p>对于相机来说，我们通过调节相机参数使得两个视角的K均为单位矩阵简化函数的运算。</p><p><img src="/images/3D/epi2.png" style="zoom:80%;"></p><p>如上图，找到一个向量垂直于对极几何平面，得到上诉等式。</p><p>对上式进行变换：</p><p><img src="/images/3D/epi3.png" style="zoom:67%;"></p><p>进一步对上式进行分析，得到F变量：</p><p><img src="/images/3D/epi4.png" style="zoom:80%;"></p><p>已知F变量可以从一张图片中得到另一张图片的对应点,F变换包含了对极几何的两个视点以及相机内参的信息。此外F还反映了在视点下场景的变换关系：</p><p><img src="/images/3D/epi5.png" style="zoom:80%;"></p><h4 id="F变换的估计"><a href="#F变换的估计" class="headerlink" title="F变换的估计"></a>F变换的估计</h4><p>得到两张图片的F变换矩阵可以得到两张图像的关联点，于是有很多算法为估计F而提出：<strong>the eight-point algorithm</strong>八点法，通过选择图上的8个关联点，联立方程$P^{T}Fp’ = 0$,得到最终的结果。此外可以选择过完备的关联点对，联立方程通过SVD分解最小化误差的方式估计F。以及<strong>正则化八点法</strong>等等。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture5_epipolar_geometry.pdf" target="_blank" rel="noopener">silde</a></p><p>2019/9/23</p><h2 id="slide-4-Single-View-Metrology"><a href="#slide-4-Single-View-Metrology" class="headerlink" title="slide 4: Single View Metrology"></a>slide 4: Single View Metrology</h2><h4 id="2D环境下的变换"><a href="#2D环境下的变换" class="headerlink" title="2D环境下的变换"></a>2D环境下的变换</h4><p><strong>等距变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{ll}{\mathrm{R}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{e}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br>该变换对原始图片进行旋转和平移，不改变物体的相对位置和大小。</p><p><strong>相似变换：</strong><br>$$<br>\left[\begin{array}{l}{x^{\prime}} \ {y^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{S R} &amp; {t} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]=H_{s}\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]<br>$$<br>对原始物体进行旋转、平移、缩放等操作，改变了物体的大小。</p><p><strong>仿射变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{a}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br>该变换在一个方向上对图像进行拉伸。</p><p><strong>投影变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {\mathrm{V}} &amp; {\mathrm{b}}\end{array}\right]\left[\begin{array}{c}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{p}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br><strong>交叉比例：</strong></p><p><img src="/images/3D/ratio.png" style="zoom:40%;"></p><h4 id="灭点和线"><a href="#灭点和线" class="headerlink" title="灭点和线"></a>灭点和线</h4><p>平面中的直线方程可以用矩阵来表示，两条直线叉乘得到垂直于该平面的垂线。</p><p><img src="/images/3D/intersect.png" style="zoom:80%;"></p><p>对于两条平行线，在齐次空间中，他们存在一个焦点（灭点）。该灭点位于垂直于两条线的一个方向向量上。</p><p><img src="/images/3D/ideal.png" style="zoom:80%;"></p><p>空间中的点或线都会在一个无限远的平面上汇聚于一个灭点：</p><p><img src="/images/3D/point.png" style="zoom:80%;"></p><p>图像中两条线相交于一个灭点，直线与夹角间存在下面的计算关系：</p><p><img src="/images/3D/vanish.png" style="zoom:80%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture4_single_view_metrology.pdf" target="_blank" rel="noopener">silde</a></p><p>2019/9/23</p><h4 id="从单张图片中估计物体的几何结构"><a href="#从单张图片中估计物体的几何结构" class="headerlink" title="从单张图片中估计物体的几何结构"></a>从单张图片中估计物体的几何结构</h4><p> 根据上一页的ppt可以看出来，当夹脚为0的时候，K变量中有5个自由度，需要通过三个角度来计算相机的内参k：</p><p><img src="/images/3D/inside.png" style="zoom:80%;"></p><h4 id="extension"><a href="#extension" class="headerlink" title="extension"></a>extension</h4><p>计算出k之后，可以根据k去恢复相机坐标系中的场景朝向：</p><p><img src="/images/3D/recover.png" style="zoom:80%;"></p><p><img src="/images/3D/result.png" style="zoom:80%;"></p><h2 id="slide-3-camera-calibertion"><a href="#slide-3-camera-calibertion" class="headerlink" title="slide 3: camera calibertion"></a>slide 3: camera calibertion</h2><p>相机的标定是十分重要的一个步骤，从图片中预测出相机的位姿和焦距等。</p><p>下面是坐标映射方程：<br>$$<br>\mathrm{P}^{\prime}=\mathrm{M} \mathrm{P}_{\mathrm{w}}=\mathrm{K}[\mathrm{R} \quad \mathrm{T}] \mathrm{P}_{\mathrm{w}}<br>$$<br>相机标定的目的是从图像中估计出相机的内参和外参。</p><p><strong>相机标定的目标为：</strong>已知物体在实际环境中的坐标，物体在图像中的坐标，预测映射矩阵M。映射矩阵M由相机的外参，内参矩阵，共有11个未知量。因此需要11个方程，6个correspondences可以解决这个问题。实际场景中，我们可以加入更多的约束，使得结果更加的robots。<br>$$<br>p_{i}=\left[\begin{array}{c}{u_{i}} \ {v_{i}}\end{array}\right]=\left[\begin{array}{c}{\frac{\mathbf{m}_{1} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}} \ {\frac{\mathbf{m}_{2} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}}\end{array}\right]=M P_{i}<br>$$<br>常用标定板进行相机的标定，用相机各个角度多次拍摄同一块标定板，然后将图片以及标定板间距输入程序中，即可算出相机的内参K（焦距，物距，倾斜度等等）。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture3_camera_calibration.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/20</p><h2 id="slide-2-camera-models"><a href="#slide-2-camera-models" class="headerlink" title="slide 2: camera models"></a>slide 2: camera models</h2><p>这一课主要对相机的历史，成像原理进行介绍。</p><p>1452年leonardo发现了暗箱开始，一直到1822年第一张相片问世，1908年出现彩色的相机，直到现在相机的性能有了巨大的提升。</p><h4 id="小孔成像-pinhole-camera"><a href="#小孔成像-pinhole-camera" class="headerlink" title="小孔成像 pinhole camera"></a>小孔成像 pinhole camera</h4><p><img src="/images/3D/pinhole.png" style="zoom:80%;"></p><p>小孔成像原理如上，利用光线直线传播性质，通过相似三角形的比例关系得到成像的尺寸位置。成像的比例关系为物距和焦距的比例。</p><p><strong>小孔的大小越大成像越模糊，因为光线存在部分的重叠。当小孔变小之后光线之间分离，得到清晰的成效效果。</strong></p><p>使用凹透镜来实现光线的聚焦，在成像位置实现模糊和聚焦的区域。凹透镜同样使得相机拍摄的场景发生扭曲。</p><h4 id="坐标系统"><a href="#坐标系统" class="headerlink" title="坐标系统"></a>坐标系统</h4><p>将场景转换到坐标系统上，在视网膜上，设置一个坐标原点添加坐标偏移，其中k，l表示一个缩放单位，即焦距长度转换为焦距需要一个变换：</p><p><img src="/images/3D/converting.png" style="zoom:80%;"></p><p>三维到二维的转换如下：<br>$$<br>P=(x, y, z) \rightarrow P^{\prime}=\left(\alpha \frac{x}{z}+c_{x}, \beta \frac{y}{z}+c_{y}\right)<br>$$</p><h4 id="齐次坐标系（homogeneous-coordinates）"><a href="#齐次坐标系（homogeneous-coordinates）" class="headerlink" title="齐次坐标系（homogeneous coordinates）"></a>齐次坐标系（homogeneous coordinates）</h4><p>在传统的笛卡尔坐标系统中，两条平行线是永远不会相交的，但是在透视坐标系中，在无穷远处所有的平行线都会汇聚到一个点，这个点常常被称为灭点。</p><p>齐次坐标系常常用N+1个数字来表示N维坐标。用w表示与透视距离有关的系数，两个系统相互转换的关系如下：</p><p><img src="/images/3D/coordinate-transfer.png" style="zoom:80%;"></p><p>进一步提取出一个相机内部参数矩阵，完成这种转变。</p><p><img src="/images/3D/matrix.png" style="zoom:80%;"></p><p>相机位置发生偏移时，通过调节camera matrix可以得到精确的坐标位置：<br>$$<br>P^{\prime}=\left[\begin{array}{cccc}{\alpha} &amp; {-\alpha \cot \theta} &amp; {c_{x}} &amp; {0} \ {0} &amp; {\frac{\beta}{\sin \theta}} &amp; {c_{y}} &amp; {0} \ {0} &amp; {0} &amp; {1} &amp; {0}\end{array}\right]\left[\begin{array}{c}{x} \ {y} \ {z} \ {1}\end{array}\right]<br>$$<br>将一个眼前的物体拍摄到相机中，然后构建他的世界坐标系坐标，步骤如下：</p><ul><li>首先通过小孔成像的映射关系将实际物体的坐标映射到相机坐标中，需要提前获取的位置信息有物体的实际坐标，相机的内参即焦距、物距、倾斜角度。</li><li>得到物体的相机坐标之后将这个坐标转换到世界坐标系中，即进行旋转、平移变换。</li></ul><p><img src="/images/3D/world.png"></p><p><strong>图像坐标—投射变换—&gt;摄像机坐标—刚体变换—&gt; 世界坐标</strong></p><p>对于整个变换矩阵M，他还有着一些性质，可以直接判断相机是否有歪斜、单元横纵比等。</p><p><img src="/images/3D/theo.png"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture2_camera_models.pdf" target="_blank" rel="noopener">Slide</a></p><p>2019/9/20</p><h2 id="slide-1-introduction"><a href="#slide-1-introduction" class="headerlink" title="slide 1: introduction"></a>slide 1: introduction</h2><p>第一节课对计算机视觉两个关键技术进行一个的简要的回顾，这也是这门课之后的大纲内容。</p><h4 id="Geometry"><a href="#Geometry" class="headerlink" title="Geometry"></a>Geometry</h4><p>物体的几何学，需要从2D的图像中抽取出3D的信息，重点内容包含相机的标定，相机参数的估计（姿态和焦距）。单图片视角的重建，多图片视角的重建。对极几何等数学映射，结构光以及volumetric stereo（3D物体的体积估计）。</p><h4 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h4><p>语义分割对图像的理解，包括目标的分类、标定。这里头也面临很多困难，例如视角的不同，尺度的差异，关照的不同，形变，遮挡等等。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture1_intro.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/19</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>some tip about resume</title>
      <link href="/2019/09/18/some-tip-about-resume/"/>
      <url>/2019/09/18/some-tip-about-resume/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>linux 环境安装</title>
      <link href="/2019/09/06/linux-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2019/09/06/linux-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>linux 环境下的python3.6安装，以及Linux系统的一些设置。</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>今天进行了linux环境的配置，感觉十分的尽兴，安装过程十分的舒适，一些配置环节比较知道来龙去脉，配置起来很过隐。感触是对linux环境比较熟悉，对这一块的帮助是很大的，其次是也知道了其他人做法其中的道理。</p><h3 id="python3-6的安装"><a href="#python3-6的安装" class="headerlink" title="python3.6的安装"></a>python3.6的安装</h3><p>linux系统默认的python版本有两个，分别是python2.7和python3.5，这次想安装一个比较常用的python3.6。现实条件是我只是一个用户权限的使用者，因此很多sodu操作无法执行。下面基础部分我跳过，重点放在linux环境的配置上。</p><p>去官网下载python3.6.tgz安装包，然后安装的时候因为没有root权限（正常安装python3.6，安装文件会放在/usr/bin,/local/bin这些地方），我在目录下新建了一个python3.6目录用来存放安装文件。安装过程：<a href="https://my.oschina.net/moonrain/blog/739612，其中`./configure`" target="_blank" rel="noopener">https://my.oschina.net/moonrain/blog/739612，其中`./configure`</a> 修改为<code>./configure --prefix=./python36</code>。</p><p>因为默认的python的版本是2.7,这时候需要修改成python3.6，（其实比较明智的做法是用virtualenv创建一个以pyhton3.6版本的环境就可以了。）首先在<code>.bashrc</code>中添加python3.6中bin的路径：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=&apos;./python/bin:$PATH&apos;</span><br></pre></td></tr></table></figure><p>然后创建别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias python=./python3.6/bin/python3.6</span><br></pre></td></tr></table></figure><p>最后source ./bashrc修改完成。</p><p>然后还差一点，pip指向的是系统的python2.7，pip3指向的是python3.6，我尝试过修改别名，发现不起效果，最后发现原来系统配置的时候都会source 一下系统的bash，将pip修改为原来的。没办法着时候转向virtualenv。</p><h3 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h3><p>用了好久了virtualenv之后，现在才意识到这个环境包的好用之处，相比annaconda简洁多了，推荐指数max。安装过程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install virtualenv</span><br></pre></td></tr></table></figure><p>virtualenv中默认使用的python是当前python指向的python版本，当然也可以自己设置成自己指定python的版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv -p ./python3.6/bin/python3 zhou_env</span><br></pre></td></tr></table></figure><p>激活virtualenv：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source zhou_env/bin/activate</span><br></pre></td></tr></table></figure><p>下面就可以正常的在python3.6的环境中使用pip了，嗑盐了。</p><p>退出虚拟环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure><p>下面贴一个关于linux文件夹先后顺序的链接：</p><p><a href="https://perper.site/2019/04/24/linux配置环境/" target="_blank" rel="noopener">https://perper.site/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/</a></p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Image Super-Resolution Using Very Deep Residual Channel Attention Networks(RCAN)</title>
      <link href="/2019/09/05/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-RCAN/"/>
      <url>/2019/09/05/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-RCAN/</url>
      
        <content type="html"><![CDATA[<p>RCAN这篇文章是2018年发表在ECCV上的一篇poster，作者<a href="http://yulunzhang.com/" target="_blank" rel="noopener">Yunlun Zhang</a>也是该领域的一个大牛。在文中作者对比了各项性能指标，均达到了state of the art的效果。在目前超分辨率领域越做越细的前提下，以提升指标性能为目的的文章越来越不好发表了。下面介绍一下文章的思路、highlight希望能够有点启发。</p><p>arxiv： <a href="https://arxiv.org/pdf/1807.02758.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.02758.pdf</a></p><p>github：<a href="https://github.com/yulunzhang/RCAN" target="_blank" rel="noopener">https://github.com/yulunzhang/RCAN</a></p><a id="more"></a><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在超分辨率领域中，深度的卷积模型十分的重要，但是训练起来十分的困难；低频的输入或特征中有着很丰富的信息，但是这些信息在网络中被同等的对待，阻碍了卷积网络表达特征的能力。</p><p>为了解决上述问题，作者提出一个残差通道注意力网络（RCAN），通过提出<strong>RIR（residual in residual）</strong>模块来构建深度的网络，RIR中包含着许多的RG（residual group），RG中包含着许多的residual block，以及许多长连接跳跃（LSC）。RIR允许低频信息通过多个跳跃直接传播，使得网络集中学习图像中的高频部分。作者提出<strong>CA（channel attention）</strong> 通道注意力机制，通过考虑通道间的相互依赖性，来重新调整通道特征。</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>作者在这部分内容中列举了很多网络，目的是说明深度的网络在超分辨率问题上是有效果的。作者提出的RIR结构，提升网络的深度。对于低频信息的相互依赖性问题，作者提出了CA方法来调整通道的特征。</p><h3 id="Residual-Channel-Attention-Network（RCAN）"><a href="#Residual-Channel-Attention-Network（RCAN）" class="headerlink" title="Residual Channel Attention Network（RCAN）"></a>Residual Channel Attention Network（RCAN）</h3><p>RCAN的网络结构如下图所示：</p><p><img src="/images/SR/rcan-net.png" alt=""></p><p>RCAN网络结构由四部分组成，第一部分是卷积浅层特征提取模块，第二部分是RIR深层特征提取模块，第三部分是上采样模块，第四部分是重建模块，网络最后的卷积层具有三个通道，表示输出的颜色。 </p><p>RCAN网络损失函数采用L1损失：<br>$$<br>L(\Theta)=\frac{1}{N} \sum_{i=1}^{N}\left|H_{R C A N}\left(I_{L R}^{i}\right)-I_{H R}^{i}\right|_{1}<br>$$</p><h3 id="Residual-in-Residual-RIR"><a href="#Residual-in-Residual-RIR" class="headerlink" title="Residual in Residual (RIR)"></a>Residual in Residual (RIR)</h3><p>RIR结构中包含着若干个（10）residual groups（RG）结构以及long skip connection。每一个RG中包含着如果个（20）residual channel attention block（RCAB）模块，内部含有许多短的连接。</p><p>RIR结构通过堆叠残差块，利用skip connection这种结构来克服网络难以训练的问题。</p><h3 id="channel-attention（CA）"><a href="#channel-attention（CA）" class="headerlink" title="channel attention（CA）"></a>channel attention（CA）</h3><p><img src="/images/SR/ca.png" alt=""></p><p>输入是一个 H×W×C（64） 的特征，我们先进行一个空间的全局平均池化得到一个 1×1×C 的通道描述。接着，再经过一个下采样层和一个上采样层得到每一个通道的权重系数，将权重系数和原来的特征相乘即可得到缩放后的新特征，整个过程实际上就是对不同通道的特征重新进行了加权分配。</p><p>其中，下采样和上采样层都利用 1×1 的卷积来实现，下采样层的通道数减少 r 倍，激活函数为 Relu，上采样层的激活函数为 Sigmoid。在论文中，作者采用的通道数 C=64，r = 16。</p><h3 id="Residual-channel-attention-Block（RCAB）"><a href="#Residual-channel-attention-Block（RCAB）" class="headerlink" title="Residual channel attention Block（RCAB）"></a>Residual channel attention Block（RCAB）</h3><p><img src="/images/SR/rcab.png" alt=""></p><p>输入一个特征 input，我们首先进行一个卷积-Relu-卷积操作得到 f，然后 f 再经过一个 CA 模块进行重新缩放得到 x，最后将 x 和 input 相加得到输出特征。其中，卷积操作都采用 3×3 的卷积核。</p><h3 id="实现的细节"><a href="#实现的细节" class="headerlink" title="实现的细节"></a>实现的细节</h3><p>RIR中RG个数：10；RG中RCAB的个数：20，conv的大小：3 x 3，channel：64</p><p>通道下采样的scale：16，C/16 = 4。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超分辨率论文摘要阅读</title>
      <link href="/2019/09/03/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81%E9%98%85%E8%AF%BB/"/>
      <url>/2019/09/03/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>这篇博客的主要目的为了记录阅读的超分辨率论文的摘要部分，了解超分辨率领域的研究前沿进度。</p><a id="more"></a><h3 id="值得注意的网页"><a href="#值得注意的网页" class="headerlink" title="值得注意的网页"></a>值得注意的网页</h3><ol><li>github上关于超分辨率领域的SOAT论文的整理：<a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank" rel="noopener">https://github.com/YapengTian/Single-Image-Super-Resolution</a></li><li>知乎上关于超分辨率一些大牛的主页： <a href="https://www.zhihu.com/search?type=content&amp;q=超分辨率" target="_blank" rel="noopener">https://www.zhihu.com/search?type=content&amp;q=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87</a></li></ol><h3 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h3><h4 id="Xuaner-Zhang-Qifeng-Chen-Ren-Ng-and-Vladlen-Koltun-Zoom-to-Learn-Learn-to-Zoom-CVPR-2019-Paper"><a href="#Xuaner-Zhang-Qifeng-Chen-Ren-Ng-and-Vladlen-Koltun-Zoom-to-Learn-Learn-to-Zoom-CVPR-2019-Paper" class="headerlink" title="Xuaner Zhang, Qifeng Chen, Ren Ng, and Vladlen Koltun. Zoom to Learn, Learn to Zoom, CVPR 2019. [Paper]"></a>Xuaner Zhang, Qifeng Chen, Ren Ng, and Vladlen Koltun. Zoom to Learn, Learn to Zoom, CVPR 2019. <a href="http://vladlen.info/papers/zoom.pdf" target="_blank" rel="noopener">[Paper]</a></h4><p>作者将超分辨率方法应用在数字变焦中，他认为真实的图片能够比生成的图片更能保留数据的细节，网络的性能也将更好。那些在制作的数据集上训练的模型，通常在实际场景下性能不好，因此本文使用单反去直接制作数据集。高分辨率使用长焦距拍摄，低分辨率使用短焦距拍摄。</p><p>由于使用单反采集的数据高低配置无法完全对齐，因此作者提出了CoBi loss function，完美的解决了这个问题。这就是本文的主要insight。</p><h3 id="Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks"><a href="#Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks" class="headerlink" title="Image Super-Resolution Using Very Deep Residual Channel Attention Networks"></a>Image Super-Resolution Using Very Deep Residual Channel Attention Networks</h3>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 超分辨率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电阻率成像数据分析</title>
      <link href="/2019/08/30/%E7%94%B5%E9%98%BB%E7%8E%87%E6%88%90%E5%83%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2019/08/30/%E7%94%B5%E9%98%BB%E7%8E%87%E6%88%90%E5%83%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><strong>电阻率成像(ERI)</strong> 是一种地球物理技术，用于通过在表面或在一个或多个钻孔中的电极进行的电阻率测量来对底层亚表面结构进行成像。</p><a id="more"></a><h3 id="电阻率数据的采集"><a href="#电阻率数据的采集" class="headerlink" title="电阻率数据的采集"></a>电阻率数据的采集</h3><p>方位电阻率成像测井是在双侧向测井基础上发展起来的，在主电极或屏蔽电极中部沿圆周剖分成12个长方形小电极（见图），每个电极的定向方位成30°辐射，12个方位电极电位彼此相等。</p><p><img src="../images/SR/bettery.png" alt=""></p><p>电流的大小反映了该方向内地层电阻率的变化。测量每个方位电极的供电电流和环状监督电极M 3 （M 4 ）相对铠装电缆钢丝外皮的电位，可计算该方向地层的视电阻率。</p><p> 地层中不同的岩石（泥岩、砂岩、石灰岩）、流体其电阻率是不同的，通过测量<strong>井壁</strong> 各点的电阻率值，然后将电阻率值的相对高低用灰度或色度图表示出来。井壁可以表示成一张黑白/彩色图像。</p><p>颜色映射如下：</p><p><img src="../images/SR/color-map.png" width="400" align="middle"> </p><p> 得到的电阻率成像图像如下：</p><p><img src="../images/SR/162.jpg" alt="162"></p><h3 id="电阻率数据的分析"><a href="#电阻率数据的分析" class="headerlink" title="电阻率数据的分析"></a>电阻率数据的分析</h3><p>微电极测井使用的电极紧贴井壁，电阻数据是测井井周一圈的数据，因此同一个水平面上数据的空间位置十分的接近。数据在空间关系上有一定的相关性。</p><p><img src="../images/SR/fmi1.jpg" alt=""></p><p><img src="../images/SR/fmi.png" alt=""></p><p>上图中的绿线是地层的分层线。对电阻率的分析过程是将电阻率数据传入一个专业软件中，将会自动生成一些简单的分层线，然后采用人工标注的方式，对电阻率数据标注进行完善。最终得到完善的电阻率标注图。</p><p>对超分辨率问题来说，有什么内在的约束？</p><p>得到新数据时，需要明白测量的精度（2.5mm），井口的大小这些数据。</p><p>反演的概念：通过一些观察到的局部信息，反推相关过程发生的原因以及机制。根据结果或信息反推事件发生的过程称为反演，而对事件发生过程的预测则称为正演。例如根据地表上探测到的部分数据，来推测地表以下的地质结构。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并查集，python示例</title>
      <link href="/2019/08/27/%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%8Cpython%E7%A4%BA%E4%BE%8B/"/>
      <url>/2019/08/27/%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%8Cpython%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>并查集是一种数据结构，在合并不相交的集合，用来判断一个图中是否有环这种问题时，具有很高的性能。</p><a id="more"></a><h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><p>并查集的主要操作就是为一个集合中的元素找到一个代表（根节点）。并查集的基本操作是合并两个集合，当拿到两个节点，第一步需要找到各自节点的根，然后选择一个节点作为新的代表，那么就完成了两个集合的合并。</p><h3 id="并查集实现"><a href="#并查集实现" class="headerlink" title="并查集实现"></a>并查集实现</h3><p>并查集可以使用一个数组来表示，数组表示图上的节点，下标表示节点的编号，数组的值表示该下标的父节点是哪一个。例如A[0] = 1 表示节点0的父节点是节点1.</p><p>并查集的实现过程主要分为两步，一步是实现节点的根的查找，另一步是实现两个集合的合并，这里包含了节点的路径压缩。</p><p>下面实现find_root算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">joint = <span class="number">10</span></span><br><span class="line">parent = [<span class="number">-1</span>]*<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_root</span><span class="params">(parent,x)</span>:</span></span><br><span class="line">  x_root = x</span><br><span class="line">  <span class="keyword">while</span> parent[x_root] != <span class="number">-1</span>:</span><br><span class="line">    x_root = parent[x_root]</span><br><span class="line">  <span class="keyword">return</span> x_root</span><br></pre></td></tr></table></figure><p>上面代码说明当x不是根节点时，循环继续往上找，当x时根节点时则返回。</p><p>下面是union的算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union_joint</span><span class="params">(parent,x,y)</span>:</span></span><br><span class="line">  x = find_root(parent,x)</span><br><span class="line">  y = find_root(parent,y)</span><br><span class="line">  <span class="keyword">if</span> x == y:</span><br><span class="line">    print(<span class="string">'circle'</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    parent[x] = y</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>上诉代码如果返回的结果是0的话则说明存在一个环，否则不存在环。</p><p>存在一种极端的情况，即每次union合成的集合它形成了一个很长的链，每次寻找一个节点的根需要遍历一下整个节点，复杂度太高，下面在union中引入路径压缩的思想，即引入另一个数组rank，表明当前节点的位置，当进行union的时候，rank小的数连接到rank大的树底下，当两个rank相同的时候，可以随意连接，但是连接之后作为父节点的rank需要加1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rank = [<span class="number">0</span>]*joint</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(parent,x,y,rank)</span>:</span></span><br><span class="line">  x = find_root(parent,x)</span><br><span class="line">  y = find_root(parent,y)</span><br><span class="line">  <span class="keyword">if</span> x == y:</span><br><span class="line">    print(<span class="string">'circle'</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> rank[x] &gt; rank[y]:</span><br><span class="line">      parent[y] = x</span><br><span class="line">    <span class="keyword">elif</span> rank[x] &lt; rank[y]:</span><br><span class="line">      parent[x] = y</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      parent[x] = y</span><br><span class="line">      rank[y] += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>在判断一个图是否存在环的时候，依次遍历图的所有边，如果union返回的结果是0的话，表明有环。</p><p>下面是一道lettcode的题目，思路就是用并查集来求解：</p><p><a href="https://leetcode.com/problems/friend-circles/" target="_blank" rel="noopener">547.Friend Circles</a></p><p>思路是将朋友的关系用边来表示，最后看parent数组中有多少根节点（等于-1）。</p><p>解法代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findCircleNum</span><span class="params">(self, M)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type M: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        edge = []</span><br><span class="line">        <span class="keyword">if</span> M == [] <span class="keyword">or</span> M[<span class="number">0</span>] == []:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(M)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(M[<span class="number">0</span>])):</span><br><span class="line">                <span class="keyword">if</span> i &lt;= j:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span> M[i][j] == <span class="number">1</span>:</span><br><span class="line">                    edge.append([i,j])</span><br><span class="line">                </span><br><span class="line">        parent = [<span class="number">-1</span>]*len(M)</span><br><span class="line">        rank = [<span class="number">0</span>]*len(M)</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_root</span><span class="params">(parent,x)</span>:</span></span><br><span class="line">            x_root = x</span><br><span class="line">            <span class="keyword">while</span> parent[x_root] != <span class="number">-1</span>:</span><br><span class="line">                x_root = parent[x_root]</span><br><span class="line">            <span class="keyword">return</span> x_root</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">union_joint</span><span class="params">(parent,x,y,rank)</span>:</span></span><br><span class="line">            x = find_root(parent,x)</span><br><span class="line">            y = find_root(parent,y)</span><br><span class="line">            <span class="keyword">if</span> x  != y:</span><br><span class="line">                <span class="keyword">if</span> rank[x] &lt; rank[y]:</span><br><span class="line">                    parent[x] = y</span><br><span class="line">                <span class="keyword">elif</span> rank[x] &gt; rank[y]:</span><br><span class="line">                    parent[y] = x</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    parent[x] = y</span><br><span class="line">                    rank[y] += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> edge:</span><br><span class="line">            union_joint(parent,e[<span class="number">0</span>],e[<span class="number">1</span>],rank)</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> parent:</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">-1</span>:</span><br><span class="line">                ans += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>哈希表，python示例</title>
      <link href="/2019/08/25/%E5%93%88%E5%B8%8C%E8%A1%A8-python%E7%A4%BA%E4%BE%8B/"/>
      <url>/2019/08/25/%E5%93%88%E5%B8%8C%E8%A1%A8-python%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>哈希表一直都是一个很重要的数据结构，从上大学开始，一直有听闻，面试题也有相当的涉及，接下来继续扫盲。</p><a id="more"></a><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p>哈希表根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把<strong>关键码值通过哈希函数映射到表中一个位置来访问记录</strong>，以加快查找的速度。</p><p>哈希表的工作原理如下</p><p><img src="/images/hash.png" alt=""></p><p>首先拿到key值，通过哈希函数将key值转化为数组的下标，在插入元素之前，判断该下标位置上是否已经存在元素，若已经存在元素则称为collision（碰撞）。</p><p>当元素发生碰撞时，存在很多方法来处理这种碰撞，常用的方法有<strong>链接法</strong>（java hashmap的实现），每一个index位置连一个链表，用来存储发生碰撞的元素。</p><p><img src="/images/link.png" alt=""></p><p><strong>另一种解决碰撞的方法为开放寻址法</strong>（python中dict的实现）。</p><p>开放寻址法指当前位置发生了碰撞，采用某种方法（线性，二次，双倍散列）对哈希表中其他位置进行访问。如果哈希表全都装满了则需要对哈希表进行扩容。</p><p><img src="/images/openadress.png" alt=""></p><h3 id="python-中dict常用方法"><a href="#python-中dict常用方法" class="headerlink" title="python 中dict常用方法"></a>python 中dict常用方法</h3><p>遍历操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dicts:</span><br><span class="line">    print(i)</span><br><span class="line">    print(dicts[i])</span><br></pre></td></tr></table></figure><p>删除操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dicts.pop(key)</span><br><span class="line">dicts.popitem() <span class="comment">#删除最后一个加入的元素</span></span><br><span class="line"><span class="keyword">del</span> dicts <span class="comment">#直接删除元素</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆排序，python实现</title>
      <link href="/2019/08/22/%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%8Cpython%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/08/22/%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%8Cpython%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>堆排序这个名称一直困扰着我，现在扫一下盲。</p><a id="more"></a><h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>首先介绍一下堆的概念：堆是一棵完全二叉树，即指允许最后一层的叶子是不满的，其他层都是满的。叶子节点的出现顺序也是从左边开始向右边累加，不允许中断。父结点必须比子节点要大。</p><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p>堆排序的算法复杂度是O(nlog(n))。由于节点满足完全二叉树，因此可以通过下标的关系找到父节点，子节点。</p><p>例如当前节点为i，父节点：(i - 1) /2。左孩子：2i+1,右孩子：2i+2。因此堆排序的策略如下：</p><h3 id="堆排序步骤"><a href="#堆排序步骤" class="headerlink" title="堆排序步骤"></a>堆排序步骤</h3><ol><li>构造堆结构，从最后一个元素（叶子）的父节点开始，循环到根节点，每次执行heapify函数（三个节点，找最大的放到根位置）。</li><li>位于根节点的元素是最大的，每次将根节点的数拿出来，作为排序的最后一个值。然后将最后一个叶节点放到根的位置。依次循环下去，直到结束。</li></ol><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">9</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span><span class="params">(nums,n,i)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    i 表示要进行调换的根节点位置</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    c1 = <span class="number">2</span>*i + <span class="number">1</span></span><br><span class="line">    c2 = <span class="number">2</span>*i + <span class="number">2</span></span><br><span class="line">    max_index = i</span><br><span class="line">    <span class="keyword">if</span> c1 &lt;= n <span class="keyword">and</span> nums[c1] &gt; nums[i]:</span><br><span class="line">        max_index = c1</span><br><span class="line">    <span class="keyword">if</span> c2 &lt;= n <span class="keyword">and</span> nums[c2] &gt; nums[max_index]:</span><br><span class="line">        max_index = c2</span><br><span class="line">    <span class="keyword">if</span> max_index != i:</span><br><span class="line">        nums[max_index],nums[i] = nums[i],nums[max_index]</span><br><span class="line">        heapify(nums,n,max_index)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_heap</span><span class="params">(nums)</span>:</span></span><br><span class="line">    n = len(nums) - <span class="number">1</span></span><br><span class="line">    last_index = (n - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(last_index+<span class="number">1</span>)[::<span class="number">-1</span>]:</span><br><span class="line">        heapify(nums,n,i)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    print(nums)</span><br><span class="line">    build_heap(nums)</span><br><span class="line">    print(nums)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums))[::<span class="number">-1</span>]:</span><br><span class="line">        print(i)</span><br><span class="line">        nums[<span class="number">0</span>],nums[i] = nums[i],nums[<span class="number">0</span>]</span><br><span class="line">        heapify(nums,i<span class="number">-1</span>,<span class="number">0</span>)</span><br><span class="line">    print(nums)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">heap_sort(nums)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习代码的框架</title>
      <link href="/2019/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%A1%86%E6%9E%B6/"/>
      <url>/2019/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>以pytorch为例，梳理一下深度学习中，数据的读取，神经网络的搭建，NMS，以及各个指标的计算流程。</p><a id="more"></a><h3 id="main-函数，程序入口，以及代码配置"><a href="#main-函数，程序入口，以及代码配置" class="headerlink" title="main 函数，程序入口，以及代码配置"></a>main 函数，程序入口，以及代码配置</h3><p>通常main函数中，通过实现argparse功能包，从函数的外部接受参数的传入，对数据，网络等进行一些基本的配置。argparse的使用方法：<a href="https://docs.python.org/zh-cn/3/library/argparse.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/argparse.html</a></p><p>main函数中一些常用的配置项：</p><ul><li>数据集的格式：coco，csv，pascal voc等等</li><li>数据的路径，包括训练集，测试集的路径等等</li><li>网络的一些细节配置，如深度，backbone 类型</li><li>一些功能的开关设置，如数据的增强等</li><li>训练过程中，一些变量的设置，比如epoch的设置，batch_size的设置等等</li></ul><h3 id="数据读取部分"><a href="#数据读取部分" class="headerlink" title="数据读取部分"></a>数据读取部分</h3><p>数据读取部分的操作包括数据集文件的读取，对图片进行数据的增强，继承dataloader实现数据的批量读取。</p><h4 id="数据文件的读取"><a href="#数据文件的读取" class="headerlink" title="数据文件的读取"></a>数据文件的读取</h4><p>这部分读取任务主要包括读取annotation文件，以及class_id文件，这里以csv格式的数据集文件为例。</p><p>首先实现一个CSVDataset类，继承至torch.utils.data.Dataset类。该类必须实现<code>__len__</code>,<code>__getitem__</code>两个方法。</p><p>在CSVDataset方法的<code>__init__</code>中，进行数据集文件的读取，最终将得到：</p><ul><li>self.classes</li><li>self.image_names : list 包含所有的数据集图片路径</li><li>self.image_data: dict[image_name] = [ {x1,y1,x2,y2,class_name},…]</li></ul><p><code>__getitem__</code>函数中需要实现的方法有根据下标来得到image，以及其对应的标注。最终返回的格式为：</p><p><code>sample = {&#39;img&#39;: img, &#39;annot&#39;: annot}</code>。在返回之前，如果有数据增强部分，还需要进行数据的增强。</p><h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>数据增强的方法有很多种，常用的图片的翻转，切割，resize，归一化等等。数据增强利用一张图片，得到它的许多副本，有效的增大数据集。数据增强能够起效果的一个本质因素在于，卷积操作对位移，视角，图片大小，光照等因素具有不变性。数据增强有线下增强和线上增强两种方式，后一种方式在dataloader提取数据的时候，才对数据进行增强。</p><p>数据增强的方法通常可以写成一个类，通过pytorch中的<code>transforms.Compose([Augumenter(),Resizer()])</code> 来对所有的增强方法进行整合。</p><p><strong>Normalizer</strong></p><p>实现一个Normalizer类，覆盖其中的<code>__call__</code>方法，对每张图片做一个正则化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Normalizer</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.mean = np.array([[[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]]])</span><br><span class="line">        self.std = np.array([[[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]]])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, sample)</span>:</span></span><br><span class="line"></span><br><span class="line">        image, annots = sample[<span class="string">'img'</span>], sample[<span class="string">'annot'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'img'</span>:((image.astype(np.float32)-self.mean)/self.std), <span class="string">'annot'</span>: annots&#125;</span><br></pre></td></tr></table></figure><p><strong>argument</strong></p><p>实现对图片的翻转，需要注意对标注也要进行处理。</p><p><strong>Resizer</strong></p><p>该方法意图将图片的大小限制在一定范围以内。因此在缩放的时候，需要找到最大的缩放比例,同时保证图片能够被32整除。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Convert ndarrays in sample to Tensors."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, sample, min_side=<span class="number">608</span>, max_side=<span class="number">1024</span>)</span>:</span> <span class="comment">#将图片resize到608，1024以下的大小</span></span><br><span class="line">        image, annots = sample[<span class="string">'img'</span>], sample[<span class="string">'annot'</span>]       <span class="comment"># 不能超过这个尺寸（有一边等于这个尺寸）</span></span><br><span class="line"></span><br><span class="line">        rows, cols, cns = image.shape</span><br><span class="line"></span><br><span class="line">        smallest_side = min(rows, cols)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rescale the image so the smallest side is min_side</span></span><br><span class="line">        scale = min_side / smallest_side</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check if the largest side is now greater than max_side, which can happen</span></span><br><span class="line">        <span class="comment"># when images have a large aspect ratio</span></span><br><span class="line">        largest_side = max(rows, cols)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> largest_side * scale &gt; max_side:</span><br><span class="line">            scale = max_side / largest_side</span><br><span class="line"></span><br><span class="line">        <span class="comment"># resize the image with the computed scale</span></span><br><span class="line">        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))</span><br><span class="line">        rows, cols, cns = image.shape</span><br><span class="line"></span><br><span class="line">        pad_w = <span class="number">32</span> - rows%<span class="number">32</span></span><br><span class="line">        pad_h = <span class="number">32</span> - cols%<span class="number">32</span></span><br><span class="line"></span><br><span class="line">        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)</span><br><span class="line">        new_image[:rows, :cols, :] = image.astype(np.float32) <span class="comment"># 两个边长需要保证被32整除，少掉的的那部分使用0来补全</span></span><br><span class="line"></span><br><span class="line">        annots[:, :<span class="number">4</span>] *= scale</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'img'</span>: torch.from_numpy(new_image), <span class="string">'annot'</span>: torch.from_numpy(annots), <span class="string">'scale'</span>: scale&#125;</span><br></pre></td></tr></table></figure><h3 id="数据调用-dataloader"><a href="#数据调用-dataloader" class="headerlink" title="数据调用 dataloader"></a>数据调用 dataloader</h3><p>pytorch通过实现dataloader方法来实现网络训练时，每次iteration的数据的输出。dataloader的逻辑是，每次从dataset中调用<code>__getitem__()</code>获取单个数据，然后组合成batch，在使用<code>collate_fn</code>参数对batch进行一些操作。</p><p><code>torch.utils.data.Dataloader</code><strong>中的参数</strong>：</p><blockquote><p><strong>dataset</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset" target="_blank" rel="noopener"><em>Dataset</em></a>) – dataset from which to load the data.</p><p><strong>batch_size</strong>(<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>, <em>optional</em>) – how many samples per batch to load (default: 1).</p><p><strong>shuffle</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – set to <code>True</code>to have the data reshuffled at every epoch (default: False).</p><p><strong>sampler</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler" target="_blank" rel="noopener"><em>Sampler</em></a>, <em>optional</em>) – defines the strategy to draw samples from the dataset. If specified, <code>shuffle</code>must be False.</p><p><strong>batch_sampler</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler" target="_blank" rel="noopener"><em>Sampler</em></a>, <em>optional</em>) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.</p><p><strong>num_workers</strong>(<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>, <em>optional</em>) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)</p><p><strong>collate_fn</strong>(<em>callable<strong>, </strong>optional</em>) – merges a list of samples to form a mini-batch.</p><p><strong>pin_memory</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – If <code>True</code>, the data loader will copy tensors into CUDA pinned memory before returning them.</p><p><strong>drop_last</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – set to <code>True</code>to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If <code>False</code>and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)</p><p><strong>timeout</strong>(<em>numeric</em>, <em>optional</em>) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)</p><p><strong>worker_init_fn</strong>(<em>callable</em>, <em>optional</em>) – If not None, this will be called on each worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as input, after seeding and before data loading. (default: None)</p></blockquote><p>算法中使用如下参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)</span><br></pre></td></tr></table></figure><p>其中<code>dataset_train</code>为<code>Dataset</code>类的对象，如上实现数据问价读取的部分。<code>num_workers</code>设置了这个类的线程数。<code>batch_sampler</code> 设置了每次从数据集中返回一个batch的sample的策略。<code>collate_fn</code> 将一系列的样本融合成一个小的mini-batch。</p><p><strong>首先是batch_sampler:</strong></p><p>继承至采样器类，需要实现其中的<code>__len__</code>方法，<code>__iter__</code>方法。该参数的作用是将数据集做成许多group组成的一个list。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AspectRatioBasedSampler</span><span class="params">(Sampler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_source, batch_size, drop_last)</span>:</span></span><br><span class="line">        self.data_source = data_source</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">        self.groups = self.group_images()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        random.shuffle(self.groups)</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> self.groups:</span><br><span class="line">            <span class="keyword">yield</span> group</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            <span class="keyword">return</span> len(self.data_source) // self.batch_size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (len(self.data_source) + self.batch_size - <span class="number">1</span>) // self.batch_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">group_images</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># determine the order of the images</span></span><br><span class="line">        order = list(range(len(self.data_source)))</span><br><span class="line">        order.sort(key=<span class="keyword">lambda</span> x: self.data_source.image_aspect_ratio(x))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># divide into groups, one group = one batch</span></span><br><span class="line">        <span class="keyword">return</span> [[order[x % len(order)] <span class="keyword">for</span> x <span class="keyword">in</span> range(i, i + self.batch_size)] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(order), self.batch_size)]</span><br></pre></td></tr></table></figure><p>如上，这个方法将数据分别存入group中，然后组成一个groups的list。通过一个<code>__iter__()</code>方法，迭代的方式将数据输出。每次输出一个batch大小的数据。</p><p><strong>collate_fn参数：</strong></p><p>该参数接受来自batch_sampler的数据，对数据进行进一步的处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collater</span><span class="params">(data)</span>:</span></span><br><span class="line">    imgs = [s[<span class="string">'img'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    annots = [s[<span class="string">'annot'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    scales = [s[<span class="string">'scale'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]     </span><br><span class="line">    widths = [int(s.shape[<span class="number">0</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    heights = [int(s.shape[<span class="number">1</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    batch_size = len(imgs)</span><br><span class="line">    max_width = np.array(widths).max()</span><br><span class="line">    max_height = np.array(heights).max()</span><br><span class="line">    padded_imgs = torch.zeros(batch_size, max_width, max_height, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">        img = imgs[i]</span><br><span class="line">        padded_imgs[i, :int(img.shape[<span class="number">0</span>]), :int(img.shape[<span class="number">1</span>]), :] = img</span><br><span class="line">    max_num_annots = max(annot.shape[<span class="number">0</span>] <span class="keyword">for</span> annot <span class="keyword">in</span> annots)</span><br><span class="line">    <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line">        annot_padded = torch.ones((len(annots), max_num_annots, <span class="number">5</span>)) * <span class="number">-1</span></span><br><span class="line">        <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> idx, annot <span class="keyword">in</span> enumerate(annots):</span><br><span class="line">                <span class="comment">#print(annot.shape)</span></span><br><span class="line">                <span class="keyword">if</span> annot.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                    annot_padded[idx, :annot.shape[<span class="number">0</span>], :] = annot</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        annot_padded = torch.ones((len(annots), <span class="number">1</span>, <span class="number">5</span>)) * <span class="number">-1</span></span><br><span class="line">    padded_imgs = padded_imgs.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'img'</span>: padded_imgs, <span class="string">'annot'</span>: annot_padded, <span class="string">'scale'</span>: scales&#125;</span><br></pre></td></tr></table></figure><p>上面的操作，将同一个batch中的图片的大小统一同样的大小。annotation的维度也统一到同样大小的维度。然后进行RGB通道的变换之后，放回一个dict。</p><p>上面这些步骤就完成了数据的loader，通过for循环从其中取得元素。</p><h3 id="retinanet网络结构"><a href="#retinanet网络结构" class="headerlink" title="retinanet网络结构"></a>retinanet网络结构</h3><p>下面从数据流动的角度分析一下retinanet的各个结构的组成。</p><p>retinanet的特征提取部分，使用的是resnet，resnet有多种深度的选择，分别有18，34，50，101，152五种深度。常用的网络深度为50，101:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span><span class="params">(num_classes, pretrained=False, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(num_classes, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet50'</span>], model_dir=<span class="string">'.'</span>), strict=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>让我们一行一行来看，第一个调用了ResNet()类，创建了一个ResNet对象。ResNet继承至<code>nn.Module</code>,需要实现函数<code>__init__</code>以及<code>forward()</code>两个方法，通常将可学习的参数放到构造函数<code>__init__()</code>中，在<code>forward</code>中实现网络数据的流动，即可实现网络的自动求导机制。</p><p><strong>ResNet</strong></p><p>resnet首次提出残差的思想，传统的卷积网络或者全连接网络在信息传递的时候或多或少会存在信息丢失，损耗等问题，同时还有导致梯度消失或者梯度爆炸，导致很深的网络无法训练。ResNet通过学习残差的方式，在一定程度上解决了<strong>网络退化和梯度消失</strong>的问题。ResNet通过大量叠加残差块的方式，加深网络的深度的同时，保证了网络的梯度不消失。ResNet有着两种不同的残差单元。分别是basicBlock 和 bottleneck结构。深层次网络使用bottleneck结构，每次经过残差结构之前都对数据进行一次降维，大大降低了网络的参数量。</p><p><img src="/images/res_unit.png" alt=""></p><p>bottleneck的结构feature经过第一个1x1的卷积层，将特征的维度压缩，对压缩后的特征进行3x3的卷积，然后经过1x1卷积层，将特征的维度放大到原来的大小。</p><p>bottleneck的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None)</span>:</span></span><br><span class="line">        super(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                               padding=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv3 = nn.Conv2d(planes, planes * <span class="number">4</span>, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(planes * <span class="number">4</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        </span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        </span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>pytorch中常用的搭建网络的函数如下：</p><p>Conv2d卷积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">参数：</span><br><span class="line">in_channels(int) – 输入信号的通道</span><br><span class="line">out_channels(int) – 卷积产生的通道</span><br><span class="line">kerner_size(int <span class="keyword">or</span> tuple) - 卷积核的尺寸</span><br><span class="line">stride(int <span class="keyword">or</span> tuple, optional) - 卷积步长</span><br><span class="line">padding(int <span class="keyword">or</span> tuple, optional) - 输入的每一条边补充<span class="number">0</span>的层数</span><br><span class="line">dilation(int <span class="keyword">or</span> tuple, optional) – 卷积核元素之间的间距</span><br><span class="line">groups(int, optional) – 从输入通道到输出通道的阻塞连接数</span><br><span class="line">bias(bool, optional) - 如果bias=<span class="keyword">True</span>，添加偏置</span><br><span class="line">输入：</span><br><span class="line">input: (N,C_in,H_in,W_in) </span><br><span class="line">输出：</span><br><span class="line">output: (N,C_out,H_out,W_out)</span><br><span class="line">计算公式：Fout = (Fin + <span class="number">2</span>*padding-kernel)/stride + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>batchNorm2d：</p><p>在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。</p><p>在验证时，训练求得的均值/方差将用于标准化验证数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">BatchNorm2d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>)</span><br><span class="line">参数：</span><br><span class="line">num_features： 来自期望输入的特征数，该期望输入的大小为<span class="string">'batch_size x num_features x height x width'</span></span><br><span class="line">eps： 为保证数值稳定性（分母不能趋近或取<span class="number">0</span>）,给分母加上的值。默认为<span class="number">1e-5</span>。</span><br><span class="line">momentum： 动态均值和动态方差所使用的动量。默认为<span class="number">0.1</span>。</span><br><span class="line">affine： 一个布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br><span class="line">输入：（N, C，H, W) - 输出：（N, C, H, W）</span><br><span class="line">值得至于的是，参数num_feature写channel数即可。</span><br></pre></td></tr></table></figure><p>ReLU：修正线性单元函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.ReLU(inplace=<span class="keyword">False</span>)</span><br><span class="line">参数：</span><br><span class="line">inplace：表示是否进行覆盖计算，节省内存</span><br><span class="line">不会引起数据维度的变化</span><br></pre></td></tr></table></figure><p>MaxPool2d 层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size, stride=<span class="keyword">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, return_indices=<span class="keyword">False</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">参数：</span><br><span class="line">kernel_size(int <span class="keyword">or</span> tuple) - max pooling的窗口大小</span><br><span class="line">stride(int <span class="keyword">or</span> tuple, optional) - max pooling的窗口移动的步长。默认值是kernel_size</span><br><span class="line">padding(int <span class="keyword">or</span> tuple, optional) - 输入的每一条边补充<span class="number">0</span>的层数</span><br><span class="line">dilation(int <span class="keyword">or</span> tuple, optional) – 一个控制窗口中元素步幅的参数</span><br><span class="line">return_indices - 如果等于<span class="keyword">True</span>，会返回输出最大值的序号，对于上采样操作会有帮助</span><br><span class="line">ceil_mode - 如果等于<span class="keyword">True</span>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作</span><br><span class="line">输入: (N,C,H_&#123;<span class="keyword">in</span>&#125;,W_in) </span><br><span class="line">输出: (N,C,H_out,W_out)</span><br><span class="line">计算公式：Fout = (Fin + <span class="number">2</span>*padding - kernel)/stride + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>nn.Upsample 上采样操作对channel进行采样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nn.Upsample(size=<span class="keyword">None</span>, scale_factor=<span class="keyword">None</span>, mode=<span class="string">'nearest'</span>, align_corners=<span class="keyword">None</span>)</span><br><span class="line">给定上采样策略mode，上采样的大小：scale_factor</span><br></pre></td></tr></table></figure><p>nn.Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.inplanes, planes * block.expansion,</span><br><span class="line">                          kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="keyword">False</span>),</span><br><span class="line">                nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">            )</span><br></pre></td></tr></table></figure><p><strong>网络结构类继承至<code>nn.Module</code>,需要实现函数<code>__init__</code>以及<code>forward()</code>两个方法，通常在<strong>init</strong>中完成网络层的初始化工作，定义各类的网络层。在forward中完成网络层数据的流动。</strong></p><p>retinanet金字塔模型的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidFeatures</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, C3_size, C4_size, C5_size, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(PyramidFeatures, self).__init__()</span><br><span class="line">        <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">        self.P5_1           = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P5_upsampled   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.P5_2           = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">        self.P4_1           = nn.Conv2d(C4_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P4_upsampled   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.P4_2           = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># "P6 is obtained via a 3x3 stride-2 conv on C5"</span></span><br><span class="line">        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6"</span></span><br><span class="line">        self.P7_1 = nn.ReLU()</span><br><span class="line">        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line"></span><br><span class="line">        C3, C4, C5 = inputs</span><br><span class="line"></span><br><span class="line">        P5_x = self.P5_1(C5)</span><br><span class="line">        P5_upsampled_x = self.P5_upsampled(P5_x)</span><br><span class="line">        P5_x = self.P5_2(P5_x)</span><br><span class="line">        </span><br><span class="line">        P4_x = self.P4_1(C4)</span><br><span class="line">        P4_x = P5_upsampled_x + P4_x</span><br><span class="line">        P4_upsampled_x = self.P4_upsampled(P4_x)</span><br><span class="line">        P4_x = self.P4_2(P4_x)</span><br><span class="line"></span><br><span class="line">        P3_x = self.P3_1(C3)</span><br><span class="line">        P3_x = P3_x + P4_upsampled_x</span><br><span class="line">        P3_x = self.P3_2(P3_x)</span><br><span class="line"></span><br><span class="line">        P6_x = self.P6(C5)</span><br><span class="line"></span><br><span class="line">        P7_x = self.P7_1(P6_x)</span><br><span class="line">        P7_x = self.P7_2(P7_x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [P3_x, P4_x, P5_x, P6_x, P7_x]</span><br></pre></td></tr></table></figure><p>retinanet在金字塔之后，接了一个回归网络以及分类网络，分别对边框位置以及类别进行分类。</p><p><strong>回归网络</strong>简单的接了五个卷积层，保持feature的大小不变，每一个channel的维度最终降为num_anchors x 4，即每一个channel需要回归出num_anchors x 4 个坐标点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RegressionModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_features_in, num_anchors=<span class="number">9</span>, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(RegressionModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors*<span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = 4*num_anchors</span></span><br><span class="line">        out = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out.contiguous().view(out.shape[<span class="number">0</span>], <span class="number">-1</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>上诉最后一行值得注意一下view()函数相当于numpy中的reshape函数，但是要求数据必须在内存中是连续存储的。由于permute函数，改变了数据的分布（浅拷贝）。因此在使用view之前，需要执行contiguous函数使得数据内存连续分布。最终out的shape为[batch_size，w x h ，4]。上诉得到的out最终输入criterion中，计算loss。</p><p><strong>分类模型</strong>的网络结构和回归模型的结构相同，唯一不同的地方在于最终输出的channel的大小。分类模型输出的channel大小为anchor的数量乘以类别（num_anchor x num_classes）。即每一个框都要预测一个类别信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassificationModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_features_in, num_anchors=<span class="number">9</span>, num_classes=<span class="number">80</span>, prior=<span class="number">0.01</span>, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(ClassificationModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_anchors = num_anchors</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors*num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.output_act = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line">        out = self.output_act(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = n_classes + n_anchors</span></span><br><span class="line">        out1 = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        batch_size, width, height, channels = out1.shape</span><br><span class="line"></span><br><span class="line">        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out2.contiguous().view(x.shape[<span class="number">0</span>], <span class="number">-1</span>, self.num_classes)</span><br></pre></td></tr></table></figure><p>最后一行首先将out的维度控制在anchor x num_classes，然后通过一个view将其变为[x.shape[0],W x H x anchor, num_classes]，每一个值表示一个框的类别，然后到criterion中去做预测。</p><p>Torch.cat 用法：<a href="https://blog.csdn.net/qq_39709535/article/details/80803003" target="_blank" rel="noopener">https://blog.csdn.net/qq_39709535/article/details/80803003</a></p><p>接下来需要生成anchor。</p><h3 id="anchor的生成"><a href="#anchor的生成" class="headerlink" title="anchor的生成"></a>anchor的生成</h3><p>anchor的设置上面，对于retinaNet最终的P3，P4，P5，P6，P7均有一个不同的设置。anchor的长宽比和scale的大小分别有三种设置，一共有9种组合。anchor的大小与feature map的大小也是相关的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.ratios = np.array([<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">self.scales = np.array([<span class="number">2</span>**<span class="number">0</span>,<span class="number">2</span>**(<span class="number">1.0</span>/<span class="number">3.0</span>),<span class="number">2</span>**(<span class="number">2.0</span>/<span class="number">3.0</span>)])</span><br></pre></td></tr></table></figure><p>几个常用的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = np.tile(a,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># a = [[1,2,3,1,2,3,1,2,3]</span></span><br><span class="line">       [<span class="number">1.2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure><p>np.repeat</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = np.repeat(a,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># a = [1,1,2,2,3,3]</span></span><br><span class="line"><span class="comment"># 与np.tile的区别是，他是一个元素一个元素的增加后进行排序的。tile则是一起增加。</span></span><br></pre></td></tr></table></figure><p>生成anchor的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Anchors</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None)</span>:</span></span><br><span class="line">        super(Anchors, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> pyramid_levels <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.pyramid_levels = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">        <span class="keyword">if</span> strides <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.strides = [<span class="number">2</span> ** x <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line">        <span class="keyword">if</span> sizes <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.sizes = [<span class="number">2</span> ** (x + <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line">        <span class="keyword">if</span> ratios <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.ratios = np.array([<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">if</span> scales <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.scales = np.array([<span class="number">2</span> ** <span class="number">0</span>, <span class="number">2</span> ** (<span class="number">1.0</span> / <span class="number">3.0</span>), <span class="number">2</span> ** (<span class="number">2.0</span> / <span class="number">3.0</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># image = [2,3,640,832]</span></span><br><span class="line">        image_shape = image.shape[<span class="number">2</span>:]</span><br><span class="line">        image_shape = np.array(image_shape)</span><br><span class="line">        image_shapes = [(image_shape + <span class="number">2</span> ** x - <span class="number">1</span>) // (<span class="number">2</span> ** x) <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute anchors over all pyramid levels</span></span><br><span class="line">        all_anchors = np.zeros((<span class="number">0</span>, <span class="number">4</span>)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, p <span class="keyword">in</span> enumerate(self.pyramid_levels):</span><br><span class="line">            anchors         = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)</span><br><span class="line">            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)</span><br><span class="line">            all_anchors     = np.append(all_anchors, shifted_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        all_anchors = np.expand_dims(all_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(all_anchors.astype(np.float32)).cuda()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_anchors</span><span class="params">(base_size=<span class="number">16</span>, ratios=None, scales=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Generate anchor (reference) windows by enumerating aspect ratios X</span></span><br><span class="line"><span class="string">    scales w.r.t. a reference window.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ratios <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        ratios = np.array([<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scales <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        scales = np.array([<span class="number">2</span> ** <span class="number">0</span>, <span class="number">2</span> ** (<span class="number">1.0</span> / <span class="number">3.0</span>), <span class="number">2</span> ** (<span class="number">2.0</span> / <span class="number">3.0</span>)])</span><br><span class="line"></span><br><span class="line">    num_anchors = len(ratios) * len(scales) <span class="comment"># 9个点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output anchors</span></span><br><span class="line">    anchors = np.zeros((num_anchors, <span class="number">4</span>)) <span class="comment"># 每一个位置上都有9个点，每个点都有四个坐标值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># scale base_size,feature 的大小与scale相乘，得到每一层anchor的大小</span></span><br><span class="line">    anchors[:, <span class="number">2</span>:] = base_size * np.tile(scales, (<span class="number">2</span>, len(ratios))).T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute areas of anchors</span></span><br><span class="line">    areas = anchors[:, <span class="number">2</span>] * anchors[:, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># correct for ratios 构造长宽比</span></span><br><span class="line">    anchors[:, <span class="number">2</span>] = np.sqrt(areas / np.repeat(ratios, len(scales)))</span><br><span class="line">    anchors[:, <span class="number">3</span>] = anchors[:, <span class="number">2</span>] * np.repeat(ratios, len(scales))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># transform from (x_ctr, y_ctr, w, h) -&gt; (x1, y1, x2, y2)</span></span><br><span class="line">    anchors[:, <span class="number">0</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">2</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line">    anchors[:, <span class="number">1</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">3</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shift</span><span class="params">(shape, stride, anchors)</span>:</span></span><br><span class="line">    shift_x = (np.arange(<span class="number">0</span>, shape[<span class="number">1</span>]) + <span class="number">0.5</span>) * stride</span><br><span class="line">    shift_y = (np.arange(<span class="number">0</span>, shape[<span class="number">0</span>]) + <span class="number">0.5</span>) * stride</span><br><span class="line"></span><br><span class="line">    shift_x, shift_y = np.meshgrid(shift_x, shift_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># shifts = [shape[0]*shape[1],4]</span></span><br><span class="line">    shifts = np.vstack((</span><br><span class="line">        shift_x.ravel(), shift_y.ravel(),</span><br><span class="line">        shift_x.ravel(), shift_y.ravel()</span><br><span class="line">    )).transpose()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add A anchors (1, A, 4) to</span></span><br><span class="line">    <span class="comment"># cell K shifts (K, 1, 4) to get</span></span><br><span class="line">    <span class="comment"># shift anchors (K, A, 4)</span></span><br><span class="line">    <span class="comment"># reshape to (K*A, 4) shifted anchors</span></span><br><span class="line">    A = anchors.shape[<span class="number">0</span>]</span><br><span class="line">    K = shifts.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 下面这一行进行了广播赋值，每一行都赋予维度不同的行进行广播，</span></span><br><span class="line">    <span class="comment"># 最终形成[1,A,4] + [k,1,4] = [k,A,4],其中k = shape[0]*shape[1]</span></span><br><span class="line">    <span class="comment"># 也就是说每一个像素位置都将产生9个anchor，每个anchor有四个坐标。 shape的大小则是由计算产生的</span></span><br><span class="line">    <span class="comment"># 每张图片在每个level处的大小在__init__处进行初始化</span></span><br><span class="line">    all_anchors = (anchors.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">                   shifts.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">    all_anchors = all_anchors.reshape((K * A, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> all_anchors</span><br></pre></td></tr></table></figure><p>每一行进行分析就是先设置每一层feature map的level，stride，sizes，ratios，scales的值。然后在forward里面<strong>generate_anchor()，对每一个level的feature生成符合要求的size的anchor</strong>，长宽比组合后共9种anchor。具体的设置可看代码。</p><p>然后进入shift()函数，shift()函数的作用是将anchor散布到每一个位置上。流程大概是，一张图片进来，分别计算出这种图片在每一层level上的size大小，然后根据每一层的anchor的大小，每一个像素点位置取9个anchor，然后返回一个$[shape[0]<em>shape[1]</em>9,4]$ 大小的矩阵。</p><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.meshgrid(x,y)<span class="comment"># 将x中元素与y中元素一一对应起来组合成坐标的形式。</span></span><br><span class="line">np.vstack((x,y))<span class="comment"># 将x，y中元素按照垂直方向叠加</span></span><br><span class="line"><span class="comment">#ravel()</span></span><br><span class="line">a = [[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">1</span>]]</span><br><span class="line">a.ravel() <span class="comment"># 将多维数组拉平，不存生新的副本 a = [2,2,1,1]</span></span><br><span class="line">a.flatten() <span class="comment"># 作用与上面函数相同，将返回一个数据副本</span></span><br><span class="line">np.squeeze([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]) <span class="comment"># 对维度为1的数据进行压缩，得到[1,2,3]</span></span><br><span class="line">a = a.reshape(<span class="number">-1</span>) <span class="comment"># 同样能够得到1维的数据</span></span><br><span class="line">a.transpose() <span class="comment"># 不指定参数表示对矩阵进行转置</span></span><br></pre></td></tr></table></figure><p>经过上面的过程，在for循环部分，将5层的anchor全部装入一个list中，anchor生成完毕。</p><p><strong>torch.cat函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">torch.cat((a,b),<span class="number">0</span>) <span class="comment"># 垂直方向 [[1,2,3],[3,4,5]]</span></span><br><span class="line">torch.cat((a,b),<span class="number">1</span>) <span class="comment"># 水平方向 [[1,2,3,4,5,6]]</span></span><br></pre></td></tr></table></figure><h3 id="focalLoss部分"><a href="#focalLoss部分" class="headerlink" title="focalLoss部分"></a>focalLoss部分</h3><p>focalLoss紧接着上面的一部分。现在回过头来梳理一下网络中数据流动到的位置：</p><p>将图片输入ResNet中，通过一个多层金字塔结构，输出5个不同深度feature map（P3，P4，P5，P6，P7），依次将这些层输入到regression网络和classification网络中，每一层都将得到$[batch,w<em>h,4]$的输出和$[batch,w</em>h*anchors,class_nums]$的输出，然后将所有结果cat到一起（水平拼接），即所有level上的anchor 的预测框会被cat到regression_anchor 和classification_anchor中。接下来要做的是判断这些anchor的好坏。根据我们的先验知识，我们产生了一部分anchor的设置，我们将网络产生的anchor和我们预生成的anchor输入focalLoss中，对anchor进行过滤，计算产生的loss。</p><p>下面介绍focalLoss：</p><p>focalLoss部分按batch为单位，每次输入一个batch的数据，然后进行loss的计算。首先计算预设置的anchor与当前图片GT的IoU。（重叠部分 / 相并部分）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_iou</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    area = (b[:, <span class="number">2</span>] - b[:, <span class="number">0</span>]) * (b[:, <span class="number">3</span>] - b[:, <span class="number">1</span>])</span><br><span class="line">    iw = torch.min(torch.unsqueeze(a[:, <span class="number">2</span>], dim=<span class="number">1</span>), b[:, <span class="number">2</span>]) -\</span><br><span class="line">    torch.max(torch.unsqueeze(a[:, <span class="number">0</span>], <span class="number">1</span>), b[:, <span class="number">0</span>])</span><br><span class="line">    ih = torch.min(torch.unsqueeze(a[:, <span class="number">3</span>], dim=<span class="number">1</span>), b[:, <span class="number">3</span>]) -\</span><br><span class="line">    torch.max(torch.unsqueeze(a[:, <span class="number">1</span>], <span class="number">1</span>), b[:, <span class="number">1</span>])</span><br><span class="line">    iw = torch.clamp(iw, min=<span class="number">0</span>)</span><br><span class="line">    ih = torch.clamp(ih, min=<span class="number">0</span>)</span><br><span class="line">    ua = torch.unsqueeze((a[:, <span class="number">2</span>] - a[:, <span class="number">0</span>]) * (a[:, <span class="number">3</span>] - a[:, <span class="number">1</span>]), dim=<span class="number">1</span>) + area - iw * ih</span><br><span class="line">    ua = torch.clamp(ua, min=<span class="number">1e-8</span>)</span><br><span class="line">    intersection = iw * ih</span><br><span class="line">    IoU = intersection / ua</span><br><span class="line">    <span class="keyword">return</span> IoU</span><br></pre></td></tr></table></figure><p>focalLoss主要对每一个anchor进入classification的分类结果，focalLoss的原理如下：</p><p><img src="/images/focal-loss.png" alt=""></p><p>整个网络的loss其实由两部分组成，一部分是分类loss，一部分是回归loss。分类loss即focal loss，回归部分的loss为边框回归的loss。实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment">#def __init__(self):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, classifications, regressions, anchors, annotations)</span>:</span></span><br><span class="line">        alpha = <span class="number">0.25</span></span><br><span class="line">        gamma = <span class="number">2.0</span></span><br><span class="line">        batch_size = classifications.shape[<span class="number">0</span>]</span><br><span class="line">        classification_losses = []</span><br><span class="line">        regression_losses = []</span><br><span class="line"></span><br><span class="line">        anchor = anchors[<span class="number">0</span>, :, :]</span><br><span class="line"></span><br><span class="line">        anchor_widths  = anchor[:, <span class="number">2</span>] - anchor[:, <span class="number">0</span>]</span><br><span class="line">        anchor_heights = anchor[:, <span class="number">3</span>] - anchor[:, <span class="number">1</span>]</span><br><span class="line">        anchor_ctr_x   = anchor[:, <span class="number">0</span>] + <span class="number">0.5</span> * anchor_widths</span><br><span class="line">        anchor_ctr_y   = anchor[:, <span class="number">1</span>] + <span class="number">0.5</span> * anchor_heights</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(batch_size):</span><br><span class="line"></span><br><span class="line">            classification = classifications[j, :, :]</span><br><span class="line">            regression = regressions[j, :, :]</span><br><span class="line"></span><br><span class="line">            bbox_annotation = annotations[j, :, :]</span><br><span class="line">            bbox_annotation = bbox_annotation[bbox_annotation[:, <span class="number">4</span>] != <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> bbox_annotation.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                regression_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line">                classification_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line"></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            classification = torch.clamp(classification, <span class="number">1e-4</span>, <span class="number">1.0</span> - <span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">            IoU = calc_iou(anchors[<span class="number">0</span>, :, :], bbox_annotation[:, :<span class="number">4</span>]) <span class="comment"># num_anchors x num_annotations</span></span><br><span class="line"></span><br><span class="line">            IoU_max, IoU_argmax = torch.max(IoU, dim=<span class="number">1</span>) <span class="comment"># num_anchors x 1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#import pdb</span></span><br><span class="line">            <span class="comment">#pdb.set_trace()</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute the loss for classification</span></span><br><span class="line">            <span class="comment"># target 的维度为类别的个数</span></span><br><span class="line">            targets = torch.ones(classification.shape) * <span class="number">-1</span></span><br><span class="line">            targets = targets.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># lt : less than 如果IoU_max的面积小于0.4，那么就认为没有匹配上</span></span><br><span class="line">            targets[torch.lt(IoU_max, <span class="number">0.4</span>), :] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            positive_indices = torch.ge(IoU_max, <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">            num_positive_anchors = positive_indices.sum()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># IoU_argmax记录着当前的anchor与哪一个GT比较匹配</span></span><br><span class="line">            <span class="comment"># 下面这个赋值语句就是给对应的anchor选择一个GT</span></span><br><span class="line">            <span class="comment"># 第一个参数选择候选的anchor，第二个参数将候选anchor的坐标值都取到</span></span><br><span class="line">            assigned_annotations = bbox_annotation[IoU_argmax, :]</span><br><span class="line"></span><br><span class="line">            targets[positive_indices, :] = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 下面一句表明对每个满足IoU条件的anchor，赋予一个类别。形成一个one hot编码（原先target的维度长度等于类别的个数）</span></span><br><span class="line">            targets[positive_indices, assigned_annotations[positive_indices, <span class="number">4</span>].long()] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            alpha_factor = torch.ones(targets.shape).cuda() * alpha</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            alpha_factor = torch.where(torch.eq(targets, <span class="number">1.</span>), alpha_factor, <span class="number">1.</span> - alpha_factor)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对focal weight进行统一的计算，然后赋值</span></span><br><span class="line">            focal_weight = torch.where(torch.eq(targets, <span class="number">1.</span>), <span class="number">1.</span> - classification, classification)</span><br><span class="line">            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)</span><br><span class="line">            <span class="comment">#      当y=1,即只有targets=1参与计算              当y=0，即只有targets=0参与</span></span><br><span class="line">            bce = -(targets * torch.log(classification) + (<span class="number">1.0</span> - targets) * torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># cls_loss = focal_weight * torch.pow(bce, gamma)</span></span><br><span class="line">            cls_loss = focal_weight * bce</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 注意对target的处理，当IoU在【0.4，0.5】之间时target=-1，不提供loss，其他情况均赋予一个cls_loss</span></span><br><span class="line">            cls_loss = torch.where(torch.ne(targets, <span class="number">-1.0</span>), cls_loss, torch.zeros(cls_loss.shape).cuda())</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算所有的loss在正例中的平均值</span></span><br><span class="line">            classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute the loss for regression</span></span><br><span class="line">            <span class="comment">#只有预测为正例的部分参与边框的回归，下面一部分为回归loss。</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> positive_indices.sum() &gt; <span class="number">0</span>:</span><br><span class="line">                assigned_annotations = assigned_annotations[positive_indices, :]</span><br><span class="line"></span><br><span class="line">                anchor_widths_pi = anchor_widths[positive_indices]</span><br><span class="line">                anchor_heights_pi = anchor_heights[positive_indices]</span><br><span class="line">                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]</span><br><span class="line">                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]</span><br><span class="line"></span><br><span class="line">                gt_widths  = assigned_annotations[:, <span class="number">2</span>] - assigned_annotations[:, <span class="number">0</span>]</span><br><span class="line">                gt_heights = assigned_annotations[:, <span class="number">3</span>] - assigned_annotations[:, <span class="number">1</span>]</span><br><span class="line">                gt_ctr_x   = assigned_annotations[:, <span class="number">0</span>] + <span class="number">0.5</span> * gt_widths</span><br><span class="line">                gt_ctr_y   = assigned_annotations[:, <span class="number">1</span>] + <span class="number">0.5</span> * gt_heights</span><br><span class="line"></span><br><span class="line">                <span class="comment"># clip widths to 1</span></span><br><span class="line">                gt_widths  = torch.clamp(gt_widths, min=<span class="number">1</span>)</span><br><span class="line">                gt_heights = torch.clamp(gt_heights, min=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi</span><br><span class="line">                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi</span><br><span class="line">                targets_dw = torch.log(gt_widths / anchor_widths_pi)</span><br><span class="line">                targets_dh = torch.log(gt_heights / anchor_heights_pi)</span><br><span class="line"></span><br><span class="line">                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))</span><br><span class="line">                targets = targets.t()</span><br><span class="line"></span><br><span class="line">                targets = targets/torch.Tensor([[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]]).cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                negative_indices = <span class="number">1</span> - positive_indices</span><br><span class="line"></span><br><span class="line">                regression_diff = torch.abs(targets - regression[positive_indices, :])</span><br><span class="line"></span><br><span class="line">                regression_loss = torch.where(</span><br><span class="line">                    torch.le(regression_diff, <span class="number">1.0</span> / <span class="number">9.0</span>),</span><br><span class="line">                    <span class="number">0.5</span> * <span class="number">9.0</span> * torch.pow(regression_diff, <span class="number">2</span>),</span><br><span class="line">                    regression_diff - <span class="number">0.5</span> / <span class="number">9.0</span></span><br><span class="line">                )</span><br><span class="line">                regression_losses.append(regression_loss.mean())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                regression_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(classification_losses).mean(dim=<span class="number">0</span>, keepdim=<span class="keyword">True</span>), torch.stack(regression_losses).mean(dim=<span class="number">0</span>, keepdim=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>边框回归部分学习一个边框的平移以及缩放关系：</p><p><img src="/images/box-regress.png" alt=""></p><p>最终将得到的分类loss以及regression loss的平均值整合成一个stack，返回下一步。</p><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(a,b) <span class="comment">#水平方向将a与b进行拼接</span></span><br><span class="line">torch.clamp(a,min_val,max_val) <span class="comment"># 将a中的值控制在min_val与max_val之间，小于取min_val，大于取max_val</span></span><br><span class="line">max_val, max_index = torch.max(a,dim = <span class="number">1</span>) <span class="comment"># 返回每一列最大值以及每一列的最大值的索引</span></span><br><span class="line">torch.lt(a,<span class="number">0.4</span>) <span class="comment"># 返回a中值小于0.4的元素的下标，ge均类似</span></span><br><span class="line">torch.where(condition,true_val,false_val) <span class="comment"># 如果满足条件者该位置为true_val,否则为false_val,其中参数的维度均相同（比如都为三维）</span></span><br></pre></td></tr></table></figure><h3 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h3><p>训练部分有几个需要完成的工作：</p><ol><li>初始化网络，设置优化器等等</li><li>将数据从dataloader中取出来</li><li>将数据输入网络中，得到网络的loss值</li><li>对loss进行反向传播，一些操作如learning rate的降低，梯度的裁剪可以在其中完成</li><li>打印出每个batch训练的结果</li><li>当训练次数到达一定的epoch时，对网络进行evaluate</li><li>保存mAP较高的网络</li></ol><p>下面通过代码来解读：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将训练过程迁移到gpu上</span></span><br><span class="line"> use_gpu = <span class="keyword">True</span></span><br><span class="line"><span class="keyword">if</span> use_gpu:</span><br><span class="line">retinanet = retinanet.cuda()</span><br><span class="line">retinanet = torch.nn.DataParallel(retinanet).cuda()</span><br><span class="line">retinanet.training = <span class="keyword">True</span></span><br><span class="line"> <span class="comment"># 设置优化器为adam</span></span><br><span class="line">optimizer = optim.Adam(retinanet.parameters(), lr=<span class="number">1e-5</span>)</span><br><span class="line"> <span class="comment"># ；learning rate的缩减器</span></span><br><span class="line">scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=<span class="number">3</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line">loss_hist = collections.deque(maxlen=<span class="number">500</span>) <span class="comment"># 实现了两端的快速添加删除</span></span><br><span class="line">retinanet.train()</span><br><span class="line">retinanet.module.freeze_bn()</span><br><span class="line">print(<span class="string">'Num training images: &#123;&#125;'</span>.format(len(dataset_train)))</span><br><span class="line"><span class="comment"># 从dataloader中取数据</span></span><br><span class="line"> <span class="keyword">for</span> epoch_num <span class="keyword">in</span> range(parser.epochs):</span><br><span class="line">retinanet.train()</span><br><span class="line">retinanet.module.freeze_bn()</span><br><span class="line">epoch_loss = []</span><br><span class="line"><span class="keyword">for</span> iter_num, data <span class="keyword">in</span> enumerate(dataloader_train):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">       <span class="comment"># 清空梯度，由于pytorch在每次backward的时候，</span></span><br><span class="line">       <span class="comment"># 会进行梯度的累积，这样的做法方便训练RNN模型</span></span><br><span class="line">       <span class="comment"># 但是在训练普通模型的时候，需要将累积的梯度清空。</span></span><br><span class="line">       <span class="comment"># 清空后做backward梯度方向有利于梯度的整体下降</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">       <span class="comment"># 将数据传入网络中，得到loss</span></span><br><span class="line">classification_loss, regression_loss = retinanet([data[<span class="string">'img'</span>].cuda().float(), data[<span class="string">'annot'</span>]])</span><br><span class="line">classification_loss = classification_loss.mean()</span><br><span class="line">regression_loss = regression_loss.mean()</span><br><span class="line">loss = classification_loss + regression_loss</span><br><span class="line"><span class="keyword">if</span> bool(loss == <span class="number">0</span>):</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">       <span class="comment"># 误差的反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">       <span class="comment"># 梯度裁剪函数,第二个参数表明允许最大的梯度为0.1</span></span><br><span class="line">torch.nn.utils.clip_grad_norm_(retinanet.parameters(), <span class="number">0.1</span>)</span><br><span class="line">optimizer.step()</span><br><span class="line">loss_hist.append(float(loss))</span><br><span class="line">epoch_loss.append(float(loss))</span><br><span class="line">print(<span class="string">'Epoch: &#123;&#125; | Iteration: &#123;&#125; | Classification loss: &#123;:1.5f&#125; | Regression loss: &#123;:1.5f&#125; | Running loss: &#123;:1.5f&#125;'</span>.format(epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))</span><br><span class="line"><span class="keyword">del</span> classification_loss</span><br><span class="line"><span class="keyword">del</span> regression_loss</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">print(e)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">if</span> parser.dataset == <span class="string">'coco'</span>:</span><br><span class="line">print(<span class="string">'Evaluating dataset'</span>)</span><br><span class="line">     <span class="comment"># 验证集验证模型的有效性</span></span><br><span class="line">coco_eval.evaluate_coco(dataset_val, retinanet)</span><br><span class="line"><span class="keyword">elif</span> parser.dataset == <span class="string">'csv'</span> <span class="keyword">and</span> parser.csv_val <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">print(<span class="string">'Evaluating dataset'</span>)</span><br><span class="line">mAP = csv_eval.evaluate(dataset_val, retinanet)</span><br><span class="line">scheduler.step(np.mean(epoch_loss))</span><br><span class="line">   <span class="comment"># 保存训练好的模型</span></span><br><span class="line">torch.save(retinanet.module, <span class="string">'&#123;&#125;_retinanet_&#123;&#125;.pt'</span>.format(parser.dataset, epoch_num))</span><br><span class="line"> retinanet.eval()</span><br><span class="line">torch.save(retinanet, <span class="string">'model_final.pt'</span>.format(epoch_num))</span><br></pre></td></tr></table></figure><p>需要注意的点：</p><p>在网络进行训练或验证时，通常先进行一次：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.train()</span><br><span class="line"><span class="comment"># or evaluate</span></span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure><p>这样的目的是模型在train和eval的时候，需要执行的操作是不一样的。例如batchNorm和Dropout在eval的时候是不需要执行的。因此需要提前对网络进行设置。</p><h3 id="eval-验证"><a href="#eval-验证" class="headerlink" title="eval 验证"></a>eval 验证</h3><p>eval作为验证网络的性能，被安排在网络执行的最后，在每个batch结束，或者达到设定的epoch的时候，对网络进行测试。并以此为依据，是否对网络进行存储。</p><p>eval部分常用的指标是mAP，该指标通过计算recall以及precision的值来得到最终的结果。首先得到网络的eval的结果，然后从标注数据中得到anno的结果，进行mAP的计算。</p><p>得到网络的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_detections</span><span class="params">(dataset, retinanet, score_threshold=<span class="number">0.05</span>, max_detections=<span class="number">100</span>, save_path=None)</span>:</span></span><br><span class="line">    <span class="string">""" Get the detections from the retinanet using the generator.</span></span><br><span class="line"><span class="string">    The result is a list of lists such that the size is:</span></span><br><span class="line"><span class="string">        all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        dataset         : The generator used to run images through the retinanet.</span></span><br><span class="line"><span class="string">        retinanet           : The retinanet to run on the images.</span></span><br><span class="line"><span class="string">        score_threshold : The score confidence threshold to use.</span></span><br><span class="line"><span class="string">        max_detections  : The maximum number of detections to use per image.</span></span><br><span class="line"><span class="string">        save_path       : The path to save the images with visualized detections to.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A list of lists containing the detections for each image in the generator.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    all_detections = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(dataset.num_classes())] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(dataset))]</span><br><span class="line">    retinanet.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">            data = dataset[index]</span><br><span class="line">            scale = data[<span class="string">'scale'</span>]</span><br><span class="line">            <span class="comment"># run network</span></span><br><span class="line">            scores, labels, boxes = retinanet(data[<span class="string">'img'</span>].permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).cuda().float().unsqueeze(dim=<span class="number">0</span>))</span><br><span class="line">            scores = scores.cpu().numpy()</span><br><span class="line">            labels = labels.cpu().numpy()</span><br><span class="line">            boxes  = boxes.cpu().numpy()</span><br><span class="line">            <span class="comment"># correct boxes for image scale</span></span><br><span class="line">            boxes /= scale</span><br><span class="line">            <span class="comment"># select indices which have a score above the threshold</span></span><br><span class="line">            indices = np.where(scores &gt; score_threshold)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> indices.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># select those scores</span></span><br><span class="line">                scores = scores[indices]</span><br><span class="line">                <span class="comment"># find the order with which to sort the scores</span></span><br><span class="line">                <span class="comment"># 得到score从大到小的下标，然后选择其中的max_detections那么多个</span></span><br><span class="line">                scores_sort = np.argsort(-scores)[:max_detections]</span><br><span class="line">                <span class="comment"># select detections score从大到小</span></span><br><span class="line">                image_boxes      = boxes[indices[scores_sort], :]</span><br><span class="line">                image_scores     = scores[scores_sort]</span><br><span class="line">                image_labels     = labels[indices[scores_sort]]</span><br><span class="line">                image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=<span class="number">1</span>), np.expand_dims(image_labels, axis=<span class="number">1</span>)], axis=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># copy detections to all_detections</span></span><br><span class="line">                <span class="keyword">for</span> label <span class="keyword">in</span> range(dataset.num_classes()):</span><br><span class="line">                    <span class="comment"># 每一张图片均表示成一个index，对所有的label都遍历一边，每个label保存若干个anchor,没有的话则不保存</span></span><br><span class="line">                    all_detections[index][label] = image_detections[image_detections[:, <span class="number">-1</span>] == label, :<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># copy detections to all_detections</span></span><br><span class="line">                <span class="keyword">for</span> label <span class="keyword">in</span> range(dataset.num_classes()):</span><br><span class="line">                    all_detections[index][label] = np.zeros((<span class="number">0</span>, <span class="number">5</span>))</span><br><span class="line">            print(<span class="string">'&#123;&#125;/&#123;&#125;'</span>.format(index + <span class="number">1</span>, len(dataset)), end=<span class="string">'\r'</span>)</span><br><span class="line">    <span class="keyword">return</span> all_detections</span><br></pre></td></tr></table></figure><p>从标注文件中读取图片的标注信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_annotations</span><span class="params">(generator)</span>:</span></span><br><span class="line">    <span class="string">""" Get the ground truth annotations from the generator.</span></span><br><span class="line"><span class="string">    The result is a list of lists such that the size is:</span></span><br><span class="line"><span class="string">        all_detections[num_images][num_classes] = annotations[num_detections, 5]</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        generator : The generator used to retrieve ground truth annotations.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A list of lists containing the annotations for each image in the generator.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    all_annotations = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(generator.num_classes())] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(generator))]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(generator)):</span><br><span class="line">        <span class="comment"># load the annotations</span></span><br><span class="line">        annotations = generator.load_annotations(i)</span><br><span class="line">        <span class="comment"># copy detections to all_annotations</span></span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">            all_annotations[i][label] = annotations[annotations[:, <span class="number">4</span>] == label, :<span class="number">4</span>].copy()</span><br><span class="line">        print(<span class="string">'&#123;&#125;/&#123;&#125;'</span>.format(i + <span class="number">1</span>, len(generator)), end=<span class="string">'\r'</span>)</span><br><span class="line">    <span class="keyword">return</span> all_annotations</span><br></pre></td></tr></table></figure><p>得到标注数据之后，开始计算mAP指标，mAP指标由recall（判断正确的占所有正确类别的百分比），precision（判断正确的占预测结果中认为正确的百分比）。通过对这两个指数的积分来计算最终的mAP结果。</p><p>recall = TP/(TP + FN) 即真正预测对的，占所有正类的比例</p><p>precision = TP/(TP + FN) 即真正预测对的，占预测结果为正的比例</p><p>TP,FP,TN,FN这几个指标第一个字母表示预测是不是对的，第二个字母表示，预测的内容是什么（正类或者负类）。关于mAP的计算可以看： <a href="https://perper.site/2019/03/22/手撕mAP/" target="_blank" rel="noopener">这里</a></p><p>下面代码计算mAP的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_overlap</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    a: (N, 4) ndarray of float</span></span><br><span class="line"><span class="string">    b: (K, 4) ndarray of float</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    overlaps: (N, K) ndarray of overlap between boxes and query_boxes</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    area = (b[:, <span class="number">2</span>] - b[:, <span class="number">0</span>]) * (b[:, <span class="number">3</span>] - b[:, <span class="number">1</span>])</span><br><span class="line">    iw = np.minimum(np.expand_dims(a[:, <span class="number">2</span>], axis=<span class="number">1</span>), b[:, <span class="number">2</span>]) - np.maximum(np.expand_dims(a[:, <span class="number">0</span>], <span class="number">1</span>), b[:, <span class="number">0</span>])</span><br><span class="line">    ih = np.minimum(np.expand_dims(a[:, <span class="number">3</span>], axis=<span class="number">1</span>), b[:, <span class="number">3</span>]) - np.maximum(np.expand_dims(a[:, <span class="number">1</span>], <span class="number">1</span>), b[:, <span class="number">1</span>])</span><br><span class="line">    iw = np.maximum(iw, <span class="number">0</span>)</span><br><span class="line">    ih = np.maximum(ih, <span class="number">0</span>)</span><br><span class="line">    ua = np.expand_dims((a[:, <span class="number">2</span>] - a[:, <span class="number">0</span>]) * (a[:, <span class="number">3</span>] - a[:, <span class="number">1</span>]), axis=<span class="number">1</span>) + area - iw * ih</span><br><span class="line">    ua = np.maximum(ua, np.finfo(float).eps)</span><br><span class="line">    intersection = iw * ih</span><br><span class="line">    <span class="keyword">return</span> intersection / ua</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_ap</span><span class="params">(recall, precision)</span>:</span></span><br><span class="line">    <span class="string">""" Compute the average precision, given the recall and precision curves.</span></span><br><span class="line"><span class="string">    Code originally from https://github.com/rbgirshick/py-faster-rcnn.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        recall:    The recall curve (list).</span></span><br><span class="line"><span class="string">        precision: The precision curve (list).</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        The average precision as computed in py-faster-rcnn.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># correct AP calculation</span></span><br><span class="line">    <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">    mrec = np.concatenate(([<span class="number">0.</span>], recall, [<span class="number">1.</span>]))</span><br><span class="line">    mpre = np.concatenate(([<span class="number">0.</span>], precision, [<span class="number">0.</span>]))</span><br><span class="line">    <span class="comment"># compute the precision envelope</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line">    <span class="comment"># to calculate area under PR curve, look for points</span></span><br><span class="line">    <span class="comment"># where X axis (recall) changes value</span></span><br><span class="line">    i = np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># and sum (\Delta recall) * prec</span></span><br><span class="line">    ap = np.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    generator,</span></span></span><br><span class="line"><span class="function"><span class="params">    retinanet,</span></span></span><br><span class="line"><span class="function"><span class="params">    iou_threshold=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    score_threshold=<span class="number">0.05</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    max_detections=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    save_path=None</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="string">""" Evaluate a given dataset using a given retinanet.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        generator       : The generator that represents the dataset to evaluate.</span></span><br><span class="line"><span class="string">        retinanet           : The retinanet to evaluate.</span></span><br><span class="line"><span class="string">        iou_threshold   : The threshold used to consider when a detection is positive or negative.</span></span><br><span class="line"><span class="string">        score_threshold : The score confidence threshold to use for detections.</span></span><br><span class="line"><span class="string">        max_detections  : The maximum number of detections to use per image.</span></span><br><span class="line"><span class="string">        save_path       : The path to save images with visualized detections to.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A dict mapping class names to mAP scores.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># gather all detections and annotations</span></span><br><span class="line">    all_detections     = _get_detections(generator, retinanet, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path)</span><br><span class="line">    all_annotations    = _get_annotations(generator)</span><br><span class="line">    average_precisions = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">        false_positives = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        true_positives  = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        scores          = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        num_annotations = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(generator)):</span><br><span class="line">            detections           = all_detections[i][label]</span><br><span class="line">            annotations          = all_annotations[i][label]</span><br><span class="line">            num_annotations     += annotations.shape[<span class="number">0</span>]</span><br><span class="line">            detected_annotations = []</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> detections:</span><br><span class="line">                scores = np.append(scores, d[<span class="number">4</span>])</span><br><span class="line">                <span class="keyword">if</span> annotations.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 表示当前图片没有标注，因此你的标注结果都是错误的</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>) <span class="comment"># 对每个框找出覆盖最多的一个标注,返回标注所在的下标</span></span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br><span class="line">                <span class="keyword">if</span> max_overlap &gt;= iou_threshold <span class="keyword">and</span> assigned_annotation <span class="keyword">not</span> <span class="keyword">in</span> detected_annotations:</span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">0</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">1</span>)</span><br><span class="line">                    detected_annotations.append(assigned_annotation)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># no annotations -&gt; AP for this class is 0 (is this correct?)</span></span><br><span class="line">        <span class="keyword">if</span> num_annotations == <span class="number">0</span>:</span><br><span class="line">            average_precisions[label] = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># sort by score</span></span><br><span class="line">        indices         = np.argsort(-scores)</span><br><span class="line">        false_positives = false_positives[indices]</span><br><span class="line">        true_positives  = true_positives[indices]</span><br><span class="line">        <span class="comment"># compute false positives and true positives</span></span><br><span class="line">        <span class="comment"># 得到一个累加的数组的结果</span></span><br><span class="line">        false_positives = np.cumsum(false_positives)</span><br><span class="line">        true_positives  = np.cumsum(true_positives)</span><br><span class="line">        <span class="comment"># compute recall and precision</span></span><br><span class="line">        recall    = true_positives / num_annotations</span><br><span class="line">        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)</span><br><span class="line">        <span class="comment"># compute average precision</span></span><br><span class="line">        average_precision  = _compute_ap(recall, precision)</span><br><span class="line">        average_precisions[label] = average_precision, num_annotations</span><br><span class="line">    print(<span class="string">'\nmAP:'</span>)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">        label_name = generator.label_to_name(label)</span><br><span class="line">        print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(label_name, average_precisions[label][<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> average_precisions</span><br></pre></td></tr></table></figure><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.argsort(scores) <span class="comment"># 根据从小到大返回元素的下标，小的在前</span></span><br><span class="line">np.argmax(overlaps,axis = <span class="number">1</span>) <span class="comment"># 找出每一列的最大值，返回他的下标</span></span><br><span class="line">np.cumsum(nums) <span class="comment"># 返回一个数组，数组中内容从头开始累加到当前位置</span></span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>经过上面几个流程我们大致梳理了一下一个网络的搭建，数据的传递，loss的计算，以及最后的验证的过程。</p><p>总结一下：</p><ol><li>构造dataloader，在这里头完成数据的读取，增强等工作</li><li>完成网络的搭建</li><li>完成网络的训练</li><li>完成验证集的测试工作</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>normalization</title>
      <link href="/2019/07/24/normalization/"/>
      <url>/2019/07/24/normalization/</url>
      
        <content type="html"><![CDATA[<p>Normalization 正则化在wikipedia上的解释是，使得某个东西更加正规和正常化的一个过程。深度学习中，正则化使用十分广泛，通常网络通过修改loss，添加参数的正则项，对参数的分布进行控制；或是在数据预处理阶段，对数据进行正则化操作。正则化操作通常指的是将数据大小范围缩放到[0,1]之间。<br><a id="more"></a></p><h3 id="对数据集的正则化操作"><a href="#对数据集的正则化操作" class="headerlink" title="对数据集的正则化操作"></a>对数据集的正则化操作</h3><blockquote><p>Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as <strong>k-nearest neighbors and artificial neural networks.</strong></p><p>正则化使用场景是数据特征范围差异大，且数据的分布未知。</p></blockquote><p>对于一般的数据集来说，我们不需要对其进行正则化操作。但如果数据集不同特征的数据范围相差过大时，我们需要对其进行正则化操作。因为数据范围大的数据，其波动对精度的影响很大，而数据范围小的特征，数据波动的影响不会有这么大，这样造成了结果精度无法提升。因此需要对数据进行正则化操作。使得数据局限在一个固定的范围内。</p><h3 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h3><p>我们知道，当一个网络与数据过度拟合，这个网络能够很好的反应训练数据，但是它的泛化性能也会大大下降。为了避免这种过拟合现象，做法通常有：</p><ol><li>削减特征的数量（难以确定哪些特征是需要丢弃的）</li><li>减少特征的参数，控制参数的分布，即使用正则项方法</li></ol><p>正则项的目的是为了对参数进行控制，包括：</p><ol><li>实现参数的稀疏化，即某些参数为0。参数的稀疏化能够自动对数据的特征进行筛选，过滤掉一些不需要的特征，同时起到简化模型的作用，避免过拟合。</li><li>最小化正则项能够尽量保持参数较小，参数小的好处在于计算方便，且在网络求导的过程中，产生的导数通常比较小，结果比较稳定。</li></ol><h4 id="范数-（norm）"><a href="#范数-（norm）" class="headerlink" title="范数 （norm）"></a>范数 （norm）</h4><p>在线性代数领域中，范数是一个函数，它为向量空间中的每个向量分配严格正长度或大小 。</p><p><strong>L0 范数：指向量空间中非0向量的个数</strong></p><p><strong>无穷范数：指所有向量中欧式距离的最大值作为无穷范数</strong></p><h4 id="参数正则项"><a href="#参数正则项" class="headerlink" title="参数正则项"></a>参数正则项</h4><p><strong>L0正则项：模型参数中，不为0的参数的个数</strong></p><p>​    L0正则化通过最小化不为0的参数的个数，以达到参数稀疏化的目的，使得模型自动选择特征。在使用时，由于L0正则项是一个NP hard问题，L1是L0的最优凸优化，因此通常用L1来代替L0。</p><p><strong>L1正则项：各个模型参数的绝对值之和</strong></p><p>​    最小化L1正则项能够将模型的参数变小，沿着0的方向靠近，降低网络的模型复杂度。添加L1正则项后方程如下：<br>$$<br>L = L_0 + \frac{\lambda}{n}\sum_{w}|W|<br>$$<br><strong>L2 正则项：各个参数的平方和再开根号。</strong></p><p>​    最小化L2正则项可以使得参数变小接近于0，当参数不会变成0（可以看下面的图来理解），因此L2将选择更多的特征，权重比较小，避免过拟合。方程如下：<br>$$<br>C=C_{0}+\frac{\lambda}{2 n} \sum_{w} w^{2}<br>$$<br><strong>lasso回归与岭参数</strong></p><p>L1正则化又称为losso回归，将L1正则项作为loss的惩罚函数。L2正则项又称为岭参数。同样可以将L2正则项作为公式的约束项。可以画图如下,其中等值线为原始的Loss，L1为正方形（绝对值），L2为一个圈（平方根）。可以看出来，图中的交点满足条件的点，因此可以看出L1正则项可以得到更多的稀疏解。</p><p><img src="../images/SR/L1L2_7_24.png" alt=""></p><h3 id="标准化操作（standardization）"><a href="#标准化操作（standardization）" class="headerlink" title="标准化操作（standardization）"></a>标准化操作（standardization）</h3><blockquote><p>Standardization is useful when your data has varying scales and the algorithm you are using does make assumptions about your data having a Gaussian distribution, such as <strong>linear regression, logistic regression and linear discriminant analysis.</strong></p><p>标准化使用场景是数据特征范围差异大，假设数据服从高斯分布。</p></blockquote><p>将数据标准化是指将数据rescale，使得数据的 $mean = 0,\sigma = 1$。数据的标准化操作如下：<br>$$<br>z=\frac{x-\mu}{\sigma}<br>$$<br>标准化操作对于很多机器学习的算法，在网络训练上有着很重要的作用。例如对于梯度下降法来说，处于中心（mean = 0）范围的数据，中心权重的参数更新将会加快。对于一些loss而言（MSE），利用欧式距离作为网络优化的目标，因此标准化操作是很重要的。</p><h3 id="Batch-Normalization（批量标准化）"><a href="#Batch-Normalization（批量标准化）" class="headerlink" title="Batch Normalization（批量标准化）"></a>Batch Normalization（批量标准化）</h3><p>其步骤如下，对一个batch中的数据进行标准化后，并学习$r,\beta$ 两个参数，对得到标准化后的值进行一个偏移，得到最终的结果：</p><p><img src="../images/SR/BN_7_24.png" alt=""></p><p><u>当进来一个batch的时候，具体的做法是，在数据输入到下一层神经元激活函数之前，计算整个batch的mean，variance，偏移后最终得到下一层的输入。</u></p><p><strong>为什么要加入Batch Normalization层？</strong></p><p>由于深层网络的输入，经过多层神经网络层的作用后发生偏移（ReLu激活函数输出均大于0，因此整体输出的mean将往大于0的方向偏移）。导致网络训练难以收敛，落入梯度饱和区导致梯度消失等问题。BN层重新通过将数据拉回N(0,1)的正态分布上，是的输入值落入激活函数梯度敏感的区域，避免梯度消失，加速网络的训练。（输入变小也有助于降低模型计算复杂度）。</p><p>但是仅仅做到这一步还不行，由于我们引入非线性的激活函数，使得网络能够学到一些非线性的性质。我们通过BN将输出拉回到N(0,1)分布上，削弱了激活函数的非线性部分的作用。因此BN通过学习两个参数$\gamma, \beta$ 来对输出做一个scale和shit操作。恢复学习到的非线性部分知识。最终得到的$y_i$ 在正态分布和非线性性质中做了一个trade off。</p><p><strong>Batch Normalization的作用</strong></p><ol><li>batch normalization极大的提升了网络训练的速度</li><li>每次BN都将网络的输出控制在一个范围内，近似于符合正态分布，能够起到正则项的作用</li><li>对参数的初始化要求降低，调参变得简单</li></ol><h4 id="layer-normalization"><a href="#layer-normalization" class="headerlink" title="layer normalization"></a>layer normalization</h4><p><img src="../images/SR/layer_normal_7_24.png" alt=""></p><p>layer normalization 正则化的方向是沿着feature的方向对CHW归一化，batch normalization 正则化的方向是以sample为单位，对NHW做归一化。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>image upsample-downsample method</title>
      <link href="/2019/07/23/image-upsample-downsample-method/"/>
      <url>/2019/07/23/image-upsample-downsample-method/</url>
      
        <content type="html"><![CDATA[<p>图像尺度的放大，缩小是图形学中一个十分常见的问题。然而这个过程并不是无损的，缩放的过程是一个非线性的过程，因此存在许多算法在效率，平滑度，清晰度和速度上进行一些权衡（trade-off）。在图形的缩放过程中，存在插值，采样等一些关键的步骤，下面对一些在图像缩放过程中使用的算法进行简要的介绍，这些算法均有其优缺点。</p><p>参考资料：<a href="https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic" target="_blank" rel="noopener">https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic</a></p><a id="more"></a><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>在处理图片的缩放问题时，需要解决的问题是：</p><ul><li>在放大过程中，新增的像素的颜色如何确定。</li><li>在缩小过程中，哪些像素需要被保留。</li></ul><h3 id="图形缩放"><a href="#图形缩放" class="headerlink" title="图形缩放"></a>图形缩放</h3><p>下面用一个1D的问题举例,如下图，y轴表示灰度图的灰度值:</p><p><img src="../images/SR/img_1d.png" alt=""></p><p>现在对这个图形进行进行放大，有两种做法：</p><ol><li>使用<strong>最近邻方法</strong>，用左边的像素填补这个位置的像素</li></ol><p><img src="../images/SR/upsample_7_23.png" alt=""></p><ol start="2"><li>使用线性插值的方法，利用前后位置的像素值生成该位置上的像素</li></ol><p><img src="../images/SR/interpolation_7_23.png" alt=""></p><p><strong>将这个问题一般化，我们通过引入卷积来完成这个操作。</strong>例如对于最近邻方法，可以使用[1,1,0]卷积核，对于插值法，可以使用[0.5,1,0.5]卷积核。</p><hr><p>与上述思路相同，我们将卷积核推广到2D的情况，同时在x和y方向上做卷积，各个像素的取值由卷积权重决定。</p><h4 id="Nearest-Neighbor-Resampling（最近邻采样）"><a href="#Nearest-Neighbor-Resampling（最近邻采样）" class="headerlink" title="Nearest Neighbor Resampling（最近邻采样）"></a>Nearest Neighbor Resampling（最近邻采样）</h4><p><img src="../images/SR/nnre.png" alt=""></p><p>用这种方式得到的图像块状比较明显，但是这种方法执行效率最快。</p><h4 id="Bilinear-Resampling-B-spline-order-1-（双线性插值）"><a href="#Bilinear-Resampling-B-spline-order-1-（双线性插值）" class="headerlink" title="Bilinear Resampling (B-spline order 1) （双线性插值）"></a>Bilinear Resampling (B-spline order 1) （双线性插值）</h4><p><img src="../images/SR/bilinear_7_23.png" alt=""></p><p>上诉公式是沿着x方向的线性差值的值，对于y方向同样用这种方式进行插值。</p><h4 id="Bicubic-Resampling-（双三次插值）"><a href="#Bicubic-Resampling-（双三次插值）" class="headerlink" title="Bicubic Resampling （双三次插值）"></a>Bicubic Resampling （双三次插值）</h4><p><img src="../images/SR/bicubic_7_23.png" alt=""></p><p>该方法需要选取的最近的16个像素点作为计算目标图像B(X,Y)处像素值的参数。每个位置的权重与像素值，以及像素的变化率有关。当a取-0.5是，bicubic函数有以下的形状：</p><p><img src="../images/SR/bicubic_shape_7_23.png" alt=""></p><p>该算法在各中图像的缩放过程中使用的最多。其中心点像素计算公式如下：<br>$$<br>\sum_{i=0}^{3} \sum_{j=0}^{3} a_{i j} x^{i} y^{j}<br>$$<br>其中参数a需要根据临近的四个点的像素值，偏导数等等来计算。具体的计算过程可以看<a href="https://en.wikipedia.org/wiki/Bicubic_interpolation" target="_blank" rel="noopener">wiki上的解释</a>。</p><hr><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>在处理具体问题时，我们知道一张图片在显示屏上是以点阵的方式排列的。当我们要放大，或者缩小时，例如用双三次插值时，对于每个像素点，无论是放大还是缩小，我们总能找到最邻近的16个位置，可以很方便的对图片进行缩放。此外，用卷积的方式进行求解，能够并行对图片进行处理，提高图片的处理效率。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Deep Learning for image Super-resolution: a Survey</title>
      <link href="/2019/07/23/Deep-Learning-for-image-Super-resolution-a-Survey/"/>
      <url>/2019/07/23/Deep-Learning-for-image-Super-resolution-a-Survey/</url>
      
        <content type="html"><![CDATA[<p>本篇论文是2019年2月份，发表在arxiv上的篇关于超分辨率的一篇综述。这篇文章系统且全面的介绍了一些基于深度学习的超分辨率方法。其中包括：</p><ul><li>超分辨率问题的定义 (problem setting)</li><li>benchmark datasets</li><li>性能评价指标 (performance metrics)</li><li>基于深度学习的超分辨率方法</li><li>特定领域的超分辨率应用 (domain-specific application)</li></ul><p>此外作者对比每个超分辨率方法，指出了网络的优点以及局限。最后对该领域的一些开放性问题(open issuse) 以及挑战提出了未来研究的方向。</p><a id="more"></a><h3 id="超分辨率问题的定义（problem-setting）"><a href="#超分辨率问题的定义（problem-setting）" class="headerlink" title="超分辨率问题的定义（problem setting）"></a>超分辨率问题的定义（problem setting）</h3><p>图像的超分辨率要解决的问题是：从一张低分辨率（LR）的图像中，恢复出一张高分辨率（HR）的图像。</p><p>通常来说，我们通过下面的方式得到低分辨率的图像：<br>$$<br>I_{x}=\mathcal{D}\left(I_{y} ; \delta\right)<br>$$<br>$I_x$ 表示低分辨率图像，$I_y$ 表示高分辨率图像，$D()$ 表示下采样的映射函数，$\delta$ 表示映射函数的参数。图片清晰度不够的原因可能有很多种，例如聚焦，图片压缩，传感器噪声等问题。一些学者提出了下面的模型来模拟这种失真的映射。<br>$$<br>\mathcal{D}\left(I_{y} ; \delta\right)=\left(I_{y} \otimes \kappa\right) \downarrow_{s}+n_{\zeta},{\kappa, s, \zeta} \subset \delta<br>$$<br>$I_{y} \otimes \kappa$ 表示HR图片与模糊核（blur kernel）k的卷积操作，下箭头表示下采样，$n_{\zeta}$ 表示方差为$\zeta$ 的白高斯噪声。</p><hr><p>目前大多数的数据库，产生LR图像的方法是直接对SR图像做一些下采样(双三次插值算法(bicubic interpolation))，同时对图片作抗锯齿（anti aliasing），去模糊等操作(blur) 。关于下采样，上采样的一些方法可以看 <a href="http://eeweb.poly.edu/~yao/EL5123/lecture8_sampling.pdf" target="_blank" rel="noopener">这个课件</a>，或<a href="https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic" target="_blank" rel="noopener">这里</a>。</p><p>关于超分问题，我们更关注的是如何由低分辨率的图片得到高分辨率的图片，即：<br>$$<br>\hat{I}_{y}=\mathcal{F}\left(I_{x} ; \theta\right)<br>$$<br>其中$\mathcal{F}()$ 为超分模型，由低分辨率图片生成高分辨率的图片。</p><p>对于一个典型的超分辨率问题来说，我们需要从一个LR图像中恢复出它的HR版本。模型的目标是最小化我们恢复出来的图片与原始HR图片的差距，<strong>目标方程</strong>如下：<br>$$<br>\hat{\theta}=\underset{\theta}{\arg \min } \mathcal{L}\left(\hat{I}_{y}, I_{y}\right)+\lambda \Phi(\theta)<br>$$<br>其中$\mathcal{L}\left(\hat{I}_{y}, I_{y}\right)$ 为生成的HR图像与原始图像的Loss，公式尾项是一个<strong>正则项</strong>。目前使用较多的loss为像素级别的MSE loss，同时一些组合型的loss也经常被使用。引入正则项的目的是控制参数的变化，使得网络更容易收敛。<a href="https://www.jianshu.com/p/70487abdf96b" target="_blank" rel="noopener">正则项可以看这里。</a></p><hr><h3 id="Benchmark-dataset"><a href="#Benchmark-dataset" class="headerlink" title="Benchmark dataset"></a>Benchmark dataset</h3><p>在一个典型的超分辨率的文章中，通常需要对一些公开数据集上进行试验，在这些公开数据集上的效果指标作为这个算法性能的评价标准。主要使用的数据集有：</p><p><img src="/images/SR/dataset_7_25.png" alt=""></p><hr><h3 id="Image-Quality-Assessment"><a href="#Image-Quality-Assessment" class="headerlink" title="Image Quality Assessment"></a>Image Quality Assessment</h3><p>图片质量的评价是一个与感知，视觉相关的问题。通常存在客观和主观的两类方法。其中客观方法根据指标计算模型直接计算得出，如MSE。主观方法则与人们的感知更为接近。下面介绍一下常用的评价方法。</p><h4 id="Peak-Signal-to-Noise-Ratio-峰值信噪比"><a href="#Peak-Signal-to-Noise-Ratio-峰值信噪比" class="headerlink" title="Peak Signal-to-Noise Ratio(峰值信噪比)"></a>Peak Signal-to-Noise Ratio(峰值信噪比)</h4><p>峰值信号比是一种图像的客观评价标准。他用最大值信号与背景噪声信号（重建与原始信号的差）的比值作为评价标准：<br>$$<br>\begin{aligned}<br>\operatorname{MSE} &amp;=\frac{1}{N} \sum_{i=1}^{N}(I(i)-\hat{I}(i))^{2} \\<br>\operatorname{PSNR} &amp;=10 \cdot \log _{10}\left(\frac{L^{2}}{\mathrm{MSE}}\right) \\<br>\end{aligned}<br>$$<br>其中L为图像点颜色的最大数值，若采样点采样8位表示，那么L = 255。该指标更加注重像素点之间的误差。典型的<strong>PSNR值在20到40之间</strong>。指标越高越好。</p><p>但是由于PSNR指标更多的放映相同位置上像素值的差异，而未考虑到人眼的视觉感知，因此作为质量评价指标是存在缺陷的。但这个指标仍是目前使用最多的一个指标。</p><p><strong>人眼视觉特征</strong></p><ol><li>对空间频率较低的对比差异敏感度高</li><li>人眼对亮度对比差异的敏感度较色度高</li><li>人眼对一个区域的感知结果会影响到周围邻近区域</li></ol><hr><h4 id="SSIM（Structural-Similarity-结构相似性）"><a href="#SSIM（Structural-Similarity-结构相似性）" class="headerlink" title="SSIM（Structural Similarity 结构相似性）"></a>SSIM（Structural Similarity 结构相似性）</h4><p>SSIM分别从亮度，对比度，结构三个方面度量图片的相似性。</p><p>首先计算图片的mean和variance：<br>$$<br>\begin{aligned}<br>\mu_{I} &amp;=\frac{1}{N} \sum_{i=1}^{N} I(i) \\<br>\sigma_{I} &amp;=\left(\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)^{2}\right)^{\frac{1}{2}} \\<br>\end{aligned}<br>$$<br><strong>亮度</strong>（luminance）指标（$\hat{I}$ 指生成的图片）:<br>$$<br>\mathcal{C}_{l}(I, \hat{I})=\frac{2 \mu_{I} \mu_{\hat{I}}+C_{1}}{\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}}<br>$$<br><strong>对比度（contrast）</strong>指标：<br>$$<br>\mathcal{C}_{c}(I, \hat{I})=\frac{2 \sigma_{I} \sigma_{\hat{I}}+C_{2}}{\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}}<br>$$<br><strong>结构对比度（structure comparison）</strong>指标：<br>$$<br>\begin{aligned}<br>\sigma_{I \hat{I}} &amp;=\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)\left(\hat{I}(i)-\mu_{\hat{I}}\right) \\<br>\mathcal{C}_{s}(I, \hat{I}) &amp;=\frac{\sigma_{I \hat{I}}+C_{3}}{\sigma_{I} \sigma_{\hat{I}}+C_{3}} \\<br>\end{aligned}<br>$$<br>其中$C_1 = (K_1L)^2$,$C_2 = (K_2L)^2$,$C_3 = C_2 / 2$。</p><p>SSIM的指标有三面三个指标组合而成：<br>$$<br>\operatorname{SSIM}(I, \hat{I})=\left[\mathcal{C}_{l}(I, \hat{I})\right]^{\alpha}\left[\mathcal{C}_{c}(I, \hat{I})\right]^{\beta}\left[\mathcal{C}_{s}(I, \hat{I})\right]^{\gamma}<br>$$<br>通常使用下面这个形式：<br>$$<br>\operatorname{SSIM}(I, \hat{I})=\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(\sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\overline{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\tilde{I}}^{2}+C_{2}\right)}<br>$$<br>一般的，$k_1 = 0.01,k_2 = 0.03, L =255$。</p><p>此外还有一些主观的评价方法（mean opinion score），利用志愿者对生成图片的质量进行五个等级的评价，来确定图片的质量。</p><p>对于图片的颜色空间来说，常用的颜色空间有RGB空间与YCbCr。</p><hr><h3 id="基于有监督的超分辨率方法"><a href="#基于有监督的超分辨率方法" class="headerlink" title="基于有监督的超分辨率方法"></a>基于有监督的超分辨率方法</h3><h4 id="超分辨率框架分类"><a href="#超分辨率框架分类" class="headerlink" title="超分辨率框架分类"></a>超分辨率框架分类</h4><p>超分辨率框架总结下来有以下四种：</p><ol><li>Pre-upsampling Super-resolution</li><li>Post-upsampling Super-resolution</li><li>Progressive Upsampling Super-resolution</li><li>Iterative Up-and-down Sampling Super-resolution</li></ol><p>如下图：</p><p><img src="/images/SR/sr_structure_725.png" height="700px" width="600px"></p><p><strong>Pre-upsampling Super-resolution</strong></p><p>该方法在将图片送入网络前先用传统方法进行图片的放大（bicubic interpolation上采样），将图片放大到输出的要求大小，然后送入CNN网络中，学习一个端到端的从LR到HR的映射。</p><p>该方法的优点在于神经网络<strong>仅需要学习一张粗糙的（传统方法放大的）图片到HR图片的映射</strong>，大大降低了网络学习的难度；同时这种结构可以任意控制图片放大倍数。该方法框架也成为了一种较为主流的框架。</p><p>该方法的缺点在于：传统的图片放大算法中通常需要包含去噪，去模糊等操作，需要<strong>花费很大的时间以及空间</strong>。</p><hr><p><strong>Post-upsampling Super-resolution</strong></p><p>该方法将LR到HR的整个过程作为网络学习的目标，上采样层在网络的末端，这种设计可以极大发挥网络的潜力，同时能够显著降低网络训练时消耗的时间与空间。在train和inference阶段速度带来了很大的提升。</p><p>缺点：仅通过一个upsample层来放大图片，使得网络学习的难度大大提升；由于upsample层的放大尺度是固定的，如果更换一个倍数，就要更换一个训练模型。</p><hr><p><strong>Progressive Upsampling Super-resolution</strong></p><p>渐进式的上采样可以解决上诉post结构的问题（例如LapSRN网络 laplacian pyramid SR network）。该结构采用许多CNN的级联结构，每个阶段进行一个上采样重构HR，生成放大2倍，4倍，8倍等结果。</p><p>该模型的缺点是结构复杂，训练难度大等等。</p><hr><p><strong>Iterative Up-and-down Sampling Super-resolution</strong></p><p>该结构反复的放大，缩小图片，试图学习到一种后映射（back projection）的关系，该模型可以很好的学习到LR与HR之间的映射关系。基于该框架的网络DBPN也获得了NTIRE 2018的冠军。尽管这种up-down的结构设计标准还未确定，DBPN网络中存在着大量的复杂的结构设计以及繁重的人工设计过程，但是这种结构有很大的研究潜力。还需要进一步探索。</p><h4 id="传统插值上采样算法"><a href="#传统插值上采样算法" class="headerlink" title="传统插值上采样算法"></a>传统插值上采样算法</h4><ol><li>最近邻插值</li><li>线性插值</li><li>双三次插值</li></ol><p>详见<a href="www.baidu.com">这里</a></p><p>事实上，所有的差值算法完全通过图片自身的内容来实现超分辨率，因此他们并不能提供多于图片的信息，此外这些差值算法还引入了一些边界效应，例如计算复杂度，噪声，模糊等等。</p><h4 id="基于学习的上采样方法"><a href="#基于学习的上采样方法" class="headerlink" title="基于学习的上采样方法"></a>基于学习的上采样方法</h4><p><strong>转置卷积层 （transposed/ deconvolution layer）</strong></p><p> 转置卷积层的作用与正常卷积层的操作是相反的。转置卷积通过在像素间插入0来扩大图片的分辨率。下面是转置卷积层的工作原理：</p><p><img src="/images/SR/deconv.png" alt=""></p><p>首先对一张图片，每个像素点之间添加一个0值，然后用一个3 X 3 的卷积核，padding= 1 ，stride = 1对它进行卷积操作，最终得到一个大小为原先两倍的图片。</p><p>这种做法能够使得网络实现端到端的映射，但是他的缺点是，产生的图片会产生一些不等的重叠，从坐标轴上看，容易形成棋盘的割裂感，一定程度上伤害了SR的性能。</p><p><strong>子像素卷积（sub-pixel layer）</strong></p><p>子像素卷积在超分辨率领域使用十分广泛，用于扩大图片的像素。他的工作原理是执行一次卷积之后，产生一个多通道的feature map。然后将这些多通道的像素reshape到一个二维平面上。原理图如下：</p><p><img src="/images/SR/sub-pixel.png" alt=""></p><p>例如要将原始的feature map大小变大s倍，那么卷积核的channel数达到$s^2$。例如输入图片的大小为$w*h*c$，经过卷积操作后变为$w*h*s^2 c$ ，然后进过reshape成$sh*sw*c$，即完成了放大的操作。在原图的基础上放大了s倍。</p><p>子像素的上采样方法有一个重要的优点在于他有更大的感受野，能够提供更多的图片信息。但是感受野的分布是不对齐的，同时卷积层使用重复的感受野会导致不同卷积边界的不真实感。</p><h3 id="网络的设计"><a href="#网络的设计" class="headerlink" title="网络的设计"></a>网络的设计</h3><p>超分辨率发展到今天，需有有效的网络结构得到了验证，例如残差学习，密集连接块。这些结构结合上面提到的四种框架能够组合出各种有效的网络结构。</p><h4 id="残差学习-（residual-Learning）"><a href="#残差学习-（residual-Learning）" class="headerlink" title="残差学习 （residual Learning）"></a>残差学习 （residual Learning）</h4><p><img src="/images/SR/residual-learning.png" alt=""></p><p>残差学习最早由何凯明的resNet提出，在超分辨率领域残差学习主要有以下两种结构：</p><p><strong>全局残差学习 global residual learning</strong></p><p>由于在SR问题中，网络通常是端到端的，输入的图片与输出的图片有着很大的相关性。因此有些研究者通过直接学习输入与输出之间的残差，在输入与输出之间连接一条high way达到这个目的。因此网络仅仅需要学习输入与输出之间的残差部分（图片中的高频部分数据）。由于残差网路中绝大多数的区域值接近零，因此在网络的学习过程中能够大大降低运算量，尤其在pre-upsample框架中。</p><p><strong>局部残差学习（local residual learning）</strong></p><p>局部残差学习与resNet中的残差模块类似，在缓解网络退化，改善网络的学习能力上具有很好的效果。</p><h4 id="递归学习（Recursive-Learning）"><a href="#递归学习（Recursive-Learning）" class="headerlink" title="递归学习（Recursive Learning）"></a>递归学习（Recursive Learning）</h4><p><img src="/images/SR/recursive-learning.png" alt=""></p><p>为了不引入过多的参数同时实现更大的感受野并学习更高级别的特征，递归学习（其是指以递归方式多次应用相同模块）被引入到超分辨率领域中。很多工作中引入卷积结构、残差结构作为递归块，均在performance上有比较好的表现。</p><p>很多学者提出了很多与递归块结合的网络结构，例如将一个大的缩放因子分解成很多子问题，然后用力对结构解决这些子问题；将image upsample作为递归块等等。由于递归块同样面临着梯度的消失和梯度爆炸的问题，因此很多残差学习，多监督学习通常也会被引入到地柜结构中，来解决这些问题。</p><h4 id="多路径学习（multi-path-learning）"><a href="#多路径学习（multi-path-learning）" class="headerlink" title="多路径学习（multi-path learning）"></a>多路径学习（multi-path learning）</h4><p>多路径学习将特征传入模型的不同分支中，每个分支有着不同的结构，以此来提高模型的超分能力。</p><p><strong>全局多路径学习 Global Multi-path Learning</strong></p><p>全局的多路径学习通过利用不同路径来学习图片中的不同特征，例如用一些分支学习一些亚频特征；学习visible特征；学习全局结构；学习低频或高频部分；用于upsample图片等等</p><p>这种思路能够提升网络的特征提取能力。</p><p><strong>局部的多路径学习（local multi-path learning）</strong></p><p>受到inception结构的影响，引入一个block，这个block中使用不同的路径，进行不同尺度的特征提取。如下图：</p><p><img src="/images/SR/local-path.png" alt=""></p><p>分别对feature map应用一个3X3和5X5大小的核，在不同的尺度上对特征进行提取。通过这种方式可以在不同尺度上对特征进行提取，能够有效的提升网络的性能。</p><p><strong>特定尺度的路径学习（scale-specific multi-path learning）</strong></p><p><img src="/images/SR/scale-specific.png" alt=""></p><p>由于多分辨率问题对图片的方法尺度不同，网络需要重新训练，但是网络结构都是相同的。这种策略就是保留网络的主干部分（结构以及参数），在网络的头部和尾部添加一个与尺度相关的预处理路径以及一个upsample路径，每次对于特定的分辨率需求，选择相关的路径，而网络的特征提取以及中间部分都得到了保留。</p><h4 id="密集连接块（Dense-Connections）"><a href="#密集连接块（Dense-Connections）" class="headerlink" title="密集连接块（Dense Connections）"></a>密集连接块（Dense Connections）</h4><p>只从密集连接块被提出之后，这种结构就广泛的应用在超分辨率领域，结构如下：</p><p><img src="/images/SR/1.png" alt="1"></p><p>该种结构将当前层之前的feature map都作为这一层的输入，能够有效的避免梯度消失，增强信号的传递、特征的复用等。此外还有很多结构是在块级上做密集的连接，该结构证明在超分辨率领域中同样有效。</p><h4 id="通道注意力机制（channel-attention）"><a href="#通道注意力机制（channel-attention）" class="headerlink" title="通道注意力机制（channel attention）"></a>通道注意力机制（channel attention）</h4><p>通道注意力机制目的是给不同的channel赋予不同的权重，不同的channel在超分辨率问题上的作用是不同的，作者使用“压缩激发模块（squeeze-and-excitation）”对不同通道进行权重的赋值。</p><p><img src="/images/SR/channel-atten.png" alt=""></p><p>作者通过一个全局pooling将image的size变成1 X 1 X C，然后通过两个卷积层，得到每一个channel的权重。然后对feature map重新赋值，得到赋予权重的feature map。</p><h4 id="先进的卷积层（advanced-convolution）"><a href="#先进的卷积层（advanced-convolution）" class="headerlink" title="先进的卷积层（advanced convolution）"></a>先进的卷积层（advanced convolution）</h4><p><strong>空洞卷积 dilated convolution</strong></p><p>空洞卷积即在原始的卷积的基础上加上空洞，目的是为了增加图片的感受野。</p><p><img src="/images/SR/dilate-conv.png" height="300"> </p><p>将这种卷积应用在超分辨率问题上也能够使得模型性能得到提升。</p><p><strong>分组卷积（group convolution）</strong></p><p>分组卷积的概念是对feature map进行分组（channel维度上的划分），按童谣的比例划分卷积核，然后将每个分组再进行卷积，最终将卷积结果组合成一个feature输出。这种卷积的方式大大减少了参数的计算量，在性能上仅仅下降了一点。</p><p><img src="/images/SR/group-conv.png" alt=""></p><h4 id="像素递归学习-pixel-recurisive"><a href="#像素递归学习-pixel-recurisive" class="headerlink" title="像素递归学习 pixel recurisive"></a>像素递归学习 pixel recurisive</h4><p>大多数的SR方法在处理图像时像素之间是独立的，无法得到像素间的相关性，因此一些学者提出pixel by pixel的生成器，通过两个网络，分别学习图像的纹理结构信息以及像素间的序列依赖关系来生成HR图像。这种方法在某些方面有一个比较好的效果，但是训练过程十分的困难，计算量比较大。</p><h4 id="金字塔pooling"><a href="#金字塔pooling" class="headerlink" title="金字塔pooling"></a>金字塔pooling</h4><p>引入金字塔模型能够有效的利用图片全局以及局部的特征，在EDSR-PP网络中使用金字塔模型能够有效的提升网络的精度。</p><h4 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h4><p>小波变换可以很方便的的将图片的信号分解成高频的纹理细节和低频的拓扑结构。将小波变换应用在超分辨率问题上，从低分辨率的图片中提取出低频信息作为输入，输出高分辨率的高频信息。</p><h3 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a>学习策略</h3><h4 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h4><p>​    在超分辨率领域，损失函数用来衡量生成的HR图片与原始的HR图片之间的差距，同时指导模型的优化。下面简要介绍一下存在的一些损失函数的形式。其中$\hat{I}$ 表示原始超分辨图像，$I$ 表示生成的超分辨率图像。</p><p><strong>像素级别的loss （pixel loss）</strong></p><p>对比GT与生成的图片在像素级别上的L1以及L2 loss：<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text {pixel_L1 }}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left|\hat{I}_{i, j, k}-I_{i, j, k}\right| \\<br>\mathcal{L}_{\text {pixel_L2}}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left(\hat{I}_{i, j, k}-I_{i, j, k}\right)^{2} \\<br>\end{aligned}<br>$$<br>L2 loss 相比较于L1 loss 来说，更加的惩罚比较大的误差，而对一些小的误差的容忍度更大。L1 loss在对性能和最终的收敛上比L2更好。对于指标PSNR来说，最小化pixel loss就可以达到最大化PSNR的目的。但是pixel loss没有将图片的质量考虑在内，因此生成的图片过于平滑，失去了高频的细节信息。</p><p><strong>满意度损失（content loss）</strong></p><p>基于感知的满意度损失，这个loss是一个L2 loss。他的不同点在于，我们将GT与生成的图片，分别输入一个欲训练好的分类网络中，取其高层特征（第$l$ 层）进行pixel wise上的loss计算。<br>$$<br>\mathcal{L}_{\text {content }}(\hat{I}, I ; \phi, l)=\frac{1}{h_{l} w_{l} c_{l}} \sqrt{\sum_{i, j, k}\left(\phi_{i, j, k}^{(l)}(\hat{I})-\phi_{i, j, k}^{(l)}(I)\right)^{2}}<br>$$<br>其中h,w,h是抽取出来的特征层的大小。</p><p>这个loss更加强调图片在生成上的相似性，最常用的分类网络是VGG，resNet。</p><p><strong>纹理损失（Texture Loss）</strong></p><p>一些文章认为图片的纹理由特征不同通道的相关性组成，定义为下面Gram matrix：<br>$$<br>G_{i j}^{(l)}(I)=\operatorname{vec}\left(\phi_{i}^{(l)}(I)\right) \cdot \operatorname{vec}\left(\phi_{j}^{(l)}(I)\right)<br>$$<br>上式中表示两个不同通道的向量的点乘结果。即第 $l$ 层特征向量的i通道和j通道的点乘结果。纹理损失依旧是L2损失，输入是生成图片和GT之间的纹理表示。<br>$$<br>\mathcal{L}_{\text {texture }}(\hat{I}, I ; \phi, l)=\frac{1}{c_{l}^{2}} \sqrt{\sum_{i, j}\left(G_{i, j}^{(l)}(\hat{I})-G_{i, j}^{(l)}(I)\right)^{2}}<br>$$<br>通过这种损失可以很好的得到较为真实的图片。但是仍然有一个难以解决的问题是，用于计算纹理损失的图片patch（方块，补丁）大小的确定依旧要根据经验来确定，太大或太小的patch使得生成的纹理不够真实。</p><p><strong>对抗损失（adversarial loss）</strong></p><p>我们使用一个SR模型作为生成器，另外我们需要定义一个判别器，下面的判别器D使用<strong>交叉熵</strong>来表示。生成器希望生成的样本判别器无法辨认，判别器希望能够鉴别出生成器生成的样本是假的。<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text {gan_ce_g}}(\hat{I} ; D) &amp;=-\log D(\hat{I}) \ <br>\mathcal{L}_{\text {gan_ce_d }\left(\hat{I}, I_{s} ; D\right)} &amp;=-\log D\left(I_{s}\right)-\log (1-D(\hat{I})) \\<br>\end{aligned}<br>$$<br>下面还有使用<strong>最小平方差</strong>最为判别器，能够得到更加真实的且高质量的结果。<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text{gan_ls_g}}(\hat{I} ; D) &amp;=(D(\hat{I})-1)^{2} \ <br>\mathcal{L}_{\text{gan_ls_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=(D(\hat{I}))^{2}+\left(D\left(I_{s}\right)-1\right)^{2} \end{aligned}<br>$$<br>下面是使用hinge loss形式的对抗损失：<br>$$<br>\begin{aligned} \mathcal{L}_{\text{gan_hi_g}}(\hat{I} ; D) &amp;=-D(\hat{I}) \ \mathcal{L}_{\text{gan_hi_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=\min (0, D(\hat{I})-1)+\min \left(0,-D\left(I_{s}\right)-1\right) \\<br>\end{aligned}<br>$$<br>使用对抗损失很大程度上带来的感知质量的提升，虽然PSNR指数有所下降，但是MOS指数有上升，取得了一个很好的视觉效果，生成的图片更加的真实。</p><p><strong>循环连续损失 （Cycle Consistency Loss）</strong></p><p>改损失受到循环GAN的启发，所用的网络不仅需要从LR到SR，还需要从SR到LR，重新生成的LR需要和输入一致，因此loss 如下：<br>$$<br>\mathcal{L}_{\text {cycle }}\left(I^{\prime}, I\right)=\frac{1}{h w c} \sqrt{\sum_{i, j, k}\left(I_{i, j, k}^{\prime}-I_{i, j, k}\right)^{2}}<br>$$<br><strong>总差异损失（total variation loss）</strong></p><p>这个算是是为了压制在生成图像过程中生成的噪声对图像质量产生的影响。他的loss有相邻像素的差异组合成。<br>$$<br>\mathcal{L}_{\mathrm{TV}}(\hat{I})=\frac{1}{h w c} \sum_{i, j, k} \sqrt{\left(\hat{I}_{i, j+1, k}-\hat{I}_{i, j, k}\right)^{2}+\left(\hat{I}_{i+1, j, k}-\hat{I}_{i, j, k}\right)^{2}}<br>$$<br><strong>基于先验损失（prior based loss）</strong></p><p>对于特定的数据，可以引入一下数据所特有的先验特征。通过这种先验特征可以很快的提升网络对这类数据恢复的性能。</p><h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>BN的提出是为了消除网络训练过程中内部参数的偏移问题。具体做法是对每一个bach做一个归一化操作，并且训练两个变量用于还原网络的表达能力。因此我们在训练过程中可以使用更高的学习率，以及不用太在意参数的初始化值。因此BN在SR网络中同样得到了广泛的应用。</p><p>但是有一些学者认为BN使得网络丧失了尺度信息，使得网络失去灵活度，同样有些网络中去除BN后，取得了一个很好的性能。</p><h4 id="课程学习-Curriculum-learning"><a href="#课程学习-Curriculum-learning" class="headerlink" title="课程学习 Curriculum learning"></a>课程学习 Curriculum learning</h4><p>渐进性的课程学习方法指的是网络从一个简单的任务出发，逐渐增加问题的难度，以此来得到一个鲁棒的模型。</p><p>超分辨率问题本质上是一个病态问题（ill-posed problem），即一些干扰对结果的影响非常的大，且系统十分不稳定，难以从结果反推回输入。这些干扰包括噪声，图片的模糊度，以及超分辨的倍数等等。</p><p>课程学习可以通过渐进学习的方式来解决这些问题，对于放大倍数很大（例如8）的任务，可以利用该思想，现训练简单的情况，例如可以先放大2，4，8倍来解决这个问题，这种方式能够大大缩短网络的训练时间，提升性能。</p><h4 id="多监督问题-（multi-supervision）"><a href="#多监督问题-（multi-supervision）" class="headerlink" title="多监督问题 （multi-supervision）"></a>多监督问题 （multi-supervision）</h4><p>多监督问题在loss 中增加一些变量，用来对某些信号进行监督，最终能够得到一个性能较好的模型。</p><h3 id="其他有用的方法"><a href="#其他有用的方法" class="headerlink" title="其他有用的方法"></a>其他有用的方法</h3><p><strong>context-wise network fusion</strong></p><p>这种方式使用多个不同结构的网络，分别进行超分辨率的训练，然后依次将这些训练结果通过卷积层组合最终的结果（SRCNN），使用这种方法能够也能够达到state of art的效果，同时效率也是可以接受的。</p><p><strong>data augmentation</strong></p><p>数据增强方面，常用于网络中的方法有random cropping, flipping,scaling,rotation, color jittering, 此外还有一个特殊的增强方式，random shuffle RGB,随机打乱RGB的颜色值，这种方法能够消除颜色带来的偏差。</p><p><strong>multi-task learning</strong></p><p>多任务学习指的是将多种任务于SR任务结合，例如语义分割网络于SR网络结合（SFT-GAN）等，将去噪声网络和SR网络结合（DNSR），这种方式能够提供数据的先验，能够更好的提升SR的效果。</p><p><strong>network interpolation</strong></p><p>网络的结合，将基于pxiel loss和基于感知loss的两种方法结合起来，得到一种中间状态的网络，这种网络同时在PSNR和真实感上有很好的表现。</p><h3 id="无监督的方法"><a href="#无监督的方法" class="headerlink" title="无监督的方法"></a>无监督的方法</h3><p>在超分辨率问题上，由于很难获得真实数据的超分辨率结果，因此 通常的做法是使用一个下采样方法，从超分辨率图像中得到他的低分辨率版本你，组成一个数据对，因此监督学习更像是学习这个方法的逆方法，人们通常忽略了提前定义好的下采样方法给数据带来的副作用。对于无监督方法来说，直接使用高分辨率的图片，更加符合现实中的场景。无监督方法上，目前仍然有很多值得探索的地方。</p><h4 id="zero-shot-super-resolution"><a href="#zero-shot-super-resolution" class="headerlink" title="zero-shot super-resolution"></a>zero-shot super-resolution</h4><p>这个方法训练了一个预测核函数直接针对每张图片都生成一个下采样（degradation）核方法，使用这个核方法来构造数据集，采用不同的缩放尺度得到测试数据，然后训练一个CNN网络来实现SR。由于这个模型需要为每一张图片构造一个函数，因此需要更多的时间。</p><h4 id="weakly-supervised-Super-resolution"><a href="#weakly-supervised-Super-resolution" class="headerlink" title="weakly-supervised Super-resolution"></a>weakly-supervised Super-resolution</h4><p>弱监督的学习方法有两个思路，第一种是不是用传统的HR-to-LR的退化函数，而是学习一个网络来实现这个过程，然后构造一个数据集，然后使用这个数据集来训练SR模型。另一种是cycle-in-cycle的方法，同时学习LR-to-HR和HR-to-LR两方面。</p><p><strong>learning degradation</strong></p><p>有学者提出了一个两个阶段的学习网络，提出一个GAN网络，学习HR to LR，用这个网络生成一个LR-HR配对的数据集，然后训练一个LR to SR的GAN网络使用上诉的数据集进行训练，最终结果能够显著提升数据恢复的真实性。</p><p><strong>cycle in cycle super resolution</strong></p><p>CinCGAN网络使用了四个生成器，两个判别器。生成器分别为noise LR -&gt; clean LR -&gt; clean HR，另外两个生成器进行反方向的生成。然后生成器用于判别生成了LR和SR的真实性，这其中引入了大量的损失函数，来保证这一过程的合理性。此外，这个方法还有很多改进的地方，来降低它训练的难度。</p><h4 id="图像的深度先验"><a href="#图像的深度先验" class="headerlink" title="图像的深度先验"></a>图像的深度先验</h4><p>使用一个随机初始化参数的CNN，对一张输入的图像，直接恢复他的超分辨率图像，仅仅利用CNN的结构先验来解决这个问题。模型的效果比传统的双线性插值要好些，但是效果不如其他监督方法，这种方法给我门提供了一种思路，仅仅利用一些手工制作的先验对图像进行超分辨率的恢复。</p><h3 id="领域相关的应用"><a href="#领域相关的应用" class="headerlink" title="领域相关的应用"></a>领域相关的应用</h3><h4 id="高光谱影像-（Hyperspectral-Image-Super-resolution）"><a href="#高光谱影像-（Hyperspectral-Image-Super-resolution）" class="headerlink" title="高光谱影像 （Hyperspectral Image Super-resolution）"></a>高光谱影像 （Hyperspectral Image Super-resolution）</h4><p>高光谱影像在视觉任务中有着很多的用途，但是由于硬件的约束，收集到高质量的高光谱数据是十分的困难的，高光谱数据的分辨率因此也十分的低。因此在高光谱数据领域应用超分辨率方法是很有前景的。</p><p>基于高光谱的超分辨率工作有以下几种：</p><p>W. Huang, L. Xiao, Z. Wei, H. Liu, and S. Tang, “A new pan- sharpening method with deep neural networks,” <em>GRSL</em>, vol. 12, 2015.</p><p>G. Masi, D. Cozzolino, L. Verdoliva, and G. Scarpa, “Pansharp- ening by convolutional neural networks,” <em>Remote Sensing</em>, vol. 8, 2016. Y.Wei,Q.Yuan,H.Shen,andL.Zhang,“Boostingtheaccuracyof multispectral image pansharpening by learning a deep residual network,” <em>GRSL</em>, vol. 14, 2017.</p><p>Y. Qu, H. Qi, and C. Kwan, “Unsupervised sparse dirichlet-net for hyperspectral image super-resolution,” in <em>CVPR</em>, 2018.</p><h3 id="未来的研究方向"><a href="#未来的研究方向" class="headerlink" title="未来的研究方向"></a>未来的研究方向</h3><h4 id="网络结构设计"><a href="#网络结构设计" class="headerlink" title="网络结构设计"></a>网络结构设计</h4><p><strong>结合图片局部和全局信息</strong>： 更大的感受野能够帮助网络获得更多图片的纹理细节。</p><p><strong>结合图片中的高低频数据：</strong>cnn网络的浅层部分能够获取图像的颜色和边界信息，深层网络能够获取图像的语义信息。</p><p><strong>纹理注意力机制：</strong>不同的纹理反应出来的细节特征是不同的，引入注意力机制能够增强图片的真实性。</p><p><strong>轻量级的结构：</strong>预测一张DIV2k的图片，EDSR模型需要花费20s，这是难以接受的，因此我们需要精简网络结构。</p><p><strong>上采样层：</strong>当前使用的上采样层均存在着不同程度的缺陷，提出一个好的上采样层，能够提升网络效能。</p><h4 id="学习策略-1"><a href="#学习策略-1" class="headerlink" title="学习策略"></a>学习策略</h4><p><strong>损失函数：</strong> 当前仍未找到一个很好的损失函数，能够兼顾感知和pixel wise</p><p><strong>Normalization：</strong>BN归一化方法十分花费时间，需要找到它的替代结构</p><h4 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a><strong>评价指标</strong></h4><p>当前的评价指标有PSNR，SSIM，MOS三种，其中PSNR容易生成过于平滑的图像，SSIM根据图片的光照，对比度，结构来评价，当时离人的感知还有一定距离，MOS与人的感知比较接近，但是统计起来十分的耗费人力及复杂。</p><h4 id="现实场景的使用"><a href="#现实场景的使用" class="headerlink" title="现实场景的使用"></a><strong>现实场景的使用</strong></h4><p>无监督学习方向上，可以学习一个degradation函数，用于数据的上采样，更符合现实数据的现状。</p><p>一些特定领域的应用方面，超分辨率可以作为整个流程的一部分。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些提升效率的方法</title>
      <link href="/2019/07/23/%E4%B8%80%E4%BA%9B%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2019/07/23/%E4%B8%80%E4%BA%9B%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h4 id="在word或ppt中插入公式"><a href="#在word或ppt中插入公式" class="headerlink" title="在word或ppt中插入公式"></a>在word或ppt中插入公式</h4><ol><li>使用mathpix snipper工具，从截图中获取latex公式。</li><li>进入这个网站：<a href="https://www.latex4technics.com/" target="_blank" rel="noopener">https://www.latex4technics.com/</a> </li><li>输入latex公式，在右下角转化为mathml格式。</li><li>打开word，插入公式。以纯文本的格式粘贴mathml代码，word自动转化为公式。</li><li>ppt中需要从word得到的公式复制过来，不支持直接转换。</li></ol><h4 id="使用jupyter链接服务器"><a href="#使用jupyter链接服务器" class="headerlink" title="使用jupyter链接服务器"></a>使用jupyter链接服务器</h4><p>jupyter有几个好处，他可以单步执行，单步调试。可以在浏览器上看执行的结果，包括图片的显示这些。当跑的代码比较简单，是测试功能的代码的时候，可以使用jupyter。</p><p>jupyter的配置：<a href="https://www.jianshu.com/p/4012f7149eb8" target="_blank" rel="noopener">jianshu.com/p/4012f7149eb8</a></p><p>用mac连接远程服务器：</p><ol><li>服务器端输入：jupyter notebook –no-browser –port=8898</li><li>本地输入：ssh<code></code>-N -f -L 127.0.0.1:8898:127.0.0.1:8898 zhouwenhui@remote-machine</li><li>最后在浏览器访问：<a href="http://127.0.0.1:8898/" target="_blank" rel="noopener">http://127.0.0.1:8898/</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xigua-支持向量机</title>
      <link href="/2019/07/21/xigua-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2019/07/21/xigua-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<p>支持向量机主要目的在于找到 一个位于两类训练样本的正中间，该分界面对样本的局部扰动的鲁棒性最好。通过该分界面能够最大限度的对数据进行分类。</p><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>xigua-神经网络</title>
      <link href="/2019/07/20/xigua-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2019/07/20/xigua-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>“神经网络是具有适应性的简单单元组成的广泛，并行互连的网络，能够模拟生物神经系统对真实世界物体所作出的交互反应。”</p><a id="more"></a><h3 id="神经网络的发展"><a href="#神经网络的发展" class="headerlink" title="神经网络的发展"></a>神经网络的发展</h3><p>1943年，神经网络模型最早是由心理学家和数理逻辑学家在提出的MP模型，它揭示了“大脑活动是靠脑细胞的组合连接实现的。”</p><p>1949年，心理学家Hebb提出 “脑细胞间某种通路在参与某种活动时被加强。” 用现在的观点来看这一说法，即我们可以通过调整网络参数（权重），来改善网络的性能。</p><p>1956年，达特茅斯会议上，明斯基，麦卡锡，西蒙等人首次提供人工智能的概念，使得人工智能在成为计算机科学的一个分支。</p><p>1962年，感知机模型正式提出，它具有输入层，输出层和中间层。</p><p>1969年，明斯基的《percetion》一书出版，指出感知机不能解决高阶谓词问题，人工智能发展陷入低谷。</p><p>1982年，hopfield向美国科学院提出了关于神经网络的报告，引起美国军方的注意，引起了神经网络的第二次高潮。在这次高潮中，hopfield网络，boltzmann机以及BP算法得到提出。</p><p>2006年之后，hiton提出深度学习，引起了神经网络的第三次浪潮。</p><h3 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h3><p>1943年提出的“M-P神经元模型”如下：</p><p><img src="../images/mp.png" alt=""></p><p>输入乘以权重之后，减去一个偏置$\theta$ ，然后通过激活函数，得到这个神经元的输出。在早期，使用的激活函数为sigmoid函数：</p><p><br>$$<br>\sigma(z)=\frac{1}{1+\mathrm{e}^{-z}}<br>$$<br>sigmoid函数如图：</p><p><img src="../images/xigua/sigmoid.png" alt=""></p><p>sigmoid 的导数形式如下：<br>$$<br>\sigma(z)’=\frac{\mathrm{e}^{-z}}{(1+\mathrm{e}^{-z})^{2}} = \frac{1+\mathrm{e}^{-z}-1}{(1+\mathrm{e}^{-z})^{2}} = \sigma(z)*(1 - \sigma(z))<br>$$<br>由于sigmoid的导数函数形式简单，取值变化范围在(0,1)之间。神经网络就是有无数个像这样的神经元结构组合而成的一个包含许多参数的数学模型。</p><h4 id="激励函数"><a href="#激励函数" class="headerlink" title="激励函数"></a>激励函数</h4><p>激励函数的作用是将无限域的变换指定到有限范围内进行输出。同时增加网络的非线性建模能力，复杂程度。</p><p>Bengio对激活函数有如下的定义：</p><blockquote><p>激活函数是映射h：R-&gt;R，且几乎处处可导。</p><p>具有软饱和函数的性质：$\lim_{s-&gt;\inf} f’(s) = 0$ ，软饱和性质只当x趋向去正无穷或负无穷的时候，函数的导数为0。硬饱和指存在一个区域c，当x接近c边缘时，导数值变为0.</p></blockquote><p><strong>ReLu激活函数：</strong>该激活函数能够在一定程度上克服梯度消失的问题。</p><p><img src="../images/xigua/relu.png" alt=""></p><p>relu在$x&lt;0$部分为硬饱和，导数为0。在$x&gt;0$部分，导数为1，<strong>能够保持网络梯度不衰减，缓解梯度消失问题。</strong> 当部分输入落入饱和区时，<strong>将导致网络的稀疏性，同时导致对应的权重无法更新（神经元死亡）。</strong>relu的输出同时具有偏移现象，即输出的值均值大于0，偏移与神经元死亡是其主要弊病。</p><h4 id="误差反向传播"><a href="#误差反向传播" class="headerlink" title="误差反向传播"></a>误差反向传播</h4><p>BP算法沿着负梯度方向减小误差，利用链式法则对每一个梯度求一个$\Delta$ 值，用于更新网络的参数。当网络陷入一个极小点时，在该点处不存在负梯度方向，因此参数无法进行更新。此时网络可能陷入局部极小点或全局最小点。</p><p>如果网络陷入局部极小点，我们希望在网络的训练过程中，函数能够跳出该极小点。可以使用的方法有 <strong>模拟退火法</strong>，即在每一步迭代，以一定的概率接受次优解，可以一定程度上避免陷入局部极小。 <strong>随机梯度下降法</strong>，每次选择部分数据进行梯度的计算，因此该梯度方向不一定是全局的下降方向，随着函数的迭代，网络误差可以慢慢降到一个可以接受的水平。</p><h4 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h4><p>深度学习模型是深层次的神经网络，通过增加网络的层次，提高网络的容量，使得它能学到更加复杂的问题。但是多层神经网络难以用传统的BP算法进行训练，因此后来的学者们也提出了许多其他的算法。</p><h3 id="神经网络的实现"><a href="#神经网络的实现" class="headerlink" title="神经网络的实现"></a>神经网络的实现</h3><h4 id="pytorch中的torch-nn包"><a href="#pytorch中的torch-nn包" class="headerlink" title="pytorch中的torch.nn包"></a>pytorch中的torch.nn包</h4><p>pytorch中关于网络结构的函数在torch.nn这个包里头，此外torch.nn.functional中也有于torch.nn对应的相关函数。他们的区别在于torch.nn中的参数是可训练的，可变的。torch.nn.functional中的函数是不可训练的，进行一些数学运算，类似于tensor于Variable的区别。因此搭建网络结构的时候使用torch.nn，激活函数则使用torch.nn.functional。</p><p>贴一个解释很清楚的文章：<a href="https://blog.csdn.net/hawkcici160/article/details/80140059" target="_blank" rel="noopener">https://blog.csdn.net/hawkcici160/article/details/80140059</a></p><h4 id="pytorch中的torch-autograd包"><a href="#pytorch中的torch-autograd包" class="headerlink" title="pytorch中的torch.autograd包"></a>pytorch中的torch.autograd包</h4><p><code>autograd.Variable</code>是包的中央类，包含一个张量，并支持几乎所有定义的操作，在完成计算后，调用<code>.backward()</code>并自动计算所有梯度。可以通过<code>.data</code>属性访问原始张量，而将此变量的梯度累加到<code>.grad</code>。</p><p>Variable类中比tensor类多了几个其他的属性：data,grad_fn,grad,variable变量可以用来计算梯度。</p><p>下面这个文章有有详细介绍：<a href="https://www.jianshu.com/p/cbce2dd60120" target="_blank" rel="noopener">https://www.jianshu.com/p/cbce2dd60120</a></p><p>可以用variable来定义网络的参数。</p>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>19/7/2019 preview</title>
      <link href="/2019/07/19/19-7-2019-preview/"/>
      <url>/2019/07/19/19-7-2019-preview/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> dialog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前缀树🌲:trie</title>
      <link href="/2019/07/17/%E5%89%8D%E7%BC%80%E6%A0%91%F0%9F%8C%B2-trie/"/>
      <url>/2019/07/17/%E5%89%8D%E7%BC%80%E6%A0%91%F0%9F%8C%B2-trie/</url>
      
        <content type="html"><![CDATA[<p>前缀树是一种存储数据的树形结构。是一种高效的检索字符串的方法，是一种多叉树的结构。它的插入与删除的效率比较高，时间复杂度为O(m).</p><a id="more"></a><h3 id="前缀树"><a href="#前缀树" class="headerlink" title="前缀树"></a>前缀树</h3><p>前缀树的结构如下图所示：</p><p><img src="../images/trie.png" alt="trie"></p><p>前缀树的结构特点为：</p><ol><li>根节点不包含字符，除根结点外，其他节点只包含一个字符</li><li>从根节点出发叶子结点，组成一个完整的字符串</li><li>每个节点包含的字符均不相同</li></ol><h3 id="前缀树的实现"><a href="#前缀树的实现" class="headerlink" title="前缀树的实现"></a>前缀树的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.res = &#123;&#125; </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Inserts a word into the trie.</span></span><br><span class="line"><span class="string">        :type word: str</span></span><br><span class="line"><span class="string">        :rtype: None</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                a[i] = &#123;&#125;</span><br><span class="line">            a = a[i]</span><br><span class="line">        a[<span class="string">'end'</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Returns if the word is in the trie.</span></span><br><span class="line"><span class="string">        :type word: str</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            a = a[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'end'</span> <span class="keyword">in</span> a:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startsWith</span><span class="params">(self, prefix)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Returns if there is any word in the trie that starts with the given prefix.</span></span><br><span class="line"><span class="string">        :type prefix: str</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> prefix:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            a = a[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># Your Trie object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = Trie()</span></span><br><span class="line"><span class="comment"># obj.insert(word)</span></span><br><span class="line"><span class="comment"># param_2 = obj.search(word)</span></span><br><span class="line"><span class="comment"># param_3 = obj.startsWith(prefix)</span></span><br></pre></td></tr></table></figure><p>上面代码用dict代替书的结构，一级一级的向下延展，前缀树由根节点往下，每一个节点的字节点就是他的key的数目，选择其中一个key，然后一级一级往下，当一个单词结束的时候，填入end作为终结符。</p>]]></content>
      
      
      
        <tags>
            
            <tag> — leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xigua:决策树</title>
      <link href="/2019/07/14/xigua-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2019/07/14/xigua-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<p>决策树是一类常见的机器学习算法，决策过程是基于树的结构进行的。叶子结点对应了树的决策结果，子节点对应了属性的测试（例如西瓜的颜色）。决策树的最终目的是产生一棵泛化能力强的树。</p><a id="more"></a><h3 id="决策树基本知识"><a href="#决策树基本知识" class="headerlink" title="决策树基本知识"></a>决策树基本知识</h3><h4 id="决策树子节点的生成"><a href="#决策树子节点的生成" class="headerlink" title="决策树子节点的生成"></a>决策树子节点的生成</h4><p>决策树的生成方式是一个递归的过程，有根结点开始，生成子节点的情况有下面三种：</p><ul><li>当前节点包含的样本全属于一个类别，无需划分</li><li>当前节点上所有样本的属性为空（例如缺失了身高这个数据），因此设置节点时，将该节点设置成样本中类别比例最大的那个。</li><li>当前节点所包含的样本集合为空时，采用样本的先验概率（例如身高为170的样本最多）来设置样本类</li></ul><h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p><strong>熵：</strong> entropy，希腊语原意为 <strong>内向性</strong>，<u>即一个系统不受外部干扰时，往内部最稳定状态发展的特性。</u> </p><p>熵同时可以作为<u>一个系统的混乱程度的度量</u>，即根据热力学第二定律，一个系统倾向于向增加混乱的程度发展，例如抛一枚硬币，最终的统计结果是正反面都是0.5的概率，对于预测来说，预测正面或者反面的不确定性都是最大的。</p><p><strong>信息熵：</strong> </p><p>信息熵是指接受数据中包含的信息量的平均值，是一种不确定性的度量，越随机的信源，熵越大。<strong>熵定义为概率分布的对数的相反数</strong>。也即是说，<u>当一个事件发生的可能性越小，当这个事件出现的时候，提供的信息就越多，不确定性越大，熵就越大。</u><br>$$<br>\mathrm{H}(X)=\mathrm{E}[\mathrm{I}(X)]=\mathrm{E}[-\ln (\mathrm{P}(X))]<br>$$<br>当数据取自有限样本是：<br>$$<br>\mathrm{H}(X)=\sum_{i} \mathrm{P}\left(x_{i}\right) \mathrm{I}\left(x_{i}\right)=-\sum_{i} \mathrm{P}\left(x_{i}\right) \log _{2} \mathrm{P}\left(x_{i}\right)<br>$$<br><strong>信息增益：</strong></p><p><u>信息增益指期望信息的有效减少量。</u>例如决策树，在一个分支上，选择一个属性进行划分，得到的信息增益越大证明划分结果不确定性越小，纯度越高。<br>$$<br>\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} E n t\left(D^{v}\right)<br>$$<br>然而信息增益趋向于选择分类更加细致的属性（分类越多，每一类的纯度也会越大），为了克服这个毛病，引入了信息增益率：<br>$$<br>g_{R}(D, A)=\frac{g(D, A)}{H_{A}(D)}<br>$$<br>其中：<br>$$<br>H_{A}(D)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|}<br>$$<br>信息增益率趋向于选择分类少的属性。（分类多，分母大）</p><p><strong>基尼指数：</strong></p><p>基尼指数比较直观，他反映了连续抽取两个样本，他们不一样的概率。因此越小表明纯度越纯。<br>$$<br>\operatorname{Gini}(\mathrm{p})=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}<br>$$<br>决策树缺失属性的处理情况：</p><ol><li>当属性缺失的情况下，选择最优的属性划分：可以修改信息增益函数，加上无缺失样本所占比例，无缺失样本中第k类所占比例，以及无缺失样本中某个属性所占比例等修正，得到划分的标准</li><li>当选定划分属性时，该属性缺失：将这些样本按照不同的概率，加入到所有的分支中</li></ol>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>xigua:线性模型(linear model)</title>
      <link href="/2019/07/14/xigua-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-linear-model/"/>
      <url>/2019/07/14/xigua-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-linear-model/</url>
      
        <content type="html"><![CDATA[<p>线性模型形式简单，易于建模，具有很好的解释性质。</p><a id="more"></a><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>线性模型试图学到一个通过属性的线性组合来进行预测的函数，线性模型将要学到下面的一个函数形式：<br>$$<br>f(x) = \omega^T x + b<br>$$<br>简单的来说，即通过训练数据 (x,y) 来学的线性模型的$\omega$ 和b，即可确定模型。</p><h3 id="线性模型-pytorch实现"><a href="#线性模型-pytorch实现" class="headerlink" title="线性模型 pytorch实现"></a>线性模型 pytorch实现</h3><p>在实现一个线性模型之前，我们首先确定一下算法实现的pipeline。</p><ul><li>数据准备：训练数据，label，以及测试数据的格式与读取形式。</li><li>模型的建立：模型类继承<code>torch.nn.Module</code>，实现其中的<code>__init__(),forward()</code>函数。</li><li>确定网络的criterion以及optimizer。</li><li>训练过程：每过一个step进行参数的更新。</li></ul><h4 id="数据准备部分"><a href="#数据准备部分" class="headerlink" title="数据准备部分"></a>数据准备部分</h4><p>在这个例子中，我们使用较为简单的数据作为输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0]]))</span><br><span class="line">y_data = Variable(torch.Tensor([[2.0],[4.0],[6.0]]))</span><br></pre></td></tr></table></figure><p>Vari3able 变量于Tensor的区别在于variable变量是可以计算梯度的，在梯度反向传播的时候进行梯度的计算。</p><h4 id="模型的建立"><a href="#模型的建立" class="headerlink" title="模型的建立"></a>模型的建立</h4><p>pytorch中模型类均需要继承一个父函数：<code>torch.nn.Module</code>.</p><p><code>torch.nn.module</code> 是所有网络的基类，我们定义的网络类，都需要继承自这个类。<code>torch.nn</code>这个类中包含各种网络层结构，linear，conv等等。对于我们的线性模型来说，我们可以定义一个网络类，然后在init中定义linear。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegressionModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义自己的网络需要继承torch.nn.Module类，实现其中的init以及forward方法:</span></span><br><span class="line"><span class="string">    torch.nn.Module:</span></span><br><span class="line"><span class="string">        torch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络</span></span><br><span class="line"><span class="string">        nn.Module是nn中十分重要的类,包含网络各层的定义及forward方法。</span></span><br><span class="line"><span class="string">        一般把网络中具有可学习参数的层放在构造函数__init__()中</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LinearRegressionModel,self).__init__()</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        线性模型：torch.nn.Linear(in_features,out_features,bias=True)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># one in one out</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure><h4 id="criterion-and-optimizer"><a href="#criterion-and-optimizer" class="headerlink" title="criterion and optimizer"></a>criterion and optimizer</h4><p>Criterion 即为网络训练过程中，输出的预测值与groundTruth之间的差距，通常在二分类问题上可以使用MSE loss，crossentropy等等。如<code>torch.nn.MSELoss()</code></p><p>Optimizer 可以使用<code>torch.optim.SGD(linear_model.parameters(),lr = 0.01)</code>。</p><h4 id="train"><a href="#train" class="headerlink" title="train"></a>train</h4><p>网络训练过程中，设置训练的次数，首先将数据传如入网络中，然后使用criterion求出输出与groundtruth之间的偏差。在每一次参数更新时，首先将梯度置零，然后进行梯度的向后传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">  pre = linear_model(x_data)</span><br><span class="line">  loss = criterion(pre,label)</span><br><span class="line">  <span class="comment"># 清空参数</span></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line">  loss.backgrad() <span class="comment"># 参数向后传播</span></span><br><span class="line">  optimzer.step()</span><br></pre></td></tr></table></figure><h4 id="evaluate"><a href="#evaluate" class="headerlink" title="evaluate"></a>evaluate</h4><p>网络测试部分比较简单，将输入输入网络中，得到其输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = linear_model(new_var)</span><br><span class="line">print(<span class="string">'result &#123;&#125;'</span>.format(result.data[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Something about keras</title>
      <link href="/2019/05/24/Something-about-keras/"/>
      <url>/2019/05/24/Something-about-keras/</url>
      
        <content type="html"><![CDATA[<h3 id="PART-I-keras-progress"><a href="#PART-I-keras-progress" class="headerlink" title="PART I : keras progress"></a>PART I : keras progress</h3><ol><li>prepare data,process data</li><li>create model,loss,optimizer</li><li>feed data to model,set hyperparamers</li><li>add some callbacks method</li><li>train and save model,save the log</li></ol><p>there is a example go through the process</p><h3 id="PART-II-data-prepare"><a href="#PART-II-data-prepare" class="headerlink" title="PART II:  data prepare"></a>PART II:  data prepare</h3><p> 生成数据部分，数据基本上是存储为coco，或csv格式。将数据从硬盘中读入内存。然后构造一个生成器，目的在于批量的（batch size大小）读出数据，预处理数据。生成器简单的使用如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_func</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):        </span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> generate_func():    </span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><p>另一种做法是实现类的<code>__next__()</code>方法，每次调用一次该类，即间接调用该方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generate</span><span class="params">(object)</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span> </span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        ... </span><br><span class="line">        data processing </span><br><span class="line">        <span class="keyword">return</span> batch_size data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># some layer in layers Dense,Dropout,Activation,Flatten</span></span><br><span class="line"><span class="comment"># cnn layer</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Convolution2D,MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils <span class="comment"># useful to transfrom data</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint <span class="comment"># save model</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> callbacks</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="comment"># prepare data</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">print(x_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="comment">#plt.imshow(x_train[0])</span></span><br><span class="line"><span class="comment"># tensorflow input(HxWxC)</span></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>],<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">x_test  = x_test.reshape(x_test.shape[<span class="number">0</span>],<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train = x_train.astype(<span class="string">'float32'</span>) /<span class="number">255</span></span><br><span class="line">x_test = x_test.astype(<span class="string">'float32'</span>) /<span class="number">255</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(x_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line"><span class="comment"># convert label to one hot</span></span><br><span class="line">print(y_train[:<span class="number">10</span>])</span><br><span class="line">y_train = np_utils.to_categorical(y_train,<span class="number">10</span>)</span><br><span class="line">y_test  = np_utils.to_categorical(y_test,<span class="number">10</span>)</span><br><span class="line">print(y_train[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">### define model</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 32,3,3 : output channel ,kernel_size</span></span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,activation = <span class="string">'relu'</span>,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line">print(model.output_shape)</span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size = (<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">### define loss and optimizer,and then compile it</span></span><br><span class="line">model.compile(loss = <span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment">#print(model.get_config())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># callback，when a epoch/batch_size start/end,it will be called</span></span><br><span class="line">checkpointer  = ModelCheckpoint(filepath=<span class="string">'best_model.h5'</span>,verbose=<span class="number">1</span>,save_best_only=<span class="keyword">True</span>)</span><br><span class="line">earlyStopping = callbacks.EarlyStopping(monitor=<span class="string">'loss'</span>,patience=<span class="number">20</span>,verbose=<span class="number">1</span>,mode = <span class="string">'auto'</span>)</span><br><span class="line">reduce_lr     = callbacks.ReduceLROnPlateau(monitor=<span class="string">'loss'</span>,factor = <span class="number">1</span>/math.e,verbose=<span class="number">1</span>,patience=<span class="number">10</span>,min_lr=<span class="number">0.0001</span>)</span><br><span class="line">tensorboard   = callbacks.TensorBoard(log_dir=<span class="string">'./log'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># write log to csv</span></span><br><span class="line">csv_historyger = callbacks.CSVLogger(<span class="string">'training.history'</span>,separator=<span class="string">','</span>,append=<span class="string">'True'</span>)</span><br><span class="line"><span class="comment">### feed data to the network</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#print('exist model')</span></span><br><span class="line"><span class="comment">#del model</span></span><br><span class="line"><span class="comment">#print('loading model ...')</span></span><br><span class="line"><span class="comment">#model = load_model('./best_model.h5')</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x_train,y_train,batch_size=<span class="number">32</span>,epochs=<span class="number">2</span>,verbose=<span class="number">1</span>,validation_data=(x_test,y_test),callbacks = [checkpointer,earlyStopping,reduce_lr,tensorboard,csv_historyger])</span><br><span class="line"></span><br><span class="line">score = model.evaluate(x_test,y_test,verbose=<span class="number">0</span>)</span><br><span class="line">print(score)</span><br><span class="line">print(history.history)</span><br><span class="line">print(history.epoch)</span><br><span class="line">print(history.history[<span class="string">'val_loss'</span>])</span><br></pre></td></tr></table></figure><p>数据读取部分主要读取csv文件的image name，以及annotation。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RetinaNet 原理记录</title>
      <link href="/2019/05/16/RetinaNet-%E5%8E%9F%E7%90%86%E8%AE%B0%E5%BD%95/"/>
      <url>/2019/05/16/RetinaNet-%E5%8E%9F%E7%90%86%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>RetinaNet作为一个one stage 的检测算法，通过对图片进行网格划分。在每个feature上选取anchor，然后对这些anchor进行边框回归以及类别的回归。</p><a id="more"></a><p>RetinaNet和大多数的one stage算法相同，直接对图片进行边框的回归，这导致了在一开始回归的时候，算法产生了大量的anticipate anchor（two stage 算法产生anchor的方式是通过region proposal的方式产生1k～2k的边框），这些anchor大部分都不包含object，即作者提到的easy negativate。 因此anchor导致了正负样本的不均衡。</p><p>正负样本不均衡主要有以下两个问题：</p><ol><li>在网络进行训练时，一些easy negativate 样本对loss不起作用，网络收敛速度很慢。</li><li>由于存在大量的easy negativate 样本，因此在loss回归的过程，easy negativate样本将会覆盖掉真正有益的收敛方向，导致模型精度下降。</li></ol><p>基于上面的分析，作者提出了一种对新型的loss，这种loss能够对不同的easy，hard样本进行权重的赋值。使得loss更加倾向于学习一些hard样本。</p><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>focal loss 由标准的cross entropy loss 演化而来，为了简单期间，我们从二分类的cross entropy入手，开始介绍：</p><p><img src="/images/article/ce.png" alt=""></p><p>从上面的loss可以看出来，当一个样本为正样本时，其预测值越高，CE loss就越小。但是这个loss对所有的anchor都同等对待，当一些样本p很大或很小的时候，基本可以断定它的类别，这些样本对边框回归，类别分类的时候，起到很小的作用，因此需要被忽略，但是CE loss无法突出这一点，因此RetinaNet的focal loss就是为了解决这个问题提出来的。</p><p><img src="/images/article/focal-loss.png" alt=""></p><p>当p很大时，即可以轻松判断这个anchor的类别的时候，1-p将取得一个较小的值，通过前面的参数，可以大大减小其对loss的影响。即降低了对简单样本的权重，同样的，对于难分样本来说，loss的形式可以增加其在loss中的权重。</p><h3 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h3><p>RetinaNet是作者为了验证这个loss的有效性而提出的。RetinaNet主要由一个resnet作为backbone，分类部分使用了FPN，特征金字塔的形式进行特征的分类。它的网络结构如下如所示：</p><p><img src="/images/article/retina-frame.png" alt=""></p><p>事实上，RetinaNet最终输出了五层feature map，在这五层feature map进行anchor的选取。</p><p>首先由Resnet 最后的三层C3，C4，C5产生P3，P4，P5，然后在C5的后面接着生成了P6，P7。</p><p>由于不方便画图，放一下keras retinanet的代码：<a href="https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/models/retinanet.py" target="_blank" rel="noopener">github</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__create_pyramid_features</span><span class="params">(C3, C4, C5, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Creates the FPN layers on top of the backbone features.</span></span><br><span class="line"><span class="string">    Args</span></span><br><span class="line"><span class="string">        C3           : Feature stage C3 from the backbone.</span></span><br><span class="line"><span class="string">        C4           : Feature stage C4 from the backbone.</span></span><br><span class="line"><span class="string">        C5           : Feature stage C5 from the backbone.</span></span><br><span class="line"><span class="string">        feature_size : The feature size to use for the resulting feature levels.</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">        A list of feature levels [P3, P4, P5, P6, P7].</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C5_reduced'</span>)(C5)</span><br><span class="line">    P5_upsampled = layers.UpsampleLike(name=<span class="string">'P5_upsampled'</span>)([P5, C4])</span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P5'</span>)(P5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C4_reduced'</span>)(C4)</span><br><span class="line">    P4           = keras.layers.Add(name=<span class="string">'P4_merged'</span>)([P5_upsampled, P4])</span><br><span class="line">    P4_upsampled = layers.UpsampleLike(name=<span class="string">'P4_upsampled'</span>)([P4, C3])</span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P4'</span>)(P4)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C3_reduced'</span>)(C3)</span><br><span class="line">    P3 = keras.layers.Add(name=<span class="string">'P3_merged'</span>)([P4_upsampled, P3])</span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P3'</span>)(P3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P6 is obtained via a 3x3 stride-2 conv on C5"</span></span><br><span class="line">    P6 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P6'</span>)(C5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6"</span></span><br><span class="line">    P7 = keras.layers.Activation(<span class="string">'relu'</span>, name=<span class="string">'C6_relu'</span>)(P6)</span><br><span class="line">    P7 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P7'</span>)(P7)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [P3, P4, P5, P6, P7]</span><br></pre></td></tr></table></figure><h3 id="anchor的设置"><a href="#anchor的设置" class="headerlink" title="anchor的设置"></a>anchor的设置</h3><p>在设置anchor的时候，作者选用了一下几种设置：</p><p>anchor-size = [32, 64, 128, 256, 512] 对应P3～P7</p><p>anchor—scale = [2 xx0 ，2 xx(1/3 )，2 xx (2/3)]</p><p>anchor-wh = [1:2 ，1 ，2:1]</p><p>每一层anchor的大小为anchor-size 乘以 anchor-scale。然后使用三种长宽比，每一层，每一个位置得到九种大小的anchor。随后对这些位置的anchor进行边框回归以及类别的回归。</p><h3 id="Loss-的形式以及计算"><a href="#Loss-的形式以及计算" class="headerlink" title="Loss 的形式以及计算"></a>Loss 的形式以及计算</h3><p>稍后补充</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 张量操作</title>
      <link href="/2019/05/12/pytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/"/>
      <url>/2019/05/12/pytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>在编写网络，传入传出数据时，对数据的维度的操作，把握是很重要的，因此这篇文章介绍一下pytorch在数据维度的改变上的一些方法。</p><a id="more"></a><p>对于两个数组来说，融合方式有很多种，最常见的是沿着横向融合以及沿着纵向融合。在方法的参数体现上：</p><blockquote><p>dim = 0 ：数据沿着纵向融合。</p><p>dim = 1： 数据沿着横向融合。</p></blockquote><p><em>torch.cat()</em></p><p>torch.cat 方法对数据沿着不同方向进行如何，dim参数决定了融合的方向，需要注意的是需要<strong>融合方向上维度需要一致</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((a,b),<span class="number">0</span>) <span class="comment"># 纵向</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((a,b),<span class="number">1</span>) <span class="comment"># 横向</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br></pre></td></tr></table></figure><p><em>torch.view()</em></p><p>torch.view 在保证数组个数不变的前提下，任意改变数组的形状（需要注意的是 -1参数表明在满足其他维度大小的需求后，该维度的大小）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">3</span>,<span class="number">-1</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br></pre></td></tr></table></figure><p><em>torch.squeeze()</em></p><p>压缩维度，使得为1的维度塌陷，维度缩减方向为dim = 0纵向，dim=1横向：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.squeeze(b,dim = <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.squeeze(b,dim = <span class="number">0</span>) <span class="comment">#纵向</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p><em>torch.Tensor.narrow()</em></p><p>删除元素的维度缩减方式，<code>torch.Tensor.narrow(dim,start,length)</code>,dim表示缩减的方向（0，1），start表示起始的位置，length表示保留维度的长度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">5.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.narrow(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">5.</span>, <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure><p><em>torch.Tensor.permute()</em></p><p>张量维度之间的顺序调换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">5.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">5.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIT</title>
      <link href="/2019/05/06/GIT/"/>
      <url>/2019/05/06/GIT/</url>
      
        <content type="html"><![CDATA[<p>github本质上是一个存储代码的工具，如果你暂时没有这个需求的话，其实可以不用在意这个东西，但是如果你在开发一个项目，希望将代码存在云上，并且实时更新与本地一致，那么github以及git操作就显得很重要了。（以上全是废话，ps：第一次以对话的方式写博客有点🦢慌）</p><p>下面教程从github上创建一个repository开始，重复一下比较常用的重要的git步骤 👇</p><a id="more"></a><h3 id="创建repository"><a href="#创建repository" class="headerlink" title="创建repository"></a>创建repository</h3><p>手动上github官网，可视化方式创建一个repository，并添加上REMEAD.md等。由于我正在做深度学习作业，因此下面都将以DL_HW repository为例。</p><h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><p><code>git clone git@github.com:WenHui-Zhou/DL_HW.git</code></p><p>通过上面语句将项目clone到本地（前提是安装了git）。然后接下来所有操作都将在这个DL_HW文件夹下进行操作。 </p><h3 id="添加-gitignore"><a href="#添加-gitignore" class="headerlink" title="添加.gitignore"></a>添加.gitignore</h3><p><code>.gitignore</code> 文件是用来告诉git什么文件不需要上传，比如你写了一个深度学习的作业，其中用到的数据集图片，就可以不需要上传。例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tmp       # 忽略文件夹</span><br><span class="line">*.jpg     # 忽略文件</span><br><span class="line">.DS_Store</span><br></pre></td></tr></table></figure><p>关于<code>.gitignore</code>还有很多灵活的用法，但是我是二八原则的拥护者，留下个链接表示一下：<a href="http://www.chengxusheji.com/archives/121.html" target="_blank" rel="noopener">gitignore 用法</a></p><h3 id="add-and-commit"><a href="#add-and-commit" class="headerlink" title="add  and commit"></a>add  and commit</h3><p>本地的git维护着三棵树，第一个是工作目录，即本地的DL_HW。第二个是缓冲区index，临时保存改动，第三个是head，保存最后一次的提交结果。</p><p><img src="../images/trick/git.png" alt="git"></p><p><code>git add *</code> : 将所有修改添加到index中去，保存零时改动。比如刚刚写了一个<code>.gitignore</code>文件，这条指令把它添加到index 上。</p><p><code>git commit -m &quot;代码提交信息&quot;</code>：将index中保存的改动提交到head上去。</p><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>前一步的操作仅仅是在本地进行的，并没有将代码真正的更新到GitHub上</p><p><code>git push origin master</code>： 将head上的改动提交到master分支上，也可以换成其他分支。</p><h3 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h3><p>老实说现在用不到，留着以后补充</p><h3 id="some-tip"><a href="#some-tip" class="headerlink" title="some tip"></a>some tip</h3><p>1.Git clone的时候会clone下来所有的历史内容，可以限制仅仅clone最近改动后的版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:WenHui-Zhou/DL_HW.git --depth=1</span><br></pre></td></tr></table></figure><p>2.当有多个机子clone了相同的项目，要保证本地的代码为最新的，需要如下操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master(分支可改)</span><br></pre></td></tr></table></figure><h3 id="last"><a href="#last" class="headerlink" title="last"></a>last</h3><p>分享一个很不错的 <a href="http://www.bootcss.com/p/git-guide/" target="_blank" rel="noopener">教程链接</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dog and cat -- USE tf.contrib.slim</title>
      <link href="/2019/05/06/dog-and-cat-USE-tf-contrib-slim/"/>
      <url>/2019/05/06/dog-and-cat-USE-tf-contrib-slim/</url>
      
        <content type="html"><![CDATA[<p>深度学习作业之一：猫狗分类。使用tensorflow的一个轻量级的库 <code>tf.contrib.slim</code>实现。</p><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>猫狗分类的数据可以从gaggle官网中下载：<a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" rel="noopener">数据链接</a></p><p>解压后发现文件分为train和val，但并没有label，它的label通过文件名来区分。</p><h4 id="将下载下来的猫狗图片转化为tfrecord格式"><a href="#将下载下来的猫狗图片转化为tfrecord格式" class="headerlink" title="将下载下来的猫狗图片转化为tfrecord格式"></a>将下载下来的猫狗图片转化为tfrecord格式</h4><p><strong><u>tf.record: 二进制格式文件</u></strong></p><blockquote><p>To read data efficiently it can be helpful to serialize your data and store it in a set of files (100-200MB each) that can each be read linearly. This is especially true if the data is being streamed over a network. This can also be useful for caching any data-preprocessing.</p><p>The TFRecord format is a simple format for storing a sequence of binary records.</p></blockquote><p>tensorflow使用其Dataset API来管理数据，将数据直接放在graph中进行处理，整体对数据集进行上述数据操作，使代码更加简洁。将图片，label转化为tf.record格式，方便大数据集的分批，快速读取，同时在进行数据预处理时简化代码，加快处理速度。</p><p>TFRecord 的核心内容在于内部有一系列的 Example ，Example 是 protocolbuf 协议下的消息体。定义了你需要的数据集的信息。</p><p><u><strong>protocolbuf：</strong></u></p><p><code>protocolbuf</code>是 <code>Google</code>出品的一种轻量 &amp; 高效的结构化数据存储格式，具体介绍可以看 <a href="https://www.jianshu.com/p/1538bf85dad1" target="_blank" rel="noopener">这里</a></p><p>即通过将结构化的数据进行<strong>序列化</strong>(转为二进制)，更小更易于维护。</p><p><strong>因此这一部分的目的就是将猫狗的数据，以及对应的label，重新生成为tf.record格式文件，随后使用tensorflow提供的API进行数据的读取。</strong></p><p>ps:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    filename = <span class="string">"%05d.txt"</span> % i</span><br><span class="line">    open(filename, <span class="string">"w"</span>)</span><br></pre></td></tr></table></figure><p>上面代码命名文件时，i长度不足10000时前面补0，保证长度为5。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux配置环境</title>
      <link href="/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
      <url>/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<p>linux 环境配置是一个很重要又很烦人的过程，下面简要记录一下环境变量配置的方法与原则。</p><h3 id="系统配置文件的加载顺序"><a href="#系统配置文件的加载顺序" class="headerlink" title="系统配置文件的加载顺序"></a>系统配置文件的加载顺序</h3><p>登入linux并启动一个bash shell，默认情况下这时候系统将会去寻找环境变量的设置文件，为环境变量赋值。系统环境文件读取顺序如下：</p><p><img src="/images/trick/linux_set.png" alt=""></p><p>用户登录系统后首先会加载<code>/etc/profile</code>全局环境变量文件，这是Linux系统上默认的shell主环境变量文件。系统上每个用户登录后都会加载这个文件。</p><p>之后执行<code>/etc/profile.d</code>目录下的所有脚本文件，完成一些字体，颜色的设置</p><p>之后开始运行<code>～/.bash_profile</code>(用户环境变量文件)，在这个文件中，又会去找<code>$~/.bashrc</code>（用户环境变量文件） 。在<code>$～/.bashrc</code>文件中又会去找<code>/etc/bashrc</code>（全局环境变量文件），若没有则不执行。</p><p>对于Vim的配置来说，在vim开启的时候将会对其进行一些基础的配置。全局配置一般在<code>/etc/vim/vimrc</code>或者<code>/etc/vimrc</code>，对所有用户生效。用户个人的配置在<code>~/.vimrc</code>，打开vim时自动执行。</p><h3 id="linux-bash查找执行的顺序"><a href="#linux-bash查找执行的顺序" class="headerlink" title="linux bash查找执行的顺序"></a>linux bash查找执行的顺序</h3><p>shell执行命令时将去linux系统中寻找指令的执行代码。寻找顺序如下</p><ol><li>别名，使用alias创建的命令</li><li>关键字，如if，for</li><li>函数</li><li>内置指令，如cd等等</li><li>外部指令，在PATH路径中寻找</li></ol><h3 id="Linux-系统目录结构"><a href="#Linux-系统目录结构" class="headerlink" title="Linux 系统目录结构"></a>Linux 系统目录结构</h3><p>​    <img src="/images/trick/content.png" alt=""></p><p>以前很多的环境变量配置不明白，就是由于不清楚linux的目录结构，以及每个文件的位置。</p><h4 id="bin"><a href="#bin" class="headerlink" title="/bin"></a>/bin</h4><p>普通用户可以使用的命令的存放目录，十分重要。例如cp，cd这种。类似的目录：/usr/bin，/usr/local/bin等等。这个目录中的文件都是可执行的。作为基础系统所需要的最基础的命令就是放在这里。</p><h4 id="lib"><a href="#lib" class="headerlink" title="/lib"></a>/lib</h4><p>此目录下包含系统引导和在根用户执行命令时候所必需用到的共享库。类似的目录还/usr/lib，/usr/local/lib。</p><h4 id="home"><a href="#home" class="headerlink" title="/home"></a>/home</h4><p>在Linux机器上，普通用户主目录通常直接或间接地置在此目录下。用户可以在自己的目录下保存仅对自己的配置文件，定制文件，文档，数据等。</p><h4 id="root"><a href="#root" class="headerlink" title="/root"></a>/root</h4><p>用户root的$HOME目录。</p><h4 id="etc"><a href="#etc" class="headerlink" title="/etc"></a>/etc</h4><p>全局的配置文件存放目录。系统和程序一般都可以通过修改相应的配置文件，来进行配置。类似的目录有 /usr/etc。用户也可以直接在HOME目录底下写配置文件，系统读取配置文件时，先读取HOME目录底下的文件，优先级最高。如果不存在配置文件的话，才去/etc下读取系统配置。</p><h3 id="usr"><a href="#usr" class="headerlink" title="/usr"></a>/usr</h3><p>安装程序的时候，默认就是安装在此文件内部某个子文件夹内。输入命令后系统默认执行/usr/bin下的程序。当然/usr/bin 需要加入PATH中。</p><h3 id="usr-local"><a href="#usr-local" class="headerlink" title="/usr/local"></a>/usr/local</h3><p>安装本地程序的一般默认路径。当我们下载一个程序源代码，编译并且安装的时候，如果不特别指定安装的程序路径，那么默认会将程序相关的文件安装到这个目录的对应目录下。例如，安装的程序可执行文件被安装(安装实质就是复制到了/usr/local/bin下面），/usr/local/include则用来存放文件。</p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>因此看到这里，环境变量的配置就是针对我们安装的第三方库，它们一般存在于/usr/下的目录中，因此PATH需要添加到/usr/的路径。此外还有一种情况，就是当安装一个库时，可能会修改掉系统的文件的软链接，导致之前系统很多库无法使用。此时的做法是在用户目录下，创建虚拟环境，在虚拟环境的进行环境的配置，将配置文件写在/home/.bashrc 等文件中即可。</p><p>上面泛泛而谈，还需要大量实践来查缺补漏。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>安装python3.7，同时保留python3.6，python2.7等：<a href="https://segmentfault.com/a/1190000015628625" target="_blank" rel="noopener">【链接】</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>shell 编程</title>
      <link href="/2019/04/10/shell-%E7%BC%96%E7%A8%8B/"/>
      <url>/2019/04/10/shell-%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>shell 编程中常见，常用的语法。</p><p>在日常Linux上编写代码，整理文件时发现，学一点shell语句能够大大加快工作效率，事不宜迟，开始学习！</p><a id="more"></a><h3 id="shell-简介"><a href="#shell-简介" class="headerlink" title="shell 简介"></a>shell 简介</h3><p>shell脚本通常是以：<code>#!/bin/bash</code> 开头的一个文件。/bin/bash是bash编译器的路径。</p><p>bash命令序列通常使用分号 <code>;</code> 或者换行符来表示。</p><p>终端的输出使用<code>echo</code> 来输出。下面是一个简单的shell脚本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo hello world</span><br></pre></td></tr></table></figure><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>shell中所有变量的类型都是<strong>字符串</strong>，且无需提前定义。此外shell中规定了一些<strong>环境变量</strong>来存储操作系统中一些特殊的值。</p><p><strong>变量的赋值：</strong> <code>val=“value”</code> ，切记等号前后没有空格。<code>val = value</code> 这种形式是判断相等的操作。</p><p>输出变量：<code>echo $val</code> 或 <code>echo ${val}</code></p><p><strong>环境变量：</strong> 定义在系统父进程中，用于系统的设置，如HTTP_PROXY用与设置代理服务器。</p><p><code>export</code> 命令可以用来设置环境变量，至此之后，shell脚本执行任何应用都会继承整个变量。</p><p>最常用接触到的环境变量为PATH，PATH变量通常包含以下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $PATH</span><br><span class="line">/home/zhouwenhui/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr /games</span><br></pre></td></tr></table></figure><p>PATH中路径根据 <code>:</code>  做为分割符，每当用户执行一条指令时，linux根据PATH中路径从前往后寻找可执行文件。PATH通常定义在 <code>/etc/environment</code> 或 <code>/etc/profile</code> 系统层次，或 <code>~/.bashrc</code> 这种用户层次上。可以通过一下方式，增加寻找的路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH="$PATH:/new/folder"</span><br></pre></td></tr></table></figure><p>补充trick：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat a.txt | tr 'replace' 'value'</span><br></pre></td></tr></table></figure><p>将输出中的replace替换成value。</p><p>字符串长度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var=1234</span><br><span class="line">length=$&#123;#var&#125;</span><br></pre></td></tr></table></figure><p><code>UID</code> 是用户类型的一个标示，root用户的UID是0.</p><h3 id="shell-数学计算"><a href="#shell-数学计算" class="headerlink" title="shell 数学计算"></a>shell 数学计算</h3><p><code>let</code> 语句可以直接执行基本的算术操作，在变量名前不需要添加$.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">no1=4;</span><br><span class="line">no2=5;</span><br><span class="line">let result=no1+no2</span><br><span class="line">let no1++;</span><br><span class="line">let no1--;</span><br><span class="line">let no1+=1</span><br></pre></td></tr></table></figure><p>操作符[ ] 使用方法与let类似：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result=[ $no1 + no2 ];</span><br></pre></td></tr></table></figure><p>上诉的指令只能用来进行整数操作，浮点数操作将使用到bc工具包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt; <span class="built_in">echo</span> <span class="string">"4 * 0.56"</span> | bc</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt; 2.24</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;result=<span class="string">'echo "$no1 * 1.5"|bc'</span></span></span><br></pre></td></tr></table></figure><h3 id="文件描述以及重定向"><a href="#文件描述以及重定向" class="headerlink" title="文件描述以及重定向"></a>文件描述以及重定向</h3><p>将输出内容保存到temp.txt中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "this string will be save" &gt; temp.txt</span><br></pre></td></tr></table></figure><p>追加内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "add to the file temp" &gt;&gt; temp.txt</span><br></pre></td></tr></table></figure><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr=(1,2,3,4,5,6)</span><br></pre></td></tr></table></figure><h3 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias new_command = 'command sequence'</span><br></pre></td></tr></table></figure><p>直接写入配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 'alias cmd="command seq"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function fname()</span><br><span class="line">&#123;</span><br><span class="line">    statements;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 调用</span></span><br><span class="line">fname; # 执行</span><br><span class="line"><span class="meta">#</span><span class="bash">传递参数</span></span><br><span class="line">fname arg1,arg2;</span><br><span class="line"></span><br><span class="line">fname()</span><br><span class="line">&#123;</span><br><span class="line">  echo $1; # 第一个参数</span><br><span class="line">  echo $2; # 第二个参数</span><br><span class="line">  echo $@; # 所有参数，"$1" "$2" ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for var in list;</span><br><span class="line">do</span><br><span class="line">    command</span><br><span class="line">done;</span><br></pre></td></tr></table></figure><h3 id="while-循环"><a href="#while-循环" class="headerlink" title="while 循环"></a>while 循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while condition;</span><br><span class="line">do</span><br><span class="line">    command</span><br><span class="line">done;</span><br></pre></td></tr></table></figure><h3 id="util语句"><a href="#util语句" class="headerlink" title="util语句"></a>util语句</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x=0;</span><br><span class="line">until [ $x -eq 9 ];</span><br><span class="line">do</span><br><span class="line">    let x++;</span><br><span class="line">    echo $x;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="逻辑运算，简短比较"><a href="#逻辑运算，简短比较" class="headerlink" title="逻辑运算，简短比较"></a>逻辑运算，简短比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ condition ] &amp;&amp; action; # 若condition成立则执行action</span><br><span class="line">[ condition ] || action; # 若condition不成立，则执行action</span><br></pre></td></tr></table></figure><h3 id="比较与测试"><a href="#比较与测试" class="headerlink" title="比较与测试"></a>比较与测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if condition;</span><br><span class="line">then</span><br><span class="line">    commands;</span><br><span class="line">else if condition; then;</span><br><span class="line">    commands;</span><br><span class="line">else</span><br><span class="line">    commands;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="算术比较"><a href="#算术比较" class="headerlink" title="算术比较"></a>算术比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ $var -eq 0 ] # 判断是否相同</span><br><span class="line">[ $var -ne 0 ] # 当var非0时为真</span><br></pre></td></tr></table></figure><ul><li>-gt：大于</li><li>-lt：小于</li><li>-ge：大于或等于</li><li>-le：小于或等于</li></ul><p>结合多个条件测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ $var1 -ne 0 -a $var2 -gt 2 ] # 使用逻辑与-a</span><br><span class="line">[ $var1 -ne 0 -o $var2 -gt 2 ] # 逻辑或 -o</span><br></pre></td></tr></table></figure><h3 id="文件属性测试"><a href="#文件属性测试" class="headerlink" title="文件属性测试"></a>文件属性测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ -f $file_name ] file_name是一个正常的文件</span><br><span class="line">[ -x $var ] var 是可执行文件</span><br><span class="line">[ -d $var ] var是目录</span><br><span class="line">[ -e $var ] var是文件</span><br><span class="line">[ -w $var ] var为可写文件</span><br><span class="line">[ -r $var ] var为可读文件</span><br></pre></td></tr></table></figure><h3 id="字符串的比较"><a href="#字符串的比较" class="headerlink" title="字符串的比较"></a>字符串的比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[ $str1 = $str2 ]] # 字符串比较最好放在双中括号中，判断相等</span><br><span class="line">[[ $str1 &gt; $str2 ]] # 判断字符串大小</span><br><span class="line">[[ -z $str1 ]]      # 字符串为空则为真</span><br><span class="line">[[ -n $str1 ]]      # 字符串非空则为真</span><br><span class="line">if [[ -n $str1 ]] || [[ -z $str2 ]];</span><br><span class="line">then</span><br><span class="line">    echo 'something'</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="执行Linux指令"><a href="#执行Linux指令" class="headerlink" title="执行Linux指令"></a>执行Linux指令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a=$(ls)</span><br><span class="line">for file in $a;</span><br><span class="line">do</span><br><span class="line">    if [ -f $file ];</span><br><span class="line">    then</span><br><span class="line">        echo 'afile'</span><br><span class="line">    else</span><br><span class="line">        echo 'not file'</span><br><span class="line">    fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="cat-拼接"><a href="#cat-拼接" class="headerlink" title="cat 拼接"></a>cat 拼接</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat file1 file2 file3</span><br><span class="line">cat -s file # 输出过滤掉多余的空行</span><br><span class="line">cat -T file # 显示制表符</span><br><span class="line">cat -n file # 显示行号</span><br></pre></td></tr></table></figure><h3 id="文件查找find"><a href="#文件查找find" class="headerlink" title="文件查找find"></a>文件查找find</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">find base_path # 找出所有bash_path 底下的所有文件名</span><br><span class="line">find . -name 'car*' # 找含特定字符的文件</span><br><span class="line">find . \( -name "*.txt" -o -name "*.pdf" \) # 匹配多个</span><br><span class="line">find /home/ -path "*/slynux/*" # 匹配路径以及文件名</span><br><span class="line">find . ! -name '*.txt' # 不找txt结尾的</span><br><span class="line">find . -maxdepth 1 -name 'f*' # 深度为1，只找当前目录</span><br><span class="line">find . -type d #将所有目录输出来 f为普通文件，l为软链接</span><br><span class="line">find . -type f -name "*.swp" -delete # 删除匹配的文件</span><br></pre></td></tr></table></figure><h3 id="find选项-exec-与其他指令结合使用"><a href="#find选项-exec-与其他指令结合使用" class="headerlink" title="find选项-exec 与其他指令结合使用"></a>find选项-exec 与其他指令结合使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -name <span class="string">".c"</span> -<span class="keyword">exec</span> &#123;&#125;\; <span class="comment">#&#123;&#125;将匹配所有的文件，然后执行</span></span><br><span class="line">find . -type f -name <span class="string">".jpg"</span> -<span class="keyword">exec</span> cp &#123;&#125; ./file/ \;<span class="comment"># 拷贝</span></span><br></pre></td></tr></table></figure><h3 id="玩转-xargs"><a href="#玩转-xargs" class="headerlink" title="玩转 xargs"></a>玩转 xargs</h3><p>xargs以标准的输入作为主要的数据流：<code>command| xargs</code>。xargs从stdin接收到的数据重新格式化，将其作为参数提供给其他指令。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VOC 数据集</title>
      <link href="/2019/04/09/VOC-%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2019/04/09/VOC-%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>本篇文章介绍VOC数据集的格式以及将CSV标注转化成CSV格式文件的方法。</p><a id="more"></a><h3 id="VOC-数据集"><a href="#VOC-数据集" class="headerlink" title="VOC 数据集"></a>VOC 数据集</h3><p>VOC 数据集可以从<a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="noopener">官网</a>下载，通常有</p><p>train： VOCtrainval_11-May-2012.tar，VOCtrainval_06-Nov-2007.tar</p><p>test：VOCtest_06-Nov-2007.tar</p><p>解压后得到的文件目录结构如下：</p><p>VOCDevkit:</p><ul><li>Annotations：存放着图片类别以及box信息,一张图片对应一个xml文件</li><li>ImageSets：里头有几个文件夹，目标检测问题只要关注Main，里头将保存训练集，测试集的图片名，用txt文件进行保存。</li><li>JPEGImages：保存着数据集图片</li><li>SegmentationClass</li><li>SegmentationObject</li></ul><p>对于目标检测问题关注以上三个文件夹就可以了。</p><hr><h3 id="将scv文件转化为voc格式"><a href="#将scv文件转化为voc格式" class="headerlink" title="将scv文件转化为voc格式"></a>将scv文件转化为voc格式</h3><p>csv格式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_url,x1,y1,x2,y2,label</span><br></pre></td></tr></table></figure><p>且同一张图片由于可能会有多个框，所以会有多条记录，代码需要完成图片的软链接建立，图片的命名，并建立新名字的txt文件，包括train和text。同时生成每张图片的xml。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> traceback <span class="keyword">import</span> print_exc</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_anno_xml</span><span class="params">(img,annos)</span>:</span></span><br><span class="line">    anno_folder = <span class="string">"./Annotations"</span></span><br><span class="line">    im = Image.open(<span class="string">'./JPEGImages/'</span> + img)</span><br><span class="line">    width, height = im.size</span><br><span class="line"></span><br><span class="line">    xml_file = open((anno_folder + <span class="string">'/'</span> + img.split(<span class="string">'.'</span>)[<span class="number">0</span>] + <span class="string">'.xml'</span>), <span class="string">'w'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'&lt;annotation&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;filename&gt;'</span> + img + <span class="string">'&lt;/filename&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;folder&gt;cartoon_VOC&lt;/folder&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;size&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;width&gt;'</span> + str(width) + <span class="string">'&lt;/width&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;height&gt;'</span> + str(height) + <span class="string">'&lt;/height&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;depth&gt;3&lt;/depth&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;/size&gt;\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> anno <span class="keyword">in</span> annos:</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;object&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;name&gt;'</span> + anno[<span class="number">-1</span>] + <span class="string">'&lt;/name&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;pose&gt;Unspecified&lt;/pose&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;truncated&gt;0&lt;/truncated&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;difficult&gt;0&lt;/difficult&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmin&gt;'</span> + anno[<span class="number">0</span>] + <span class="string">'&lt;/xmin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymin&gt;'</span> + anno[<span class="number">1</span>] + <span class="string">'&lt;/ymin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmax&gt;'</span> + anno[<span class="number">2</span>] + <span class="string">'&lt;/xmax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymax&gt;'</span> + anno[<span class="number">3</span>] + <span class="string">'&lt;/ymax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;/bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;/object&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'&lt;/annotation&gt;'</span>)</span><br><span class="line">    xml_file.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> [<span class="string">'train'</span>,<span class="string">'test'</span>]:</span><br><span class="line">    ftxt = open(file_name+<span class="string">'.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">    <span class="keyword">with</span> open(file_name+<span class="string">'_dataset.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        reader = csv.reader(f)</span><br><span class="line">        img     = <span class="string">''</span></span><br><span class="line">        pre_img = <span class="string">''</span></span><br><span class="line">        annos  = []</span><br><span class="line">        reader = list(reader)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> reader:</span><br><span class="line">            <span class="keyword">if</span> img != line[<span class="number">0</span>] <span class="keyword">and</span> img != <span class="string">''</span>:</span><br><span class="line">                <span class="comment"># ceate soft link</span></span><br><span class="line">                pos = line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>].find(<span class="string">'.'</span>)</span><br><span class="line">                img_id = <span class="string">'0'</span>*(<span class="number">5</span>-len(str(count)))+str(count)</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    os.symlink(line[<span class="number">0</span>],<span class="string">'JPEGImages/'</span>+img_id+line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>][pos:])</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    print(e.__class__.__name__)</span><br><span class="line">                    print_exc()</span><br><span class="line">                ftxt.write(img_id+<span class="string">'\n'</span>)</span><br><span class="line">                write_anno_xml(img_id+line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>][pos:],annos)</span><br><span class="line">                img   = line[<span class="number">0</span>] </span><br><span class="line">                annos.clear()</span><br><span class="line">                annos.append(line[<span class="number">1</span>:])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                img   = line[<span class="number">0</span>]</span><br><span class="line">                annos.append(line[<span class="number">1</span>:])</span><br><span class="line">            sys.stdout.write(<span class="string">'&#123;&#125;/&#123;&#125;\r'</span>.format(count,len(reader)))</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">    ftxt.close()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 基本语法</title>
      <link href="/2019/03/29/pytorch-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/"/>
      <url>/2019/03/29/pytorch-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>本篇文章将记录pytorch使用过程中的一些值得记录的trick。</p><a id="more"></a><h3 id="pytorch-基本工作流"><a href="#pytorch-基本工作流" class="headerlink" title="pytorch 基本工作流"></a>pytorch 基本工作流</h3><p>【0】引入必要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>【1】准备数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor(<span class="number">1.</span>,requires_grad=<span class="keyword">True</span>)</span><br><span class="line">x = torch.randn(<span class="number">10</span>,<span class="number">3</span>) <span class="comment"># 10*3的矩阵</span></span><br><span class="line">y = torch.randn(<span class="number">10</span>,<span class="number">2</span>) <span class="comment"># 10*2</span></span><br></pre></td></tr></table></figure><p>【2】网络搭建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义网络层，网络输入输出参数等等，下面使用pytorch内置的函数</span></span><br><span class="line"></span><br><span class="line">linear = nn.Linear(<span class="number">3</span>,<span class="number">2</span>) <span class="comment"># 搭建一个输入channel为3，输出channel为2的全连接网络</span></span><br><span class="line">print(linear.weight)    <span class="comment"># torch以及替我们定义好了参数</span></span><br><span class="line">print(linear.bias)</span><br></pre></td></tr></table></figure><p>【3】损失函数以及优化器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = nn.optim.SGD(linear.parameters(),lr = <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><p>【4】网络正向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred = linear(x)</span><br><span class="line"><span class="comment"># 计算loss</span></span><br><span class="line">loss = criterion(pred,y)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><p>这一点和tensorflow很不一样，tensorflow要先搭建好整个网络，然后将数据feed进去，pytorch则是动态构建网络图，边搭建网络边进行传值。</p><p>【5】网络后向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 后向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">print(<span class="string">'dl/dw'</span>,linear.weight.grad)</span><br><span class="line">print(<span class="string">'dl/db'</span>,linear.bias.grad)</span><br><span class="line"><span class="comment"># 使用optimizer的方式更新参数</span></span><br><span class="line">optimizer.step() <span class="comment"># 一次更新参数</span></span><br><span class="line"></span><br><span class="line">pred = linear(x)</span><br><span class="line">loss = criterion(pred,y) <span class="comment">## 重复上诉步骤直到完成参数拟合</span></span><br></pre></td></tr></table></figure><h3 id="torch与numpy相互转化"><a href="#torch与numpy相互转化" class="headerlink" title="torch与numpy相互转化"></a>torch与numpy相互转化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">4</span>]]) <span class="comment"># numpy.array</span></span><br><span class="line">y = torch.from_numpy(x)     <span class="comment"># torch.tensor</span></span><br><span class="line">z = y.numpy()               <span class="comment"># tensor to numpy</span></span><br></pre></td></tr></table></figure><h3 id="torch-导入数据的pipline（流程）"><a href="#torch-导入数据的pipline（流程）" class="headerlink" title="torch 导入数据的pipline（流程）"></a>torch 导入数据的pipline（流程）</h3><p>torchvision是torch中一个用于 <strong>生成图片，数据集，模型类，欲训练模型</strong>的包。它主要包含一下几个部分：</p><ol><li><strong>torchvision.datasets</strong>:  用于导入一些比较流行的开源数据集（cifar等）</li><li><strong>torchvision.models</strong>: 包含了很多流行的网络框架，包括alexnet，VGG，resnet，以及一下欲训练模型</li><li><strong>torchvision.transforms</strong>: 定义了一些常用的数据预处理的函数，如random crop，rotate等等</li><li><strong>torchvision.utils</strong>: 里头定义了很多好用的函数，如保存图片等</li></ol><h3 id="torchvision-datasets-的使用"><a href="#torchvision-datasets-的使用" class="headerlink" title="torchvision.datasets 的使用"></a>torchvision.datasets 的使用</h3><p>下载，导入数据，以及按一定的batch取出数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get the dataset</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">'.'</span>,train=<span class="keyword">True</span>,transform=torchvision.transforms.toTensor(),download = <span class="keyword">True</span>)</span><br><span class="line">image,label = train_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">loader = torch.utils.data.Dataloader(dataset = train_data,batch_size = <span class="number">64</span>,shuffle=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment">#每次load 一个大小为64的batch的数据</span></span><br><span class="line">train_iter = iter(loader)</span><br><span class="line">image,label = train_iter.next()</span><br></pre></td></tr></table></figure><h3 id="pytorch-训练minist数据集中的一些方法"><a href="#pytorch-训练minist数据集中的一些方法" class="headerlink" title="pytorch 训练minist数据集中的一些方法"></a>pytorch 训练minist数据集中的一些方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 读取数据</span></span><br><span class="line">train = torchvision.datasets.MNIST(root=<span class="string">'./'</span>,train=<span class="keyword">True</span>,transform=torchvision.transforms.ToTensor(),download = <span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># data loader</span></span><br><span class="line">data_loader = torch.utils.data.DataLoader(dataset = train,batch_size = <span class="number">100</span>,shuffle = <span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">for</span> image,label <span class="keyword">in</span> data_loader:</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> num_epoch:</span><br><span class="line">  <span class="keyword">for</span> i ,(image,label) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    output = model(image.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">    loss = criterion(output,label)</span><br><span class="line">    optimizer.zero_grad()  <span class="comment">#切记，在计算导数前要将导数置零</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> i+<span class="number">1</span> == <span class="number">100</span>:</span><br><span class="line">      print(<span class="string">'epoch:&#123;&#125;/&#123;&#125;,step:&#123;&#125;/&#123;&#125;,loss:&#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>,num_epochs,i+<span class="number">1</span>,total_step,loss))</span><br></pre></td></tr></table></figure><h4 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不算梯度</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  correct = <span class="number">0</span></span><br><span class="line">  total = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> image,label <span class="keyword">in</span> val_loader:</span><br><span class="line">    output = model(image.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">    _,predict = torch.max(output.data,<span class="number">1</span>)</span><br><span class="line">    total+= label.size(<span class="number">0</span>)</span><br><span class="line">    correct += (predict == label).sum().numpy()</span><br><span class="line">print(<span class="string">'accuracy: &#123;&#125;'</span>.format(correct/total))</span><br><span class="line">torch.save(model.state.dict,<span class="string">'model_param.ckpt'</span>)</span><br></pre></td></tr></table></figure><p>其中<code>val,index = torch.max(matrix,1)</code>，计算matrix中每一列的最大值，返回最大值以及他的下标。</p><h3 id="构建网络结构"><a href="#构建网络结构" class="headerlink" title="构建网络结构"></a>构建网络结构</h3><p>torch.nn 主要复制网络的构建，但是很多时候，torch.nn中不满足我们需要的网络，因此我们需要自己定义。<code>torch.nn</code>继承至<code>nn.Module</code>，<code>nn.Module</code>为所有网络的基类。当我们的网络类继承这个方法时，需要实现<code>__init__(),forward()</code>两个函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NerualNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,hidden_size,output_size)</span>:</span></span><br><span class="line">    super(NerualNet,self).__init__()</span><br><span class="line">    self.fc1  = nn.Linear(input_size,hidden_size)</span><br><span class="line">    self.ReLu = nn.ReLU()</span><br><span class="line">    self.fc2  = nn.Linear(hidden_size,output_size)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">    out = self.fc1(x)</span><br><span class="line">    out = self.ReLu(out)</span><br><span class="line">    out = self.fc2(out)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>调用时<code>model = NerualNet(input_size,hidden_size,output_size)</code>，每次使用<code>model(x)</code>即自动执行forward。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(in_channels,out_channels,kernel_size,stride=<span class="number">1</span>,padding=<span class="number">0</span>,dilation=<span class="number">1</span>,groups=<span class="number">1</span>,bias=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="构建一个sequence"><a href="#构建一个sequence" class="headerlink" title="构建一个sequence"></a>构建一个sequence</h3><p>sequence 将在其中的网络层从上到下连接上一层的输出作为下一层的输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of using Sequential</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># Example of using Sequential with OrderedDict</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">'conv1'</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">'relu1'</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">'conv2'</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">'relu2'</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure><h3 id="图片预处理集合"><a href="#图片预处理集合" class="headerlink" title="图片预处理集合"></a>图片预处理集合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Image preprocessing modules</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Pad(<span class="number">4</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor()])</span><br></pre></td></tr></table></figure><p>其中transforms.ToTensor()将 PIL image tensor (H, W, C) in range [0,255] to a torch.Tensor(C, H, W) in the range [0.0, 1.0]。</p><h3 id="pytorch-保存以及导入预训练参数"><a href="#pytorch-保存以及导入预训练参数" class="headerlink" title="pytorch 保存以及导入预训练参数"></a>pytorch 保存以及导入预训练参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet(residual,[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]).to(device)</span><br><span class="line">...</span><br><span class="line">torch.save(model,<span class="string">'model.ckpt'</span>) <span class="comment"># save the structure</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'model_para.ckpt'</span>) <span class="comment"># save the parameter</span></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = torch.load(<span class="string">'model.ckpt'</span>)</span><br><span class="line"><span class="comment"># 下面的resnet结构需要提前定义好 </span></span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'model_para.ckpt'</span>))</span><br></pre></td></tr></table></figure><h3 id="resent实现需要注意的地方"><a href="#resent实现需要注意的地方" class="headerlink" title="resent实现需要注意的地方"></a>resent实现需要注意的地方</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Residual block</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels, stride=<span class="number">1</span>, downsample=None)</span>:</span></span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(in_channels, out_channels, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(out_channels, out_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        <span class="keyword">if</span> self.downsample:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># ResNet</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        self.in_channels = <span class="number">16</span></span><br><span class="line">        self.conv = conv3x3(<span class="number">3</span>, <span class="number">16</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.layer1 = self.make_layer(block, <span class="number">16</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self.make_layer(block, <span class="number">32</span>, layers[<span class="number">1</span>], <span class="number">2</span>)</span><br><span class="line">        self.layer3 = self.make_layer(block, <span class="number">64</span>, layers[<span class="number">2</span>], <span class="number">2</span>)</span><br><span class="line">        self.avg_pool = nn.AvgPool2d(<span class="number">8</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">64</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_layer</span><span class="params">(self, block, out_channels, blocks, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        downsample = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> (stride != <span class="number">1</span>) <span class="keyword">or</span> (self.in_channels != out_channels):</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                conv3x3(self.in_channels, out_channels, stride=stride),</span><br><span class="line">                nn.BatchNorm2d(out_channels))</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.in_channels, out_channels, stride, downsample))</span><br><span class="line">        self.in_channels = out_channels</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(out_channels, out_channels))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.conv(x)</span><br><span class="line">        out = self.bn(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.layer1(out)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">        out = self.avg_pool(out)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>这段代码在结构设计上，将residual从整个网络中剥离出来。residual部分在resnet中多次使用，可以起到代码复用。这residual这一部分同样继承了nn.module，在resnet中进行调用。在整个网络反向求导的过程中，同样可以反向传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out = out.view(out.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="comment"># 即保持第一维不变，然后后面的所有的维度特征进行flatten展开。类似于reshape。</span></span><br><span class="line">out = out.shape(out.size(<span class="number">0</span>),<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>在对resent进行evaluate的时候，需要先执行<code>model.eval()</code>。这是因为bn，dropout这些操作在训练和测试的阶段不一样。</p><h3 id="pytorch中的LSTM的调用"><a href="#pytorch中的LSTM的调用" class="headerlink" title="pytorch中的LSTM的调用"></a>pytorch中的LSTM的调用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Recurrent neural network (many-to-one)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, num_layers, num_classes)</span>:</span></span><br><span class="line">        super(RNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=<span class="keyword">True</span>)</span><br><span class="line">        self.fc = nn.Linear(hidden_size, num_classes)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Set initial hidden and cell states </span></span><br><span class="line">        h0 = torch.zeros(self.num_layers, x.size(<span class="number">0</span>), self.hidden_size).to(device) </span><br><span class="line">        c0 = torch.zeros(self.num_layers, x.size(<span class="number">0</span>), self.hidden_size).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward propagate LSTM</span></span><br><span class="line">        out, _ = self.lstm(x, (h0, c0))  <span class="comment"># out: tensor of shape (batch_size, seq_length, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Decode the hidden state of the last time step</span></span><br><span class="line">        out = self.fc(out[:, <span class="number">-1</span>, :])<span class="comment"># 因为有许多层，只要最后一层</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>其中LSTM调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.LSTM(input_size,hidden_size,num_layers，batch_first=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># input_size 指输入的一个数据含有的特征数（维度）</span></span><br><span class="line"><span class="comment"># hidden_size 指隐藏输出具有的特征</span></span><br><span class="line"><span class="comment"># num_layer 指共有多少个LSTM层叠在一起</span></span><br><span class="line"><span class="comment"># batch_first 指LSTM输出的h和c第一个维度都为batch</span></span><br></pre></td></tr></table></figure><p>h：hidden</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h0 = torch.zeros(self,num_layers,x.size(<span class="number">0</span>),self.hidden_size)</span><br><span class="line"><span class="comment"># 指hidden处的参数</span></span><br><span class="line"><span class="comment"># num_layers值共有几层</span></span><br><span class="line"><span class="comment"># batch_size=x.size(0) 共有几个batch</span></span><br><span class="line"><span class="comment"># hidden_size: 输出的hidden特征数</span></span><br></pre></td></tr></table></figure><p>c：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c0 = torch.zeros(self.num_layers,x.size(<span class="number">0</span>),self.hidden_size)</span><br><span class="line"><span class="comment"># 参数与上相同</span></span><br></pre></td></tr></table></figure><p>调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out,(hn,cn) = self.lstm(x,(h0,c0))</span><br></pre></td></tr></table></figure><h3 id="一个较大项目的代码布局逻辑"><a href="#一个较大项目的代码布局逻辑" class="headerlink" title="一个较大项目的代码布局逻辑"></a>一个较大项目的代码布局逻辑</h3><p><code>train.py</code> : 程序开始执行的地方，作为整个项目的核心指挥，负责对个个部分进行调度。他的主要思路如下：</p><p>【1】通过argparse接受传入的各种配置参数，包括数据集的路径，model的存储路径等等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ = <span class="string">'__main__'</span>:</span><br><span class="line">  parse = argparse.ArgumentParser()</span><br><span class="line">  parse.add_element(<span class="string">'--model_path'</span>,type=str,default=<span class="string">'./models'</span>,help=<span class="string">'saving training model'</span>)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>【2】调用main() 函数，开始执行程序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先执行image progressing步骤，对图片进行预处理部分</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">  transforms.RandomCrop(args.crop_size),</span><br><span class="line">  trnasforms.RandomHorizontalFlip(),</span><br><span class="line">  ...</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># build data loader</span></span><br><span class="line"><span class="comment"># 此处实现了一个继承torch.utils.data.Dataset的数据集处理类，实现了__init__以及__getitem__。</span></span><br><span class="line">data_loader = get_loader(args.image_dir, args.caption_path, vocab,transform, args.batch_size,shuffle=<span class="keyword">True</span>, num_workers=args.num_workers) </span><br><span class="line"></span><br><span class="line"><span class="comment"># build the model</span></span><br><span class="line"><span class="comment"># 此处实现了一个model类，继承至nn.Module</span></span><br><span class="line">encoder = EncoderCNN(args.embed_size).to(device)</span><br><span class="line">decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示loss以及optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">    params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())</span><br><span class="line">    optimizer = torch.optim.Adam(params, lr=args.learning_rate)</span><br><span class="line">    </span><br><span class="line"><span class="comment">## train the model,通过data loader来产生数据</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(args.num_epochs):</span><br><span class="line">  <span class="comment"># 获取batch数据，进行训练以及预测</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD 复现</title>
      <link href="/2019/03/29/SSD-%E5%A4%8D%E7%8E%B0/"/>
      <url>/2019/03/29/SSD-%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>SSD是经典的one-stage目标检测框架，在速度和精度上都比Faster RCNN，YOLO（V1？）要更胜一筹。这次复现SSD作为理解网络以及学习pytorch的一个机会，这篇文章将尽可能的详细记录SSD的复现细节。（好大的flag🍐）</p><a id="more"></a><p>在复现SSD之前，我想就pytorch的两大部件进行一下介绍，分别是数据集模块（<code>torch.utils.data.Dataset</code>）以及网络模块(<code>torch.nn.Module</code>)。</p><h3 id="数据集模块"><a href="#数据集模块" class="headerlink" title="数据集模块"></a>数据集模块</h3><p> pytorch数据读取主要有三个类：</p><ul><li>Dataset </li><li>DataLoader </li><li>DataLoaderIter</li></ul><p>他们使用的方式为Dataset做为参数传入DatasetLoader中，DataLoader做为参数传入DataLoaderIter中。</p><p>因此完成pytorch数据集读取模块第一步要做的是：</p><p>【1】定义<strong>数据集类</strong>。</p><p><code>torch.utils.data.Dataset</code> 是一个抽象类，因此继承Dataset需要实现他的两个方法，<code>__len__()</code>，<code>__getitem__()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line">data_set = &#123;<span class="number">1</span>:<span class="string">'a'</span>,<span class="number">2</span>:<span class="string">'b'</span>,<span class="number">3</span>:<span class="string">'c'</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(data.Dataset)</span>:</span><span class="comment">#需要继承data.Dataset</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 1. Initialize file path or list of file names.</span></span><br><span class="line">        self.data = data_set</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># 每次读取一张图片以及对应的label，</span></span><br><span class="line">        <span class="comment"># 可以对图片进行一些flip等操作（torchvision.Transform).</span></span><br><span class="line">        <span class="comment"># 最终返回的是一个含有(image,label)的pair</span></span><br><span class="line">        <span class="comment"># 可以在init()函数的位置处生成csv_reader,或是一些list，集合</span></span><br><span class="line">        <span class="keyword">return</span> index, self.data[index]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data)</span><br></pre></td></tr></table></figure><p>对于这个Dataset这个类，只要实现了这两个函数，然后每次调用的的时候都能出来一个img，label，内部无论是list，generator都是可行的。</p><p>在<code>__getitem__()</code> 处可以执行一些图片变换等工作，torchvision.transforms中有着许多对图片的增强操作。常用的有<code>Resize</code> , <code>RandomCrop</code> , <code>Normalize</code> , <code>ToTensor</code> (这个<strong>极为重要</strong>, 可以把一个PIL或numpy图片转为<code>torch.Tensor</code>）</p><p>【2】定义dataLoader</p><p>dataLoader的定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False)</span><br></pre></td></tr></table></figure><p>其中<code>dataset</code>即上面定义的dataset，<code>batch_size</code>指一次调用该函数，输出的样本个数。<code>num_workers</code>指线程数，当大于等于1时就表示多线程。<code>collate_fn</code> 用于定制输出的batch，通过传入lambda表达式来实现，即当一张图片对应多个边框的时候，就需要进行图片以及边框的匹配。</p><p>dataLoader还实现了一个<code>__iter__()</code> 函数，这个函数输入为dataLoader，输出为dataLoaderIter，是一个迭代器。</p><p>具体使用如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset = CustomClass()</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">10</span>,...)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">  <span class="comment"># data[0]为图片</span></span><br><span class="line">  <span class="comment"># data[1]为标准</span></span><br><span class="line">  <span class="comment"># 共有10对</span></span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="网络结构模块"><a href="#网络结构模块" class="headerlink" title="网络结构模块"></a>网络结构模块</h3><p>pytorch 使用<code>nn.Module</code> 来构建网络，在pytorch中每一个网络层都是一个<code>nn.Module</code>类，并且类之间相互嵌套。<code>nn.Module</code>中有两个比较重要的部分，分别是</p><p><code>__init__()</code> ：完成逻辑模块的初始化。</p><p><code>forward()</code>：完成计算图的正向传递的过程。例如nn.Linear模块的定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinear</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">()</span>:</span></span><br><span class="line">    super(MyLinear,self).__init__()</span><br><span class="line">    </span><br><span class="line">    self.w = nn.Parameter(torch.randn(outp,inp))</span><br><span class="line">    self.b = nn.Parameter(torch.randn(outp))</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">    x = x @ self.w.t() + self.b</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>pytorch中提供了许多现成的类可供使用：</p><ul><li><code>nn.conV2d</code></li><li><code>nn.MaxPool2d</code></li><li><code>nn.ReLu</code></li><li><code>nn.BatchNorm2d</code></li></ul><p>同时<code>nn.Sequential</code>实现了一个序列，用来构建网络模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_size,out_size,kernel_size,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    nn.ReLu()</span><br><span class="line">   nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">  ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>输入将按照网络层从上到下进行参数的传递。</p><p>此外nn.Module类还会对网络的参数进行管理，<code>nn.parameters()</code>中将会保存着网络所有的参数。便于参数的管理。</p><p>我们可以使用nn.module构建许多的网络层，然后通过输入输出传值的方式将他们连成一个计算图。</p><p>下面将按照数据的读入，网络的搭建，网络的训练，以及效果的评估几个方面进行。</p><h3 id="SSD-复现"><a href="#SSD-复现" class="headerlink" title="SSD 复现"></a>SSD 复现</h3><p>参考<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="noopener">github链接</a>。</p><p><strong>【1】数据的准备</strong></p><p>数据集是一些由视频切帧而来的图片，一秒切一帧，对于每张图，由相应的标注信息，标注信息csv格式。通过读取csv数据集的方式，来完成数据的读取（github版本为使用pycocotool读取数据）。通过继承data.Dataset以及实现dataLoader的方式来获取数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># csv格式为：url,x1,y1,x2,y2,label</span></span><br><span class="line">TRAIN_ROOT = <span class="string">'./data/train_dataset.csv'</span></span><br><span class="line">VAL_ROOT   = <span class="string">'./data/val_dataset.csv'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detection_collate</span><span class="params">(batch)</span>:</span></span><br><span class="line">    targets = []</span><br><span class="line">    imgs    = []</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> batch:</span><br><span class="line">        imgs.append(sample[<span class="number">0</span>])</span><br><span class="line">        targets.append(sample[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> imgs,targets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">csv_loader</span><span class="params">(data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data_root,transform = transforms.ToTensor<span class="params">()</span>)</span>:</span></span><br><span class="line">        self.data_root  = data_root</span><br><span class="line">        self.dataset    = &#123;&#125;</span><br><span class="line">        self.imgs_index = &#123;&#125;</span><br><span class="line">        self.transform  = transform</span><br><span class="line">        self.index      = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> open(self.data_root,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> line[<span class="number">0</span>] <span class="keyword">in</span> self.dataset:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]].append(line[<span class="number">1</span>:<span class="number">5</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]] = [line[<span class="number">1</span>:<span class="number">5</span>],]</span><br><span class="line">                    self.imgs_index[self.index] = line[<span class="number">0</span>]</span><br><span class="line">                    self.index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        img_path = self.imgs_index[index]</span><br><span class="line">        label    = self.dataset[img_path]</span><br><span class="line">        img      = cv2.imread(img_path)</span><br><span class="line">        img      = self.transform(img)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(label)):</span><br><span class="line">            label[i][<span class="number">0</span>] = float(label[i][<span class="number">0</span>])</span><br><span class="line">            label[i][<span class="number">1</span>] = float(label[i][<span class="number">1</span>])</span><br><span class="line">            label[i][<span class="number">2</span>] = float(label[i][<span class="number">2</span>])</span><br><span class="line">            label[i][<span class="number">3</span>] = float(label[i][<span class="number">3</span>])</span><br><span class="line">        label  = np.array(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.index+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">dataset    = csv_loader(TRAIN_ROOT)</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">2</span>,collate_fn = detection_collate)</span><br><span class="line"><span class="keyword">for</span> img,label <span class="keyword">in</span> dataloader:</span><br><span class="line">    print(img)</span><br><span class="line">    print(label)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>如上，可以看出我们使用detection_collate方法来对每个batch size中读到的数据进行二次组织。</p><p>【2】网络的构建</p><p>数据已经准备好了，接下来要做的就是将网络搭建起来，然后将数据输入。</p><p>ssd的网络的backbone是vgg网络，利用vgg网络提取图片特征。</p><p>vgg的结构如下：</p><p><img src="./images/CNNnet/VGG16.png" alt=""></p><p>实现backbone的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">base = &#123;</span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'C'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>,</span><br><span class="line">            <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>],</span><br><span class="line">    <span class="string">'512'</span>: [],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="hard-negative-mining"><a href="#hard-negative-mining" class="headerlink" title="hard negative mining"></a>hard negative mining</h3><p>SSD 中对feature map位置的提取6个或4个边框，这些边框的尺寸由一些超参数决定。在进行网络训练之前，需要对生成的这些边框进行正负样本的标注，标注的标准在于这些边框与GT边框的IoU重合度，如果重合度大于0.5，则表示这个边框是证样本，小于0.3表示这个边框是负样本。</p><p>在对正负样本进行标注时，一般要保证正样本：负样本的个数为1:3。但是对于一张图片来说，其上大部分的框都是负样本，因此需要进行hard negative mining将一些得分较高的negative 做为hard negative。</p><p>hard negative mining一般是，有正负样本，然后分类器分出来一些分错的负样本（容易将负样本看成正样本的那些样本），即假阳性(false positive )，也就是说在对负样本分类时候，loss比较大（label与prediction相差较大）的那些样本，这些就是hard negative/困难样本，进行重新训练。</p><p>网络搭建部分主要继承nn.Module模块，继承init以及forward模块，实现网络结构的搭建，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python </span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录各层的channel</span></span><br><span class="line">base   = [<span class="number">64</span>,<span class="number">64</span>,<span class="string">'M'</span>,<span class="number">128</span>,<span class="number">128</span>,<span class="string">'M'</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="string">'C'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="string">'M'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>] <span class="comment"># M表示floor（边角舍弃）方式的Maxpooling，C表示ceil（补全）方式的Maxpooling</span></span><br><span class="line"><span class="comment"># vgg之后的各各层</span></span><br><span class="line">extras = [<span class="number">256</span>,<span class="string">'S'</span>,<span class="number">512</span>,<span class="number">128</span>,<span class="string">'S'</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>]</span><br><span class="line"><span class="comment">#每一层每个像素位置将取出的边框个数</span></span><br><span class="line">mboxes = [<span class="number">4</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(base,input_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    base: 各层的channel</span></span><br><span class="line"><span class="string">    input_channel：传入数据的维度</span></span><br><span class="line"><span class="string">    batch_norm：是否使用bn</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    这个函数主要使用一个list，将每一层的函数存储起来，用base来控制当前层是什么</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = input_channel</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> base:</span><br><span class="line">        <span class="keyword">if</span>   v == <span class="string">'M'</span>:<span class="comment"># 表示是一个maxpooling</span></span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">'C'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="keyword">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels,v,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d,nn.BatchNorm2d(v),nn.ReLU(inplace=<span class="keyword">True</span>)] <span class="comment"># inplace=True 指它将直接修改input的值，而不重新分配空间</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    pool5   = nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">    conv6   = nn.Conv2d(<span class="number">512</span>,<span class="number">1024</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">6</span>,dilation=<span class="number">6</span>)</span><br><span class="line">    conv7   = nn.Conv2d(<span class="number">1024</span>,<span class="number">1024</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">    layers += [pool5,conv6,nn.ReLU(inplace=<span class="keyword">True</span>),conv7,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(extras,in_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="comment"># extra layers added to vgg for feature scaling</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = in_channel</span><br><span class="line">    flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras):</span><br><span class="line">        <span class="keyword">if</span> in_channels!=<span class="string">'S'</span>:</span><br><span class="line">            <span class="keyword">if</span> v == <span class="string">'S'</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,extras[k+<span class="number">1</span>],kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag],stride=<span class="number">2</span>,padding=<span class="number">1</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,v,kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag])]</span><br><span class="line">            flag = <span class="keyword">not</span> flag</span><br><span class="line">        in_channels = v</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg,extras_layers,mbox,num_classes)</span>:</span></span><br><span class="line">    loc_layers  = []</span><br><span class="line">    conf_layers = []</span><br><span class="line">    vgg_source  = [<span class="number">21</span>,<span class="number">-2</span>] <span class="comment"># vgg的21层即conv4_3,和-2层即fc7</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(vgg_source):</span><br><span class="line">        loc_layers  += [nn.Conv2d(vgg[v].out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]           <span class="comment"># location 有四个参数</span></span><br><span class="line">        conf_layers += [nn.Conv2d(vgg[v].out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)] <span class="comment"># 类别预测将有class_num个数</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras_layers[<span class="number">1</span>::<span class="number">2</span>],<span class="number">2</span>):     <span class="comment"># 这里就是说取extras中奇数层，然后取bounding box，从第二层开始</span></span><br><span class="line">        loc_layers  += [nn.Conv2d(v.out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">        conf_layers += [nn.Conv2d(v.out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> vgg,extras_layers,(loc_layers,conf_layers)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">priorBox</span><span class="params">(obejct)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    在feature map上计算初始边框的坐标</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,cfg)</span>:</span></span><br><span class="line">        <span class="comment"># 将config中的一些超参赋值过来</span></span><br><span class="line">        self.image_size    = cfg[<span class="string">'min_dim'</span>]</span><br><span class="line">        self.num_priors    = len(cfg[<span class="string">'aspect_ratios'</span>])</span><br><span class="line">        self.variance      = cfg[<span class="string">'variance'</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]</span><br><span class="line">        self.feature_maps  = cfg[<span class="string">'feature_maps'</span>]</span><br><span class="line">        self.min_sizes     = cfg[<span class="string">'min_sizes'</span>]</span><br><span class="line">        self.max_sizes     = cfg[<span class="string">'max_sizes'</span>]</span><br><span class="line">        self.steps         = cfg[<span class="string">'steps'</span>]</span><br><span class="line">        self.aspect_ratios = cfg[<span class="string">'aspect_ratios'</span>]</span><br><span class="line">        self.clip          = cfg[<span class="string">'clip'</span>]</span><br><span class="line">        self.version       = cfg[<span class="string">'name'</span>]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Variances must be greater than 0'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">            mean = []</span><br><span class="line">            <span class="keyword">for</span> k ,f <span class="keyword">in</span> enumerate(self.feature_maps):</span><br><span class="line">                f_k = self.image_size / self.steps[k]</span><br><span class="line">                s_k = self.min_sizes[k] / self.image_size   </span><br><span class="line">                s_k_prime = sqrt(s_k*(self.max_sizes[k]/self.image_size))</span><br><span class="line">                <span class="keyword">for</span> i,j <span class="keyword">in</span> product(range(f),repeat=<span class="number">2</span>):</span><br><span class="line">                    <span class="comment"># unit center x,y</span></span><br><span class="line">                    cx  = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    cy  = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    <span class="comment">#aspect_ratio: 1</span></span><br><span class="line">                    mean += [cx,cy,s_k,s_k]</span><br><span class="line">                    mean += [cx,cy,s_k_prime,s_k_prime]</span><br><span class="line">                    <span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">                        mean += [cx,cy,s_k*sqrt(ar),s_k/sqrt(ar)]</span><br><span class="line">                        mean += [cx,cy,s_k/sqrt(ar),s_k*sqrt(ar)]</span><br><span class="line">            <span class="comment"># back to torch land</span></span><br><span class="line">            output = torch.Tensor(mean).view(<span class="number">-1</span>,<span class="number">4</span>)</span><br><span class="line">            <span class="keyword">if</span> self.clip:</span><br><span class="line">                output.clamp_(max=<span class="number">1</span>,min=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,phase,size,base,extras,head,num_classes)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        phase:  train,test</span></span><br><span class="line"><span class="string">        size:   ssd输入图片的大小，也即是版本把</span></span><br><span class="line"><span class="string">        base:   vgg的网络结构</span></span><br><span class="line"><span class="string">        extras: vgg之后的那些层</span></span><br><span class="line"><span class="string">        head:   loc，conf 的boxes</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(SSD,self).__init__()</span><br><span class="line">        self.phase       = phase</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.cfg         = (coco,voc)[num_classes == <span class="number">21</span>]  <span class="comment"># config.py 中对数据集的一些配置</span></span><br><span class="line">        self.priorbox    = PriorBox(self.cfg)</span><br><span class="line">        self.priors      = Variable(self.priorbox.forward(),volatile=<span class="keyword">True</span>)</span><br><span class="line">        self.size        = size</span><br><span class="line"></span><br><span class="line">        <span class="comment">## ssd net</span></span><br><span class="line">        self.vgg         = nn.ModuleList(base)</span><br><span class="line">        self.L2Norm      = L2Norm(<span class="number">512</span>,<span class="number">20</span>)</span><br><span class="line">        self.extras      = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        self.loc         = nn.ModuleList(head[<span class="number">0</span>])</span><br><span class="line">        self.conf        = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> phase == <span class="string">'test'</span>:</span><br><span class="line">            self.softmax = nn.Softmax(dim = <span class="number">-1</span>)</span><br><span class="line">            <span class="comment">## detection.py</span></span><br><span class="line">            self.detect  = Detect(num_classes,<span class="number">0</span>,<span class="number">200</span>,<span class="number">0.01</span>,<span class="number">0.45</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        sources = list()</span><br><span class="line">        loc     = list()</span><br><span class="line">        conf    = list()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg to conv4_3 relu</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        s = self.L2Norm(x)</span><br><span class="line">        sources.append(s)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg up to fc7</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>,len(self.vgg)):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply extra layers</span></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(self,extras):</span><br><span class="line">            x = F.relu(v(x),inplace=<span class="keyword">True</span>)</span><br><span class="line">            <span class="keyword">if</span> k%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                sources.append(x)</span><br><span class="line">        <span class="keyword">for</span> (x,l,c) <span class="keyword">in</span> zip(sources,self.loc,self.conf):</span><br><span class="line">            loc.append(l(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line">            conf.append(c(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line"></span><br><span class="line">        loc  = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> loc],<span class="number">1</span>)</span><br><span class="line">        conf = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> conf],<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self,phase == <span class="string">'test'</span>:</span><br><span class="line">            output = self.detect(</span><br><span class="line">                loc.vire(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                self.softmax(conf.view(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes)),</span><br><span class="line">                self.priors.type(type(x.data))</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output = (</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                conf,vire(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes),</span><br><span class="line">                self.priors</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span><span class="params">(self,base_file)</span>:</span></span><br><span class="line">        other,ext = os.path.splitext(base_file)</span><br><span class="line">        <span class="keyword">if</span> ext == <span class="string">'.pkl'</span> <span class="keyword">or</span> <span class="string">'.pth'</span>:</span><br><span class="line">            self.load_state_dict(torch.load(base_file,</span><br><span class="line">                                            map_location=<span class="keyword">lambda</span> storage,loc:storage))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'sorry wrong'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span><span class="params">(phase,size=<span class="number">300</span>,num_classes=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">'test'</span> <span class="keyword">and</span> phase != <span class="string">'train'</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    base_,extras_,head_ = multibox(vgg(base[str(size)],<span class="number">3</span>),add_extras(extras[str(size)],<span class="number">1024</span>),</span><br><span class="line">                                  mbox[str(size)],num_classes)</span><br><span class="line">    <span class="keyword">return</span> SSD(phase,size,base_,extras_,head_,num_classes)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 论文复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手撕mAP</title>
      <link href="/2019/03/22/%E6%89%8B%E6%92%95mAP/"/>
      <url>/2019/03/22/%E6%89%8B%E6%92%95mAP/</url>
      
        <content type="html"><![CDATA[<p>mAP在很多检测任务中使用十分频繁，微软的COCO数据集专门提供了一套API，实现预测模型的mAP计算（pycocotools），本篇文章打算用最原始的方式手撕mAP，希望使得对整个指标更好的理解。文章参考Retina-net，并在其基础上进行修改。</p><a id="more"></a><h3 id="mAP是什么？"><a href="#mAP是什么？" class="headerlink" title="mAP是什么？"></a>mAP是什么？</h3><p><strong>mAP</strong>： mean Average Precision, 即各类别AP的平均值，例如COCO数据集，共有80+1类（背景），对每一个类别的物体求一个AP，mAP即为所有目标AP的平均值。</p><p><strong>AP</strong>：AP为PR曲线（precision-recall）与x轴围成的面积</p><p><strong>Pricision</strong>：TP/（TP+FP），即预测为真（预测结果放后面即TP）当中，真正为真的比例。</p><p><strong>Recall</strong>：TP/（TP+FN），即预测为真当中真正为真的个数，占所有样本中真个数的比例。</p><p>对于TP，FP，TN，FN表示四种情况，其中T，F是从结果来看，是否预测正确。P，N则是从预测来看，预测正误。</p><p><strong>TP</strong>：预测是对的，预测样本结果为真。该类样本的个数</p><p><strong>FP</strong>：预测是错的，预测样本为真。该类个数。</p><p><strong>TN</strong>：预测是对的，预测样本为假。该类个数。</p><p><strong>FN</strong>：预测是错的，预测样本为假。该类个数。</p><p><strong>真假鉴定：</strong>当预测边框与GT的边框重合程度，PASCAL数据集中，认为IoU大于0.5认为是真，小于0.5认为是假。</p><p><strong>IoU：</strong>预测边框与GT边框的 重叠面积/两个边框并集</p><p><strong>mAP-IoU[0.5, 0.95]</strong>：COCO要求IOU阈值在[0.5, 0.95]区间内每隔0.05取一次，将这个IoU作为真假边框的评判边界。可以计算出10个IoU下的mAP值，然后这10个还要再做平均，即为最后的mAP。</p><h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><p>指标虽然很多，但是都是很简单的指标，耐心的理解一下，也不辛苦的。看完上面的指标有几个疑问：</p><ol><li>IoU计算的时候需要边框与GT对应起来，每个GT对应一个边框后不再参与后面边框的匹配。那么与哪个GT边框对应呢，这是个问题？<strong>（置信度+IoU最大）</strong></li><li>AP在计算的时候需要计算AP曲线下方的面积，这个该怎么算呢？</li><li>计算precision，recall的时候需要每个类单独算，然后用于之后算AP，感觉是几个循环，外循环是个遍历类别，内循环对每个预测边框做一下循环，具体怎么实现呢？</li></ol><h3 id="实作"><a href="#实作" class="headerlink" title="实作"></a>实作</h3><p>这一部分将按照输入数据，数据处理，计算IoU，计算Precision，Recall，计算AP等步骤。</p><p><strong>预测结果数据</strong>：假设经过模型预测得到一个csv格式的预测结果，格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/<span class="number">1.j</span>pg,<span class="number">10</span>,<span class="number">78</span>,<span class="number">25</span>,<span class="number">34</span>,face,<span class="number">0.9</span></span><br></pre></td></tr></table></figure><p>分别是图片的位置，预测的边框（左上）（x,y,w,h)，label，以及置信度。</p><p><strong>GT数据</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/<span class="number">1.j</span>pg,<span class="number">15</span>,<span class="number">80</span>,<span class="number">30</span>,<span class="number">32</span>,face</span><br></pre></td></tr></table></figure><p>分别是图片的位置，边框位置以及标签。</p><p><strong>数据处理：</strong></p><p>为了更好的计算每一个类别预测的precision以及recall，直觉上来说，应该需要一个比较好的格式方便计算，我们可以将这种格式设置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_detections = [img_index][label][box_index]</span><br></pre></td></tr></table></figure><p>意思为每一个图片，对应若干个label（例如一张图上对应桌子，人），每个label对应若干个边框，（例如一张图片中有多个人）。</p><p>因此第一步需要把csv格式的数据转换为上面的格式，在转换之前需要借助道dcit字典。目的是为了对相同的图片的label。boxes进行汇总。dict的格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  img1:&#123;label1:[[box1],[box2]...],label2:[[box1],[box2]...]..&#125;</span><br><span class="line">  img2:&#123;label1:[[box1]]&#125;</span><br><span class="line"> ]</span><br></pre></td></tr></table></figure><p>即外围是一个list[],保存每一张图片的信息。每个图片是一个字典，key为图片名，val是另一个保存label和boxes的字典，这个字典的key为label名，val为多个boxes的list结构。</p><p>下面代码是读取csv文件，并将数据转化为上诉格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">img_name = &#123;&#125;     <span class="comment"># imgId: 1</span></span><br><span class="line">boxes_label_scores = &#123;&#125; <span class="comment"># imgId: [[x,y,w,h,score],...]</span></span><br><span class="line">class_num = <span class="number">1</span> <span class="comment"># 表示类别个数</span></span><br><span class="line"></span><br><span class="line">pre_gt_csv = <span class="string">'score_mintest.csv'</span></span><br><span class="line">   </span><br><span class="line"><span class="keyword">with</span> open(pre_gt_csv,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">   reader = csv.reader(f)</span><br><span class="line">   lines = list(reader)</span><br><span class="line">   <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">       <span class="keyword">if</span> len(line) &lt; <span class="number">7</span>:</span><br><span class="line">            line.append(<span class="string">'1'</span>) <span class="comment"># 当为GT的时候，最后需要添上置信度为1</span></span><br><span class="line">       <span class="keyword">if</span> float(line[<span class="number">-1</span>]) &lt; score_threshold:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">       <span class="keyword">if</span> line[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> img_name.keys():</span><br><span class="line">            img_name[line[<span class="number">0</span>]] = <span class="number">1</span></span><br><span class="line">            temp = line[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">            temp.append(line[<span class="number">-1</span>])       <span class="comment"># [x,y,w,h,score]</span></span><br><span class="line">            box_dict = &#123;&#125;</span><br><span class="line">            box_dict[line[<span class="number">5</span>]] = [temp]  <span class="comment"># label:[[],[]]</span></span><br><span class="line">              <span class="comment">#&#123;img: &#123;label_name:[x,y,w,h,socre],[x2,y2,w2,h2,score2]...&#125;,img:&#123;...&#125;.. &#125;</span></span><br><span class="line">            boxes_label_scores[line[<span class="number">0</span>]] = box_dict</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># the image is exist</span></span><br><span class="line">            temp = line[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">            temp.append(line[<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> line[<span class="number">5</span>] <span class="keyword">in</span> boxes_label_scores[line[<span class="number">0</span>]].keys():</span><br><span class="line">                boxes_label_scores[line[<span class="number">0</span>]]    [line[<span class="number">5</span>]].append(temp)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                boxes_label_scores[line[<span class="number">0</span>]][line[<span class="number">5</span>]] = [temp]</span><br></pre></td></tr></table></figure><p>在进行边框对比的时候，我们希望对置信度高的边框提前进行IoU的判断，因此对boxes_label_scores中的boxes进行置信度的排序<strong>(解决第一个问题)</strong>，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> boxes_label_scores:</span><br><span class="line">    labels = boxes_label_scores[img]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels.keys():</span><br><span class="line">        boxes = boxes_label_scores[img][label]</span><br><span class="line">        boxes = sorted(boxes,  key=<span class="keyword">lambda</span> x: float(x[<span class="number">-1</span>]),reverse=<span class="keyword">True</span>)</span><br><span class="line">        boxes_label_scores[img][label] = boxes</span><br></pre></td></tr></table></figure><p>由于上面字典的结构，key与label均为真实值，然后我们希望用all_detections这个list的结构来代替，因此需要引入图片与下标，label与下标的一一对应关系。</p><p><strong>图片与下标对应：</strong>我们对测试集中读取的图片从上到下，依次进行计数。该数对应该图片的Id（切记，在进行GT比较时，顺序不能乱）。</p><p><strong>label与下标对应：</strong> 将其转化为下标，从0开始一次进行计数。</p><p>也可以专门生成一张数字与图片，数字与类别一一对应的表格，比较直观。上诉方法则比较方便，但是容易混乱。因此将字典结构赋值给三重数组代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all_detections : [img1[label1],[label2]..] ; img2: label1,label2...</span></span><br><span class="line">all_detections = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> boxes_label_scores[img].keys()] <span class="keyword">for</span> img <span class="keyword">in</span> boxes_label_scores.keys()]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#inds_keys = list(img_name.keys()) # [img1,img2,...n-1]</span></span><br><span class="line">inds = img_name.keys() <span class="comment"># 充当图片的id，与图片一一对应</span></span><br><span class="line"><span class="comment"># ind与图片路径一一对应</span></span><br><span class="line"><span class="keyword">for</span> ind,img <span class="keyword">in</span> (enumerate(inds)): <span class="comment"># 每次得到img_name 即图片路径</span></span><br><span class="line">    <span class="comment"># index 与label一一对应</span></span><br><span class="line">    <span class="keyword">for</span> index,label <span class="keyword">in</span> enumerate(boxes_label_scores[img].keys()):</span><br><span class="line">        all_detections[ind][index] = boxes_label_scores[img][label]     <span class="comment">## ind为图片，index为类别，从0开始</span></span><br><span class="line"><span class="keyword">return</span> all_detections</span><br></pre></td></tr></table></figure><p><strong>计算precision，recall</strong></p><p>生成数据之后需要根据数据去计算TP，FP，TN，FN等参数。一个直观的想法就是大循环是个label，然后每次算出一个类的AP之后，保存一下，循环结束了算一个平均。</p><p>计算precision即计算预测边框中真正预测对的部分占预测为真的个数。计算recall即计算预测边框中TP与总的GT的比例。因此我们以label为大循环，一次去遍历每一张图片，然后去更新TP，FP的值。如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">inds = list(range(len(img_name.keys()))) <span class="comment"># 充当图片的id，与图片一一对应</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(class_num): <span class="comment"># </span></span><br><span class="line">        false_positives = np.zeros((<span class="number">0</span>,))  <span class="comment"># precision = TP/（TP+FP）Recall = TP/（TP+FN）</span></span><br><span class="line">        true_positives  = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        scores          = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        num_annotations = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> inds:</span><br><span class="line">            detections           = all_detections[i][label]   <span class="comment"># image：i，class：label</span></span><br><span class="line">            annotations          = all_annotations[i][label]</span><br><span class="line">            num_annotations     += len(annotations)   <span class="comment">#.shape[0]       # boxes的个数</span></span><br><span class="line">            detected_annotations = []</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> detections:</span><br><span class="line">                scores = np.append(scores, float(d[<span class="number">4</span>]))</span><br><span class="line">                <span class="comment">#if annotations.shape[0] == 0:</span></span><br><span class="line">                <span class="keyword">if</span> len(annotations) == <span class="number">0</span>: <span class="comment"># 预测为真，但这个label的个数是0</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>)</span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br><span class="line">                <span class="keyword">if</span> max_overlap &gt;= iou_threshold \</span><br><span class="line">                   <span class="keyword">and</span> assigned_annotation <span class="keyword">not</span> <span class="keyword">in</span> detected_annotations: <span class="comment"># IoU满足条件，分配的标注没有被标注过</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">0</span>)     <span class="comment"># FP += 0</span></span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">1</span>)      <span class="comment"># TP += 1</span></span><br><span class="line">                  detected_annotations.append(assigned_annotation) </span><br><span class="line">                <span class="keyword">else</span>:                                                   <span class="comment"># 标注已经使用过</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>) </span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>值得注意的是，false_positives与true_positives并不是直接算个和，而是将每一张图片是否为TP，FP按照1，0保留下来。如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">false_positives = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>] <span class="comment"># 下标表示图片的序号，0表示否，1表示真</span></span><br></pre></td></tr></table></figure><p>这样存储的好处在于随后计算AP（PR曲线下方面积）时，方便计算。</p><h3 id="计算单个-label的AP"><a href="#计算单个-label的AP" class="headerlink" title="计算单个 label的AP"></a>计算单个 label的AP</h3><p>上一个部分代码得到了每张图片的PR值结果。计算AP值即算PR曲线的下方面积，因为不能直接算积分，因此我们需要想想办法。PR图是一张recall为x轴，precision为y轴的曲线，随着图片进行叠加，分别计算出P，R值，然后绘制出曲线。为了保证PR值尽量准确，我们首先对图片进行置信度从高到低的一个排序，然后累加计算其PR值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># no annotations -&gt; AP for this class is 0 (is this correct?)</span></span><br><span class="line"><span class="keyword">if</span> num_annotations == <span class="number">0</span>:</span><br><span class="line">    average_precisions[label] = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># sort by score</span></span><br><span class="line">indices         = np.argsort(-scores)</span><br><span class="line">false_positives = false_positives[indices] </span><br><span class="line">true_positives  = true_positives[indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute false positives and true positives</span></span><br><span class="line">false_positives = np.cumsum(false_positives) <span class="comment"># 依次累加</span></span><br><span class="line">true_positives  = np.cumsum(true_positives)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute recall and precision num_annotations也是据图片累加的</span></span><br><span class="line">recall    = true_positives / num_annotations</span><br><span class="line">precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)</span><br></pre></td></tr></table></figure><p>上诉代码首先根据scores对PR值进行排序，然后对每张图片从1…n累加计算出TP，FP值，因此最终得到的TP，FP也是一个长度为图片个数的数组。</p><p>计算AP的方法：</p><p>计算AP通常有两种方式，一种是07年以前的11点法，第二种是则是对每一个点都计算差值。</p><h4 id="Calculating-the-interpolation-performed-in-all-points"><a href="#Calculating-the-interpolation-performed-in-all-points" class="headerlink" title="Calculating the interpolation performed in all points"></a><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics" target="_blank" rel="noopener">Calculating the interpolation performed in all points</a></h4><p>该部分参考github上的讲解。先看图，对于Precision与Recall的插值如下，</p><p><img src="../images/trick/AP1.png" alt=""></p><p>也就是说，对于precision来说，从末尾开始，precision每个点的取值都等于其前一个点与当前点的最大值，即<code>mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])</code>。当遇到更大的precision时，重新开始重复上面计算，得到许多矩形框如下,计算该面积即可：</p><p><img src="../images/trick/AP2.png" alt=""></p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_ap</span><span class="params">(recall, precision)</span>:</span></span><br><span class="line">    <span class="string">""" Compute the average precision, given the recall and precision curves.</span></span><br><span class="line"><span class="string">    Code originally from https://github.com/rbgirshick/py-faster-rcnn.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        recall:    The recall curve (list).</span></span><br><span class="line"><span class="string">        precision: The precision curve (list).</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        The average precision as computed in py-faster-rcnn.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># correct AP calculation</span></span><br><span class="line">    <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">    mrec = np.concatenate(([<span class="number">0.</span>], recall, [<span class="number">1.</span>]))</span><br><span class="line">    mpre = np.concatenate(([<span class="number">0.</span>], precision, [<span class="number">0.</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the precision envelope</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># to calculate area under PR curve, look for points</span></span><br><span class="line">    <span class="comment"># where X axis (recall) changes value</span></span><br><span class="line">    i = np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># and sum (\Delta recall) * prec</span></span><br><span class="line">    ap = np.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br></pre></td></tr></table></figure><h3 id="计算IoU"><a href="#计算IoU" class="headerlink" title="计算IoU"></a>计算IoU</h3><p>当我们在计算Precision与Recall的时候需要判断样本是否是真样本，因此需要计算IoU值，计算IoU的大致思路如下，首先对一张图片，拿到一个置信度最高的边框，然后对该边框与该图片所有的GT边框都计算一个IoU，选出一个IoU值最大的GT边框作为与该边框匹配的边框。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> compute_overlap</span><br><span class="line">overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>)</span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br></pre></td></tr></table></figure><p>其中compute_overlap库是一个动态链接库，即为一个.so文件，通过.c文件编译而来。<a href="https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/utils/compute_overlap.pyx" target="_blank" rel="noopener">overlap代码github地址</a>。算法就是那样了，retina-net作者偷懒，直接用了fast rcnn的代码，我也偷个懒😂。</p><p>值得注意的是，每当一个GT边框被使用过之后，需要将其标记一下，避免下次重复计算。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>求mAP的方法需要通过预测网络提前生成测试集的box，然后将pred_csv, GT_csv传入方法中，最终求返回每个类别的AP。</p>]]></content>
      
      
      <categories>
          
          <category> 手撕系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python Tip</title>
      <link href="/2019/03/20/python-Tip/"/>
      <url>/2019/03/20/python-Tip/</url>
      
        <content type="html"><![CDATA[<h3 id="字符串查找元素"><a href="#字符串查找元素" class="headerlink" title="字符串查找元素"></a>字符串查找元素</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">astr = <span class="string">'1234'</span></span><br><span class="line">astr.find(<span class="string">'1'</span>) <span class="comment"># 返回下标或-1</span></span><br><span class="line">astr.rfind(<span class="string">'1'</span>) <span class="comment"># 反向查找</span></span><br></pre></td></tr></table></figure><h3 id="python-lambda-表达式"><a href="#python-lambda-表达式" class="headerlink" title="python lambda 表达式"></a>python lambda 表达式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">g = <span class="keyword">lambda</span> x:x+<span class="number">1</span> <span class="comment"># x为输入，x+1为输出: g(1) = 2</span></span><br><span class="line"><span class="comment"># python 中自带的lambda表达式</span></span><br><span class="line"><span class="comment"># foo =[2, 18, 9, 22, 17, 24, 8, 12, 27]</span></span><br><span class="line"><span class="comment"># 输出：[18, 9, 24, 12, 27]</span></span><br><span class="line">filter(<span class="keyword">lambda</span> x:x%<span class="number">3</span> ==<span class="number">0</span>,foo)</span><br><span class="line"><span class="comment"># map,将foo中每个元素都算一下</span></span><br><span class="line"><span class="comment">#输出：[14, 46, 28, 54, 44, 58, 26, 34, 64]</span></span><br><span class="line">map(<span class="keyword">lambda</span> x: x * <span class="number">2</span> + <span class="number">10</span>, foo)</span><br><span class="line"><span class="comment">#reduce 类加</span></span><br><span class="line">reduce(<span class="keyword">lambda</span> x, y: x + y, foo)</span><br></pre></td></tr></table></figure><h3 id="获取图片大小"><a href="#获取图片大小" class="headerlink" title="获取图片大小"></a>获取图片大小</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">'whatever.png'</span>)</span><br><span class="line">width, height = im.size</span><br></pre></td></tr></table></figure><h3 id="python-🀄️的类"><a href="#python-🀄️的类" class="headerlink" title="python 🀄️的类"></a>python 🀄️的类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">    self.name = name</span><br><span class="line">    self.__sex = man <span class="comment">## 在属性前加上两个_ 变成私有变量</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">    print(<span class="string">'hello'</span>+self.name)</span><br></pre></td></tr></table></figure><p>python中前后都有双下划线的变量是特殊变量，如<code>__ver__</code>,可以直接访问，定义式避免这种定义方式。例外，仅有一个下划线，如<code>_name</code>,这种变量表示不要轻易访问，但是它是可以被直接访问的。</p><h3 id="获取变量信息"><a href="#获取变量信息" class="headerlink" title="获取变量信息"></a>获取变量信息</h3><p>例如<code>dog = Animal(&#39;dog&#39;)</code>:</p><ul><li><code>type(dog)</code> 来获取dog的类型。</li><li><code>isinstance(dog,Animal)</code> 判断dog的类型</li><li><code>hasattr(obj, attr)</code> 判断类是否有attr方法/属性</li><li><code>getattr(obj,attr[,default])</code>:得到属性的值</li><li><code>setattr(obj, attr, value)</code>: 设置属性的值</li><li><code>dir(dog)</code>: 获取dog的所有属性和方法</li></ul><h3 id="类方法，静态方法"><a href="#类方法，静态方法" class="headerlink" title="类方法，静态方法"></a>类方法，静态方法</h3><p>可以使用类或实例直接访问：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">class_info</span><span class="params">(cls)</span>:</span></span><br><span class="line">    print(cls)</span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">static_info</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'something'</span>)</span><br></pre></td></tr></table></figure><h3 id="定制类以及魔法方法"><a href="#定制类以及魔法方法" class="headerlink" title="定制类以及魔法方法"></a>定制类以及魔法方法</h3><p>python中有一类方法，使用双下划线包裹起来：<code>__new__</code>等等，这类方法称为魔法方法，可以对类提供特殊的功能，方便定制类。</p><p><code>__new__(cls)</code>: 当创建一个类时，首先调用<code>__new__(cls)</code>方法，之后再调用<code>__init__()</code></p><p><code>__str__</code>: 当我们直接输出一个实例时，如<code>print(dog)</code>,得到的输出为：<code>&lt;__main__.Animal object at 0x10c37aa50&gt;</code>,通过覆盖<code>__str__</code> 方法可以输出我们想要的内容。</p><p><code>__repr__</code>: 当我们不用print时，调用该方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="string">'Animal object (name: %s)'</span> % self.name</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="string">'lalal'</span></span><br><span class="line">print(Animal(dog))  <span class="comment">## 调用__str__()</span></span><br><span class="line">Animal(dog) <span class="comment">## 调用 __repr__()</span></span><br></pre></td></tr></table></figure><p><code>__iter__(),__next__()</code>: 定义该方法使得类允许迭代调用,首先调用<code>__iter__()</code> 获得一个迭代器，然后每次迭代调用next。（可以不定义iter）。</p><p><code>__geitem__</code> 用于获取值，类似地，<code>__setitem__</code> 用于设置值，<code>__delitem__</code> 用于删除值，让我们看下面一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.coordinate = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"point(%s)"</span> % self.coordinate</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.coordinate.get(key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setitem__</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        self.coordinate[key] = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__delitem__</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">del</span> self.coordinate[key]</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'delete %s'</span> % key</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.coordinate)</span><br><span class="line"></span><br><span class="line">    __repr__ = __str__</span><br></pre></td></tr></table></figure><p>调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'x'</span>] = <span class="number">2</span>    <span class="comment"># 对应于 p.__setitem__('x', 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'y'</span>] = <span class="number">5</span>    <span class="comment"># 对应于 p.__setitem__('y', 5)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p             <span class="comment"># 对应于 __repr__</span></span><br><span class="line">point(&#123;<span class="string">'y'</span>: <span class="number">5</span>, <span class="string">'x'</span>: <span class="number">2</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(p)        <span class="comment"># 对应于 p.__len__</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'x'</span>]        <span class="comment"># 对应于 p.__getitem__('x')</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'y'</span>]        <span class="comment"># 对应于 p.__getitem__('y')</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> p[<span class="string">'x'</span>]    <span class="comment"># 对应于 p.__delitem__('x')</span></span><br><span class="line">delete x</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p</span><br><span class="line">point(&#123;<span class="string">'y'</span>: <span class="number">5</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(p)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><p><code>__getattr__()</code> 只有在属性不存在的情况下才会被调用。</p><p>与 <code>__getattr__</code> 一起使用的还有 <code>__setattr__</code>, <code>__delattr__</code>，类似 <code>obj.attr = value</code>, <code>del obj.attr</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=<span class="number">0</span>, y=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span><span class="params">(self, attr)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> attr == <span class="string">'z'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">raise</span> AttributeError(<span class="string">"Point object has no attribute %s"</span> % attr)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span><span class="params">(self, *args, **kwargs)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">'call func set attr (%s, %s)'</span> % (args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> object.__setattr__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__delattr__</span><span class="params">(self, *args, **kwargs)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">'call func del attr (%s, %s)'</span> % (args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> object.__delattr__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">call func set attr ((<span class="string">'x'</span>, <span class="number">3</span>), &#123;&#125;)</span><br><span class="line">call func set attr ((<span class="string">'y'</span>, <span class="number">4</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z = <span class="number">7</span></span><br><span class="line">call func set attr ((<span class="string">'z'</span>, <span class="number">7</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">8</span>, <span class="keyword">in</span> __getattr__</span><br><span class="line">AttributeError: Point object has no attribute w</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w = <span class="number">8</span></span><br><span class="line">call func set attr ((<span class="string">'w'</span>, <span class="number">8</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w</span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> p.w</span><br><span class="line">call func <span class="keyword">del</span> attr ((<span class="string">'w'</span>,), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.__dict__</span><br><span class="line">&#123;<span class="string">'y'</span>: <span class="number">4</span>, <span class="string">'x'</span>: <span class="number">3</span>, <span class="string">'z'</span>: <span class="number">7</span>&#125;</span><br></pre></td></tr></table></figure><p> <code>__call__</code> 方法,对实例进行调用就好像对函数调用一样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>+<span class="number">1</span></span><br><span class="line">a = A()</span><br><span class="line">a() <span class="comment"># 将调用__call__方法</span></span><br></pre></td></tr></table></figure><p>使用 <code>__slots__</code> 来告诉 Python 只给一个固定集合的属性分配空间，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    __slots__ = (<span class="string">'x'</span>, <span class="string">'y'</span>)       <span class="comment"># 只允许使用 x 和 y</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=<span class="number">0</span>, y=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">a = Point()</span><br><span class="line">a.z = <span class="number">1</span> <span class="comment"># 报错，只允许对x,y赋值</span></span><br></pre></td></tr></table></figure><p>定义<code>@property以及@setter</code> 方法，第一个将方法当作属性来用，第二个将这个方法当作属性来赋值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Exam</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, score)</span>:</span></span><br><span class="line">        self._score = score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, val)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> val &lt; <span class="number">0</span>:</span><br><span class="line">            self._score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> val &gt; <span class="number">100</span>:</span><br><span class="line">            self._score = <span class="number">100</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._score = val</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e = Exam(<span class="number">60</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score = <span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score = <span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure><p><code>super()</code>:当使用子类与夫类方法相同时会发生覆盖，如果希望保留父类则调用super方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span>（<span class="number">111</span>）</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().greet()</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'WangWang...'</span></span><br></pre></td></tr></table></figure><p>使用元类：元类主要用来拦截类的创建，修改类的定义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrefixMetaclass</span><span class="params">(type)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, name, bases, attrs)</span>:</span></span><br><span class="line">        <span class="comment"># 给所有属性和方法前面加上前缀 my_</span></span><br><span class="line">        _attrs = ((<span class="string">'my_'</span> + name, value) <span class="keyword">for</span> name, value <span class="keyword">in</span> attrs.items())  </span><br><span class="line"></span><br><span class="line">        _attrs = dict((name, value) <span class="keyword">for</span> name, value <span class="keyword">in</span> _attrs)  <span class="comment"># 转化为字典</span></span><br><span class="line">        _attrs[<span class="string">'echo'</span>] = <span class="keyword">lambda</span> self, phrase: phrase  <span class="comment"># 增加了一个 echo 方法</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> type.__new__(cls, name, bases, _attrs)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span><span class="params">(metaclass=PrefixMetaclass)</span>:</span></span><br><span class="line">    name = <span class="string">'foo'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bar</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'bar'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bar</span><span class="params">(Foo)</span>:</span></span><br><span class="line">    prop = <span class="string">'bar'</span></span><br></pre></td></tr></table></figure><p>创建迭代器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fib</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回迭代器对象本身</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回容器下一个元素</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.a, self.b = self.b, self.a + self.b</span><br><span class="line">        <span class="keyword">return</span> self.a</span><br></pre></td></tr></table></figure><p><code>__iter__()</code> 创建迭代器，<code>__next__()</code>每次迭代均调用该方法取得迭代值。</p><p>创建生成器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fib</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"><span class="meta">... </span>        a, b = b, a + b</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> a</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> item <span class="keyword">in</span> f:  <span class="comment"># 每次执行到yield返回一个值并停止，第二次调用f.next()时冲yield处开始执行</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> item &gt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> item</span><br></pre></td></tr></table></figure><h3 id="Python-OS模块"><a href="#Python-OS模块" class="headerlink" title="Python OS模块"></a>Python OS模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dir <span class="keyword">in</span> os.listdir(<span class="string">'./'</span>):  <span class="comment"># 当前路径下的所有文件</span></span><br><span class="line">  print(dir)</span><br><span class="line">os.path.abspath(<span class="string">'.'</span>) <span class="comment"># 得到绝对路径</span></span><br><span class="line">os.path.dirname(<span class="string">'file.txt'</span>) <span class="comment"># 　获取当前文件的父目录</span></span><br><span class="line">os.path.basename(<span class="string">'./path/to/file.txt'</span>) <span class="comment"># 输出file.txt，得到文件名</span></span><br><span class="line">os.path.splitext(<span class="string">'afile.txt'</span>) <span class="comment"># 输出(afile,txt),分离文件名和扩展名</span></span><br><span class="line">os.path.split(<span class="string">'/path/file.txt'</span>)<span class="comment"># (path,file.txt)，分离目录与文件</span></span><br><span class="line">os.path.isfile/os.path.isdir() <span class="comment">#判断是否是目录或文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##遍历目录</span></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(<span class="string">'/Users/ethan/coding'</span>):</span><br><span class="line">     <span class="keyword">print</span> root</span><br><span class="line">     <span class="keyword">print</span> dirs</span><br><span class="line">     <span class="keyword">print</span> files</span><br></pre></td></tr></table></figure><h3 id="python-zip函数"><a href="#python-zip函数" class="headerlink" title="python zip函数"></a>python zip函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">zipped = zip(a,b)<span class="comment">#[(1,4),(2,5),(3,6)]</span></span><br></pre></td></tr></table></figure><h3 id="print-重定向"><a href="#print-重定向" class="headerlink" title="print 重定向"></a>print 重定向</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'afile.txt'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  a = <span class="string">'this is a string'</span></span><br><span class="line">  b = <span class="number">11</span></span><br><span class="line">  <span class="keyword">print</span> &gt;&gt; a,b</span><br><span class="line"><span class="comment">## 重定向将a,b输入afile.txt 中</span></span><br></pre></td></tr></table></figure><h3 id="sys-stdout-标准输出"><a href="#sys-stdout-标准输出" class="headerlink" title="sys.stdout 标准输出"></a>sys.stdout 标准输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys.stdout.write(<span class="string">'&#123;&#125;/&#123;&#125;\r'</span>.format(step,len(lines)))<span class="comment"># 控制台输出</span></span><br><span class="line">sys.stdout.flush() <span class="comment"># 将控制台输出的抹掉</span></span><br></pre></td></tr></table></figure><h3 id="xlsx文件读取"><a href="#xlsx文件读取" class="headerlink" title="xlsx文件读取"></a>xlsx文件读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line"></span><br><span class="line">XLSX_PATH = <span class="string">'./video_id.xlsx'</span></span><br><span class="line"></span><br><span class="line">workbook = xlrd.open_workbook(XLSX_PATH)</span><br><span class="line">print(workbook.sheet_names())  <span class="comment">#得到所有表的表名</span></span><br><span class="line"></span><br><span class="line">id_list = []</span><br><span class="line"><span class="keyword">for</span> sheet <span class="keyword">in</span> workbook.sheet_names():</span><br><span class="line">    booksheet = workbook.sheet_by_name(sheet) <span class="comment"># 根据表名得到表</span></span><br><span class="line">    col = booksheet.col_values(<span class="number">0</span>)[<span class="number">1</span>:] <span class="comment"># 得到表的第一列</span></span><br><span class="line">    id_list += col </span><br><span class="line">    print(<span class="string">'sheet name: '</span>+ sheet)</span><br><span class="line">    print(col)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'total account:'</span> +str(len(id_list)))</span><br><span class="line"></span><br><span class="line">from_slsx_get_video(id_list)</span><br></pre></td></tr></table></figure><h3 id="progressbar-进度条的使用"><a href="#progressbar-进度条的使用" class="headerlink" title="progressbar 进度条的使用"></a>progressbar 进度条的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> progress <span class="keyword">import</span> *</span><br><span class="line">progress = ProgressBar()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> progress(range(<span class="number">1000</span>)):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="python-enumerate使用"><a href="#python-enumerate使用" class="headerlink" title="python enumerate使用"></a>python enumerate使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">  print(i,label)</span><br></pre></td></tr></table></figure><h3 id="python-argsort"><a href="#python-argsort" class="headerlink" title="python argsort()"></a>python argsort()</h3><p>argsort是numpy的一个函数，这个函数的作用是返回从小到大排序后的元素下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">-1</span>])</span><br><span class="line">sort_index = np.argsort(a)</span><br><span class="line">a = a[b] <span class="comment"># 进行排序</span></span><br></pre></td></tr></table></figure><h3 id="numpy-cumsum"><a href="#numpy-cumsum" class="headerlink" title="numpy cumsum()"></a>numpy cumsum()</h3><p>cumsum()这个函数用来对数组依次累加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.cumsum(a) <span class="comment"># b = [1,3,6]</span></span><br></pre></td></tr></table></figure><h3 id="numpy-maximum"><a href="#numpy-maximum" class="headerlink" title="numpy maximum()"></a>numpy maximum()</h3><p>这个函数的输入为两个数组，然后生成一个数组，每个位置上为这两个数组中较大的那个。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.array([<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">c = np.maximum(a,b) <span class="comment"># c = [2,2,3]</span></span><br></pre></td></tr></table></figure><h3 id="python-排序算法"><a href="#python-排序算法" class="headerlink" title="python 排序算法"></a>python 排序算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>]</span><br><span class="line">a.sort() <span class="comment"># 输出为空，直接改变a</span></span><br><span class="line">sorted(a) <span class="comment"># 输出排序后的结果，但不改变a</span></span><br></pre></td></tr></table></figure><h3 id="Python-中的序列"><a href="#Python-中的序列" class="headerlink" title="Python 中的序列"></a>Python 中的序列</h3><p>序列是python 中最基本的数据结构。序列对象均可以进行索引，分片，迭代，加，乘操作，可以用in判断元素是否存在序列中。其中list，tuple，str都属于序列。</p><h3 id="list-列表"><a href="#list-列表" class="headerlink" title="list 列表"></a>list 列表</h3><p>list是可修改的一个变量，可以对他进行任意的修改。可以使用list()函数，对str字符串，和tuple进行转化成list。下面对list的各种函数进行讲解：</p><h4 id="index"><a href="#index" class="headerlink" title="index"></a>index</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># index 用于从列表中寻找第一个出现元素的下标</span></span><br><span class="line">nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]</span><br><span class="line">nums.index(<span class="number">2</span>)</span><br><span class="line">nums.index(<span class="number">9</span>) <span class="comment"># 如果找不到则抛出异常</span></span><br></pre></td></tr></table></figure><h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于计算一个元素出现的个数</span></span><br><span class="line">nums.count(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="append"><a href="#append" class="headerlink" title="append"></a>append</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于在元素末尾增加元素</span></span><br><span class="line">nums.append(<span class="number">8</span>)</span><br><span class="line">nums.append([<span class="number">9</span>,<span class="number">8</span>]) <span class="comment"># 将[9,8]作为一个整体加入 nums = [1,2,..,[8,9]]</span></span><br></pre></td></tr></table></figure><h4 id="extend"><a href="#extend" class="headerlink" title="extend"></a>extend</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将list进行融合</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">a.extend(b) <span class="comment"># a = [1,2,3,4,5,6]</span></span><br><span class="line"><span class="comment">## extend 元素不允许直接添加一个元素</span></span><br><span class="line">a.extend(<span class="number">3</span>) <span class="comment"># 报错</span></span><br><span class="line">a.extend([<span class="number">3</span>])</span><br></pre></td></tr></table></figure><h4 id="insert"><a href="#insert" class="headerlink" title="insert"></a>insert</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#insert(pos,val)</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a.insert(<span class="number">1</span>,<span class="number">4</span>) <span class="comment"># a = [1,4,2,3]</span></span><br></pre></td></tr></table></figure><h4 id="pop"><a href="#pop" class="headerlink" title="pop"></a>pop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于移除list中的元素，默认是最后一个,返回值为移除的数</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a.pop() <span class="comment"># a = [1,2,3]</span></span><br><span class="line">a.pop(<span class="number">1</span>) <span class="comment"># a = [1,3]</span></span><br></pre></td></tr></table></figure><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># remove(val) 移除list中值为val的元素</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a.remove(<span class="number">2</span>) <span class="comment"># 移除第一个相同的，a = [1,2,3,3,4]</span></span><br><span class="line">a.remove(<span class="number">8</span>) <span class="comment"># 若不在list中，则抛出异常</span></span><br></pre></td></tr></table></figure><h4 id="reverse"><a href="#reverse" class="headerlink" title="reverse"></a>reverse</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 反转数组</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a.reverse() <span class="comment"># a = [3,2,1]</span></span><br></pre></td></tr></table></figure><h4 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法直接对list进行排序，修改list的值</span></span><br><span class="line">a= [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">a.sort() <span class="comment"># 直接修改a, a = [1,2,3]</span></span><br><span class="line">a.sort(reverse=<span class="keyword">True</span>) <span class="comment"># 反向排序</span></span><br><span class="line"><span class="comment"># 此外可以指定key，进行一些多列的排序</span></span><br><span class="line">student_tuples = [</span><br><span class="line">        (<span class="string">'john'</span>, <span class="string">'A'</span>, <span class="number">15</span>),</span><br><span class="line">        (<span class="string">'jane'</span>, <span class="string">'B'</span>, <span class="number">12</span>),</span><br><span class="line">        (<span class="string">'dave'</span>, <span class="string">'B'</span>, <span class="number">10</span>),</span><br><span class="line">]</span><br><span class="line">sorted(student_tuples,key=<span class="keyword">lambda</span> student:student[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmp 指定函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare</span><span class="params">(x,y)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x-y</span><br><span class="line">sorted(alist,cmp = compare)</span><br></pre></td></tr></table></figure><h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a>sorted</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法不是list的方法，返回值为排序结果，不改变a</span></span><br><span class="line">a = [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">sorted(a) <span class="comment"># 返回值为[1,2,3]，a不变</span></span><br></pre></td></tr></table></figure><h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h3><p>元组是一种不可变的序列，不可对tuple进行修改，它用()来表示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = (<span class="number">1</span>,)  <span class="comment"># 当仅有一个元素的时候，必须叫上一个逗号</span></span><br><span class="line">c =() <span class="comment"># 空元组</span></span><br><span class="line">tuple <span class="comment"># 可以进行索引分片，与正常的序列相同</span></span><br></pre></td></tr></table></figure><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>字符串是一种序列，满足索引，分片，加法，乘法等操作，并且字符串也是不可变的变量。</p><h4 id="find"><a href="#find" class="headerlink" title="find"></a>find</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find函数用于找字符串中的子串的位置</span></span><br><span class="line">astr = <span class="string">'this is a dog'</span></span><br><span class="line">astr.find(<span class="string">'is'</span>) <span class="comment"># 返回第一个子串出现的位置</span></span><br><span class="line">astr.find(<span class="string">'is'</span>,<span class="number">4</span>) <span class="comment"># 指定起始位置</span></span><br><span class="line">astr.find(<span class="string">'is'</span>,<span class="number">4</span>,<span class="number">7</span>) <span class="comment"># 指定起始和结束位置</span></span><br></pre></td></tr></table></figure><h4 id="split"><a href="#split" class="headerlink" title="split"></a>split</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split 指定一个分割符对字符串进行分割</span></span><br><span class="line">a = <span class="string">'a,b,c,d'</span></span><br><span class="line">a.split(<span class="string">','</span>) <span class="comment"># 返回一个list数组</span></span><br></pre></td></tr></table></figure><h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># join 函数类似于split的逆函数</span></span><br><span class="line"><span class="string">','</span>.join([<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'3'</span>]) <span class="comment"># 得到一个字符串：'1,2,3'</span></span><br><span class="line"><span class="string">''</span>.join([<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>])  <span class="comment"># 得到一个字符串：‘abc’</span></span><br></pre></td></tr></table></figure><h4 id="strip"><a href="#strip" class="headerlink" title="strip"></a>strip</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于删除左右两边的空格</span></span><br><span class="line">a = <span class="string">'   sdssd   '</span></span><br><span class="line">a.strip() <span class="comment"># a = 'sdssd'</span></span><br><span class="line">a = <span class="string">'##sadsd sasd%%%'</span></span><br><span class="line">a.strip(<span class="string">'#%'</span>) <span class="comment"># 删除左右两边的#与%</span></span><br></pre></td></tr></table></figure><h4 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于体会匹配项</span></span><br><span class="line">a = <span class="string">'this is a dog'</span></span><br><span class="line">a.replace(<span class="string">'is'</span>,<span class="string">'isnt'</span>) <span class="comment"># a = 'this isnt a dog'</span></span><br></pre></td></tr></table></figure><h4 id="lower-upper"><a href="#lower-upper" class="headerlink" title="lower/upper"></a>lower/upper</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回字符变大或者变小的结果</span></span><br><span class="line">a = <span class="string">'ABC'</span></span><br><span class="line">a.lower() <span class="comment"># 放回abc，但是a仍然不变</span></span><br></pre></td></tr></table></figure><h3 id="dict-字典"><a href="#dict-字典" class="headerlink" title="dict 字典"></a>dict 字典</h3><p>dict是有key-value组成的一个类型。</p><p>创建，遍历字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">adict = &#123;&#125;</span><br><span class="line">adict[<span class="string">'a'</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 遍历</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> adict:</span><br><span class="line">  print(k,adict[k])</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> adict.keys():</span><br><span class="line">  print(k,adict[k])</span><br></pre></td></tr></table></figure><p>判断元素是否在字典中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&#125;</span><br><span class="line">d[<span class="string">'a'</span>] = <span class="number">1</span></span><br><span class="line">d[<span class="string">'b'</span>] = <span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'b'</span> <span class="keyword">in</span> d:</span><br><span class="line">  print(<span class="string">'b is a key'</span>)</span><br></pre></td></tr></table></figure><h4 id="clear"><a href="#clear" class="headerlink" title="clear"></a>clear</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d.clear() <span class="comment"># 清空所有项</span></span><br></pre></td></tr></table></figure><h4 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 浅复制</span></span><br><span class="line">d2 = d1.copy() <span class="comment"># 对d2的改变同样也会改变d1</span></span><br><span class="line"><span class="comment"># 深复制，生成许多独立的样本</span></span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">d2 = deepcopy(d1) <span class="comment"># d2与d1无关</span></span><br></pre></td></tr></table></figure><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#访问字典中的元素</span></span><br><span class="line">d.get(<span class="string">'key_val'</span>) <span class="comment"># 返回值，如果没有的话返回None</span></span><br><span class="line">d.get(<span class="string">'key_val'</span>，；<span class="string">'default val'</span>) <span class="comment"># 如果无，放回default val</span></span><br></pre></td></tr></table></figure><h4 id="update"><a href="#update" class="headerlink" title="update"></a>update</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将两个字典进行相加</span></span><br><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>&#125;</span><br><span class="line">b = &#123;<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line">b.update(a) <span class="comment"># b = &#123;'a':1,'b':2&#125;</span></span><br></pre></td></tr></table></figure><h4 id="Items-keys-values"><a href="#Items-keys-values" class="headerlink" title="Items,keys,values"></a>Items,keys,values</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#items将dict项以list的方式返回，keys将key以list的方式返回</span></span><br><span class="line">d = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k ,v <span class="keyword">in</span> d.items():</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> d.keys():</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> d.values():</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="pop-1"><a href="#pop-1" class="headerlink" title="pop"></a>pop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除key</span></span><br><span class="line">d = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line">d.pop(<span class="string">'a'</span>) <span class="comment"># 返回a的val 1</span></span><br><span class="line">d.popitem() <span class="comment"># 随机删除掉一对键值对</span></span><br></pre></td></tr></table></figure><h4 id="对字典进行排序"><a href="#对字典进行排序" class="headerlink" title="对字典进行排序"></a>对字典进行排序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">student = [&#123;<span class="string">'name'</span>: <span class="string">'john'</span>, <span class="string">'score'</span>: <span class="string">'B'</span>, <span class="string">'age'</span>: <span class="number">15</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'jane'</span>, <span class="string">'score'</span>: <span class="string">'A'</span>, <span class="string">'age'</span>: <span class="number">12</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'dave'</span>, <span class="string">'score'</span>: <span class="string">'B'</span>, <span class="string">'age'</span>: <span class="number">10</span>&#125;]</span><br><span class="line">sorted(student,key = <span class="keyword">lambda</span> stu:stu[<span class="string">'age'</span>])</span><br></pre></td></tr></table></figure><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set是一个元素不重合的集合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = set()</span><br><span class="line">a.add(<span class="string">'0'</span>) <span class="comment"># 添加元素</span></span><br><span class="line"><span class="comment">#遍历集合</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line">  print(e)</span><br><span class="line">e.remove(<span class="string">'0'</span>) <span class="comment"># 删除元素</span></span><br></pre></td></tr></table></figure><h4 id="交集，并集，差集"><a href="#交集，并集，差集" class="headerlink" title="交集，并集，差集"></a>交集，并集，差集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s1 = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">s2 = &#123;<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">s3 = s1&amp;s2  <span class="comment"># 交集，s3 = &#123;3&#125;</span></span><br><span class="line">s4 = s1|s2 <span class="comment"># 并集，s4 = &#123;1,2,3,4,5&#125;</span></span><br><span class="line">s5 = s1 - s2 <span class="comment"># 差集，s5 = &#123;1,2&#125;</span></span><br><span class="line"><span class="comment"># 判断是否是子集</span></span><br><span class="line">s1.issubset(s2) <span class="comment"># s1是否是s2的子集</span></span><br></pre></td></tr></table></figure><h3 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(x, y, z=<span class="number">0</span>, *args, **kwargs)</span>:</span></span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 其中x,y为必须传入的参数，z默认参数，</span></span><br><span class="line"><span class="comment"># *args 接受无限制的值参数，变为一个list</span></span><br><span class="line"><span class="comment">#**kwargs 接受键值参数，最后变成一个dict</span></span><br></pre></td></tr></table></figure><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">map(square,a) <span class="comment"># 返回值为[1,4,9]</span></span><br></pre></td></tr></table></figure><h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reduce(<span class="keyword">lambda</span> x, y: x * y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])  <span class="comment"># 相当于 ((1 * 2) * 3) * 4</span></span><br></pre></td></tr></table></figure><h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter(<span class="keyword">lambda</span> x: x &lt; <span class="string">'g'</span>, <span class="string">'hijack'</span>) <span class="comment"># 返回 ac</span></span><br></pre></td></tr></table></figure><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeitalic</span><span class="params">(func)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapped</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"&lt;i&gt;"</span> + func() + <span class="string">"&lt;/i&gt;"</span></span><br><span class="line">    <span class="keyword">return</span> wrapped</span><br><span class="line"></span><br><span class="line"><span class="meta">@makeitalic</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure><p>即调用hello的时候会提前调用makeitalic，对hello进行装饰。</p><h3 id="pdb-python调试工具"><a href="#pdb-python调试工具" class="headerlink" title="pdb python调试工具"></a>pdb python调试工具</h3><p>pdb是调试代码的一个工具包，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pdb </span><br><span class="line">a = <span class="string">"aaa"</span></span><br><span class="line">pdb.set_trace() </span><br><span class="line">b = <span class="string">"bbb"</span></span><br><span class="line">c = <span class="string">"ccc"</span></span><br><span class="line">final = a + b + c </span><br><span class="line"><span class="keyword">print</span> final</span><br></pre></td></tr></table></figure><p>代码在set_trace()处进入暂停，输入<code>n + enter</code>进入下一行，下一次敲回车将重复上一个操作。输入<code>q</code>退出程序。在控制台允许执行print等代码来获取结果。</p><p>查看当前位置前后11行的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l</span><br></pre></td></tr></table></figure><p>查看当前所有的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll</span><br></pre></td></tr></table></figure><p>添加断点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b line-number</span><br><span class="line">tbreak line-number <span class="comment"># 添加临时断点</span></span><br></pre></td></tr></table></figure><p>清除断点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cl <span class="comment"># 清除所有断点</span></span><br><span class="line">cl line-number <span class="comment"># 清除该行断点</span></span><br></pre></td></tr></table></figure><p>打印变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p expression</span><br></pre></td></tr></table></figure><p>逐行调试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n 下一条</span><br><span class="line">s 下一行，能进入函数题</span><br><span class="line">r 跳过函数体</span><br><span class="line">c 跳到下一个断点</span><br><span class="line">unt line-number 一直执行到line-number</span><br><span class="line">a 查看函数参数</span><br></pre></td></tr></table></figure><h3 id="关于python的相对导入问题"><a href="#关于python的相对导入问题" class="headerlink" title="关于python的相对导入问题"></a>关于python的相对导入问题</h3><p>python包导入的时候不同的层级关系可以使用<code>..</code> 或<code>.</code> 来表示上一层目录和当前目录。这种层级关系是通过module中<code>__name__</code>字段来定义的，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">package/</span><br><span class="line">    __init__.py</span><br><span class="line">    subpackage1/</span><br><span class="line">        __init__.py</span><br><span class="line">        moduleX.py</span><br><span class="line">    moduleA.py</span><br></pre></td></tr></table></figure><p>在这个package的同级目录中调用<code>moduleX.py</code>文件时，该文件<code>__name__</code>就<code>.package.subpackage1.moduleX</code>，因此该moduleX反过来去调用moduleA，可以写作<code>from .. import moduleA</code> 。但是如果在同一个文件目录下执行脚本的话，该文件夹下就会变成top-level script，name就变成了<code>__main__</code>，因此层级结构就会失效。</p><p><strong>因此含有这些层级结构的脚本，不允许直接运行，而是需要由外层的文件来间接调用。</strong></p><h3 id="python-捕获异常"><a href="#python-捕获异常" class="headerlink" title="python 捕获异常"></a>python 捕获异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> traceback <span class="keyword">import</span> print_exc</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> something wrong</span><br><span class="line"><span class="keyword">except</span> Exception, e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'type is:'</span>, e.__class__.__name__</span><br><span class="line">    print_exc()</span><br><span class="line">    <span class="comment"># print "exception happened!"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN 复现</title>
      <link href="/2019/03/16/Faster-RCNN-%E5%A4%8D%E7%8E%B0/"/>
      <url>/2019/03/16/Faster-RCNN-%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>Faster RCNN是目标检测领域的一个benchmark，具有很好的借鉴意义。<a href="http://perper.site/%2F2019%2F02%2F14%2FFaster-RCNN%E8%AF%A6%E8%A7%A3%2F" target="_blank" rel="noopener">Faster RCNN详解</a>介绍了Faster RCNN的网络结构，检测流程，以及一些训练过程等，接下来主要想通过<a href="https://github.com/smallcorgi/Faster-RCNN_TF" target="_blank" rel="noopener">github上的repo</a>来复现一下论文，并在自己的数据集上跑一下结果。</p><a id="more"></a><h3 id="准备环节"><a href="#准备环节" class="headerlink" title="准备环节"></a>准备环节</h3><p><strong>.so文件</strong>：.so文件是Linux下共享库文件，也是ELF格式文件。类似于DLL。.so文件能够节约资源，加快代码速度，方便代码的升级。</p><p><strong>.o文件</strong>：目标文件,相当于windows中的.obj文件</p><p><strong>.a文件</strong>：静态库,是好多个.o合在一起,用于静态连接</p><p>其中这些共享链接文件与操作系统相关，换一个系统时需要重新生成。</p><p><strong>pycocotools:</strong>这个文件库的作用是操纵coco数据集的一些api。安装方法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><br></pre></td></tr></table></figure><h3 id="环境的配置"><a href="#环境的配置" class="headerlink" title="环境的配置"></a>环境的配置</h3><p>参考tensorpack的 <a href="https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN" target="_blank" rel="noopener">readme</a>。将所有环境配置好，以及数据集的格式。</p><h3 id="COCO-train2017数据标注格式："><a href="#COCO-train2017数据标注格式：" class="headerlink" title="COCO train2017数据标注格式："></a>COCO train2017数据标注格式：</h3><p>整个json共有一下几个字段：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">    <span class="attr">"categories"</span>: [category]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中<code>info,licenses</code>字段表示一些数据集以及证书信息。</p><p><code>images</code>字段表示图片路径信息，有以下几个字段：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">"images": [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"license"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"file_name"</span>: <span class="string">"000000397133.jpg"</span>,</span><br><span class="line">            <span class="attr">"coco_url"</span>: <span class="string">"/val2017/000000397133.jpg"</span>,</span><br><span class="line">            <span class="attr">"height"</span>: <span class="number">427</span>,</span><br><span class="line">            <span class="attr">"width"</span>: <span class="number">640</span>,</span><br><span class="line">            <span class="attr">"date_captured"</span>: <span class="string">"2013-11-14 17:02:52"</span>,</span><br><span class="line">            <span class="attr">"flickr_url"</span>: url,</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">397133</span></span><br><span class="line">        &#125;,</span><br></pre></td></tr></table></figure><p>关键字段为<code>coco_url</code>，即为图片的路径名，<code>id</code>:与annotations字段image_id相对应的一个id。</p><p><code>annotation</code>字段包含以下内容：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">annotation&#123;</span><br><span class="line">    "id": int,    </span><br><span class="line">    "image_id": int,</span><br><span class="line">    "category_id": int,</span><br><span class="line">    "segmentation": RLE or [polygon],</span><br><span class="line">    "area": float,</span><br><span class="line">    "bbox": [x,y,width,height],</span><br><span class="line">    "iscrowd": 0 or 1,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>image_id</code>:与images字段中id对应，找到图片的真实路径</p><p><code>category_id</code>：images box中的类别信息</p><p><code>segmentation</code>：mask的区域，即多边形区域</p><p><code>bbox</code>：目标boundding box[top left x position, top left y position, width, height]</p><p><code>iscrowd</code>：0 or 1，0表示segmentation为RLE格式，1表示其为polygon格式。</p><h3 id="将原有标准修改为COCO格式"><a href="#将原有标准修改为COCO格式" class="headerlink" title="将原有标准修改为COCO格式"></a>将原有标准修改为COCO格式</h3><p>由于源码中大量使用道其他字段，因此基本上都需要补充完整。</p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>对于大部分的源码思路都可以视为：</p><ul><li>准备数据，配置网络，设置holder</li><li>设置权重和bias</li><li>搭建网络</li><li>设置损失函数，设置优化器</li><li>step by step训练网络</li></ul><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--logdir'</span>, help=<span class="string">'log directory'</span>, default=<span class="string">'train_log/maskrcnn'</span>)</span><br><span class="line">...</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="comment">## 使用</span></span><br><span class="line">print(args.logdir)</span><br></pre></td></tr></table></figure><p>COCO数据集中有81类，我们使用的数据集仅有两类，因此需要对数据集部分进行修改。</p>]]></content>
      
      
      <categories>
          
          <category> 论文复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>awk,grep 学习</title>
      <link href="/2019/03/16/awk,grep-%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/03/16/awk,grep-%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>awk是一个文本解释型语言，在文本处理领域十分的常用。awk的典型用途如：</p><ul><li>文本处理</li><li>执行算术运算</li><li>执行字符串操作</li></ul><a id="more"></a><h3 id="awk的工作流："><a href="#awk的工作流：" class="headerlink" title="awk的工作流："></a>awk的工作流：</h3><p>awk的工作流十分简单：<strong>读取-&gt;执行-&gt;重复</strong></p><p>read：从标准输入流中读取一行</p><p>execute：所有awk执行对文本中每一行都执行处理</p><p>repeat：处理过程不断重复，直到文件到达结尾</p><h3 id="awk命令行"><a href="#awk命令行" class="headerlink" title="awk命令行"></a>awk命令行</h3><p>awk的命令行格式为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk [option] afile.py</span><br></pre></td></tr></table></figure><p>我们可以使用单引号来指定awk命令，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk '&#123;print&#125;' afile.py</span><br></pre></td></tr></table></figure><p>以下语句输出数据中第三列和第四列：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '&#123;print $3 "\t" $4&#125;' marks.txt</span><br></pre></td></tr></table></figure><p>其中<code>-F</code>设置分割符为<code>,</code>，awk默认分割符号为空格。在使用程序语句如<code>print</code>时，需要加上大括号。其中<code>$3,$4</code>表示数据中的第3列和第4列。<code>$0</code>表示一整行都输出。</p><p>以下语句输出匹配字符(不指定输出则输出一整行)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk '/a/' aw.txt # 输出含有a的一整行</span><br><span class="line">awk '/a/ &#123;print $1 $2&#125;'  aw.txt # 输出含有a的行的1,2列</span><br></pre></td></tr></table></figure><p>重定向输出：即将awk的输出，输出到文件中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk '/a/' aw.txt &gt;&gt; new.txt</span><br></pre></td></tr></table></figure><p>不显示重复行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '!seen[$1]++' aw.txt</span><br></pre></td></tr></table></figure><p>其中seen可以看成一个字典dict，当没有这个值的时候!seen[$1] == 0,因此允许输出。但当这个值以及存在时，则不输出。</p><p>单引号内可以使用各种判断语句：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '$1&gt;$2 &#123;print $0&#125;' aw.txt</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）</span></span><br><span class="line">$ awk <span class="string">'&#123;print $1,$4&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 指定 , 为分割符（-F），将字符串分割</span></span><br><span class="line">$  awk -F, <span class="string">'&#123;print $1,$2&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 多个分割符，先用 空格后用 ,</span></span><br><span class="line">$ awk -F <span class="string">'[ ,]'</span>  <span class="string">'&#123;print $1,$2,$5&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 设置变量 -v</span></span><br><span class="line">$ awk -va=1 -vb=s <span class="string">'&#123;print $1,$1+a,$1b&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 过滤出第一列大于2的数</span></span><br><span class="line">$ awk <span class="string">'$1&gt;2'</span> log.txt </span><br><span class="line"><span class="comment"># CSV_PATH为输入，TRAIN_PATH为输出 ,-v 为定义变量</span></span><br><span class="line">awk -v min_area=<span class="variable">$&#123;MIN_AREA&#125;</span> -F <span class="string">','</span> <span class="string">'&#123;   </span></span><br><span class="line"><span class="string">    area=(($4-$2)*($5-$3));</span></span><br><span class="line"><span class="string">    if(area&gt;min_area)&#123;</span></span><br><span class="line"><span class="string">        print $0;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span>&lt;<span class="variable">$&#123;CSV_PATH&#125;</span> &gt;&gt; <span class="variable">$&#123;TRAIN_PATH&#125;</span></span><br></pre></td></tr></table></figure><p><a href="https://coolshell.cn/articles/9070.html" target="_blank" rel="noopener">awk参考链接</a></p><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><p>grep是类unix系统中执行正则表达式的命令 ,下面是grep使用的<a href="https://www.cnblogs.com/sky-heaven/p/10187395.html" target="_blank" rel="noopener">15个场景</a>：</p><ol><li>下面语句判断文件中是否含有搜索的内容：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep 'tf' afile.py</span><br><span class="line">cat afile.py |grep 'tf'</span><br></pre></td></tr></table></figure><ol start="2"><li>从多个文件中查找指定字符：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 文件夹有demo_1.txt,demo_2 文件</span></span><br><span class="line">grep 'this' demo_1.txt demo_2.txt</span><br><span class="line">grep 'this' demo_*</span><br></pre></td></tr></table></figure><ol start="3"><li>忽略大小写(-i)：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -i 'The' demo.txt</span><br></pre></td></tr></table></figure><ol start="4"><li>在文件中匹配正则表达式：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep 'a*b' demo.txt</span><br></pre></td></tr></table></figure><ol start="5"><li>grep -w 完全匹配</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -w 'ab' demo.txt</span><br><span class="line">grep -iw 'ab' demo.txt # 不区分大小写</span><br></pre></td></tr></table></figure><ol start="6"><li>grep显示匹配出的前后几行</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -A 3 'a' demo.txt # 显示a出现的行，以及后三行</span><br><span class="line">grep -B 3 'a' demo.txt # 显示a出现的行，以及前三行</span><br><span class="line">grep -C 3 'a' demo.txt # 显示a出现的行，以及上下三行</span><br></pre></td></tr></table></figure><ol start="7"><li>用GREP_OPTIONS来让查找的项醒目</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export GREP_OPTIONS='--color=auto' GREP_COLOR='100;8'</span><br></pre></td></tr></table></figure><ol start="8"><li>用grep -r来搜索所有的文件及子目录</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -r 'file' *</span><br></pre></td></tr></table></figure><ol start="9"><li>显示不匹配的项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v 'match' demo.txt</span><br></pre></td></tr></table></figure><ol start="10"><li>匹配多个项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -e '1' -e 'a' -e 'q' demo.txt</span><br><span class="line">grep -v -e '1' -e 'q' demo.txt # 输出一个都不匹配的项</span><br></pre></td></tr></table></figure><ol start="11"><li>计算匹配的项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -c 'a' aw.txt</span><br><span class="line">grep -v -c 'a' aw.txt # 不匹配的项</span><br></pre></td></tr></table></figure><ol start="12"><li>显示匹配的文件名:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -l 'a' a*  #输出a开头且匹配的文件名</span><br></pre></td></tr></table></figure><ol start="13"><li>只显示匹配的字符串：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -o 'a.*b' aw.txt  # 而不是显示一行</span><br></pre></td></tr></table></figure><ol start="14"><li>显示匹配字符的行号:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n 'a' aw.txt</span><br></pre></td></tr></table></figure><ol start="15"><li>显示匹配字符的字节位置：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -b 'a' aw.txt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vim 学习</title>
      <link href="/2019/03/13/Vim-%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/03/13/Vim-%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="Vim-简介"><a href="#Vim-简介" class="headerlink" title="Vim 简介"></a>Vim 简介</h3><p>Vim是在Linux环境下的一种强大的文本编辑工具，之所以学习它，是由于在服务器上写代码需要直接在服务器上操作，不像windows上有那种简单课操作的编辑器，如sublime等等。</p><h3 id="Vim-模式"><a href="#Vim-模式" class="headerlink" title="Vim 模式"></a>Vim 模式</h3><p>Vim与大多数文本编辑器不同，它的默认模式为移动光标，删除文本等，而不是大多数编辑器那样直接为插入模式。</p><p><strong>普通模式：</strong></p><p>普通模式能进行的操作如移动光标，删除文本等。</p><p>删除指令：</p><p><code>dd</code> ：删除当前行</p><p><code>d</code>+ 上下左右移动指令，分别表示删除上一行，左一个，下一行，或右一个</p><p><code>2dd</code>: 删除两行</p><p><strong>插入模式：</strong></p><p>在普通模式按i，或a进入插入模式，ESC推出插入模式。</p><p><strong>可视模式：</strong></p><p>这个模式类似与普通模式，对样本有高亮</p><p><strong>命令行模式：</strong></p><p>在命令行模式中可以输入会被解释成并执行的文本。例如执行命令（<code>:</code>键），搜索（<code>/</code>和<code>?</code>键）或者过滤命令（<code>!</code>键）</p><h3 id="游标使用："><a href="#游标使用：" class="headerlink" title="游标使用："></a>游标使用：</h3><p>h，j，k，l：分别表示上下左右移动</p><p>w: 向下一个单词，b: 向上一个单词</p><h3 id="进入插入模式"><a href="#进入插入模式" class="headerlink" title="进入插入模式"></a>进入插入模式</h3><p><code>i</code> : 当前光标出插入</p><p><code>A</code>: 当前光标所在行最后一个位置插入 </p><p><code>o</code>: 当前光标的下一行插入</p><p><code>a</code>: 当前光标的后一个位置</p><h3 id="退出Vim模式"><a href="#退出Vim模式" class="headerlink" title="退出Vim模式"></a>退出Vim模式</h3><p><code>:x</code>: 保存并退出，等同于<code>:wq</code></p><p><code>:q!</code>: 强制退出，不保存</p><p><code>:q</code>: 退出不保存</p><p><code>shift + zz</code>: 退出并保存</p><h3 id="删除文本"><a href="#删除文本" class="headerlink" title="删除文本"></a>删除文本</h3><p>普通模式下的删除文本操作。</p><p><code>x</code>: 删除当前光标处的一个字符</p><p><code>X</code>:删除光标前一个字符</p><p><code>dd</code>: 删除整行</p><p><code>dw</code>: 删除整个单词</p><p><code>D</code>: 删除至句尾</p><p><code>d^</code>: 删除至句首</p><p><code>dG</code>: 删除至文章末尾</p><p><code>d1G</code>: 删除至文章开头</p><h3 id="重复执行上次命令"><a href="#重复执行上次命令" class="headerlink" title="重复执行上次命令"></a>重复执行上次命令</h3><p>普通模式下<code>.</code>表示重复执行上一次命令。执行相同执行操作代码：<code>N&lt;command&gt;</code>,如<code>10x</code>,<code>20dd</code>,<code>d5w</code>。</p><p>显示行号: <code>:set nu</code></p><h3 id="行间跳跃"><a href="#行间跳跃" class="headerlink" title="行间跳跃"></a>行间跳跃</h3><p><code>NG</code>: 游标跳到第N行</p><p><code>gg</code>: 游标跳到第一行</p><p><code>G</code>: 游标跳到最后一行</p><p><code>ctrl + o</code>: 回到上一次跳转的位置</p><h3 id="行内跳跃"><a href="#行内跳跃" class="headerlink" title="行内跳跃"></a>行内跳跃</h3><p><code>w</code>: 跳到下一个单词的开头</p><p><code>e</code>: 当前单词的结尾</p><p><code>0</code>: 跳到行头</p><p><code>$</code>: 跳到行尾</p><p><code>f 字母</code>：向后搜索字母并跳到第一个该字母的位置</p><p><code>F 字母</code>：向前搜索字母，第一个字母位置</p><p><code>t 字母</code>： 向后搜索字母，并跳到这个字母的前一个数</p><p><code>T 字母</code>： 向前搜索字母，并跳到其后一个数</p><p><code>~</code>: 将字母大小写转换</p><h3 id="文本的复制"><a href="#文本的复制" class="headerlink" title="文本的复制"></a>文本的复制</h3><p><code>yy</code>: 复制游标所在的整行</p><p><code>3yy</code>：复制3行</p><p><code>y0</code>: 复制到行首</p><p><code>y$</code>: 复制到行尾</p><h2 id="字符替换及坐标操作"><a href="#字符替换及坐标操作" class="headerlink" title="字符替换及坐标操作"></a>字符替换及坐标操作</h2><p><code>r + &lt;替换字母&gt;</code>: 替换掉光标所在位置的字母</p><p><code>R</code>： 连续替换，知道按下esc</p><p><code>cc</code>: 删掉这一行，换为插入模式</p><p><code>cw</code>: 删掉一个词然后进入插入模式</p><p><code>C</code>: 删除光标位置一直到行末，进入插入模式</p><p><code>u</code>: 撤销当前操作</p><p><code>U</code>: 撤销当前所有操作</p><h3 id="指令替换"><a href="#指令替换" class="headerlink" title="指令替换"></a>指令替换</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%s/imgs/car_openimg\/imgs # 使用car_openimg/imgs替换imgs</span><br></pre></td></tr></table></figure><h3 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h3><p><code>shift + &gt;</code>: 向右缩进</p><p><code>shift + &lt;</code>: 向左缩进</p><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p><code>/ + word</code>: 表示查找word，输入n或N查找下一个位置</p><p><code>? + word</code>: 与上相同，只不过查找方向不同</p><p><code>\*</code>: 查找游标所在位置的单词</p><p><code>g\*</code>： 查找部分符合要求的单词</p><h3 id="视窗"><a href="#视窗" class="headerlink" title="视窗"></a>视窗</h3><p><code>:new</code>: 新建视窗</p><p><code>:close</code>: 关闭视窗</p><p><code>:q</code>: 同上</p><h3 id="执行外部shell命令"><a href="#执行外部shell命令" class="headerlink" title="执行外部shell命令"></a>执行外部shell命令</h3><p><code>:! command</code>:执行外部shell 命令</p><p><code>:w filename</code>: 将当前编辑的文件另存为filename</p><p>vim 确认当前的括号：</p><p><code>shift + e</code>: 光标跳到当前内容的第一个框</p><p>重复上次操作：小数点 <code>.</code></p><h3 id="VIM-打开多个文件"><a href="#VIM-打开多个文件" class="headerlink" title="VIM 打开多个文件"></a>VIM 打开多个文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim 1.py 2.py</span><br><span class="line">:bn ## 切换</span><br></pre></td></tr></table></figure><h3 id="Vim-行移动"><a href="#Vim-行移动" class="headerlink" title="Vim 行移动"></a>Vim 行移动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dd,k,p</span><br></pre></td></tr></table></figure><p>k为向上移动，当移动到合适的位置时用p粘贴。</p><h3 id="tabe-多标签切换"><a href="#tabe-多标签切换" class="headerlink" title="tabe 多标签切换"></a>tabe 多标签切换</h3><p><code>:tabe a.txt</code>： 打开a.txt 文件</p><p><code>gt</code>: 在多标签中切换</p><p><code>:tabc</code> 关闭标签，或<code>:x</code>等</p><h3 id="vim-跳转到变量或函数的定义处"><a href="#vim-跳转到变量或函数的定义处" class="headerlink" title="vim 跳转到变量或函数的定义处"></a>vim 跳转到变量或函数的定义处</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ ,ctrl+i #跳转</span><br><span class="line">ctrl + o : #跳转回来</span><br></pre></td></tr></table></figure><p>查找鼠标所在位置的字符：<code>gd</code></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux trick</title>
      <link href="/2019/03/13/linux-trick/"/>
      <url>/2019/03/13/linux-trick/</url>
      
        <content type="html"><![CDATA[<h3 id="pickle-文件"><a href="#pickle-文件" class="headerlink" title="pickle 文件"></a>pickle 文件</h3><p>pickle文件的解释如下：</p><blockquote><p>It is used for serializing and de-serializing a Python object structure. Any object in python can be pickled so that it can be saved on disk. </p></blockquote><p>即用来将python对象序列化后存放在磁盘上的一个工具包。</p><p> Pickling is a way to convert a python object (list, dict, etc.) into a character stream.</p><p>pickle主要有两个功能，<code>dump</code> 以及<code>load</code>：</p><blockquote><p>pickle has two main methods. The first one is dump, which dumps an object to a file object and the second one is load, which loads an object from a file object.</p></blockquote><p>dump用来将dict，list等等保存成pickle文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line">file = open(<span class="string">'pickleObject.pickle'</span>,<span class="string">'wb'</span>)</span><br><span class="line">pickle.dump(a,file)</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure><p>load用来将pickle文件读出来，还原成python object</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">file = open(<span class="string">'pickleObject.pickle'</span>,<span class="string">'rb'</span>)</span><br><span class="line">b = pickle.load(file)  <span class="comment"># b == a is a dict</span></span><br><span class="line">print(b[<span class="string">'a'</span>])</span><br></pre></td></tr></table></figure><p><strong>linux 操作：</strong></p><p>管道命令?</p><p>查看文件夹下文件个数：</p><p><code>ls -l |grep &quot;^-&quot;|wc -l</code></p><p>写txt文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line">f = open(<span class="string">'a.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> a.keys():</span><br><span class="line">    f.write(key+<span class="string">'\n'</span>)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><p>读txt文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">'a.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">    print(line,end = <span class="string">''</span>)</span><br></pre></td></tr></table></figure><p>assert语句：</p><p>在发生错误时让算法崩溃。其用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression,<span class="string">'报错语句'</span></span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> expression:</span><br><span class="line">    <span class="keyword">raise</span> AssertionError</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> type(a_str)== str</span><br></pre></td></tr></table></figure><p>读当前文件夹下的文件名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> os.listdir(<span class="string">'./'</span>):</span><br><span class="line">    print(path)</span><br></pre></td></tr></table></figure><p>复制：将文件file1复制到dir1下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp file1 dir1</span><br></pre></td></tr></table></figure><p>python 找到最后一个.的位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str.rfind(<span class="string">'.'</span>, beg=<span class="number">0</span> end=len(str))</span><br></pre></td></tr></table></figure><h3 id="python-set操作"><a href="#python-set操作" class="headerlink" title="python set操作"></a>python set操作</h3><p>set 中保存不重复的key。</p><p>创建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aset = &#123;<span class="string">'apple'</span>,<span class="string">'orange'</span>,<span class="string">'pea'</span>&#125;</span><br></pre></td></tr></table></figure><p>判断set中是否含有key：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">'apple'</span> <span class="keyword">in</span> aset:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>set集合的交并集操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a-b <span class="comment"># a中包含而b中不包含的元素</span></span><br><span class="line">a|b <span class="comment"># a与b的元素并集</span></span><br><span class="line">a&amp;b <span class="comment"># a与b中元素的交集</span></span><br><span class="line">a^b <span class="comment"># 不同时包含于a与b中元素</span></span><br></pre></td></tr></table></figure><p>Set 删除操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aset.remove(<span class="string">'apple'</span>)</span><br></pre></td></tr></table></figure><p>Linux 复制文件夹：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r dirname .</span><br></pre></td></tr></table></figure><p>Vim 撤销：<code>u</code></p><p>python 在指定文件位置处添加字符后重新保存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">f1.open(<span class="string">'a.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line">content = f1.read()</span><br><span class="line">pos = content.find(<span class="string">'word'</span>)</span><br><span class="line">content = content[:word+<span class="number">4</span>]+<span class="string">'add something'</span>+content[word+<span class="number">4</span>:]</span><br><span class="line">f1.close()</span><br><span class="line">f2 = open(<span class="string">'a.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">f2.write(content)</span><br></pre></td></tr></table></figure><h3 id="shell-语言"><a href="#shell-语言" class="headerlink" title="shell 语言"></a>shell 语言</h3><p>用shell写成的文件通常被保存为<code>.sh</code>后缀。被称为脚本Bash的应用程序。 可以理解为在linux电脑上的一系列系统操作，比如下载文件，进入某个文件夹，下载某个文件等等。即可以通过shell程序来指挥kernel，让系统达成我们需要的硬件任务。</p><p>示例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Program:</span></span><br><span class="line"><span class="comment"># This program shows "Hello World!" in your screen.</span></span><br><span class="line"><span class="comment"># History:</span></span><br><span class="line"><span class="comment"># 2015/07/16 VBird First release</span></span><br><span class="line">PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/<span class="built_in">local</span>/bin:/usr/<span class="built_in">local</span>/sbin:~/bin</span><br><span class="line"><span class="built_in">export</span> PATH</span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"Hello World! \a \n"</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><p>第一行：<code>#!/bin/bash</code> 作用为宣告这个档案内的语法使用bash的语法，所有的sh文件必须有这一句。其他的<code>#</code> 则表示注释作用。</p><p><code>#</code> 号注释部分：建议你一定要养成说明该script的习惯：1.内容与功能； 2.版本资讯； 3.作者与联络方式； 4.建档日期；5.历史纪录等等</p><p>PATH部分为主要的环境变量，用来保存当前的路径信息。</p><p>echo那一句为程序的主要执行部分。</p><p>使用<code>sh hello.sh</code> 来执行代码。</p><p>shell变量：</p><p>变量名不加美元符号，而且变量名和等号之间不能有空格。使用变量是在变量名之前加上美元符：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">your_name=<span class="string">'zhouwh'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$your_name</span></span><br></pre></td></tr></table></figure><p>定义只读变量：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">myUrl=<span class="string">"http://www.google.com"</span></span><br><span class="line"><span class="built_in">readonly</span> myUrl  <span class="comment"># 之后无法修改</span></span><br></pre></td></tr></table></figure><p>删除变量：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unset</span> variable_name</span><br></pre></td></tr></table></figure><p>Shell 字符串：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str=<span class="string">'单引号，双引号，不用都行'</span></span><br><span class="line">str=<span class="string">"this is \" <span class="variable">$your_name</span> \""</span> <span class="comment">#需要转义的情况，双引号里头允许出现</span></span><br></pre></td></tr></table></figure><p>字符串拼接：直接使用双引号即可：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用双引号拼接</span></span><br><span class="line">greeting=<span class="string">"hello, "</span><span class="variable">$your_name</span><span class="string">" !"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$greeting</span></span><br></pre></td></tr></table></figure><p>获取字符串长度：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">string=<span class="string">"abcd"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#string&#125;</span> <span class="comment">#输出 4</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;string:1:3&#125;</span> <span class="comment"># 输出 bcd 子串</span></span><br></pre></td></tr></table></figure><p>控制语句：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if 语句</span></span><br><span class="line"><span class="keyword">if</span> condition</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    command1 </span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    commandN </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment"># for 语句</span></span><br><span class="line"><span class="keyword">for</span> loop <span class="keyword">in</span> 1 2 3 4 5</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"The value is: <span class="variable">$loop</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#while语句</span></span><br><span class="line"><span class="keyword">while</span> condition</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">command</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="awk-语句："><a href="#awk-语句：" class="headerlink" title="awk 语句："></a>awk 语句：</h3><p>awk是一个强大的文本分析工具，简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。其基本的用法如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'&#123;[pattern] action&#125;'</span> &#123;filenames&#125;</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）</span></span><br><span class="line">$ awk <span class="string">'&#123;print $1,$4&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 指定 , 为分割符（-F），将字符串分割</span></span><br><span class="line">$  awk -F, <span class="string">'&#123;print $1,$2&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 多个分割符，先用 空格后用 ,</span></span><br><span class="line">$ awk -F <span class="string">'[ ,]'</span>  <span class="string">'&#123;print $1,$2,$5&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 设置变量 -v</span></span><br><span class="line">$ awk -va=1 -vb=s <span class="string">'&#123;print $1,$1+a,$1b&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 过滤出第一列大于2的数</span></span><br><span class="line">$ awk <span class="string">'$1&gt;2'</span> log.txt </span><br><span class="line"><span class="comment"># CSV_PATH为输入，TRAIN_PATH为输出</span></span><br><span class="line">awk -v min_area=<span class="variable">$&#123;MIN_AREA&#125;</span> -F <span class="string">','</span> <span class="string">'&#123;</span></span><br><span class="line"><span class="string">    area=(($4-$2)*($5-$3));</span></span><br><span class="line"><span class="string">    if(area&gt;min_area)&#123;</span></span><br><span class="line"><span class="string">        print $0;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span>&lt;<span class="variable">$&#123;CSV_PATH&#125;</span> &gt;&gt; <span class="variable">$&#123;TRAIN_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除第一列</span></span><br><span class="line">awk <span class="string">'&#123;$1="";print $0&#125;'</span>  file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除第一行</span></span><br><span class="line">awk -F <span class="string">'\t'</span> <span class="string">'NR==1&#123;next&#125; &#123;print $0&#125;'</span> <span class="comment"># 当NR==1时跳过</span></span><br></pre></td></tr></table></figure><p><strong>CSV 文件</strong>（Comma Separated Values file，即逗号分隔值文件）为一种纯文本文件。</p><p>python 读取csv文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'stocks.csv'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f_csv = csv.reader(f)</span><br><span class="line">    headers = next(f_csv)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> f_csv:</span><br><span class="line">        <span class="comment"># Process row</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>python保存csv文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'some.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    writer.writerow([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure><p>python dict合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_dict = dict(dict1.items()+dict2.items())</span><br></pre></td></tr></table></figure><h3 id="Python-virtualenv"><a href="#Python-virtualenv" class="headerlink" title="Python virtualenv"></a>Python virtualenv</h3><p><code></code>virtualenv`创建一个拥有自己安装目录的环境, 这个环境不与其他虚拟环境共享库, 能够方便的管理python版本和管理python库。</p><p>安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure><p>创建新环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv zhou_env</span><br></pre></td></tr></table></figure><p>激活：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ./bin/activate</span><br></pre></td></tr></table></figure><p>退出虚拟环境：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure><h3 id="matplotlib-画图"><a href="#matplotlib-画图" class="headerlink" title="matplotlib 画图"></a>matplotlib 画图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">data = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">print(type(data))</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">绘制直方图</span></span><br><span class="line"><span class="string">data:必选参数，绘图数据</span></span><br><span class="line"><span class="string">bins:直方图的长条形数目，可选项，默认为10</span></span><br><span class="line"><span class="string">normed:是否将得到的直方图向量归一化，可选项，默认为0，代表不归一化，显示频数。normed=1，表示归一化，显示频率。</span></span><br><span class="line"><span class="string">facecolor:长条形的颜色</span></span><br><span class="line"><span class="string">edgecolor:长条形边框的颜色</span></span><br><span class="line"><span class="string">alpha:透明度</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">plt.hist(data, bins=<span class="number">40</span>, normed=<span class="number">0</span>, facecolor=<span class="string">"blue"</span>, edgecolor=<span class="string">"black"</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment"># 显示横轴标签</span></span><br><span class="line">plt.xlabel(<span class="string">"区间"</span>)</span><br><span class="line"><span class="comment"># 显示纵轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">"count"</span>)</span><br><span class="line"><span class="comment"># 显示图标题</span></span><br><span class="line">plt.title(<span class="string">"bbox—count"</span>)</span><br><span class="line">plt.savefig(<span class="string">'aimg.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="文件传输"><a href="#文件传输" class="headerlink" title="文件传输"></a>文件传输</h3><p><code>rz</code>: 在iterm2中输入rz指令，将会出现一个窗口选择文件，开始上传到当前文件夹。</p><p><code>sz filename</code>: iterm2 弹出一个窗口，选择保存文件的地址。 </p><p>vim 隐藏到后台：<code>ctrl + z</code></p><p>命令行调出vim：<code>fg</code></p><p>linux看文件大小：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls -lsh</span><br><span class="line">du -sh *</span><br></pre></td></tr></table></figure><h3 id="打包文件"><a href="#打包文件" class="headerlink" title="打包文件"></a>打包文件</h3><p>压缩：<code>tar czvf file.tar ./filename</code>,czvf表示create zip view file<br>解压缩：<code>tar xzvf file.tar</code>，xzvf表示extract zip view file</p><h3 id="过滤数据集中不合适的记录"><a href="#过滤数据集中不合适的记录" class="headerlink" title="过滤数据集中不合适的记录"></a>过滤数据集中不合适的记录</h3><ol><li>找出不合适的记录：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat all_box.csv | grep '不合适记录名'  # grep拿cat的输出当作输入</span><br></pre></td></tr></table></figure><ol start="2"><li>维护一个delete_imgs.txt 文件，用来存放不合适记录</li><li>使用delete_imgs.txt 文件中不合适记录来查看all_box.csv(数据集)中不合适的记录。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -f delete_imgs.txt  all_box.csv</span><br></pre></td></tr></table></figure><ol start="4"><li>删掉不合适记录，得到合适记录的输出，将输出存成一个新的new_box</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v -f delete_imgs.txt all_box.csv &gt; new_box.csv</span><br></pre></td></tr></table></figure><ol start="5"><li>查看剩下的合适条数：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat new_box.csv |wc -l # -l 行数 -w 字数</span><br></pre></td></tr></table></figure><h3 id="命令行输出"><a href="#命令行输出" class="headerlink" title="命令行输出"></a>命令行输出</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat *.csv &gt; all_box.csv</span><br></pre></td></tr></table></figure><p>awk判断字段1不重复的记录数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F ',' '!seen[$1++]' train_set.csv |wc -l</span><br></pre></td></tr></table></figure><p>linux 查看显卡运行状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><h3 id="python-shuffle操作"><a href="#python-shuffle操作" class="headerlink" title="python shuffle操作"></a>python shuffle操作</h3><p>shuffle操作将数据集打乱：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">list = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">random.shuffle(list)</span><br></pre></td></tr></table></figure><p>tmux:</p><p>tmux 可以在终端软件重启后通过命令行恢复上次的 session ,即当你训练网络中断时，下次开启仍然可以重新连接。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tmux ls  # 列出所有的tmux会话</span><br><span class="line">tmux new -s zhouwenhui  # 创建新的会话</span><br><span class="line">tmux -2 attach -t zhouwenhui # 重新进入原来的session</span><br><span class="line">ctrl + b , d # 暂时退出当前会话</span><br><span class="line">ctrl + b , c # 新建窗口</span><br><span class="line">ctrl + b , w # 切换窗口</span><br><span class="line">exit # 退出当前窗口</span><br></pre></td></tr></table></figure><h3 id="Linux创建账号"><a href="#Linux创建账号" class="headerlink" title="Linux创建账号"></a>Linux创建账号</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">useradd zhouwh</span><br><span class="line">passwd zhouwh</span><br><span class="line">userdel [-r] zhouwh # 删掉用户</span><br></pre></td></tr></table></figure><h3 id="Linux-给用户赋予root权限"><a href="#Linux-给用户赋予root权限" class="headerlink" title="Linux 给用户赋予root权限"></a>Linux 给用户赋予root权限</h3><p> vim /etc/passwd 文件，找到新创建的用户所在行，把用户ID修改为 0即可，如下。</p><blockquote><p>zhouwh​：x:0:1002::/home/zhouwh:/bin/bash</p></blockquote><h3 id="Linux用户切换"><a href="#Linux用户切换" class="headerlink" title="Linux用户切换"></a>Linux用户切换</h3><p>新建的用户的目录在/home/zhouwh底下，使用如下语句可以实现自由的切换。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su - zhouwh # 切换到zhouwh 用户</span><br><span class="line">su - root # 切换到root 用户</span><br></pre></td></tr></table></figure><h3 id="Linux-安装anaconda"><a href="#Linux-安装anaconda" class="headerlink" title="Linux 安装anaconda"></a>Linux 安装anaconda</h3><p>在anaconda上下载相应版本的安装软件，然后执行以下操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-4.4.0-Linux-x86_64.sh ## 安装</span><br><span class="line">echo 'export PATH="~/anaconda3/bin:$PATH"' &gt;&gt; ~/.bashrc# 环境变量</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 国内镜像</span><br><span class="line">rm -rf anaconda # 卸载</span><br></pre></td></tr></table></figure><h3 id="Json-的读写"><a href="#Json-的读写" class="headerlink" title="Json 的读写"></a>Json 的读写</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Writing JSON data:&#123;'a': 'Runoob', 'b': 7&#125;</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(data, f)</span><br><span class="line"><span class="comment"># Reading data back</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></table></figure><h3 id="dict-to-json"><a href="#dict-to-json" class="headerlink" title="dict to json"></a>dict to json</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  json.dump(data,f)</span><br></pre></td></tr></table></figure><h3 id="打开文件头几行-末尾几行"><a href="#打开文件头几行-末尾几行" class="headerlink" title="打开文件头几行/末尾几行"></a>打开文件头几行/末尾几行</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat afile.txt|head -n <span class="number">100</span></span><br><span class="line">cat afile.txt|tail -n <span class="number">100</span></span><br></pre></td></tr></table></figure><h3 id="指定运行的GPU"><a href="#指定运行的GPU" class="headerlink" title="指定运行的GPU"></a>指定运行的GPU</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2 python train.py</span><br></pre></td></tr></table></figure><h3 id="实时显示GPU使用率"><a href="#实时显示GPU使用率" class="headerlink" title="实时显示GPU使用率"></a>实时显示GPU使用率</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi -l 1</span><br></pre></td></tr></table></figure><h3 id="执行程序时滚动屏幕"><a href="#执行程序时滚动屏幕" class="headerlink" title="执行程序时滚动屏幕"></a>执行程序时滚动屏幕</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctrl+b 之后 + [</span><br></pre></td></tr></table></figure><h3 id="bashrc"><a href="#bashrc" class="headerlink" title=".bashrc"></a>.bashrc</h3><p>基于linux/unix的系统一般情况下都将 bash 作为默认的终端 shell。因此可以通过修改 bashrc 配置文件对执行的命令进行一些自定义。</p><p><strong>.bashrc是一个纯文本文件，用于保存和加载不同用户的终端首选项和环境变量</strong>,bash 在每次启动时都会自动载入 bashrc 配置文件中的内容。每次修改.bashrc文件后使用source ~/.bashrc进行环境的激活。</p><p><strong>终端首选项</strong>：最常用的一种方式为为linux系统命令定义别名，方便定制输入。</p><p><strong>环境变量：</strong>Linux是一个多用户操作系统，可以在linux中为不同的系统定制不同的环境变量。</p><h3 id="环境变量的设置"><a href="#环境变量的设置" class="headerlink" title="环境变量的设置"></a>环境变量的设置</h3><p>环境变量可以分为系统环境变量和用户环境变量。</p><h4 id="系统环境变量："><a href="#系统环境变量：" class="headerlink" title="系统环境变量："></a><strong>系统环境变量：</strong></h4><p>系统变量的设置将对所有的用户均生效。</p><p>对<code>/etc/profile</code>文件添加环境变量将对所有用户均有效。例如添加CLASSPATH变量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile    </span><br><span class="line">export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib</span><br></pre></td></tr></table></figure><h3 id="用户环境变量"><a href="#用户环境变量" class="headerlink" title="用户环境变量"></a>用户环境变量</h3><p>在用户目录下修改文件.bash_profile,改变的量仅对该用户有效。如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash.profile</span><br><span class="line">export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib</span><br></pre></td></tr></table></figure><p>直接在命令行运行：<code>export 变量名=变量值</code>仅对当前的shell有效。</p><h3 id="bashrc-profile-bash-profile-的区别"><a href="#bashrc-profile-bash-profile-的区别" class="headerlink" title=".bashrc,profile,.bash.profile 的区别"></a>.bashrc,profile,.bash.profile 的区别</h3><p><img src="../images/codingTip/peizhifile.png" alt=""></p><h3 id="Linux-中常见的环境变量"><a href="#Linux-中常见的环境变量" class="headerlink" title="Linux 中常见的环境变量"></a>Linux 中常见的环境变量</h3><p><strong>PATH：</strong>指定命令的搜索路径,中间用冒号隔开。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=&lt;PATH1&gt;:&lt;PATH2&gt;:&lt;PATH3&gt;:&lt;PATH4&gt;</span><br></pre></td></tr></table></figure><p>在配置文件中修改PATH：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH='~/anaconda3/bin/:$PATH'</span><br></pre></td></tr></table></figure><p><strong>HOME：</strong>指定用户的主工作目录</p><p><strong>HISTSIZE：</strong>指保存历史命令记录的条数</p><p><strong>LOGNAME：</strong>指当前用户的登录名。</p><p><strong>HOSTNAME：</strong>指主机的名称</p><p><strong>SHELL：</strong>指当前用户用的是哪种Shell</p><p><strong>LANG/LANGUGE：</strong>和语言相关的环境变量</p><h3 id="Linux-查看环境变量"><a href="#Linux-查看环境变量" class="headerlink" title="Linux 查看环境变量"></a>Linux 查看环境变量</h3><ul><li>echo 显示某个环境变量值 echo $PATH</li><li>export HELLO=”hi” 设置新的环境变量</li><li>env 显示所有环境变量</li></ul><h3 id="linux-创建快捷键"><a href="#linux-创建快捷键" class="headerlink" title="linux 创建快捷键"></a>linux 创建快捷键</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias ict="ssh xxx@ictvr.ml -p 11111"</span><br></pre></td></tr></table></figure><h3 id="Linux-打印出目录下文件决定路径"><a href="#Linux-打印出目录下文件决定路径" class="headerlink" title="Linux 打印出目录下文件决定路径"></a>Linux 打印出目录下文件决定路径</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for f in 'ls cat';do echo '/data/cartoon_detect_data/'$f;done &gt; total.txt</span><br></pre></td></tr></table></figure><h3 id="python-查看文件大小"><a href="#python-查看文件大小" class="headerlink" title="python 查看文件大小"></a>python 查看文件大小</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lht</span><br></pre></td></tr></table></figure><h3 id="下载视频"><a href="#下载视频" class="headerlink" title="下载视频"></a>下载视频</h3><p>runonce服务器上,sh tmp.sh,/root/cartoon_data_prepare，其中需要视频id，从表格中读取。</p><h3 id="linux截取字符串前n个字符"><a href="#linux截取字符串前n个字符" class="headerlink" title="linux截取字符串前n个字符"></a>linux截取字符串前n个字符</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -c1-100 file.py # 前100个字符</span><br></pre></td></tr></table></figure><h3 id="linux-shell判断外部传入的参数"><a href="#linux-shell判断外部传入的参数" class="headerlink" title="linux shell判断外部传入的参数"></a>linux shell判断外部传入的参数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ ! -n "$1" ] ;then  # 判断是否有个参数</span><br><span class="line">    echo "you have not input a word!"</span><br><span class="line">else</span><br><span class="line">    echo "the word you input is $1"</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># </span></span></span><br><span class="line">if [-e "$1"] ; then #判断传入的参数是否是个文件/目录</span><br></pre></td></tr></table></figure><h3 id="linux-批量更改文件名"><a href="#linux-批量更改文件名" class="headerlink" title="linux 批量更改文件名"></a>linux 批量更改文件名</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rename 's/search/replace/;' test*.jpg</span><br></pre></td></tr></table></figure><h3 id="linux-awk复制文件"><a href="#linux-awk复制文件" class="headerlink" title="linux awk复制文件"></a>linux awk复制文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $1&#125;'</span> ~/zhouwenhui/mAP/test_set.csv| <span class="keyword">while</span> read day ; do  cp <span class="string">"$day"</span> <span class="string">"./aaa"</span>; done</span><br></pre></td></tr></table></figure><h3 id="创建软链接"><a href="#创建软链接" class="headerlink" title="创建软链接"></a>创建软链接</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s a/path to/soft_path</span><br></pre></td></tr></table></figure><p>soft_path为软链接。</p><h3 id="linux-批量删除文件"><a href="#linux-批量删除文件" class="headerlink" title="linux 批量删除文件"></a>linux 批量删除文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf PAD8_*.jpg</span><br></pre></td></tr></table></figure><h3 id="传输大文件"><a href="#传输大文件" class="headerlink" title="传输大文件"></a>传输大文件</h3><p>mac上通过rz,sz与服务器之间传输文件，由于文件过大（百兆）容易导致内存不足。因此需要先将文件拆分后一个一个上传（下载）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">split -b100k ev.zip ev  # 将ev.zip文件分成每个文件100k的小文件，由ev开头，如evab ...</span><br><span class="line">md5sum ev.zip # 查看原文件的md5值</span><br><span class="line">sz ev* # 将小文件依次下载</span><br><span class="line">cat ev* &gt; ev.zip #本地将所有小文件还原</span><br><span class="line">md5sum ev.zip  #查看还原文件的md5值，是否之前相同</span><br></pre></td></tr></table></figure><h3 id="查看后台进程"><a href="#查看后台进程" class="headerlink" title="查看后台进程"></a>查看后台进程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux</span><br></pre></td></tr></table></figure><h3 id="杀死进程"><a href="#杀死进程" class="headerlink" title="杀死进程"></a>杀死进程</h3><p>当执行一个多线程的任务的时候，使用 ctrl+z停止进程，然后根据进程的id号，依次杀死进程。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow 笔记（CNN分类器VI）</title>
      <link href="/2019/03/13/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88CNN%E5%88%86%E7%B1%BB%E5%99%A8VI%EF%BC%89/"/>
      <url>/2019/03/13/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88CNN%E5%88%86%E7%B1%BB%E5%99%A8VI%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="CNN分类网络"><a href="#CNN分类网络" class="headerlink" title="CNN分类网络"></a>CNN分类网络</h2><p>CNN网络在原来网络的基础上加入了卷积层，对特征进行提取后分类，能够提升网络的分类准确率，同时在网络中加入了dropout，缓解网络的过拟合。</p><a id="more"></a><p>写一个分类器的基本思路如下：</p><p><strong>Assemble graph:</strong></p><ol><li>read data</li><li>create placeholder</li><li>create weight and bias in a layer</li><li>create a net structure</li><li>specify loss function</li><li>create optimizer</li></ol><p><strong>train model:</strong></p><ol><li>specify the epochs,iteration,batch-size</li><li>initial variables</li><li>step by step run the optimizer（use feed_dict to feed data into x,y placeholder）</li></ol><p><strong>tf.Session() encapsulates the environment</strong></p><p>对于mnist分类来说，需要注意的是，我们将输入向量的大小设置成28*28*1的形式，然后通过卷积进行操作。如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">x_image = tf.reshape(xs,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>]) <span class="comment"># [nsample,width,height,channel]</span></span><br></pre></td></tr></table></figure><p>对于卷积层tensorflow中使用<code>tf.nn.conv2d</code>来创建。该函数的参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(input,W,stride,padding)</span><br><span class="line"><span class="comment"># input表示输入的参数</span></span><br><span class="line"><span class="comment"># filter:W表示卷积核的参数即：[kernel_w,kernel_h,in_channel,out_channel]</span></span><br><span class="line"><span class="comment"># stride表示步长：[1,x_move,y_move,1]</span></span><br><span class="line"><span class="comment"># padding = 'SAME' / 'VALID' 卷积后大小不变 / 卷积后大小变小</span></span><br></pre></td></tr></table></figure><p>创建一个卷积层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x)</span>:</span></span><br><span class="line"> <span class="comment"># conv weight: [kernel_w,kernel_h,in_channel,out_channel]</span></span><br><span class="line">    Weights = tf.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>],stddev = <span class="number">0.1</span>)</span><br><span class="line">    bias = tf.constant(<span class="number">0.1</span>,[<span class="number">32</span>])</span><br><span class="line">    <span class="comment"># stride = [1,x_move,y_move,1]</span></span><br><span class="line">    output = tf.nn.conv2d(x,Weight,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding = <span class="string">'SAME'</span>)</span><br><span class="line">    <span class="keyword">return</span> output+bias</span><br></pre></td></tr></table></figure><p>对于池化层，tensorflow中使用的函数<code>tf.nn.max_pool</code>，该函数的参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.max_pool(input,ksize,stride,padding)</span><br><span class="line"><span class="comment"># input为输入的数据</span></span><br><span class="line"><span class="comment"># ksize:表示卷积核大小，[1,kernel_w,kernel_h,1]</span></span><br><span class="line"><span class="comment"># stride: [1,x_move,y_move,1]</span></span><br><span class="line"><span class="comment"># padding = 'SAME' / 'VALID'</span></span><br></pre></td></tr></table></figure><p>创建一个max pooling 层:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pooling</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding = <span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure><p>dropout层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.dropout(x,keep_prob = <span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># x: 输入的向量</span></span><br><span class="line"><span class="comment"># keep_prob：dropout的比例</span></span><br><span class="line"><span class="comment"># keep_prob通常是一个tf.placeholder,在训练时设为一个小数，在测试时设为1</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create placeholder</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])/<span class="number">255.</span></span><br><span class="line">    ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line">    keep_prob = tf.placeholder(tf.float32) <span class="comment"># dropout rate</span></span><br><span class="line">    x_image = tf.reshape(xs,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>]) <span class="comment"># nsample,28,28,channel</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'conv1'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">32</span>]))</span><br><span class="line">    out_conv1 = tf.nn.conv2d(x_image,Weights,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)+bias <span class="comment"># 28,28,32</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'pool1'</span>):</span><br><span class="line">    out_pool1 = tf.nn.max_pool(out_conv1,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>) <span class="comment"># 14,14,32</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'conv2'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">64</span>]))</span><br><span class="line">    out_conv2 = tf.nn.conv2d(out_pool1,Weights,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>) <span class="comment">#[14,14,64]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'pool2'</span>):</span><br><span class="line">    out_pool2 = tf.nn.max_pool(out_conv2,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)<span class="comment">#[7,7,64]</span></span><br><span class="line">    out_pool2 = tf.reshape(out_pool2,[<span class="number">-1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>]) <span class="comment"># nsample,7*7*64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc1'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">1024</span>]))</span><br><span class="line">    out_fc1 = tf.nn.relu(tf.matmul(out_pool2,Weights)+bias)</span><br><span class="line">    drop_out_fc1 = tf.nn.dropout(out_fc1,keep_prob) <span class="comment"># nsample,1024</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc2'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">1024</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape=[<span class="number">10</span>]))</span><br><span class="line">    prediction = tf.matmul(drop_out_fc1,Weights)+bias <span class="comment"># nsample,10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create running environment</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment">## compute accuracy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(X,Y)</span>:</span></span><br><span class="line">    pred = sess.run(prediction,feed_dict=&#123;xs:X,keep_prob:<span class="number">1</span>&#125;)</span><br><span class="line">    correct = tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(Y,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))</span><br><span class="line">    <span class="keyword">return</span> sess.run(accuracy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'optimizer'</span>):</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#initialization</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># visualization</span></span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'./log'</span>,sess.graph)</span><br><span class="line"><span class="comment"># train</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch,keep_prob:<span class="number">0.5</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(mnist.test.images[:<span class="number">1000</span>],mnist.test.labels[:<span class="number">1000</span>]))</span><br></pre></td></tr></table></figure><h3 id="Tensorflow-保存变量"><a href="#Tensorflow-保存变量" class="headerlink" title="Tensorflow 保存变量"></a>Tensorflow 保存变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w = tf.Variable([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],dtype = tf.float32,name = <span class="string">'weight'</span>)</span><br><span class="line">b = tf.Variable([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]],dtype = tf.float32,name = <span class="string">'bias'</span>)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"my_net/save_net.ckpt"</span>)</span><br><span class="line">    print(<span class="string">"Save to path: "</span>, save_path)</span><br></pre></td></tr></table></figure><h3 id="提取变量restore"><a href="#提取变量restore" class="headerlink" title="提取变量restore"></a>提取变量restore</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 先建立 W, b 的容器</span></span><br><span class="line">W = tf.Variable(np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>)), dtype=tf.float32, name=<span class="string">"weights"</span>)</span><br><span class="line">b = tf.Variable(np.arange(<span class="number">3</span>).reshape((<span class="number">1</span>, <span class="number">3</span>)), dtype=tf.float32, name=<span class="string">"biases"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里不需要初始化步骤 init= tf.initialize_all_variables()</span></span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 提取变量</span></span><br><span class="line">    saver.restore(sess, <span class="string">"my_net/save_net.ckpt"</span>)</span><br><span class="line">    print(<span class="string">"weights:"</span>, sess.run(W))</span><br><span class="line">    print(<span class="string">"biases:"</span>, sess.run(b))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SSD M2Det 详解</title>
      <link href="/2019/03/10/SSD-M2Det-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/10/SSD-M2Det-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>SSD是经典的one-stage算法，可以认为是关于类别的多尺度分类网络，作为很多one-stage网络的基础框架，有必要阅读一下。</p><p>M2Det是今年（2019）CPVR论文，基于SSD框架的扩展，M2Det 若采用 single-scale inference 可达到 11 FPS, AP 41 的准确率，采用 multi-scale inference 可达到 AP 44.2 的准确度。</p><a id="more"></a><h2 id="SSD-详解"><a href="#SSD-详解" class="headerlink" title="SSD 详解"></a>SSD 详解</h2><blockquote><p>SSD: Single Shot MultiBox Detector</p><p>submit time：2015</p><p><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="网络的背景及作用"><a href="#网络的背景及作用" class="headerlink" title="网络的背景及作用"></a>网络的背景及作用</h3><p>当前网络通过提取候选框等方式进行目标检测，运行速度对于一些应用场景来说太慢了。</p><p>SSD是一种使用单个深度神经网络来检测图像中的目标的方法，SSD 速度的根本改进来自消除边界框proposal和随后的像素或特征重采样阶段。他的主要特点如下：</p><ul><li>one-stage检测器，用于多个类别目标检测，比先前技术相比（YOLO）速度更快，且更准确。</li><li>SSD方法的核心是<strong>使用小卷积滤波器来预测特征图上固定的一组默认边界框的类别分数和位置偏移。</strong></li><li>为了实现高检测精度，我们从<strong>不同尺度的特征图产生不同尺度的预测</strong>，并且通过宽高比来明确地分离预测。</li><li>这些设计特性得到了简单的端到端训练和高精度，进一步提高速度和精度的权衡，即使输入相对低分辨率图像。</li></ul><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/images/article/SSD.png" alt=""></p><p>SSD的检测过程如下：</p><ol><li>SSD输入为包含类别以及真实框标记的图片数据。 </li><li>卷积处理时，我们在具有不同尺度（例如（b）和（c）中的8×8和4×4）的若干特征图中的<strong>每个位置处选择不同横宽比的小集合（例如4个）默认框</strong>。 </li><li>对于每个默认框，我们预测对所有对象类别（c 1，c2，…，cp）的形状偏移和置信度。在训练时，我们首先将这些默认框匹配到真实标签框。 例如，两个默认框匹配到猫和狗，这些框为正，其余视为负。 </li><li>模型损失是位置损失（例如平滑L1 [6]）和置信损失（例如Softmax）之间的加权和。 </li></ol><p> SSD方法基于前馈卷积网络，采用多尺度特征度检测的方式，产生固定大小的边界框集合和框中对象类别的分数，接着是非最大化抑制步骤以产生最终检测,如下图：</p><p><img src="/images/article/SSDstructure.png" alt=""></p><ul><li><p>输入：300x300</p></li><li><p>经过VGG-16（只到conv4_3这一层，由于更深的网络特征难以恢复）</p></li><li><p>经过几层卷积，得到多层尺寸逐渐减小的feature map</p></li><li><p>每层feature map分别做3x3卷积，每个feature map cell对应k个类别和4个bounding box offset，同时对应原图中6（或4）个anchor，<strong>即每一个位置将会预测4或6个anchor，然后每个anchor有k个类别概率值以及4个位置偏移值。</strong></p></li><li><p>38x38层, 最后3x3层, 1x1层三个feature map的每个feature map cell只对应4个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，其他feature map的feature map cell对应6个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，1:3， 3:1两种。因此总共有<br>$$<br>38* 38*4+19*19*6+10*10*6+5*5*6+3*3*4+1*1*4=8732<br>$$<br>个anchor。</p></li></ul><h3 id="anchor的中心："><a href="#anchor的中心：" class="headerlink" title="anchor的中心："></a>anchor的中心：</h3><p>每层的feature map cell对应的anchor中心的计算方法如下<br>$$<br>(\frac{i+0.5}{|fk|},\frac{j+0.5}{|fk|})<br>$$<br>其中i,j是当前的位置，fk是当前feature map的大小。</p><h3 id="anchor缩放因子"><a href="#anchor缩放因子" class="headerlink" title="anchor缩放因子:"></a>anchor缩放因子:</h3><p>$$<br>S_k = S_{min}+\frac{S_{max}-S_{min}}{m-1} (k-1),k\in[1,m]<br>$$</p><p>缩放因子指不同大小的feature map对应不同大小的anchor。<em>m</em>表示最终有m个 feature maps将要作为预测,对每一个k层的feature map计算其anchor的大小，即$ S_k$。 此外$S_{min}$ 为 0.2，$S_{max}$ 为 0.9。因此对于所有层，scale都在[0.2,0.9]之间。</p><p>对于每一个尺度，都可以计算其相应的anchor大小，如下：<br>$$<br>\begin{align}<br>w_k^{\alpha} &amp;= S_k \sqrt{\alpha_r} \\<br>h_k^{\alpha} &amp;= S_k \sqrt{\alpha_r}\\<br>\alpha \in &amp;{1,2,3,\frac{1}{2},\frac{1}{3}}<br>\end{align}<br>$$<br>特别的，当 $a_r=1$ 时，增加一种 $s_k = \sqrt{s_{k-1}{s_{k+1}}}$ ，对应6种anchor的长宽比，对于4个anchor来说，不使用3和$\frac{1}{3}$。</p><h3 id="网络损失函数"><a href="#网络损失函数" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>SSD的损失函数由两部分组成，分别是置信度损失（softmax loss)以及位置损失（L1 loss），如下：<br>$$<br>L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))<br>$$<br>其中N是匹配的GT框个数，当N = 0时loss等于0。$\alpha$是置信度与位置loss之间的一个权衡因子。</p><p>对于置信度loss ：<br>$$<br>L_{conf}(x,c) = - \sum_{i\in Pos}^N x_{ij}^p log(\hat{c}_{i}^p) - \sum_{i\in Neg} log(\hat{c}_{i}^0)\quad where \quad\hat{c}_{i}^p=\frac{exp^{c_{i}^p}}{\sum_p exp(c_{i}^p)}<br>$$<br>即softmax的交叉熵loss。</p><p>位置损失如下：<br>$$<br>\begin{align}<br>L_{loc}(x,l,g)&amp;=\sum_{i\in Pos}^N \sum_{m \in {cx,cy,w,h}}x_{ij}^k smooth_{L1}(l_i^m-\hat{g}_j^m) \\<br>\hat{g}_j^{cx}&amp;=(g_j^{cx}-d_i^{cx})/d_i^w \quad \hat{g}_j^{cy}=(g_j^{cy}-d_i^{cy})/d_i^h\\<br>\hat{g}_j^{w}&amp;=log(\frac{g_j^w}{d_i^w})\quad \hat{g}_j^{h}=log(\frac{g_j^h}{d_i^h})<br>\end{align}<br>$$<br>其中g表示GT的边框中心，d表示预测的边框的中心，该loss与Faster RCNN的loss 相同。即我们去学习的是边框的偏移量，而不是直接预测边框。当预测值l与g的指标相同时即完成，反向可推导出目标的边框。</p><h3 id="样本选择"><a href="#样本选择" class="headerlink" title="样本选择"></a>样本选择</h3><p>正样本：预测框与GT的重叠程度大于0.5的认为是正样本</p><p>副样本：将边框置信度排序，找出置信度高的边框，保持正负比例为1:3.</p><h3 id="train-trick"><a href="#train-trick" class="headerlink" title="train trick"></a>train trick</h3><p><img src="/images/article/ssdtrain.png" alt=""></p><p>SSD使用了诸如数据增强，空洞卷积等操作，是的进度进一步提升。</p><p>数据增强的方式为：</p><ul><li>整图输入</li><li>截取图上一部分进行输入</li><li>随机crop</li><li>将上面的图片都resize到一个固定大小，输入网络</li></ul><h3 id="MS-COCO上的精度"><a href="#MS-COCO上的精度" class="headerlink" title="MS COCO上的精度"></a>MS COCO上的精度</h3><p>SSD在coco上的精度如下：</p><p><img src="/images/article/ssdcocoTest.png" alt=""></p><hr><h2 id="M2Det-详解"><a href="#M2Det-详解" class="headerlink" title="M2Det 详解"></a>M2Det 详解</h2><p>M2Det是一个one-stage的目标检测网络。基于SSD框架扩展而来。主要的思想是Multi-Level Feature Pyramid Network(MLFPN)，多层次的特征金字塔网络。</p><h3 id="网络的背景及应用"><a href="#网络的背景及应用" class="headerlink" title="网络的背景及应用"></a>网络的背景及应用</h3><p>论文中提出物体分类和物体检测问题上的缩放尺度变化矛盾，即物体分类模型提取高层次的特征，高层次的特征往往更容易学到具有辨别力的信息，模型会专注于一些辨认力强的点，例如鸟🐦，倾向于检测翅膀。</p><p>但是由于物体检测问题需要将整个物体框起来，仅仅识别出有辨别力的点无法保证完全把目标框起来，因此作者提出使用浅层的特征来辅助学习目标的检测任务，即确定边框位置。</p><p><strong>因此高阶的特征有助于分类，低价的特征有助于物体的检测。</strong></p><p>作者提出，通常解决尺度变化的问题采样的方法是<strong>从输入图像提取出的特征金字塔，从而克服原始图片的缩放问题</strong>。该方法可以同时用于训练和测试阶段中，相对开销较小，易于集成，适合end-to-end。本文的目的即是构造一个更加高效的金字塔模型用于检测不同缩放大小的对象。作者将该结构加入到SSD中去，取得了超过benchmark的成绩。</p><h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p>作者通过对比多种金字塔特征提取方式，总结了这些模型的确定，并提出自己的特征提取方式。</p><p>先前模型的缺点：</p><ul><li>先前的模型都是基于分类网络作为特征提取的主干网络，对目标检测任务而言，先前金字塔结构提取的特征表达不足以预测目标位置。即特征太少。</li><li>每个feature map仅由主干网络的single level给出，仅含单层信息不够全面。</li></ul><p><img src="/images/article/M2detpyramid.png" alt=""></p><ul><li>SSD型：使用了主干网络的最后两层，再加上4个使用stride=2卷积的下采样层构成；</li><li>FPN型：也称为U型网络，经过上采样操作，然后对应融合相同的scale；</li><li>STDN型：基于DenseNet的最后一个dense block，通过池化和scale-transfer操作来构建；</li><li>MLFPN型：Multi-level&amp;Multi-scale</li></ul><p>MLFPN结构如下，对主干网络(vgg)提取到的特征进行融合；然后通过TUM和FFM提取更有代表性的Multi-level&amp;Mutli-scale特征；最后通过SFAM融合多级特征，得到多级特征金字塔用于最终阶段的预测。</p><p><img src="/images/article/M2Detstructure.png" alt=""></p><h3 id="FFMv1"><a href="#FFMv1" class="headerlink" title="FFMv1"></a>FFMv1</h3><p>FFMv1整合了VGG网络中浅层conv4_3的特征以及深层conv5_3的特征作为base feature（从Figure1中可以看出）。其结构如下所示，先进行一个1*1的卷积压缩channel，然后upsample到相同的大小，进行如何得到base feature。</p><p><img src="/images/article/MMFv1.png" alt=""></p><p>###TUM</p><p>TUM的结构是一个U-Net的结构，如Figure1所示。他的内部结构如下：</p><p><img src="/images/article/TUM.png" alt=""></p><p> TUM结构输出的左右feature map均输入SFAM中，同时将最大一个feature map(128,40,40)传入FFMv2中作为下一次TUM的输入。</p><h3 id="FFMv2"><a href="#FFMv2" class="headerlink" title="FFMv2"></a>FFMv2</h3><p>FFMv2输入为base feature与上一层最大的feature map结构如下：</p><p><img src="/images/article/ffmv2.png" alt=""></p><p>通过堆叠TUM以及FFMv2产生不同层次的feature map，最终分别提取出图片的shallow，medium，deep的特征。每个TUM以及FFMv2的输出特征计算如下：</p><p><img src="/images/article/multi-scale.png" alt=""></p><h3 id="尺度特征聚合模块SFAM"><a href="#尺度特征聚合模块SFAM" class="headerlink" title="尺度特征聚合模块SFAM"></a>尺度特征聚合模块SFAM</h3><p>SFAM负责将每个金字塔的输入聚合起来，得到Multi-level feature pyramid。然后输出值prediction layer。</p><p><img src="/images/article/SFAM.png" alt=""></p><p>每个TUM都会输出一个六层的特征金字塔，SFAM首先对每一层相同channel的特征进行融合。第二步采用SENet的方法，即是透过 Fully-connected layer 来学习每个 feature 应该给多少权重。最终 prediction layer 会接受的是 i 个不同尺度的 Feature maps。</p><h3 id="模块配置"><a href="#模块配置" class="headerlink" title="模块配置"></a>模块配置</h3><ul><li>M2Det 网络采用VGG-16和ResNet-101作为特征提取的主干网络。</li><li>MLFPN的默认配置包含有8个TUM，每个TUM包含5个跨步卷积核5个上采样操作，输出为6个不同scale的特征。</li><li>在检测阶段，<strong>为6组金字塔特征每组后面添加两个卷积层，以分别实现位置回归和分类。</strong></li><li>后处理阶段，使用soft-NMS来过滤无用的包围框。</li></ul><h3 id="网络损失函数-1"><a href="#网络损失函数-1" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>网络的顺势函数沿用了SSD的方法，即置信度softmax损失以及边框回归损失。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>data training tip</title>
      <link href="/2019/03/08/data%20training%20tip/"/>
      <url>/2019/03/08/data%20training%20tip/</url>
      
        <content type="html"><![CDATA[<h2 id="Json-文件格式切换"><a href="#Json-文件格式切换" class="headerlink" title="Json 文件格式切换"></a>Json 文件格式切换</h2><p>数据集中Json文件挤在一堆，需要将其格式化输出，Json文件格式化代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">json.dumps(&#123;<span class="string">'a'</span>: <span class="string">'Runoob'</span>, <span class="string">'b'</span>: <span class="number">7</span>&#125;, sort_keys=<span class="keyword">False</span>, indent=<span class="number">4</span>, separators=(<span class="string">','</span>, <span class="string">': '</span>))</span><br><span class="line"><span class="comment"># 输出如下：</span></span><br><span class="line"><span class="comment">#&#123;</span></span><br><span class="line"><span class="comment">#    "a": "Runoob",</span></span><br><span class="line"><span class="comment">#    "b": 7</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure><p>文件改写实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'../dataset/train_round1/train_no_poly.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> fin:</span><br><span class="line">    js = json.load(fin)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'train_no_poly.json'</span>, <span class="string">'w+'</span>) <span class="keyword">as</span> fout:</span><br><span class="line">        json.dump(js, fout,sort_keys=<span class="keyword">False</span>, indent=<span class="number">4</span>, separators=(<span class="string">','</span>, <span class="string">': '</span>),ensure_ascii=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p><strong>Json 处理字符串读写和文件读写：</strong></p><p>处理字符串：<code>json.loads(fileDir)</code>得到字符串，<code>json.dumps(dataDict)</code>得到Json文件。</p><p>处理文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Writing JSON data</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(data, f)</span><br><span class="line"><span class="comment"># Reading data back</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></table></figure><h2 id="MAC-git-使用"><a href="#MAC-git-使用" class="headerlink" title="MAC git 使用"></a>MAC git 使用</h2><p><strong>安装Git</strong>：<a href="https://www.jianshu.com/p/7edb6b838a2e" target="_blank" rel="noopener">链接</a></p><p><strong>验证是否成功链接远程github</strong>：<code>ssh -T git@github.com</code>，如果正确返回 hi wenhui-zhou.</p><p><strong>提交本地项目到GitHub上</strong>：</p><ol><li><p>在GitHub网站上创建一个仓库</p></li><li><p>复制其clone 链接，将仓库clone到本地:</p><p><code>git clone git@github.com:WenHui-Zhou/learnGit.git</code></p></li><li><p>打开learnGit文件夹，将工程文件保存在这个目录下</p></li><li><p>提交修改，将工程上传到GitHub上</p><p><code>git add fileName</code>：在仓库目录下，将文件添加到本地仓库。</p><p><code>git add .</code> ：将所有文件添加到本地仓库。</p><p><code>git commit -m &quot;some comments&quot;</code>：添加评论。</p><p><code>git push</code>：上传到远端仓库。</p></li></ol><h3 id="github-更新文件"><a href="#github-更新文件" class="headerlink" title="github 更新文件"></a>github 更新文件</h3><ol><li><code>git status</code>：查看仓库状态，如果有所不同的话，会显示不同的文件。</li><li><code>git add file</code>：将更改的文件加入到本地仓库。</li><li><code>git commit -m &quot;comment&quot;</code>：添加评论。</li><li><code>git push</code>：将代码提交到GitHub上。</li></ol><h3 id="git-getch"><a href="#git-getch" class="headerlink" title="git getch"></a>git getch</h3><p>当与人协作时，远程主机有了更新，可以通过<code>git fetch</code> 来取得更新的内容。</p><ol><li><code>git fetch origin master:tmp</code>，在本地创建一个tmp分支，将远程master 分支的代码下载到tmp分支上。</li><li><code>git diff tmp</code>，比较本地代码与从远端下载下来的代码的区别。</li><li><code>git merge tmp</code>，合并分支到本地的master。</li><li><code>git branch -d tmp</code>，如果不想要tmp分支的话，则可以删除。</li></ol><h3 id="git-pull"><a href="#git-pull" class="headerlink" title="git pull"></a>git pull</h3><p><code>git pull</code>：将远端代码与本地代码直接融合，等于上面的git fetch + git merge。</p><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>将本地<strong>更新的分支</strong>推送到远程主机。因此我们每次进行远端数据的更新操作之前需要更新一下本地的分支。即：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m "comment" // 在本地分支上添加文件并添加评论</span><br><span class="line">git push  // 将远端分支进行更新</span><br></pre></td></tr></table></figure><h3 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h3><p>在GitHub上点击fork将其他用户的仓库更新到自己的GitHub下，然后进行clone到本地，进行一些工程上的修改。这个库当前属于你，照样执行上面的<code>git push</code>等操作。完成后在GitHub上发起pull request，然后系统会对比两个工程的修改之处，然后发起request，在其他用户那边将会多一个request操作，可以同意，则进行merge。</p><h3 id="同步fork的库与原始的库"><a href="#同步fork的库与原始的库" class="headerlink" title="同步fork的库与原始的库"></a>同步fork的库与原始的库</h3><p>使用指令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git remote add  //添加本地库</span><br><span class="line">git fetch       // 将远端的不同fetch到本地</span><br><span class="line">git merge        // 融合</span><br><span class="line">git push         // 更新到自己的GitHub上</span><br></pre></td></tr></table></figure><h3 id="iteration、epoch、batchsize的含义"><a href="#iteration、epoch、batchsize的含义" class="headerlink" title="iteration、epoch、batchsize的含义"></a>iteration、epoch、batchsize的含义</h3><ul><li>epoch：数据集所有数据训练过一遍为一个epoch，类似于一本书，epoch为几就是要看几遍。</li><li>batch-size：一次迭代（更新参数）所使用的数据数量。类似于书中每个章节。</li><li>iteration：总共的迭代次数，一次迭代所用的数据为一个batch-size，即一次看一章。因此迭代的次数为dataset/batch-size，每本书看epoch次，因此iteration = epoch * (dataset/batch-size)。</li></ul><h3 id="python-dict的用法"><a href="#python-dict的用法" class="headerlink" title="python dict的用法"></a>python dict的用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">adict = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125; <span class="comment">#创建</span></span><br><span class="line">dict(zip([<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])) </span><br><span class="line">print(adict[<span class="string">'a'</span>]) <span class="comment"># 访问</span></span><br><span class="line">adict[<span class="string">'a'</span>] = <span class="number">2</span> <span class="comment"># 修改</span></span><br><span class="line">adict.pop(<span class="string">'a'</span>) <span class="comment"># 删除</span></span><br><span class="line">adict.get(<span class="string">'a'</span>) <span class="comment"># 如果没有这个key返回None</span></span><br><span class="line"><span class="keyword">for</span> key,values <span class="keyword">in</span>  dict.items(): <span class="comment"># 同时获得key和val</span></span><br><span class="line">    print(key,values)</span><br></pre></td></tr></table></figure><h3 id="python-中的类"><a href="#python-中的类" class="headerlink" title="python 中的类"></a>python 中的类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(object)</span>:</span>  <span class="comment"># 继承object</span></span><br><span class="line">    <span class="comment"># 数据成员</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,score)</span>:</span>  <span class="comment"># 类函数的第一个参数固定为self</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br><span class="line">        <span class="comment">## 私有成员,变量名前加上两个下划线__,只能类函数内部访问</span></span><br><span class="line">        self.__name = name</span><br><span class="line">    <span class="comment"># 方法成员</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getname</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getscore</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.score</span><br><span class="line"><span class="comment">#创建对象</span></span><br><span class="line">stu = Student(<span class="string">'xiaoming'</span>,<span class="number">100</span>)</span><br><span class="line">print(stu.getname())</span><br><span class="line">stu.sex = <span class="string">'man'</span> <span class="comment"># 外部添加数据变量</span></span><br></pre></td></tr></table></figure><h4 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">'animal is runing'</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cat</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">acat = cat()</span><br><span class="line">acat.run() <span class="comment"># 调用父类的run函数</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cat</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">'cat is runing'</span>)</span><br><span class="line">acat.run() <span class="comment"># 执行自己的run函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#多态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runrun</span><span class="params">(animal)</span>:</span></span><br><span class="line">    animal.run()</span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">runrun(animal) <span class="comment"># animal类</span></span><br><span class="line">runrun(cat) <span class="comment"># animal 子类</span></span><br><span class="line">runrun(aman) <span class="comment"># 类中含有run()的类也可以</span></span><br></pre></td></tr></table></figure><h4 id="property属性"><a href="#property属性" class="headerlink" title="property属性"></a>property属性</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">socre</span><span class="params">(self)</span>:</span>   <span class="comment"># 把socre变成一种数据属性，对象可以直接赋值</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"><span class="meta">    @birth.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, value)</span>:</span><span class="comment"># 对于score赋值的规则限制，在setter里头</span></span><br><span class="line">        <span class="keyword">if</span> value&gt;<span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'score must between 0 ~ 100!'</span>)</span><br><span class="line">        self._score = value</span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">s = Student()</span><br><span class="line">s.score = <span class="number">100</span></span><br><span class="line">print(s.score)</span><br></pre></td></tr></table></figure><h4 id="classmethod-类"><a href="#classmethod-类" class="headerlink" title="classmethod 类"></a>classmethod 类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">    bar = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func1</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'foo'</span>) </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">(cls)</span>:</span>      <span class="comment"># 方法类必须使用cls作为参数，不需要初始化</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'func2'</span>)</span><br><span class="line">        <span class="keyword">print</span> (cls.bar)</span><br><span class="line">        cls().func1()   <span class="comment"># 调用 foo 方法</span></span><br><span class="line">A.func2()               <span class="comment"># 不需要实例化</span></span><br></pre></td></tr></table></figure><h4 id="staticmethod"><a href="#staticmethod" class="headerlink" title="staticmethod"></a>staticmethod</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">()</span>:</span>      <span class="comment"># 静态方法，对参数没有要求</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'func2'</span>)</span><br><span class="line">A.func2()               <span class="comment"># 不需要实例化</span></span><br></pre></td></tr></table></figure><h3 id="下载单个文件夹"><a href="#下载单个文件夹" class="headerlink" title="下载单个文件夹"></a>下载单个文件夹</h3><p>在github上进入该文件夹所在的目录，复制文件夹链接：</p><p><a href="https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN" target="_blank" rel="noopener">https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN</a></p><p>随后在服务器上输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svn checkout https://github.com/tensorpack/tensorpack/trunk/examples/FasterRCNN</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO V2,V3详解</title>
      <link href="/2019/03/08/YOLO-V2-V3%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/08/YOLO-V2-V3%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>YOLO V2,YOLO V3是基于YOLO V1 的基础上，对网络进行改进，使得mAP，检测精度提升，同时仍保持较快的检测速度。本文将详细介绍V2，V3的特点。</p><a id="more"></a><h2 id="YOLO-V2-详解"><a href="#YOLO-V2-详解" class="headerlink" title="YOLO V2 详解"></a>YOLO V2 详解</h2><blockquote><p> YOLO9000: Better, Faster, Stronger</p><p>submit time: 2016</p><p><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>YOLO V2 在保持与V1基本框架相同的情况下，对网络进行了各种调优，主要做的修改如下：</p><p><img src="/images/article/YOLOchange.png" alt=""></p><h3 id="batch-norm"><a href="#batch-norm" class="headerlink" title="batch norm"></a>batch norm</h3><p>Batch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。</p><h3 id="high-resolution-classifier"><a href="#high-resolution-classifier" class="headerlink" title="high resolution classifier"></a>high resolution classifier</h3><p>当前大部分网络的预训练模型都是在ImageNet上224*224大小的图片上进行fintune的，YOLO V2首次用448*448大小的图片对分类网络进行fintune（10 epoch），使用高分辨率分类器后，YOLOv2的mAP提升了约4%。</p><h3 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h3><p>YOLOv1直接对目标进行边框预测，由于目标的尺度变换范围很大，导致了YOLOv1在精确定位方面表现较差。YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框。YOLOv2借鉴了Faster R-CNN中RPN网络的先验框策略。RPN对CNN特征提取器得到的特征图（feature map）进行卷积来预测每个位置的边界框以及置信度（是否含有物体）。</p><p>YOLOv2采用 416 * 416大小的图片作为输入。下采样的总步长为 32，对于 416*416大小的图片，最终得到的特征图大小为13*13，维度是奇数，这样特征图恰好只有一个中心位置。对于一些大物体，它们中心点往往落入图片中心位置，此时使用特征图的一个中心点去预测这些物体的边界框相对容易些。YOLO V2每个cell与yolov1类似，都分别去预测目标的IoU，以及每个框的类别预测值。使用anchor之后精度有点下降，但是YOLO V2的召回率（预测为真的占GT中真的比例）大大提升。原因是使用了anchor每张图片预测的边框数大大提升。</p><h3 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h3><p>在预测边框时传统的如Faster RCNN使用的是手工设置边框大小，yolov2中采用kmeans聚类的方法，选用box与聚类中心box之间的IOU值作为距离指标，即离的则认为是那一类，作者选择了五个先验框作为聚类中。</p><h3 id="New-Network-Darknet-19"><a href="#New-Network-Darknet-19" class="headerlink" title="New Network: Darknet-19"></a>New Network: Darknet-19</h3><p>YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。</p><h3 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a>Direct location prediction</h3><p>yolov2 采用不同于RPN的边框回归的方法，yolov2回归的目标是预测边界框中心点相对于对应cell左上角位置的相对偏移值。</p><p><img src="/images/article/yolobounding.png" alt=""></p><p>yolov2为每个cell预测5个bounding box，为每个bounding box预测五个坐标值，使用如下的公式进行边框的回归。</p><p><img src="/images/article/boundregression.png" alt=""></p><p>结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。</p><h3 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h3><p>由于YOLOv2模型中只有卷积层和池化层，为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔一定的iterations之后改变模型的输入图片大小。YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值.</p><h3 id="YOLO-V2-训练"><a href="#YOLO-V2-训练" class="headerlink" title="YOLO V2 训练"></a>YOLO V2 训练</h3><p>YOLOv2的训练主要包括三个阶段。</p><ul><li>第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224 * 224 ，共训练160个epochs</li><li>第二阶段将网络的输入调整为 448*448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs</li><li>第三个阶段就是修改Darknet-19分类模型为检测模型，并在检测数据集上继续finetune网络</li></ul><p><img src="/images/article/yolo2train.jpg" alt=""></p><p>其网络结构为：<a href="https://ethereon.github.io/netscope/#/gist/d08a41711e48cf111e330827b1279c31" target="_blank" rel="noopener">链接</a></p><p><img src="/images/article/yolo2structure.jpg" alt=""></p><h2 id="YOLO-V3"><a href="#YOLO-V3" class="headerlink" title="YOLO V3"></a>YOLO V3</h2><blockquote><p>YOLOv3: An Incremental Improvement</p><p>Submit time: 2018</p><p><a href="https://arxiv.org/abs/1804.02767" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>YOLO V3在速度和精度上比YOLO V2有了很大的提升，同时网络结构也复杂了不少，通过改变网络来权衡速度和精度。YOLO V3 的主要改进如下：</p><h3 id="Darknet-53"><a href="#Darknet-53" class="headerlink" title="Darknet-53"></a>Darknet-53</h3><p>YOLOV3作者使用了Darknet 53作为特征提取网络， Darknet 53是一个在Imagenet.做预训练的网络，YOLOV3 <strong>共有106 fully convolutional</strong> 。因此在速度上较YOLOV2慢一些。网络结构如下：</p><p><img src="/images/article/darknet.png" alt=""></p><p><img src="/images/article/y3.png" alt=""></p><h3 id="Detection-at-three-Scales-多尺度预测"><a href="#Detection-at-three-Scales-多尺度预测" class="headerlink" title="Detection at three Scales 多尺度预测"></a>Detection at three Scales 多尺度预测</h3><p>v3最显着的特点是它可以在三种不同的尺度上进行检测（32，16，8）。YOLO是一个完全卷积网络，通过在网络中的三个不同位置处应用1 x 1内核进行预测，每个尺度均预测三个边框，每一个边框的参数为$N ×N ×[3∗(4+1+80)] $，4表示边框的偏离值，1表示目标预测，80表示共80个类别。</p><p>多尺度的检测很好的客服了小物体的预测问题。</p><p><img src="/images/article/y3pre.jpg" alt=""></p><h3 id="No-more-softmaxing-the-classes"><a href="#No-more-softmaxing-the-classes" class="headerlink" title="No more softmaxing the classes"></a>No more softmaxing the classes</h3><p>作者使用sigmoid函数代替原来的softmax。由于softmax函数存在一个先验假设，即一个物体只能属于一个类别，这种假设在COCO集合上不成立。例如一个目标同时属于person和women，因此作者选择了sigmoid。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow 笔记（分类器 III）</title>
      <link href="/2019/03/08/TensorFlow-%E7%AC%94%E8%AE%B0%EF%BC%88%E5%88%86%E7%B1%BB%E5%99%A8-III%EF%BC%89/"/>
      <url>/2019/03/08/TensorFlow-%E7%AC%94%E8%AE%B0%EF%BC%88%E5%88%86%E7%B1%BB%E5%99%A8-III%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>本篇文章详细的从头到尾实现一下mnist分类器。</p><a id="more"></a><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>建立一个mnist数据集的数字分类器，需要做的主要有，</p><ul><li>从数据集中下载数据。</li><li>添加网络层（参数为，输入，输入size，输出size，激活函数），</li><li>定义输入数据的<code>placeholder</code>，构建网络结构，定义层。</li><li>定义loss，优化器.</li><li>定义计算精度的函数</li><li>定义train过程，以及精度的输出过程</li></ul><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tf.examples.tutorials.minst <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="添加网络层"><a href="#添加网络层" class="headerlink" title="添加网络层"></a>添加网络层</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_Function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variables(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variables(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.1</span>)</span><br><span class="line">    Wx_add_b = tf.matmul(input,Weights)+bias</span><br><span class="line">    <span class="keyword">if</span> actication_Function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_add_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_Function(Wx_add_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h3 id="构建网络结构"><a href="#构建网络结构" class="headerlink" title="构建网络结构"></a>构建网络结构</h3><p>网络为三层网络，一个输入层，一个隐藏层，一个输出层。均为全连接。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line">prediction = add_layer(xs,<span class="number">784</span>,<span class="number">10</span>,<span class="keyword">None</span>)<span class="comment">#仅有一层</span></span><br></pre></td></tr></table></figure><h3 id="Loss，优化器"><a href="#Loss，优化器" class="headerlink" title="Loss，优化器"></a>Loss，优化器</h3><p>分类问题的损失通常选用交叉熵，优化器可以选用SGD来优化。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction,labels = ys)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure><h3 id="计算精度"><a href="#计算精度" class="headerlink" title="计算精度"></a>计算精度</h3><p>这里要算的数据是预测值与GT之间的差。数据格式为one-hot类型，因此计算步骤先判断每一行是否相等，然后去平均即可,传入的数据为测试集数据。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeAccuracy</span><span class="params">(xtest,ylabel)</span>:</span></span><br><span class="line">    pred = sess.run(prediction,feed_dict=&#123;xs = xtest&#125;)</span><br><span class="line">    correct = tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(ylabel,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))</span><br><span class="line">    result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="train-过程"><a href="#train-过程" class="headerlink" title="train 过程"></a>train 过程</h3><p>使用batch-size SGD的方式进行训练更新：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(opertimizer,feed_dict = &#123;xs:x_batch,ys:y_batch&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            print(computeAccuracy(mnist.test.images,mnist.test.labels))</span><br></pre></td></tr></table></figure><p>整个过程完成，可以通过增加网络层，修改激活函数，learning rate等方式来测试结果。</p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">写一个分类器，首先定义数据</span></span><br><span class="line"><span class="string">然后定义判别层，层包括输入，输入维度，输出维度，激活函数,权重</span></span><br><span class="line"><span class="string">然后是构造结构</span></span><br><span class="line"><span class="string">写loss</span></span><br><span class="line"><span class="string">写opertimizer</span></span><br><span class="line"><span class="string">然后开始训练</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#get the data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_Fcuntion = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.1</span>)</span><br><span class="line">    Wx_add_b = tf.matmul(input,Weights)+bias</span><br><span class="line">    <span class="keyword">if</span> activation_Fcuntion <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_add_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_Fcuntion(Wx_add_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个三层的神经网络用于mnist 的分类，分别是输入层，输出层，隐藏层</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义输入</span></span><br><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#构造层次</span></span><br><span class="line">prediction = add_layer(xs,<span class="number">784</span>,<span class="number">10</span>,tf.nn.leaky_relu)</span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeLoss</span><span class="params">(xtest,ylabel)</span>:</span></span><br><span class="line">    pre = sess.run(prediction,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    correct_rate = tf.equal(tf.argmax(pre,<span class="number">1</span>),tf.argmax(ylabel,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_rate,tf.float32))</span><br><span class="line">    result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(computeLoss(mnist.test.images,mnist.test.labels))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLO V1 详解</title>
      <link href="/2019/03/07/YOLO-V1-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/07/YOLO-V1-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>YOLO 系列检测方法是不同于RCNN系列检测方法的另一种思路，其速度相比于Faster RCNN要快很多，但是精度上基于Faster RCNN框架的算法表现要更好一些，下面介绍YOLO V1.</p><a id="more"></a><blockquote><p>You Only Look Once:Unified, Real-Time Object Detection</p><p>Submit time: 2016.5</p><p><a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="网络的作用及背景"><a href="#网络的作用及背景" class="headerlink" title="网络的作用及背景"></a>网络的作用及背景</h3><p>YOLO在做目标检测时将任务作为一个空间上分开的目标框及其类别置信度的回归问题。单个神经网络一次计算就能够直接从整幅图象预测目标框和类别置信度（one-stage）。</p><p><img src="/images/article/YOLOv1.png" alt=""></p><p>YOLO的训练基于整幅图像，而且能够直接对检测任务进行优化。这个统一的模型在目标检测方面相比传统方法有多个好处。</p><ul><li>YOLO极其之快，YOLO是一个回归问题，省去了复杂的pineline</li><li>YOLO是在整幅图像上全局检测。检测过程中能够包含全局的上下文信息</li><li>YOLO学习到的是物体更加泛化的表示。在如艺术画像上，性能较优</li><li>精度上，YOLO的精度略差于最优的精度</li></ul><h3 id="YOLO-V1的网络结构"><a href="#YOLO-V1的网络结构" class="headerlink" title="YOLO V1的网络结构"></a>YOLO V1的网络结构</h3><p>yolo的训练思路为对一张图片划分成S*S大小的网格，然后每个网格预测B的检测框，以及这些检测框的置信度（与GT的IoU程度）。每个边框包含5个变量，分别是(x,y,width,height,confidence)。其中x,y指边框的中心，confidence指置信度。</p><p>对于每一个网络，我们同时计算一下其内含每种物品类别的条件概率：$Pr(Class_i|Object)$，条件概率不受检测的边框数影响，因此对于每个网格还需要预测C个类别的条件概率（是否包含该类别的概率）。当我们测试时，将C个类别的条件概率与边框预测值执行度相乘，得到：<br>$$<br>Class-confidence = Pr(Class_i|Object) * IOU_{truth}^{predict}<br>$$<br>从而得到每个检测框各个类别的分类置信得分。这些分数就同时包含了检测框中出现某类的概率以及检测框和目标的匹配程度。</p><p><img src="/images/article/yolodetect.png" alt=""></p><p><strong>网络结构：</strong>网络一共有24个卷积层和两个全连接层。模型初始的卷积层从图像中提取特征，而全连接层则预测输出概率和坐标。</p><p><img src="/images/article/yolov1structure.png" alt=""></p><h3 id="训练过程以及Loss计算"><a href="#训练过程以及Loss计算" class="headerlink" title="训练过程以及Loss计算"></a>训练过程以及Loss计算</h3><p>YOLO中每个网格可以预测多个检测框。在训练阶段对于一个物体的预测，只分配一个预测框，这种分配是基于与GT当前的IOU最大的预测。这会导致不同检测框之间的特殊化。每一个预测都会在预测特定的尺寸、长宽比、物体种类方面有更好的表现，从而提高整体的召回率。</p><p>网络优化的loss 如下：</p><p><img src="/images/article/yolov1loss.png" alt=""></p><p>其中$\mathbb I_{i}^{obj}$表示网格i中出现了物体 ，$\mathbb I_{ij}^{obj}$ 表示网格i中第j个框负责预测。loss中第一项表示预测边框与GT边框中心的MSE loss，第二项表示预测边框与GT边框长宽的MSE loss，第三项表示对含有物体的网格的每个预测边框置信度的MSE loss，第四项是对不含有物体的网格的每个边框置信度的MSE loss，第五项是对每个网格含有C个类别的条件概率的MSE loss。</p><p>为了训练过程更加的稳定，使用loss从小到大，同时使用dropout和数据增强，防止过拟合。</p><h3 id="YOLO-V1-特点"><a href="#YOLO-V1-特点" class="headerlink" title="YOLO V1 特点"></a>YOLO V1 特点</h3><ul><li>YOLO 在推理时，即图片预测时预测速度非常快，只需要一次网络评估。在Pascal VOC上，每张图像上网络预测<strong>98个边界框和每个框的类别概率</strong>。</li><li>YOLO对相邻物体检测效果不好：由于每个网格只预测两个检测框并且只能用有一个类别。这种设置限制了小目标，以及密集目标的检测效果。</li><li>很难泛化到一些新的或者不寻常的长宽比的检测目标：由于模型是直接从数据中学习边框预测，因此对于一些边框不规则的情形难以检测。</li><li>损失函数对大检测框和小检测框的误差是相同对待的。一个小的误差对于一个大的检测框通常都是比较温和可以接受的，但是一个小的误差对一个小的检测框的IOU有着较大的影响。主要的误差来源就是不准确的坐标定位。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>YOLO V1在先对图片划分S*S个网格，然后对每个网格均做2个边框的预测，以及对所有C个类别计算每个类别对象存在网格内部的条件概率。因此对每个网格检测的变量如下：</p><p><img src="/images/article/yolopred.png" alt=""></p><p>对于每一个对象，用对象中心的落在的网格来预测这个对象的边框，如下图：</p><p><img src="/images/article/yolotrain.jpg" alt=""></p><p>最终通过最小化loss，对边框进行预测。</p><p><img src="/images/article/yololosspic.png" alt=""></p><p>最终得到预测结果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bag of Freebies for Training Object Detection Neural Networks</title>
      <link href="/2019/03/05/Bag-of-Freebies-for-Training-Object-Detection-Neural-Networks/"/>
      <url>/2019/03/05/Bag-of-Freebies-for-Training-Object-Detection-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<p>这是一篇关于目标检测，语义分割领域，<strong>数据预处理</strong>以及网络<strong>调参的技巧文章</strong>。这些技巧对一些强大的算法，如Faster-RCNN，YOLO的性能有很大的提升。<br><a id="more"></a></p><blockquote><p>Bag of Freebies for Training Object Detection Neural Networks<br>submit time: 2019.2<br><a href="https://arxiv.org/pdf/1902.04103.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>这篇文章在没有损失网络速度的前提下，介绍了一些通用的微调方法，使得网络的性能得到了大大的提升，网络的精度得到大幅提升。</p><p>作者首先探讨数据增强方面，图像<strong>mixup</strong>的方法。随后作者探讨了在目标检测训练的pipeline，例如 <strong>learning rate scheduling</strong>, <strong>weight decay</strong> ，<strong>synchronized BatchNorm.</strong> 第三，作者探讨了将上面这些方法共同作用在一个两步或一步检测网络中所带来的性能提升。</p><h3 id="mixup"><a href="#mixup" class="headerlink" title="mixup"></a>mixup</h3><p>本文的研究者认识到了多目标检测任务的特殊性质有利于实现空间不变的变换，因此提出了一种用于目标检测任务的视觉相干（visually coherent）图像混合方法。使用mixup，但是beta分布选择较大a&gt;=1,b&gt;=1(而不是传统的0.2)，融合后的图片显得和现实一致。同时没有对mixup进行空间上的扭曲，使用几何形状保持的对齐方式对图片进行融合。<br><img src="/images/article/mixup.png" alt=""><br>如上图第一中传统mixup的方式作者认为仅仅是引入了一些noise。第二种mixup的方式不对图片进行distort，同时与视觉一致，数据增强效果更好。</p><h3 id="Classification-Head-Label-Smoothing"><a href="#Classification-Head-Label-Smoothing" class="headerlink" title="Classification Head Label Smoothing"></a>Classification Head Label Smoothing</h3><p>大部分的目标检测或语义分割网络中使用的loss 是基于softmax的交叉熵loss，这种loss 鼓励检测到的目标类别为正类别为1，其他为0。softmax函数如下：<br>$$<br>p_i = \frac{e^{z_i}}{\sum_j e^{z_j}}<br>$$<br>因此loss鼓励$e^{z_i} &gt;&gt; e^{z_j},i != j$这种极端情形，十分容易发生过拟合现象。因此使用label smoothing 来缓解这一现象。具体做法如下：<br>我们对groundtruth q进行smoothing操作，q在变换前是one hot编码形式，通过如下变换：<br>$$<br>q_i = (1 - \epsilon )q_i + \frac{\epsilon}{K}<br>$$<br>其中$\epsilon$ 是一个很小的数，完成smoothing 操作。</p><h3 id="Data-Pre-processing"><a href="#Data-Pre-processing" class="headerlink" title="Data Pre-processing"></a>Data Pre-processing</h3><p>作者采用了一下的数据增强方式：</p><ul><li>随机几何变换. 包括随机裁剪, 随机扩张, 随机水平翻转，随机缩放等等。</li><li>随机颜色抖动：包括亮度，色调，饱和度，对比度。</li></ul><h3 id="cosine-learning-rate-decay-and-Warm-up-learning-rate"><a href="#cosine-learning-rate-decay-and-Warm-up-learning-rate" class="headerlink" title="cosine learning rate decay and Warm up learning rate"></a>cosine learning rate decay and Warm up learning rate</h3><p>通常在训练过程中，学习率都是从一个较大的值开始然后在训练过程中不断减少，最常用的是 Step schedule（阶梯式衰减）。例如，训练一定的Epoch之后，学习率衰减为原来的 0.1。Step schedule 使得急剧学习率的急剧下降，造成训练不稳定的问题。因此作者选择更为平滑的 Cosine 学习率衰减策略。<br><img src="/images/article/learingrate.png" alt=""></p><h3 id="Synchronized-Batch-Normalization"><a href="#Synchronized-Batch-Normalization" class="headerlink" title="Synchronized Batch Normalization"></a>Synchronized Batch Normalization</h3><p>在多GPU环境下，对于一些batch size很小网络，在训练的时候BN会导致一些性能的下降。这个问题可以通过同时进行BN来解决。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileNet V2 详解</title>
      <link href="/2019/03/04/MobileNet-V2-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/04/MobileNet-V2-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>MobileNet V2 是在V1的基础上做了一些结构上的调整，主要有<strong>inverted residual</strong> 以及<strong>Linear Bottlenecks</strong>的改进。使得mobileNet v2 的精度进一步提高，结构进一步合理。<br><a id="more"></a></p><blockquote><p>MobileNetV2: Inverted Residuals and Linear Bottlenecks<br>submit time: 2018<br><a href="https://arxiv.org/pdf/1801.04381.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="mobileNets的背景及作用"><a href="#mobileNets的背景及作用" class="headerlink" title="mobileNets的背景及作用"></a>mobileNets的背景及作用</h3><p>mobileNet V1在设计的时候使用deepwise separable conv代替传统的卷积，大大降低了模型的计算量和复杂度，但是其仍然存在以下两个缺陷：</p><ul><li><strong>直筒型的结构影响网络性能</strong>，后续的网络如ResNet等，在网络中重复使用图像特征能够提高网络的性能。（引入inverted residual）</li><li><strong>depthwise Convolution 导致特征退化问题</strong>：由于depthwise conv使用很小的卷积核（1x1），经过BN归一化，以及relu激活之后很容易变为0，即变成死节点,<strong>导致特征退化</strong>。（我的理解是，对于一个1x1的kernel来说，归一化过程可能会把它变成负数，然后relu激活后就会变成死节点。但是对于kernel size比较大的卷积，要使整个卷积核上的数都变成负数要难很多，因此不会有很严重的特征退化问题。）（引入linear bottlenecks）.</li></ul><p>mobileNet v2 通过引入inverted residual，将图像中的特征反复使用，提高网络的性能。对于特征退化的问题，通过linear bottleneck，去掉网络中的relu等步骤，能够缓解特征的退化。<br><img src="/images/article/v2detial.png" alt=""></p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性激活函数。</p><p>线性瓶颈的倒置残差结构：模块的输入为一个低维的压缩表示特征，首先将其扩展到高维并用轻量级depthwise conv 进行卷积。随后用线性卷积（linear conv）将特征投影回低维表示。</p><p><strong>MobileNet v2 模型的特点：</strong></p><p><img src="/images/article/linearBottle.png" alt=""><br>如上图，mobileNet v2在V1基础上进行了改进。</p><p>相同点：<br>mobileNet v2由v1发展而来，继承了<strong>深度可分卷积</strong>（depthwise seperable conv），采用深度卷积和逐点卷积来代替传统的卷积操作，使得计算量大大减小。<a href="http://perper.site/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener">参考链接</a></p><p>不同点：<br><strong>V2在每个DW卷积之前加入了一层PW的卷积，主要作用是用于提升特征的channel数。</strong>由于DW层无法提升feature map的通道数，于是先通过PW提升feature map的通道数，PW卷积的大小为：Mx1x1，卷积核的个数可以控制，也即为卷积后得到feature map的通道数。至于提升channel的具体原因如下：</p><blockquote><p>当我们查看深层卷积层所有的d通道像素时，在这些值中编码的信息实际上位于某个流形中，这些流形结构可以嵌入到低维子空间中。<br>ReLu在高层空间中的变换有助于增加网络的非线性。对于ReLU（Bx）激活后的非0部分，输入空间与输出空间之间的特征映射是线性变换。另一方面，当ReLU破坏通道时（relu小于0的部分），它会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。<br>总而言之，以下两个特性表明感兴趣的流形区域位于较高维激活空间的低维子空间中：</p><ol><li>如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。</li><li>只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。</li></ol></blockquote><p>因此我们需要先对channel通道进行升维。假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。线性可以防止非线性破坏太多的信息。</p><p><strong>Linear Bottleneck：</strong>V2 去掉了第二个 PW 的激活函数。论文作者称其为 Linear Bottleneck。这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。由于第二个 PW 的主要功能就是降维，降维之后使用线性瓶颈层来获取低秩信息，防止非线性破坏太多信息。</p><p><strong>倒置残差：</strong><br><img src="/images/article/inverted_residual.png" alt=""><br>V2的 shortcut  设计与ResNet相反，呈一个纺锥型，中间大两头小，因此称为<strong>倒置残差</strong>。使用倒置设计是由于其内存效率要高得多。<br>网络将PW层得到的feature map先扩展6倍，然后通过DW卷积，与一个shortcut上来的feature map融合之后再输入PW卷积。</p><p>mobileNet的结构单元如下：<br><img src="/images/article/v1structure.png" alt=""><br><img src="/images/article/V2structure.png" alt=""></p><p>网络结构参数如下：<br><img src="/images/article/v2net.png" alt=""></p><p>整体的结构如下：<a href="https://zhuanlan.zhihu.com/p/33075914" target="_blank" rel="noopener">参考链接</a><br><img src="/images/article/structureV2.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow 笔记（搭建网络-II）</title>
      <link href="/2019/03/04/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-II%EF%BC%89/"/>
      <url>/2019/03/04/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-II%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>本篇文章主要讲网络搭建过程中的代码以及注意要点。<br><a id="more"></a></p><h3 id="添加网络层"><a href="#添加网络层" class="headerlink" title="添加网络层"></a>添加网络层</h3><p>定义网络结构，然后将网络层添加到神经网络中。定义网络层的主要步骤有：</p><ul><li>确定网络的参数：<strong>输入，输入的size，输出的size，激励函数</strong></li><li>定义weight，biases</li><li>计算output</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_function = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.01</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(input,Weights)+biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        output = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = activation_function(Wx_bias_b)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>可以看出来，网络层神经元的个数即为输出的outsize的大小。</p><h3 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h3><p>以下为搭建一个三层神经网络，其中输入层为1个神经元，输出层为1个神经元，隐藏层为10个神经元。搭建网络是需要完成的事情为：</p><ol><li>定义数据，网络层中的参数维度</li><li>定义传入的参数placeholder，loss，optimizer等</li><li>值得注意的是，数据的维度变化需要十分注意</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># create data</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.rand(x_data.shape[<span class="number">0</span>],x_data.shape[<span class="number">1</span>])</span><br><span class="line">y_GT = np.square(x_data)+<span class="number">0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># placeholder</span></span><br><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>]) <span class="comment">#表示样本数，和每个样本的维度为1</span></span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># structure</span></span><br><span class="line">l1 = add_layer(ms,<span class="number">1</span>,<span class="number">10</span>,tf.nn.relu)</span><br><span class="line">output = add_layer(l2,<span class="number">10</span>,<span class="number">1</span>,<span class="keyword">None</span>)</span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),<span class="number">1</span>))</span><br><span class="line">optimizer = tf.train.GrandientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#train</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br></pre></td></tr></table></figure><p><strong>代码详解如下：</strong></p><ol><li><p><code>x_data = np.linspace(-1,1,300)[:,np.newaxis]</code>：其中<code>np.linspace(-1,1)</code>生成-1，到1之间的300个数。<code>[:,np.newaxis]</code>指将生成的数据维度提升。原来是1x300，现在是300x1，由1为变为300维，每个数据占一个维度。</p></li><li><p><code>xs = tf.placeholder(tf.float32,[None,1]) #表示样本数，和每个样本的维度为1</code>：其中<code>[None,1]</code>有一种含义为，当你不知道样本数的时候，抓住每个样本的维度即可。</p></li><li><code>tf.reduce_sum(tf.square(output-ys),1)</code>: 其中<code>tf.reduce_sum()</code>这个函数为求和函数，第一个参数是一个<strong>数组</strong>，第二个参数默认则为<strong>所有数之和</strong>。第二个参数为0，则为<strong>列之和（0）</strong>，第二个参数为1则为<strong>行之和（1）</strong>。<code>tf.reduce_mean()</code>参数含义与求和函数一致。</li><li>在写网络结构的时候，用placeholder，暂时忘记掉真实的数据，先构建好框架后，然后传入参数。</li></ol><h3 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h3><p>可视化模块一般使用<code>matplotlib.plot as plt</code> 来绘图。</p><p><strong>matplotlib的层次结构：</strong><br>matplotlib的结构类似与一个树状结构。<code>Figure</code> : 为层次结构中的最外层，内部可包含多张plot图像。plot图层次结构可包含的对象例如刻度线，单独的线条，图例和文本框。几乎每个“元素”都是一个Python对象。具体代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.linspace(-np.pi,np.pi,<span class="number">300</span>)</span><br><span class="line">xsin = np.sin(x)</span><br><span class="line">xcos = np.cos(x)</span><br><span class="line">plt.subplot(<span class="number">221</span>) <span class="comment"># 表明共有2列，2行的图片要画，现在拿到第一个来画</span></span><br><span class="line">plt.plot(x,xsin) <span class="comment"># 要画折线图，如果点很密集，就是曲线图</span></span><br><span class="line">plt.xlabel(<span class="string">'x轴'</span>) <span class="comment"># 所有属于这个子图的小对象，如颜色，图例，都可以修改</span></span><br><span class="line">plt.subplot(<span class="number">222</span>) <span class="comment"># 表明2列2行，现在要画第二个</span></span><br><span class="line">plt.plot(x,xcos)</span><br><span class="line">plt.subplot(<span class="number">223</span>) <span class="comment"># 表明2行2列，现在要画第三个</span></span><br><span class="line">plt.scatter(x,xsin) <span class="comment"># 要画散点图</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>如上，每次使用<code>plt.subplot(xxx)</code>交换控制的子图，非常好懂哈哈哈。</p><p>下面是搭建网络，绘制拟合图的完整代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">添加层需要考虑的因素有几个，首先输入的数据，输入的数据尺度，输出的尺度（神经元个数），激活函数</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_function = None)</span>:</span></span><br><span class="line">    <span class="comment">#定义权重</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+ <span class="number">0.01</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(input,Weights) + bias</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">构建神经网络：</span></span><br><span class="line"><span class="string">1. 搭建一个输入层仅有一个神经元，隐藏层10个神经元，输出层1个神经元的网络</span></span><br><span class="line"><span class="string">2. 需要定义数据，网络层，输入输出，placeholder，loss ，optimizer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># np.linspace(-1,1,10)[:,np.newaxis],引入新维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create data</span></span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:,np.newaxis]</span><br><span class="line"></span><br><span class="line">noise = np.random.rand(<span class="number">300</span>,<span class="number">1</span>)</span><br><span class="line">y_GT = np.square(x_data) + <span class="number">0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># create network</span></span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32,x_data.shape)</span><br><span class="line">ys = tf.placeholder(tf.float32,y_GT.shape)</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs,<span class="number">1</span>,<span class="number">10</span>,activation_function=tf.nn.relu)</span><br><span class="line">output = add_layer(l1,<span class="number">10</span>,<span class="number">1</span>,activation_function=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),<span class="number">1</span>))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#illustration</span></span><br><span class="line">ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">plt.scatter(x_data,y_GT)</span><br><span class="line"></span><br><span class="line">plt.ion() <span class="comment"># 动态画图，不停止</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;))</span><br><span class="line">            predict = sess.run(output,feed_dict=&#123;xs:x_data&#125;)</span><br><span class="line">        <span class="comment">#    plt.plot(x_data,predict)</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                ax.lines.remove(lines[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># plot the prediction</span></span><br><span class="line">            lines = plt.plot(x_data, predict, <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">            plt.pause(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure></p><h3 id="TensorBoard-可视化"><a href="#TensorBoard-可视化" class="headerlink" title="TensorBoard 可视化"></a>TensorBoard 可视化</h3><p>Tensorboard 作为tensorflow网络结果可视化的一个比较好的工具，他使用<code>tf.name_scope(&quot;name&quot;):</code>的方式对部分元件进行整体的命名。并且支持多层的嵌套。如下例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"layer"</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"Weight"</span>):</span><br><span class="line">        Weights = tf.Variable(tf.random.normal([<span class="number">300</span>,<span class="number">1</span>]),name = <span class="string">'W'</span>)</span><br></pre></td></tr></table></figure><p>tensorboard工作的思路是将文件写入磁盘，然后由浏览器进行访问，写入磁盘的语句如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'./log'</span>,sess.graph)</span><br></pre></td></tr></table></figure><p>最后在命令行中，进入文件目录输入指令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir = 'log/'</span><br></pre></td></tr></table></figure><p>随后在浏览器中输入：<code>0.0.0.0:6006</code>即可预览。</p><p>tensorboard还可以监控单个变量的变化情况，使用histogram直方图来显示。<code>tf.summary.histogram</code>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Weight"</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.normal([<span class="number">300</span>,<span class="number">1</span>]),name = <span class="string">'W'</span>)</span><br><span class="line">    tf.summary.histogram(name,Weight)</span><br></pre></td></tr></table></figure><p>tensorboard看一个一维的变量，如loss，使用<code>tf.summary.scalar</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce.mean(tf.reduce.sum(tf.square(y-p_pred),<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'loss'</span>,loss)</span><br></pre></td></tr></table></figure><p>最后需要对所有的summary进行融合：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merged = tf.summary.merge_all()</span><br></pre></td></tr></table></figure><p>接下来在训练的时候更新参数,然后使用<code>writer.add_summary(result,step)</code>来将summary写入文件中。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            result = sess.run(merged,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">            writer.add_summary(result,step)</span><br></pre></td></tr></table></figure><p>接着使用命令行运行即可.x</p>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileNets 详解</title>
      <link href="/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>mobileNets为谷歌开发的，为<strong>移动或嵌入式端</strong>视觉应用开发的一个轻量级高效模型。<br><a id="more"></a></p><blockquote><p>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications<br>submit time: 2017<br><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="mobileNets的背景及作用"><a href="#mobileNets的背景及作用" class="headerlink" title="mobileNets的背景及作用"></a>mobileNets的背景及作用</h3><p><strong>背景：</strong>在很多CNN的是被问题中，总体趋势是使用更深层次更加复杂的模型来实现更高的精度。然后提高精度的代价往往是网络在尺度和速度的性能变差，对于一些要求时效且计算资源有限的任务这些网络难以完成。</p><p><strong>mobileNets：</strong>本文介绍的moblieNets具有<strong>高效的网络结构和两个超参数</strong>，以便构建非常小的，快速度的模型，可以轻松匹配移动和嵌入式视觉应用的设计要求。</p><p>本文提出了一类网络结构，允许模型开发人员选择与其应用程序的资源限制（延迟，大小）相匹配的小型网络。MobileNets主要侧重于优化速度，但也能够产生小型网络，我们介绍了两个简单的全局超参数，可以在时间和准确性之间进行有效折中。</p><p><strong>深度可分离卷积：</strong><br><img src="/images/article/deepwiseconv.png" alt=""></p><p>一个传统的大小为$M*N*D_k*D_k$的卷积核，对一个大小为$D_F*D_F$的features map进行卷积，他的计算量为：$N*M*D_k*D_k*D_F*D_F$.<br>MobileNets基于深度可分离卷积构建，深度可分离卷积由两层构成：<strong>depthwise convolutions</strong>和<strong>pointwise convolutions</strong>，分别对将$M*N*D_k*D_k$的大小的卷积核进行深度（channel）和尺寸（$D_k$）上的分割：<br>其中M为通道数，N为卷积核个数，$D_k$为卷积核大小。</p><ul><li>depthwise convolution：将$M*D_k*D_k$的卷积核分解为$1*D_k*D_k$，一共M组卷积核（不使用N），即每个卷积核仅对一个通道进行处理。对于一个大小为$D_F*D_F$的features map他的计算量为：$M*D_k*D_k*D_F*D_F$.</li><li>Pointwise convolution（1x1卷积）：即将$M*D_k*D_k$的卷积核分解为$M*1*1$大小的卷积核共有N个，用来创建depthwise层的线性叠加。该层的计算量为$N*M*D_F*D_F$.</li></ul><p>Deep-wise 分离卷积相比于传统卷积的计算量减少如下：<br>$$<br>\frac{M*D_k*D_k*D_F*D_F+N*M*D_F*D_F}{N*M*D_k*D_k*D_F*D_F} = \frac{1}{N} + \frac{1}{D_K^2}<br>$$<br>计算量得到了显著的下降，而模型准确率仅下降了一点点，MobileNets对两层卷积层都使用了BatchNormalization和ReLU非线性激活。 一个转换的例子如下：<br><img src="/images/article/deepwise.png" alt=""></p><h3 id="MobileNets-网络结构"><a href="#MobileNets-网络结构" class="headerlink" title="MobileNets 网络结构"></a>MobileNets 网络结构</h3><p>网络共28层，大大量重叠的deepwise结构组成，最后接一个argpooling送入全连接层进行softmax分类。网络中大部分参数及计算来自1*1的卷积层，以及最后的全连接层。<br>网络很少使用BN以及数据增强技术，因为小网络不易发生过拟合现象。<br><img src="/images/article/deepwisestructure.png" alt=""></p><h4 id="超参-Width-multiplier（更小的模型）"><a href="#超参-Width-multiplier（更小的模型）" class="headerlink" title="超参 Width multiplier（更小的模型）"></a>超参 Width multiplier（更小的模型）</h4><p>我们使用一个参数$\alpha$，称为width multiplier。它的作用是在每层均匀地减负网络。对于一个给定的层和$\alpha$，输入通道的数量从M变成$\alpha M$，输出通道的数量从N变成$\alpha$N。深度可分离卷积的计算复杂度变为原来的$\alpha$倍。<br>α在(0,1]之间，通常设为1，0.75，0.5和0.25。Width multiplier有减少计算复杂度和参数数量（大概α二次方）的作用。用于定义新的简化结构，但需要重新进行训练。计算复杂度如下：<br>$$<br>\alpha M*D_k*D_k*D_F*D_F+\alpha N* \alpha M*D_F*D_F<br>$$</p><h4 id="超参-Resolution-Multiplier-（Reduced-Representation）"><a href="#超参-Resolution-Multiplier-（Reduced-Representation）" class="headerlink" title="超参 Resolution Multiplier （Reduced Representation）"></a>超参 Resolution Multiplier （Reduced Representation）</h4><p>使用超参数$\rho$用于减小图片的尺度，$\rho$的范围在(0,1]之间，用于缩减图片的大小，计算复杂度如下：<br>$$<br>\alpha M*D_k*D_k* \rho D_F* \rho D_F+\alpha N* \alpha M*\rho D_F* \rho D_F<br>$$</p><p>通过调整$\alpha,\rho$来使得模型在资源使用和精确度上执行折中。</p><h3 id="网络的损失函数"><a href="#网络的损失函数" class="headerlink" title="网络的损失函数"></a>网络的损失函数</h3><p>网络损失函数较为简单，即为feature map接一个全连接层，然后连上softmax loss。<br>$$<br>Loss = \sum_I y_i \log p_i<br>$$</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>MobileNets 是一个目标识别网络，即用来判断一张图片的类别。它在原有CNN的基础上，将卷积层进行了deepWise 和pointWise上的分解，参数量大大减少，精度仅下降一点点。缩减结构的同时，使用两个超参数控制参数的大小以及图片的大小，在精度和资源上进行权衡。此外，MobileNets可以作为许多网络的特征提取部分，例如Faster RCNN的特征提取部分等等，精度在可以满足的情况下，大大降低了网络的参数量。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow 笔记（基础部分-I）</title>
      <link href="/2019/03/03/TensorFlow-%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/03/03/TensorFlow-%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>TensorFlow是一个开源的软件包，用于各种感知以及语言理解的机器学习，深度学习任务。<br><a id="more"></a></p><h2 id="简单例子："><a href="#简单例子：" class="headerlink" title="简单例子："></a>简单例子：</h2><p>使用MSE loss去拟合一条二维的直线，优化方式选择SGD。步骤如下：</p><ol><li>定义训练数据，以及GroundTruth</li><li>搭建tensorflow的结构，包括变量的定义(weight,bias)，损失函数的定义，优化器的定义</li><li>执行tensorflow，使用tf.Session()定义回话，用于执行tensorflow计算图。设置epoch的次数（执行次数）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#create data</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>) <span class="comment"># 100个 0～1之间的数</span></span><br><span class="line">y_data = x_data*<span class="number">0.3</span> + <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create tensorflow structure</span></span><br><span class="line">Weights = tf.Variable(tf.random.uniform([<span class="number">1</span>],<span class="number">-1.0</span>,<span class="number">1.0</span>))</span><br><span class="line">Bias = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">y = Weights*x_data + Bias</span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># execute</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(Weights),sess.run(Bias))</span><br></pre></td></tr></table></figure><p>这里头可说的东西有很多，首先是：<code>np.random.rand(100)</code>,即：</p><h3 id="numpy产生随机数的方式："><a href="#numpy产生随机数的方式：" class="headerlink" title="numpy产生随机数的方式："></a>numpy产生随机数的方式：</h3><p>为什么重要，因为很多神经网络中参数的初始化，都是使用numpy来完成的，以前没仔细记录导致一知半解，自己写不出来。<a href="https://www.jianshu.com/p/214798dd8f93" target="_blank" rel="noopener">详细链接</a></p><ol><li><code>np.random.rand(4,2)</code>: 表示产生（0，1）之间的float随机数，维度为4x2.  <code>np.random.rand(4,2,3)</code>:维度为4x2x3.</li><li><code>np.random.randn(4,2)</code>: 表示产生一组符合正态分布的数 N ( 0,1 )，维度是4x2.</li><li><code>np.random.randint(low,high,size = (4,2))</code>: 表示产生一组整数，维度为4x2，大小在[low,high)之间。</li><li><code>np.random.seed(1) np.random.rand(5)</code>:表示指定了seed，该seed下产生的随机数是相同的。</li></ol><h3 id="tensorflow中表示变量的函数：tf-Variable"><a href="#tensorflow中表示变量的函数：tf-Variable" class="headerlink" title="tensorflow中表示变量的函数：tf.Variable()"></a>tensorflow中表示变量的函数：tf.Variable()</h3><p>tensorflow中所有的变量使用函数定义，<code>tf.Variable</code> 类用于操纵变量，该变量可以通过op运算来更改他的值。<br><strong>定义变量：</strong><br><code>weights  = tf.Variable(&lt;initial-value&gt;,name = &lt;optional&gt;)</code><br><strong>变量的初始化：</strong><br>与其他语言不同，tensorflow在使用变量的时候需要先进行初始化操作。可以这么理解，<strong>tensorflow内部是以执行Graph的形式进行计算的，之前的所有操作，如定义变量，仅仅是构建Graph的结构，但是并没有真正的将值传入Graph节点中，因此需要tf.Session()来执行初始化操作，为变量节点赋值。</strong>初始化如下：<br><code>init  = tf.global_variables_initializer()</code><br><code>sess = tf.Session()</code><br><code>sess.run(init)</code></p><h3 id="tensorflow-产生随机数"><a href="#tensorflow-产生随机数" class="headerlink" title="tensorflow 产生随机数"></a>tensorflow 产生随机数</h3><ol><li><code>tf.random.uniform([2,3],minval = -1,maxval = 1,seed = None)</code>：表示产生均匀分布的随机数，大小在[minval,maxval]之间。</li><li><code>tf.random.normal([2,3],mean = 0,stddev = 1)</code>： 表示产生正态分布的随机数，服从N（0，1）。</li><li><code>tf.truncated.normal([2,3],mean = 0,stddev = 1)</code>：表示生成范围在[mean-2stddev,mean+2stddev]范围内的正态分布随机数。</li><li><code>tf.random.shuffle([1,2,3,4])</code>：表示沿着第一维，对数组进行重新排列。</li></ol><p>此外初始化为0: <code>tf.zeros([2,3])</code></p><h3 id="tensorflow-中的Loss"><a href="#tensorflow-中的Loss" class="headerlink" title="tensorflow 中的Loss"></a>tensorflow 中的Loss</h3><p><strong>MSE Loss：(L2)</strong><br><code>mse = tf.reduce_mean(tf.square(y_pre,y))</code><br><strong>MAE Loss: (L1)</strong><br><code>mae = tf.losses.absolute_difference(y_pre,y)</code><br><code>mae_loss = tf.reduce_sum(mae)</code></p><p><strong>处理分类问题交叉熵Loss：</strong><br><code>softmax_sparse = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,logits = y_pred)</code><br><code>loss = tf.reduce_mean(softmax_sparse)</code><br>其中不要求y-true 是one-hot 格式。</p><p><strong>优化器：</strong><br>tensorflow中的优化器共有其中，均在<code>tf.train</code> 这个类中，使用的时候看具体的应用。<code>optimizer = tf.train.GradientDescentOptimizer(0.5)</code><br><code>train = optimizer.minimize(optimizer)</code></p><h3 id="tf-Session-会话控制："><a href="#tf-Session-会话控制：" class="headerlink" title="tf.Session() 会话控制："></a>tf.Session() 会话控制：</h3><p>Session 用于执行计算图中的节点，因此获取一个值，或者是最小化loss等操作，都需要使用Session来激活部分计算图。使用如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    sess.run(train)</span><br></pre></td></tr></table></figure></p><h3 id="tf-constant-常量："><a href="#tf-constant-常量：" class="headerlink" title="tf.constant() 常量："></a>tf.constant() 常量：</h3><p>tensorflow 用 <code>tf.constant()</code> 来申请一个常量，常量指不能被修改的数。<br><code>matrix1 = tf.constant([[1,2],[3,4]])</code></p><h3 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder"></a>tf.placeholder</h3><p><code>tf.placeholder(tf.float32,[3,2])</code>:表示数据类型为<code>tf.float32</code>，大小为3x2。使用placeholder的目的是：</p><ul><li>placeholder 可以作为一个参数，专门用来将数据传入函数中</li><li>由于tensorflow是计算图模型，如果使用变量传参数的话，计算图将会变得很大，不便与计算，因此使用placeholder来代替</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">input1 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">input2 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">ouput = tf.multiply(input1,input2)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output,feed_dict=&#123;input1:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>]],input2:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]&#125;))</span><br></pre></td></tr></table></figure><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.relu(features,name = <span class="keyword">None</span>) <span class="comment"># 下面均相同</span></span><br><span class="line">tf.nn.relu6</span><br><span class="line">tf.nn.crelu</span><br><span class="line">tf.nn.elu</span><br><span class="line">tf.nn.selu</span><br><span class="line">tf.nn.softplus</span><br><span class="line">tf.nn.softsign</span><br><span class="line">tf.nn.dropout</span><br><span class="line">tf.nn.bias_add</span><br><span class="line">tf.sigmoid</span><br><span class="line">tf.tanh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ESRGAN 详解</title>
      <link href="/2019/03/02/ESRGAN-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/02/ESRGAN-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="ESRGAN-详解"><a href="#ESRGAN-详解" class="headerlink" title="ESRGAN 详解"></a>ESRGAN 详解</h3><p>ESRGAN网络是在SRGAN的基础上，对对抗损失以及感知损失进一步的改善，引入residual-in residual Dense Block(残差密集块)来组建网络而取代了网络中的BN。并且借鉴了相对GAN的思想，让给判别器预测相对的真实性，而不是完全相同。<br><a id="more"></a><br>ESRGAN网络的作者是香港中文大学的学生，他对学习的建议是多看论文多实验，自己push自己！显然能力越大舞台越大！</p><blockquote><p>ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks<br>submit time:2018 ECCV<br><a href="https://arxiv.org/pdf/1809.00219.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h4 id="ESRGAN-的作用"><a href="#ESRGAN-的作用" class="headerlink" title="ESRGAN 的作用"></a>ESRGAN 的作用</h4><p>传统提升SR（super resolution）的方法是使用Peak Signal-to-Noise Ratio(PSNR)峰值信噪比，即最小化生成图片与GT之间的MSE loss，但是这种优化策略倾向于输出平滑的结果而没有足够多的具体细节。<br>这篇文章在SRGAN的基础上进行改进，提升了图片超分辨率的精度，作者从三个方面提升修改模型：</p><ul><li>引入密集残差块（RDDB）去除了BN，节省内存空间提升模型的结构，使之具有更大的容量和更易于训练。</li><li>辨别器使用相对平均GAN（RaGAN），即判断“是否一个图像相比于另一个更真实”而不是“是否一个图像是真或假”。这个改进有助于生成器恢复更真实的纹理细节。</li><li>SRGAN感知损失部分，使用激活函数之前的VGG features map，而不是SRGAN激活之后的feature map，调整后的感知损失提供了清晰的边缘和更具有视觉体验的结果</li></ul><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><strong>生成器部分：</strong><br><img src="/images/article/ESRGAN.png" alt=""><br>生成器结构上的改进：</p><ul><li>去除所有的BN层</li><li>用残差基础块代替原始基础块</li></ul><p><img src="/images/article/ESRGANgen.png" alt=""><br>BN在训练期间需要计算整个训练集的均值和方差，当训练集和测试集差异很大的时候会引入伪影，造成图像的模糊，通过在残差块中去除BN层，有助于提高泛化能力，能够减少空间和计算复杂度。</p><p>生成器训练过程的tip：<br>1）残差缩放，例如将残差乘以0和1之间的常数（图中$\beta$），然后将它们添加到主路径以防止不稳定。<br>2）较小的初始化参数，当初始参数方差变小时，残差结构更容易训练。</p><p><strong>判别器部分：（相对判别器）</strong><br>判别器部分使用相对判别，也即是说真实图像与生成图像哪个更加真实一些。<br><img src="/images/article/ESRGANdis.png" alt=""><br>如上图，真实判别器为$D(x_r) = \sigma (C(x))$,其中$\sigma$ 为sigmoid函数，$C(x)$为sigmoid转换前判别器的输出。相对判别器在则判断是的，真实图像是否比生成图像更加的真实：<br>$$<br>D_{ra}(x_r,x_f) = \sigma(C(x_r) - E[C(x_f)] )<br>$$<br>其中$E[C(x_f)]$为在mini-batch中所有的生成图片取均值。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><strong>生成器部分：</strong><br>生成器的loss由三部分组成：</p><p>$$<br>L_G = L_{percep}+ \lambda L_G^{Ra} + \eta L_1<br>$$<br>其中$L_{percep}$为vgg中激活函数之前的features map与GT的features map的MSE loss（同SRGAN），$L_{G}^{Ra}$损失为对抗损失（与判别器对称）：<br>$$<br>L_G^{Ra} = -E_{x_r}[log(1-D_{Ra}(x_r,x_f))] - E_{x_f}[log(D_{Ra}(x_f,x_r))]<br>$$<br>即生成器的目标是另判别器将生成图片判断成比原始图像真实。$L_1$ loss 表示恢复图像与真实图像之间的L1 距离：$$L_1 = E_{x_a} || G(x_i)-y||_1$$</p><p><strong>判别器部分：</strong><br>判别器loss与生成器对抗loss对称，如下：<br>$$<br>L_D^{Ra} = -E_{x_r}[log(D_{Ra}(x_r,x_f))] - E_{x_f}[log(1 - D_{Ra}(x_f,x_r))]<br>$$<br>判别器的目标是将原始图片判别成更加的真实。</p><h4 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h4><ul><li>用密集残缺块来代替原有的基础块，去除了BN</li><li>对GAN进行修改，进而去判断相对真实感</li><li>对激活前的features map做MSE提升恢复精度</li></ul><p><strong>网络插值：</strong>为了去除PSNR导致的像素平滑，同时保证感知质量。可以通过训练一个PSNR 的生成器$G_{PSNR}$，然后基于GAN网络的$G_{GAN}$进行fine tune,然后利用插值模型得到一个插值网络。<br>$$<br>\theta_{G}^{INTERP} = (1-\alpha) \theta_G^{PSNR}+\alpha \theta_G^{GAN}<br>$$<br>因此可以通过调整$\alpha$的大小来调整网络输出PSNR指标与视觉效果。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>网络在SRGAN的基础上进行了大量的改进，包括在训练方法上，loss的设计上等等，最终取得了较好的恢复结果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微电阻成像</title>
      <link href="/2019/03/02/%E5%BE%AE%E7%94%B5%E9%98%BB%E6%88%90%E5%83%8F/"/>
      <url>/2019/03/02/%E5%BE%AE%E7%94%B5%E9%98%BB%E6%88%90%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="微电阻成像"><a href="#微电阻成像" class="headerlink" title="微电阻成像"></a>微电阻成像</h3><p><strong>原理：</strong></p><p><strong>微电阻率扫描成像测井</strong>采用多个有序排列、间距几毫米的钮扣电极测量井壁地层电阻率，并形成分辨率很高的井壁图像，从而对地层进行细微分析的电阻率测井方法。<br><a id="more"></a><br>它采用多个压向井壁的极板，每个极板上的多排钮扣状小电极向井壁地层发射电流，由于电极所接触的井壁岩石的结构、成分及所含流体的不同引起电流变化，<strong>电流的变化反映了正对电极处井壁地层电阻率的变化。</strong>经过适当的处理，可以描绘为彩色或灰度等级的<strong>井壁电阻率图像</strong>，对地层岩性、沉积特征、构造特征、裂缝及洞穴等进行分析。</p><p><strong>微电阻图像：</strong></p><p>将电阻率数据进行处理，然后进行颜色的映射，得到的结果如下：<br><img src="/images/ictproject/test.jpg" alt=""><br>上图宽表示井口的周长，长表示测井的深度（图中仅为部分长度）。可以看出来，途中存在倾斜的黑色条道，只是由于探测的时候设备仅仅有六个探测口，然后每次探测完一个深度探测口发生旋转，继续进行探测。黑色条道即为探测器之间的距离。</p><p><strong>任务：</strong></p><p>根据已有的数据，恢复出黑色条道部分的数据。</p><h2 id="workFlow"><a href="#workFlow" class="headerlink" title="workFlow"></a>workFlow</h2><hr><h3 id="2019-3-5"><a href="#2019-3-5" class="headerlink" title="2019.3.5"></a>2019.3.5</h3><p>沟通需求之后发现暂时需要实现有数据部分的数据恢复工作，接下来用网络跑一下看看效果。如果效果好的话，改写到tensorflow的版本。</p><p>下图是使用ESRGAN恢复得到超分辨后的结果。右图是原图放大到像素级别的效果，左图是图片恢复后的效果图。<br><img src="/images/ictproject/SRresult.png" alt=""></p><hr><h3 id="2019-3-3"><a href="#2019-3-3" class="headerlink" title="2019.3.3"></a>2019.3.3</h3><p>do something in this place</p><hr><h3 id="2019-3-2"><a href="#2019-3-2" class="headerlink" title="2019.3.2"></a>2019.3.2</h3><p>看了一些对微电阻成像图像的应用，发现人们会根据有数据部分的图像来推测没有数据的部分，通常使用曲线的先验来判断的，如下：<br><img src="/images/ictproject/电阻率图像.png" alt=""><br>也就是说我们可以对数据进行标注，然后加入一下曲线先验信息等，然后采用深度学习的方法来做。</p><p>专业人员可以从电阻率的分布曲线看出岩石的类型，如下图，因此可以认为电阻率在空间分布上是存在一定的规律的。是不是可以找一个指标来表示这种分布？<br><img src="/images/ictproject/中砂岩.png" alt=""></p><hr>]]></content>
      
      
      <categories>
          
          <category> 项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux操作及远程服务器访问</title>
      <link href="/2019/03/02/linux%E6%93%8D%E4%BD%9C%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE/"/>
      <url>/2019/03/02/linux%E6%93%8D%E4%BD%9C%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRGAN 详解</title>
      <link href="/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="SRGAN"><a href="#SRGAN" class="headerlink" title="SRGAN"></a>SRGAN</h3><p>SRGAN是一个这篇文章将生成对抗学习用于基于单幅图像的高分辨重建，不同于传统的CNN的方法，SRGAN得到的超分辨率的图片放大四倍之后还是能够体现细节感。</p><blockquote><p>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network<br>submit time:2017<br><a href="https://arxiv.org/abs/1609.04802" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h4 id="SRGAN的作用"><a href="#SRGAN的作用" class="headerlink" title="SRGAN的作用"></a>SRGAN的作用</h4><p>SRGAN目标从一个<strong>低分辨率</strong>的图片中生成它的<strong>高分辨率版本</strong>。</p><p><strong>传统CNN方法：</strong>基于深度学习的高分辨率图像重建已经取得了很好的效果，其方法是通过一系列低分辨率图像和与之对应的高分辨率图像作为训练数据，学习一个从低分辨率图像到高分辨率图像的映射函数。但是当图像的放大倍数在4以上时，很容易使得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为传统的方法使用的代价函数一般是最小均方差（MSE），使得生成的图像有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。作者还做了实验，证明并不是信噪比越高超分辨率效果越好。<br><strong>本文的做法：</strong>应当使重建的高分辨率图像与真实的高分辨率图像无论是低层次的像素值上，还是高层次的抽象特征上，和整体概念和风格上，都应当接近。因此在loss部分，SRGAN加上了feature map部分的MSE loss。</p><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/images/ictproject/SRGAN.png" alt=""></p><p><strong>生成网络部分：</strong>SRResnet，由残差结构，BN，PReLU组成，用于实现高分辨率的生成。<br><strong>判别器部分：</strong>由大量卷积层，Leaky ReLU,BN等结构组成，用于判别图像的真实性。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>SGGAN的损失函数由两部分组成：<br><img src="/images/ictproject/SR.png" alt=""><br>content loss，以及adversarial loss组成。<br><strong>content loss：</strong>传统算法使用的是还原图像与GT图像之间的MSE损失，作者为了避免放大后特征过于平滑，认为高层次（features map）也应当相似。因此定义了VGG feature map loss。<br><img src="/images/ictproject/vggMSE.png" alt=""><br>其中$\phi_{i,j}$表示feature map的位置在j-th conv 与i-th Max pooling 中间的部分。即同时对GT与生成的图片提取feature map，然后最小化这两种features map的MSE loss。</p><p><strong>adversarial loss：</strong>对抗网络部分的loss为判别器判别loss，即当生成器生成的图片，判别器认为为真实的图片时，该loss取得最小。<br><img src="/images/ictproject/SRGen.png" alt=""></p><h4 id="SRGAN输入输出以及亮点"><a href="#SRGAN输入输出以及亮点" class="headerlink" title="SRGAN输入输出以及亮点"></a>SRGAN输入输出以及亮点</h4><p><strong>SRGAN的训练数据：</strong><br>GT：为原始高分辨率的图片<br>train data：原始图片经过高斯滤波得到的图片<br>输出：即为最终恢复高分辨率之后的图片</p><p>亮点：</p><ul><li>训练了一个SRResnet，由Resnet生成的一张恢复高分辨率的图片，然后将这张图片与GT传入Vgg网络中，训练一个MSE loss 最小。</li><li>重新设计了Loss，将features map的MSE Loss，与对抗网络的Loss结合。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>这篇文章可以比较好的恢复分辨率低的问题，结合了高层特征Loss以及对抗网络的loss共同作用，得到比较好的还原结果。</p><p>看这篇文章的本意是想要对电阻成像数据进行恢复，这么看来，恢复的前提需要GT，但是数据集中并不存在这部分数据，因此这种方法可能需要进行修改。我觉得一个思路可能可以行得通，首先对电阻成像数据进行切割，然后将切割后的小batch图像作为GT，进行训练，可能可行。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>project two</title>
      <link href="/2019/02/25/project-two/"/>
      <url>/2019/02/25/project-two/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX19eRNTcv19R3+EzCEj6+ixQlyzn63ROi7ra3EHn7iU1DPucBkmYxsnpmOd4hkN7sXJxkxX4/v1ek7+8ztZBuZnsFhw1gBYlfLjinjldbzwDaj34wZ6odR13Oia6Q9BztogNSJZiRVrfOEgn1DI0FVNOMKlpdig3z4ceAfefgl/SRTg7HDn+b865wWizxixCUSi1ChcO0hwSBW5NQdv96nhWKsGZMAA7wOUBbtCFS9Ewd91mEoSkgqWTgDBU9M7ctuoUGjyocmX2zabq6SQxUWxWl+tqAiPkdNIH1sX0F/IAx+ToS+/LbwJDjvzh57M0iGmOQvKc+LnQ0B5e9d7Pw0fVX6KZ3OnH3XOX9c43Ag1F9rJSR5SBNhBzfA6H5lheL0740enNnnqgkRwpYijPKSpeXvrFZS0y2xd2ayUxw6fcIOyfSWbKJ38Y0PPt9rUEvIoWJTPT3L/b6Jbm1KZ6hpIUAGiMfvbjLaMyb7mDTfbqqm8uVtB6l4ble3CNC+GJZEU5DKL/FFzNxu44nrIhT6dW0RUgjZJ3RZH5CU7ERswy2wEM3WfLarEuKjUSXOOYGTHaV7iiskubJ4Mo3NPpvIxC/V5uZkrIlJHOA0+JLYlKacnBhMG5z+RvRQgF0Wm7oAnCx2J+qUtSsTT739h+x8XPcyRgnfdD/BCM+woOhyRdPZSDGZRZI5KLqT/f8OYL4Ntgp4i4o4MR4dCcmn5Ppl8KNjRHZ0FIDx5ZcUoO9nNLMCfX4NodKCBC9Fd2ga4j5BQ30Oh5M3jdZnwwS1dLy2kmNt0dawtKg0uahrk0F4ZrDiWJmbtGrRWIWvWl9qLLEZsZlwpJxUWaMKzKRUKBLE2NbCzO/OU/wkIU/p+rdj9GcAkI6u4kVu0ghtWmzRLLSRNcglnHifHs7aEBGGQNckFOnyxwUSJ2yzA6ceQcHFQ2KLvlBDH3uhUU567A60tA90gM+9VcR7RDDSa2YR3SoLzgLYD05tBpqLC1ij7DlU2nMivseRiaBEm2yV7JsQhtBvOvSFmuIj7Ih2eic+s7Y1U6wQCARmfbc6NX4gc/Rq8QpCrAx988lN3tAju/Cc6X+gDKOEYdjKGi9nZhkOkHdhWmJtT8oZKAwWU5JI7buSxpLUn9L005mwu+lbWuCoYz4bpGGjmz/w9yqyCw9YU95f3GK5oWx81oPZJwTCgKmfNq0tE9M1K8M+rX8OmCO+Y6srwSywtpCvkBRgzH19zjvwA1jzTTtCviyJ0vj473keb6Gu7wGYjetDfX0rM55ZyPctuoF9L+Ee4930/w9AIyMuCHB5VPIOZ2GDIpFERB0nUn+y5gHnnEp9DB7mtxgroy0JybdlMGAQGzTjj2XlhivnW+0z0lChI/hN3n2awl8l0Yl8kN7/32vEPAPRtziDxTLutYQusa+3LGtF97SHITQ+r53MBsCJ5y/6CSG7EOR6PCwvN+naNxhy+/PEAHQoIhOAk7cugDIbVV/wrUkVSXnxR24AQ5zCtDMu4uhB8qlQD5b2SNDAxw0WGOr3+qFHDUmnyNmazaexk9enE5+ceKwWJz9geqJI+WFsrm33wf/WKMn3is8mu1YTV7oM0FAnVXI9Nvk/64rqeSURABfI7DKCr+VFHj+IsQVT+9rpCmWBAs8sfwhmMFhlo7zngiLP4oRe7zzYqu+o2e9Jsb1BGTjlxukNlCkosJP//gRB5o2yaPw8toPCC3clAWHv0odtpOdIaFlPMW1OTVoENPDmTfv8aXuPN0kjxPgU9ZJ7w2ivnk9bvpc5fKHrfOy87p5EZt2wnvlT8rE2fOD0LQ19gFG+xkGjVFe26Wet/hTh1hew7/+aLhYp4B55/qVz/CvHQFObaqnH8p6cNuFcDRzpJvGYAnjgxYnD76dBLUD0eJGyn3P1juqMrsBXlsLB0u1tymve0gSqxP3hHARKMCToUt3qpER0SPFyfiSG0GB1ph+G8o5a1Icp4P9iREpa0NSKuXu2x74Pe7sKciwNcJo4sEeb4PR7nyQqCphqv1lxOF0OIjpwkSUQiU2yJ62BY+GZ6A064dCtqzpvXpdSoJvFmgi/wFSmJAn8h82AsZdk0XREp8IAtpzLq5SFRAtvPZFZJeAY+tUJefHfneSLg9ZMWUOJqwHq97JLZL6XyQ02QzmMPj0NgVlo/aNSF6b7ceh6jB71x+3nEtAHd36wnPw+UAXzhC9cgnsRFsXM6pb9lqFgpRVIXqwCZbIRpNk+0rP0Wi7uYwap4UCL2N7nZHfpT228ev/8Q/3Fs7vww5JvtXrqUCWnAIAgdydFR+ADh6mB66KUDcBZMN0TNmEwW1Y7NhxqVOyklEivfLOUht1BddsspUWbSsKVCwkgwxRerQi5p4PJR0O20cOziIc64sfi51ZN74qUzx+nxhHHMs//q3aGnlxqU9CSVxHrQ7AT35ZyZVav3/zX3zl+F53HDYmn0R3UdytIp58w+1j5YXtnR9E51yjiynQibmSubx5SC9jKT+w2c9DOy1XXZR7l6QV0A5YAgyr9KIxMK5drR9E/abaoYQOBoJwUPwKt7lF6HVidtx73+c1VvAHH0syjbNuBoq+anLrxvtCIN5ihccbjTcopLiFwfuOQq6XmnfWyOOx4i3cYjhlH4h45PFvLk43mwD5wLE9mYhGAfbC99PDyMVmOSw3vZu/ycpt7qkBcoPFYTonPNWWoWogkl4cWHLFori2X6T8YCYO1SVwdS+sCR/qJBMzpIolCy8LQ5f3HIsaWfM6NXfLeNSwq/JzOomgglpYiQw4goQ+TrJHMpIunQD/E6bGXkvbvm0SZuZsnKuAJnV5a4nOKgBeXIlHVQuKaH0I2a+OY26DwuOfP6iSzY+Fm7yEpHyyNDs0po8/CZVjD4C9jx1lg1YuEpDpJt+S/MvRchBKgOXAUnnTWudJl36NU+0gtZfAu/Iw3Pm5PrcAGHyR7aFQhhFWv0etTsf0RNh+7Y1jW9iWZDRvIOHcTZnrodDPFRzNDAluYXNOs4bK7ezGIPzY3KxfgclfSD67MGpmvFJ5xvsKSfWOZL0iUWrkaTNsQgknWWXSJT1Nr2RUFB2TuejskF3dmmMr3vZqj2J9qV+DZ2R3JBgpRTUPozRuG41wddK3m5EGQgetfb4U2AJCxBe9FEXO6he4tdzfgORyGQXRirTsEshWbRc+cq8FM1LjJOsQgXgg6O3BqpfmIceZE7W8y3VbqmpSl9PLDey3D+OY+W9pOmeGmNv7Bl3tNkC0kC3xPfMpnobwHBQn5yys6+nw/cHvCnHFCdEzkwM9tBP9BkQ1oTqL/6DsQ/cOAHngA7UY2AIsl30SBemmuAwIzyE4fZtxqbToYKocqvUz6t7oXekuCu/8v/x38J3AsX+i80HPuRzy0ltumyA1yUBbqMf8xuR8IVjIV2NGVGYtao0rehCghsd6OeDmmLgca+tuM7ASh8Ms75kM7v24g/72WA1vwT43Zyu6VurmDLVk/i4DIN3pQJ0P/nwmIDwpWLg+r8UwLHsgcbuuHRwJP/hnICMLAj7relh6+BrpeLsWgqKbVLGKP6x2osK3EYX6vSg0/lsOIK1YIoec8lSOoivKE4BhXwCR7fm+BhkTfVoyr5Z74UPQAQkgCw3LCyt7UX1RiWOTl/P0gLkaP27jA0DAiNDTzW9AJBuNL/0k7fyGRB0wSiTLy0Yob7fhw5x0/tymzSLats7faD+BSXpC+woJsbnWatOjg310IvGJK0vFS5tcXXCzLBVvAAB/lxHZUsAmrPE9QpbZ8LbgfdUmVPeEzSydzSNxTsQ8TI9Vt6HQHvoGR+uqwhFkbQv638Q3PkGyR8Dd4DPILF88O+cnVyeT3ELy2da+Rp8PnhXa0KQ8u/BB5H/VAhFjDe6W9fUtLfocXUR4DV0MK+iprkaC+NKD6ZHW1Rux46q5qj0pi3SBVpLtm1CI+bMxfunfkmelsKub0n+sgB+2n+1w25FA7qg9KZIEbSEPfdbqz/Fj3AFmYzxn2/zKlAiAg7SSEO4hlfbnM908K8b4bDvzfO0RBUpa3E33JYAllBMsAi8xbI5fRsyluddkuQfnwC2RHBdM3Vlbvvp/RWQDmgqhtGn2w5FuS3dhfD7hLrBoeDT0UjaYIs9I/6264gA59USIJl2kzSEG2Tdn++dHhnTbTKwvrpI1Rx7TGpPnSy4kodcdIQ074AMTQySOC3ei1kAX8e+hZ8aFQIJzst+ahR6vd+Z0asSPj2drzIBMJxXkTnBaQVL5gXXBiZm95VuhVmeX6bA4/632uz1xZZMe4e/TNBqVJu2vl8Y/Mp6j4HLwwCxUzrWfVqhHEkKpM3yd5mQmgln3MKETbi0V7aMk5uqrEa30nuPpWbI0szQIi+hw/ELHMQNCa0K6WVgFNHGy7EweVOkQCKUTKCIqkzleypuARzoJYajoY6QqCWvVQFZF/C4WJSiePq5NJQ0p8yM8apaKA2U8sMDK6zOymi5hV5wjUoqqaNzBeYeVMhxv4Ea3OF91T8ub6MJNkMKkysK5EyyRcTCDO+Ye4z89ToRUetJYXAntRzQP8/cTT+xCn8kn8ZMHtxCC9NTG1Az8Cee672+fKmvEGKaI4REiw+TJeVXzEjLNG0DTZL+3S4RfUPymUVwTn5Wn48lwPON4CdsqwM+rxzsdAVFK+Xb0m07hUm/Rxhv3u0wXG65wPOFLx2FE2R/USb+VIxb5LI1gUUL8J0TH85hkt24wJ8YZTDShlpAPUIRCeGOzqJZul4zQPRgRlyi64AYOhp18Xkh+Ri/SPfz1CVSGSoo/9I+gmaJFpGatvRe/TUPyCEBQ40HntQTvMWRYD5v7f0/Ag+uQVnsWDzqMhm0GiPHmNSSPnlRmUXzFrLu5R/1UGTOoRpziwWH4lDM47KEQbOrpuiGr6ad1d1TaBOzRZbEej1ayDhOGxtjgPHEDNDHZy6guid1VCBYmV30Z6njO51cU9t1GCw5Rg1yDQO3MVhfVHysr2kfB7GY3l4tLec80OOM6cy555VnuoZLI1+BNoiVPCU5/fdKlBdS2AfSla68vs9wDGRvb3mFKW7crtFne3hqRfc3TVo9v5bVL7zLqw1HYLq0iaQhySiL/lfEavtNbryKBuKJ3nKdJLXmEIT6qtgI0AeCKxioZlBKUUBvAoObE5pFvyrTUKq6F4wo/e3WLh0pTXE2vZPhxs9ate68CLvZkSfFy0PWMJCQ1fvBNRDkInnbRTBCL//uJ2VcVe99XW2kmKJCro+ao2MdA28kJEBJL9dwxq8aqPq7yx6kYOReOQoxzNk0pxSd8ZhY2w0usz3EImuX9GRuMqpMy3I7NE29ng5ahRyVzIIa0g4lsvIHiP8EnPzqIC0lFRses0jCe2fcsUBL+GPm1aHaksjbR5Ex0pLzKz7laMAQbEtAUguKbAkVIxLRMPo7xJ3sndmtPGriliANiVSFGWk0BBAOIpJmHxt4b08nACfAq+EOkTM5QfbptBAUU9CNWVh+hXqb+AO0+Y6FxVg4i15yAUEXHPX1GKkvfArmXcn5ze55aClunjTgdmIVNdpkQeXwP3JKda7sh8v8WSnAvNaGpE/E3bvkg39sa47EWDZ7L5cGgBbOlrsdFUqfHyqU0YRucJs3ZFxzvWJ/DKXYZFcW6oRUSwIoyv607ZPGx8UmGVryYmiwGiJrHbiYMG8Hm8JLm+AkDjRMAaya8ZZPZrrXuX2f0y3xPJzRn0E0VJNlho2NT92li9b+fsyNA4EPFgsILRNobt61hpQtztKUJ9NFfjIP9eSWw3SYg90C5NC0ttwVlHlSVBJeIWfqBk1JbM4qQRiIESRIseeYLJnwnoaLfJH2y7XUwft/KI5rE1V2JEBHNeJwpcK8tFh9vPd55tTZZCpNaYtGkMavKhVntB88sh1HGJv9IwwK0UKov8Il9oce7C3oDZrb+Zb11QqYK1oW30jSbFxQ0bxRzD7P2BQaiBI3U54FCsY+eHDRGcLY+DreSj1EPxTfVL0o8q4Wu0fiy7w2hyq5kEX3rXRqvJgkEAfnlQ0VheObLjq5xIKmz/n+smN12zT/0ES2FK74CKm2ShyFWjd+R1WJC/rqHi+YQYw1DlNJneUtmZM1KsEw/HwGwrNeVt3EOZQNAb0g9zQsH1bzTnOg6QaBQytxJW600pV7P0xX3gVBN9NSAiXEgcee+MxjPfKJprD53pkuepkgmfkFSfYdsyCh9kaqWu2ZEbZVZGU52+i3fhv8AtaObv44IBo6o1xkQZR6WS/JfbHwIzgSkZpG4N3NMQDDMcWnpwTl8+NpeQqtv0EItAaLK5ulimuy5iXMi9XhN6cL7VQ6l0tzTYq6yfrXdEPHjZoiPLMHJnzgxuNcNbzYVw419pPxgx3rAc9odIsI8yb4wbl9KCGOtmh1IsPjBhLZDoB8JFeVwq7GUDNxeF8vKmQMX3pA8cD7vWvFgNzoU5C3j2AmZa0FnKvjNfDgDywJsDYHPRiisM2e42+puYxvRFarOcLkIl/UmXc9Q+l9Ve46Mglo303bCSM281LvDsSEjYkjqFmJ53MyBjxqWKIiisOKKSLU3BbyG2zJDrC2tPslYl7RG0kp2c3hz7l7+9ludd36JzwsL87Jk2xMY6tqqUEXa4pYlXjSSL9KGCRbAlP/XOSk6JehCsCw5s0A2mvlnvmaCoyvvi2DiNqHjmq4J2vnH+zR9qKoGudDgPs5EgvQkmKyVYvq4XzWNIYLrMYbfDXiWyH1bhQL6U/2uFC48HOEKyfqeE2yIQ/JOs3ChpAgVqqv3R2oX9C7+l+CRMTzfOmBR3ryigfPcJrURjtYLmCtvB4HiACP2yY0Y7+uCtrNwxfFeUMVY955mVQNyYnSkIcCGqDhMD1BaSRshgyHCgXYi306VcAc0Ms6PcQ9jY2ev4q281S8MBjzUPyfdVvxC4GN/fnBTWKWx0dDemUEHvldar4VaerRD8D2GvqTlSZEztmdfenlkbI4hTDPxi6GUoOhjz3goKDSm5eCEKbOe2PnuuL3A0njPqv/L5eXyfYp8vWiVq3Y5W2KN8wCCldh4j1Z6y4LDv9rNMWf9HYfewOHk7WSK5/mB16eW+8qE604Uh0qLf7YpfP2gKNITsfjIv6P55iZK+4HSTAc+FJ3tOPTvnUECqIgJubg+WZ2OA2HpGAMTWJoXj8bKMHY9DYs0gdp8D22sN6gfWVJZ4eOzLWG4tj44RhUgY/rWcli3rtj3ik+0/Ar0q8eFwt87ZXRgZeyQoNpExE6g+FS0wqXbLEgeMPsrpuHDJqoJABPCwNTk/yn9VKMVncZdtp/bA0+4vSB6RfiicJnE/cA/mD4SYiDlupXHCXsiiQw1K6nkixgNLvzDWElxlqlMp/Sa4/8P2rJxCtMOhyy4ZkPxoNULDUoqT3ufJoWHWnkvUy7E7SmKy/a5Dl/AElzdoGBhsv4wXcTzol1YHKaDFU18E5UxRk+czCZwMNUUI+1VK77UwD/YxVFd1pYEE+vTUnaEtn1EuR2hsRvKsoTVQYUhsa1sQvopXDe+oMcaW4YzWQEfM5BX/qfgCyTq29md1ja7s5XBfWet7WQbs9waWMzYhGNWdFY8YidxeRjGYCmsKv1z4WQnbOJAZnA1DT2hJDqO6O49ACpioV6NbqSDBmZUSsEJqpbhCIj0fhhzeWoeMfLtXjqZrE71aTOlwMkLgz9WLMaTVC/o81+sgNL+oSwv5UQZW8Fn9DU3zIg3xrZ21cx6KaQ23f/bbJyUSWkNodsI1kclu8vMwvYHtLU9JydlNB1HmHfERFKZzMX5S24pIUTH3KksvtM6ytsWoiJjd20Vz68K7DFuwIk7ZwKVCIcGkk5nDn0Wxh/e/+GDovbHiNNHgTOzwG0JMIlfm2pkP13kRViXX8RxcZvlL4NzLWSJ+Jf0IYq15oTp+emX603LXe93i8ZSGfU3Qp96KzonASbDkBrLpEXmVVhCQhbZ7f5/skLNK9WafWGRAu6qhBkLvj31TO6WXOHhbZjbF5v97zFmAiowjfhGKrBrz8mGT9nbOVe+/EnRcudrVhSDX0hUjB6MjNJlwHJmylidymd+IOTiqWatZDvc/zUC07eO6mSdCDpoUq0E2kxCKRt6tS34WSi0qpcKqq8nEtRIaWqH4kE8afOAAq+cUgp2EitgiN4N1xItANSdt2c/SU3bSEa1BhS79sF1hz9yU94GaxyBjMwOz2+i332gPp4T/kJofbEPoFKIEqBDH3P8QWCpDV4ZqzAKnfJ3vJ0fqcuj5yAtwet6lmMkeUrTJcJ6YKc3/kryO7o+WsUQVKMTGPkSTuV2zVQ0evwp6FPcD/Ocm4Hus1nqbGBV7BFm08KYE5X00xh1SKuPvAmDTNVetkItLNaGmx7XXYv2cF8Rn/p7iXjsjKtZqGsQLt+Xreu8VeGmnXPyKJiDDwX5M3Dd1mcbVwYv9bPKKkHvbIiSxGeo0oiNYo/vrmIUY57545JHz9JNzHe0GOEZi3mA9ooF/vuVA0Mcan36H5R18ya+8Ljw5EJ8wS3wRz/93rBTrtDu/5PcY2v2vr6f2RkGAAoqCT6kJPz8P6MC3npP5NFINp1EIGmwO+R7mxDxNHPp1SRpxQaLZse9/Y+8iUDxWJYMjbB7bZfjvqpbm/zSzmBLxCDf1H5kq2I8ONO/AAS2jwMHzYkRGQ3+aw/zdZI8QqpVsbxx3kH5bMMnMvyirW7+ny7f1VpzGB6rsF3Aiod9LB4u/qRg323Txr+VTfLoqFmgqha08GAnU201LNqBQcqRqw9zrSTEJ7spkREesC6EDqxPQuFuZvrAF+ILCRl0sesnNvqQjUJtu9gcahxm0re8NgpHh9l7leBlwlikPN/5UD+0LE9sdjJ9j1Ns/9Y0cavvWOtXuuuX+Z704d95mWYiaKHWZTfHipEZqLEScaZbPy5NndGQ5ucm7tpJpZtG2M+7/ixnb0kl5l47N3rAly5d3yx349iopa7s1fssAG1xx6mUawggAKiqlF1W5gIpqNE8mgOROzp9NOaBrYAUPTMIJgSSzw6P5qP+lFDVqenw0TGZbFGNFononINha48YxDJoOGjgpKiRdyy8wi6SH1/g8atWF9PbbzNvRy1itaPvkmd1ek2Aol9fmbJPZh4iakcZFYLM9VNyK0BvgVHYJvhdjfRXpk6od3ekMcwBF0yope2oP6uOX1PjGUJH4GZn+i3dOXW8iTALbB6ensQ1lMPuI0wFL4OpsJ/pb9e1CM7G2uWVjy4ahvh33bXrsX+beHMuwqZh1Dx64Q8xOHswhweSulcKSLOFPe2Yvo6159BDyk8cefyZDmHroltjGUMmc5FV/4NjyBILKBvfnJtduBJ8vohzf7PUFGTlA9cQ84jDJvkMb+/EeD9iMAtMtR9gsFlEyYVOQuEkxRloO1XfdW42NvpOwm7i0ijKXooAX2hU36KkMEcAPEM6c3Cig5YuEzrJAUzNMFmH0xoCtgdIY53+KV1vlWgggFtgicZJYfLUj0QNgE+T+Nl+zMBfFQfxE7iOJzdNqBJBilH9Px1oqdTfgCa1T3EgAtn558DffdEIrBknCrK7dfiT2N0ZwvwWycT+LsUmkh4BSoPyBLr5WbEa8cJS7g/7+ri9r5E3msGH0EpGIBIJynkXLlXuXYHXiX0WkMRNDCphYpRvrjM670NEnQh9oIH+9h0aXvKUPzFeQa770zeRQrwfZh9DAodzVLHjXcJarMrZBQXhAotJS6dvueqquloRdfOFlPGDJ5/Rae/DrvlZ2U2FgmaOMXJha+ILgmNgXPFeY+447DqVzqoZJXTngnSexscZOlwU/XkvEOcewiMEOY0eGz1k0opfsFtMq8zILLml/waaHtpjjqAYcxPPa1jzl2pCXbS00wxqk5EFOJE5BCkH16NptT4UXSSLrIoWRAfcazdCatq4fr/4DYuTiIMgc23yJ4w/On17IdYvwZIutOduvHRHVux4AJpDwgB1nWCkMBflEXCIe2+qGK3jLZXyZGmnu67qRr5czxCzm4K0qtbjb2THL1X7Y3BZ5iO14ZxssNIk9pwT1xO3GyCFs3WHoIthfPN7R89z/IMt3W4ppdF8Y3ClMX3sE2BfGjEtNR7e6s9n/sZDbnktOzfD09QJCoasHnjj1do61CxTJEGCUbo4j2PVw8oO7suxXPZlZSj+UOmRsRbLyvGsufkF8Eixev5zeSML2wPUk0sgRf/EpTWrNZqAYiVNsb5bkGFUYHkMxjmA08FpjG3fXH2TqzH5N/IdMnnslQO6mH2tjFkYshQEiBenVY4UhelvgLU32CW6Wq/PXc1VCJogc4AC5vvHHEkMpb+lkYu0wAAXpbkMKmw53NH+JAQm5qqzW0u53DaSmTRkHgIOz7i/6haz4iu+BH0OWyIp7AmZj73Ms5w810Qj/jNxgum7DVeOIcF2tLfNM9Km9gtc4uGiH/vsA8MC91BpOH+Fh9+ZqTCu4aYMg6j6z168JzNIEK1oxouI2+80coP1sFKGXTYu6oQleTUC+JmdtFSb0bYLnaGQyO72OE6VM/XatjVYgWqcrUu3PcuV+TeqX2IqzrrJNOXM0J9IE3Ny5TZ7/jwI0qoO3sU03WBoNZCsiKDpFrH2PH4bY6QO1jdWhaTBRmdZ8lVIBq+6jryiOOmAgJ/P6bifxypr/pA4k2DFncqeO8pi/KqSrp5KLft5+NNMNghZSJCRGc6ruMgGbbpthKB9RSX+QeGzz55WIECE8V1DTHwtjfM2iXfgON4RJ7OPu3c76okfjFXNtbd87u7uK/i56XayfG0fi0INTK75tLNuZkgUMg7PKHUUp2shmSCSBfRewxUI9gJo8TQJoSSI5uJzbhocRAlTGGp35MOXo5G9QfAMLQLJd8179qNw90jgceRgprlYtA0Qu0p1vVME42kytgb552CLIhqwaOPQZumDuZJVPUQ1udGVM3FEPY1iozj22aM31DIK0AFgvDtNzBE9Rw+bkTofnShjiVXRb3Ss8tdxFngq45UKgORU73Nrv09VVludC0StG2o0XLEsaO5wNfl6pq7PNGJDw2SH4GEbB/JLbwp9W0caLLkBPLLF2ZmwKGWUO9G5CVaOMkEcTUKzq7JKD6DSms6vgTaH3MsuX4Sjp5ZBHWZ9wwhIDjiNIhb+28xOX/7vdA859Vbm2JzclwqIJmwgQFSMREesG/YdPx/KouNvJDpZ1/yfZDU3mOQ21mSSa5THA1TUl8u4G9QIWq+CxFLfvodDvmsY03MqZ3rKAfQOaLBOdZHZbLLpKA5wpYDIUipMj0w0vGQJIyn+x3RqqXTzpCgEWwy/IsCvmoVSgKXA8XLKY3qSGMz/8gbsDkR4ih2dDuvUU7wvSXk/jfgKChaEOWhFKosW4jl8tjbVoOaesiGF8ngTPIm4VlDmYw7/gkWfaAoTux4rXb3Z3efWuhy990uyAZvX3YTldbTtZsMRsELrSagFjF4PbhL8ufvS/9fEMJuRsj8qiAhhD/NdfhDg5LGzj3yxDVL6Slk9cbXNjR+pKT9Vt26VCKn0Wq85ziIrdPCUJ8NPZ9ge6fX/WOiM7jsgnI5VVVTYl+8So7LEbfJmdeHRrLeRQ1HkF/fcFmkPLPLHwpdOZ/E+80FP8ZM2VGihg3d/aHjbK13dV1rbsZg0a/Ud8r3yHRFvePFT8wCObTzX1DKTfgIsSeYtIXtook3sW5hgpCs1RyO7ojPgYBSxQEz3XOCHeYdf8U3chD08QYm3Z2DvzyJ1Jq8TlWZ73/KiZia2aLBraT4WJJEaiUuKgfEAglPIGYScHezNv11Vf0lM3JaEpMsMa0a0/kqfUUtxmliO2Em1OV8AOjZOPhQuTtTWBIWx/y6dXU2Rwt1s6qAOb8RcAtE60PQNw13dOUHf0grG+qisNMfWsuedFSrZlJD34THX3sIiZLbVzEG63cmqeh+E4oUWB75z7FLBptYPoYn1Ht631WrjOmPkEreX83Fodgx9CD3ef+vIUrTk0UlYOQri5/Ve/v95wMac1Ev5G6GHvdU5QLnldaYmTdV12Z/OPaN8AYdg45dGtZ1n5JwEwmvqMYn+yyGHn24NT+ZdcKmfFNPRv8m5Q7oqMgcse/N2XlO+HaovAP2SlHyTSrzWGY+i0FkYurpnPpL008ws9HDWfZ2I6jM5kjHTItVREnxUV3F0tMrzQe3Hh56BVKvjqOr8K2IIsm5HHZfhfv/ui6Dl/8zcHA+VMkRI82bpEm4xmUB1IFlHPC/GcoRY3UVPUBiVv8skSNXTI9iZ00lxRcOYX/ovb2vVXvAI/946bojM61KedgovWWTV5QG+78ihZDZroZcq1iiH0LM0DESQ2l/kZq3PdbyjT1JWoqZcYMltM1w46MXFA9MaKRUd1fCpmW7ZvGjiygmWddL1rsn23DCb4M3X8cTTVq/DMv6SrRIW5cyMYhywfgSoqcwVnA1lAGSvfbueEi0Ou0nE9Y01rygu51ovoGqGDIlBjwbR4y3HGbmOfxj0u+UgpZaWhK+fLtxR5WsD0VDi3alrOS/XCzVmb0WxgVisqA8n+uv/MPiwAkgcbVldSeUAab5v8JL0A5nSaE+gUbHArh6dk2REEmbq/qqHv9WDTK8a7RJH4CxRWIMCXK/Qqgccedpbym4qIcFdqRQakWe43pplffI7ESWPcscVClsjM9ovcFfDWJ44U79MXhTEQMGkIG5qwFzi3xFMeCSXCkfzwe/EuQ+gZrySYnrzTtSX0b4hEo4SV40eOxQ/uInY9LR95auEgrQneBjEMCZXxWLsAG0FXWwF6Qw2IG8aGr61YC2shIEv/jKm0KeJubDviw2QgV3nkcO1tJkGMuNpbXF80Gp7Ox9GAkhVSElu+L7F9Vk8QKltpt9qzyMY6uwMz0LLiM4SpZxPPLyylymNmL2VZh1RLrRwnO8gR+X/WEvcFC0hJxV7KTpI9bvmdTeq5YOLSWkxIb1IOQJa+60tHPWpcVywRMliRt4pbz1kAFiIq/MRs9dhSrRAf61QzEy0irJa2OK52e4lFd8M6CcZplveRHodSdxzsuOoe+z63RJXEhoQmtKp8+SM/jYtjj2btEnbmlDNFROpQ2+MPDoHzmuFHCDdmSKAd3EsO2O9TEDqjrgqgNdj5eDuEYAORiIpJOKWyAQsjEZJnxg5maZ4LWI9pL/WjrI/CUf2kZ7PaqgWTChkyr6vxoyqjTzwAjGLQY+mcEq7OHgKz1MycwRzkNuA9jyGaUvzxBIcXFHkYMIYyANIkqxObvr4kBzBjS0xArCdttADLGmm9KbQVlZXd2EyhmNC8BWmwN2j7QR4dDAYVBo3D+NjZpezI4/5HHIU3KV03ym0aStHY3BDdIhJQs8+heHxyr3ufjlX8XNOdXntgqkZ+qWbPbu5XFGOeUi3i+k8qk5M7la0YKTnHYZ1miflzptQ5DZs1GWoELPqqsEDIn7iXB1eazfTcjq7JhVpMUKGUEG+fjsu4BziUNTUgEFglY0kmxp2NmkuMam9DN5VwdetDsRBMJwZOKsG0Rl88zea9IB7gBXgUV24Q/FdNiWvuNXzYihqMp4ETRSatQWnorLa0gqMnaoVNrhs4hBTbg9eQbxnDt7Vf7QiFUsUkp5oaBeh4M/dNwoDiFXrR07j+T5eexW58y3obysFgPkImtfoBUAdJy606hI3nFXW/EcE+pdGix4SJv5kLoM0BWFHCwSH4ykpJQhKINGsYRwlSVLJ41THvktf/FAmj6wGhqmcEZ6FEWRvV72WyoBthTOwcqSIGD99qeFS/Ioe3ut2yTuK6TsZA2HCwJEvaXReNRkkkgDpJ7F/i2t931x9P1FoBA5UP1LP2PuiDcZROArRjoSeowpKzVbEu34E/Dxj44km+OVeBgX+wb8NWVW3YcN4fHFONDdwUrnyCZo2Xhig+bjaCsIGvH+sa2K/tmYzaXEnms0GSbQM1FanmjdXBN2Mu6yTtAPLnddjE3d4N/leQAHpY9d4OibbuJ9hmmD7tk/3BVSZOHmsNmUOvbTIIx69U4wtKNnohZ7912Y+ie9F4NBmWStsaP1TnAau165KkJXIBLm2DKxleDe9cX7dT6V8X4tlok2zoNHVLAycFbsQS/cvTdWLV2IO0zzLHBrFWvO6AsfL/SiiFtkYVXK7neHR8w+iHzYpmNXSlJfeqisCMcVOSTwoeMT8XG84Fq0d2138e6MSscUybtDqr0TdUH/A6grlSQfUya93Eb1zTUCkuE+LoUe0AC2GG7ta0KqUeCtiRdZKCjhGIEjan1sfxsYDMI3jHx6df496ZVm+FwcL4Lgo8KzVwcOOM+HFYBfIGRmatSsUFzDw6/S5dYryxvdzfhWpnrNSKRMHUE0eJlO7uXSuDbSPZCx0/vg4NgnoO0a503Q4GFBuElE8nyZ8u58fmzjKwKZQOjaMtGTu3CkMciL+pyogBzxU9NzelNfrI+JG6/f7QvlQYaQ4+oST0MbAIM5TyouWlvvmhP+iITy6adF3UiXSxiTcTYXIeadHBdialBjx3s8g3Hg/mt+rPsZWIlUa8XuxE/jGofmK2R232xmECZG4VOtqmDe86uqyp56Pi1mqrpHIJQDGcsA/i8FPEbpLlHGLRIkNWULcwIFJI485rm3P5JQr99ebQKP0TUAxOYid/Su16aXELoav6J14e2Wk1m7xCjB4k8QdPxHGCoTnhEWsctTS4ilBDdR3ymp0TWKAcXSk5Hw+2Pygf3FmJUjtbMUiAgdEEjjEvFTarV76Z47bmEndzz905jhfOleqATKtPEc9VRNEk1rTHouZ1jlJZ1OHv78iQzmGBLAx5WdidBbFcmXGBZT4PqUp10qrQEBOiOSP/gXvvh4YlLwj3mzt/dt++2eYBGBrT66nISisIS+rLqJ/wQRckQV3aE9+ZzGoONtj8GjGV2cuLUzBSDJE6B8xLueS6X9nCRCfiNCcNL9GlCWkY1URXZQBj1qXoFIFOhP90dohz7jDX4M0YxlU/O26yQDJVichb+ub1edEX175FqMeooKEChhO8/gAyUPdkyONRkTSGCQXdEZQnnkabM1fBiyfoDJGW79c074Kvum2t9O1VA1nrhvBswlsiyhyFq/cQVxbQ0mm+w4Sh35pvPBAsXef0PAEY+odpWrA7ihceW5hCZFccj7QCas0Cs2fMFxPotcVY2x4dVMAktqOrdTveco0toXwa6kKBbH+l9Mda+MJrkmLqScA9C054RUP+DcSRRvMgemmft3RN9w27bEspVbJ3E4+cu55nHUzTpP2ftGxJJO8Ikp+XCStpPIZNmY6NUDxs0Oy17PVONLoIUehC2entfwm+hOkjUODLyq6FK6pHs5mCSDlulDzOwt4BWCeOnNlQoyLQxEqlIn7mxXmMbn9+dijJh4GWFQZvMKw6H5vHfpBzE4cKQbe2nzRT2gC3vFN/HV2tiq6qRzmfGUhyRi2YED4JmoKxk3Y+59iZ7Yq4TMrC7foRD4eMh7UjHsJhHyy4emHbLIFEuguMxzlp/hlsrSDnGersKsgOLGwPCE4JkYg2K4UsAFmBFJxbb9jW0GlAPSp+MKvNyfWPxvYYZMyzwlukqMpioftZAx6JJi83UEDV3c43hxVMGJ+4ZTp2GFcK+GiIdH9q1p/6uyzZcqbsOI1wBmQHqleGTGIQP+aSFY4XuPHDSuiP5zHTNehVJdwu0oqW8giNr24WZpcdpWVy01dcaIHMYeyw5s2lYtyAzVeOGiR6ns60P/3NQbj/44pjL4KCC0d89A3X8BBRU7NJ/QGKBJcPUGx//kXAwwsTnFp6B7PBCeY27KZGJ4y3bpPgecLXra0TFbHV/ffZIOisd1R6ujl4wdghSf8XPlw/U7sXeMZqxJlcLixmkvrmyi2aiqVRDHYQcuwOtPKNuZpO/VDBaGDTm+MCgiPaFosVHtSdq9EFAYoCgpUgFmJSTuhA5y0MlBVAwdNWdEtTky8q3K+oGQqyz6ui7iyYiP9Bupg5ipX3vVz37K2DcForgQeq2dUktQRrOAvzaLl+5pc1KiomPn37VVO16PSm2W62WB7a0sbc96TOGA78nzm4InzKn7xNUTEPZfKxknx5zr7EBmL8ufRdLF8bl2SWieQ8Vmv5P5M8efVzHbVrUTSt8GFbUyc+JtOlMQ1UOZbPjfJrxjZYDNQM8wHD/NLcQkps/qqRum5POmxp3bnCIDRGRbP3b3u8oS7fC54ZMaT5UsyeQnlWJgUvhX49fhpayzD/M8NSxjaIgyjg6pQdJxsJQ56Rssm/yS0bWwaYpRkRfwSnZYR/EEV5Z+KD/zZUDfH1XzkGTxRxoGmqmNWyZM0qdonVVeSO30iYo+GuMyplATokkIkf9qxFOO3Ku0CBstilNSY588cjwsUK0u9fMmCAys0FrOR6dscSxisTKWEtS6NKGnJ8x343rrYmgoXhlqwDwOa3NhLyiVLCyqXAWoRJIpIbPP+zPwNf3HhJSnzDNmIVHEsrfUSIwAlpwljazAKFiM7rFXHtwcRO8JgQ+e0PfKkOi9H2mQx/muNkB5m16oZJUKwbgc2tGoYlBeaMuDcvXqMoPu7zQI+4t3iYodu/+RaXyIoeMT8/5AujolGZUst7r+jQAZvdTUr809Ka6yP2aIWbnIsMUNw51JqX+Co6Im6VIOkbFVnTqIVBAlOzMkzRKG2YiicdFaHDlsT95iEvnPfclGDBd+Z6wjAT9whw9P6vtQyvQU2aEZBpHcxm8mEGhWX2t+BLu7ZTxkv74Go3pxxHkVKVnwp+DdqV9Yelc0Z7qMhSZ+CVJiiJWzEhzob1DwIVf7l1rjLzn+oaRJjBH2a/iXuv/tQ2dAwncUrA8trAGn+MNXe3wphXD5YwLlD9wJe3TpV1sqTIYH2SvH+xZAzXXnwcTw+JwfdYSD/KTvYQmX46BevzWqsCRliTmRYX/BEUkXn1sad6Hk6hYQtylAulUoZMAzP+1zwKFpee18uC+2caxjYFhhqX2i+mSDVrsN+AytwKk4WX4wNbSiRax2lvUNMpFxOxP1zZmHwHdXVgImsrPV9ZrQJBtQdtxF5jY6WHvxS2VpktqJr3dykBcICzBBa4hOGmuQEkOMgrfUoN+x71cjZ7R/telisO+hKAhGEk7nuX6nfPj2gZXCPq7JGRg1SGmHomv8i3BPsXXGBdC57aUkR3FBMIgrTTN9kYGWJZAsnbntkBXHZTQ/KzpbPyIzmJjbHLS9NTIgvv8kX7m8PxNhqmFLXUdW12BVPBZHSubsLYxJ5apg/ozKs4Cru+Z3WXz2Dt0+G3d5lLGnsbyO9eQpREIhwJHvqry95B67QjZbVHaSaTeHH2nKZMVhhdU3IMMqPBX7IOfB8ll70mVi04LbF6mc3YYPV7GOkBSVfKtWkkoTgffGBAoV3yhMg/K09W/Fs+2jwS2DRh3vVF4yDmriBz82PKujIBXdslS0cjhtn+Hahcg70Ysc0RZMgvpn4aYwIgwpoV85OxEwlD8233WuQ9VJxo2G9uPncE/XUEPk+Dzr8X1Y9FwrLWROHv195hh2hKxtODNoTgwe7lptOqkoWz7Tk3Aai6iZy6fqEsxs1aMHGW50M2Dq1FPW3tmHhgOr+48j3kXVxglmKW7OAfI+vknfQf41R93WVXzxnWhEDAdJv7yJQmAfRVZTSanLkp63rOsSPJgJ81fWEAoVce/VvTDI1UpPBlYkZhqZpPzgPC5Oq6YV8WHj1DGPq/2O81D48arN+4v891524GqJW/3q7rNv30LbltgvWi4v/r56lHKffsAJWnlJhpzRzTgh33bJdUrD3KIuC1F2Eb13pdmOaxrpCEyV/ycPqwpvS6DHdINVVnMGJ6KnklCNYVtGJM/2j4mrTB0kiUZep4ZsnmOD72za9HC+zdZLi3o8qO14uy5LMNetxFERzEP8AjOBnhO0QIwyDjstaHBGyaAf6OFsJ1YZvmE74yFB7/DTPe6+LGAAQnkA26XxAyA3y3LhkvWrYuB9zN8RJ1x+0llrhwSf2jhQXwauyhZGioElOES0Vvh8HjdFQHAp3l0qQ5zbNXL3Rxnrc3iJSGA2fSP+PfYouqgrKKjEyNPgapsWbKHNMdV9dEYu8B+dJK5zgSvPuL0rMQRZWi7F3fFZm5oYfA+zlqAAfYR74uPMwOe+HUNVvHYhhkpsji/JHG0F/eBc1LyYaeU97+4F1gmtIlQhyFHV4BMyYtJMeTXZHhRtdWzWLhjm7cbMGtYBexP9wuVHsL/PckYq0g1B+vC3DnH8caJvgRdOmb8B921XkNjHIYH5ffQTvubxilc60cKkR1LANG7LFNKbrSJPMJROrQDVE2hfmuiSDfa2UYoSdTSyyke1F14wF+TxOspoyiReY9JQo94U/vtg1F8cSHF/6PYnKOuxSF08cA4BqeAZfR5NFnhAOF5BZyfc5aUJi1iLg63/YfAoiIJ/4FNcW9TE3Xz4R3lu+pgUXQEnf9sEpbrMDBZ9ncmKgLEA4j6PE1Bvof1dQheMRZ/oBMEyfVrNNvIWzK3yQc6ZGgmktQpr9OqU9IIvJmbs0GTLsySKAp8SluqNrB8Xev+sVpF6sAjJuQ53kp8dIHd0n0Grg1uYB05B1zImUbK8TsCGY7BM6T+ZB9mdsUguaxCmpeZwlPCxdIGSD2Ox1aSSyq7GIFT0NLWLJITNdxWqJQybamyXPvGCx5Bob7wzgRICB9vuvxX6NzQ2w+sBdvbVjruNa52m3HR1IIjHNkeiY6AR4OFo+IiNw+74rKkVgCVWMVzjBtXKSUuPvttEbTQqO2BrIcnXj8kTh8FSt+v/ER+ldN3H5bth6urbau7Z25KvvYTNVBLqAjTOnQKr8Z/6eKzIpyZOlPTqbQf1jgchHAsXJTFGmc3lqyF8iq88iHS3iEms8uRiSrbQHqq14ohvaX3Ji5Pm60mE45ZE+2Ubr2PhAcQs1lnLkbQtdB7BhW4++Yf7vLjvc3vcWkGv8jhHwnedmSZ3oO703IgHVTYgWmTHS1EI2jWpZR1ySMkPQUxS9nyh2hY/xaH0q57Ftp2cAhoRvAD5ClVkRpnu+wCs2OltfErFK3czIADaOsgp2OIMU7j1Nk8JkY8fKRLRiJ2U2lJqUuhvD0vYEtzPQJdFzz1NgSYxFHZx8nxd/2o8OvdqiCyn1FXsDnK21bpDAYhYTXqdijbUE5RqrPIV+DJf7v/IlCGFpXkD7JX/BZ7sdiMBHz8ehDHkbWxIWjJZD7eXj7Sp5nsZ+w2B4yMecdmPqPZ9OHcVM4idatI6toYIhy7QWOyPr6dr7/BpLuOtMw8wMv26i8I6aVMbJwJSP6+OH6B9ac+BRilWT9pOkT5K7vn6Fn0ujxTT8OdlZHE4XiavYOfIh21Yd3wJ7rja1WhLGhGeomE6oJZFhyxkDAW+q5JIb1n8W85x1E9pDpAnkoZM45904kulUALdl+qEElUwMEh0Sz0Nl+qreLYqnzfGKXnK0jsAKPBYpg/dfXPa/Xm3JY+eyd/ZyWpG2xmzKOyKUFYQOc9pkrLtHJsZ5ESkzTKFvZlwNSsOZ2KwtBVgsTS1m6SEqZ1URocbyR2dZPF1Uje4HoguGAejsIc2YZUFvSrzK352+bIViADSzbOvVXBtT6AkxV9MjvgzxyoZ06Z9S3apJkppWKZ5LbO765U25asCkzsXmFWlVxq10fwXUC8I6dohsz/Rl7nrO+W3Fxnl8vGdb6+uGZDIf9A/qUfK8J1f4B0Dpjpn7awxpa3LJgV7Vfic8nAm/585r0LHO4AME/Nleqh53EyXdp5v7GWHTFA3KHu8zyqVeS1Uu2ezkDFyRYDNgmhdXp/KFpRZwHylPhdq6S+xG5auUpsiZPMFGttqh2UTZIUI3EaVAUml2mzAAgmCqYrsbL7f7QzvOFCMzv+jDsklasqzMf2ChKvwv+parqMT6exSz9SeiqDXdrieExK+RpHupmAl3wF3wrL0Y1vugnKTUSBjnSIAjJCEb2wOynWkCDBZ/Cmz2rBud7ftA0O3XQkJwTBveXLcbA4kXCCXO9hT1ivQhQk7kzFxzav1xq7WVJf3DvZqTxZ8rY7HXFPg5vzJbi7IOmkXgPsfiYza5+uew24xbV5GUk5f/Dlu8T3SjLSillnSNFoPbWNvlObsftntYtorw3A9l58beYghtDBpEA0FWjZnYJbiT+LV/kghIwW1UKWb5mo3UO2jdosN+di3sFS1tfiVU46H3rJVyN7CRsvFtMqYkzirVkgIaFgYA3M3vBAgKBAu/LBaq24KrYcKvM1ciVpLMGPPX9vZ3HIjWXtr3dvoH/zNqP5ivo/5gmwMzlx42URSEgpIfdmxDN1TCqCXFcRLo+LeaeD3T7WCfxeJVye3pSZ+IwIKNUU5d0XSuSLaIoO6zUbHg5FbGZ03V1bx58+Ar5P6DVcrF852NEpgTnJCrK1qrXizl3NN0PWP65tu02piJc1isqAlmN0jYFHh58hkMk88xwyqFaRasA3/LU0ZfKHcIcfCkrAdmGzre2V6Xlb9OlRD4S83PorAoGvcenI6tOcuGpJ/oSmx8BFu7Us7rARScfJ0b/Q1UqJfzjZeYw13BkouecNccSG/Iddp62+A1vMDOQbMEkw4ih5fXvg0hoXR+frDhDWdyddpZnZwpgDQM5oBphiUIVgErbLbHICIUQcJANuBzylo5yDntwIJDQEl6wfzeXbyKHVXozmFPFt9LXkPpw7EA5nik6qD/QTLYdgLaV1AbiQ+iZZSoM8HyRYB6m2W83kxUhpWfZ5MQTBb9fI5zHDp+5f12QNt5pJm5YamC7+2yxT9UEFtSpJKKsr4ATwVlKlh0tmeNS6lHn9GNKsAaA3A12KNFsJzRn2QHFy5miPyfNnHO3MchGQj7OjLf66iCwRApxI2h5QX8kNVwzSHNAyZKIO4LxKm00Crb+n3Ap+3+UxPY0riHjmGesXnKt57/0ZTxCrzSrqWsg+MegC1kECfZFeAu8ItC2KfiUWq/UPSmlz6B1GTRYXi9Y1kRgoi+cP+E+rUCwplgrNCKtjHeifAoj1xc+h+/uKdRVHOluYStSY4XS1x/YMpyAXEe/+I3I/jPl/fakAMhmCgI7GzNCSRhnU3ffUDl7xXN/ZDnMOh9RCW5HnIzUSWFJTFSMaPqVXuHVLqEHS/xJ9/7LaynDKZonwZ7fuQnheXDuErvAco496bFK6YBwCR4Gi1WcWpj/2askb3Bw+fkRHbnSSBhqvk/gkJz7v/MaR5f4DcWo4VS4GV0fsgS7QSogBTXFpxp69bwHfBdPPYpT0fJw4/sA7YEpxS6DL6bcXKpy9F5173JVJMwJe+Bs4lrDDLVwFEC6YggQmHrtXjjffUNSWhmzGS9sgBY8x873+DcBFbY0htQSMmcvOGDQSFKBpNMSUbcCdSCTQqMtahDFK+tqaPJkfPqKTxvyyQMP8skJl98RG6FnG02L5m5JDqR23AwghHC/6Vaomwl/1Kaw7CU77JfY9SeBhXBlSUymVzmctN4aqDNvRVLMwqn0PO5bYOgkyqI7PjImL90KY7u64CpfW/oZYHTHlqPvf1z0idcUZ0zUynqNWnyT6mMbiQwn9P2exGFiZTtgreFyaGZisKx56MU+q7R54og4S/ZwJFFz1abX+c9iJLdGlM1aImdU8DQMDXdB2eKWz48m8OujxIc2vNAXrL62AXjgXg2VEvZIy/pdb9DZnlZJMQjDK96HH4RFwgDiHEDamKMh8RZywVbHFEWhv/tj60q61ZeDjDi/onQojGfKmzXJyfLHun2wiS4Fv0Mn+9MwXtU0pMxzoSA4CDSHUi0DSZSswYu1yuWt6g1hLfLvEfApnGCF7+Gju84+1as4upOuS04ZOHnUyOkfySCJHB3XXLwELO3OgBhCPCQ4Bp5AsmTU58tmhYQw+olOraLOVOqmxnVW1wdeMUt8sUKPx2BCMczH7MhDD5Ojq7F8fIvqkGEDMjsj3nN5s79rS7EYQp8hQvAqexsN3ct/RgnolswyOvPQ7Vu167Y9sIl6NAhvl//vmZQAavTsAoWSMvaH+H/4yozSIHqI4tN5gHdJ3Efo8mDzvgU7YGE0wsyEPFITD71msYqnHdZbP6xtK9kQgVYn1gupbhJHt4r6mw0A/yewXdvSNhYoQWt1wGomInLlK5ZhkhSGztEpaQtZ9FbrYy/o7Bt8fcg8lngvySNLUMm/TdwopZ5WCXnNf+G+SRtC4A2cvIHPc4MJn83O38XnWLSWX8Zv0tYmfaorUSjZor0FGyIizSXve20wWI9j42s90P80gNmUyJN+K7gG5zqp4yprVg1G3vjBMSiEHzoF+MoFSDC8/aQV5jHbm5BBElw11mHui8vysIRT3Tg6/EiajHlnd5jydMBVyIYp9OE9Odzt7V2E4OUmE+kPhN1/ZLhG7t5bzl1VZ0bVDCXZSILHOyv4y9YLPFBNzLC7ixBHGmClGchVVIyODT/ZxA755oFuYHKv51sOaJi+VX+PdYpa5nlTmr+gGBXRmyr2ZKxTucoxWbndv8MODouE5dkb9rFIOaDxikRQWZIETbdmCaWITOrzcZbKoZbMPrb0Cmr5JiDrcJCiAWHRQ2CZLVjcndivCR268jK86kAAnsWQKu4Htx+t01/zR4ROO4wOILqP/Xqx1Y77Fn0sjjZglk9lnHI4gh5kywekqHc6PBq+ZBEJX7WRifmN6gumUi3YZoGZO1MWEY0UwywzhaARpYFPgsxbtlgh4kjb4SoaZIXrmBQe7ATrUpNTIUUsLsLLQ6owQaTs6ioYIHSwi6aZEZ3Qr/WRiRSD5X/oqGAT2BGZKO7p4Jv40DJBChuik0kwfgvT3hjRxMTSfhl9nUucBuKN5n8bkeVomPeS/Lx5K622N/guqpBYJtvquO0a8cqTv3v41qjtuHe08tseXazylOgL1rKk2V9tYKZjxpvBObTTrq8l6R2RvOnMz26rk0OwFb6VePEmSuWoMl3GVSugk1gxaRP3BrI+HxstCAHadNd6ekUOHgc3yxnII6OFlTRvLd4bcQiMvPRwsti+xjvgghHepnDB5TczOYVNfL7dxZakfq40Fa1C97gHuyNukvc7/yATVXJQKCaXDJwm/LbN7ZWwE9ubBI9yKtvqp2JYR3a8kmmhSxOte/VhV9y1QBgZEN9y/gpjoytfF7tuYzuri7d2R8ANGwNRYp9GEXS3jlKJRukZGY5pkoA5i2iiABWGEix7IYBRnLD5o7QKO8VSAWd1pCu2F8LayrZzeC7T0jnq5THt8KL3qI734aA4q20ZxfnX99eq5PPK4eiRWpHur4uv5B6tmNYqxyILW3HJBCPfeSYeqDrQbtMckwTTd9PwKYklmavD/6xj2RvEhT40ierfMtjpWVsFnnJu9pt3ghVzK5BFhi2znjcTKgGM26QFvpIEKoAd8bLPEE5VfQnUg7o6UlC73M+XygTlC1g2CPMSUhN9zsXoJvV33+JPENU12elxRloPQz8YjilII+j5zefZoL5Dr8ZZp7kjb/1hQrhRpkrGsz0KqxLAe9L1iQExDzUIvwUrChGbenKm9zPVDIYIEUv3OqyWpdx90NyHi5SbwM/29pCHJCCaR7ur48P9EjOfoBlTf7Ahmo97RYRLCus8pcjCn673/mETCUwTxNWMIgd/hq709ryTGVw40XDrvcZLlGUxnGv5fpXGQH/XVkGorVmgNHrSQQqFM84aWs80g4Ki/9PtLb4pWepgRIzTYbU6g1kvqilZUYNLPueO4UPZGxPP6DMfWq7ugaSa0JE/yGwHpKcUQrETlpF3HM8ScEnkBGqzYm/Q2pRXl/br7zEjUY3H7tYLmBYFdnfjhNLLaTfQ1WtxLxZAoxFzni1sFxnm1ryXKk8mWtqVyMR/seZqD3AbEC75pf2Hkgx2PRFopVOt5SHapKuspMrkDjoHkXN5BPDBBNOLCZ2mvsC/lyV7PYyu+stdNcEF3FNulG/M4FbDke7EpMlr6yKhdgSt+tACsbg4QvuMGvZwWQHFABbSxcmd8yX7ZzP1DvA1gdEP7G/Lj8l3F3ZVUmxc6SA4EsR6dkZg6lenoLClq0p6k6nsseZy+P0gyg6714IEYC3BivC1H0OTmZY0A4iT6mqE74odvITzIja5jHmSN9/QyIlJnEr/5vq0qsZG4bWDsjOuwdokcZ5v/+w6pkNjcSKP7zos9s5/bISDMzrEre2lmNNdynEyXY/JfnqCg8CRC7692ORYqkvrVODNebb5q7B3P/rfbYv4gXkq81EO2V4j3xQSMMsncOE/Cn1cZZ0oP4zOa/HQs5acu1f+pIIYAXiRjr8TiYaYIBB7pbmx6fpV6Wi1kdvmDE0CMUIcR3yFttyiouQ7R2jj3kvGuoOhpU7/ejI3olmtEuMgqbMp5IZWhpMG2Pcqo/n3M0hmwpB23ctKQdt/xZGNCLAMrKGUvVan5++8wvFzkXj+dKjTGKR/aVjxNVRmucmUS+t+0ZbJnuOQJqv9lRrJND8LSo6gGLjPNCORtWy3u0WYZBOuDMVFcLecLEzIPw/4hSQRIEVaVyOl46qYmS46tAfsbRT8H+fFNE6irG2JJwUPzkEUIekvvpPx6RfU3D/CGD3HEr7jebBbpsvvKfVveWoNHSe9x0OfUZ76VhoQQQuBPAKEQyk1KvLzKgGY3TGyn0f6Pyt9I6PF+luf12TqmDHQ0otWVq4rA6C1zstNU7H4XLD0o96GFPZ4TDWDoDNk+1NVDNJ2AVQOsgAf7EiqoKIH0Raj4gytkf2IapWad6ouPUZdseQOIb116DfKqsdu1yktUFl1y8exdkzkWFvLxHhpAeXLwqf+MC9sbt3ukc1Xfk+uUGkxLAPLQ1LkN1UlC5vpyBSOSXkSW8WwG2Rf8pJBB890zjoSUDPT7sMqywrvkmDqoS7oQDCr/Olpmd7rUkPdNyCvmlM9mgMiAVjC4AIG5qZEZJ29j85mZZwQXU58uXsgrKUy4FxytgT3BtbAzscm7QMTmnbM0b7pe52ov+jtN7pNiIaDyUsUPHjjLQJLUxBjmRjFhgjcDepjqsZ4JmDUOueXWmOhRWv00KTdmqCEjguG/8eSTfO8tKjZ/ynAaEBEmRYmjV0l0OzoJ94ugi4u6AwoB1D+XvCa6Jk7lDWLDKsApSGwB8Jz5aJHrlAt0z05yUn3NU193B+JP/6xhme/11U6zBDxFgVjGQIsyiFNgDjxxoZujAtmr+QPWOPDYMccD22ADxoAbjQDcgeZGJd5SEZIujU9uEZYQc59fT2Fc8y3LigbKx4+yc0mMV6HN4ba7Xl2Sni0YZ4nru/oNkbGok/iLVjmZk2aMLQhQJwWQ8QKx6E6b9Kq2S9C5yL0p4OUpYThTvcWjOiK6hTPjex3zkZPCLHFOOBMtMPVOYMe1PHaif475YvpbKqQSzuZ97yuO5Oo1aMLa7OGCbX8ahdeY2Dni0HXMJfxYCzqOw4CRGpFsLTfuoSWHpLpqv9v6eAb2GFYmmQJHqhMWi1Zj12n15Ar+MMZh7qgut33xsRFyhpfuBAEmnIzIOicQFJ4421d5OIa+ANmtZgG12uS8xPUQHUdoBxMLOQPMTnsyxVMQ3fKF5RFudIXtVCEUc1qAemUM9fEToBW2dIr/juVNeHnACNLiHwBdcX1FhPyn7P7tzMIHQ8oufx9kFa4AM+AR+Szsb9YKsdZIg2Gnv1YWUXT0+jrZSMiANZhjO7WAw1f+Sk/sIyX1d7oaMv25+axX7JnX1VT0JDdSvk7zKWIRc6pWnY5jG+FgFGMgnfMgm0uoPzCZUvqEe7eVvftWE0dWwy2u5TPG0GWBHkPVFIsc0DDGVrU6zYDqsG+1+IdcoEnmA0uhx7nJj805O+zzzEYIQ5itpOmQB1FPFIPLxvvq7b6TPPnad2Cd8lPKugwt2XTNKijZ2S3Y6acOemrcRCZ1zLCZokWUEmaRNjSicUCQe96h9HMNIrl0okOIEEK40Os+4mcMeu/Mnu0xbXxnPJ2+0vwSVEWE+APpZzjJNImWoG/lJrMz60wyWDNtCWN6aXQzbsvKLpy7euuPKXV/JdXFKyTPQHI9PPTXcbdOg1njvz4J4swpseKAFDPaA9IbJgpPY4bMP0mJWm9Zvew9O/AIxZo+/fec5F6s93USUqCBm8kAwnoPVMd1xWKk5UkRNxfOgVP4pJ1/EXFzqM2t5I9wVsSOzMQES7kGP2/lHLaQCsdtsQsz7VPbMD1NgqAs6PR6pej0uvg+K4DdIi2wqb2JnQJ3/7EYaFIqMK10rNLXKWJYgGfDLwtMMi7aUc1pY8zkzmoV6Yf6b3nC3eOFpzwzWwGbNHK1/OhukgbUOBTXaphMH6gUBGB8Gv9tKirgiOOCM+tY0MI/Hel4Vqymqc6NnOr83jghHt7Ichvy5OPNq9/lUS6rPaJKoaAFbEwugQ/yDK1PqVjwX0a8VFByfcbAXYV40FHQhw/kqYA9LrwQKdQ8Vd/cfu/ZMSRPobXWIPBV3UAKz7655vhknmSGB91SO6cFE9Wc9MBRL2QPlkQ7FSSAZD0ffVUKt8ksWZr8Yvs3GpDVK5tpV13wbv4Ta2IuqTFxkRqeQM4HejkLeRW7mxtMsMFLhVKxmmlvxtJG3+tOu+fgLqI7jSm4UsgRPLkJOlKEkn6nXNYaWyTYIt0U2X6hbR9HfFeluhSlpDdfL6aHxCbpOElTI5L0GMEKZgQXC34OL9a0R15KWeLT2UQjlPoQeV5y7C4AAXvmn+LA7erjzrAypIvRamxqwrR7huSJQ3pk2YJiRRZ+khzmzg511f26jCmexcjTBBP4R0XsTuyrl0POmrzEZhg6FCZIhtUZT+Mb383Hh/lmr1VeXUA58GAobHMCWmeG8xAiNKD01VDW385B5aVj7/F5VTUr2IOA+7LorpcFjcOdbkxi5a1EG3k3kqRJZjAm2t+L4lamoCNujQYPIfkjLkttIbj7hhcgWgdQGmBJRn08mnnOIeB9/SWOigtgTIFCJVz/KWF2aFTjjGWtf4/HCKTWFnzMo8GXiXuHyV8pN+5BCQ8TkxfiuQ1mNy3G/JXNmKzc9SFg0p8xSBkHlbEKOvNY8oNAPGlBl5txV2sN+djGpQIpzjR9YHacHMysSnbMCLIlgE4rf1iJVIpryMwoRxSEC7yBdE/+rlcAUFaLLjEXcTuPfOLI5TdV3zIEln69t0zROoylNKxBwzcYgBP4Kqj8sfKdL3UNNaKxv5zLO8cSrjySf1RNV8mnR6SIV1lRKmtDOyuI0ITwZMh9OVJsU9VJ5hrbfIYhGVWRs/RU3LwQ6oSW5I7T7B8hE9wJ5hSXqXNU0x+FOqiZ1swixUhtay6OxuD6pS47aU14Uml7D+dJsq4N3bAn1EWes4/NmPyrHefL4UhCJsMqHtMnQPoUMzcfrTdurQwdnoe2/1GZvS31r6YSIZRpIi+PdIS5nzR3OBD3L4uBrouFDd7Yui8du5zCOjt3TIwOeZo5PvmLUFbTVgRM1zLBC4qbvRMvwpoMBnfaQ0xNJnbsscQTCqf7x9/PvmFhms7spQYU6HKJFvFMEGp5tyj5nGc1m2jCNXTY/+07H3t7ijhf8PtU7UE3HsXq2l4ma7EVzs975nDI+JRP+N6q4RffZDTIr0eUDSmqCTdDMjVKLMBkg29UA71YoqrCtm1QwMRwyWYluHTzqoqYVkg71aToFJLIaCPRhLk88C/qOPwRhamJKLtWn22ZY8rdvYaQsvKmwpv/TLKf3O5FJJhAQTtcyJsojSe0hwY44CSG0O0O0uR+M6bFN7ZId6AWvVfcJDDZdSfAuAu3FWrQyeiBby9FVXEMnVFqEiZErcvIaE4pO6u7qLVdop48uOovfnNFN11Q9TEqrGbSoTEBRgYcyuMhw97X/kzOfXBb5dnengx0gxCOU0vXQBGP+tDLt+oPkFzPCEu3WbBxDcynTnXsYLDSg5VZtBDcE8FPKKdxLiqrIHr4yF7Gteigq0w7g7ALeYYx0cz2W1+4RCsx4Auh0ove4fJuEphWLKXhIFGf0S2HMxjJqn1NtFieQSb9yP6omm7naFT6a6paEp2+OzCjVDvcVK7B4+Z2mkJKYDIifqxoqIoyZq6vI+qV1Nml60+/MkI0X2e3yGM5jOUYNLzTqbPI+WJJDIK39oepU+gl/wB2C6B3uDPiMIwGv5I3mgOPMwzuB4ATN7EgemyRJ6uPNUOAnqMD9sJW/FYvMnjXgRZw+qyCMTVtn+8FkgB3NKupWJBNbmp87fX5i8l8tY6jesMtE6wJFY266QERNxDht/A0bTDzsT4bT3kpHFEn+hfQ36Jd0jWT6NcxUo/oWs73BcJFwkxbaHCAT3t/EKuW3vL68YlMqZQ0Hgq+/hzYl7jk0dl1hqgpFQ9EBdtH2n2GlbbwTLhqj0KEm1r07rxWDNRu54R0IoeENkUqp+lkvmLz7/YjAs28JPdlmkpfHJmwAAr/L/I1CIKP9BYcbtgRTfetwo7qzI55G5dN3vISzABitJkoAUXRVwtnj21uIb9bzA/lyX+jfFIJdfSyAST2K/TA9SpYsqnGn7/hj/VEWQ1AzAwc+nObHI3Z3gQrmpsC1zH70AjgoHHxS1oZdfb019MKKqHlz9AT7s4sIggaxXv1c6Sq4SRiCCJTdgAEgLLKAAdAbPdncDQe0TWS/WFzQmTAmG4AbTRWleNnc5+iGl7e8Xm26BJpIvDuj+psucaYfCSvpzJ5ee0enOxlI0HHGlyesiHFiPK1N5Iub0VFg/a5x1Et5tF0/OScuNn1xl8UCcHapJiz3WHDseVW2hyH6wj3EtrUSnuhDaiKu2p+UWbsaIRLzayYR2cBZcIcu+6iuDDXXeA5npHRPiqzxebAI9t1RkEd3E2RaymaSVY/ADgSdzSupM19RKplk9pRlITprEsgkUQ4REQnHa2Wdq18C+z4KDaJiKUNFHCqkW0QXqricFtR4g0ZGCaW/A30JDt2z3KK0CuwDOhR6KjNC12h5gKPY5Pjw1IsSKrYJshOHoIZyUuuwe16MQBpuXtZgNJsXdzmQWPfcdiKJo3HH5TylHkjVucoDa47PK7670To+Ak//cjdCTxZtHbnbptY0lMo2YiSU8UL626Z0caTUPUT81/jS/H1OImerzq0xhvt0G5wSyAiL5PSM720jBR+6a4t50JvJ8AqB43Yd09YhEQe8iR81o9mBFYud2b9S/ea5Y5ISKEmo9GPmfSD2rcC1pxkvHQ4WrJOu8tarVBo37c57/y2O/4oAnXsrsCxpyZ+x7QJx2iymwRZPB2E1kMWNb+wQyj/u6xxumU2EKo3DEs6GUC7tk7zw9v+yYWPIfkAZS+V4SU+e1NcoDL9Y4pK6DjUcxvUPQ0vTgnBAfF5yazlEeahvfcsaBXjQsPgxIyPAHS9zCMPFzAMEngIBeQxcI/06h3j88pWVRiKIqzipudJgMGMvGN0sAA9UEf96Vkf371G3gJqk3Nokcs1PVGYbtk398neZ9wqkFY/2czdMDT9dE1INNeg2M3YxYwyZK9DNe2emhE41D0wRStjD9NcwYIqw5rhfMLLxrrL7ZzpUpvLX0xvewKuG2/P0STAd36RmBCXeRaqKyiI1moB1+zk9hdL1k2MyzCEcSf9v0Pp5JinvH/erYDsDh27Dn26QvmuQtlGDGfs26XBFbtOI/Nf9q71YPxcqz/vX7+BiEXLc656OXpPH0+RmZj/4dSzHP930sCQKr4CWprRcH08iN1wQ5zdhE/HSk050c+lrjmVqU74xmnNsvyKKQqZOpkJAaoPLsnF92o7yYAGUJ0GDr9sKezXjTgGK7/Svf4Oo4imGvVn3zXNZSDSofxgkvprBslrIYUwfBJYJfEcjfBAzvQ46ap+d45bUfUpRYw3/mbtOmSbOvjMt5JyGEEAXuiHT/DyLuLhNp0yjURmkv+LWOaRiR2Pgsui6G5s4sKrEEUgfVJRJIuOWOjvLKvZpEOCrWdn+v8z1ecZ2d9cQJCz56+m5smSPEqVYop0+QBKoPq+pvuidPWhigWzrmoB4NGDXgqHDrS3Evfrjip11jcPe76X8cSJExn/30BA1pQwYJgI6cmVXWzTIsrwrm8tt/0/vAYOYprvwJ0+yfp3M2DxcSiu+ZF1ObrXE32xotYyvCAW/D5x3OTN9ZJZNPbOk5/QZ9k3kDU8bn+lUiYpluUYDb8ftMw4YSSZ+oU8P38p2Jl6D87wbtFDkDXNw1HMamF28vwj3xETFos38181cgsJPCXxvYk6m/GDmdTxns9zrCbM7vyJRzIiYATFD/qthDDh4lES23SgTvdwdS65YzhdCzxjmF/tSEt87TWYA7B+22cLEF67anqw/779r3EfmRzKfsQ3v7t8v6MNWzBc0r0OplAAUGAy4cv/Mq7et7XNoVzfH32ph0C5kKon8x4i+KxqUtkk7d9WwbeFA9EO2nO5rovDF/C7PU7EoXuVEFMV/ulSuG/dOn4a5boQYyEfhHMaSo3ltm9E0T1YhCVWV1zK93CYzc88p/sw2oLA3FDBk3M1ovBgcMS3sxkxNHyXJurPYb6ggJczX1swFFWg3U0BB5jNWv5e84uowBc82edcIHDXufE4UzUgtR3WCPUv0Xhwt4Ekf+L7UkOHucTR4MeUhg7dqKbRE7B1HrdpAIHqiocfWqFUqj3sJEtFVF8jT64JshdwbrZBg2SO9Xy0vvdA+3xDuFoFVwX08W1RZU7ddWH6b94btrZZst5/1twY0rSeZGeK9HQcqMlt7A6SL24Mx/z3/NaWQIwE1zDksXrO6q1S7ljISfZTR+2eAJCVA1VxdY2r3z56q8XNSfA1zGD3VzhOzzm/sD9EDQtw8ftwVmQxIUpiFKGp5iTmE4f0OC+7STuV9FM9cExQ4PaWnhcTskjF5LD/tEooDyfAnGdV5TSwkoKVW7JK6ca4PjU+xyjS97YHmbQei8VO35MMhJ0UTGcDAx5ParjGx9Lz7z3NWU0zH66TzGzwAvsgjF7rCDa6iJFa6tkXNiN2XVuBXPIhFHs/B267xJPNZ9rTBZgOyruF2iMTPKv2OA6jnAa0WduwwnCzDlACzNXE0qY9ogiS4EJLEt/QvCjnXQSLAZs0gst/oArF+KSY1QQSUgnRn7En8B9ZvbZFw+r2UiOwsae9rkHdn5xV01xaaD+7PEmcFmSR+z70xATxwUdp3ovzlicaT2lKMoR14bKrW72T9Rp1HRC2K6Bvmx7uCREEcvzgEubGEORVyegmIfKnJyZzolN3onMyBtfMxeIVoBq9ba2cHcpL/rlijkqiIjHZZM99eAnnBaFOKQqOV/taTyFKrKdpBtjTNMDD/DmVV9Zn0dJdYJH+8wfuZM4zPOI3zDfGwV9pLwG4QA5JHi+ipiTNI/Zan8IIN06rRNuJ+Zem8Y1/J+gMNa2QnqQ0Wd674LdAnzBUl/oSCBlwMJQH4bL+U0DhP78jtEcsWk0AbbYC0LTOPP0pWVBNWi2lPPPooveOG+Jg/rcIyww54VHPQEiEZ2sL0k8UBdM5OGqai/U8ls6MVvl2DcPBTqluutdHkOGW4gSBBa90ZjEHb24+vzfDd4Kq9auccCT4FuACywQsJ7F2yxD0o5jclwd0qjyNFBU+Hp7eL96a6ZVHqKVioC9ap6j9FrRl1Ns+ad69LKHDEz6UzYiJCM2ZGFUTODEdbjl901uSJJz6235hEBtkLyoCRHI7bnpw61igN98F3+CyGJt2vDAaTncX9UFhpWq6kaNvdkrmxjhpIiJhRPUiIr8zngQCqlvi0KoZz1ifhnYai9hkwZLGbTR75psdkjqgMFGS4bgN35jpnGTFi5Pcc2Bb9sv38GpVk/3evO3tTIphmld+rNd1w3S9rKB6ZSHylgjbpLlvtbhRYW/EqoIukv5o2IgkcZBUIVcqwcza6FeDunMst+75AV2teC++5PKeSygYtjmZQq9anWgierj6Pi6VqXhenjFGjRbU50uSsCxlhosYCZIuKoew/71kmK2fFlhNPpw/8YILzHQInCpaDV7mi0A2LWrHamFA/JsSYXRiYlKXbCuP13gDlrnJvD2gQAbq/4gHo5TH/iCIIrol/2uuInI1aluco/jFa4ImTh7Bkr08I7o9QvFgMDpSAhImbS3McdrOFZy/oVwgldSuYXKWFmVVdrmPbDXfav0T1P1rZqW6hrjBP6R+cqoBlWOjuEQ8Y5sXwRKrbRhW6aR7dZ4pf4hkneGJ9AjBUABJyxYVGvBmWjsK4aot6Xlolkbx9fsuxA/RA13J/jk2pdt8Y8sPH57cSdVd665K+Jj1NM3NTtNWS1iWL0D/DNPc9WaJR5rgj4NWqnGZEfpZ9t965fYuEquUv8vUNZee7gs0/qCbImaAra8QWqg9ywSWqFq7BXSPNgFfUZ+ybgkk8fcz4Lpw6lf4okRJZY/cwQPE7BO1kZ+6FMV5PR50/UQwVgvykl1kwniBdmwKDeeMJCstLJYRQAD3RByAFIma/diH8hL9EN2irWflmHKYeCzNURYqPck7OetTm68KpViC7jMGQ6L8TwswAffyfyoulucwfOitkJN2AMW/VJuuR1tQ69kQDoDd+hV2po9CHy5Vx0V46YRkt8dcxFRgSe3JhKqzLv1MTjV/9ACKxdNFHsnk8HzO7R/LM4mFr9gLKFFIqYQq3xrL/Bj73dZHWrVszoLd0ztNz5DXdbm2Bvci6RhZqwLRa4cIHWwZIeOpqYr2g6DsvVf1BhU7iGsXJGajluohl1/MqYvDmDW59g9nkhEccVFDey17OD15bqNsRZvLdkOlK2acHjbk4JurQA+WXCVMM9ehBgz/RZMVDwh2Sbqwg7gbZdGIgi+vDEz8DUNGBE0EmgjDU6GDn8d8nZqab+lQsajtXD7BswytOGUrvoPkH110CYE39NJuNt+QaHGf/UF9byxFzakUlVICXA91o2aPnwc3hp/NHzB8VZF7hFmtus15wZ3GURaDX0nt0gItDgURdo2spLHR3dTOIWybc6w0hGlBmpyNmXAW7LJrjqpgTAEuM63e+Nf/7UJAuDHwQiDzEEwJpNy9DN3Xb2mEX8W0h3M3ta4+U3S5lb2eB3cJmcR9p1M33M2TUsOqwuqRPq4nloJ7HZUB9FdGtekkQOAmxBMeX1r30rQTQ3a6qTSWg8Y9Xvis3W/iTU23gXfinQJoD34GIMQmvxEmKA0g6AXMhktbPFiWqDR/FcVKe7E9L8lZw+Pgz9Mn7puGLVAXMImq/123NIFh/FPzZU9ZnMiyFWE35ZAdfW4ZIpZ1EEwv6axxqyQivGlfRBcmND+cV2zloBq1QgMG/IWik05pu1ZwCJ0QKlHxuyLCk0Q+pR1QWxLxXJpG/b9W3iPOln3Yo7pOBRGyUrhqxrB/YImxtB4I11WJmE4ZBZVbJinxwvApiBZBT70MV2zMJI8bLCFWygq+J2ElU2zjy0EYYucaZOQ3wHLlVARTZZnMzBMMsHG/P4V6bsJMq0E12jgupKtNf1FO7FkD3qYkP3e0f03BC6ZDqBYgKWm3ImrJYEn3i100iq7QCw4mGohSPNq90olbwjOImc18EjzK/Tzith0Gn/wsgXcGL6evvo48TPAZxaqzJeC15UFidDxBwOqSbGAm4rnb8zoNflGgbHpxiNFV93GfUS8CzoVtW0Frf07gxkFpPBnmXnIisliCJFRlF1bG5anQ09oKXxcssaX7iKABxyJdXeO9bxjsl7i4NWVbCQCp1t/zZf78LAWLqOOjrr/bHATUsHkuty150sAjRlbJ44gy7nyV+ZNNhBLugMM645qQWz9dEZO6XeF/vRaZNvlhUdgi3LB5hLJFHyejL4qpXZp1gD8Xu0snSB3bP0Ga4BYDejoByfiYoUYXm4xm6dL6X5tHPr0T4AM82jA437SfpD2+B5Ed/wbMcCVbTq2Vgv8Lx+e6eMqy8aAAjl9crAu+ofDudoSeHkjemPK9WukXHa3YVAGdaZfq5LK1d+YOenbos+jeWZVAROncE1uDJ5FPF2d1p2wmYUbCoVZuf6EgNZf9WW47JlE6VlbmH24bt9NnCoYsKrpSOEPjPrKlvzqNYNxTKmDemABvOFf1d9eq1UDq+GvRHsy4h0W1jlJMgj+4r3r4K9V4Byfu8m1PzJpS9POXsZnZv4bAQnQBtdlUFh2o++9tTIgIGsvID2SKETzR2QH7WzNHV7ZLw3eW7XJebvVEAXthf2Nff9FjABK7ZMU2n0x1TSOn80I1/oW6inaT9zBvi9VWQHP0dtoWsOlKqfS4SaOONQlyKfuIkjZuX3ZiugRrpiOBWHUtWELap2ya1QRdsraeCba3vap9tjtpUF/1pVucT7DbmvRskQKOrs1ZE8pwWXA+bmrT50Q5r0+uTWH1y6HnWwzH1Foq6ppKxmlmUQLx83AH9iJEND0qsH3HueksG08K1kOQx2k1+8hfINoMrjhd6w2c1SD1uEh2SI7tyyaIBnDc36cTk38bhogsqtPSYVP7KHb3xSX5p97oXChUR7La2ioPcaayVYtxASre/U6AuUbLF71a8f0p/GQCDYiLfKgAkvdTJ29e4qKU7X6aSm0767FLvpTXdohEJDy9xpBrkqSkM0mfzZ6DaZw793WRRhJc4UNexkjbke9DEuG901/d3IToOYNB9w3X+HST7A4mlOj1YLNV5sQN7Y9ONz18Hf8AEVBKeacP27xrEFmAGO2VBzLu51Xq2wEmeom/sRY91gaZfsZ/odxj6gjGlcunenkxMMbR7EQ6zL4ibBW6KeDZ7Hb71uNX0kUYHjpvzI3Q2rKI5efb6ypo/1obCXSYt41DusAaV6AwOYmWrY/EGW/TUwxO6/VITuEuijQeon7/C9dNI85hVHt1rEYy/WOZEO0jotd+E0LjoPTnRjmzhIf1LTPY3TdjwgDmZ0HXX4JyRnYJpE7d8RWBpM0U0SbruoJmqu7APljM3QiKbRyFWdD2LxsjIf1FQi3kpIiXam4Zbjqoh6NRPW8a+KU6S7rk8GS09XsOTYgeJXwwfjXa3g5MkJU022We9msEFj5niq0Fqi7kB+euz+RHDCccmALwrcJuh1tXmZr6aeVtK5rIkArzHmZTbh7y6HX3xJldLdHzw2ZrgBJ5dIfPDvVw1tIR5Kgf3FdMKSqGlmrVfvlIpN/tft/GxzMDSD2p+rR13VqYNVCLPXhWxprw9EFwvaxVtPqfTbpF1VPtmTOLCRcGQUXLWCu2JY3avQbxU297o67CjKKACqdxtcghH9n6UowjrDtRqgwDOSuQawPfzgF/1Fhn4k4sDx819vay29eS9K3ptaH1fxS60gNjdcJA0flGSv+oJORNr78qseY616Wlz9QtYqK7bU53kWJH6q/3Ct48DFxodxtFQQOGT7dJnezFB2TbR2YkRmnZlcy6wMrHm08AfKgqomJuqqjyp3isCM6XZHBD4rw7as2q2CGuimxd6TItD6HV0jHttjCesPDPgp9eJzjtP+81XmBAUXmZIf2igWfxl3zKPnq3rw5D8peQZ9yrvHsuyF9SHj52dYBFp+62z/1HG8fUHmBK5KVZs68xHwioBxWQSpmYAwBYECOJb8ksmOxvqRJ9YBNFzchDSERoqVWB547koid1URhqARei8OyagqfCACqo+H3hYYZBf4regfGLHxG12lJjDuGwDCeIi3/OyaioShkkFG/fYliJg/IUBMiUu0ELi5hhPTvypUZ7oaeFpgbwH89wCoPmdA9TlQXfktsidTcNLJ/5JZ4/NF5ujfz9tdOPT/fdZ1RgWcp0m4yywNrFwjuS+Tk7DQ8gLTL+mLiDFaBh3uaWF4otBDrm1iI1mtnfZTfquFVFjUSwCmuzcIlBwcCOs42uwHJKziurpF4T2fml/Ycd0aTge08sqXCH+GhJywBQ3ULieDYGXaaJuD8MWs6x2nBaCDPJwNrbBybWgJlcRJnMsQRQcJcI1pHJWgru6HekgXgMni66voC1ybVomXouufnqd7hmQC2eKbkXEdrk2Nr5QK+EEskb/vruwH1/SuKV22u98Z8EpsnbOCd3D+jIzgq5g2BZoKC0uktGD99tpvMRdwpdza282t8sDi4eDoHyxWb6Ogbua5AgY0KE54uM5t5G3y5FbfI6+32Q35IgWi5fZf2xOYi/knVx5lWCRmfVoF4iRapLWGsp2bBG9H7tjq3qkGaKKF58NpEiEygXExU7Wzsza3tGcQOg3b9GaxxKukBIb4lJ8NmlyGKhduX0pvMWGrZQpXR+aLW1O8pVMkbNQDzMfaIunHDIVqeyY/TCGG/93kgVlBsXD5x77yY0juSkByXuqzvk4T3uV5wXJ7BwdC7wU9Z9YMBbH6ucdgvXi29fusOPgvhpg7VWaMl0s1q+gFg9XLE3K/yUKj/TtVxyqhMk/8jSRVy608ow0n7tg0XonSxwdL/M6cGVJqJpwRYEz1MqOXIn6OnIAfrx6DwWn3uaIt7AR1WX1DRk6JEsCW+NNrnPljRX0ODkaOWIjMLjKEZBkZrcgoTayzgR2tb5GN6h3tX+28YCU+iWlEh/6ofbB1FUDhU86nKzRvshbwCWguuTUEgjKkVZLd7VFvqrEnOpCaT+qTW4ypzzGJs+e3SmmnKcS0k8ZvKK3jeuuQAmqGhBeHzPzmitKdm7Nhi+/ArSMOPFuiJj5rEAEa1y4OpEJMp6yM82WET8IHsaSDXu3th03bImlmupQdxoZ0A9fpAsYdCfqOyOgJkLsVl/oZN0qKWCFfWYeFRt2WN4AmptVAaLePXmqwuCx3+PezE52t7xsOWyMX6F1DjPLWybWLsiOZxJJUrQeT9YLCSoZa7oHiOFTEM3v1nYmr8qa5wl3GRG/QqRhg7ydVh+EWviZfMCzz1Z4TM03e3zfLxKdLsOq4xGtciL+GzB+xRKUCivO1ZgEEz2JUpbSXxS1V/opv9NkJ9kbnElq0Ht/1zv0rM5LeWhvDNdiNiOCHDQTpjX8dz69HrQWAWo/knbUV2cX4dxWvrHSUqRzidNY/Y2maBsVgY/EQQAlJbubI4Sk6groDI7xO37o0pWqW11UvGN9rEHYnqubfsru0sWMD7GVLPLTkOCEghLIaORRIIxjCBluN6/H/LdaA17754RssM+captR213HPBjMqHgdxAYjc/SCDD1dBNZtCCTHDLwCp4wgRAlGzOVu+rumGWYiVrb3RcqIVX03hRggZMaVXV+rVHjZWVJHRUGbPPSNkBuJ2RxNdEB2/X8wvDq55dBU2N3iwIUShZTF8sLNJG26y+HzneDmFMWb06Uyz8Vb2L7P57YN7w+IOr5xtmB/3ooOEPw85syWXbIFjwiqJZ29u6lqT7BYKUDuR5y6PNwl3b2QZDkDD4c6QAH4WR0JH3e82XseIUvTHw5OY13o+EK7FU+hUrXB0JYGHhEIA8PPE+Lm5NZuKXbqBf0b8j30Qk+xs5+jRqm0g/YxlXF8j2xDVbeXjJwjGc/SXHL4sShM2hw+9NAtMIvilrLQCdwq/QTGqSkik0RKDyts/47D7WUk75CbwTDivfyd2YmzDVLqbr2xkWtbw8bWcKk64IKaFv+kGkL0rp/1uSSRp8LZTh3cMRpuUSKa954Qupi+HbyGCiL+VPGKPjcJGoxWRhO2TAmrRAJv2Bx/lSUW5i9eaPhPBgFU</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>谈看论文和记笔记</title>
      <link href="/2019/02/23/%E8%B0%88%E7%9C%8B%E8%AE%BA%E6%96%87%E5%92%8C%E8%AE%B0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/02/23/%E8%B0%88%E7%9C%8B%E8%AE%BA%E6%96%87%E5%92%8C%E8%AE%B0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本篇纯属个人体会之谈。</p><h3 id="如何看论文"><a href="#如何看论文" class="headerlink" title="如何看论文"></a>如何看论文</h3><p>这几天看了些论文，遂总结一下看论文的方法。我尝试了很多方法之后觉得下面这种方式比较合适：<br><strong>找论文</strong><br>找论文一般的的途径就是找综述文章，找博客总结类的文章，里头一般就按时间顺序排好列出若干重要的论文，打好基础后专门去看与(🌧️这个表情还蛮可爱)问题相关的文章。<br><strong>看文章</strong></p><ul><li>下载文章后，网上找翻译，对照着翻译大致通读一遍文章</li><li>通读完文章之后，上网找对该文章总结的博客，越多越好</li><li>结合自己的认识，参考博客总结一下文章内容，尝试复述</li></ul><h3 id="如何总结文章"><a href="#如何总结文章" class="headerlink" title="如何总结文章"></a>如何总结文章</h3><p>上次看到一个博客里头关于文章的总结结构十分的好，值得借鉴一下：</p><ol><li>这个网络是用来干什么用的，有什么好的特点, <strong>网络的背景及作用</strong></li><li>然后直接搬出代码，讲这个网络的网络结构，简直一目了然，<strong>网络结构</strong></li><li>讲一下结构中特殊的部分，以及好处，<strong>网络的亮点</strong></li><li>第三部分讲损失函数，这个也很精彩，因为一个网络知道他的网络结构和损失函数就了解的差不多了，<strong>损失函数</strong></li><li>第四部分讲测试的输入输出，讲清楚就知道怎么用的，<strong>网络输入与输出</strong></li><li>最后做了一下总结，清晰易懂 ，<strong>总结</strong></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN系列论文</title>
      <link href="/2019/02/23/GAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87/"/>
      <url>/2019/02/23/GAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h3 id="GAN系列论文"><a href="#GAN系列论文" class="headerlink" title="GAN系列论文"></a>GAN系列论文</h3><h3 id="Generative-Adversarial-Networks-GAN"><a href="#Generative-Adversarial-Networks-GAN" class="headerlink" title="Generative Adversarial Networks(GAN)"></a>Generative Adversarial Networks(GAN)</h3><blockquote><p>Generative Adversarial Networks<br>submit time: 2014<br><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>生成对抗网络中含有两个模型（均由多层感知机实现）：</p><ul><li>生成模型G：用来将<strong>随机样本映射到真实数据分布</strong></li><li>判别模型D用来<strong>估计样本来自真实样本的概率</strong></li></ul><p>G的训练目标是最大化D产生错误的概率，D训练的目标是最大化真实样本的判别概率。相当于一个极小化极大的双方博弈过程。<br><img src="/images/resume/gan.jpg" alt=""><br>以上是模型的结构图，生成器的输入一个随机分布的数据，判别器输入的是真实样本和生成的数据，做一个二分类，最后通过一个sigmoid函数输出样本的概率。</p><p>训练D来最大化分配正确标签的概率即$\log(D(x))$.我们同时训练G来最小化$\log(1−D(G(z)))$。换句话说，D和G的训练是关于值函数$V(G,D)$的极小化极大的二人博弈问题：<br>$$<br>\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x)]+E_{z∼pz(z)}[log(1−D(G(z)))].<br>$$</p><ul><li>$Pdata(x)$：真实数据的分布；<br>$x$：真实数据；<br>$P(Z)$：生成数据的分布；<br>$Z$：生成的数据；<br>$G(Z)$：生成器网络；<br>$D(X)$：判别器网络。</li></ul><h4 id="GAN的训练过程"><a href="#GAN的训练过程" class="headerlink" title="GAN的训练过程"></a>GAN的训练过程</h4><p>首先对具体的问题定义出生成器和判别器（多层的感知机）。<br><strong>1. 训练判别器（discriminator）</strong><br><img src="/images/resume/train_discrimintor.png" alt=""><br>如上图，判别器的优化目标是上式两项期望和最大。输入为真实数据和生成的数据。由于log函数是一个增函数，他的形状如下：<br><img src="/images/resume/log.png" alt=""><br>因此当判别器将真实数据判错时，第一项得到的D(x)的值将小于1，当判别器将生成数据判断成真实数据时，第二项的1 - D(G(x))将小于1。由上式可知由于错判将会导致上式的期望接近无穷小。因此最大化这个式子（等于0表示完美的判别），可以使得判别器尽可能对数据正确判别。<br><strong>1. 训练生成器（generator）</strong><br><img src="/images/resume/train_generator.png" alt=""><br>生成器的目标是最小化上图中的式子。由于第二个式子在优化的时候能够提供很大的梯度，使得算法快速收敛，因此通常使用第二个式子作为生成器的目标函数。式子含义十分明显，就是使得G(x)生成的数据分布与真实数据分布无限接近，D(x) = 1时，函数取得最大值。<br>整个训练过程如下图所示，判别器和生成器交替优化训练：<br><img src="/images/resume/total.png" alt=""><br><strong>全局最优解：</strong><br>不断迭代上式，上诉方程最终会收敛到一个全局最优解。<br>首先固定G，优化D，得到D的全局最有解为：<br>$$<br>D(x) = \frac{P_{data}(x)}{P_{data}(x) + P_g(x)}<br>$$<br>上式可以通过对目标方程求导得到。将上式带入到目标方程里去最优化G的结果，最终我们将得到如下方程：<br><img src="/images/resume/CG.png" alt=""><br>即两个KL散度减去log(4)，由于KL散度的值大于等于0，当且仅当：$P_z(z) = P_{g}(x)$时，该方程取得最小值-log(4)。<br>我们知道，当固定D去优化G时，优化的最优结果应为生成的数据分布与真实分布相同：<br>$$P_z(z) = P_{g}(x)$$<br>上式恰好等于D(x)最优条件下，G(x)的最优结果，因此通过迭代的方式去优化GAN的目标函数能够同时得到最优的生成模型和判别模型，并使得生成的数据与原始数据尽可能的相似。<br>（具体的式子推导过程可参考论文）。<br>因此判别器D(x)的全局最优解为：<br>$$<br>D(x) = \frac{1}{2}<br>$$<br><strong>例子：</strong><br><img src="/images/resume/aganstructure.png" alt=""><br><img src="/images/resume/GANexample.png" alt=""></p><h3 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h3><p>由于单纯的GAN的生成器太过自由了，对于较大的图片，较多的pixel的情形，基于简单 GAN 的方式就不太可控。于是Conditional Generative Adversarial Networks提出了条件型的生成对抗网络，通过给GAN中的G和D增加一些条件性的约束，来解决训练太自由的问题。</p><p>在生成模型（G）和判别模型（D）的建模中均引入了条件变量y，这里y可以是label，可以是tags，可以是来自不同模态是数据，甚至可以是一张图片。</p><p>$$<br>\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].<br>$$</p><ul><li>在生成器模型中，条件变量y实际上是作为一个额外的输入层（additional input layer），它与生成器的噪声输入p(z)组合形成了一个联合的隐层表达；</li><li>在判别器模型中，y与真实数据x共同作为输入，并输入到一个判别函数当中。<br><img src="/images/resume/conditionalGAN.png" alt=""></li></ul><p><strong>常见的输入结构如下：</strong></p><p><img src="/images/resume/condstructure1.png" alt=""><br><img src="/images/resume/condstructure2.png" alt=""></p><p><strong>模型的训练过程：</strong><br><img src="/images/resume/condtrain.png" alt=""></p><p><strong>论文中作者使用的例子：</strong><br>在MNIST数据集的实验中，对于生成器模型，将label的one-hot编码与100维的均匀分布的噪声输入融合起来作为输入，输出是784维的生成数据，与数据集28*28的维度一致。对于判别器模型，作者使用了一个maxout的激活层连接输入数据（与生成器输入相同），随后将maxout与判别器相连。</p><h3 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h3><blockquote><p>Image-to-Image Translation with Conditional Adversarial Networks<br>submit time: 2016<br><a href="https://arxiv.org/pdf/1611.07004v1.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="pix2pix网络的主要作用及特点"><a href="#pix2pix网络的主要作用及特点" class="headerlink" title="pix2pix网络的主要作用及特点"></a>pix2pix网络的主要作用及特点</h3><p>pix2pix是一个基于CGAN改造的一个做图像变换的网络，在CGAN的基础上修改了生成器G的网络结构，及判别器D网络的网络结构。同时引入一个生成图片与样本间的L1 loss增强生成图片的低频信息。</p><h3 id="pix2pix-网络结构"><a href="#pix2pix-网络结构" class="headerlink" title="pix2pix 网络结构"></a>pix2pix 网络结构</h3><p>以下网络结构都是用了<code>conv-BatchNorm-ReLu</code>的单元结构。<br><strong>生成器G(X)的网络结构：</strong><br>生成器的网络结构是U-Net结构，即encoder-decoder加上skip layer的类型<br><img src="/images/resume/unet.png" alt=""><br>这种结构在输入与输出之间共享图片底层的信息，有利于图片细节的还原。<br>具体每一层的尺寸看代码注释：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">encoder_1: [batch, 256, 256, in_channels] =&gt; [batch, 128, 128, ngf]</span><br><span class="line">encoder_2: [batch, 128, 128, ngf] =&gt; [batch, 64, 64, ngf * 2]</span><br><span class="line">encoder_3: [batch, 64, 64, ngf * 2] =&gt; [batch, 32, 32, ngf * 4]</span><br><span class="line">encoder_4: [batch, 32, 32, ngf * 4] =&gt; [batch, 16, 16, ngf * 8]</span><br><span class="line">encoder_5: [batch, 16, 16, ngf * 8] =&gt; [batch, 8, 8, ngf * 8]</span><br><span class="line">encoder_6: [batch, 8, 8, ngf * 8] =&gt; [batch, 4, 4, ngf * 8]</span><br><span class="line">encoder_7: [batch, 4, 4, ngf * 8] =&gt; [batch, 2, 2, ngf * 8]</span><br><span class="line">encoder_8: [batch, 2, 2, ngf * 8] =&gt; [batch, 1, 1, ngf * 8]</span><br><span class="line"></span><br><span class="line">decoder_8: [batch, 1, 1, ngf * 8] =&gt; [batch, 2, 2, ngf * 8 * 2]</span><br><span class="line">decoder_7: [batch, 2, 2, ngf * 8 * 2] =&gt; [batch, 4, 4, ngf * 8 * 2]</span><br><span class="line">decoder_6: [batch, 4, 4, ngf * 8 * 2] =&gt; [batch, 8, 8, ngf * 8 * 2]</span><br><span class="line">decoder_5: [batch, 8, 8, ngf * 8 * 2] =&gt; [batch, 16, 16, ngf * 8 * 2]</span><br><span class="line">decoder_4: [batch, 16, 16, ngf * 8 * 2] =&gt; [batch, 32, 32, ngf * 4 * 2]</span><br><span class="line">decoder_3: [batch, 32, 32, ngf * 4 * 2] =&gt; [batch, 64, 64, ngf * 2 * 2]</span><br><span class="line">decoder_2: [batch, 64, 64, ngf * 2 * 2] =&gt; [batch, 128, 128, ngf * 2]</span><br><span class="line">decoder_1: [batch, 128, 128, ngf * 2] =&gt; [batch, 256, 256, generator_outputs_channels]</span><br></pre></td></tr></table></figure></p><p><strong>判别器的网络结构：</strong><br>判别器为卷积网络，结构如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">layer_1: [batch, 256, 256, in_channels * 2] =&gt; [batch, 128, 128, ndf]</span><br><span class="line">layer_2: [batch, 128, 128, ndf] =&gt; [batch, 64, 64, ndf * 2]</span><br><span class="line">layer_3: [batch, 64, 64, ndf * 2] =&gt; [batch, 32, 32, ndf * 4]</span><br><span class="line">layer_4: [batch, 32, 32, ndf * 4] =&gt; [batch, 31, 31, ndf * 8]</span><br><span class="line">layer_5: [batch, 31, 31, ndf * 8] =&gt; [batch, 30, 30, 1]</span><br></pre></td></tr></table></figure></p><p><strong>网络的总体架构如下：</strong><br><img src="/images/resume/pix2pix.png" alt=""></p><h3 id="pix2pix的出彩的结构："><a href="#pix2pix的出彩的结构：" class="headerlink" title="pix2pix的出彩的结构："></a>pix2pix的出彩的结构：</h3><p><strong>选择PatchGAN进行训练：</strong></p><p>为了能更好得对图像的局部做判断，作者提出patchGAN的结构，也就是说把图像等分成patch，分别判断每个Patch的真假，最后再取平均！PatchGAN可以看成另一种形式的纹理损失或样式损失。在具体实验时，70x70的尺寸比较合适。</p><p><strong>损失函数加入L1 loss：</strong><br>众所周知，用L1和L2 loss重建的图像很模糊，也就是说L1和L2并不能很好的恢复图像的高频部分(图像中的边缘等)，但能较好地恢复图像的<strong>低频部分</strong>(图像中的色块)。</p><p><strong>图片的高低频信息：</strong><br>（1）低频就是颜色缓慢变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，梯度较小的一块区域，这部分就是低频。<br>（2）高频就是相邻区域之间灰度相差很大，这就是变化快，梯度变化明显，即边缘部分，即<strong>高频显示图像边缘。图像的细节</strong>处也就是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。</p><h3 id="pix2pix的损失函数"><a href="#pix2pix的损失函数" class="headerlink" title="pix2pix的损失函数"></a>pix2pix的损失函数</h3><p>pix2pix在CGAN的基础上加上了生成图像与原始图像的L1 loss：<br>$$<br>L_{L1}(G)=E_{y∼p_{data(x,y)},z∼p_z(z)}[‖y−G(x,z)‖_1]<br>$$<br>加入L1 loss增强了生成器对低频部分的还原（颜色变化平缓的部分，色块等等）。因此最总的loss为：</p><p>$$<br>G^∗=\min_G \max_D L_{cGAN}(G,D)+\lambda L_{L1}(G)<br>$$<br>其中：<br>$$<br>\min_G \max_D L_{cGAN}(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].<br>$$</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>由于网络引入L1 loss，同时它是学习一个输入图片到输出图片的位移映射，映射范围十分有限，因此当训练集中不存在输入图片类似的样式时，输出的结果将不可控。</p><h3 id="pix2pix-总结"><a href="#pix2pix-总结" class="headerlink" title="pix2pix 总结"></a>pix2pix 总结</h3><p>pix2pix是cGAN网络出来之后，在图片变化上使用的第一个网络。网络的亮点在于生成器与判别器使用<code>conv-BatchNorm-ReLu</code>单元的U-Net结构，在目标函数上引入L1 loss，使得生成的图片更加的真实。网络训练方便，使用了SGD + adam共同训练，使用了BN，dropout等技术等等。最终结果图如下：<br><img src="/images/resume/result.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>project one</title>
      <link href="/2019/02/22/project-one/"/>
      <url>/2019/02/22/project-one/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX1+1367URDRiFSRwpSZiqO59SKZl6wTPMUVgvI32vyWCzTm89lHfV3y8pG+/BqWZ4Nrz0Taphn0FkfJOqq4/crN7iVw545hJyOl2+4cgnKfp7Tuad+Syo4PPbYULG54qG2810HHZTgzFy3e4ZlEcBnGgCHDpnTo/ieZ4OfH79Oqt9SB6dZOhPYwD+ZLapMsLSpAZw6r9nv69u4xVwgw8vDPM/13VN9BrDCLCdEfh3dD56AnAn7tKGvso3f28h368TfS88w96L/v2hJQQZ0AjK9dnzt5k20SgvBz4qO8X+pbPAmjBhuH4243ZV9TX789DwKdqtkmBFVve23uTpJB74E+5G7Nz/YaXyvd6TKlHz+7nQ5CsOKkQOv9MJENnSPhKbc8Mz9hvF8s01W3J0yptzaNpzVXSluN3sDLF2YWpMWSaaTtbnXj2StRvwNMm09PkSzC7PWQdTZHu+iPNSTy+T5/46v/n8zdtQYc1YgMhf256k1P4g+wT5SfBm/S4uP/Dc030F/boZtEJLhuog/zFDZY7FliXu5e/gx0oo5Sa32wOHzgJpK2Zqx6a+q/kY9Agk+MkWaCAPUVXrNUC0/sqjYMHkNP1bvkU3nzoweyhjrgioiNWP8dgVVlw7uZNd0pZPaoZDgdZw/yrmFSZ2GXsJysh2uttvcn72at91H2lCTui6CKsA0QKgEPKxDSyREqIhfaI0V0y6j6CJt2H3qaIQCNF4NaGHSjRP/ya/LTse3ulTinjaw4d8iVNMOru7m+gAcn8mOj6jDZgFs7f7RjtKXhVzmpH6FfM4DmNmoUYKLJBtQXthLWxvdFSHFN28UrTaR8R09ksIv6NLLkN/RoOhMLbBcellJRFlLXXyKVbjzVTJBKL6PQKW/kVbzROmkPjTHHE537SszXYEoCmjX1TSWWw6m2fPh25Ehq1XL2A2HL48jhZLnh0XI2Lu6XGS9LNoLPijBCNW60pEmda8ZS7kj1TQPUMxLC2WB7I3RO5e/lGffKlDSiyJoRsQSx8Zd9k6B9JUnPFJrANyR6WrC8AX7ALSzK/FmD080HmMjENfMfvBHoPdFnNjsQHz16oHfvlZSKZrenPrrUajEjTP+YW/xgxTYv65desudVHOpxdEVeMlNPe9c0GY/xMF1Oq6qb8VBI5bZ1Orq2V4r4+yjHnawPHm8aUlfqn3Z64MxHtCAVvWgs7KEKyBpoD49+/Bza3hU8y9GxqMdMV6nep8MGM+cFkLHdUsMrQ93KrvmeK53lQd5h92iaCDVAWQ6dv6szsXFThxQlhFYRE2MOklnk1EnPT/uMuUatnHeqqpN4x9sOuRfrKJwmAkfVIu6u24cPvTsopYRyaPYVXYswymvlKjfpKPxb2i3gZfRFIPY8tCOnHrvPWdmiry/6LVWP2wxSwabaYsL2CiwtKVKSgwl0/kuwO+fZ1LnHDhFo3VEn4UA9I2iIk/fPMJsGG2s5c58oEInk7SoHohT7MAwaQuuYx4w9dKrlifbENx+8P6fz90VOwz7/LgyARWpaNTKH6YJzN5thZhxeTtBOvh7Md2681Yi7EK7gKxvxoj3okLW/jTKINQlVlShRpxp10MS7MWKQnMo9ykhlHjjVK9jY23XA8dZEfIQYJRcORAgnVE9DcqEut96n+czaC+xhMZVJEh4RkCFNQcGu6nXpVmf/RukMxxN54awoqZF+v/LhBCtGM6yb41LNjwrZgmoantSW3L7X9EOCuVPDkJZ9WifNsQymJ2gEANkCGVVcuacxdSMQ2RZnaG2kTYJ8o4kTDNOotzJzqjVHS0s55BxaAl5+vFO87+7s3lUqIGSCx4OAyCMeB2FDV/b7ruoYPUmZmjE82QkMC/4xbImggq/BQGqy8Zw68ac+TYFTS1oHBz0YpaPhQSAbmkpxLNEX5XQomZtH0bk0ZJRqS5spBFtZTMpE39VQgVDtaqD0LnASQC4TwgrR6A9Ma6+BwhE/Xio7w3iBi5KQHehvIYqmTzoGk7SIERSMDYU6eqmTvA8ihgtmpc12+5vueVzqpWHFgNVpUmSMYE6cOWP9Ptgloh31ItKeYE40d1ihO7x/I0+slJfsj5iHG6wVwEuycqbGo+EX9JPXl80TLO+WmikEdjyCMYOIYRB3RbVLBOBR06SpPNvgaqfnVr+af4pFBy1akOy8okMnYSYNjEydNQ8V9q7kjR2xCKkSojVWkS6aqO1we1k82WVwNF5RuelZ+tuTMVVGuRjy5ajusKoJlMr/0DzWvdr44q9KqQ1jT4EQNC00FLJyke1lo/9MnSBr+Z+aDkQtE2LlxWfijBNSgmwRIOWBvtaPrneY6hP8XKwlOz6rPJLPbYboMRZ41aO+AMCFEvIO0x3koyWwMyYcLBU92ch3bB7dTnPA0u+JLAeY8dbMRRTU5jusPOc0e6VBC+FEND3zpFcHrfVwxRDq52i1vAkD+xL9fJIDNaewgd5PhQ2tQo68kd5iu96w6SRjhNURKfntPqmrrge9ZqdaEigN19qFYtSmoYBFMSwQRp73n84bES/HJh/TxhSyxUnQ17xASuJTYqagTmMc2b3rxKCsUkTjLMmskYoGSpiNY2FOXRYp/G57J4UBR8I4sn78hhzZW/ZNY4c2FTWS261fzOM/8O6f5lFylKTndZddLiceZbG5KHt/iSwwDKkJ0cOMCUdHFkHILrBmwX6PsSlJZOoA5naqQgs9z7ZH9mxfywm2BVg4SMR9a+ovRDJVfygki6AvkfrJNILS/1WvNm4waCAowX4Rytle6Um7Qv0806coHQUzvxtPLrrdEHc5IdoDTFGGXvCeXMNPymAyJKQDHwOPfg6/NEPWtJIBgDOVwrEBs6IA0UJmcw/lAQMxEwHnRgYyD0xeMKb1ayj9cyGSwHC+aOdnkmRzX8Z08DdqhyTrASiw3Hpy1bltT7wOpwC7FDPqGzrtdXRIata9bTl7VFKIxybePq12CuIwaOk42DCFP7O8AVGjdjbLm0QuVg/x6ukPVcjG1ipKegQzWpr7HZJhqIvbuKiZg6uc/wRxgT39U2z0vo5DU9W5/eCXbduF2S/WwdbIyqwmIuzExkCVC5FPsnZCKryUhhBSDW5Ew43oNPKZnWSiobWKoAKkKKoXbixYX2kQ/MRfky6YHDCuNK2Nsyl0bTXC0L2aCW3qyexEnPhKax//YKjLBuMy509Q/tI5/bMWclw6BbHh0yZb4ek7qwomABHhPkmhHLzj/y7cAo7ou/XrHnr7uWjaBeSVOEhcNDFSF7OQmWqltETSLweriZXGuj3jYxZCa3bL3pmig0PeE/BuzJHHf4SzSyWkPIEBm9B8+eNocd11HiSgOkVi8VPo7jywHqCpgXbjxR0tWni5SosrNtbkI7oLZNfRc1xZb2pZynIx3dhKI/cuw9XsfNavsPPDNxjkoUpMzNtYLTcq6c0c6rztaUZjp4/d92NdxRH9SpcMm8po94QTYe+lU+B6ctnQITwgkRBnbWUaAVJFSTdSQmeAkrVLcjvlUCTtXxj3jwsfZhe4/LJXxotkTN9Al0pSYBFuaP2EtlJp8yIazyAlvg0pfDLeGowQBK9QXYCuFSBmrRuAJ2tPBfdECtJtcOc+5T1hqg+nxyy2i9fQll7TrgkbEaygYO0cgN8Gh0ZhrKbCOaqT0X6D1hhEcr++CBmKgP1UUl7TlCZXwkeXjKUM6dnJK57wLUBUZriT/449cxHIiXvOuukibHnEAypnCtcPkkdx9rEujguDErhLeof1KufU3F2StXN3Ss5IcdUjYN4YSToQtjYMLL06nUTVPOLgSUBRI0sMslfxUrCWNllghOZQChQAXQTZSTo9EalAHYMBhrEUGfrDYEyDx2TPHIxU5GF8qHGgADf8uQUqUN5KEpdgE1uzLt74sIfWa3HtEab46tdtiNDdjZOAQ4KeBKz8U23NCwtajXOQYuprEHeaQXVJXU/h2ncqcPV2IBF7PX4KHiN5XN2Mw9XAolbDYJFdQUtiLo5DoBcXNMCh6ct3mAod4fMKtikpbgGYHpkxhvmvkIESAfYIra/ecU6W9eM460hG7pS2hfCeHL2vF8dtW0alIit1fly11cVhdjrOVW754o6zJWpY04COriDfa8FiWIlH9exVOgad/R966+6MS1zfhSnEuLK+jWa5F7c2lSDe16xbazAjaVRZZb4u5nl5LH9JUf5Q/S6z6p+ZvxL04+P7hb++DAgNIYQpDxlTtDS71lLC+LCNIpErQnfktCVaeqpe3iRwA2U1SnXQ4zIvY7m05Uh3YdTS8XkZN+wGfGnVLyzBKs8mMdJHAQaQEOnRgsa/3LfdDyjPHSJSTfCZlwB7hmBzREz1aXSmkM5i9v3JlskpZXzwPG/gq/Df9FEjAd+KdM8zF3m8UrIQmU1iHpQnm34fxNdzgdN2F0d85Es895rGstat0jZVt36rNle8hQzeDa03ZZIMVv3UmOz+pM6yPOFWrqxH1+eiavCUhLCmE5xQh7Koe4V62BKxigj4U/z5InYs/egkWaNhM3pwQS4Wt/cUNgEktfR3fMlbZOFBFul2Gd3nWLFktL9CNIauPMczYq1EZWoc0TtG0FwYGlw9TttRdwdg90Aci88ZB5A88EE2gCTJrzcYCjRhhVhVthTc7ct7emiK6iYkRPUzmm5HzN0AalCR8lKt00zRLV3qm0ApaZXfrplAyq0jRTXhxf2gmVc5O4qtoenZ6LKxuZWzr+PND8vUDj2OW+7ltnEJVvK85VxdlH+sdVSq8aRg7v2OCwJhx34OK//bQIOU4Y1vISvFly0bxyBKUoV5yv2SpxUUGou2BztMZM4litipKfhvT4wu/twM/JJOHdTHIAdTh9uCAwUHLjy6q0pfGFSFTczKctvKvmdiiLyihWmrlJlnW1NAnctabQRLYruEEGRxyVs5h1FOk4gtzow7puiA2m+xcirexdzX9o6TaqJMYKPm/+wlOt7SuZ9XRDI+3jvhCfevPOqoAlz2ZmIId2i6DtuMJtYgtVMKb6sVAVUHSu8lIM+dkE5oiz7JEfScehYpKHXaoqGKXt9hICObQhPTvQsi+C6sRX9M+CiAh6++EmicCu0DQBv2Uk2hWqJtHIOgbCqFn3k9bZUO2TwlLn02wpN/WQlL6gOO7PYkAbrtJXhTqqkJLJmO3Bfwoj+87FpzqK3OlPZ5AaUu+tkDr9YwzT3nl2VXgLTJTgO9+2P/ohCNIed4vQImUMko1UB/F5P/0P5ALMGkXeOoojtCKd5oA0TWGHgMWxEvdATIF0LwtyOxU3uKHWiUosZHbUUNjDCLPvlB3bUAejYKy1yx+SoDzHdzrQkGF2W5EYMwsmX6Fas9DEt2Gl0EJPLZ5XNfNWFf8y4QeJS4aHRylSLcGn1rA7zqeADUbO58DyAcS5VU9bd2M7IzC8uuLZP61P+VkwQc1IfkSD+sXHNdUoln0+g+qaPjqG+eYBnJaVUgxcwgjKbgqteXD3i7AyNZs72G3CY0Uuv3GmMoL4sC0OjhVAuZrAaaiYSKCsLxQZS2uLwjbpIher48Dsjn8FELzZxUKCSojn3oNMXU1cARLsExE0i189qV5JtMSiD/3ueIUq0/HNw+f2pnOkH7QjwnfhXn6vE5e8ZvE/U7USFzpRnossxugU/Xsf675jAZl8WzO2zW3/iJcoEwEJFJAGNAwfV5cG54uH3+3xSwDni5rWvIgAM/Np850PqcQGwmfyEK7M6+kczKiJKoqdcuOzuAFtLLPe72y7URSj5hKVhAeu6fazMex52Yo6ped4mZZ5FDrOo4c3/mor9UMIgZ/l6fCBnRLrkKSiZ72shoyViPOSyQKyyYnmrMHB8FoVhF46Nt0rw3YubiPKzoAEuM7b0BG3vlJ69DDWxdjFtQNeJJ9VG3M/xvsYguVwV+2x0ZxNvyGGSKh4DYCQwftCVQAWiU6P05qP7f66gKgJo6QMJEQGjnyCHyb/M075kBjpBANnbTuyrmw1Lxune0w0ttU7TDM9ZoAMfGfdZCXyBmVJUn13ZfU9SPojxdPg0MW+dWNHWZ5maG2xJyXdQStVMGOvsT7DADLgwrmycstmSjH6/CvpsI/YIE6BxbP8NLMNyjKFQXDmDR8fYTMj6mXJ0Zy0PxVIdTtgMAhZF0v8tYTmRmwx29bjVWCpzqJD1MmMwV3Luz+w21uK2NqbTSpavcWFy2N/bYjMc7tnIgt+pWGyXkK650IDf3ItwE4mmh8dC1RPDDftzfpm5WX03jtZ7s0+j2fDcyO9ruU05wZ1vyR8InQ5ZHGUSGKIt7dFbIEUdFstLiFTI2+ijDzBhMWOt/sn+/sX+DzdANqU4RRLzktFdIIpRr6+usdFFk189y3b0KlSjhlwZSsEuSPciKvhRUA+SdlSwTE8uPbk18NYH05xrd9REHXw36+qJ5MNYyLC7MVYDiIpJ0+TYhUfIY1p6ZyxgR5K/DTnQ67BfH1uUpHRamnmnqQwlheMfHi1WBtXuogp4/snKDhIpvUXspKzymjk2W/tZVzHegP238jiQ7jagh6qaq+XLcKAqWVB9tukUmwAgQJ+DCG5vZS4t7pA0mTr6+IStktXbybyaDJ+EW2Q7gpUZYoangeEEaShzac9iJE55hbLZqR4iR4KqTT7vleqey87ixWdvdFQgQqxecq9fJwcsbfjzYrAMYroJPz3y4jfK7rz09Xg5wKeTrgJTCt52SShQKaYSI/Ev2dd4tq63TKY+TjW0MKXfDuSGei0G28hHFjG9SiqHSQfgT7eR6KYAuKe92oTuQRqpx2b/DuykSBY2rtMizG7M0SXrHKCzHLZlNkQEzlPrBItqylCXjARaVtKVC1Fzj27SZtYstCPTH1Vab81MKLHbTsow9vuZHD9NoCB+Zda4BpY/vygIILggm5x/hW5vUYHN4k6kqTOCAy6Ay2Zn4nOBrjm5DtdGTp4zicjJ1WRkTgvqYezRkJ2S1f/Xd1PuQON6zO9+6b6TyHm6zubEa8sHF7UwUKJIizumFFniGzA10gbdey5yScwPMiXCYScST87WYW8TOllV2yCiCASRcJs817KrDNLh9VT7efYieKjgt9ECJOR260/SSOp23+3f1K927NxYRk/DQtK6zQ8tMReMU9gGkI41lQ+9srpr0o2J4VpACtkWyuExGtMQQD0LRQGXrnYB4VmdvCbYd8I8ceaPVTmgwXyh5425Vi58vVyE1xWplATrooIVd7r/r9d7yPhVMVdsmlW8qo8wjyAQB4h9JSTa9XQcFDOr/sUBr/ZGhjzAwyiScNRvJf1yCmQzACFeYfN5A9aiMTtdB1Zqg0C8LELzVyNfJu1pK9kTCCYknSVEWW49SuIoBIzV/lq/271tBN7GqKXler0iZlf9abCdSRPmKcrxIEXYPXUw5MP9PD1aQ2QVAtJuWTPjHXxasfNPhdTbMTBZzubfi5L27oc82hLZcQ4FPLVfRHAMMb/rWZAngZMlHqXH1crQ+UvSnRRrOSQfpBW0B+yPOdexYd+V3N4vD3jzdKXbJAOndFcWt3RoemDJqMKT4vysIbSi8Pw/3gyKojYqq58fPwi3txM9aLTM2KWrWL4AU1TZpxcWJwOfhesDq/fQEC+GueF2yMHyqCoPdyWALoqNa9ZO3Mwm3mNLJ4zcnwEFw6N2NYMEJ18maEG9ePEMS71gDVW36b4iYq9GwLWkN+pj2CGFMHzHjJfmlYtfwWnldAjJyQdFa/Cot/Vt7vEGSk6cQszLCy+D4sOBBnnCblGDo3aJF1q78Ef4WCMt4h/ttbkj7oyRzzXK4lK6PzEhfknirtis9LuabK3R4fk11zIqu/xY5VJf6rfPNE39L6g3NYl6jHB3eQefBefaP9HCTagrN+QOhQACzsA9gQRNvYmFo83/4oM8pICNR6lDVUxAP8ywpfmZ6UU2UPZZOhLQyMSMb4hwEyW7KHo/go3gT/pIQE3azotmYw4uyMlJpQNSn2pgJejUYceLEKp0O/6mF2mzI4KMxj1fHEIP4k8VYoKQHCu4AZcXiJiVeLql3M884WRCl0Wfk3V8g5iPm9vGpVt4l3wsqjd8rBDtjAWRYho5AC14htR63Lcty2yO2BppRGkDG/zIVDJd0/0rMF9navO1BK0Au8litXZRjPy9HzQNeEv+uUmevlDxvsuZgoge0a/TvbrYqRIQ4cbFg8m7SgznRBo4odyrDSz/f/70+qmat7KJtbb0Bv8QpYyhwkupvo9Fk5QP4OgI7rq7Eh+hKqpYu7MTKIRZMdJGnBZeRtK+7X527cccMIn3GYVNW40SMT6kgZ3Vy6rk18BDAGmbEjrboHSFsqjMIKyg7BdqeeG3EE/WzK3eUgHcC4epwU8cVuAFEPCCT+w5NJVHXgNL9ZHjPAP+es791R97hpumhzkla0eXMDdHc6DrbwWVhk1zt82LQ8Y+TB4zQKLtGiUpD+TXlfW8xABg2MkmOPvL2x3sva3mruhw4BfV81vxC9SinaOzEiqqtR/AohTs2uRY09aCb7pkrkTIlhiZU8m5gLCpvl8Irkw24uL22A0rlSrTLM7FIPpyOsiT7auzOk2X5zHcN759GUIC6sQjksMPLeJYpaj6NMpH9Jm0Vcc58HsAD2MHnqJM4P4yWu7FiQM67ZIulEl9/V2RPIxS9lgU4GvXibT4FP9Wi1Vm57J33JVfW4MT1eFnzTkLkdGu5WQwjHqCEWjt5ZsIbT1NTMZugEjczZTlGDKrMUpXvi+pSkYuc2D7PCxyYelTlVJ7XoO5+MEB/N6SZRb6chF9p5XlYUpKtElkYFe/WHQ+rWvYC8yIGGdK7k8d/C9aKMsP2/aC6jC8PQHvqjZ9vBkNE6/9MIMIH+2MjSDcmrlY/4UdapMN5JZQB4tsbSUNtb7t+zb0JMHEJE6tbUpI8NDXSws2XYoJkMV84YejXOAv5tvQLkzngv73+NbCjzxI6OC+4U+ZZBaHV2a6Q1Kus8pDxRpPqyIQHlJpfpbW4V+mmqlg4v3l6Eu2kOusExJGYUT/+KoFjTyDRlBGgf3QxE6O62dPVykjH2CM3Bta4JeyBiqGrKFDLytNbX4yokNbRXzWCH0bzPqHGuzLx7Q1zOarg0cLtT1exrnPTzUYQFyiMVmdaJ6h6gRHNWfst+tAI9Lc1f6zIun245Km/ThDxjjH+voKQF20K2zadoC3VhfmqCfMWf+b1lwHdq3jlownvVv7mXKXQnHK1ldQYAyQ+ZcN5egtcd6DTcqqedAr/2GxatrDZBoVBarfRethl5FjtS64HcMOUFmJPXiCAviE3QyeaKC42sscsVAM5gP9xAFc9XOx2TtmrnAGMoWHntwPrS3ZxdjceS1KYkqqNbvTKXYtvoPIvdzz6ETM9XiuVWD8dQ89IvvQ0Qnd1BjEt1WI8PPwLbEyK1+j3XzVU0cPehN3hY4ZbQKec8WEoq9zflcmdBQb1KOv7rFxXmxSoyb5DQCz2JvbBcgw7c2Zsi6JNHRi9BNDPFsH11MH3oq+2pKbQ8hTUMAau1aO7m0Ny8LCT/idR8Wma0AbTsQvRBAS9RirF0Id9X3g+vQ3kOCLJtidobPnq1oyCUCsO496Q71m4ZKlCzQvCGLjOTt7jpdtziYSdMC6PAklY3MWVx8gJwoUZ8fHPs6wP4KUD7eTpEkvJ1OCLUC45XExA7vdzcYR2lbHkMUVr04xtlu0TtpKKhUn1z3velBUJLt9NnCB1Ns15LnkFwj2YoQ3M2Q2kNx6RPuXuuptUMS47rvkBCE33O15Y6SzpI3x3HbXlfs3GlGRREAW1ipEGYZ1OgqUIDqFkhaiRjGYiAYyKTV4Kx2hPJ67RbCObhZoenYH3hqhbf9lwEO7XBH/Tcu3rrJtsvhJbeH21LnHeqEi0dmI9DRQ9J70o9UCANw/5vcOR8yB91/tvL3wi9+wLKcogp6PE1QxT9BHfcXJzBNJm/OXT+1wm91tL/1cgLPnENkIJ3NOAv37GKnDosKoa5aNVpxMVHZxggAA2EHBZZqgqZUsrnEDh1H5v6rj5DZdu4V9zeZQakvRI6Pk4BbWCTcTpHvkVILOqzF0TmeFTJQa+F8+Y8g6v1jf0s5F1h+yCObOUjb6m2cUHP5UxPiO9tyh09HFstgr4pLgZQPdr+QNxcALCrefKmrE4oruEmvY0HD9yT1q1dGQDJrwsnnqb1QJm+Ed3XcYTG6LKgJIIWfBqxcZv7BNAIFtw5fkDwlN/Q1iBcAYLJSlGoQlshEUXdotg3O4i+ianiaEyKK9hW1nS8tmlEasVnbMB2/1OsCCzycmSzRvmhbJ66zqlYRUrZVzL1zmCO8a0q9yFOYsBV3U/qboNOyQ3hCvamyEA7/O295RqejcfOSjZ44VrN5DTBCN+cyKh2/4ZmwzUkS3ThYYBcGanOWnn+M0KhoXYQTbJy/QWUnzNpBJKm4BEro19zJglLRxzOBfQs524WfvsHX5wHG28e1/cSFPe7V/tLkLCbaS2JFTRhAZxWWBnO711Ex6RNNdQLL2vfIJuqFsaHjbcSFwVGzflBRrhnUaWaiCoBeoikE/TChktoknyf/zsyMfmUe/oXmFC805EIJ3UNhyigANdHWsRa6oM+VpVknJwr+7U4s/gqPQ1QjOPXeMjp21nYfd3Y9kYvQGybz9mV4xC8h1wQd2byDoj1/x/aZ4T4VIwzCcM7oRwXg17fLcxZpJHy5ZPrBaAdBfrVpCSmALziWNivMkS9E9Fmtc76msuZyoxmC49oqc/tXHposWdeFHmXzjHUACtsy1Iq61Gpzot8bnKp4gYKPwIHqGoMibJuF1qsExmUMDrupGev3rfr3HmQ8rUazdKUyk5efvrY19jBYjVHwXgksMAV9Ezog5r+WB+Sg0GYsOCLr6NYJZyvXQf1mYoVnzgU5nOQHlQzxPjqg0mCNK6aVB7eFvK/eqLJ7S1sDjTWpANGSTzXiOiZsGt9S4w2hmmQvzq/KW7Q+tEoThgJtga/r/yXoTOwPqeoO+FjbLanhYQXLpvhCvK+PTz1sTPXfLCTQruWF/qmozfu+gP4/uCqCebDWdpijSERKnrUR74LSs1YVu6jF/8/8ewf50E+gYJgOjBMV7NpHeBxaNLfxiTXvgBb82HU9pd7sz/2dc21I/SiKalT3+MqUAFUpC3x1AK0pJIhZTf/jw+1/qROF4+qqzhQSAk9z1FX45M9kGQOaSy+xDV1UeJyaLRrh/PbwLObxzSiEX1GbFMsrNzrnwJTTBCQzWXqGmXLsUYCbEmnasdUkMomsqUnn01al/Xksmjnkwj1dz61O70xztMZ16yxkojdKMLEf2I/fmfOpsrdak4ZChfMo3tUDCh5mIsjuhvEl9biGYpc6abe/4JE89lt5Ju97MCLTEVDqItTuLWHcZKmvnhnyKeQ12sysLS+eazObmIYwJ8rXqRvDvcAL0SqAil4xFeERGIziqz5GSUV1kk0PQx1338rywREtDBzL0y3o4BPPM7IsmF8aH8f2IW0K8Xp7FDCCEpECWxXzJhwvQtCg8GAD8jwXUoN8xXjlIFQ+Fal40YRMwvkDSaTqX0MVMojS0DSc5paJeikru37MgwtBe4eSG1iRLM1eyZvBwsZjBEJmiGwounv5m5oma25M1D4lRlOmjvMSbGmkcPbJNb5WUZ2rOJIVTkARDijDV4t1wGcxc/r7al2dSwlkPOpW+fsE0GjRJrCpfPXbRdwPyXZe0Xl1xPZxcZvyilPzA/XADwVZOWTkvUr3Ilg+hcBEAW8dckYvLzfOAYQ1LKDITgZWj4soZe885zP6nuelJk1BbixV4YXaxW6PeZWyoJDgph3i2n9k+ommRtlJ2k9roVio0BZkkkbo8rAZ0sJ6DD5i2yHCuJlZqUT0yNzKIaGJozag7G4yROm2m/ywe34jM5/HuLkYdrNhJrRqSE0iGvSUE1NnC56a7iRZe3sCkC1iwMTZMkKB01st2EhTNfKEzuZvMuuHVt4lmFbXrgRZ6Rclen8xJh3h0eCfebG4Z5dXtKt9lUnSm2C9nLZGFm+/d2VQ52LuKnbwAaqpGgFs2NVQR7fEKRcFyXiVKrSCykcFG6RqPbr7a9SzDU1FMcGJDezwMqhyHGkWLJfoFn95Q7pKj664b/ejjvZ/pB5myHtHIOl7i6G4RnDmn9oFbJVPn49/xynwuM2htWswlfkTQ9gjrFKR48dlRa6jE0WDZ52pFgGIVhSyE7SDu/fYgOH8Om60ulhZ8DkhMsSURSwjzCo8kPcaC8+tBETQ1iPI1UhOPd72vz0MiLBC55oz2kOc/tsfMW/eZRZV5f1LU6x2dknLj5GFSrgbTxNjhgrHLf9Z73QByzQqOMbUsxpwTKmlnQNz/69x5IygryOjF8+uRIZDcxHQIvJpdAeMdyfD59dNiI41AEpcrzeyc9lsiVJBfplYiAa/+l2NNUl8Inh6SoBMwuYTr/rUjRhz/IDCKohNbxPaTLJluHxeYBgmRZpF0gJWW1rUT5h6Thf4D5uwvCI5xpaVBhXE+nan0q1tu5MwUekaA+LIZTbhR2Q9FMKdOgPU1bZHYp58eC3Ok5SugXTbu65D1ifjtSUupAwFHKWZi80evwIp0vbBUHlBB3tSeKZl0DZ++599S/Q+yn8PgBE8sQ6eCcGzXL0G/4DN/CtDOUCvO5AzL5+EMneq8WXQosY1pSawClKbubqqTyQnUQCEPrnXgdm9vdQWbATcR9liQCxtTpoM61dzC/dGX2eu/oXBNXZw756ZkFk0ggrl4c7nfvn3rE5R9GBmCKxvmyfgvvxt6oOXuEEElmSTH0ULpDxF7ZKjwUpjTlfaBfe9iJaKhilB0Evd1Si7TldLhwD1Ot3kSfvgXJN4Jf/H+lMizuCQivkbPs+NJFeV36lLYBp0L7m4JUZv/UXGI6YqRzNkpTJvodlus4tCBsSqqjb7JRNOCtteYQ4qMd6kRNfHTLUn6Hyuc91kRKlXfc7VwijKWfdN+2QoOPpK41wNJNt49HghfhhHLPkFS4Vl0uPXXFL3+kyKMVUU8XmNZOuUShJggX+KsKwA+s74PPNMJhYanYicFubeI6iH2T7LCEm8KpHnkJzppsm+B82RXtRhVcFkW2sUIkaCNHQsE/yGLg+b8bgWTmYgfx63UuBuJJJ/qj18Yipt6naF9MGt0lhGoCaQdDzSxsM2P18IQGe9YPC6jhHM5JGwkgCBoefFdtefdAVimrfmuXF4wqe+7U6UMrzJfYkhYb1Pg6GsyD+KA2YqUtQeczkbaXjQiXlXzVBNrzHq4WdKkKgKibhT4MLxPuZyuXLEAk3N345M4G0IOh3jqnKkLcaJi0O4M357/bzMu9VUPPQF0KI4f0XdI1seFAnOSZ/Z9GFiFou/I3BAxeeUGReg0TEaypOU7AVo1agfLAl9RFLBeyBWgQ+EK0OZY/ZL+8U28QufpXRmweJVIONoZ1CLg8SKRl3TmriZUKA9kDD2HrRjxcgt8azY70HoypulZevLlttod96SCYTz0R0S97wx2wRwKMqEfNMG2Bmmd43/98YqmSb8dMiBwXEUDS2/3yfy6H79Xm0uwkVyaBEgZqtYbI0BP6W31wW5dj1n4mKfpz50u3DMYOqvE64X5pk1uXj7vAyFBmm1aLpn7tRVleE0Wbke6ZYWPstYENkcFlfAV5RbCGHQyjX6EinRJMEFtqb/yI7KLQSWUiIZPBSTcwUf6McMc/OG9w55Jk7nmJR6eOplARdfIYcTZGn0FGGTcbwMBbvUGqp6OqVOfgvijelPT29yoodPNB+2KtTaK/c2QyOEv+NS4re85zpIuHn03dseZetwxQ4XAcoR+3ajPLQX8MFHw4CQw5MeMlRI+WZv3Exx1AYCvV4YIGf63jSTbJUA0b55ynCb1G9OdaH7o2Cjpskh9cHesOhm4wm1PZGWSdpl76nFhT5aL3pdRmZU0kh/0WS/IblLFDshAiPTf/G2OJK8eCeX35kyPVw21qD8FVn473gtL97MHcEot0IEhgW0PWYJ/uhMqrAzyo3MoEXEgJUEDt+BObP6+60eE4/elpib2AineFDMGXwS3SgyoHcqwwt6o27sHOzO2Vch4IFqMCMugEdUmocaV/3tnp1kftWRuEAf1sNUHi14Uk7kFheMdq2GRWgp8fnMuXciTuKIBe4VaeuTKzbohkjJ5FEB2L7rNYeHgRrAFy1ZoYKTov03HQUVmqdf5dHgUts//+a3VJV0k7skcA4Kj1eGWw0NL+tkBvjdiHaN49b468n8AOz0OZ7rgl3k2Yl8vNgGNaUclTvetUmP4JEsa55UBC58gjDQgGKtVlXB+h3902IdjNk3wsb4eJHIJeFhuhbEtariOQYt4fPEB6JnoMEV8pOTWeNHxaKYOJG185rf7xVQxygkGwf7bMhN2GMBw4D9sfI6stYt4ghtjFrfoM68SBibqvtEN6B8lkCCPBfZrD0AUbwtV0vYXq58eopgZStthiVBYnj9XHghjvj1G4b4DSardAaQvbU452wP+fsYg150nK07sDusWVbx/M2c3KJi1Gopd0q/G1Iw7bv283YEUiPT5KjdXZB287bfrpB12Hfh3Q4XtNCJriFAb6iADnG85lDqW6r38HtBezc9yV6frZPaLmgfEfujFHEKprh4AZJplqVEl3FyJq/aDK7MX/kZIKsHLeAIjMBZPV12/cYnLkdnwcL2JbLmoUZHNGi+mZJ6JIEyAi3qPbWUSaMVnhojfKIuB4onRIFg1DWD2ejdRc/HNeZfx/Vm/1tcaCjYn47r1CmL13BQFFrUgAwCJdftHm+0qC3qYHEmHdVgHOJW1zY/fjB26Z2DGa30HSYs0Gi56uF23ULgX8zREe4oDLDDskXdDxU8wEWimkdwbFvGHEzIa0/W0v83KPptIzlxSUiKSo5+xEDgbCyAroDyYNMveX4s4cy1IqOqUk0xVyhxUy3ibkdmakabSbHnBsQ6zDcfV2l2sZoP3sR886E21ixyGTNkVMgm6CWjPeAaZ0erQMT2sYZBHssHRLJo2MrBlfEs98XcprMwmnf9v8Himn7RqK2W0PyGuQ+WdPlnWIe6xzR5T0H7vQwWGV9olJwECFM4rfZHMw7IuD/gqm0NZsDB5Jv1qJLOMVYoSJpISP5QjOt2cXARD+FGP+z/yNQvKiZLARWet8SlIupE9gLTGmXWHr2l54jzXmr/Ufsd6dBe/r8LMm9OVulw9gGFqw66hVJ1+V10tMxqiEbjppElZG6TVn+Cqa9SgRd936RBqMzQDq1Rpc+zodRcnLDJOi1Gop93xlaA8r3F+8LlGoLR5TqRDYZqg5QiIw9gPnvnjhqR0xDqn7YU37EOV8whyb4kuUPpLWJLW9bVqlkchMGR/Qa+7CYupZUz6/XwYOXMtkdSl2jtvLkqUKNLaCCvSRlVwPEgXrWzad26Lf7G1qejJWVD8y5cw/iY28vloz4bpKh+iDB+9txns7IhPY/KR+9UXiFhkH/uQSJiTt1gZrSftqDCp3m89OzRLFmX0SvFDFXO+i0FdHjvgPDYGj3uqvI83iICqOn7HVQtCUlaXTL6yFk/OpbikoVD2VnOvmXRf/RHVFOlRFHBWDQq1QfCwtZkJ4fifFqp+QLaoD+jQMlTu5rkbnkK1iU3XvAJT9Js6vZlmhkrcX/zELOJ35gGuRw97l/LdZ6f+e+/esU97yVaH2LfpMx5jSOZOWs1Q8etdsTNRHnnwdp6kpUKQWV/OYGP+XXKoyf+Pd0zmRDib0IIUgK7WyB+EBWR2AdkKDuurREY5COovQaXstpC5JsrVkBFXTUFU7swhGLrny6xF45vbBgVZK45TGkcfFh8B695apXvdj2AM40BrxCHNUBQDX9FlrlhRKnx3cG3nUnEpi5nULrXNDXNbVpz0PMccD7daFaL5GNwb9RGuate6IQr2ybYF8VtIdBtd04hy+5ymw2S8p7NuXyPyHJRwnibQQNyjOvvTnYb4CuJr+BLKnCt/CD5oratV5lijHNDoWVTFwOpV0G5QXBUzU+drB1G9Hkyr98+RrsmDOnfSQC2OgeDtlNTqA5Hns5TpR22ZSvhEKnk7iHv9BV6lRZaorcaQoonFaGWly9ZKltGma/ssPlQpcXW4Mp/77lLTIzBXWaUCcohRx4C1xQPnBQYDcNX44Nu67w8Q2q+ZdFII4lZu3EXUth1TGd3VJfDWfbVxh8pTbLTf0IM8UnpP9ksrJ+0/oJHi9SYiCoYB2WbD+gN1Z5kAj5Ogvvq6ljka9Zu6bkvdBnzaqZGKP6uS2T205pPoqgibNMpavnturl41CeZG8pVbkYBKtKmWfffvV2AdDY45s4RdyX/Xe6P6bDZeXdRO4l6DgXPUIsJMe6NxzxwTYjBuXRjZZysQBJfGnek1bgXeFOwGe0PFf9L5LTxVn4z9kG4ilMrK+jAk8KBv8YEMDTJ+qRSIC8xxYzvfpfbdUOgX0RzdS21DcngfAv+t0bwI2SMKZNpEoEz3G/uAD9ZYesMAhUF9Zq0UPCc06D7O6OKc1s4jcC3ufKEASW/nMy/Rfhjno1tcuNLVwMDIRwUIp5itztsQolGMV8bHnqjzqUzfA30WyRF9mMn1r8NvNcbj9A2JTpGaVqE3b4h+48tt/BALsjouIPse/E7mAiZYKPbuaN9LnPq669qu1/KOlG53GOy+rkBiFJj6C9NJU6h7LtROLYcjEaeZWjME7xWRzekUxFwXdAF9BhTpVeUbbKKS0rIl3J3pG0tLIPaalje4OLbfx4suFFERjXscwygJYBKkV34lKXiiVEKx3wf31gE7t2cv34d4FSU9s1o4DLSmtLgpEtEEhCFC/1h39ch6RfgJR1asdCUsuYtSf0eV6a49Hqp2K6wvBR9COpeSwf28BZj+t1vVgq5WNifZNCBLQYgtuDqmx/zqDOjvBj2Ax3923wUamJOWllUI80+XaTgaWC8a1msZn8OBdX8lKgNJWL2ZA6gNR71tDYN//mvLF2I+9Sjw86gPkypbQwAVRw2nC/cb/lKulHASj0FHUTINpxzDkWDHUpr82h2NOS71oE8sIdqjonYAWE12DWQsDXMEE1UEIa7PVQbwnpGOnN0KPMVFS/paIbAVT2r1J6fp418QPukcjYtDH/rd5fW5F/Se4ueDFDR5sQaGMbT7vwE7tgEcmxN3q2WKPbmGoRyJSLKBYE0eFG9muEOshjhLl+WgF/SHxUioEpnV3Ly67F/OhW0D3F+cDDxnizPi/9+iZhkt/gm8aHvC1GYIr5y+wZ8Rr85PgCWVsr+xTPsPcR4glY3e8iMmtUUc4XhlJMB8N01j/pTDBlwsdzU9lQIEbiXMHisDt8NXFbUGnXj9B6uEV4flF2qE1WX+KHbeVSobp9sdbGuEN3r8bljFkbOOadp5giIPaQ3dhzGUaL9uaBkWnGW1s7vkwgUxxog8kSCojE+rk+4G+Y3brdCo7iAHiW4qaJ9kb1gLPkbT0xubX/Z5BpdAjworLbXt7tFocM9lCmGTYFHxJxeZhPeSOzKZmjdQpI7wPV1fUf2V/CyeJXiPbLxS5+ZA3/32/Nzfe1cSOyocNRR3GTPCe+G6g46C5BFCv/nubaYBXYNCIbBb3/OWEF3nB8b1RwCIK3iHzGbacvFZdwIqV0XyizcFq6d0RBQ2DXHAV4f5uwimVHV1cyvIAIjtczK79V/dzBWiGfQpcacg87WhQnk2r/RyoIE5C5EinQpYZgnj8HxDJishXgfge6fH6WcT9XAOSorDeU+IB/rVnessQrY1v2P2lGwjphIFCqIBFGh5I6p25/lMCpKBAXw/d9CSYqmcbSmhIUE5/7HBAI72EzdiJEma9zflsU1ZeGb6tELsQwVazOFmpnvLiISjhp+3Uc1yDK8sJVOUDC7vFhPpHepiEIkOcQhw3/9bU22AmpDGWTAizkyUmj6huomvXVjT3pl2kii3DfqVQzZyW6z/div7Je0IbSEB3sS9alfuU1h0+07dFSDdgi6LWV0Q2p1XmucssOR9aF/Pj7PbefSwvPhyZSXelX/qEjxyNr5+cDRzKjOZ6YChh2hhFwffDQtR39DlIQW88EQbMUiTNBgkJzCC23SVlQkNQYGpszx/VZjYod341Jk4/bm8NksNxVfh0ahQ6tWK09ZGe8ODRrTCrlTuhRYMpeIYzQgachtajKyK9Dk8rO5M8FgUNNcNu0haV5052PjRMkqWNNraZWL5HyoBOjuOjSGPEvRl88KwW/ZADBEHQ9+1Toh1Hsf4JLNQR54ZWfXiBrvXBMVIUuL/p0+GQJLmSZNosnzuNUfmP7DF/HKwC0JBJrykT9scTKLVLG0eS6vbxWmNso+aVDmaqPEzh9LuY80PhlPuLpM6BTF73VZKAbl1wV/q/nuRFnayeCKJlSev5sDkPVLwjUFDMyY4byy/Dhd75/jKVpsW3WX3AhBlzsUC3Z/wFRnUdxCRRWWo5ogxzfHMHJkzN+ENrrtDiKYO6z1yIBxrwqLllEoqIpiI8e5ALmGMadABuEW4JfHzhQgK9zfXd6ntFLAS1jY7Ka9xH7mmMcqXFWfMRq8vZD5sterroBXZehGZHBIQp5QoBrTahVPlUiEZmlx5POAXrKOdQFUpr61P4IAywx2iT0ACO1lGij6x8/K//Is6th8e28vo+w5ACunYk2sZVcz2uwt6exDIGmeQRd2Dtan6c0E1gdGGt1Q0HnvzqUF0u4A4ebMw/HDiDvQtFPs2VCJJlczJaUzMWOUB5hhnE0hLkTos6HkAzT9a3eJ2WLgNnZmo2qNX6hiRWA6aUPcljFtGjcKGkMGkh2ArZQzpssBCEnbA8kt5Mr9uSo17znurzisYNg4sKo5jCWYvBklaWbMtEO08CQYQN1L9Sx7d6kXBuAmmLwLkAVq4j57ciGYTP3IBe009A8PYGTGvEj+tEXKh3C+AQ/9tKjtpHKvw/JBcDq5aTNCuQlzVgAMgD+mjHjLFEk80jr19im46kxwT31Qb7GP7hQkNO28XO04eSIyYGjo2i6EHekDabRoin03wfNVyLNnwBlBOqLQA8sNyKSA2j3d2jJ6R4i2Hi6oJh9IrpC2XvEyny+QtoBcLn8NfOz+MXXJ0LHK/Z+VaLHT3UdGygSnH7MZbBMETmLYYzAMyzrPYQHLx3sH7t6AdT1UlxzrJ4xoIAufG0SxSoKPsGjQNWIMXOciLhzSp8Ohaw+QdxgJqSB2s78U3O8Pq5myNoDvgFo8goaeEOdKLtKAPJFLCOyHmqGXuU/ElP5ybafFbnuK9QM6rO0rI7mFopqHbecFk3NvfEDfuqK+OgUxq6kNhYnh7V71TFepqkBWn/gffEki4RNlVxpQspPA2I+n7ylVcNdcUjHAu/H6I7E3o4FQX8NxYhtB54Xw4pAAU3SKGjW4gDwaoiMhaT4eobhTyzM3JZtXkYVn+K8gbqF5y6ki79Li9OlPPjIPTF34q8F3V4yc6aHt5W+p5HqJItpHwUAqA2nc6+C7Lakt9SZUAudiSXJP+3g4UFN7mHKyHly2bmxQqa+IShJ0vyN1q20/pNp/bO2nNmBzAYlf/HYE6CbLdoNpw8eFwN5BgAl9retRRo/g0N/RElWGdczzScBdE8KA4KdPEjCsOF7HF9hVhOKHi50cF36UmwxN4EYuw8PfSKIDkIUrc42HKwWa4DmU1AkVEfYGEJNc4idlPB9EZFOZvn2hkmtYY2mbsnN+Oqc5jaedBHPTUOH+1F1SKSVQ2XkqRw/W7RX5kkdAKyWWnpeZ8NU5YZB1gJh/8eCTURfK74uwtqueAUP1giplBkorxPRfegTwcXQ+E72ISc52usLijThrmZWvT+8XzxLd2FMBobXbCn5uuUOwunoxwa4ow9xREYqkLYNWtrSrQg8XMbLCoC+KUHu/Jzs/5Xa9VwhQbnmeUGfJ7hwzwZV88Xgm1wMN5pwnZ4yOnLIP2tGl3LHiB9LSOasIrnJynpZM3HC0LoHKZKdi9Y2zcqQPXF++kV4eiBnC+b1jx262WCmgQpJC9br1gkPzIfAhIndoeJYUn4YfT6bfIiAPPf+rFfvSyYZqKGKzOQHFHlEIrHL70Rqt/m4EcJaQSZ00xcK6dXLMkAAwpzhGCJfXY8OMNV/10idEtB/3BIDyI0k4oGHvG1rQlUan+RAtfzy15VZby2XryCMUi2MA0NfWYPPryIQ8zZcf+qdQ80tbWXIixOHl/aJWjuok6sH5UW7yma9pPzLgFykJ3sMC4caZ4mBUNZLKAhoIZtspvvSRtm+2cQFrXlKqViT1m22T44OUHWkBoyc8S2OFvvxB/ZqvVraCtrJuUJ0wBtXtIY551fYvm0Za9WmCdTba2JPtakqvGQGJWtqQ/mYdMLcyHJCreUOmYwTVTuAxfOoX1jSMHzNuA+hDKqPwbBMe99zaomQMKqKSM+9zHnG06zTKNfn+6e7K9zK0NYvvDWKzTgewaYhO74xQJ5U2l4Gpe+a6bn9jb9zRSp7JqpjUAXHxraZMmYOEn30GgJF4N3EQ26pvxb3jh6gPjZEtKU8Ml2EhT6tOZextG3DpHRXiylGWHkQZnvsf2rKVKoBr7lhStu4XcNmWv4U29kmhFH7L+O01U9IbyZIpjtq3eGSnq88+VxD4EwB9MvLP4GcCVBAsa+sUIHe7Om6ILleWythkaKcZ41tfmrHgfPIWAUlTUirHKiPNjaigqo8v70VzXnwvCfffAHJ8+/o8IZyGG8CyQyCVwTSSu30bFPupKPmTL5zQMcBWah+vU8KRuOZN38G8KgprbbphdR9t9bWQ4cXnRSGI1bh7lUARua8t3oY3YRL75d5rnkpqPQdFie0rhXbZDUhMJSW2R/DnzRA3kXx0U/HYM8t2VtGIjZ9IsxFxxqtCs/J68YavhysNQI/IiiDZ5CkY2XVJXdVVx80eY9BvTP2vN3WNSJLyPywQXXY97VTRdrg52qlHlUlbGBbmalJrDd2trtkGsn+1kVuHpvpo4SBEJ+YzVpqQzft1aKsNA8JUDCy9S5S9djXbILhW1ZlbJ1AdUU6dXTMA6wS8v//6bOUtTafkw2jpTVYJo0tO3PEB4xgd19YuTLkBc+YpqEFDreTrCgA9obKPRk8nln6IVVjcKDBCH/ntYV2VakfHZ3FqDCDnk8i25nkzsq3bfLCHog5d7yGGtGpOjYF4opYUSeMTRlulf3ehjI3R/Gaq8p+vc5NcPC3iewt2AxwTyPa3tQ0BpHcUswRsGq+PwSxVFz1mxumn9oX+xU0RssouN0g0r0EKyUCkir6uW5eGssgyuPg6Q25kmqR6Fv3J6LDv+L+53UY5HdndfgnELmvkmGLeaPF0/1Nlvjr4zzhFncjAZexCrD8Uwx8GDnrNNApFsJgH4Y9r2BtMyYQhqdTLQVolJXKrU1hHNltjwnmtBPriKk+tR9GO9UT49pmiejwd7jzOtoL8ja3O/T6CRrhYu4AyrEDccYcJtonK1tfYifqQ1ugZZkm0CMMO0Urg8ZwYs6GMCWm7D59ScfSki5BpA3WDWL/BD0G2WZr1/KI54GWHwy/zBoPDVKB6FsSeyxSIBvloy3sEKyPwFRHZ63JenCFYEndRYzvwmT5GNyV19BqDoBlkVwaUtS+8lX1qvUBgkixRGFkMs+u7TKUkGHqbTwYUR4P5s5Nm8gHJW6bKL6unShq4F9Hqfz/GJoODCSj84ww41NXzN2bH8b1JRRrFQn1m+70Qtej6nM04/uXVldQlrhjSHKjUbwJFmJ2xHz7SfkyaSDpcKUFgxUpn7zHj3XLACHvxcDWWH0PPrtrZhMTeyq2hgdPCtUEqlij1m3tPc77gy0FXQhCOnc59XAN7B9G6jm24AJ/IabA//xjY/zqF6EZZk0f3pDMNE76VE2/ka22RGgyoWXLn4F7UqmtQn5d+Ag4Em7vu22iIb+c076J0lfCB0Ei/dVv+5nSYtijbBio8xfShu2r329CeRqYRDi/egmGv/IpX4apmPg8BiT7jgLZ4v32F5KgNELj6/FbJROqU4zvfq5bsOEAuT10rsZ7c9VrT4q08MrJYz86VYo96Puybyspv9+dI3ovzgijaILggyC74NK9wBXzNI5vWbXD/TLhjLyUwqFHjyA3mZse3RrUprybIHOD4FoIChGJCUSNxfDnPzAhXk1bHpv1ZCS7O92PFsJST1LISdT915+asZoIy65xOPWg5hYFfMuJtIf6hcUFOQNAgejpEnyiBiBtS8ZQaXFEvfC/o+EpZsaiPF2m1D+y2pLiQhUdJvenHTtpb2xHCrKJ66Dfe0BaveiBaoRMyGAUXpT77zkpfwW4t+EZ0oJk3VLa4flFUv0r4uxjoNKgCjxO5Bm1dv8yZ1hyrhAK/HejH33c9uU0HoeXE0El/Rs1hecsIlEmZGTXzv6m/ldeIQvsLsIUhUmDk42c/rtO20f7qUF/tbOu5hJqdnsJBVo6Nk9s7j8QQiSmXtQ4xJzpNkPj8WE2Cw0xjYIdrmYiwlsalfu+A+8nihmMt3s9FI7hKqPdF/wEB9+GxsIY+ljFduk+BaGzG/g7L9soupTS2sQAqACM7uWlLnd6BcUtov6sxhI8H6rPUIZ+3Zxk41hK2/6Ucv+IQQ4lplvYwdBUYTYGS2pOn5AeqSyetvvwX4d0tSH8mEIbOdfokELO3S7R919/MCyx7g5CzD/tU4BFAcm4xK7Oih7V6h2ibJt2WNwiroCDksulcIWc1sv9ER8kCoUNSoa/gfS6Pv/R8lInphcKctG/hBtETxxdW7YQ7Nknvg8Od2Ik8LCw45lJFtpQ8MqbJ0ILuofw+g5/nS7RFvD+v+M/hgFV8vBFwyE08U9skVv75cOjRoSosA8ut1NpP8rNXH/GTb4v8Tr4ITMmK5T29TrPcdAhkIzOEn5OweFyVEkrLIlL9e7Pg961Mf59CC58N8A3J/VvoGVN6M87pHWQAU0JW5k+wzBq3xhhPO9WeBj2Kr/9bSriW5xsrsmN0Vquv0BIDknovdmNRCskb06z9UXW95qp+hEodOUhoQu4yymAzcYTCi6m2RmSAmV2A8HxFZXPi8CYlak7iNwA32WbwFNg2Q4IZNh0lSwzkYPLXCji17UJP0MEb5UtTXEsfoB1W1CjmCjf+4z4hHPne1oTrrhwgLTixXYjE90OX8t+7T3Met6CXjuD8jYC38CmpWBMBrhfNacS0FKxImVSjKCQqVWcHojkR+VAU5UPMJ5jj/BhgO3ruf4Sr7y8ewhAv5Ty2bu5F2a19iZ9K5VFYcQdKMfsnipVqwDyyBkCP6qI3+U7mw/KPNKgLZSYmxDOgP97Vum/UPpusVGZ9ozafp0f3v8iHASrX3OVxgvUBwvLmV1jTfwyxyMnQwiEjvWFLQrpqQdbGYTI1uv4Xd0xGap6hv/xIc4MsLmDdhnGAIfVyC8pA3UVMP0I9ywWO8qlnI+WOdR//yjAT5ggUv8Q3nN5R8mUhr/eiHnNYax6EXswLVYMW7KO/2sa7Jxl9fLYPtm1PgVhgCyuiA9LfcqmWZw8bGxjGkr7t+Yxt7PhuJZIesTd3s4Z7iD1AdviHPvEi8xOAj7YM4/b+ynsl5rdQvHHw34Ryzc7GrLMq41iH6g7LzZIJUsUeVsAVKJoxiFczoAB/XCGFvvY120PlxRBCSZHvDDvNe3A7dbeqofM5NzfmF3Y+1X9QVUGvYsIiVVvOdHiDI+IWll/cTYNXJwCgXRDEbgzgJogtRM+Sv3pDKbzQtSsjiki6RsOqrPwgkFS0tN3BgfGDmBrIs3TpRdbHRoQANAHOS/IsxU36bE+8nGkYZfixXl0pnUpCNxk4ICPRQa0BcExPdf4wmExn7XKVoiJh2QRJw4AWTHzwFugMEmufrt0I1an3X9EoXu261DWIjqP7p1M5MAPeNcg/uG9lPmEHLeNtJLnrSNBiH0pm06ia/+CR2fpcffro27nf3LRaN9m4xnJNbxKycccjcx8nUnXrlrnhxa18Rg5hirAeUbfLZ2iVGbOQr8uTgvkbzss8Cbdh42pzMttFQQYZOKcrHAgmvZOKGR2pX1USfLvrV34jpnjtFDuD6/FgE9UWh0suEOqTMGQSB2qHR83Q/vhkQmDQ3+TzAsWl9q2kXiGN+Q5Pk+b0Ug6o9pJKYaj2AFbDhw70+8h+SH2aLZ869vPWwJQ/yaJBtdWSfy/HAoo5W2lbomGi3Wzty03OI8BM3LaKJG2zFsZ6I3C6CusQzR2lMpyMAj+w7Q6lWj+Tcm3kE4hSxqqYLovqdJfHQIctm3Z83RYX+nkBf/HY/gQWaWc7cCSKEUJW88SuFB8DnFaYzslBaYHKG2InJJN6OWISRXGPKaBV1wmoVDBdA4zFL9VTQctKQ3Y/gV1/FfsRcXW/PVNciE39Q84aJfdUFCo9Yq6CwHSokNiXiDzSpPrYsbqAUtUH2RREgD586QXISeeABW/AfwzWhZFErbr1A/6nb2fhbTIAJUs8J+ofnwSlQlD7mFM85eX6KTK62p7TgyWK4fgnbYpBc2DZdenEZp1+8r+REGOwbT0tI6mpIqOC8Yav0ZUhxuxWWfSIyHI/8XFgqFzEs6AGqFak8LYfFoLB3ybUi6Tg5b0cfDkUtPjeeVbT4089IOEx/rgpDHSB9RvOZHE3JnKokvLbQPCazDzaP0o2chNheE+uGevzomGly64YPNH1sWxJDZh7zkBBVq2WPpr+ABj4dOsWJtNUfouHkG1OcStZyJ0rNCmAta0hRrMCS6SC46GcNWlnT6wwQc5KzrAIrUPj6gcosJXq+tlN95cl1AamP8XycKSTnq65hrAHTE9UxFh3p/iuBE7QvlhGAb28jp/zdEeGrjNXxijsdJ4hatDRHYOjOpLLFjFOeQcNAbiBj8XGGkC5bmQ/bLIRz6zE6mcWgDK+4IywMz48mzW7VSplQWxk4Cwk2WXTSpMlOH3WqP5/I5DVZz3XOzZhE4Q4jcp+JV+yFhquikDVcmYJ5c2UcQWF/cM6dbVETEjmTW+wzPr3Xs5D4QaQ/v3e9cVG0UW3XCP2ac46SDV1DlTYsaxwqDpsLgfgCg/kIVG+1J+YkKVy5amG82IHZe6kDnYyDMyFv62GxG2zBrHrnWoQJcbyyjqTrGhAWSc0lpIQDbr9KplB0hjV3GxSXO1etxHlA+eFvloPH3VaaLfDpOHGb34yjam7J5m9yuSHUP1mz+9STEOrHCq6+QddQhX2bdRFbVmglHzfFWrYItVMyEfaOUH4+a/2pBXEW4kzaSYb0Z7sPJSVDLDOqoGYTmjNbVSbymWSlt4ObIC/t2BF+Rk58NzhF4x6iaq2OM8U8KWA9/Z8+SfdUkcPgoxM/hwrDMQpmmkso4qk0aINHOy5P/vLUN+R8605inc1UeUeODLwRhLjlGkY9Q/IZ9dPlSX0KQ+fre8hLfmjp5/lGK7Acgzw3ihjU7V+d/R90nPCdIDER3u7gPH6+ommst2QOGxp9h2Ns/9c4MlX3ZpWhMALyuvht/TtuhXbsxjgNenAhKqfC56UVbsNWWZHQq6diW8KD+yY1t0Cv29+L0ZEIGrg7UgdUnGAXzL6ZGDgbIRV4bsipmvknHgJ/QA+7W+ceapCeEFUVdr5UJimXJ6hNorL4jpsHIq1OW5GkZmQtGemUMIyk4dv8VrxerCjSmeKRhjvoDaIImJ2gTbKsjz7yyym48LQTh+EY1Sj14BYR2GS0FnZmAGIjaxAXl9oFF5S5BS4Z4FFzjPBNUZ0bU7U7Gxw5uEJIeo2bd7OqmCKCE+OtLKw4XJyZRvIJMWZ1pCvWjjZ20OkcTuQ7ULv0ODiN9Tl1V3gOOaVSKWmJqXkSVZybYLVet1hw3oMaHH7nW+Wl4jP/XjX/zv4JJ0atfa08FqWS8l45cJq29JGbb+rXITsXdrhRYg+NZYi0o6/IKJDvFwfREXE8PiszaxQWV1prP/F0Rz9xcxe4fSkAqpLWxZ+nw9Jxef8pqVzVy4Hvh5iok4yq93Zmr2ydtVEJFiKSne/vmaCgNcQ/SCzyErB8vq0iWz/LAmQOF65ZnbR2N0MHG4igEWFLH/3MnELAOFuFzw9QUD9eEfXotQgqoX74hl6IDW+HI0vj7rTfAuy4uTg8s4vSi2VZQuVtQYVPyJLF3bGgiV0MUg+qvjVQy8JS70LoTbJhvLbVvZAM03/8vhTnteAXrDWL6xUKRGtZ69n0zlBWxOAShZOJ1L+8FLhVdZnB4RsbO9XoYTda3tqKEUdKgcdvwHB3wWqCXCmkhI0+oCnBZ74TytbRyofGSPKSTMFFG+/QC6cAdxrLPzB1hd3wqTjVcFCdREtzz/Tm97tc5DzfgNmPTFWqNFPazi+FeOj2hI+VYoEomt+Zmof49d6PsY7cO8Xw031kG7H9255/KE7QT3JlZopFzduVUQgns4z3P/F59ncHxR8ExRb8y2COqA6uPem2hgay0nb2QPYXkspzKrdzZ/fkmUC1zY8U/hhczzL4wJBrWqQjDMa06OaofqhjBJNHl3e3O1AstgfXnuC14GmzEASE5TfMCIFK4wvZ1TJtMm4Yt20gCc4JgjbFLRnBFfjEVehYNTtDE9UcYgb4Aj8350mbw7ZdYy5y1mesF3VdtKefxar9jBuIA1ko5sTXZriCQMhSX4sX+B0qq1KyipYsczMYLw13mHDs2xY4Rhw63RFMXTMF86A4io4T/ZL1EzhYua+E4dYI60t2NBEa2WxYLb/pS0YRko162AhO019ENwhhEqh0p7+GvMM1npFxEYb1oQnDffMxAmQ3mSq4mwpdPcKoG8DI/3oyqSpfIC94zgKGdceoXGNtabEpwcv0oU3GnsUKk/hhlv/DRkleQmI/rStb5jTjt2lRwAiZchR4yhmNkakdAelPHs79tb4vS1PxXM/cJb+1htaygmVrbDf4ac/y8a6IJaUxVTsd89pBZ42ZcJmnBXnw0QLZwmgHtkbeBGotM7A02w2EmezvB+FzOmU7jjEGZIxJ48hMhej1iNzU+zwgtXOFI3TDORtjBsVeYhuLCyUNwFNdXBBf2xxdOy0WLgnKlquskZ+XXbkDZFM5uWdvGPpVm9E07Vkj78OAZOlsb1+RgjIH/zV3DUvBD0AWScvP/0qYk4ben/m5b9nna0cNikRremanNOT00lrGxkiKBD7+DugrHllfzBmmgC19AKrQ1+j+1VY5o8DHveOKoUqMJxng+dtNgJYJ7chQ2yxGOe5aW/dRa3TuF168FibksimilhtJUAraXUl/Dvpv93JtApd45AfCcLHKy7Ul2Q9RJC1SGOL/Gnspc2c05zxUi0LLD2i1RfcF9M0/lM7v6Mt1RSHrNu4a/l4ton+waNFx2AbZyofmj4xO+lc0HMiHB4u6Rgb14e877pBpNnj0BGLUdx9XuXyp8h1kM/orzzi0IgPVFMs8Rfqh3gbxH98aC2i9vGL/LyMshmK1o8Cn7NNXRRqgAkIdJRyVdC02Iil3velVswiOdAjXS7IHR/fHxBXIfApoIH8wPBDpgCwNDYIAzbx+xRgRch4WzAmeTGqpWSyzxJMeYQ8A1hGEpvsZeu3SIWxjDM5lrVqwlUf0FhGBfghzFT+drYZ0d7mVlsY7etXSkUm7ID6b68TUBLgWQ0YZLeYvgZuwNtx6mHsrTH2Sv8T+X7ZWyMU8eEbTgnl+Clb4fZHfxoxFwGtA/e+NQ8OyUg8D38r6e02mgliH9NeMpsm+JqfOzBC3BR+TnUYAtPPI0nede8+qlRSIVCouo324+rlsNBoXy8ltXeaq36AdBK2qHvrH2fmeMHq+NtB6hWIBFAnp1qZ66gEqRwKcQfJOEWtD/chfNzaz7ntKJ4RU9WizhhW8t4PO+Ma0N43psThweun13gy1xHPAeaSTOG6rOZQMt47F2dVKkIfulT3R5Whs5oNPAV6LC0y0WH8W4dJ6ywlL3R5TgO5axEcC6vPXGExpEvcfsHoYmgcw3awdY69vuC4PzO4vdz4lpBa2Yof9W6CV0XuJCc95HPyMMM3bedzQzsl8KwqNBxq32B59hFCyVwIDiJ+wHQu1D/H4F9OjsTEzMzBjv3Smd6Ix+BnOAF/xrMj20gcwNUoLHYuvNMEngr4wqUHyUzvYEnjPl+zn1P3t/sFxoI0dSQ+NbpNLHydyPnwD6ZoKpv0lp4Z2Z/GCVonDfFR5voKiDrU2yxDudaC84hfsp8jJOREm2H1uvw36A8v9EHTAFNReJaaf7OcTV12BuGkXGUyfgWxrCHKbmRpskSUsc5aNHpcbxReivm9DbNK3UmyWIHIIiekvsNrJt5c0OAKXew/0pLSRQl3GurrDnYjNWnxv4Ez9KFFlNOY+C2ESrfZ9UO2gt8b8GbxFHaedEAyQl9+GETqkazOnbPzP/AM2BP3L5Boy35KTT8ACBytQ8fYxmehAJ5EMPbFDkiiWRTrHfBr28rHNerp/vEz7eDRmagOBw4rSQp/Pd4HpUDr/euwByhqtEj1SwZzduFxecl4SnXBrugh21ghdrll9ZIGHh6LIYI9aZfKqX89ByPQF4eai3fbixJSGW7kbcyH/K9/dIMGnJfwezEAiI71O7u+RP5A3hQx53pmR/8mZVB+GKHXW621cDriLTT5mzDpm+6MguqxVQYKrnN5HL9W+BvAn1Cy9IWGKqcg0R7Phv7hw0r+LUlCiqZP8WfVKUfKTIKyrh+HKncTfOgx0euV56zjKRHibmVBEpCCzi0EadgA0+ziys+BGEFIR4et87zq2akrHvC3Zoz8a8hHUgX5qmc9nWDw5Uo2mWZ5pCPnv9xVEboSR1ETj+OerW1MGbGevNPBOwdoo/6zClCoujokBgkdQYrGaiX1AD6tbMKf3Y0F2EIQXY6GuJIpjCl466ypRLVtX63VXgnckWTBA+Gurer1p+IDd1eKAyOmekfGDOOAFMLlqOKhJ3iX6AeK5IDtFOCbFH+BUezEPVtZYscFqQGQ7b8WysX//25tJAWVJ1pm1kDuCVKwMghBJiIo3/Wa+sRBcEb5K9uzc8id+4TU9S47lpIXXsMYugTAEPeQZ36dB8XqZVw6hHH2yFHCROORH8x3U/xUJ1I8XjENuWwkwFjuK2F2XGIIrYTElcxfRnGqngxT9XWmaBFrByp9NgugJ24ESdPHlIeeduNHSJBpOPCMEH6wkHXoBVBy8HgJBs1PCGEi+lffbO4Z0Mp8xXEBeeqVt+Djt/Qsv99R54bGrPW9fGJ086O2ddHdJAaahCSkedV3iwVAm6320BOYeAc5qEkA3DkJJXb2pK9eYMqQXhvDrqSn0nd0zJVu6qv5QSXUD+oe1HDSTJxrZ9O0A8jyhJgllaORPZGD0UdNJEmNtvAYpfb4bRYfd/LLU8WDpayWmc96GZdWlDbXbvcjeMFgAplF8YTtGRDn4YOblFoOUuKfyGZn2uVPtnk/TxCT1EjBaYVefIZAlWvqlfjYf7Ud1azjsJ81kfo98KNPdNuWrSG+oECZ/nCUbJGMfvDovFLPzdh7TIscc5Z1i149hpu6uk8LHDFSCgoZqC/WbhZNzAQrCEnG3DRtd/NGRdFxMUznSlR/TlJPfy1Q4+jsw+wVcoTg1Pq23sXu15jdMi2y4DZwZhDJHQ4n3vvzkSW6cs8E+weCRO668+hBSauHMXdY5cYxzXmeAkQHpC66QpZTFc97wZoeMdB5sK3GYeDzb7rmrspcoMiqk1vvda9oyctXe4ybFvGxjwR81CJvhNOgZMg5d8rvEm5B+f9he1xuwGeVa0YHRwBQCq2WeSBt+SuGKRx4HvpZhHPdKb6SivCSQP9btI91kmLWRxhAs95bBHR5pgT7K+SzuqansafWM2df1Iu83PzOrF9By5eEle5q/MNHKHm+Wl5GJBkMQuwShGT/SjeqTqTakws+beUj8fC9XwIRBCXWDRicf35R5PQsiwM3uwzZD+pNGp4RXCsnEPIXyR0fMnffVFbOUiRF70CWGxsbhKFH4qzp+0zTE452+Q6S6vaI5g2NDgnltcCcHUnkHGPbm01okzULR9ZzwnhamsX6s2SNoZU45VN+oJGnicjZpLC/W/zQHYzkPbxh2t38o9YdOLK5ReAlZLOAZ0O6+o1pi3aC8Tz3SLGwV67M4L6c7K26lNXXgq42BPHY+BJozv2NqfVUfHrr5QX0A9/d0+oJnWcsU72tgm1J/YasnVxlGd+xC0bzhLo18Dn1QFxZ3z85PbGPtAMUXlEdUw7iGvA0VmbFK8XHrogWfvllCUxnNklf4uP2XMqDyJ8KZCtC49VjMMLAARkyrzQRON/rlCOs38GnLCqoQLqITI6GC/ku8P6CbkyH12qIt9rAowb8uGe+OzE4XcqCifWix4CFdflJybH9nUaFmGVc1bMkqWUiLoD3vrA3EAR4PDdt+DYrmwxkUTxe4OWLdAh5vY3kHj8p47qDT7NQJ8Hy3l3z4GuLumDtbRiTPKfM6tfa52pLYJuEkR2r9SZRkgL7F5MAeBDGw8Dg58ReypVTGc4RLuF0k5HhT5s4RxuTMElUKtL4sFYFBddUhDz8QJmthS2OlSN+nLVJkIXm37YP/V5JSM5uo8sQG0wRj/61sQIU2HRvBw93/MQwNM57s9LTYmhrTD75Fsd3wDnrPbr9dc9judtHoUSZVk4QdqybQnWhvVo6PYWr4dPVfIbHms56CUe8DdIQ9k+h4eSSn2fHgcCW1Z0I3dg/SA7HTUDLfMmS0iL7ZQ8MZJH7oEbBTg89nQYMk4mpvORqjLPcRaJb9NhbKWQtUFgHebAaNQAE5SA/V83fYpbHplSeWopDcwDQPRUBQZvSDc25jMmLxJzxhzMKRgHpl+pTO8kuBG0Ua1nkjDgK5/Z/AIMrAmknXYKiD7IP8umqRwIiXylJbrvOtqxHYS7YQ2NmryjB+3B5vptbnaLrr+QhY9g+AYu4C+AUYk4aidpqPg6oEVbOVQBykxn9gBmqWDX7cZlcIaHUARZb1AqFmhLN+jHIha3fflWQjlq0BXLyngtX3IgqlQV8EBFm1ETaefP+BR4VApzMtriXIxbwZ77DKYpcFlxpftOuZK2hZB+OQjV49aMS0Gy1+zYVqwMctu94XaAXH54guiMSbQqPiyS42t4IVmjm2kcAxaAHLt/dW6/fYmWN36FfPYLQtjkQxiD8+dQ+FXWZf4jGbnlxl9fL6oxAUElG/bxp9in+li5b6AeAUWsKludHMZmmAA9DzgpAGpcWte1vojt03KODXdUhsVnXPdTQLBr6qxmBiyo4HOgNGfPNpvqI7RfZ6jjRiBz5KUJP2dffO/qjC0nn0Wm3DjG41S5UWhW9VI6r+y4fjlWntbMRYawZRsUgsZHsg/uKn3LPUhuvmNgr5dYmxWtL7r9Wt7UolNkjATFTPLN+zIEpqehg9z/CVaA1rlvzugXJ0hp8uZlq8AgPGilp6a56OCbCiCTiIWXMXRHWxCVZsJe98tyLtYDLjLWfWwxbj/I1vR1ag/E1g6c0vDyJA6PuUNm4bT4/hqlU7F7jDhsa0GKbOVaeUQLZ/Zg/nk536fXGvhGniwo2NuNXHONWL4D5SXmIFgKaaEoUzJbBQnli8CllXR4cir/VvdwkFb26PAs2z7C5/biwQyH0vX/sQjonZgYYueVO0l/etFD1rOXP8Q75Ru3oiv/YCDLXCm2PeCtBonZn4Y5z3YkgFQmG0ucgqIKBBIypQgrpGG3CGlDVjAxWuXl5iqtkakAsUTTuxWAXPPKw94F6vQowbUPki8V9LiNHEhOsv7GimdteCag2lwuD0lLjTO5WfNpvcrlEB0ZWpzZqYTGRGrsFiryVFO8utF4JiE/ojUPGcaveVgmEhrEwo4UHpVrfVQ/NHkOi8cndzDcEWDK6qjcrWXiRrTCkjoYGXenadt0bGlpp5g4skrx/lpRcib1aXA8oJVnl6LoUmRcU9Mr2B25+bLKc6IdnzT1k8+sfItV73wb+6XjDreECrqSkfi7sdxPQutO3bwronW+E3NR5s0xSWMvZkOvxxgqhPH4F8+NNezveigOZSd74XnKl5ACWBuBvqvsXxqYR/3q4NL3sG1teJuZkwRPX3xylFLsNQ/dLOlOfiB2OHV16jEnMj7ntnDSNqaP0TVA1W+Y7Ozx6Xhl8IoNPPIHIBtlpbotgeFL+39KsIjkxXkCJC2Mo4QZ46mnJCiy6R/bFDygI6Z46I7NLN5Pu70nbB3Gvy8Y62Eaw7w+09cnbgtOSaREtnyEjFv0kpWtUx0hSv01L2rL9VucTyKZoi4qBdEhhwUwJgLIvYnZNLoMFIUDXH/6gma1hsyxp6lSe4mWSJ/Ke8JLL/28eYAdjPuMthz/a8EkBhOMoStD7h1KSoQkMaGZQHlrxDfUuXgV5vs+6/0OFyuEe2L0iy8qqcg9TyX6Ci6efx7tSHXcX2zMycV8kjJaT88UjgpPEULgFlvBit/HEgv6gypIy9fJyF3cB5buHwQDusVahzwiLJh8ZLWsUq+4I91GUc1VzzlBpverFG/A9hEe5UjtfbVR0cP6QQWhIJmutBg1LCqFmAeGJWpsaolzEReU2H+IlxAc8KWZdJvAA1V+pYbi4i8H+9QzvLZ4Z+fE3uKjvBA/a13pJjmtfv1VNfKRl1VmAIySrkglfkiqpB/R1XkzEyRwxax3QcFFm6Nct5Xi8ni/Desu2Sr393CMghwpaDTlvNaDRgkyvfkv3pA5awg6s6cPzt1sN9bnurHZH1gkk8/715HAYgkT0cn2MaSaon4DthiYPUSHtYimSsiZVQp12Qx4udY2atOWskw8tq+AFkBkwulEhJgATT82Btae/HpP2zewrc2DjyiLtq6nv1txded/GVGSeiRZP+IAckfO5UX9lVSKNb1gyVkZpTsFGYMBpyX910ksuZvKioJ0rm8bsO+VIg/hQ8VvNSwuU0EsiFKEbIG902FabU6+bE+W7AVLP/CDFUUUQcE2uLNZOKrsI0KZQPZT7Kq1ZiZ8HcLk8bgq0xGPQpgGLGNt1CCiKqm3pbWIzyNfCSHIOoHdwQ0wKtpDuSlH7+BDyPwahDVri+oG//jp8jr2eo/NuGZhgHPk9MGUiEI99fhSTZ2a0kJRWJ8TE63O04n/0EoAJwceGnVouEtlPaoJ2kaZ8/Y6AqYKxZ+a6VD3KstEyq8CZ6LWBXtLdaWF9+/9HkCMQD/+vWR4SVgWYFkAzCFTr7U8NawMr/gUtF4sMTHUa+JSqPGRtE0JBBbP6v6Bj73Neq8UP2EokmbMDxVw6p6+YgtrfXvSNVJkFrE71gOirfjtWvwDBW8UrSemgoqbPS8y2x3vqcC3d2DFIH9ergny06U5ynM4f5u84GygHM3V7z0VgWlF3Iu2E17EkB4nyvpAZzYzy38Uaur0ObvGuM4jIQ5r0+X9sPRSOvBuNgeSzuogdUeQeoJCk5A9HeWSIKM9ln1gOpIUoRYrWqr3BFWjmrwiYgz7cVQQAtCyd4Jgt+oL8xgBtOaQcGyzGTkDVn/CrYx4If+V2lZj6CJupioz5/enpw55wIgiMOCLv2iO9F1/cQI4IWkfbbD1jGRev4pV3jkgv2TayGLbxam9R63m5PmTUucj884EsYLKL60BEqjZB253gEK40Lx7kwR+bVF2abIuNRdk0Fg7mcOKhq5Oqd1Ca1QqopEnnJ9hniSTPSl3lvAQ5pzOKvdJ6kXNnrj7w6PNZ0xpdLic2hTMcKbALtfQMZ7lEJxNrPGnsb5KNf8CebEGkYRnCFiOrMJj97juNRsToT673LIsPCK7uRe7OE0Mx4VwWqODfQSY/FDlPiiEVi+wPcmgwm/LnNu8Ve2E+W9zIq/IWikTMnNv3pu5Zv1k5QYasI0rF9nxvP6covtC0cfcidn5HCG6PWTDNDdIiLTHhmjGdV68AGeTJc/zEMWFxfleu6CRh66jiCPqTEMeuvPjq/Zv7EwGd2s+V5V5cJ1mNYIsekxhZRPwlOnTTObOsDAvCCbgMcDGig/7Ix6DSUW8ougycP5AmN8fISD5StJnnmmfE3nWhkJ0it30fU93MyNCp4Wzj2yu4qTK3r7xSmjMlkcRUqoDWoGjo1E2NmTHb78jQPE5pTv94k54lbb94lF8Q2vyuWQxcN5M63PWj1VEGVjz0wL3cPjc4vu4J97UZphOreF8iEqlVjCJQUJyFkxRK8NQSuuTmnBPkzhw51GpZnGA6y6xAH/FCN/etg5WxtRO5QpdbTuPISi5aYYGnuCULQINTTHg0yxaLuK8S5CLcmlHvi3NNQAWfbEGZ1zEUDmTozQrowsK3AHpaOpKZlUYIJg/h0847mSe/h90p6b4Ofd1aT1Uh5wrgU9l8HZX9mWH1IS5d4TLuyb8+oRsE9OV/OQxB6jICUYeGqawLJXRYcPNdtgSUZ13PIMGY22fy3MKEMM/nzX++VqeUMw3CI7QI5Pdrp7USOdf7vcXEDTdNOVj9dE5GQVbKLZ4O6w1J4frRhiCykda38y1pvqsUaLxfgj8d7QVznqrYsJwbHcukKrt+jRBV8cRdVypJrTeHebQorNQnyq+VJrwlo2nHWTr/hep938SER+UO7Jmyz5cnvncHTZ5rcmEU7YwFUJP0RVRQEqGokq7VTv+0lfBDoQ1ylzp28MNI0HzRG3YZzNOJkUvGHXT/8YIbIGOaDlLzp98njQNDEL+z+UnQs/ODcRqch3mp2S5U1xsyrAQ0aA0u8ZFGri/NktpjrNbIdbTZ4tWF8owwL6eMlxGsDLHZIsEvzI+eeSI9f/h4nsmxTF3/zLjQsmBw5RigQFAusxecib93/KqQGFW537cq/gaGv7QrkWsie/BNfQIu5oyojiSyFRYeOnAn93Ig2Tq6UlXr+x/E4ZHTDirJiF38i0M/r2YiCpTeNltCW8BXaO3d+CYCTwQZWp2EEBlkrGEENWLwN/AkgjGISaT4c1fr2Dqrq78JXHIXpZpPEy8CL1afDn0J0ymw6ZkWxND0OVYIpqx3kO84iMDew4uH76XHyuQi03Ss/vLvKGs870XHuh/KVVY8wQwtKsq4/N05TwTAilz/2XViy1K9zu6cJl2uDQaHhJRpYGZPJLliLsoN6O3y7xCnxqUlY0fMDnfNb+r3KESs26T42ewoZNkWE6f+oBafNgCzg90sMUD2QvHFjV1TI4xmT4RNbwkM5vLVfjFOOYo50qfUqcYfUAjOCVgCf7wgofWlcB3kUZHjRt7oXLTJ3NB1g+ZsBSGedIDamlDWuQowRWFaAaUf7fqUaU7HGPFeoqMSrPrDcbWv4Yk382NjVypXq0EfQSzyvuKCnJw/UocgmU7MlAr+DU4ae+Zy/Zpx49txzroQHd2T8rQX/wsMVyRU6pSbPiSExFm9J9+0cIpAgBYIkYVSheCUwT7Ug1xEd68cnyWifD4G7WU1EOVE14jDa5a4TX30M38ufVU/+uzwTCUkSDCP5M4qnEfdvDc8m9scW/nnK4qdm0g4Qp08MJ9fQtgqErmfPqMcctEabwEIm09ZebyMtT5GxyQ+9y0tURI8bOOqd7nMqANKmJPxdM/B7NVIqu+B9iUPeNtGRDf9iMeWsXELOBcvonOEqFtFOi723ZJ43wsxD0mk3v98kk+/IU0o1acOGAtV3reQw4bS7krC4KEVjcp3exzuhLVCC9tT12Qn12k2UVuivdGFG+KhYLyyhsvlT+jnjtyXytPXzOcTA2WWNPpFv0FDV7rCXE699ycmay9RUELcix/64hxNGOXIcQ2gYnAg5ndPpHt9Siu1eaFxpv480pqbQvsBH2Hq5KprsxBdSF+lUW3AH/tnvAHjGhonjQRLWfdKpqyivK3JP/m6TyZ4KyHdYW10W5yO92Ir107O5Z1FPZBPyzpkNkko8IMn/g2tJtAEIHF5zYh7CiQc/mV9dsYDUqrIazMDMUhpzhF17poKtJ/CqqikMGjpns6r6plpeJXC8zXbdASvWSxKMuy5nrdT3kOcrdN2pB34ax6/usLI/SxxPgyUAiu8dX0+EhkKyzdZQ+NOpKNvaJpuNKVMxR9fv6AhJw2R9+1+XqjN3RXEcrYJqykHliTU2xPfoxP7RUCPcxZctVVcjS94XA7oqlZ8VZGnYbNFCM5aSBx4s+obaivZezVCRSPt/asqW7idVZPoYAvb0Tjlvajn6MO/v0/CpLgib9FoFvPepJfzfFlJ8tB9YxwxJNAEWovmhMXOqOagW20OUyZD0K40FkwopDgT+xnIUexN4ICO1inf7ZcNbCJRwMteBg0RBSM/lUrZCG23OTB3wdQSoWkfOUSCXTyZRe13fwapGsXAgvYGWj01N1GR4JT9DvMSASvild7Af7W33hqz6Kov9XIhRATfjxNdHEMZFrX786N5mXOPMw4QR1SEGpcfGXRoWSWnDsm8jd30W+1crv0qVIVFeWWWYE8IfNpKDceI8KzekahtmSrHiVD+c1HFluqeT1WH1uwNsBDFs7y9QgEkegLPBqgPXtsTH927SDoaQvI2KqE4UUu0cY3bXig1YxI7pu87RON3DprkRGTf33yWnUPzObE7hv8iQex0BlrvO0RyLiqW8/fC1FsUsA/N8kd87OzZiXFe0nUGhhKV28wPR6eAe59LStTJ6Y6boZy0HhFdzvzN0a6E22nlp5yCL+zgdJ4jnvUi+I7F9zTApBJcbP5bmQxX+jVCzWyLyypOIoahIzoJiW1wTkGy7kvTrzf0EBsgo3F8vZZ+LrI16zcIa1PsT0YC2Pxo12hbiHvKUZcyPEoQarcD6TIpQ7XMBUHS29gCMcTPdwHwWQnrS02zVA7N5ug9B5kLlZjmOJzPrEcLpx/U6Ayy3fkXRT7CQzBJGrPuQKH8vaU3DVxM6nDhlx22DyN8V+eLWqUEYquTvBlBWHepJ006G8EF+k8H3XWg+/HXsNOVMUBlblm2AKuYxLnKcJr3jhnHu7V0bvm44OKsUm5yoRLtre1mSXltJxv5RjD4Qep90K6JBRx9U9MbWwpVPQfhlk4VGZnxo9m648YuSCo+IlvfJuxT3oKGsUGgw6hhkEXOfW0FQsxJxFVnlA+HTPZ/2b4wH2+ybAWNh6Eky0ib6PJ/kg2eOvtyZq+Yannlpvmjp0gdwKH4x//Bs4K8Pz4EbaKHb7on2iLlXlH1qDd4reXlwMrs3fd4rgoRmDRyMfRcnM+Ao9SwlwbJCH31wZAFLT//uTOy6uPrziRtK9L4x05SrbbRA4vIDT5mbs2PvRR1xBI1p4TQ8Oq4yx4yHQPoSnW3ExWtClmcWefJN6FEU/HeDrXlpsSm4UJTKlmYTJ/r+CRx0JOeEI+8/CW4UxGrGVNxyL0v2x0TyjbPSqHbawaND8Sm6XNObb81FAS6FmCAsgFUNjdd09yDiGNqnzKegkXkUqAbzYMhZgSBTLy4ppr5g+97xKDJjrjWbdnRCD2JgEHgYhh2t6zCZmFhkrLejDDYaJjzwtaKz6TATVuGluZyU1LwZ52h/s4HCMHMsm5V0B927IUda0OTV21ie/zzOwCKVxfSFBHTgiQ3mtfB14+tA0tES8GTZFHWg1GViIMGg7dbsoV0ExTVtaFSJMAQ6v8HO1eLqRVydpbg/dOyybzvCEvGONCsddt9oO892+bWaL9xo7LoF9uf6bGNdIsbVfb5q5jN4QoOt1Rl1Pfb/Jrh5fOAyJIx2GgAVj2n6ZGGZsZTr0WuVxkYU+X59Cdyy65JJGycyuyfjkaK6SchGC7aUR3rlO31nJJzUyUimrWLy58mVwbai2EzKfb1pnE3S4RNd0keq3rbq0JRHU93exvEMrcLuv6ZJeP5CSMA5+61xZ9zQyaMD8Gvz9H1qZiX3GOIW34vBNfIikAQGTudgzZ7yDgdQhEp+wNzyN2TpKlmZE01n7mPBDFhr570h7jiO4h1hRuE5oiiDHO0nHoxXQbhw/IZ2oDd6lLJ5yWC4Rt3d59QBZWesTpkZz47TLt/jDDjaTERk9BjfghVi9B/l2xOz7h5fo/w9xJtBEcd4ZNBJhDP05zev0ygBAULe1oqqQi3G/k9on/pFVI2748N8KflIaaaLelDDPl3UW83eQK/OVgECSdESTt4SficmoeUh+MQkVc2IBBDCEld4nA2fH0pO6HG3Duf8Ohm4fr/cUMQBuW+DQ2cQs/oKpEeb1xsxL1dOHlVwUjE08T5jwQWpJN5DOeykw1Jee9ugrJp8NpOMU5qXLmr1fU0RjCIv+5lgoNd/wb7LdEQTBQeXrZV+Tiis8RaC7lHNWdh7n9DkTj44vPONJ81Lx37yOMeSPi+Yiy6QYxP4eBj6/OQy7BOuGG+xLEiGxHPyses1fwTqYjOC9sw2EthK27yj13HHAOiWdgFyYcPRDbcGdP6K19UzHoL59uG7KdVW3Ve1lQqNEawfgjn0YTPyR6O1ykEaS/XIvM9TWFxrI4p3pytlSyrWFBv9D5QivUadg29IsHt7QvGYF9uD4eht8pis0x4c0NG0FmvKarmzGAWbOqxLl7qVnwwFc9Z7zcaZKQEcdIl7a+y/Kbckj/aYmMlt3aVX1tGaczHfHip8cDjbFM5E+vGEkoj7SulXtBniZN9g5pmC5QsiiLO8OV9WqIr6cL4rzEGptmfSnSYo0K+duuuIPvNPyJ1m2UzUPn4wp3CEbXoyX/Et/3qNiAKe9qAC4HmmzDxdhN41Y0OtR3M/8InJBhRcMDHITLWdoDJHNS3CmSR0LbC7ynD9scEr9/JibKNt7SlNFZecuAUV751W7zCyOh/oo4o9OmmFwPGu3ip97XrOZIvxp2Gqv13HzV4Y3/44k4DF9w00HpcNDcJiVQ/+7UkvmPqPlLjHPrO10RhUymL7BV5cREOGRQBjVKxpBJcTy2JoG9F9GiXn3tvE8H6OaEPkqLf+6sWE4silFwcxqDxHR+xJgDCEEfMTV6WLSHA1zMA0vBPWT5wunv1x8IZVWtzSSs/xFLrqHXzMmXDINla54cn3luWkVIeRQnSMg30OJdpcziImL3xPURpTvqqu74UDX9uMC9rEEcmR60R3sTheEds2jGM4teLdooQWz0j8ad+wIYTgs2TKlapIDuqfJ4CLW3ubDpy5VwxiCGmSMcUvTna+tLUOV67tWpsTs1IFGO8QLf/ZeoCUm5REwM6IngaQtoSm3WXaSC0Q8HMm7JOBUpYBKi35Wg6MODVjbf8q5KpHEq7kvExUIo4VbJ3TpdnjMLFEHKqH0PtwQbxTMlxn3HZzD2sYhGuwxhCPI07MK6rPM6HmBkMaLQHErA21s7pivlvGQijxFF3MiHRNSD8AFzNaHwWKOyKbdqEdkKVKBsptP2ypTByX6qB4lkHxpsOHBYJSObrhjl24yZjKYMwrhiZ2FPWoliuzScezN9EW2zVyn9MdKNXhYik/6D76CL53wLzBZarl7s5lBCHbT5HZW22uwuEDyclkj/G9rnD81X1bZrHrPO4bKbjfWsQUDCFDdJJuEOyEvNUt4+k1eGfiHIqcUWm+NzamK9QlPD8eKZCe8tx4XqKw7ClFAsVfIK63ET5rfWQQ1zl8hBdL9a1zTVZQSb4eP8Y+YiqFHL/lCCALtIzlZ+q45Scd61/PSKJzM3kOuV5uQ3UekNiQpgSX6wZr7bZMzMqcX56wVZdMEHs9/b4Ugb9vwk31+bPewr1N36OHzyd3qXMqasAT7p+1qA7puu34i1/w4KJxae+andRXinG8DWLYV06yIdkACL8uTBI6YoWuw5ycm5pTkcWyaucVeW8ttvRmr9I6gky1rHUdeh3M64lM1aI81ExC1hctEjb5xCg0ujnR0Fn9d9mlWEVxzt/FyG92LZCIUolanzWeUpUWiKRi47qAID85f5sNQA8ApS8AxR3kDfPXiNuFO1+4IIal3tOzWEkzPUZAuzoCXaZdlBtDLrQS1laSDpR7mMF++hxhTW384e46KHLhBKep/g8lLMkoypLUdm0tTsof5ZGdcKnzoQKOqFhHCHM2TuLiGNzkcJIsogL3ft0juYcz6gg757yFURWjYuc82JzkbvfV9It0hWZHNhY7StWLXXEvvN4N7gFGmHpjvQH3auDgKsNoQUpKpz4V9dyRoTj0HAEGAtFomG3DIjLkSq398VuIH/W/jrjh5Qohq0EzaOhH/Y50xbks10kyTvwcz88IVyPcw01Yu6SZK/WvelPquUNuj+BEexbRN+/BFasBqGZyOJHByqZJj1pLdEoe2g/Mdj3QjtI0pmax+3242P7HMV992H/tSdrq2Fj8HBRvJnKb8iLFTLFWoInb9JIbj1uUbiPe6HBlgQ6837eIBHtTya7o5M7tx4vUf2t4fpBis4ns6QDMB35UBDCtv/1fFLf6uGj/x0ekjFQruCNsJGvYJmfRrPei9MUFaUXU12a3+LkDnh2x7DuOO20nLbL+pej+o8ngg3I8QB8TzN3xcuUpDKuyWWrAqLVC/7J3979o7n/0J2u+kAFB5ZxzFBGroMYV7WRlClmsEG8DGboEVRKLgZvOaOx5taQZjjAmE+uJuvvUkjAlG59YvojIAkAIfM/DPPrkdK5nO7DdtOOg4cYciOUUtT/QJjyZw/ARNN/ZPBdomwg2NtajLAuwPb3+cSXb3nquv/yopmYHifelTM/ZnG+FdpkNwzicJPzMSyJRIj7enB7rXCRvqdOzs1Otbp1xVpuC8q2SxwLgx9gF7UOz3rWgVHK3NYcHFOkqWbY3zCgRk87VKQrO27MjsCDbCWOXCJJXQb1kcWUtI4o60K01Au59Sabj+RDQh/pPw5bVmtqu82xgiktSKMP8QwfTSav/wDxPEmJA0Lt8hG7xWkBGVEKpJShZxjYf9hTVLMleym9WQ9/WK3gdfUNzCVXj1xSUloI/4Yq/FduYw+IQCqbcH7/pt14NiXQ0wHOitBrUblmx7LE/7wEyY72NWw5wC3q9jG8epHWYCatXP+wVqYbCKAhs4Ebz4so3O0xc3hdyW2x7qBij0Hd6J6o11dCeLUIJQeOMAJpdmk0Lvy+4D7fSq2mvovCf5Lu2QIrLsUOOQl9SvZOxrvbHRd5AKFMaCvwKh406IZOInneW8kni7eXqbWqrSCE2sY9Q6KXsiTgGKxW7cORrpJ6X6zm2V+lplodl4PnDMgnF10PdNE+j/tiUe9mUlzT2vqRjYwjaIMX+za4qPR2Q3Pt/bZqaYqbkP8sYhB1dUTehknE/CryRjUYcyVo4EmygLp9gkRTbQc5najwXyiP1QKoYimcg3CQp4g69CWKyjkm2DiOGSnKaQHnc76HT8Z3jiWs+7ghdBBX9AJdQWmZgOHV4VFZEAKjcbHyQ2efEINd2t+ZyjxDrlnkwz8aZzTkct63V72afNttBYWD8IjeKYKhk8zZ9v6elZj/O6pJGkufbmTSNYlyQCJT4HhTia3qvYGnoAhucn2niHpr5iZeGttizs0s/6VlPX+jK3N+AJBDzAo3P0QSii2zNiWkY38gIn/G3trg/v1BNM7GUZmqlrOqt8g8CejtHWck7u+p3jJBZcLfrvPaMbVi24zx8mzzPV4XfuQ765mu0W2Hl6dZhEIViHZKOPcJdPbx3eSOlIRIxKpDE37uYEsEtWor7qSfFDJEpR+QQz9Ll5rhNFnwW7OjclW2+X+CYHg7hbidAjvNK0sbqGw0zD8TmXASsoLH2h7p7+ThNLze8ZBisla4hLiUDv9shTrWuKMWIl/F3dl9yJRE9WrierWzP0cjGAkT+5auf0/D3vFGXmLZTUHXxZFvjqrc4XnqM1gQzS9G7vGSKO1daid14PlA/f4LNUVIDKD/8D9mpP+XyuMRC/OhkMO82f2gXs7Vwp1FaXc5IjasgB0o2c4EMjkumi9uheRTGnki1GCa04eFd1fTQ3Ac9O5mur6+6rmGetAamEBUtTmySqKyYGxzwW3lH/sUSpT//bqxbX72Wk1ee89m4LkjjTygHTice8iQ/C9I+XiePceV4yjdHXR5vCXkjMrRX0foOpjL23GO2lOIUxKqy1YdkEkuXQV0XR+5HBV+9CmtHLYOGd4LDFAjtUmxIDSqD1IXMNHd3qLH/OYiOgtPG4YfKzlpjYLvzCSQK8ZcHrnyHkHjRoWKCPPJv7B+o5ak5wMxj8UD91/bls3ulTegkeLvkyz2ORdJVLz6ALsX0xCLJ0drSGUp++RFZZUmZsLZP2jxzTVgtbBNjCoxTnNpKvprhXLxjLLnxq7Mvc7SGtaF7cDDiqc2mjSVFI9rgiSinWG9/ZbANyfWthG8plPLcjkitGebGuCapSBBa4ZpWzLQpIDsbOJaHmz62wYtYRKrcPfEhvHuEU4RmdqE7cdPCwoVCjFlljDuuMkSMco392AAWOjeIoBO+2lMxUm0n2xc7eFLh+iHOgQPfRBd1A8YDOCerkXuOpqdhGzFpDVUXX4CLJBtRERM+oyxJMOV9MK+0jV3m1R8T0tL6/O/ZkQYQ8ae/Snox+lRwDxMsTND95rtd8vv/MxJ4eK82OzgNYz6JHQcig6PTSOuR2XtJ2e5SotoK5w6snFLn27U/8UnQDG6e+4teMl702oXcK+eRot4fWv4bNX7HUjhV2OoZfunpiaUzRkHHuW7c/YbKSwrHzmY2PS2FAtEJ3YzWEAFT0CTQqqTWuAV1eJOqDjsrou2aZyLlMSwM6puNvLOrzjSD1rsP8M6nm4D/0T/Bi925qHc7pR9oU+uuGVP1PJUbbkj+NkYIY0SnjgdUX7czI+jn0+2JMP5xXRBKrXPWDaPFpxKJrwYcVOXjkPYezioi4sYAdm5frfku9qyLKDD2QByfKydpmGzYcDCadPBSXJ05dy2C8LL2n1e9AcwQE5H+GHCWWU91WkE+w0afidd1KrkdN1SHUwqZMQtZUmueYv5mC6GOTt9vS4qGHV9SD95cOHBf76LFYMHMkGtX+RB1WaQTSZabIOSBkef48U+TMGMpW9Z4lzt7tM6E30ZSwLXx1CRAV0WnYe7DTKSt+vEZRv1ghxboxYWWE7yNBlOkhDoUwwbe4D4WAFvtR+yYKhuapqfNDHxJ7QCFyfLtJ1sjk+3Ic53fxha/+EuF/yQBYVu42CesrlZ459BEUoj8AJtpDsrQDQXXu9Yz4piMxGH+G4HJhVJEba7Aupmrk5ZoxSV/XBBKjGH/ZkfJdRMpEACB/IozL0cCHNP0716xb8tQuqTq7wWEgmHMhsTFgIjxH+9oXr9dqFnC0wszuH4vvOISFFVDml8RFFjEr2e2N0l65DT9We9+AH/hLoP9uz50nD1eAH1Kl6qtWXzyWb5Ola/SnIbC27tE97wcqOoFjbUygytCyEk1N+oy5va7L0foF4n5PUXEu4riQfSgv+ZP6r0kOwF7NY23/RmQnCyR4zfK6P/80up354qtZBdFDsj9wfw+MNDbCdenr+9aiRUixiVTq9kL/Ansn2KDB+kpYUTgiiMYTgPEoKNFMhlLEaediAKUeS5Z2/XNNJISPv1+joCcwpteMDjTpdwRACiGAXtV2td/XgUfrd4hlecOoGpmDFfD3kypRq+gj7iKGt8Ol+6CZCuO9ay5eLIHRKapmd8Lyd3tA3k/AzVnbzlPyOsbnlosmaZZdw6DwDcHovhoRMhVAD/6Ealj4ioQCh+11tdpomYMLfw5iHwEgUXrhOOnLyrLtloTB6DH4eeysiYl3E25vuvFrsQSJPTLy8ofST7hXKnUNj2VTg9ImS3wfOBlDNmmcBZ+epx4Xi6guQ/+n1JXuIIN6+I46BDT7tFu4aKfcAgWaMzJCmJeN5yRJZsPYa2jVRmMrv++Vdop8zJ64MDo3JKKWCp5sGZP5X4purME2N4Kz2l+AfJnzcIplyABv0+1JPKNNRDoQsui+0zugWpS5mpafRHyZ9bz7WNABJBQgp+Omeud9rK/5s7H3ZR+72UHOdJgY6bjucg6XlQrqXahsa0VAbkFHJbX1XnipDlGV3ihDNbMi57QJtNLNsPTXfpRP6oYwJGq38rIX8oUEVeDjWTBg/yQQoLuiNYId9IuLCmDehyJElsnOV7kGEjRl1/m0TmtxTSrGyu7DOqaJ3H7KzGJbSvYcFqn8DniKSAKQdykMNayUYqAgc7z4gf8QB1tjevPFa6+ZZZqo9yw+xS0810VtiQ+008rqnBVyh81FH8Rfm1HXv43YwvkSObQLR6CaxpPNL+227XdZtH4BOokpwyaSipXHvS7CSkE17mIKoKMW5x7e51crh312E9wd7rRBdbJx05uX0/P6GaX/2t86p/2oLg9526bLGzTq+rsOu93zfEYjbgZJQ/k97k/z3DyQjvIiHE29biclhe36sy0H7N6zlXyW73dF7bx2OYoU3vV9Eir4xUTt8Ink7oICWCGVasFaw16WSUbCDoDZ8mO2ghbzUNU4i9ANdYxT57+GFBQJlOXmG5Zj21oiehccrVrW//2fRoaAbX8BbKxzVGeszL3rKTCjuJNmj2FkgjN0Kna9MwvM0dpUQzttSIX1+H9ReRaoidJs0xlJHYZEfVwRUFzsQ8x3Syt0+H0tqf8JHL7bP3aAx8fKKQ7gvfGCa9Ny2sZQlrjcjL2Y0AWAHrZ/69rrHE7ZbBTIJXN142UuihVJ1AU09pvOf38oJoxT8WxaWcbw3E5pY4kUcZipZtWMPQf49GdF5WCmvUbjd95zwDRZcglnj91DpJAGkxzGKps9HNO2Wkh+JMg6RPiDeBwyoZ+hZm+EDF2yHzhbT0nNj0XSM+ctmlWjOpvDTh+JC9ib/DGSqgEEYFaSvlmVFjVvSgn9/8kikL/Ue0Q/zMhKCYcEB6vLHeh4mR8wPWLNr9Tb7B6sAGZOfEA37pIcgOJ8vYp5hsXQhWglLQKSEVm2vVYFNK6JLwdPjDv7tPXZwigZe++u6s2cYn9IOYfqqbFzQiyNZTLqb+ss1mqjwIaiBfqTSoix9jDQytF4Gl+9re01F+nK8WUWlC6UqLM/KibN7SLxDiHiA8W3RpycSj8i3fBwMsklo7DGoEI8lfaKLlbzU0V3Ynr3wIRYDhoc+4bw23aqOjjjuE5AnLUkAiUBDURXqLkzDYGUoqBCgNstpA5P0jmpTR9e/J/GVEHhUdQeJjFzH6jCU0Z9CClx2CXAlhrI9k8B/HNFfCy9R2u6NS0Pj1vYOlAC7azd2Ijed6Jej4bzWqlKPIUpKSaYNxdtXW5RqOcmGJkj55Hy4PW2UFXnzzUYbIdBinD1JerrqGBDQGPTIGVNoNjzg8QptahkN6TufKY25ihlDPo6vhSL/oes6vKNzN53Nne3GVYE6X2n9KIpzOCTl93KZ+xYgUXv4coTs94v1nu2YjLMoW+SBZROX+20TV6UU+FOm0cmBsrrGe04wJo09fPC8IvGv2Vwq9tJPCZlOHrqshNRq4t0yMCnEE6u5G49ZPBq2lJPKeXvLrASZZUThwqCQeWLPfGgZcQFlTsFfspUtKwQ672Jx6pzRTwF3ltOcUcCqUlCfYFWxZa3QcWSpk8/1kIVIeFS2X9bE77SJc4jPt6JQIre9LxPYFQ2vwTolGc7VoAu1JfQnhTzjr/M1045ewYjlJ1YMsSW4sDS5OMYpcv/oN1+Q9rb1gFMc3RrI7QBC9UYQBrz9aDmembSlv4+HEOoQPmWhYCbyhsSRDoXo/ZWr9QCWQdbA9BEIomu0Rmzhq6/nbdV4dnOpwNCtMHo5OAaGaIzghY6LXtN15aq7B1BRftf5RndSYSwn5oPkyPJKYyBY5CfzLOQ8NSeafwGdnqxIAn6QELiNT15CmBUoibQDGtwV3N8lHPW+DsdpGeAVTTMg/dFUTlpg7jgTjFtWzOYpXJMWRVaeFDMWOMYQvqvk1Pq3lDdHEUUxq6ywfmbbAm1H6w4KuSabckH9SKpE9MhHsFTFWh7INfnNGqsHsBn2glFSQtIc8TBlL5Z7TBprDLlh1etMkjgwQLW+2HotpAr670IsHL0deDciNy3AAt6gamAlnIMwh5aNtbCPZylwDqdEttGJf2CZWZWMNh5oGeJ4sbXwYzFNyPNgxoPFno8ssHgLF4Pgtc0h4JzyPEbCu7+ixrQnhB0akj6LS2VNLMtn1PfpkflZ7MMZCILjh4Z4sKfGy9WI13I3Ji0gozb/JrgGQkH/Opo6fMzSdVqe4zRceyHDKmTnxo6ThYjQTdGcRqfFnGr+kCz5RgY4LMLiwXfvg9qMy+6pDgMeIQ8gdsVtfRc2EZOcXeNqj1r4CWpzaq63wMwifj4+0zNN07GA3J+PXX0uh7683chWbPiCn05bAUe1oA5aM2PbQyieB/7X0aLJGzel3D984DEkD2JbNuU7wCtDpSEqXPKrCU44YPeg0CAcHldL24ilK0BNNkYmqyY4U1l1IYDqHf0s84APPMFe0uzMqetkV0eUlH6G2nPPqwkW4/sJTCX+sioO2h23yRqko6dW5gpO0L7toxJxGryb18TxCiKAj43gqnzJaC/mJ7+xHHSlXUVJ91K9VcbtT7jvo9D2RmUMGNhWuv3sMHaElF+UUBDjyRDkupWRj0oYTeIQnujYD8LgQB3Ws+vzDeyrizT3JPW3tFdXZYRif4QhQ5BJYGBMmxl5nMav/25nAjmzJ2di6Bz4riYKexwKtZsTUyf2HR/Fa5vsR2ZZ4KDlnTrr/b1qAE1tBhc2/aFjBbItFQcCVWR6tmV2jt1Rb/pXFrKvD8DHPsUxEW+5Pw7jTGbMwLik7hglTAW9DCMy+CRBdiphlp09fiAjSQae08TyV9GkcYpEBauQ3kxNU6xUMlAP3SqQfbutFDNObLvMsM6aj+lAJVrm/ZgLzn0CGK3A17y7LHhVSN7EEQahXi5k+iu94KcZ5+73TgyVZ0ZtHNoiM7gsXldg/qizU7e+KAFtQa6wCWw3tlKnA6tFITCo3tTVzCTK5nqTeRRfbqac8hY0qkWLMdLVipN2VMAYrnrI7PpzE9/KZaxRiz7PWiva8NMB/AuGkTjSqfa+EoaaXOdf/OHdv7cwJb52gxpA134rBMQR2GDix85bOLQv9AaIdftYnhq2TkUFLaMVrBgvE6HTSi18TgtUtp2FW3ZJS99aWbzzWL/BJs5X33UMN6aek9QbE+5jpLVvVrThMl2Ug50MYvzzwpNV1lSnaD/eruTbP4oY+WDQPz7XjT49eAuNH99TariRMUUIm5ws4SipnrRoIbS+vN6iZJ/vb+qRdxoGDcfUFl6tmgZQN1qO7zXNOzTf8p3usVAk1DwOZ3dBlqJoz3eQEKt5jIVW1Onkm5+Jdn9DWdDmRTvkhbv0TL5ao1klhOKCipnNyRirV42A/JOd4S/tBBi04vchNgs/ZOYp2Wwe6m0IqZEe1l/sT0k8DFSMljSHsH3J/XP17xdAPMuym55O044cON9/86GDDlqG67U9nxRUMFdQfn5qOJa5odqyja5f9d5pyZsjwsXC2NKpvrJXRQdrr0SUpSEccYl9e8jmT9qEYxG7+ltKdjEYeCfM/jSRyy28BTXtXqNTQj4tgD4vI90YZrJq63Y6hORL8gT04wX2uUxRh2Gw1/AetCRtKQsA8D512f9Qcg+WQZjKhVXtdB/p7j5aqB9aHM09bIR2nvQwxChAXU6zMbuHwYQyhpJy4t3MWq2A93TDqC83gophINY0loUK4hFH206Vt/Vj17LU5Mn1PED4NNPmXiv01yHly6v/JIKt4V8f1/MGjPJMkxzq7KuOo0fBnmz9LH6HlzbDLmwxwM9r/iVywrw+nBFUJqnj7+zMakkfXJ75ltScdxFfij6X1v659itP6ZcKBOaGUPUDr2nhSIaL4isZHF6GxQrHkkpYMVpQhypZWaAigJ6Ozg7bnK0dz6uKSWOYRLG9xI8otQaV0RGWU4ORCGbFRN1rh1HwV6/Da+qvZelc67KoEk6wtsGtXd1epTU3prtyMRyzvCywQTAWsEFNjlGXXDAh3HUKY1sXTEc4KK3hpaErZCgUmkqtqQHtBUbNH+k10VCiHnaDiVU0orNmJm4omwc4K1KtRAXeoD+3SWLLCkjQYwZUljpF+Ewjuw+WE2pKb1mx03k6cyVDvnfmcqRl8MbA2ZKqgTumz4B4MLvoEN+MvthouZbThQ6qViOG2QeP6QJir+DqHEs8uR87v3JX2gEbqrqHqcQsWt1aSBNpY1XOzlLolI2/URYubrRWDgY6+gauXc/Q2j5OdboZRbDT7Zh3sZHIS+mweF2BE7y3OwUudrWZLKOQozFClBHXw06GEjlO8o+si+oAF8nG3acXkK4hRDT6EboEoLmlWay4SlaOl3kTkXwWq12Jcf7/le0WNakg1xF8r3J+7qjHy/VlDBrTWS3E09CQ1pvXSWgz+Vk8ZoqzH2eXzKlgcwwT2kXqOz0LHCC57bCo6E4do6lAgZ9mTiE4Sq3XF1ZEIciMuWW6u6x9IVAapOHsQsirRr3S4356QgWgJP0LOIIm1ZwXr5XvyrvE4oUYby6dcL32dlNeHbHACe+Ru8qJ06p20d6mSl1243KROlqV62/iHChggSA7RX1ut1wheD/VQB9W+hQ46P/b4Z+MzcDIEHQYUsHAKAMxcajPYo9M83jVUT/j1u92EVT8jdfGu+4ZFmM8uwpykjOX6c6E9pWlSCGspODu7QYt4rIPkHBFcLx/A6kOwEQUzpO8qOZOPYm6RegNYXymXxpotp2H0gGG4258sRMlS/kUfY8DDp5sqnfU8zDDQGberpT59UpJcHRwXFoH61BojwQjxG+cMPS9pUsBxHJ1UTaxkfzo2LwoGD+AVlUrNuiuxUwgfMod3NHqCTQJEGtkscJ1qRTHYg18gKzqVFqXOo0uUJmyChQwRjVRQxDCc4atF9hkLD07pJMRhGLtEyvNe0BfZmT+twuFC2SDwF9VRWvD/GG5ojUbac0a0u482T0PJ7fVWNk1D/iAlHzljIzFxsTg07+i8TVorByTY4sSq/WAW2J5PN1CIGokU4y+gEPE99emDCVcJDxFzBtBKAkac+zWDzfAvq6Wwv5O9AxMa4HcoYgi/R9sL1HiK836OJhttaD4Q2lNw1DK0V1RaliyqgHPX4o35YKgbwS1eDibld2sq6uDzEhXy2OwdqZbdVfk/rVOaWbJ7g1oMZs4QFAfOVlzs/j+RTtkluZ7MEy78jlIz/jGe7tUsJx7hnb+u0DWmDcqOW/QxPp48Qv3+0lnaGMggI6iBhvVFAowGdcU3MCVRNF22qCBLQ4IHhzS0fVVxG3XVxNKveZ3o3T5UNnFTCh/zP8MEi9d8Cf8V9KRLs7rhxGRc/rO+/yIxp8Crf6soABQ/aWh6C3HqoVATWgabEal1iyR+cfWW1Bfe41HWW/hVycsnEulFDLWsSX1dVlYujUU4kp8wsR6m6yrqK04hmHtSH6WTZVktzYD51iPy7eX2KdxPQzWVq/rL6CaptHWT1dEnAqQTISnsiw12+kt7NBwA6jxWdm2rzItu0sJy+LvznKbcp8o9yFsHhIy/wS9O3hLtJRYkgt8b0kMo3z+o6TambqH93mimomNr2HhppRvxAXw5ox53bTyfcTrzD40xPUXYZX/BJR/ET1sw10O/c8P4ducPTA0NVr5aM7IEmMrMKI4GKAmPDuDLR0GESiqX7G4fEYdkO8R5I2IpstlXOvgBFK485olbzVBIsH+lrNIFmxSHWySMKzdiVDsUh9FNCLbhgXIHHIl+X3MVIZqIxeZ2EnoVp/RViBNmFi8g/fS2732Yr04hQCaDXDix660RpHNrPqIFuj26NS9vSDjowWORYKBhRre6jMJYmxCItPUMiKyHaqV/Z5fk03grFDqgzj9BHFqvCTqCrdJMd5zhVa9Ip8twPD7aDxcofvcOh043tI9KKSr6Ad0qltVfQIXv5AFZkU+PAsqKpWDMnn4YJITYoXSYczHaJ/Q4tctYc3CzpqdjFenlSI+KrsnJ5EtO3ZMqnQ6+AcupFLQM40BfecdVZI2gDL/oQeTkGfsCbY4iSN8y1GoV4k7vEsY6z+3GtV0HgIFF2Jx0ZIti6K3bV7XhMm69IJpTAVbvQFE5rR7BtRhyQlEopWfKVYHs8impuPiRLUB2waRk4ys6Kn+wvl+nKwFymEdSqkV5YkjGM0QvJ9PXoSGE4MTAPkAJRfr1ZaF4XCMpVK5Kmh5G31nHgTOaisEyYn/2FEV93E4W7MiYsJpQjJNqUomqaYrg/iwGLnz4Fv/AkygtPYVCmXjqmZYKP3LzEOnmJX2xHe6bOay1/98XPpufjm53FHq3tfX5tzeHH0OcYHQ5EkEi00WJVoyG74Y2Zorshp66X25qbTbDKtW1CVgAOuLk43rcWeys/bEQfFTgwrwv4CzSxXji3domIK7CULCD65LETliMCWXwAMXlH7qL0COkTE74ZOcWVmpWyPd/vWRg8Dnfj1dxuAo0mshC7quCC5fATEXrOkXax9k7SwRm0/r7CwlA/V4PxjU1NtVHDicSrBVfHl8BFnScLmW8pJCJhtBCblmQmHjFTQpTqMzdpAGxqDzQ8qfZ6UoKO/mfrUN6RsOTzOvjJR+jciTPJCJfMXKM81QFAlJz5PoCVyv87N7Rs6oUp6oR76vILUJnpkBdI+GXbHBmc+ZV8gWEcs2xZYDJFKDbkdFRwYiRT/+E+1GKKTSiXBjOFHyhjnIaGIITakuS9dwbXMhmNIF614SSEVJHi5j+bgfjsVC4q35Z1abribnlUZ7cYdfzBKSdfkY/rRbyS+iXOadO/KWumxHe5pNgDm+OKnSsdNkysRyIwAmpyEeGbqecuUFaLTF3+ZmN8WCPe1ooagD2quEj/Qh+R0b/pvS3Ja8UQGjiqP6pIbVqO3tWG16SWz5YF0o29Nks4A/boW0gdoK07WX+jjMKFiF9Zyj9RGW3tkJRowfIP5e6vG9SIyTiQHtR5c5Gx0gY4mOZSm98zG87iNASB3XBwPOclj7NajHfZpeTH41uAVbwDd+p4ItqUPkhjiPXwhq0fwTwyujUr6G574FYsvWIcSL/KitQxmSessFf0pftRcGHv8o8wiZc5oxyatbK3kFU+h8PG5a1Jblpdzrf8GrIn9EIwdf7RUMSFWbZtNpQd+puDwCDQpM6AcsSGcjhlGOJtz/4iaY83djNmE6R1kHfXkDDcwxlBjbhK3A+V5YCaBzSZ31N/Np3YUIm/u+vaT7Bqr9iSpqQOFtgenirqzq61Wp6GTNksTejIy3s89zEDxU16TYt4agncIuWw+N0WsCXjOJ7IBipFDck9JOFodi3F9xnVzmBCiPQ4U+NIFq6vqCktf7F8IDAdTj9DrByBBg7pMvxC8W4Se/AAyRb5QvZr28Q5LWnaLiwetMgomgA36AuiyyQTS5vdDte63lPeY6WtG3bCXcdaiJ1oT/v/5mnW3Xy8I2ckb8YHUWX9pJ9Fl/jXhajHk09BrxMryIkAPJiIEzdsFkSya3BEcUaiYlIEjwy/vuL1/GIqRoC3TDpvEnbO0AXPC8C1L5Z4RrGObLu31Ax4kH1Z/AGvDJ9uQk7J/tRXQVj+Ajs/iipa7EzStDLwwcjjpk1jB8peTmcX5jsUcsBLhiSKopQziUKK9+gcJ1zhIaeWP6su2KujamGrI5/J5qLuuJSvrEpqTWPeOCaDDqNkPZF5s+Kq6QwiAj87nf1cGYK20tfPvzaNuXhdZid7ugl6QPZvxELJDa7tVvoY7FiAbmu2Vhf7cm06XTFj7RZflchItWSHtzCuC+2lx7taOWp9gW71UqkbD9Rh8aUmQEjk8Z5MFZSS6WVtIaDn5X1HhuSP9ao5fMa0LoJpeBEt0OHMb9+sFra7Nk46Aa5VoJvN4h0Y83Nqp6TKWZ7X++HgDiODYuBPGZ0lGI9X+tQnGfCL07F7AeCScJCRk+4LIP9ubCcLmjyhdE0tsSgjsNqUl6GRtxpEBm+TNJ0YeobwN9Upk3wkAQG93/mTBuenk63P6c99LxDJJdMdWWfPvexQ/kJXpjIY5bs2orftLlstxNB/16VbDahRrTfZfFTLiJJuGf9IBn/OhZwKkzG0VQkkLdJlZc87dLtuxrsGPyqJrZUHWGX5kiG4zW4ZIkuuqXY2ZhMUd46eYvxufg8jvhLkfrRfECVQBF1CkijW1iruu3eQ7SAM75zVYW5oYam7tmgmhrUmPbbTEnKe2O8KVOQbTyCy0p7pfYZ2bp2dI0bFZBNdjsMHn2xxwrjHJwiZkEjexbyqwJ51ROEaiVzNTgQxVzC01QaKoxuex1gQ79fHUK+WqrgMykj7k4E79BRcd74Ppsrjyb+KehQ+Qd66nQT6aRHLYo4OdEH+/mgKIZi7oHdPl6POP4hVbcRDpcJYuwh26Diq0I/uP0VEnOjv9CZmgiPuwiu+PqpAMZktIq9Z3tRBPP3MIqp0+dXqWqIB5RfqQmOAiWO23kCAco7n0yw+kgswP3DbR2AEasrGUrloeGbqijcYJn6TEAEqj1KjgyxB9vDTXKQmKhat6p5L86lYCHMbPG/aXhzDXZpcWvhpxeschLQMLZI4qks6Hrz9VUaIExo2WLJLmAFvlxlwutw83TXB9eWOmxSB8x5xB7YVohIFJT4jNh5yVbEalB/M7LMaRcF2l/7GW29XLf2ngIJJc/2IaXbiUUyOotEAVTgrlsvAhSk/v6wbCHFxPN0pgK7UdPEWkyUf775xzaXGafy/9RpbMU8pXBA06s6ssN2KfzGfqqO/DWpwUXjHhJdzCJ2v84eWGU5xzUgPqZbMCpzgYC8+Wc34jZ7N37e3zYV/xM/S7S83VOXoTtJ1phiIRABvVOvr83jwA1EJz3meXSpLEeE2i1KM6rJMc90ehSmmIIgU2p0vh2+R5dvoTmrgwZ/sAsvTkzIQiFMnIdTUTm7GkUnpdLitymyvaSVyEq9BciUsJW/+5JdkTImfaPEwMCUD/55B862u2v6Z9zhDd6D+Ly7T4Jad64U4SYfEhwzzgL0kkUixwz8ElUzJxHmIw+yDdyZxv344kcLzO4l0D1F0xuXSZ7S1k8jhsXyi07oLaUUsKr8gZJlLdqeBLSf195k2WC0BPBDqOdJG+vEpuPbxP+2XROs18kIti/4+C/APqksgyNPOattwPjUPzF8PqmI40vXgh9kCE9q3eJ/Bn1KLxskogcQbdDIfAibsSLlCvTJNZz5VL1psExlv4SrC52MFtpVEoMob7UfzaCJDYmwy1bwCyiqB2xEGTDqObQFguUfXYsZaeG+PAdzwU+sTkbK4zCDLmJ5yxMF6/zEPNyQmtlwqLf6zaVTDVESvi24BL4DH1c3yoGQCsj352u0335flO3k4hnDOfC7o0gSgm7Uz+QVvpMDofb70NP+u37+MN6rJXfvTiVsBuxAehu4Ta8uDjEzAjsIOQ5Ltz2mV5cnkpdrK/hnzA1uIFjLUesWaq2JY09gfXUU7Qwa76BFgZND8l5cL5a5pkAuAgLJQgFGtzf5tgpboHErQgmqH1L8t2TVulYURvGJ/JaGzNvN1VTcBdlMxA7drmb6HdYbcmmk0zBpPijK2BUVSOYUeNNr6g4AFgQkxi4KMwC5Tlq5X5bezW47THKun6uoJlaKCC2wVoL0jDP/NGiNIRB0g1c5FoQ0Pkc4yvf63nMLkFPjIdnd1oBXgQO1TmQBiC0Yw5ySSxfAwzNejFJKkntT4IV8Zrldu5VvBrzGljdoch+bQkXb0+uZAZMEZZm9t+jnkslUoNJJl6qf+Boga42RqvQoy4aq8eXkD033J9kx6lWR5lNWexWK6SN5URHxLzHealcoR+FQ9gyWSS3v9/F9iT4eaYBJYYGbAIzjDsKrh7dIJ75kaZqjPArCOUl2TjAPtvrjIHU75VvQ9OSgQFdw7HLYW9r3vqvZrXO1YXNhGczeYdhTAVuziKQmjeh4ysc6enmwG3VH8joBeb1CyYndHJVdJY062gD/P3O5xbj+ZeYGhQmKUIrIek+ARR6dgCtA1P0AwXPQbCFc6m4QhA0PtpFk74joxoDtAPcQr9rGJvJjeN/Gj/qUHoQl00R+VNNllX8yDckL99nI/S7oeqcGsphTNauuwrAaCpqLvOEGBlkk9cTuhDaYadn8HYp2GtTpaU9kFKWpSxLnMSAxxc0+oKx63ApP+zbCCTpXp5HmhVgCtfijGVdeTc8k16hD7A5H6mY9xeG4m+VtjwW8jtys2UJvsDFeyid7CUntqmDyvWtHAltcXk6pS+H899/MVk4jUOkzfugSXR09GlxtQ5EPqgft+/zEQQsbayby5CeIswRGoB637B8gH7PYJU7mrJat1DITKEwwpySev4taFQyw0D7Fd7ALOJKMh9ZKlkak+G02U0ZTIGps1r0raGezCOXY5TXX6WyHX+bW7Fsb1ze26vJ23/emoxyTeeKacJILdA0dpfxnapSNStAP9upQTmHuFacToxWr2s8INh6nP02QNNSCSYuNIkFDlEPeVGxdoLaFnKOaQVozxNqvDCJ94IUAo1aPxZwnbL8yLuZBhau7YQpAJseTBIykNa91CvE0Lu9JsW5gRpiqcK/WNOt6hnE5aN98Q34FiaimD8amFRJnCjFnH8gH7WB8WnU3lmETyMTONABBWN/VxXOkp4b1Fr8fD3KdkZ1ZC5XUw3fEkKsA2jeBBzEP4EbjNKgrJvkqj19K8Cg64wiDN9nic3vEor/OSPzyn7YtCund/oemECX7TTC04esGjD2Asm/jjuDSp2B5RpN4LZWXJZPX7sx+E4o5FAjauCRKfI+A/oBR8BoCqJFv2DWwsvpR3lPLuCk3FxCnN/EluDUCUBDCm2Kf8gyVZiChJmV/XsRYqmRb0X+6ji1/GJoufaUg2S1CbHg6Z9m/P2+ezuuKOgRxbcLgfrA9atsW076/BSDsEoMC842tttQ4GFaAwmxUW+ii6zxI1yq1HP2VCuCTgDpib+l6Oxij8zSzov+vu8Jar7pEe0kdaGA0Oq1zQe2JCnybzSq1O2NcPIm5dtruPkKY6/tORSJdimtWEOVfqgO4TQNRelDrkaigLzVbDgcLbG2LQezUnXDVy9BPOIzPN6I+EigfaCUm8e2c8bY/CgVrn1mc3qzRmMfRvUyAsl7G3tVtBuSiANEiiVFxm3DEe8+sfMCVkC7F+jG4c3YvwN2yenuOzMp9YCSlk/JQM7g/W5hk7fxV2m+AHItrUkIBs/LsrU5uvDWJFPIxaSc0z4NPK3E25XaGZuS1qTqZ6Q++VowWWWu43lHMbJ96rF9RPjM82R/MBslb4r+ceLBmb/gxXhuzYJsqS/M4jN7rZOYt2EVOP1Lzi68illiTAZEHWJM91Vj2yNpY6iMeqZDMCB1vdox4OHGlaB3saIPq9/auv5Ec+ckS5Xuu4LVdA1fAUM+uy6Gd/+EtsBNQOmiOHmKzMVEerVwT4IM4CPlDwggx62Ul6vWeizLNMqKB6asKaLMiZ5lorXThBz18LQnnycDRJA792H/By0JhHPg4HSzb3vJ6eZelSd7UJBo8v7ASWsRFAqWcgYChtUJdsXH4oynP/qadUOnttsODwyC7UKd4uW8ZAqOHErb5YOaLvyXHaknhl0yCQBRe81aUpci79/GokkZZPN/v9kBsIAmckdvxoR9hbOzOgigUNc4Kl+g1vWz/ItQLegFsosu9zZGP57hcFahDf6BHhPSLP7fi5JTR9KSSrEVh2s1sXkpc6j5CbZyVDiv68+j0O4OnVwijwd10Dhy9VTfK6geGyTsioa/4P3Bl8NtJzQXuSHNp9LEh+ZuR2rqSBeEvUyw8WIpWg3O/aLiBMwWwJUNg0pwljMkc6BYDg/mn/024YW0q3LmR0bej5GKlbad9iH4cRMdh3d0HfreGTfY+7rXUF4G5r4BK0FHBROluho+d66kpnct6/DetuHfc8aixdTTMWTFHlp0RCWyKCM9y57k/+XORnA5rCuxx+/M8ZuksfapRTPOV/kxi9JzGqyiTLzv9NPnLJRKFQgkP5EnowtfQ5ZKQ3mAqHiH14QWghGgsl4nDpqOaN0IbQ/gcPRnODYe7xZSfWfpmwRROrDdAoF24aoFUOZJtJ9ymG0osN/FIY938HHq6HwLOlcLK6q7jSVmZxfegLOz5lDE+nQuSfHKZykfHV9VWgR3Gn4SxKBkQhGnqg5Aw9rDkBJrKnMmz0Ku6/z7qMG/iCRkRJbkCFdkupeUQd1NLbFGSQ0n5RIxUF6YycDpj70u2If2//HsoRHDuwtiFrDiGi1bc0b+6mQ5CDEg6bcB3pOYA0GdNbllma3KjIWDVgJ2x9rFuajf1xedkca7zVs84c/kqWjs9teABldkh20rPqRydKVJBRXNoVg=</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>语义分割简要总结</title>
      <link href="/2019/02/22/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/"/>
      <url>/2019/02/22/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="语义分割简要总结"><a href="#语义分割简要总结" class="headerlink" title="语义分割简要总结"></a>语义分割简要总结</h3><p>CNN padding 的方式：</p><ul><li>valid padding：当卷积到边界时，最后边界位置不够卷积则直接舍弃。</li><li>SAME padding：当卷积到边界时，最后边界位置不够卷积则用0补充，保持图片尺寸大小不变。</li></ul><p>视觉未来研究方向：</p><ul><li>三维数据集</li><li>序列数据集</li><li>使用图卷积网络（GCN）对点云进行分割</li><li>上下文知识</li><li>实时分割</li><li>存储空间</li><li>序列数据的时间一致性</li><li>多视角整合</li></ul><h4 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h4><p>FCN之后，CNN网络在语义分割领域引起了人们极大的兴趣。SegNet在FCN的基础上引入了更多的shortcut，它不是直接对不同层的feature map进行融合，而是通过Max pooling的方式传到后面的层中，这种方式能够包含更多的信息。<br><img src="/images/FCN/segnet_architecture.png" alt="segnet_architecture"></p><h4 id="Dilated-Convolutions孔洞卷积"><a href="#Dilated-Convolutions孔洞卷积" class="headerlink" title="Dilated Convolutions孔洞卷积"></a>Dilated Convolutions孔洞卷积</h4><p>在FCN中有两个关键，一个是pooling减小图像尺寸增大感受野，另一个是upsampling扩大图像尺寸。在先减小再增大尺寸的过程中，将会有一些信息损失掉，那么能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？答案就是dilated conv 空洞卷积。<br><img src="/images/FCN/dilated.png" alt="dilated"><br><strong>空洞卷积的一个最大的特点就是可以增大感受野，避免使用pooling。</strong>图中，对于一个7x7的图像patch（a图），只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7<br>(a) 普通卷积，1-dilated convolution，卷积核的感受野为$3 \times 3 = 9$。<br>(b) 扩张卷积，2-dilated convolution，卷积核的感受野为$7 \times 7 = 49$。<br>(c) 扩张卷积，4-dilated convolution，卷积核的感受野为$15 \times 15 = 225$。<br><img src="/images/FCN/dilategif.gif" alt="dilategif"><br>但是由于dilated convolution 存在一些问题：</p><ul><li>kernel 并不连续，也就是并不是所有的 pixel 都用来计算了，因此这里将信息看做 checker-board 的方式会损失信息的连续性。（在还原的标注图片上就会出现一些不连续的小格）</li><li>对于一些尺寸比较小的物体分割效果差。</li></ul><p><strong>解决方案：</strong><br><strong>通向标准化设计：Hybrid Dilated Convolution (HDC)</strong>，图森组的文章对其提出了较好的解决的方法。他们设计了一个称之为 HDC 的设计结构。</p><ul><li>第一个特性是，叠加卷积的 dilation rate 不能有大于1的公约数。比如 [2, 4, 6] 则不是一个好的三层卷积，依然会出现 gridding effect。</li><li>第二个特性是，我们将 dilation rate 设计成 锯齿状结构，例如 [1, 2, 5, 1, 2, 5] 循环结构。</li><li>第三个特性是，我们需要满足这个式子：<br><img src="/images/FCN/tusample.png" alt="tusample"><br>就可以保证对所有的pixel都能够卷积到，同时层次的锯齿结构对小物体也有很好的检测效果。<h3 id="DeepLab-V1："><a href="#DeepLab-V1：" class="headerlink" title="DeepLab V1："></a><strong>DeepLab V1：</strong></h3></li></ul><p>DCNNs的成功得益于<strong>DCNNs定位图像变换（平移等）的内在不变性</strong>, 这一属性能加强它们学习数据的分层抽象能力。不变性非常适用于高级视觉任务（目标检测）。但不利于低级任务，如语义分割，哪些我们需要知道他们精确的位置信息而不是他们的抽象特征。</p><p><strong>DCNN定位图像变换的内在不变性理解：</strong>即对图像进行pooling 降低分辨率提高感受野，尽管图像变得比较模糊，位置信息也不准确，但是不影响网络对物体的识别，但是对于位置信息比较关心的语义分割来说就是一大缺点。</p><p>DCNN在图像标注任务应用上的两大技术障碍:</p><ul><li><strong>信号的降采样，分辨率低：</strong><br> DCNN中多次的max-pooling及downsampling(striding)造成信号分辨率减小, 信息失真比较严重</li><li><strong>空间不灵敏性：</strong><br> DCNN对空间信息不敏感，它可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓</li></ul><h4 id="孔洞卷积："><a href="#孔洞卷积：" class="headerlink" title="孔洞卷积："></a><strong>孔洞卷积：</strong></h4><p>对于<strong>信息降采样，信息丢失</strong>的问题，我们使用’atrous’孔洞卷积，减少pooling的使用，同时扩展感受野，以获得更多的上下文信息。<br><img src="/images/FCN/holeconv.png" alt="holeconv"><br>其中（a）为stride为2的pooling，pooling之后四个神经元的感受野对应为7。（b）中为stride = 1的pooling，四个神经元的感受野为5，虽然保留了更多的信息，但是感受野降低了，信息更加的冗余。（c）中使用stride=1，hole = 2的卷积核，四个神经元的感受野仍然为7，同时保留了更多的信息（features map的分辨率较高）。</p><p><strong>感受野的计算：</strong><br>感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。<br>当已知上一层的感受野计算下一层的感受野时有：<br>$$<br>r = (m-1) <em> stride+ksize<br>$$<br>其中m为上一层的感受野。<br><strong>空洞卷积的感受野计算：</strong><br>dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\</em>3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。</p><h4 id="全连接的CRF（条件随机场）"><a href="#全连接的CRF（条件随机场）" class="headerlink" title="全连接的CRF（条件随机场）"></a>全连接的CRF（条件随机场）</h4><p>DCNN的预测图可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓，其内在的不变性限制了对位置精度的预测<strong>（平移不变性破坏了模型对位置信息的预测）</strong>，<strong>本文使用了全连接的CRF作为后处理操作，通过耦合DCNN的识别能力进一步优化分割的边缘。</strong><br><strong>DenseDRF：</strong><br>对于每一个位置i，如果有观测值$x_i$(该位置的颜色)，标签$y_i$(类别信息)，。以像素为节点，像素与像素之间的关系作为边，就可以构成一个条件随机场，通过观测$x_i$的值来推断对应的类别信息$y_i$。<br><img src="/images/FCN/crf.png" alt="crf"><br>denseCRF的公式如下：<br><img src="/images/FCN/crfformula.png" alt="crfformula"><br>由式子可以看出来，CRF预测像素类别和像素的颜色强度，像素位置有关系，<strong>模型包含耦合相邻节点的能量项，有利于对空间邻近像素进行相同标签的分配。    </strong><br>下图是dilate conv + CRF的组合效果。<br><img src="/images/FCN/convCRF.png" alt="convCRF"></p><h4 id="Deeplab-v2"><a href="#Deeplab-v2" class="headerlink" title="Deeplab v2"></a>Deeplab v2</h4><p>deeplab v2在v1的基础上进行升级，其提出的<strong>ASPP技术来更好地分割多尺度的物体</strong>。通过采用最新的ResNet 图像分类DCNN构建了DeepLab的残差网络变体，实现了<strong>更好的语义分割性能。</strong><br>deeplab v2的特点：</p><ul><li>使用Atrous Convolution 代替原来上采样的方法，能有效地扩大卷积核的视野，增加更多的上下文信息而不增加参数的数量或计算量。 </li><li>提出多孔空间金字塔池化(ASPP)，在多尺度上鲁棒地分割物体。ASPP使用多个采样率和有效视野的滤波器对features map进行多尺度信息提取。 </li><li>第三，通过合并DCNN和概率图模型全连接CRF方法，增强物体边界的定位。</li></ul><p>DCNN应用于语义图像分割中的三个挑战:</p><ol><li><strong>特征分辨率下降问题解决：</strong><br>该问题是由连续DCNN层中的最大池化和下采样(滑动步长)的重复组合引起的。为了克服这一障碍并有效地产生更密集的特征图，<strong>将最后的池化层替换为atrous convolution 层</strong><br><img src="/images/FCN/convcompare.png" alt="convcompare"></li><li><p><strong>多尺度下的物体的存在</strong><br>该问题由于物体的多尺度状态引起的，有些物体太小或者太大无法检测出来。处理这种情况的一个标准方法是向DCNN提供相同图像的重缩放版本，然后聚合特征或分数图，但开销很大。我们的方法：<strong>我们有效地使用具有不同采样率的多个并行的多孔卷积层来实现对特征图的采样，称之为“多孔 space pyramid pooling”(ASPP)技术。</strong>在多个尺度上捕获物体的上下文信息。<br><img src="/images/FCN/spppool.png" alt="spppool"></p></li><li><p><strong>DCNN位移不变性导致对位置定位模糊：</strong><br>一种减轻此问题的方法是当计算最终的分割结果时使用跳跃层(skip-layers)从多个网络层提取特征。我们的方法是：<strong>通过全连接的条件随机场(CRF)来提高模型捕获精细细节的能力。</strong></p></li></ol><p><img src="/images/FCN/deeplap2.png" alt="deeplap2"></p><h4 id="deeplap-v2工作流程"><a href="#deeplap-v2工作流程" class="headerlink" title="deeplap v2工作流程"></a>deeplap v2工作流程</h4><ol><li>将所有全连接的层转换为卷积层</li><li>通过多孔卷积层对conv5输出的features map进行多尺度的特征提取，提高特征分辨率以及感受野，然后送入softmax进行分类。此时产生的features map大小为原图的1/8</li><li>采用双线性插值对features map进行8倍上采样以达到原始图像分辨率</li><li>生成全连接的CRF的输入，优化分割结果 </li></ol><p>值得注意的是：特征图的训练和全连接CRF的训练是分开进行的，先用DCNN生成预测结果图，然后用全连接CRF进行分割结果的优化。<br><img src="/images/FCN/resultCRF.png" alt="resultCRF"><br>上图是DCNN产生的预测图，然后通过1，2，10次的CRF迭代的结果。</p><h4 id="deeplab-v3"><a href="#deeplab-v3" class="headerlink" title="deeplab v3"></a>deeplab v3</h4><p>V3在v2的基础上进行了结构上了一些改进，<br><img src="/images/FCN/deeplabv3.png" alt="deeplabv3"><br>v3，v3+，Xecption这里实在不想在看了，以后有机会回来补充。先留一个flag。可能就是之后几天里某一天吧。state of art 似乎绕不过。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview Summary</title>
      <link href="/2019/02/21/Interview-Summary/"/>
      <url>/2019/02/21/Interview-Summary/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DP动态规划问题</title>
      <link href="/2019/02/21/DP%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/"/>
      <url>/2019/02/21/DP%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="DP动态规划问题"><a href="#DP动态规划问题" class="headerlink" title="DP动态规划问题"></a>DP动态规划问题</h3><p>  动态规划方法常常应用于解决优化问题，通常分析一个问题是否可以用动态规划方法求解可以从以几个方面判断：</p><ol><li>原问题可分，原问题的数据结构(array,tree,graph)可以进行划分。</li><li>原问题有最优子结构。</li><li>原问题的最优解将由一系列的子问题的解组合而成。</li></ol><p>动态规划法的一般<strong>思路</strong>为，通过枚举所有可能的分类策略，来组合成最优解。关键步骤在于找到一个合适的递推公式，将原问题转化为一个多步决策的问题。</p><p> 下面是重点介绍几个DP问题，以及他们的解题过程。 </p><p><strong>矩阵连乘问题：</strong><br> 问题描述：给定n个矩阵 $（A_1,A_2,A_3…..A_n）$，其中$A_i$与$A_{i+1}$是可乘的，i=1,2,…n-1。考察n个矩阵的连乘积 $A_1A_2A_3,….A_n$ 。由于矩阵乘法满足结合律，试提出矩阵连乘积最优计算次序，使得计算量最小。<br><strong>分析：</strong>确定矩阵相乘次序的问题等价于在原始序列上添加括号。通过改变不同位置上的矩阵的计算次序，能够减小矩阵乘法所需要的计算次数。经典的序列划分问题。现在来判断该问题是否可以用动态规划方法来求解：</p><ol><li>原问题是否可分：假设找到一个位置k添加括号能够得到最优解，因此将原问题转化为（1，k）与（k+1，n）两个序列，子问题性质与原问题完全相同，因此问题可分。</li><li>问题的递推公式（最优子结构）： $$ OPT[1,n] = OPT[1,k]+OPT[k+1,n] + p_0p_kp_{n+1} $$</li><li>由于子问题之间不存在相互关系，原问题的最优解由一系列子问题的最优解组成。 </li></ol><p><strong>矩阵连乘问题求解：</strong><br>若使用递归的方法，对原问题进行枚举，枚举每一种加括号的方式，能够得到原问题的解，但是计算量巨大，对这道题来说，他的时间复杂度是：$2^{n-1}$算法框架如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">recursive_matrix_chain(i,j)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> i == j then</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    OPT(i,j) = INF</span><br><span class="line">    <span class="keyword">for</span> k=i to j<span class="number">-1</span>:</span><br><span class="line">        q = recursive_matrix_chain(i,k)+</span><br><span class="line">            recursive_matrix_chain(k+<span class="number">1</span>,j)+</span><br><span class="line">            p[i]*p[k+<span class="number">1</span>]*p[j+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> q&lt;OPT(i,j):</span><br><span class="line">            OPT(i,j) = q</span><br><span class="line">     <span class="keyword">return</span> OPT(i,j)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>memorizing technique：</strong>动态规划法的英文为dynamic programming，programming 这个词最早有tabular这个词演化而来，tabular意为表格，因此DP方法可以直观的理解为动态填表法。动态规划法的一个重要思想就是：<strong>对子问题的结果进行保存。</strong><br>算法框架如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">memorize_matrix_chain(i,j)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> OPT[i,j] != <span class="literal">NULL</span>:  <span class="comment">//如果子问题已经算过了，就可以不用算了</span></span><br><span class="line">        <span class="keyword">return</span> OPT[i,j]</span><br><span class="line">    <span class="keyword">if</span> i == j:            <span class="comment">//递归法的出口</span></span><br><span class="line">        OPT[i,j] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> k = i to j - <span class="number">1</span>:  <span class="comment">//对每一个子问题划分情况进行枚举</span></span><br><span class="line">            q = memorize_matrix_chain(i,k)+</span><br><span class="line">                memorize_matrix_chain(k+<span class="number">1</span>,j)</span><br><span class="line">                + p[i]*p[k+<span class="number">1</span>]*p[j+<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> q &lt; OPT[i,j]:</span><br><span class="line">                OPT[i,j] = q</span><br><span class="line">    <span class="keyword">return</span> OPT[i,j]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该方法的时间复杂度为： $T(n) = O(n^3)$ ，动态规划问题的时间复杂度计算方法为：子问题的个数子问题的时间，对于本题： $O(n^2)n = O(n^3) $<br>一种更快的实现方法，从底往上计算省略递归步骤。 具体思路是：先将分割的长度由2到n进行遍历，每次拿出一个长度然后对其进行由i到j每个位置的划分，均求一个最大，对每次的结果进行保存，最后得出结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">matrix_chain_multiplication()</span><br><span class="line">&#123;</span><br><span class="line">    for i = 1 to n :</span><br><span class="line">        OPT[i,i] = 0</span><br><span class="line">    for l = 2 to n :  //子串的长度由2到n递增</span><br><span class="line">        for i = 1 to n - l + 1: //l长度下，对i所有可能位置进行遍历</span><br><span class="line">            j = i + l -1        // j移到子串的最后位置上</span><br><span class="line">            opt[i,j] = INF       </span><br><span class="line">            for k = i to j - 1: //对每一个位置均遍历一下括号的位置</span><br><span class="line">                q = opt[i,k]+opt[k+1,j]+p[i]*p[k+1]*p[j+1]</span><br><span class="line">                if q &lt; opt[i,j]:</span><br><span class="line">                    opt[i,j] = q</span><br><span class="line">                    s[i,j] = k</span><br><span class="line">    return opt[1,n]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>0/1背包问题</strong><br> 给定一个集合其中有S个物品，每个物品i有一个重量 w_i 和一个价值 v_i ，每个物品只有一个，你有一个能装重量为W的背包。问怎么装使得所装物品的价值最大。</p><p>分析：我们将0/1背包问题转化成一个多步决策的问题，在第i步决定是否选择第i个物品。因此有一下的递推表达式：<br>$$ opt({1,2,…n},W) = \max \begin{cases}  opt({1,2,…n-1},W)  &amp;   opt({1,2,…n-1},W-w_n)+v_n \end{cases}<br>$$<br>算法框架如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Knapsack(n,w)</span><br><span class="line">&#123;</span><br><span class="line">    for w = 1 to W:</span><br><span class="line">        OPT[0,w] = 0</span><br><span class="line">    for i = 1 to n:  //现在拿i个物品</span><br><span class="line">        for w = 1 to W:  // 现在拿出w个空间来装</span><br><span class="line">            if w &gt; w[i]:  //当前拿出的空间够装现在的货物</span><br><span class="line">            OPT[i,w] = max(opt[i-1][w],opt[i-1][w-w[i]]+v[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>回退法判断物品是否被取走：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void traceback()</span><br><span class="line">&#123;</span><br><span class="line">    for i = n to 2:</span><br><span class="line">        if(m[i][c] == m[i-1][c]):</span><br><span class="line">            x[i] = 0</span><br><span class="line">        else:</span><br><span class="line">            x[i] = 1</span><br><span class="line">            c -= w[i]</span><br><span class="line">    x[1] = m[1][c]&gt;0? 1:0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>时间复杂度为 O(nW) 伪多项式时间。$ O(nW) = O(n*2^{logW})$ ，W为输入的长度，当W很大时，算法效率很低。需要注意的是，我们选择物品的顺序是从头到尾挑选，而不是在一个子集中随机挑选。</p><p> <strong>最小覆盖点问题：</strong><br> 问题描述：在一个图中找到最少的点，使其能够覆盖图中所有的边。</p><p>问题分析：这个问题可以用一个树的结构的分析。当选取当前的点作为最优结果中的一点时，从从改点的所有子节点作为新的子问题，否则选取所有的儿子节点，从其孙子节点作为子问题。 该问题的最优子结构为：<br>$$ opt(root) = \min ( 1 + \sum_copt(c)  ,  children + \sum_gopt(g) )$$<br>算法框架如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vertex_cover(root)</span><br><span class="line">&#123;</span><br><span class="line">    if(root == NULL):</span><br><span class="line">       return 0</span><br><span class="line">    opt(root) = min(sum_of_child+opt(g),1+opt(c))</span><br><span class="line">    return opt(root)     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>动态规划问题的适用于求解那些子问题存在大量重复的问题，可以通过存储中间结果的方式大大缩小程序的复杂度。通常的求解方式有递归法，动态填表法。</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>语义分割系列 -- FCN详解</title>
      <link href="/2019/02/20/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%B3%BB%E5%88%97-FCN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/20/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%B3%BB%E5%88%97-FCN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="语义分割系列-–-FCN详解"><a href="#语义分割系列-–-FCN详解" class="headerlink" title="语义分割系列 – FCN详解"></a>语义分割系列 – FCN详解</h3><p>FCN是深度学习用于语义分割领域的开山之作，他的主要核心贡献在于：</p><ul><li><strong>全卷积（convolutional）：</strong>采样端对端的卷积网络，将普通分类网络的<strong>全连接层换上对应的卷积层（FCN）</strong></li><li><strong>上采样(upsample)</strong>：即反卷积（deconvolution），恢复图片的位置信息等，反卷积层可以通过最小化误差学习得到。</li><li><strong>跳跃连接(skip layer)</strong>：通过连接不同卷积层的输出到反卷积层，来改善上采样很粗糙的问题。</li></ul><blockquote><p>FCN：Fully Convolutional Networks for Semantic Segmentation<br>submit time: 2015<br><a href="https://arxiv.org/abs/1411.4038.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><h4 id="FCN与CNN"><a href="#FCN与CNN" class="headerlink" title="FCN与CNN"></a>FCN与CNN</h4><p>通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于<strong>图像级的分类和回归任务</strong>，因为它们最后都期望得到整个输入图像的一个数值描述<strong>（概率）</strong>，比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。<br>如下：下图中的猫, 输入AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高。<br><img src="/images/FCN/CNN.png" alt="CNN"><br>FCN相对用于图片分类领域的经典网络如Alexnet, VGG, Googlenet等只是在最后几层稍作了修改，替换，以让它们适用在了semantic segmentation上面。下图中可看出FCN相当于分类CNN网络在模型后端所有的变化。<br>FCN<img src="/images/FCN/FCN.png" alt="FCN"><br><strong>全卷积：</strong><br>前端输入，一般CNN分类网络选择使用固定大小的image patch来作为输入，这个patch往往是从原图当中剪切出来的；<strong>而FCN网络则使用整张原图来作为输入，允许图片大小不固定。</strong>然后在模型的后端，CNN分类网络会使用FC层对最后的CNN层生成出的feature map进行处理，从而丢掉由前端CNN各层处理所一直保存着的图片上敏感区域的位置信息，进而只抽象表达出它的类别信息来，以交由后面的softmax等层来最终预测出它的类别概率分布；<strong>FCN则不同，它丢掉了CNN分类网络后端的FC层，进而保留了图片上的区域位置信息，又在其后加上了几层CNN来进一步分析处理，整合主干网络输出特征，最终它生成出有着C+1（C为目标类别数，+1是为了考虑进去图片背景）个channels的heat map（本质上可以理解为是cnn所产生的feature map）来。</strong><br>由于FCN网络前端CNN处理过程中会不断选择用Pool来整合、下采样特征，从而扩大后来层次的receptive fields，因此最终我们生成出来的heat map其大小肯定要小于原输入图片大小。<strong>实际上最终生成的feature map比原图片缩小s倍</strong>，s为图片中下采样层次stride的乘积即累积下采样步长。<br>而我们Semantic segmentation的目标是要预测输入图片每个像素点的可能类别。因此我们要想办法将输出的heat map与input raw image关联起来。简单的话可以直接使用线性二次插值来解决。<strong>FCN中通过在网络最后加入步长为s的deconvolution层来使得最终的网络输出heat map具有与输入原图一样的大小</strong>。<br><strong>全连接层-&gt;卷积层</strong></p><ul><li>第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为k=7，padding = 0,stride = 1,共4096个卷积核，这样输出数据体就为[1x1x4096]了。</li><li>第二个全连接层，令其滤波器尺寸为K=1，共有4096个卷积核，这样输出数据体为[1x1x4096]。</li><li>对最后一个全连接层，令其K=1，共1000个卷积核，最终输出为[1x1x1000]</li></ul><p><strong>上采样：</strong><br>下图是一个反卷积的过程，首先在feature map上增加padding，padding的大小为Kernel size - 1，padding部分用0来填充。随后使用卷积核在对该feature 进行卷积操作。该图是一个strides(步长)为1的反卷积，即FULL卷积方式：<br><strong>full: 滑动步长为1，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：N1+N2-1 x N1+N2-1</strong><br><img src="/images/FCN/upsample.gif" alt="upsample"><br>下图是步长为2的反卷积，可以使得图片变大，反卷积中步长指的是原图像素间填充0的行数。这时候原图中就会出现孔，可以这么理解，反卷积与卷积对应，当卷积stride为2的时候，表明下一次卷积将跨越两个像素。<strong>当反卷积stride为2时，意味着反卷积的步长为0.5，即需要走2步才能走到下一个像素位置。</strong><br><img src="/images/FCN/upsample_stride.gif" alt="upsample_stride"><br>反卷积效果：<br><img src="/images/FCN/deconv.png" alt="deconv"></p><p><strong>跳跃连接(skip layer)：</strong><br>由于直接从最后的feature map上采样到图片大小，精度上过于粗糙，这是因为当网络较深时可以学到比较深度的特征，同时过深的网络也会丢失空间位置信息。这意味着较浅层的输出具有更多位置信息。如果我们将两者结合起来，我们就提高结果。<br><img src="/images/FCN/fcndeconv.jpg" alt="fcndeconv"><br><strong>训练过程：</strong><br>第一阶段：<br><img src="/images/FCN/step1.jpg" alt="step1"><br>用经典的分类网络进行初始化，最后两层参数不使用。<br><img src="/images/FCN/step2.jpg" alt="step2"><br>从特征图（16*16*4096）预测分割小图（16*16*21），之后直接上采样为大图。<br>反卷积（橙色）的步长为32，即特征图放大16倍，这个网络称为FCN-32s。<br><img src="/images/FCN/step4.jpg" alt="step3](/images/FCN/step3.jpg)上采样分为两次完成：第一次为橙色×2。在第二次上采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。 第二次反卷积步长为16，这个网络称为FCN-16s。!step4"><br>升采样分为三次完成（橙色×3）。进一步融合了第3个pooling层的预测结果。 第三次反卷积步长为8，记为FCN-8s。 </p><h4 id="LOSS"><a href="#LOSS" class="headerlink" title="LOSS"></a>LOSS</h4><p>FCN的loss 为交叉墒loss，先接一个soft Max将网络的输出转化为概率。用概率计算交叉墒。<br>tensorflow 中调用的函数为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,</span><br><span class="line">labels=tf.squeeze(annotation, squeeze_dims=[<span class="number">3</span>]),name=<span class="string">"entropy"</span>)))</span><br></pre></td></tr></table></figure></p><p>CNN 网络优化通常使用的是SGD，随机梯度下降法来优化。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cross entropy 交叉熵以及softmax</title>
      <link href="/2019/02/20/cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax/"/>
      <url>/2019/02/20/cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax/</url>
      
        <content type="html"><![CDATA[<h3 id="cross-entropy-交叉熵以及softmax"><a href="#cross-entropy-交叉熵以及softmax" class="headerlink" title="cross entropy 交叉熵以及softmax"></a>cross entropy 交叉熵以及softmax</h3><p>交叉熵常常用在CNN网络中，作为网络的loss，他描述的是模型数据分布与训练数据之间的相似程度。最小化交叉熵等价于模型产生数据与训练数据相似度越高。</p><p><strong>信息量：</strong><br>用来衡量一件事情的不确定程度，一件事情发生概率越大，他的不确定性越小，信息量越少。信息量的计算公式为：<br>$$<br>I(x_0) = - \log(P(x_0))<br>$$<br>例如，当$p(x_0) = 0.1,I(x_0) = 3.32$，$p(x_0) = 0.999,I(x_0) = 0.0014$</p><p><strong>熵：</strong><br>用于衡量一个系统的混乱程度，代表一个系统信息量的总和。当一个系统信息量越大越不稳定。熵等于所有事件所带来的信息期望总和。<br>$$<br>H(x) = - \sum_{x\in X}p(x) \log p(x)<br>$$<br><strong>交叉熵：</strong><br>交叉熵描述两个事件之间的相互关系：<br>$$<br>H(A,B) = -\sum_i P_{A}(x_i)log(P_{B}(x_i))<br>$$</p><p><strong>如何计算两个分布之间的不同： KL散度</strong><br>KL散度，有时候也叫KL距离，一般被用于计算两个分布之间的不同，KL散度不具备有对称性。<br>$$<br>D_{KL}(A||B) = \sum_i P_A(x_i)\log(\frac{P_A(x_i)}{P_B(x_i)}) = \sum_{i}P_{A}(x_i)log(P_{A}(x_i ))- \sum_i P_{A}(x_i)log(P_{B}(x_i))<br>$$<br>由上式可以发现，<strong>KL散度 = - 熵 + 交叉熵</strong>，当熵固定不变时，认为交叉熵等价于KL散度。</p><p><strong>机器学习中使用交叉熵代替KL散度：</strong><br>机器学习的过程中希望在训练数据上模型学到的分布 P(model) 和训练数据groundtruth的分布 P(real) 越接近越好，可以通过优化KL散度，使其KL散度最小来达到目的。<strong>由于训练数据groundtruth是固定的因此求解KL散度将会等价于求解交叉熵。</strong>因此最小化交叉熵将会得到一个比较好模型。</p><p><strong>softmax：</strong><br>在神经网络分类任务来说，最后一层将会输出x的一维特征，<strong>每一个位置表示一个特征表示值。这个表示值越大认为这张图片是这个类别的概率越大。</strong>因此可以用特征表示值来判断类别。但是在实际运用中，特征表示值的用途不大, 我们更希望得到具有统计意义的概率。例如可以利用概率来优化KL散度，使得预测结果更加准确。<strong>softmax它将多个神经元的输出，映射到（0,1）区间内，表示类别的概率，从而进行多分类。</strong><br>softmax的公式如下：<br>$$<br>S_i = \frac{e^{V_i}}{\sum_j{e^{V_j}}}<br>$$<br>其中V表示神经网络输出的一维数组。</p><p>softmax在实际使用时需要注意数值溢出的问题。如上公式，在计算概率的时候存在指数运算，当V数值很大的时候将会发生溢出。因此需要对上式做一下处理，将指数部分同时减去指数中的最大值。<br>$$<br>D = max(V) \\<br>S_i = \frac{e^{V_i - D}}{\sum_j{e^{V_j - D}}} = \frac{e^{V_i}}{\sum_j{e^{V_j}}} / \frac{D}{D}<br>$$<br>经过处理后，保证数值不会发生溢出现象。</p><h3 id="神经网络中的应用"><a href="#神经网络中的应用" class="headerlink" title="神经网络中的应用"></a>神经网络中的应用</h3><p>大多数的CNN网络中，均适用softmax + cross entropy作为损失函数。<br>首先是交叉熵LOSS：<br>$$<br>Loss = -\sum_i P_{groundtruth} \log P_{predict}<br>$$<br>其中$P_{groundtruth}$是真值的类别分布概率。在多分类问题中，一张图片只属于一个类别，因此$P_{groundtruth}$表示成one hot编码，即[0,0,…,1,0,0]这种形式。对于$P_{predict}$来说，神经网络输出的特征值经过softmax层，转换为概率的形式。因此Loss 最终会等于：$$-\log p_i$$i表示这个图片真实的类别。</p><h4 id="交叉熵-softmax反向求导："><a href="#交叉熵-softmax反向求导：" class="headerlink" title="交叉熵+ softmax反向求导："></a><strong>交叉熵+ softmax反向求导：</strong></h4><p>由上式可知，交叉熵的形式非常简单，其中$p_i$由softmax计算得到。带入softmax公式，得到交叉熵最后的形式为：<br>$$<br>L =  - \log \frac{e^{V_{i}}}{\sum_j e^{V_{j}}}<br>$$</p><p><strong>对交叉熵的求导：</strong><br>在进行BP方向传播的时候，更新参数的时候，误差需要由交叉熵提供，即$-\log p_i$，然后对每一个参数值通过链式法制都求一次偏导,例如对$W_{ij}$：<br>$$<br>\frac{\partial{L}}{\partial{W_{ij}}} = - \frac{1}{\frac{e^{a_i}}{\sum_k e^{a_k}}} \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}} \frac{\partial{a_j}}{\partial{W_{ij}}}<br>$$<br><strong>对softmax进行求导如下：</strong><br>上式中间部分为对softmax求导，令<br>$$<br> y_i = \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}<br>$$<br>对softmax求偏导数：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}}<br>$$<br>当 <code>i!=j</code> 时：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ 0 - e^{a_i}e^{a_j}}{\Sigma^2}=-\frac{e^{a_i}}{\Sigma}\frac{e^{a_j}}{\Sigma}=-y_iy_j<br>$$<br>当 <code>i==j</code> 时：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ e^{a_i}\Sigma - e^{a_i}e^{a_j}}{\Sigma^2}=\frac{e^{a_i}}{\Sigma}\frac{\Sigma - e^{a_j}}{\Sigma}=y_i(1 - y_j)<br>$$<br>求导过程比较简单，算一下就知道了，不要害怕。得到误差对权重的偏导数就可以对该权重进行更新了，CNN网络通常使用的更新方式为SGD。</p><h4 id="SGD-随机梯度下降法"><a href="#SGD-随机梯度下降法" class="headerlink" title="SGD 随机梯度下降法"></a>SGD 随机梯度下降法</h4><p>最优化算法的核心是从当前点走到下一个点，是的目标函数得到下降。即$x_0 -&gt; x_1$，最优化算法考虑两个问题，即从当前点，<strong>移动的方向和步长</strong>。可以写成下面形式：<br>$$<br>x_{k+1} = x_k + \eta P_k<br>$$<br>其中$P_k$是前进方向。令$P_k = -\nabla f_k$，即负梯度方向时，下降速度最快。这种方法在及其学习中称为梯度下降法。他有一个缺点，就是需要严格求解出整个数据集的梯度，才能走到下一步。而且十分容易陷入局部极小点,因此我们使用SGD来改善这一现象。<br>SGD 算法的表达式和GD差不多:<br>$$x_{t+1}=x_t+\eta_t g_t$$<br>这里 $g_t$ 就是所谓的Stochastic Gradient，它满足 $E[g_t]=-\nabla f(x_t)$。它对导数的要求非常低，导数算起来非常快。由于数据样本中存在大量无用的冗余信息，因此使用随机梯度下降法可以得到近似的下降梯度，而仅仅话费少量的计算资源。<br><strong>softmax tensorflow 实现版本</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># downlown the data</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input data</span></span><br><span class="line">X = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">Y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"><span class="comment"># model variable</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"><span class="comment"># define model</span></span><br><span class="line">y_predict = tf.matmul(X,W) + b</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=y_predict))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train_step = optimizer.minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">global_initial = tf.global_variables_initializer()</span><br><span class="line">sess.run(global_initial)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step,feed_dict=&#123;X:batch[<span class="number">0</span>],Y:batch[<span class="number">1</span>]&#125;)</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_predict,<span class="number">1</span>),tf.argmax(Y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line">print(sess.run(accuracy,feed_dict=&#123;X:mnist.test.images,Y:mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">print(sess.run(b))</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 题解(持续更新)</title>
      <link href="/2019/02/20/LeetCode-%E9%A2%98%E8%A7%A3/"/>
      <url>/2019/02/20/LeetCode-%E9%A2%98%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>本篇文章置顶，长期更新，用于记录日常刷题题解以及需要注意的tip。<br><a id="more"></a></p><p>2019年的关键词：思路要紧！</p><hr><p>28/5/2019</p><h3 id="116-Populating-Next-Right-Pointers-in-Each-Node-117"><a href="#116-Populating-Next-Right-Pointers-in-Each-Node-117" class="headerlink" title="116.Populating Next Right Pointers in Each Node,117"></a><a href="https://leetcode.com/problems/populating-next-right-pointers-in-each-node/" target="_blank" rel="noopener">116.Populating Next Right Pointers in Each Node</a>,117</h3><p>这一题看leetcode上的表示方式十分的唬人，实际上还算是比较简单。思路就是层次遍历，然后每次遍历用两个数来维护每一层的遍历次数。在元素进队列的时候进行左右的连接。（116的树为完全树，117的树不是完全树，同样的做法）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val, left, right, next):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        que    = []</span><br><span class="line">        que.append(root)</span><br><span class="line">        count  = <span class="number">1</span></span><br><span class="line">        record = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> len(que) &gt; <span class="number">0</span>:</span><br><span class="line">            node = que.pop(<span class="number">0</span>)</span><br><span class="line">            count -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                que.append(node.left)</span><br><span class="line">                record += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> len(que)&gt;<span class="number">1</span>:</span><br><span class="line">                    que[<span class="number">-2</span>].next = que[<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                que.append(node.right)</span><br><span class="line">                record += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> len(que)&gt;<span class="number">1</span>:</span><br><span class="line">                    que[<span class="number">-2</span>].next = que[<span class="number">-1</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">                node.next = <span class="keyword">None</span></span><br><span class="line">                count = record</span><br><span class="line">                record = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><hr><p>21/5/2019</p><h3 id="103-Path-Sum-II"><a href="#103-Path-Sum-II" class="headerlink" title="103. Path Sum II"></a><a href="https://leetcode.com/problems/path-sum-ii/" target="_blank" rel="noopener">103. Path Sum II</a></h3><p>思路：这一题可以沿着深度遍历的方向去做，然后在遍历的过程中，记录下路径。然后判断，当前path上的元素之和是否等于sum，并且当前节点是叶子结点。划重点：<u>sum(path) + root.val</u> 之和来判断，而不是把所有val都加到path上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.result = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_path</span><span class="params">(self,root,sums,path)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> sum(path) + root.val == sums <span class="keyword">and</span> root.left == <span class="keyword">None</span> <span class="keyword">and</span> root.right == <span class="keyword">None</span>:</span><br><span class="line">            self.result.append((path+[root.val])[:])</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        path.append(root.val)</span><br><span class="line">        self.find_path(root.left,sums,path)</span><br><span class="line">        self.find_path(root.right,sums,path)</span><br><span class="line">        <span class="keyword">if</span> path!=[]:</span><br><span class="line">            path.pop()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span><span class="params">(self, root, sum)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type sum: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        path = []</span><br><span class="line">        self.find_path(root,sum,path)</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br></pre></td></tr></table></figure><h3 id="114-Flatten-Binary-Tree-to-Linked-List"><a href="#114-Flatten-Binary-Tree-to-Linked-List" class="headerlink" title="114.Flatten Binary Tree to Linked List"></a><a href="https://leetcode.com/problems/flatten-binary-tree-to-linked-list/" target="_blank" rel="noopener">114.Flatten Binary Tree to Linked List</a></h3><p>思路：这一题太巧妙啦，要把所有节点压到右支上，这时候用的方法是先后续遍历，用一个变量记录上一个节点，然后作为当前节点的右节点，同时砍掉当前的左节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flatten</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: None Do not return anything, modify root in-place instead.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.prev = <span class="keyword">None</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(root)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">            dfs(root.right)</span><br><span class="line">            dfs(root.left)</span><br><span class="line">            root.right = self.prev</span><br><span class="line">            root.left = <span class="keyword">None</span></span><br><span class="line">            self.prev = root</span><br><span class="line">        dfs(root)</span><br></pre></td></tr></table></figure><hr><p>19/4/2019</p><h3 id="107-Binary-Tree-Level-Order-Traversal-II"><a href="#107-Binary-Tree-Level-Order-Traversal-II" class="headerlink" title="107. Binary Tree Level Order Traversal II"></a><a href="https://leetcode.com/problems/binary-tree-level-order-traversal-ii/" target="_blank" rel="noopener">107. Binary Tree Level Order Traversal II</a></h3><p>思路：哇，类似的专题好多啊，这一题要求按层次，从最后一层依次打印到第一层，与前面几题的区别在于，每次将层插入第一个位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrderBottom</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        line =[root]</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        val = []</span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            num-=<span class="number">1</span></span><br><span class="line">            val.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                res.insert(<span class="number">0</span>,val[:])</span><br><span class="line">                val = []</span><br><span class="line">                num = len(line)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>18/4/2019</p><h3 id="102-Binary-Tree-Level-Order-Traversal"><a href="#102-Binary-Tree-Level-Order-Traversal" class="headerlink" title="102. Binary Tree Level Order Traversal"></a><a href="https://leetcode.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="noopener">102. Binary Tree Level Order Traversal</a></h3><p>思路：层次遍历一棵树，最近做的题都比较接地气啊，都是大一做的题，哈哈我感觉记得这么清楚全要谢谢林老师。这一题要求把每一行的的元素依次打印出来，每一行一个list。</p><p>用队列结构来处理这个问题。首先从根节点开始，依次进队列，每次循环头节点出队列，并将其子节点进队列。然后维护一个计数器，计数器初始化为每一行list长度，当这个变量变成0的时候说明这一行已经遍历完成了。重新开一个list。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        line = []</span><br><span class="line">        line.append(root)</span><br><span class="line">        val = []</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            val.append(node.val)</span><br><span class="line">            num -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> node.left != <span class="keyword">None</span>:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right != <span class="keyword">None</span>:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                res.append(val)</span><br><span class="line">                val = []</span><br><span class="line">                num = len(line)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="103-Binary-Tree-Zigzag-Level-Order-Traversal"><a href="#103-Binary-Tree-Zigzag-Level-Order-Traversal" class="headerlink" title="103. Binary Tree Zigzag Level Order Traversal"></a><a href="https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/" target="_blank" rel="noopener">103. Binary Tree Zigzag Level Order Traversal</a></h3><p>思路：这一题沿着Z字形进行输出，只需要在上一题的基础上加一个记录层数的变量即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zigzagLevelOrder</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        line = []</span><br><span class="line">        line.append(root)</span><br><span class="line">        val = []</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        level = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            num -= <span class="number">1</span></span><br><span class="line">            val.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                num = len(line)</span><br><span class="line">                <span class="keyword">if</span> level%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                    val.reverse()                    </span><br><span class="line">                    res.append(val)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    res.append(val)</span><br><span class="line">                val = []</span><br><span class="line">                level += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>15/4/2019</p><h3 id="96-Unique-Binary-Search-Trees"><a href="#96-Unique-Binary-Search-Trees" class="headerlink" title="96. Unique Binary Search Trees"></a><a href="https://leetcode.com/problems/unique-binary-search-trees/" target="_blank" rel="noopener">96. Unique Binary Search Trees</a></h3><p>思路：这一题说给一个数字，求出所有平衡二叉树的个数。根据平衡二叉树的性质可以知道，左子树小于根节点，右子树大于根节点。因此有这种关系：</p><p>f(1) = f(0) x f(2), f(2)=f(1) x f(1), …  f(n) = f(n-1)xf(0)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numTrees</span><span class="params">(self,n)</span>:</span></span><br><span class="line">    res = [<span class="number">0</span>] *(n+<span class="number">1</span>)</span><br><span class="line">    res[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(j):</span><br><span class="line">        res[i] += res[j]*res[i-j<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="94-Binary-Tree-Inorder-Traversal"><a href="#94-Binary-Tree-Inorder-Traversal" class="headerlink" title="94. Binary Tree Inorder Traversal"></a><a href="https://leetcode.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="noopener">94. Binary Tree Inorder Traversal</a></h3><p>这一题要求按中序遍历的方式输出一颗二叉树。可用递归的方式解决。想起这道题，林老师上课的画面迎面而来，哈哈。</p><p>中序遍历思路为沿着树的枝往下走，当回溯时，第二次遇到这个节点的时候返回，此时记录下遍历的节点值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,root)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left)</span><br><span class="line">        self.res.append(root.val)</span><br><span class="line">        self.dfs(root.right)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.dfs(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br></pre></td></tr></table></figure><h3 id="101-Symmetric-Tree"><a href="#101-Symmetric-Tree" class="headerlink" title="101. Symmetric Tree"></a><a href="https://leetcode.com/problems/symmetric-tree/" target="_blank" rel="noopener">101. Symmetric Tree</a></h3><p>思路：这一题判断树是否是镜像。用树的结构进行递归，每次递归判断是否为镜像，如果不是则返回False。每次进行递归的时候传入树的对称边。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,left,right)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="keyword">None</span> <span class="keyword">or</span> right == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">if</span> left != right:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">if</span> left.val != right.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> self.dfs(left.left,right.right) <span class="keyword">and</span> self.dfs(left.right,right.left)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span> self.dfs(root.left,root.right)</span><br></pre></td></tr></table></figure><hr><p>25/3/2019</p><h3 id="92-Reverse-Linked-List-II"><a href="#92-Reverse-Linked-List-II" class="headerlink" title="92. Reverse Linked List II"></a>92. <a href="https://leetcode.com/problems/reverse-linked-list-ii/" target="_blank" rel="noopener">Reverse Linked List II</a></h3><p><strong>分析：</strong>这一题需要定义头节点，关于元素的调换的问题，都需要定义头节点。然后记住tail，head，思路清晰一点，就很好做了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseBetween</span><span class="params">(self, head, m, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type m: int</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> m == n:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        dummy = ListNode(<span class="number">-1</span>)</span><br><span class="line">        dummy.next = head</span><br><span class="line">        p = dummy</span><br><span class="line">        newhead = p</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            newhead = p</span><br><span class="line">            p = p.next</span><br><span class="line">        tail = p</span><br><span class="line">        q = p</span><br><span class="line">        p = p.next</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n-m):</span><br><span class="line">            p_pre = p.next</span><br><span class="line">            p.next = q</span><br><span class="line">            q = p</span><br><span class="line">            p = p_pre</span><br><span class="line">        tail.next = p_pre</span><br><span class="line">        newhead.next = q</span><br><span class="line">        <span class="keyword">return</span> dummy.next</span><br></pre></td></tr></table></figure><h3 id="93-Restore-IP-Addresses"><a href="#93-Restore-IP-Addresses" class="headerlink" title="93. Restore IP Addresses"></a><a href="https://leetcode.com/problems/restore-ip-addresses/" target="_blank" rel="noopener">93. Restore IP Addresses</a></h3><p><strong>分析：</strong>这一题蛮有意思的我感觉。它的内循环是从1到3，即截取的字符长度，每个截取的长度都作为ip地址的一部分。每次截取子串的时候需要对他们进行合法性判断。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.res = []</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(self,s,ret,index,count)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> count&gt;<span class="number">4</span>:</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">4</span> <span class="keyword">and</span> index == len(s):</span><br><span class="line">      self.res.append(res[:<span class="number">-1</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">      <span class="keyword">if</span> i + index &gt; len(s):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      temp = s[index,index+i]</span><br><span class="line">      <span class="keyword">if</span> (temp[<span class="number">0</span>] == <span class="string">'0'</span> <span class="keyword">and</span> len(temp)&gt;<span class="number">1</span>) <span class="keyword">and</span> (len(temp) <span class="keyword">and</span> int(temp)&gt;=<span class="number">256</span>):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      helper(s,ret+temp+<span class="string">'.'</span>,index+i,count+<span class="number">1</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">restoreIpAddresses</span><span class="params">(self,s)</span>:</span></span><br><span class="line">    self.helper(s,<span class="string">''</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> self.res</span><br></pre></td></tr></table></figure><hr><p>24/3/2019</p><h3 id="91-Decode-Ways"><a href="#91-Decode-Ways" class="headerlink" title="91. Decode Ways"></a><a href="https://leetcode.com/problems/decode-ways/" target="_blank" rel="noopener">91. Decode Ways</a></h3><p><strong>分析：</strong>这一题是典型的动态规划题，主要就是想到状态转移方程该怎么写就行了。有几种情况要进行分析。首先当前位置上为0的时候，当前的字母需要与前一个字母组成一个合法数据才行。否则就是按照正常的方式单个字母，两个字母的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numDecodings</span><span class="params">(self, s)</span>:</span> <span class="comment"># 动态规划</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> len(s) == <span class="number">0</span> <span class="keyword">or</span> s[<span class="number">0</span>] == <span class="string">'0'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [<span class="number">0</span>]*len(s)</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">'0'</span>:</span><br><span class="line">                <span class="comment"># 必须与前一个组成一个二位数</span></span><br><span class="line">                <span class="keyword">if</span> s[i<span class="number">-1</span>] == <span class="string">'2'</span> <span class="keyword">or</span> s[i<span class="number">-1</span>] == <span class="string">'1'</span> :</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                        dp[i] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        dp[i] = dp[i<span class="number">-2</span>]</span><br><span class="line">            <span class="keyword">elif</span> int(s[i<span class="number">-1</span>:i+<span class="number">1</span>])&lt;=<span class="number">26</span> <span class="keyword">and</span> s[i<span class="number">-1</span>]!=<span class="string">'0'</span>:</span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                    dp[i] = <span class="number">2</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i] = dp[i<span class="number">-1</span>]+dp[i<span class="number">-2</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i] = dp[i<span class="number">-1</span>]</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> dp[len(s)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><p>23/3/2019</p><p>这两天的状态和前两天一样，没办法调整🤢</p><h3 id="90-Subsets-II"><a href="#90-Subsets-II" class="headerlink" title="90. Subsets II"></a><a href="https://leetcode.com/problems/subsets-ii/" target="_blank" rel="noopener">90. Subsets II</a></h3><p>这题用递归的方法做，我觉得在做题的时候应该要多总结思路，首先就要确定这一题是什么类型的题目。然后向方法，一定唔要无头苍蝇似的，面试题差不多就median了，加油咯⛽️。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,nums,pos,temp,res)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> sorted(temp) <span class="keyword">not</span> <span class="keyword">in</span> res:</span><br><span class="line">            res.append(sorted(temp))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(pos,len(nums)):</span><br><span class="line">            temp.append(nums[i])</span><br><span class="line">            self.dfs(nums,i+<span class="number">1</span>,temp,res)</span><br><span class="line">            temp.pop()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsetsWithDup</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        self.dfs(nums,<span class="number">0</span>,[],res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>这一题有一个地方，需要注意一下，就是深浅拷贝的问题。（错过的问题）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">temp = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = temp <span class="comment"># 浅拷贝，a随着temp而变化</span></span><br><span class="line">a = temp[:] <span class="comment"># 深拷贝，a与temp无关</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = copy.deepcopy(temp) <span class="comment"># 深拷贝</span></span><br><span class="line"><span class="comment">## 排序问题</span></span><br><span class="line">a.sort() <span class="comment"># 直接改变a</span></span><br><span class="line">sorted(a) <span class="comment"># 返回值为排序后的结果</span></span><br></pre></td></tr></table></figure><h3 id="89-Gray-Code"><a href="#89-Gray-Code" class="headerlink" title="89. Gray Code"></a>89. <a href="https://leetcode.com/problems/gray-code/" target="_blank" rel="noopener">Gray Code</a></h3><p><strong>分析：</strong>这一题本来想要递归的方法来做，但是奈何，递归不满足格雷码依次变一位的原则。因此本题采用格雷码的公式求解。G(i) = i ^ (i/2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">grayCode</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>&lt;&lt;n):</span><br><span class="line">            res.append(i^i&gt;&gt;<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>21/3/2019</p><h3 id="100-Same-Tree"><a href="#100-Same-Tree" class="headerlink" title="100. Same Tree"></a><a href="https://leetcode.com/problems/same-tree/submissions/" target="_blank" rel="noopener">100. Same Tree</a></h3><p>最近有点儿奇怪呀， 明天想着做的事情，都没能做起来。</p><p><strong>分析：</strong> 这一题用递归调用的方式求解。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSameTree</span><span class="params">(self, p, q)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type p: TreeNode</span></span><br><span class="line"><span class="string">        :type q: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> p == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> q==<span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> q == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">if</span> p.val != q.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> self.isSameTree(p.right,q.right) <span class="keyword">and</span> self.isSameTree(p.left,q.left)</span><br></pre></td></tr></table></figure><hr><p>18/3/2019</p><h3 id="73-Set-Matrix-Zeroes"><a href="#73-Set-Matrix-Zeroes" class="headerlink" title="73. Set Matrix Zeroes"></a>73. Set Matrix Zeroes</h3><p><img src="/images/leetcode/73.png" alt=""></p><p>一直想刷题一直没刷，很惭愧。</p><p><strong>分析：</strong> 这一题是找出行活列含1的数，然后将整行置0。对呀python的数组，可以整行整行的赋值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix[key] = [<span class="number">0</span>]*n   <span class="comment"># 对key这一行整行赋值</span></span><br><span class="line"><span class="comment">#对列赋值,不可以整行</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">  matrix[i][key] = <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setZeroes</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type matrix: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: None Do not return anything, modify matrix in-place instead.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        dict_x = &#123;&#125;</span><br><span class="line">        dict_y = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> len(matrix) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> len(matrix[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        m = len(matrix)</span><br><span class="line">        n = len(matrix[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">                <span class="keyword">if</span> matrix[i][j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dict_x:</span><br><span class="line">                        dict_x[i] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> dict_y:</span><br><span class="line">                        dict_y[j] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> dict_x.keys():</span><br><span class="line">            matrix[key] = [<span class="number">0</span>]*n</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> dict_y.keys():</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">                matrix[i][key] = <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="77-Combinations"><a href="#77-Combinations" class="headerlink" title="77. Combinations"></a>77. Combinations</h3><p><img src="/images/leetcode/77.png" alt=""></p><p><strong>分析：</strong>这一题目的就是用递归的方式来求解，需要记住的是上一次的递归起点。需要注意的一点是，当一个list要添加另一个list作为一项时，使用：<code>list.append(list1[:])</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,n,idx,k,res,cur)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">      res.append(cur[:])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(idx,n):</span><br><span class="line">        <span class="keyword">if</span> k &gt; n-i:</span><br><span class="line">          <span class="keyword">return</span> []</span><br><span class="line">        cur.append(i+<span class="number">1</span>)</span><br><span class="line">        self.dfs(n,i+<span class="number">1</span>,k<span class="number">-1</span>,res,cur)</span><br><span class="line">        cur.pop()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">combine</span><span class="params">(self,n,k)</span>:</span></span><br><span class="line">    res = []</span><br><span class="line">    cur = []</span><br><span class="line">    dfs(n,<span class="number">0</span>,k,res,cur)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="78-Subsets"><a href="#78-Subsets" class="headerlink" title="78. Subsets"></a>78. Subsets</h3><p><img src="/images/leetcode/78.png" alt=""></p><p><strong>分析：</strong>这一题的思路是，看到这种递归问题，想到需要用循环来做。需要所有长度的情况都考虑进去。需要把所有的长度都考虑进去。因此要维护一个长度，由于不重复，因此需要维护一个下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,nums,idx,ilen,res,cur)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> ilen &gt; len(nums):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> len(cur) == ilen:</span><br><span class="line">            res.append(cur[:])    </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(idx,len(nums)):</span><br><span class="line">            cur.append(nums[i])</span><br><span class="line">            self.dfs(nums,i+<span class="number">1</span>,ilen+<span class="number">1</span>,res,cur)</span><br><span class="line">            cur.pop()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        cur = []</span><br><span class="line">        self.dfs(nums,<span class="number">0</span>,<span class="number">0</span>,res,cur)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="80-Remove-Duplicates-from-Sorted-Array-II"><a href="#80-Remove-Duplicates-from-Sorted-Array-II" class="headerlink" title="80. Remove Duplicates from Sorted Array II"></a>80. <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/" target="_blank" rel="noopener">Remove Duplicates from Sorted Array II</a></h3><p>这题从头扫描到尾巴，当情况符合的时候进行覆盖。le表示重复的个数，每一次覆盖条件满足都需要覆盖。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeDuplicates</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        le = <span class="number">0</span></span><br><span class="line">        pos = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i<span class="number">-1</span>] == nums[i]:</span><br><span class="line">                le += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> le&lt;<span class="number">2</span>:</span><br><span class="line">                    pos+=<span class="number">1</span></span><br><span class="line">                    nums[pos] = nums[i]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                le = <span class="number">0</span></span><br><span class="line">                pos+=<span class="number">1</span></span><br><span class="line">                nums[pos] = nums[i]</span><br><span class="line"> <span class="comment">#       nums[pos] = nums[len(nums)-1]</span></span><br><span class="line">        <span class="keyword">return</span> pos+<span class="number">1</span></span><br></pre></td></tr></table></figure><hr><p>14/3/2019</p><p><img src="/images/leetcode/71.png" alt=""></p><p><strong>分析：</strong> 犹豫要不要用python刷题，发现python实在是方便,这一题用stack的思路来做。首先用<code>/</code>把字符进行分割，然后用一个dict组织。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">simplifyPath</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type path: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        str = path.split(<span class="string">'/'</span>)</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> str:</span><br><span class="line">            <span class="keyword">if</span> ch == <span class="string">'..'</span>:</span><br><span class="line">                <span class="keyword">if</span> len(res) != <span class="number">0</span>:</span><br><span class="line">                    res.pop()</span><br><span class="line">            <span class="keyword">elif</span> ch!=<span class="string">''</span> <span class="keyword">and</span> ch!=<span class="string">'.'</span>:</span><br><span class="line">                res.append(ch)</span><br><span class="line">        ans = <span class="string">'/'</span></span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> res:</span><br><span class="line">            ans += ch+<span class="string">'/'</span></span><br><span class="line">        <span class="keyword">if</span> len(ans) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        <span class="keyword">return</span> ans[:len(ans)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><p>11/3/2019</p><h3 id="63-Unique-Paths-II"><a href="#63-Unique-Paths-II" class="headerlink" title="63. Unique Paths II"></a>63. Unique Paths II</h3><p><img src="/images/leetcode/63.png" alt=""></p><p><strong>分析：</strong>用动态规划做，递推公式为：$path[i][j] = path[i-1][j]+path[i][j-1]$。需要先把第一行和第一列先填上1。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; obstacleGrid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(obstacleGrid.size() == <span class="number">0</span>||obstacleGrid[<span class="number">0</span>].size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][<span class="number">0</span>] == <span class="number">1</span> ) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> height = obstacleGrid.size();</span><br><span class="line">        <span class="keyword">int</span> width = obstacleGrid[<span class="number">0</span>].size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt;&gt; path(height,<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt;(width,<span class="number">0</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;width&amp;&amp;obstacleGrid[<span class="number">0</span>][i]!=<span class="number">1</span>;i++)&#123;</span><br><span class="line">            path[<span class="number">0</span>][i] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height&amp;&amp;obstacleGrid[i][<span class="number">0</span>]!=<span class="number">1</span>;i++)&#123;</span><br><span class="line">            path[i][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;width;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[i][j] == <span class="number">1</span>) <span class="keyword">continue</span>;</span><br><span class="line">                path[i][j] = path[i<span class="number">-1</span>][j]+path[i][j<span class="number">-1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> path[height<span class="number">-1</span>][width<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="64-Minimum-Path-Sum"><a href="#64-Minimum-Path-Sum" class="headerlink" title="64. Minimum Path Sum"></a>64. Minimum Path Sum</h3><p><img src="/images/leetcode/64.png" alt=""></p><p><strong>分析：</strong>这一题和上一题差不多，唯一的区别在于这一题是找到最小的代价，因此去min就可以了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minPathSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(grid.size() == <span class="number">0</span> || grid[<span class="number">0</span>].size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> height = grid.size();</span><br><span class="line">        <span class="keyword">int</span> width = grid[<span class="number">0</span>].size();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;width;i++)&#123;</span><br><span class="line">            grid[<span class="number">0</span>][i] += grid[<span class="number">0</span>][i<span class="number">-1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;height;j++)&#123;</span><br><span class="line">            grid[j][<span class="number">0</span>] += grid[j<span class="number">-1</span>][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span> ;i&lt;height;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;width;j++)&#123;</span><br><span class="line">                grid[i][j] += min(grid[i<span class="number">-1</span>][j],grid[i][j<span class="number">-1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> grid[height<span class="number">-1</span>][width<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="65-Valid-Number"><a href="#65-Valid-Number" class="headerlink" title="65. Valid Number"></a>65. Valid Number</h3><p><img src="/images/leetcode/65.png" alt=""></p><p><strong>分析：</strong>字符串的转移这种问题很讨厌啊，情况太多了，总之思路就是从头到位扫一遍，判断很多边界情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isNumber</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>( !s.empty() )&#123;</span><br><span class="line">          s.erase(<span class="number">0</span>,s.find_first_not_of(<span class="string">" "</span>));</span><br><span class="line">          s.erase(s.find_last_not_of(<span class="string">" "</span>) + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">1</span>&amp;&amp;s[<span class="number">0</span>] == <span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">        amap[<span class="string">'-'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'+'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'.'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'e'</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;s.size())&#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="string">'0'</span>&lt;=s[i]&amp;&amp;s[i]&lt;=<span class="string">'9'</span>)&#123;</span><br><span class="line">                flag = <span class="number">1</span>;</span><br><span class="line">                i++;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'-'</span>||s[i] == <span class="string">'+'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'-'</span>] + amap[<span class="string">'+'</span>] &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;s[i<span class="number">-1</span>]==<span class="string">'e'</span>)&#123;</span><br><span class="line">                        i++;</span><br><span class="line">                        <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i!= <span class="number">0</span>&amp;&amp;s[i<span class="number">-1</span>]!=<span class="string">'e'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    i++;</span><br><span class="line">                        <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                amap[s[i]]++;</span><br><span class="line">                i++;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'.'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'.'</span>] != <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'e'</span>]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span>||(<span class="string">'0'</span>&lt;=s[i<span class="number">-1</span>]&amp;&amp;s[i<span class="number">-1</span>]&lt;=<span class="string">'9'</span>))&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'.'</span>]++;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(s[i<span class="number">-1</span>]==<span class="string">'-'</span>||s[i<span class="number">-1</span>]==<span class="string">'+'</span>)&#123;</span><br><span class="line">                     i++;</span><br><span class="line">                    amap[<span class="string">'.'</span>]++;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'e'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'e'</span>]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;(<span class="string">'0'</span>&lt;=s[i<span class="number">-1</span>]&amp;&amp;s[i<span class="number">-1</span>]&lt;=<span class="string">'9'</span>))&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'e'</span>]++;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(s[i<span class="number">-1</span>]==<span class="string">'.'</span>&amp;&amp;flag == <span class="number">1</span>)&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'e'</span>]++;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(amap[<span class="string">'.'</span>]||amap[<span class="string">'-'</span>]||amap[<span class="string">'+'</span>])&#123;</span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="69-Sqrt-x"><a href="#69-Sqrt-x" class="headerlink" title="69. Sqrt(x)"></a>69. Sqrt(x)</h3><p><img src="/images/leetcode/69.png" alt=""></p><p><strong>分析：</strong>这一题用二分法做比较快。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">mySqrt</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line"><span class="comment">//        int a = 0;</span></span><br><span class="line"><span class="comment">//        a = sqrt(x);</span></span><br><span class="line"><span class="comment">//        return a;</span></span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> r = x;</span><br><span class="line">        <span class="keyword">while</span>(l&lt;=r)&#123;</span><br><span class="line">            <span class="keyword">int</span> m = l+(r-l)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(m&gt;(x/m))&#123;</span><br><span class="line">                r = m<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                l = m+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> l<span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>10/3/2019</p><h3 id="54-Spiral-Matrix"><a href="#54-Spiral-Matrix" class="headerlink" title="54. Spiral Matrix"></a>54. Spiral Matrix</h3><p><img src="/images/leetcode/54.png" alt=""></p><p><strong>分析：</strong>这一题用最简单的四个循环这种思路求救最合适！然后需要注意的是，在对边界进行缩减的时候，需要保证仍然满足begin&lt;end的条件。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; spiralOrder(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(matrix.size() == <span class="number">0</span> || matrix[<span class="number">0</span>].size() == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> rowbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> rowend = matrix.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> colbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> colend = matrix[<span class="number">0</span>].size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(rowbegin&lt;=rowend&amp;&amp;colbegin&lt;=colend)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colbegin;i&lt;=colend;i++)&#123;</span><br><span class="line">                res.push_back(matrix[rowbegin][i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rowbegin++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowbegin;i&lt;=rowend;i++)&#123;</span><br><span class="line">                res.push_back(matrix[i][colend]);</span><br><span class="line">            &#125;</span><br><span class="line">            colend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend || colbegin&gt;colend) <span class="keyword">return</span> res;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colend;i&gt;=colbegin;i--)&#123;</span><br><span class="line">                res.push_back(matrix[rowend][i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rowend--;</span><br><span class="line">             <span class="keyword">if</span>(rowbegin&gt;rowend || colbegin&gt;colend) <span class="keyword">return</span> res;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowend;i&gt;=rowbegin;i--)&#123;</span><br><span class="line">                res.push_back(matrix[i][colbegin]);</span><br><span class="line">            &#125;</span><br><span class="line">            colbegin++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="55-Jump-Game"><a href="#55-Jump-Game" class="headerlink" title="55. Jump Game"></a>55. Jump Game</h3><p><img src="/images/leetcode/55.png" alt=""></p><p><strong>分析：</strong>与某一题很类似，总之记住记住当前位置能达到的最远距离的方法来求解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canJump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() &lt;= <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> lastindex = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(lastindex&lt;nums.size())&#123;</span><br><span class="line">            cur = max(lastindex+nums[lastindex],cur);</span><br><span class="line">            <span class="keyword">if</span>(cur&gt;=nums.size()<span class="number">-1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(cur==lastindex &amp;&amp; nums[lastindex] == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            lastindex++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="59-Spiral-Matrix-II"><a href="#59-Spiral-Matrix-II" class="headerlink" title="59. Spiral Matrix II"></a>59. Spiral Matrix II</h3><p><img src="/images/leetcode/59.png" alt=""></p><p><strong>分析：</strong>这一题属于构造nxn的一个数组，可以按照读取的方式进行构造。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; generateMatrix(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; matrix(n,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n,<span class="number">0</span>));</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> matrix;</span><br><span class="line">        <span class="keyword">int</span> rowbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> rowend = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> colbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> colend = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(rowbegin&lt;=rowend &amp;&amp; colbegin&lt;=colend)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colbegin;i&lt;=colend;i++)&#123;</span><br><span class="line">                matrix[rowbegin][i] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            rowbegin++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowbegin;i&lt;=rowend;i++)&#123;</span><br><span class="line">                matrix[i][colend] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            colend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend)</span><br><span class="line">                <span class="keyword">return</span> matrix;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colend;i&gt;=colbegin;i--)&#123;</span><br><span class="line">                matrix[rowend][i] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            rowend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend)&#123;</span><br><span class="line">                <span class="keyword">return</span> matrix;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowend;i&gt;=rowbegin;i--)&#123;</span><br><span class="line">                matrix[i][colbegin] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            colbegin++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> matrix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="60-Permutation-Sequence"><a href="#60-Permutation-Sequence" class="headerlink" title="60. Permutation Sequence"></a>60. Permutation Sequence</h3><p><img src="/images/leetcode/60.png" alt=""></p><p><strong>分析：</strong>递归全排列，当满足长度的个数到达k个时得到结果。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">    <span class="built_in">string</span> ans;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> n,<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(res.size() == n)&#123;</span><br><span class="line">            count++;</span><br><span class="line">            <span class="keyword">if</span>(count == k)&#123;</span><br><span class="line">                ans = res;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(count!=k)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(visit[i]==<span class="number">1</span>) <span class="keyword">continue</span>;</span><br><span class="line">                res += to_string(i);</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                dfs(n,k);</span><br><span class="line">                res = res.substr(<span class="number">0</span>,res.size()<span class="number">-1</span>);</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">getPermutation</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">         visit = <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n+<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line">        dfs(n,k);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="61-Rotate-List"><a href="#61-Rotate-List" class="headerlink" title="61. Rotate List"></a>61. Rotate List</h3><p><img src="/images/leetcode/61.png" alt=""></p><p><strong>分析：</strong>这题需要处理掉循环插的情况，即取模即可。然后就是正常的链表。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">rotateRight</span><span class="params">(ListNode* head, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>||head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        <span class="keyword">int</span> n = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">auto</span>  p = head;</span><br><span class="line">        <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            n++;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        k = k%n;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>) <span class="keyword">return</span> head;</span><br><span class="line">        p = head;</span><br><span class="line">        <span class="keyword">while</span>(n - k <span class="number">-1</span> &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            k++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> q = p-&gt;next;</span><br><span class="line">        <span class="keyword">auto</span> ans = q;</span><br><span class="line">        p-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">while</span>(q-&gt;next!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            q = q-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        q-&gt;next = head;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="70-Climbing-Stairs"><a href="#70-Climbing-Stairs" class="headerlink" title="70. Climbing Stairs"></a>70. Climbing Stairs</h3><p><img src="/images/leetcode/70.png" alt=""></p><p><strong>分析：</strong>动态规划法求解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n,<span class="number">0</span>);</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[i] = dp[i<span class="number">-1</span>]+dp[i<span class="number">-2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>7/3/2019</p><p>不知道为什么漏了6号，我明明都有做🐸</p><h3 id="51-N-Queens"><a href="#51-N-Queens" class="headerlink" title="51. N-Queens"></a>51. N-Queens</h3><p><img src="/images/leetcode/51.png" alt=""></p><p>N皇后递归最经典的问题，我觉得我在求解递归的问题的时候思路不是很清晰，总是做的不好，有必要总结一下。</p><h4 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h4><p>递归就是你需要确定一个循环机制，然后每次递归需要进行标记（不标记的话每次都执行一样的东西了），当然是根据条件进行标记的。因此对于递归的条件判断也需要十分注意，每次递归结束需要释放掉当前状况所添加的约束。</p><ol><li>定义约束变量，比如visit矩阵用于判断是否遍历过</li><li>确定主循环，主循环指需要对所有的子问题进行完整解析</li><li>将当情况的约束加到visit上，进行递归</li><li>确定递归返回条件，比如temp.size()&gt;=n</li><li>结束递归将当前约束释放掉</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//回溯法</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; res;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; visit;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; temp,<span class="keyword">int</span> pos,<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == n)&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(pos&gt;=n) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="function"><span class="built_in">string</span> <span class="title">s</span><span class="params">(n,<span class="string">'.'</span>)</span></span>;</span><br><span class="line">            <span class="keyword">if</span>(pos == <span class="number">0</span>)&#123;</span><br><span class="line">                s[i] = <span class="string">'Q'</span>;</span><br><span class="line">                temp.push_back(s);</span><br><span class="line">                visit[pos][i] = <span class="number">1</span>;</span><br><span class="line">                dfs(temp,pos+<span class="number">1</span>,n);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">                visit[pos][i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>((i==<span class="number">0</span>||visit[pos<span class="number">-1</span>][i<span class="number">-1</span>]!=<span class="number">1</span>)&amp;&amp;</span><br><span class="line">                    (i+<span class="number">1</span>==n||visit[pos<span class="number">-1</span>][i+<span class="number">1</span>]!=<span class="number">1</span>))&#123;</span><br><span class="line">                <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[j][i] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">int</span> tempi = i<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">int</span> tempj = pos<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&gt;=<span class="number">0</span>&amp;&amp;tempi&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj--][tempi--] == <span class="number">1</span>)&#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i+<span class="number">1</span>;</span><br><span class="line">                tempj = pos+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&lt;n&amp;&amp;tempi&lt;n)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj++][tempi++] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i+<span class="number">1</span>;</span><br><span class="line">                tempj = pos<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&gt;=<span class="number">00</span>&amp;&amp;tempi&lt;n)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj--][tempi++] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i<span class="number">-1</span>;</span><br><span class="line">                tempj = pos+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&lt;n&amp;&amp;tempi&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj++][tempi--] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;</span><br><span class="line">                    s[i] = <span class="string">'Q'</span>;</span><br><span class="line">                    temp.push_back(s);</span><br><span class="line">                    visit[pos][i] = <span class="number">1</span>;</span><br><span class="line">                    dfs(temp,pos+<span class="number">1</span>,n);</span><br><span class="line">                    temp.pop_back();</span><br><span class="line">                    visit[pos][i] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; solveNQueens(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;=<span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        visit = <span class="built_in">vector</span>(n,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n,<span class="number">0</span>));</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; temp;</span><br><span class="line">        dfs(temp,<span class="number">0</span>,n);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="206-Reverse-Linked-List"><a href="#206-Reverse-Linked-List" class="headerlink" title="206. Reverse Linked List"></a>206. Reverse Linked List</h3><p>递归题</p><p><img src="/images/leetcode/206.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">reverseList</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>||head-&gt;next == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* p = head-&gt;next;</span><br><span class="line">        ListNode* q = head;</span><br><span class="line">        q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">while</span>(p)&#123;</span><br><span class="line">            <span class="keyword">auto</span> temp = p-&gt;next;</span><br><span class="line">            p-&gt;next = q;</span><br><span class="line">            q = p;</span><br><span class="line">            p = temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> q;</span><br><span class="line">        <span class="comment">//递归做法，先将所有的节点打散，然后从最后一个慢慢往前连接</span></span><br><span class="line"><span class="comment">/*        if(head==NULL||head-&gt;next == NULL) return head;</span></span><br><span class="line"><span class="comment">        auto last = head-&gt;next;</span></span><br><span class="line"><span class="comment">        head-&gt;next = NULL;</span></span><br><span class="line"><span class="comment">        ListNode* newhead = reverseList(last);</span></span><br><span class="line"><span class="comment">        last-&gt;next = head;</span></span><br><span class="line"><span class="comment">        return newhead;*/</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="226-Invert-Binary-Tree"><a href="#226-Invert-Binary-Tree" class="headerlink" title="226. Invert Binary Tree"></a>226. Invert Binary Tree</h3><p><img src="/images/leetcode/226.png" alt=""></p><p><strong>分析：</strong>在每一次递归时进行左右交换。树的遍历方式算是递归的一种。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">TreeNode* <span class="title">invertTree</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">auto</span> p = root-&gt;left;</span><br><span class="line">        root-&gt;left = root-&gt;right;</span><br><span class="line">        root-&gt;right = p;</span><br><span class="line">        invertTree(root-&gt;left);</span><br><span class="line">        invertTree(root-&gt;right);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="104-Maximum-Depth-of-Binary-Tree"><a href="#104-Maximum-Depth-of-Binary-Tree" class="headerlink" title="104. Maximum Depth of Binary Tree"></a>104. Maximum Depth of Binary Tree</h3><p><img src="/images/leetcode/104.png" alt=""></p><p><strong>分析：</strong>每一次进步一个深度，然后如果为零返回。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> maxn = <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode* root,<span class="keyword">int</span> level)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">        dfs(root-&gt;left,level+<span class="number">1</span>);</span><br><span class="line">        dfs(root-&gt;right,level+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span>(maxn&lt;level) maxn = level;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        dfs(root,<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>5/3/2019</p><h3 id="49-Group-Anagrams"><a href="#49-Group-Anagrams" class="headerlink" title="49. Group Anagrams"></a>49. Group Anagrams</h3><p><img src="/images/leetcode/49.png" alt="49"></p><p><strong>分析：</strong>这道题使用哈希表来解决，记录是否有相同的元素被访问过。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; groupAnagrams(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; strs) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(strs.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;strs.size();i++)&#123;</span><br><span class="line">            <span class="keyword">auto</span> temp = strs[i];</span><br><span class="line">            sort(temp.begin(),temp.end());</span><br><span class="line">            <span class="keyword">if</span>(amap.count(temp) == <span class="number">0</span>)&#123;</span><br><span class="line">                amap[temp] = res.size();</span><br><span class="line">                <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; a;</span><br><span class="line">                a.push_back(strs[i]);</span><br><span class="line">                res.push_back(a);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res[amap[temp]].push_back(strs[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="82-Remove-Duplicates-from-Sorted-List-II"><a href="#82-Remove-Duplicates-from-Sorted-List-II" class="headerlink" title="82. Remove Duplicates from Sorted List II"></a>82. Remove Duplicates from Sorted List II</h3><p><img src="/images/leetcode/82.png" alt=""></p><p><strong>分析：</strong>这一题的思路其实很简单，就是当你要删除一个数的时候，你应该保证目前的指针指向要删除的数的前一个,因此需要保证next和next之后的数都不为空。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">deleteDuplicates</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* dummy = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        dummy-&gt;next = head;</span><br><span class="line">        <span class="keyword">auto</span> p = dummy;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next &amp;&amp; p-&gt;next-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val == p-&gt;next-&gt;next-&gt;val)&#123;</span><br><span class="line">                <span class="keyword">int</span> same = p-&gt;next-&gt;val;</span><br><span class="line">                <span class="keyword">while</span>(p-&gt;next&amp;&amp;p-&gt;next-&gt;val == same)&#123;</span><br><span class="line">                    p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dummy-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="83-Remove-Duplicates-from-Sorted-List"><a href="#83-Remove-Duplicates-from-Sorted-List" class="headerlink" title="83. Remove Duplicates from Sorted List"></a>83. Remove Duplicates from Sorted List</h3><p><img src="/images/leetcode/83.png" alt=""></p><p><strong>分析：</strong>这一题比较好做，唯一要注意的是不要判断p不为空。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">deleteDuplicates</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        <span class="keyword">auto</span> p = head;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val == p-&gt;val)&#123;</span><br><span class="line">               p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> p = p-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="86-Partition-List"><a href="#86-Partition-List" class="headerlink" title="86. Partition List"></a>86. Partition List</h3><p><img src="/images/leetcode/86.png" alt=""></p><p><strong>分析：</strong>我发现我链表的题做得还行。这一题思路是先走到链表尾巴，然后遇到比目标大的数，就截取下来放到最后。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">partition</span><span class="params">(ListNode* head, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* dummy = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        dummy-&gt;next = head;</span><br><span class="line">        <span class="keyword">auto</span> p = dummy;</span><br><span class="line">        <span class="keyword">auto</span> q = head;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next)&#123;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">        q = p;</span><br><span class="line">        p = dummy;</span><br><span class="line">        <span class="keyword">while</span>(count)&#123;</span><br><span class="line">            count--;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val &lt; x)&#123;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                q-&gt;next = p-&gt;next;</span><br><span class="line">                p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">                q = q-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> dummy-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="87-Scramble-String"><a href="#87-Scramble-String" class="headerlink" title="87. Scramble String"></a>87. Scramble String</h3><p><img src="/images/leetcode/87.png" alt=""></p><p><strong>分析：</strong>这一题用递归的方法做，感觉所有用递归的方法其实都是最耗时的方法，更好的方法可能是动态规划方法。总之递归之后应该有一个动归才是。然后基本思路是做两次判断，第一次两个串切在同一个位置上，第二次在首尾位置上。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isScramble</span><span class="params">(<span class="built_in">string</span> s1, <span class="built_in">string</span> s2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s1.size()==<span class="number">0</span>||s2.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(s1 == s2) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; letters(<span class="number">26</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s1.size();i++)&#123;</span><br><span class="line">            letters[s1[i]-<span class="string">'a'</span>]++;</span><br><span class="line">            letters[s2[i]-<span class="string">'a'</span>]--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">26</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(letters[i]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;s1.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(isScramble(s1.substr(<span class="number">0</span>,i),s2.substr(<span class="number">0</span>,i))&amp;&amp;</span><br><span class="line">              isScramble(s1.substr(i),s2.substr(i))) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(isScramble(s1.substr(<span class="number">0</span>,i),s2.substr(s1.size()-i))&amp;&amp;</span><br><span class="line">              isScramble(s1.substr(i),s2.substr(<span class="number">0</span>,s1.size()-i))) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>4/3/2019</p><h3 id="46-Permutations"><a href="#46-Permutations" class="headerlink" title="46. Permutations"></a>46. Permutations</h3><p><img src="/images/leetcode/46.png" alt=""><br><strong>分析：</strong>这一题是典型的排列问题，用递归的方式完成，然后用一个数组来标记当前的位置是否被读取过。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == nums.size())&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(visit[i] == <span class="number">0</span>)&#123;</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                temp.push_back(nums[i]);</span><br><span class="line">                dfs(nums,visit,temp);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; permute(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit(nums.size(),<span class="number">0</span>);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        dfs(nums,visit,temp);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="47-Permutations-II"><a href="#47-Permutations-II" class="headerlink" title="47. Permutations II"></a>47. Permutations II</h3><p><img src="/images/leetcode/47.png" alt=""><br><strong>分析：</strong>这一题与上一题的一个改善是，有重复的数，去重复的一个方法是对数组排序，如果当前的元素与上一个元素相同，并且上一个元素没有被访问过（意味着上一个元素曾经在这个位置上），直接跳过这个位置进入下一个位置。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//  set&lt;vector&lt;int&gt;&gt; res;</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == nums.size())&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(visit[i] == <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i<span class="number">-1</span>] == nums[i]&amp;&amp;visit[i<span class="number">-1</span>] == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                temp.push_back(nums[i]);</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                dfs(nums,visit,temp);</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">                temp.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; permuteUnique(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit(nums.size(),<span class="number">0</span>);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        dfs(nums,visit,temp);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="45-Jump-Game-II"><a href="#45-Jump-Game-II" class="headerlink" title="45. Jump Game II"></a>45. Jump Game II</h3><p><img src="/images/leetcode/45.png" alt=""><br><strong>分析：</strong>这一题用动态规划或者greedy来做，具体看代码即可。dp中对i之前每个位置进行判断，时间复杂度为$O(n^2)$ , greedy中cur指当前能到最远位置，last指上一步能到最远位置。然后需要排除掉一步不走的情况。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="comment">/*    int jump(vector&lt;int&gt;&amp; nums) &#123;</span></span><br><span class="line"><span class="comment">        if(nums.size() == 0) return 0;</span></span><br><span class="line"><span class="comment">        vector&lt;int&gt; dp(nums.size(),INT_MAX);</span></span><br><span class="line"><span class="comment">        dp[0] = 0;</span></span><br><span class="line"><span class="comment">        for(int i = 0;i&lt;nums.size() ;i++)&#123;</span></span><br><span class="line"><span class="comment">            for(int j = 0;j&lt;i;j++)&#123;</span></span><br><span class="line"><span class="comment">                if(nums[j]&gt;=i-j)&#123; </span></span><br><span class="line"><span class="comment">                    dp[i] = min(dp[i],dp[j]+1);</span></span><br><span class="line"><span class="comment">                &#125;</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return dp[nums.size()-1];</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">jump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> last = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size()<span class="number">-1</span> ;i++)&#123;</span><br><span class="line">            cur = max(cur,i+nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(i == last)&#123;</span><br><span class="line">                last = cur;</span><br><span class="line">                res++;</span><br><span class="line">                <span class="keyword">if</span>(last&gt;=nums.size()<span class="number">-1</span>) <span class="keyword">return</span> res;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="50-Pow-x-n"><a href="#50-Pow-x-n" class="headerlink" title="50. Pow(x, n)"></a>50. Pow(x, n)</h3><p><img src="/images/leetcode/50.png" alt=""><br><strong>分析：</strong>由于指数乘法可以由比他小的指数乘起来得到，一次可以用分治法来做。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">myPow</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">int</span> n1)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n1 == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1.0</span>;</span><br><span class="line">        <span class="keyword">if</span>(n1 == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> n = n1;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;<span class="number">0</span>)&#123;</span><br><span class="line">            n = -n;</span><br><span class="line">            x = <span class="number">1.0</span>/x;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">double</span> res = myPow(x,n/<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span>(n%<span class="number">2</span> == <span class="number">0</span>) <span class="keyword">return</span> res*res;</span><br><span class="line">        <span class="keyword">return</span> res*res*x;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>3/3/2019</p><h3 id="40-Combination-Sum-II"><a href="#40-Combination-Sum-II" class="headerlink" title="40. Combination Sum II"></a>40. Combination Sum II</h3><p><img src="/images/leetcode/40.png" alt=""><br><strong>分析：</strong>这一题用递归来求解，对于重复的问题，在执行一次递归之后，对重复的元素进行排除。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; candidates,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp,<span class="keyword">int</span> target,<span class="keyword">int</span> pos)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target == <span class="number">0</span>)&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = pos;i&lt;candidates.size()&amp;&amp;target&gt;=candidates[i];i++)&#123;</span><br><span class="line">            temp.push_back(candidates[i]); </span><br><span class="line">            dfs(candidates,temp,target-candidates[i],i+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">while</span>(i+<span class="number">1</span>&lt;candidates.size()&amp;&amp;candidates[i] == candidates[i+<span class="number">1</span>]) i++;</span><br><span class="line">            temp.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum2(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">if</span>(candidates.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        sort(candidates.begin(),candidates.end());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        dfs(candidates,temp,target,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="42-Trapping-Rain-Water"><a href="#42-Trapping-Rain-Water" class="headerlink" title="42. Trapping Rain Water"></a>42. Trapping Rain Water</h3><p><img src="/images/leetcode/42.png" alt=""><br><strong>分析：</strong>这一题之前做过，思路就是用两个数组，从左到右记录最大的val，从右到左记住最大的val，然后水坑的值就等于三个数组相减。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">trap</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(height.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; left(height.size());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; right(height.size());</span><br><span class="line">        left[<span class="number">0</span>] = height[<span class="number">0</span>];</span><br><span class="line">        right[height.size()<span class="number">-1</span>] = height[height.size()<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height.size();i++)&#123;</span><br><span class="line">            left[i] = max(left[i<span class="number">-1</span>],height[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = height.size()<span class="number">-2</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">            right[i] = max(right[i+<span class="number">1</span>],height[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;height.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = min(left[i],right[i])-height[i];</span><br><span class="line">            <span class="keyword">if</span>(temp&gt;<span class="number">0</span>) res += temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="44-Wildcard-Matching"><a href="#44-Wildcard-Matching" class="headerlink" title="44. Wildcard Matching"></a>44. Wildcard Matching</h3><p><img src="/images/leetcode/44.png" alt=""><br><strong>分析：</strong>字符串匹配问题多可以用动态规划来求解，思考动态规划问题的时候不要想太多步。就想着当前这一步有多少种情况就可以了。同时需要注意边界问题。<br>递推情况如下：<br>当<code>p[j] = &#39;*&#39;</code>:</p><ul><li>s[i-1]和p[j-1]进行匹配，s[i]和p[j]进行匹配。此时考虑*表示1个字符。</li><li>s[i-1]已经和p[j]进行了匹配，s[i]也仍然和p[j]进行匹配。此时考虑*表示n个字符。</li><li>s[i]和p[j - 1]进行了匹配，此时考虑*表示0个字符。</li></ul><p>当<code>p[j] = &#39;?&#39;</code>等：<br>p[j-1]与s[i-1]进行匹配，p[j],s[i]匹配。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = s.size(),n = p.size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(m+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(n+<span class="number">1</span>,<span class="literal">false</span>));</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p[i<span class="number">-1</span>] == <span class="string">'*'</span>) dp[<span class="number">0</span>][i] = dp[<span class="number">0</span>][i<span class="number">-1</span>]; <span class="comment">// s为空，p为连续* 号</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;=n;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(p[j<span class="number">-1</span>] == <span class="string">'*'</span>)&#123;</span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j]||dp[i][j<span class="number">-1</span>]||dp[i<span class="number">-1</span>][j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(p[j<span class="number">-1</span>] == <span class="string">'?'</span>||p[j<span class="number">-1</span>] == s[i<span class="number">-1</span>])&#123;</span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m][n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="67-Add-Binary"><a href="#67-Add-Binary" class="headerlink" title="67. Add Binary"></a>67. Add Binary</h3><p><img src="/images/leetcode/67.png" alt=""><br><strong>分析：</strong>做过类似的面试题，然后思路就是这样没错了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">addBinary</span><span class="params">(<span class="built_in">string</span> a, <span class="built_in">string</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = a.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> m = b.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> add = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;=<span class="number">0</span>&amp;&amp;m&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> le = a[n] - <span class="string">'0'</span>;</span><br><span class="line">            <span class="keyword">int</span> ri = b[m] - <span class="string">'0'</span>;</span><br><span class="line">            <span class="keyword">if</span>(le+ri+add&gt;=<span class="number">2</span>)&#123;</span><br><span class="line">                res = to_string(le+ri+add <span class="number">-2</span>) + res;</span><br><span class="line">                add = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res = to_string(le+ri+add) + res;</span><br><span class="line">                add = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            n--;</span><br><span class="line">            m--;</span><br><span class="line">        &#125;</span><br><span class="line">        res = (n&gt;=<span class="number">0</span>? a.substr(<span class="number">0</span>,n+<span class="number">1</span>):b.substr(<span class="number">0</span>,m+<span class="number">1</span>)) + res;</span><br><span class="line">        <span class="keyword">if</span>(add == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> left = n&gt;=<span class="number">0</span>? n:m;</span><br><span class="line">        <span class="keyword">while</span>(left&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(res[left] == <span class="string">'0'</span>)&#123;</span><br><span class="line">                res[left] = <span class="string">'1'</span>;</span><br><span class="line">                <span class="keyword">return</span> res;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res[left] = <span class="string">'0'</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            left--;</span><br><span class="line">        &#125;</span><br><span class="line">        res = <span class="string">'1'</span>+ res;</span><br><span class="line">        <span class="keyword">return</span> res;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>2/3/2019</p><h3 id="32-Longest-Valid-Parentheses"><a href="#32-Longest-Valid-Parentheses" class="headerlink" title="32. Longest Valid Parentheses"></a>32. Longest Valid Parentheses</h3><p><img src="/images/leetcode/32.png" alt=""><br><strong>分析：</strong>这一题括号匹配，用栈的结构来解决，每次将括号的下标存入栈的结构中。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestValidParentheses</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxn = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; sta;</span><br><span class="line">        sta.push(<span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'('</span>)&#123;</span><br><span class="line">                sta.push(i);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                sta.pop();</span><br><span class="line">                <span class="keyword">if</span>(!sta.empty())</span><br><span class="line">                maxn = max(maxn,i-sta.top());</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    sta.push(i);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="34-Find-First-and-Last-Position-of-Element-in-Sorted-Array"><a href="#34-Find-First-and-Last-Position-of-Element-in-Sorted-Array" class="headerlink" title="34. Find First and Last Position of Element in Sorted Array"></a>34. Find First and Last Position of Element in Sorted Array</h3><p><img src="/images/leetcode/34.png" alt=""><br>这一题题目要求复杂度是O(log(n)) 很显然就是用二分法来做的，然后如果找到了target，就往target的两边去找相同的元素。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; searchRange(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res = &#123;<span class="number">-1</span>,<span class="number">-1</span>&#125;;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> high = nums.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> mid;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;=high)&#123;</span><br><span class="line">            mid = (low+high)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] == target) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;target)&#123;</span><br><span class="line">                high = mid<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                low = mid+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(low&gt;high) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(i = mid<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] != target) &#123;<span class="keyword">break</span>;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res[<span class="number">0</span>] = i+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(i = mid + <span class="number">1</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=target) &#123; <span class="keyword">break</span>;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res[<span class="number">1</span>] = i<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="36-Valid-Sudoku"><a href="#36-Valid-Sudoku" class="headerlink" title="36. Valid Sudoku"></a>36. Valid Sudoku</h3><p><img src="/images/leetcode/36.png" alt=""><br><strong>分析：</strong>判断横排，竖排，里头九宫格即可。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isValidSudoku</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt;&amp; board)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(board.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//横排</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap.count(board[i][j]) != <span class="number">0</span> &amp;&amp;board[i][j]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                amap[board[i][j]] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//竖排</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap.count(board[j][i])!=<span class="number">0</span>&amp;&amp;board[j][i]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                amap[board[j][i]] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//九宫格</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i += <span class="number">3</span>)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j+=<span class="number">3</span>)&#123;</span><br><span class="line">                <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> h = i;h&lt;i+<span class="number">3</span>;h++)&#123;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> k = j;k&lt;j+<span class="number">3</span>;k++)&#123;</span><br><span class="line">                        <span class="keyword">if</span>(amap.count(board[h][k])!=<span class="number">0</span>&amp;&amp;board[h][k]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        amap[board[h][k]] = <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="39-Combination-Sum"><a href="#39-Combination-Sum" class="headerlink" title="39. Combination Sum"></a>39. Combination Sum</h3><p><img src="/images/leetcode/39.png" alt=""><br><strong>分析：</strong>经典的一道递归题，下次一定要会做才行，因为最基本的递归就长这个样子。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">digui</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates,<span class="keyword">int</span> target,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp,<span class="keyword">int</span> pos)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target == <span class="number">0</span>) res.push_back(temp);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = pos;i&lt;candidates.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(target&gt;=candidates[i])&#123;</span><br><span class="line">                temp.push_back(candidates[i]);</span><br><span class="line">                digui(candidates,target-candidates[i],temp,i);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">if</span>(candidates.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        digui(candidates,target,temp,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>1/3/2019</p><h3 id="38-Count-and-Say"><a href="#38-Count-and-Say" class="headerlink" title="38. Count and Say"></a>38. Count and Say</h3><p><img src="/images/leetcode/38.png" alt=""><br><strong>分析：</strong>这一题是递归的题，出口是n = 0 或 1，然后用for循环判断当前生成的字符。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">countAndSay</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>) <span class="keyword">return</span> <span class="string">"1"</span>;</span><br><span class="line">        <span class="built_in">string</span> s = countAndSay(n<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">string</span> newS = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">while</span>(i+<span class="number">1</span>&lt;s.size()&amp;&amp;s[i] == s[i+<span class="number">1</span>])&#123;</span><br><span class="line">                count++;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            newS += to_string(count) + s[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newS;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>2/28/2019</p><h3 id="30-Substring-with-Concatenation-of-All-Words"><a href="#30-Substring-with-Concatenation-of-All-Words" class="headerlink" title="30. Substring with Concatenation of All Words"></a>30. Substring with Concatenation of All Words</h3><p><img src="/images/leetcode/30.png" alt=""><br><strong>分析：</strong>控制一个words的所有字符长度的子串，然后在子串里面看是否满足条件。用hash_map做。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; findSubstring(<span class="built_in">string</span> s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; words) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(s.empty()||words.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> m = words[<span class="number">0</span>].size();</span><br><span class="line">        <span class="keyword">int</span> n = words.size();</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; m1;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;words.size();i++)&#123;</span><br><span class="line">            ++m1[words[i]];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;=(<span class="keyword">int</span>)s.size()-m*n;i++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;s.size();</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; m2;</span><br><span class="line">            <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(;j&lt;words.size();j++)&#123;</span><br><span class="line">                <span class="built_in">string</span> t = s.substr(i+j*m,m);</span><br><span class="line">                <span class="keyword">if</span>(m1.find(t) == m1.end()) <span class="keyword">break</span>;</span><br><span class="line">                ++m2[t];</span><br><span class="line">                <span class="keyword">if</span>(m2[t]&gt;m1[t]) <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(j == words.size()) res.push_back(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>2/26/2019</p><h3 id="53-Maximum-Subarray"><a href="#53-Maximum-Subarray" class="headerlink" title="53. Maximum Subarray"></a>53. Maximum Subarray</h3><p><img src="/images/leetcode/53.png" alt=""><br><strong>分析：</strong>这一题时简单的DP问题，用一个数存之前的序列和，当和小于0时则清零。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxn = INT_MIN;</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(ans&lt;<span class="number">0</span>) ans = <span class="number">0</span>;</span><br><span class="line">            ans += nums[i];</span><br><span class="line">            maxn = max(maxn,ans);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="15-3Sum"><a href="#15-3Sum" class="headerlink" title="15. 3Sum"></a>15. 3Sum</h3><p><img src="/images/leetcode/15.png" alt=""></p><p><strong>分析：</strong>这一题要找出所有的相加为0的组合，可以定义三个变量，用来控制数组中相加的数字，一个数字控制外循环，里头两个数字当遇到与前一个相同时，需要跳过。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; threeSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res; </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> begin = i+<span class="number">1</span>,end = nums.size()<span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i<span class="number">-1</span>]==nums[i]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">while</span>(begin&lt;end)&#123;</span><br><span class="line">                <span class="keyword">int</span> result = nums[i]+nums[end]+nums[begin];</span><br><span class="line">                <span class="keyword">if</span>(i!=end&amp;&amp; result == <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp = &#123;nums[i],nums[begin],nums[end]&#125;;</span><br><span class="line">                    res.push_back(temp);</span><br><span class="line">                    end--;</span><br><span class="line">                    <span class="keyword">while</span>(end&gt;=<span class="number">0</span>&amp;&amp;nums[end+<span class="number">1</span>] == nums[end]) end--;</span><br><span class="line">                    begin++;</span><br><span class="line">                    <span class="keyword">while</span>(begin&lt;nums.size()&amp;&amp;nums[begin<span class="number">-1</span>] == nums[begin]) begin++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(i==end||result&gt;<span class="number">0</span>) end--;</span><br><span class="line">                <span class="keyword">else</span> begin++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="16-3Sum-Closest"><a href="#16-3Sum-Closest" class="headerlink" title="16. 3Sum Closest"></a>16. 3Sum Closest</h3><p><img src="/images/leetcode/16.png" alt=""><br>这一题是上一题的变形，省去了判断过滤重复的步骤，只要求一个绝对值最接近1就好。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">threeSumClosest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = INT_MAX;</span><br><span class="line">        <span class="keyword">int</span> ans;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> j = i+<span class="number">1</span>,k = nums.size()<span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">while</span>(j&lt;k)&#123;</span><br><span class="line">                <span class="keyword">int</span> result = nums[i]+nums[j]+nums[k];</span><br><span class="line">                <span class="keyword">if</span>(i!=k&amp;&amp;<span class="built_in">abs</span>(result-target)&lt;=sum)&#123;</span><br><span class="line">                    sum = <span class="built_in">abs</span>(result-target);</span><br><span class="line">                    ans = result;</span><br><span class="line">                    <span class="keyword">if</span>(result&lt;target)j++;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(result&gt;target) k--;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(result&gt;target) k--;</span><br><span class="line">                <span class="keyword">else</span> j++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="17-Letter-Combinations-of-a-Phone-Number"><a href="#17-Letter-Combinations-of-a-Phone-Number" class="headerlink" title="17. Letter Combinations of a Phone Number"></a>17. Letter Combinations of a Phone Number</h3><p><img src="/images/leetcode/17.png" alt=""><br>这一题比较简单，把存结果的数组当作栈来用就行了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; letterCombinations(<span class="built_in">string</span> digits) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(digits.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt; alphabet = &#123;</span><br><span class="line">            &#123;&#125;, &#123;&#125;,&#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>&#125;,&#123;<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>&#125;,&#123;<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>&#125;,&#123;<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>&#125;,&#123;<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>&#125;,&#123;<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>&#125;,&#123;<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>&#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; tem(alphabet[digits[<span class="number">0</span>]-<span class="string">'0'</span>]);</span><br><span class="line">        <span class="built_in">string</span> a =<span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;tem.size();i++)&#123;</span><br><span class="line">             a += tem[i];</span><br><span class="line">             res.push_back(a);</span><br><span class="line">             a = <span class="string">""</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;digits.size();i++)&#123;</span><br><span class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; te(alphabet[digits[i]-<span class="string">'0'</span>]);</span><br><span class="line">            <span class="keyword">int</span> resSize = res.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;resSize;j++)&#123;</span><br><span class="line">                <span class="built_in">string</span> ahead = res[<span class="number">0</span>];</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>;k&lt;te.size();k++)&#123;</span><br><span class="line">                    res.push_back(ahead+te[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                res.erase(res.begin());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="18-4Sum"><a href="#18-4Sum" class="headerlink" title="18. 4Sum"></a>18. 4Sum</h3><p><img src="/images/leetcode/18.png" alt=""><br><strong>分析：</strong>这一题是前面三个数的加强版，注意一些重复的判断就行了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; fourSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() &lt; <span class="number">4</span>) <span class="keyword">return</span> res;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i] == nums[i<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i+<span class="number">1</span>;j&lt;nums.size();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j&gt;i+<span class="number">1</span>&amp;&amp;nums[j] == nums[j<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">int</span> begin = j+<span class="number">1</span>,end = nums.size()<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(begin&lt;end)&#123;</span><br><span class="line">                    <span class="keyword">int</span> result = nums[i]+nums[j]+nums[begin]+nums[end];</span><br><span class="line">                    <span class="keyword">if</span>(result == target)&#123;</span><br><span class="line">                        res.push_back(&#123;nums[i],nums[j],nums[begin],nums[end]&#125;);</span><br><span class="line">                        begin++;</span><br><span class="line">                        end--;</span><br><span class="line">                        <span class="keyword">while</span>(end&gt;begin&amp;&amp;nums[end] == nums[end+<span class="number">1</span>]) end--;</span><br><span class="line">                        <span class="keyword">while</span>(begin&lt;end&amp;&amp;nums[begin<span class="number">-1</span>] == nums[begin]) begin++;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(result &gt; target) end--;</span><br><span class="line">                    <span class="keyword">else</span> begin++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="19-Remove-Nth-Node-From-End-of-List"><a href="#19-Remove-Nth-Node-From-End-of-List" class="headerlink" title="19. Remove Nth Node From End of List"></a>19. Remove Nth Node From End of List</h3><p><img src="/images/leetcode/19.png" alt=""><br><strong>分析：</strong>这一题要求执行一趟，删除掉倒数第n个节点。可以用两个指针来完成，第一个指针领先第二个指针n的位置，当第一个指针到达终点时，第二个指针的位置就是倒数n的位置。然后需要注意删除第一个元素的情况。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">removeNthFromEnd</span><span class="params">(ListNode* head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        ListNode* pre = head;</span><br><span class="line">        ListNode* last = head;</span><br><span class="line">        ListNode* pos = head;</span><br><span class="line">        <span class="keyword">while</span>(n--)&#123;</span><br><span class="line">            pos = pos-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(pos == <span class="literal">NULL</span>) <span class="keyword">return</span> head-&gt;next; <span class="comment">//当删除第一个元素时</span></span><br><span class="line">        <span class="keyword">while</span>(pos!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            pre = last;</span><br><span class="line">            last = last-&gt;next;</span><br><span class="line">            pos = pos-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        pre-&gt;next = last-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="22-Generate-Parentheses"><a href="#22-Generate-Parentheses" class="headerlink" title="22. Generate Parentheses"></a>22. Generate Parentheses</h3><p><img src="/images/leetcode/22.png" alt=""><br><strong>分析：</strong>这是一道很经典的递归的题目，我做出一道就有感觉了。就是说看递归一定是这一步做了某种选择，待会还要回来。而且要比较注重递归程序的出口。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> nn;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ans;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">digui</span><span class="params">(<span class="built_in">string</span> res,<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(res.size() == <span class="number">2</span>*nn)&#123; ans.push_back(res);<span class="keyword">return</span>;&#125;</span><br><span class="line">        <span class="keyword">if</span>(left&lt;nn)  digui(res+<span class="string">"("</span>,left+<span class="number">1</span>,right);</span><br><span class="line">        <span class="keyword">if</span>(right&lt;nn&amp;&amp;right&lt;left) digui(res+<span class="string">")"</span>,left,right+<span class="number">1</span>);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; generateParenthesis(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> ans;</span><br><span class="line">        nn = n;</span><br><span class="line">        digui(<span class="string">""</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="24-Swap-Nodes-in-Pairs"><a href="#24-Swap-Nodes-in-Pairs" class="headerlink" title="24. Swap Nodes in Pairs"></a>24. Swap Nodes in Pairs</h3><p><img src="/images/leetcode/24.png" alt=""><br>调换两个数，需要三个指针，然后注意特殊情况只有一个数的时候的。直接放回head。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">swapPairs</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        ListNode* pre = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        ListNode* first = head;</span><br><span class="line">        ListNode* second = head-&gt;next;</span><br><span class="line">        pre-&gt;next = head;</span><br><span class="line">        <span class="keyword">if</span>(second == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        head = second;</span><br><span class="line">        <span class="keyword">while</span>(second != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            pre-&gt;next = second;</span><br><span class="line">            first-&gt;next = second-&gt;next;</span><br><span class="line">            second-&gt;next = first;</span><br><span class="line">            pre = first;</span><br><span class="line">            first = first-&gt;next;</span><br><span class="line">            <span class="keyword">if</span>(first!=<span class="literal">NULL</span>) second = first-&gt;next;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> head;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="29-Divide-Two-Integers"><a href="#29-Divide-Two-Integers" class="headerlink" title="29. Divide Two Integers"></a>29. Divide Two Integers</h3><p><img src="/images/leetcode/29.png" alt=""><br><strong>分析：</strong>这一题由于有越界问题，可以用long long申请变量，保证不会溢出。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">divide</span><span class="params">(<span class="keyword">int</span> dividend, <span class="keyword">int</span> divisors)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> divide = dividend;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> divisor = divisors;</span><br><span class="line">        <span class="keyword">if</span>(divisor == <span class="number">0</span>) <span class="keyword">return</span> divide;</span><br><span class="line">        <span class="keyword">int</span> sign = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(divisor&lt;<span class="number">0</span>) sign = <span class="number">-1</span>,divisor *= <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">if</span>(divide&lt;<span class="number">0</span>) sign *= <span class="number">-1</span>,divide *= <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">long</span> time = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(divide&gt;=divisor)&#123;</span><br><span class="line">            time++;</span><br><span class="line">            divide -= divisor;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(time*sign&gt;INT_MAX) <span class="keyword">return</span> INT_MAX;</span><br><span class="line">        <span class="keyword">if</span>(time*sign&lt;INT_MIN) <span class="keyword">return</span> INT_MIN;</span><br><span class="line">        <span class="keyword">return</span> time*sign;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><h3 id="4-median-of-two-sorted-array"><a href="#4-median-of-two-sorted-array" class="headerlink" title="4. median of two sorted array"></a>4. median of two sorted array</h3><p><img src="/images/leetcode/4median of two sort array.png" alt=""><br><strong>分析：</strong><br>这一题要找两个排序好的数组的中位数。</p><blockquote><p>中位数有一个性质就是一定位于数列的中间位置，而且中位数左边的数都小于中位数，中位数右边的数都大于中位数</p></blockquote><p>因此我们对数组位置进行分析时，需要保持中位数位置一定为数组长度的一半，又因为这道题对两个排序好的数组寻找中位数，因此可以分别对他们使用分治法求解。<br><img src="/images/leetcode/4median_analysis.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums2)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//首先拿到数组的长度，并设置nums1的长度大于nums2</span></span><br><span class="line">        <span class="keyword">int</span> m = nums1.size();</span><br><span class="line">        <span class="keyword">int</span> n = nums2.size();</span><br><span class="line">        <span class="keyword">if</span>(m&gt;n)&#123;   </span><br><span class="line">            <span class="keyword">auto</span> temp = nums1;</span><br><span class="line">            nums1 = nums2;</span><br><span class="line">            nums2 = temp;</span><br><span class="line">            swap(n,m);</span><br><span class="line">        &#125;<span class="comment">// n &gt; m</span></span><br><span class="line">        <span class="keyword">int</span> imin = <span class="number">0</span>,imax = m,half = (m+n+<span class="number">1</span>)/<span class="number">2</span>; <span class="comment">//half保证了长度为数列的一半</span></span><br><span class="line">        <span class="comment">//接下来在nums2数组中对中位数位置进行遍历</span></span><br><span class="line">        <span class="keyword">while</span>(imin&lt;=imax)&#123;</span><br><span class="line">            <span class="keyword">int</span> i = (imax-imin)/<span class="number">2</span> + imin; <span class="comment">// seperate nums1</span></span><br><span class="line">            <span class="keyword">int</span> j = half - i; <span class="comment">// j为num2的分割点，可以看出来j为一半的长度，不是下标</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;m &amp;&amp; nums1[i]&lt;nums2[j<span class="number">-1</span>]) <span class="comment">// i is too small</span></span><br><span class="line">            &#123;</span><br><span class="line">                imin = i+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums1[i<span class="number">-1</span>]&gt;nums2[j])&#123; <span class="comment">// i is to big</span></span><br><span class="line">                imax = i<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;  <span class="comment">// ferfect</span></span><br><span class="line">                <span class="keyword">int</span> max_left,min_right;</span><br><span class="line">                <span class="keyword">if</span>(i == <span class="number">0</span>)&#123;</span><br><span class="line">                    max_left = nums2[j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(j == <span class="number">0</span>)&#123;</span><br><span class="line">                    max_left = nums1[i<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    max_left = max(nums2[j<span class="number">-1</span>],nums1[i<span class="number">-1</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>((m+n)%<span class="number">2</span> == <span class="number">1</span>)&#123;</span><br><span class="line">                    <span class="keyword">return</span> max_left;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i == m)&#123;</span><br><span class="line">                        min_right = nums2[j];</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(j == n)&#123;</span><br><span class="line">                        min_right = nums1[i];</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span>&#123;</span><br><span class="line">                        min_right = min(nums1[i],nums2[j]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">return</span> (min_right+max_left)/<span class="number">2.0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="26-Remove-Duplicates-from-Sorted-Array"><a href="#26-Remove-Duplicates-from-Sorted-Array" class="headerlink" title="26. Remove Duplicates from Sorted Array"></a>26. Remove Duplicates from Sorted Array</h3><p><img src="/images/leetcode/26.png" alt=""></p><p><strong>分析：</strong><br>这一题思路比较简单，由于数组是排序过的，因此重复的数在相邻的位置上。所以做法就是用i遍历一边数组，用j保持数组不重复的长度，当出现不重复时<code>j++</code>，将不重复的数补充到j位置上。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">removeDuplicates</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(i&lt;nums.size()&amp;&amp;nums[j] == nums[i])&#123;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(i&lt;nums.size())</span><br><span class="line">            &#123;</span><br><span class="line">                j++;nums[j] = nums[i];</span><br><span class="line">            &#125;   </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> j+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="837-New-21-Game"><a href="#837-New-21-Game" class="headerlink" title="837. New 21 Game"></a>837. New 21 Game</h3><p><img src="/images/leetcode/21.png" alt="Alt text"></p><p><strong>分析：</strong><br>先吐槽一下自己，最近刷题有点儿太慢了。<br>这一题的题意是说，Alice每次都可以在1～W之间随机选择一个数，当Alice选择的数累加起来大于等于K的时候，Alice停止游戏。这时候这个累加和如果大于N那么Alice就输了，小于等于N Alice就赢了。题目叫我们算Alice赢得概率，就是累加和小于等于N的概率。</p><p>这一题可以用DP来求解,维护一个累加和窗。设dp[i]为当前累加和为i的时候的概率。要求i的概率有下面关系：<code>dp[i] = 1/w * (dp[i-1]+dp[i-2]...dp[i-w])</code>，即我可以先选择i-1，然后选1。由于可以选择的数只有W个，因此窗口宽度为W。对于累加和有下面的关系：</p><ul><li>i&lt;K : Wsum += dp[i] 表明当前的i可以作为下一次两步选择的第一步</li><li>i-W&gt;=0: Wsum -= dp[i-W] 表明对于下一个i来说，因为W的范围限定，取不到第dp[i-W]作为前两步选择的第一步，需要把概率减去，维护窗内概率。</li><li>N&gt;= i &gt;=K: res += dp[i]；结果为res,即这个时候分数在K与N之间。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">new21Game</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> K, <span class="keyword">int</span> W)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(K == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 共有N+1个状态</span></span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; dp(N+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">double</span> Wsum = <span class="number">1.0</span>;  <span class="comment">// 记录前W个数的概率</span></span><br><span class="line">        <span class="keyword">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">        dp[<span class="number">0</span>] =<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            dp[i] = Wsum/W;</span><br><span class="line">            <span class="keyword">if</span>(i&lt;K) Wsum+=dp[i];  <span class="comment">// 当前的i可以作为下一次两步选择的第一步</span></span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res += dp[i];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(i-W&gt;=<span class="number">0</span>) Wsum -= dp[i-W];  <span class="comment">//对于下一个i来说，当前的i-W下一个无法取到</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="481-Magical-String"><a href="#481-Magical-String" class="headerlink" title="481. Magical String"></a>481. Magical String</h3><p><img src="/images/leetcode/481.png" alt=""></p><p>这一题的题意是说，1和2将会交替出现，最开始1先出现，然后去产生下面的数，最后会发现产生的数组和每一行数字的个数序列将会是同一个序列。最后统计一下序列中1的个数。<br>数字的产生规则如下：</p><ul><li>先产生1</li><li>1与2交替出现</li><li>当前字符串最末尾的数字控制添加入字符串的字符个数，如122，表示下一次将加入2个1，变成12211</li><li>前三个数比较特殊，直接生成122</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">magicalString</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">string</span> s = <span class="string">"122"</span>;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(s.size()&lt;n)&#123;</span><br><span class="line">    s+= <span class="built_in">string</span>(s[i++]-<span class="string">'0'</span>,s.back() == <span class="string">'1'</span>? <span class="string">'2'</span>:<span class="string">'1'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count(s.begin(),s.begin()+n,<span class="string">'1'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>有几个新函数记录一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = string(char_num,char); //产生char_num个char</span><br><span class="line">count(s.begin(),s.begin()+n,&apos;1&apos;);//计算字符串s中含&apos;1&apos;的个数</span><br></pre></td></tr></table></figure></p><h3 id="2-Add-Two-Numbers"><a href="#2-Add-Two-Numbers" class="headerlink" title="2. Add Two Numbers"></a>2. Add Two Numbers</h3><p><img src="/images/leetcode/2.png" alt=""><br>这一题题意说的是用链表表示数字，表头为个位。然后将两个链表相加，计算他们的和，返回一个新的链表。<br>这一题比较简单，要注意的有种情况：</p><ul><li>链表相加完，有一个链表长度还有剩余</li><li>链表要记录进位，最后可能进位项还为1</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        ListNode* head = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">auto</span> p = head;</span><br><span class="line">        <span class="keyword">int</span> step = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l1!=<span class="literal">NULL</span>&amp;&amp;l2!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = l1-&gt;val + l2-&gt;val+step;</span><br><span class="line">            <span class="keyword">if</span>(sum&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                sum -= <span class="number">10</span>;</span><br><span class="line">                step = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                step = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            p-&gt;next = <span class="keyword">new</span> ListNode(sum);</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            l1 = l1-&gt;next;</span><br><span class="line">            l2 = l2-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> l = l1 != <span class="literal">NULL</span> ? l1 : l2;</span><br><span class="line">        <span class="keyword">if</span>(l!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(l!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = l-&gt;val +step;</span><br><span class="line">                <span class="keyword">if</span>(sum&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                    sum -= <span class="number">10</span>;</span><br><span class="line">                    step = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    step = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                p-&gt;next = <span class="keyword">new</span> ListNode(sum);</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">                l = l-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(step==<span class="number">1</span>)&#123;</span><br><span class="line">            p-&gt;next = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="数据大小及其表示的问题"><a href="#数据大小及其表示的问题" class="headerlink" title="数据大小及其表示的问题"></a>数据大小及其表示的问题</h3><ol><li><p>整数int的上下界：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最小的表示方式：-1&lt;&lt;31，INT_MIN</span><br><span class="line">最大的表示方式：1&lt;&lt;31 -1,INT_MAX</span><br></pre></td></tr></table></figure></li><li><p>其他类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unsigned int -&gt;UINT_MAX</span><br><span class="line">long-&gt;LONG_MAX</span><br><span class="line">unsigned long-&gt;ULONG_MAX</span><br></pre></td></tr></table></figure></li><li><p>无穷大的选择：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int INF = 0x7fffffff;</span><br></pre></td></tr></table></figure></li></ol><p><code>0x7fffffff</code> 是32-bit int的最大值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int INF = 0x3f3f3f3f</span><br></pre></td></tr></table></figure><p><code>0x3f3f3f3f</code>的十进制是1061109567，是10^9级别的（和一个数量级），而一般场合下的数据都是小于10^9的，可以用来表示无穷大。此外，<code>0x3f3f3f3f * 2 =2122219134</code>，这非常大但却没有超过32-bit int的表示范围，所以0x3f3f3f3f能够满足“无穷大加无穷大还是无穷大”的需求。<br>如果我们想要将某个数组清零，我们通常会使用memset(a,0,sizeof(a))。但是当我们想将某个数组全部赋值为无穷大时，就不能使用memset函数而得自己写循环了，因为memset是按字节操作的。如果我们将无穷大设为0x3f3f3f3f，0x3f3f3f3f的每个字节都是0x3f！所以要把一段内存全部置为无穷大，我们只需要memset(a,0x3f,sizeof(a))。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="keyword">sizeof</span>(a));  <span class="comment">//给a数组置0</span></span><br><span class="line"><span class="built_in">memset</span>(a，<span class="number">0x3f</span>,<span class="keyword">sizeof</span>(a));<span class="comment">//给a数组赋值正无穷</span></span><br></pre></td></tr></table></figure><ol start="4"><li>表示一个很小的数：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const long double eps = 1e-8;</span><br></pre></td></tr></table></figure></li></ol><p><code>1e-8</code> 是0.00000001，用来表示一个很小很小的数，通常可以用来判断两个数是否相同，即精度的差距。</p><hr><p>2/22/1019</p><h3 id="3-Longest-Substring-Without-Repeating-Characters"><a href="#3-Longest-Substring-Without-Repeating-Characters" class="headerlink" title="3. Longest Substring Without Repeating Characters"></a>3. Longest Substring Without Repeating Characters</h3><p><img src="/iamges/leetcode/3.png" alt=""><br><strong>分析：</strong><br>这一题题目非常好理解，找到字符串中的最长非重复子串。一看这一题的题目就感觉会有大量的元素比较，重复计算，因此可以用DP来做，用一个数组存储子问题的解。</p><p>维护一个数组res[j]，用来存储子问题的解，遍历原始数组，如果发现循环到的元素s[i]与res中最后一个位置所代表的元素不同，这res[j]++;如果发现相同这<code>j++;res[j] = res[j-1]-1</code>。具体写代码的时候里面有很多陷阱，看代码注释：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res(s.size());</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        res[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;s.size();i++)&#123; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = j;k&lt;i;k++)&#123; <span class="comment">//判断当前循环元素与子串中是否有重复</span></span><br><span class="line">                <span class="keyword">if</span>(s[k]==s[i])&#123;</span><br><span class="line">                    flag = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(j&gt;=i) <span class="keyword">continue</span>;  <span class="comment">//由于底下有i--的操作，需要保证j&lt;i</span></span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;  <span class="comment">// all different</span></span><br><span class="line">                res[j]++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;           <span class="comment">//如果有重复</span></span><br><span class="line">                flag = <span class="number">0</span>;</span><br><span class="line">                j++;        <span class="comment">//res表示的子串向前缩减</span></span><br><span class="line">                i--;        <span class="comment">//当前遍历到的元素需要保留</span></span><br><span class="line">            res[j] = res[j<span class="number">-1</span>]<span class="number">-1</span>&gt;<span class="number">0</span>? res[j<span class="number">-1</span>]<span class="number">-1</span> : <span class="number">1</span>; <span class="comment">//保证res[j]最小为1</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> *max_element(res.begin(),res.end());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p><strong>tip：</strong><br>关于vector找最大值最小值：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> maxValue = *max_element(s.begin(),s.end());</span><br><span class="line"><span class="keyword">int</span> minValue = *min_element(s.begin(),s.end());</span><br></pre></td></tr></table></figure></p><h3 id="5-Longest-Palindromic-Substring"><a href="#5-Longest-Palindromic-Substring" class="headerlink" title="5. Longest Palindromic Substring"></a>5. Longest Palindromic Substring</h3><p><img src="/images/leetcode/5.png" alt=""></p><p><strong>分析：</strong><br>找到最长的回文子串，可以用一个窗口去扫描，窗口的长度有2到字符串长度。该做法的时间复杂度为$O(n^2)$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">longestPalindrome</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> length = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> l = <span class="number">2</span>;l&lt;=s.size();l++)&#123; <span class="comment">// 回文的长度</span></span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;l&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size()-l+<span class="number">1</span>;i++)&#123;</span><br><span class="line">                <span class="keyword">int</span> j = i+l<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">int</span> temp = i;</span><br><span class="line">                <span class="keyword">while</span>(temp&lt;j)&#123;  <span class="comment">// 判断窗口内是否满足回文</span></span><br><span class="line">                    <span class="keyword">if</span>(s[temp]==s[j])&#123;</span><br><span class="line">                        temp++;</span><br><span class="line">                        j--;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span>&#123;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(temp&gt;=j)&#123;  <span class="comment">//说明满足回文</span></span><br><span class="line">                    pos = i;</span><br><span class="line">                    length = l;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> s.substr(pos,length);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>2/23/2019</p><h3 id="6-ZigZag-Conversion"><a href="#6-ZigZag-Conversion" class="headerlink" title="6. ZigZag Conversion"></a>6. ZigZag Conversion</h3><p><img src="/images/leetcode/6.png" alt=""><br><strong>分析：</strong>这一题题意要求生成zigZag字形的序列，如图。可以用下标间关系求解，规定i为行数，j为要输出位置的下标，则该序列中下标间存在以下关系：</p><ul><li>V口向上： j += 2*（numRows-i-1）</li><li>V口向下：j +=2i</li><li>第一行和最后一行处于V的交界位置，需要排除掉一种即可。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">convert</span><span class="params">(<span class="built_in">string</span> s, <span class="keyword">int</span> numRows)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">if</span>(numRows == <span class="number">1</span>) <span class="keyword">return</span> s;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;numRows;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> j = i;</span><br><span class="line">            <span class="keyword">while</span>(j&lt;s.size())&#123;</span><br><span class="line">                res += s[j];</span><br><span class="line">                j += <span class="number">2</span>*(numRows-i<span class="number">-1</span>);</span><br><span class="line">                <span class="keyword">if</span>(j&lt;s.size()&amp;&amp;i!=<span class="number">0</span>&amp;&amp;i!=numRows<span class="number">-1</span>)&#123;</span><br><span class="line">                    res += s[j];</span><br><span class="line">                &#125;</span><br><span class="line">                j += <span class="number">2</span>*i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="8-String-to-Integer-atoi"><a href="#8-String-to-Integer-atoi" class="headerlink" title="8. String to Integer (atoi)"></a>8. String to Integer (atoi)</h3><p><img src="/images/leetcode/8.png" alt=""><br><strong>分析：</strong>这一题做的我很狼狈，可以按从头到尾扫描的方式来做，我的做法太蠢了。特例很多。</p><ul><li>从头到位扫描。</li><li>当判断一个string 转成int是否超过精度的时候，可以申请一个long long类型的变量，判断他是否大于边界值。</li><li>char 转int的方式： <code>str[i] - &#39;0&#39;;</code>即可。 </li></ul><p>我的做法：（不推荐，虽然挺快的）<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(str.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">string</span> s = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;str.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s ==<span class="string">""</span>&amp;&amp;str[i] == <span class="string">' '</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(s==<span class="string">""</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">isdigit</span>(str[i])) s = str[i];</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(str[i] ==<span class="string">'-'</span>) s += <span class="string">'-'</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(str[i] == <span class="string">'+'</span>) s += <span class="string">'+'</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">if</span>(!<span class="built_in">isdigit</span>(str[i])) <span class="keyword">break</span>;</span><br><span class="line">                s+=str[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">1</span> &amp;&amp; s[<span class="number">0</span>] == <span class="string">'-'</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>((s[<span class="number">0</span>]==<span class="string">'+'</span>||s[<span class="number">0</span>]==<span class="string">'-'</span>)&amp;&amp;!<span class="built_in">isdigit</span>(s[<span class="number">1</span>])) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(s[<span class="number">0</span>] == <span class="string">'-'</span>)&#123;</span><br><span class="line">            flag = <span class="number">-1</span>;</span><br><span class="line">            s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(s[<span class="number">0</span>] == <span class="string">'+'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(s.size()&gt;<span class="number">1</span>&amp;&amp;s[<span class="number">0</span>]==<span class="string">'0'</span>)&#123;</span><br><span class="line">                s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">string</span> min = <span class="string">"2147483648"</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;<span class="number">10</span>)  <span class="keyword">return</span> flag == <span class="number">1</span>? INT_MAX:INT_MIN;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;=min.size()&amp;&amp;s&gt;=min) <span class="keyword">return</span> flag == <span class="number">1</span>? INT_MAX:INT_MIN; </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> stoi(s)*flag;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>比较合理的做法：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(str.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> base = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sign = <span class="number">1</span>,i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(str[i] == <span class="string">' '</span>) i++;</span><br><span class="line">    <span class="keyword">if</span>(str[i] == <span class="string">'+'</span>) i++;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(str[i] == <span class="string">'-'</span>) sign = <span class="number">-1</span>,i++;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;str.size()&amp;&amp;str[i]&gt;=<span class="string">'0'</span>&amp;&amp;str[i]&lt;=<span class="string">'9'</span>)&#123;</span><br><span class="line">        base = base*<span class="number">10</span> + str[i++]-<span class="string">'0'</span>;</span><br><span class="line">        <span class="keyword">if</span>(base&gt;INT_MAX) <span class="keyword">return</span> sign == <span class="number">1</span>?INT_MAX:INT_MIN;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> base*sign;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="35-Search-Insert-Position"><a href="#35-Search-Insert-Position" class="headerlink" title="35. Search Insert Position"></a>35. Search Insert Position</h3><p><img src="/images/leetcode/35.png" alt=""><br><strong>分析：</strong> 这一题可以用分治法来做，主要的点在于当要找的数不存在时，它如果比num[high]大，那么插入点为high（需要保证high&gt;=0），如果比high小，插入点为high+1<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">searchInsert</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> high = nums.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;=high)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (high+low)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] == target) <span class="keyword">return</span> mid;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;target) high = mid <span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">else</span> low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(high&gt;=<span class="number">0</span>&amp;&amp;nums[high]&gt;target) <span class="keyword">return</span> high;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> high+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>24/2/2019</p><h3 id="10-Regular-Expression-Matching"><a href="#10-Regular-Expression-Matching" class="headerlink" title="10. Regular Expression Matching"></a>10. Regular Expression Matching</h3><p><img src="/images/leetcode/10.png" alt=""><br>这道题的题意是判断两个字符串是否能够匹配，由于*号可以替换多个字符，因此这一题有一个递归的过程，也就是说，替换的个数可能是1，2…等等。所以要用递归的方法求解。</p><ul><li>当<code>p[1] == &#39;*&#39;</code>: 两种情况，<code>*</code>直接跳过；match一个字符；</li><li>当<code>p[1]!=*</code>: 则两个字符对应位置match</li></ul><p><strong>递归解法：</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p.empty())</span><br><span class="line">            <span class="keyword">return</span> s.empty();</span><br><span class="line">        <span class="keyword">if</span>(p[<span class="number">1</span>]==<span class="string">'*'</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> isMatch(s,p.substr(<span class="number">2</span>))||(!s.empty()&amp;&amp;(s[<span class="number">0</span>] == p[<span class="number">0</span>]||p[<span class="number">0</span>]==<span class="string">'.'</span>)&amp;&amp;isMatch(s.substr(<span class="number">1</span>),p));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> !s.empty()&amp;&amp;(s[<span class="number">0</span>]==p[<span class="number">0</span>]||p[<span class="number">0</span>]==<span class="string">'.'</span>)&amp;&amp;isMatch(s.substr(<span class="number">1</span>),p.substr(<span class="number">1</span>));</span><br><span class="line">      </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>动态规划法利用dp数组把所有的子情况都进行保存。有以下几种情形：</p><ul><li><code>dp[i][j]</code>: s(0,i) ,p(0,j)是否match</li><li>当 <code>p[j-1] != *</code>: <code>dp[i][j] == d[i-1][j-1]&amp;&amp;s[i-1] == p[j-1]</code> </li><li>当<code>p[j-1] == *</code>： 两种：有替换或无替换：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[i][j] = dp[i-1][j] //in this case, a* counts as multiple a </span><br><span class="line">dp[i][j] = dp[i][j-1] // in this case, a* counts as single a </span><br><span class="line">dp[i][j] = dp[i][j-2] // in this case, a* counts as empty</span><br></pre></td></tr></table></figure></li></ul><p><strong>动态规划：</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p.empty())</span><br><span class="line">            <span class="keyword">return</span> s.empty();</span><br><span class="line">        <span class="keyword">int</span> len1=s.size(),len2=p.size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(len1+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(len2+<span class="number">1</span>,<span class="literal">false</span>));</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>]=<span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;=len1;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=len2;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(p[j<span class="number">-1</span>]==<span class="string">'*'</span>)</span><br><span class="line">                    dp[i][j] = dp[i][j<span class="number">-2</span>] || ( i&gt;<span class="number">0</span> &amp;&amp; dp[i<span class="number">-1</span>][j] &amp;&amp; (s[i<span class="number">-1</span>]==p[j<span class="number">-2</span>] || p[j<span class="number">-2</span>]==<span class="string">'.'</span>) );</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    dp[i][j] = i&gt;<span class="number">0</span> &amp;&amp; dp[i<span class="number">-1</span>][j<span class="number">-1</span>] &amp;&amp; (s[i<span class="number">-1</span>]==p[j<span class="number">-1</span>] || p[j<span class="number">-1</span>]==<span class="string">'.'</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[len1][len2];</span><br><span class="line">    &#125; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="12-Integer-to-Roman"><a href="#12-Integer-to-Roman" class="headerlink" title="12. Integer to Roman"></a>12. Integer to Roman</h3><p><img src="images/leetcode/12.png" alt=""></p><p><strong>分析：</strong><br>这一题题意要求将普通数字表示称罗马数字，注意一一对应的关系即可。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">intToRoman</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">while</span>(num&gt;=<span class="number">1000</span>)&#123;</span><br><span class="line">            res += <span class="string">"M"</span>;</span><br><span class="line">            num -= <span class="number">1000</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">900</span>)&#123;</span><br><span class="line">            res+= <span class="string">"CM"</span>;</span><br><span class="line">            num -= <span class="number">900</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">500</span>) res+=<span class="string">'D'</span>,num -= <span class="number">500</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">400</span>) res += <span class="string">"CD"</span>,num -= <span class="number">400</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">                res +=<span class="string">'C'</span>;</span><br><span class="line">                num-=<span class="number">100</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">90</span>)&#123;</span><br><span class="line">            res += <span class="string">"XC"</span>;</span><br><span class="line">            num -= <span class="number">90</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">50</span>) res += <span class="string">'L'</span>,num -= <span class="number">50</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">40</span>)res+=<span class="string">"XL"</span>,num -= <span class="number">40</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                res +=<span class="string">'X'</span>;</span><br><span class="line">                num -= <span class="number">10</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">9</span>)&#123;</span><br><span class="line">            res += <span class="string">"IX"</span>;</span><br><span class="line">            num -= <span class="number">9</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">5</span>) res += <span class="string">"V"</span>,num -= <span class="number">5</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">4</span>)res +=<span class="string">"IV"</span>,num-=<span class="number">4</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">                res +=<span class="string">'I'</span>;</span><br><span class="line">                num -= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络-- CNN</title>
      <link href="/2019/02/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/"/>
      <url>/2019/02/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/</url>
      
        <content type="html"><![CDATA[<h3 id="卷积神经网络-–-CNN"><a href="#卷积神经网络-–-CNN" class="headerlink" title="卷积神经网络 – CNN"></a>卷积神经网络 – CNN</h3><p>CNN最早由LeCun 在1998年《Gradient-based learning applied to document recognition》中提出，并提出了一个目标检测的模型：LeNet-5，随后在2012年ImageNet竞赛上，基于CNN网络的AlexNet取得了第一，且正确率超出第二近10%，取得了历史性的突破。CNN开始大放异彩，VGG Net，Google Net，ResNet等，都是基于CNN网络的一些杰出的工作。</p><p><img src="/images/CNNnet/CNNhistory.png" alt="CNNhistory"></p><h4 id="CNN基本模块"><a href="#CNN基本模块" class="headerlink" title="CNN基本模块"></a>CNN基本模块</h4><p>CNN由输入和输出层以及多个隐藏层组成，隐藏层可分为<strong>卷积层</strong>，<strong>池化层</strong>、<strong>RELU层</strong>和<strong>全连通层</strong>，如下图：<br><img src="/images/CNNnet/conv.jpg" alt="conv"><br><strong>输入层</strong><br>CNN的输入为原始图像，三维（RGB）或二维的向量。<br><strong>卷积层</strong><br>卷积层是CNN的核心，卷积层由一组可学习的滤波器（filter）或内核（kernels）组成，它们具有小的感受野，每个卷积核具有kernel size，padding，stride等参数。从图像的左上角依次做内积操作，提取出图片的高层次特征。<br><strong>pooling layer</strong><br>池化层对conv后输出的feature map进行下采样操作，这样的好处有降低参数的数量，防止过拟合等作用。<br><strong>relu激活函数</strong><br>在CNN中使用relu激活函数，在网络中引入了非线性。通过relu激活函数传递卷积运算的结果。因此，最终特征映射中的值不是简单的线性关系。<br><strong>全连接层</strong><br>全连接层的输入是一维向量，需要将pooling 层的输出向量flatten成一个一维的向量，然后输入到全连接层中，最后送到soft Max层进行类别的分类。</p><p><strong>值得注意的是：</strong>在很多CNN网络结构中，pooling层的<strong>kernel = 2x2, stride = 2 ， padding = 0</strong>,经过这样的pooling后，<strong>输出图片缩小一半</strong>。 卷积层的<strong>kernel = 3x3, stride = 1， padding = 1</strong>。经过这样的卷积，<strong>输出大小与输入相同</strong>。</p><h4 id="CNN的特点"><a href="#CNN的特点" class="headerlink" title="CNN的特点"></a>CNN的特点</h4><p><strong>局部感知</strong><br>局部感知即卷积核的感受野，指的是卷积核所覆盖的像素面积，由于每个卷积核所覆盖的面积仅是很少的一部分，是局部特征，即为局部感知。CNN是一个从局部到整体的过程（局部到整体的实现是在全连通层）。下图是全连接层和卷积层的对比。<br><img src="/images/CNNnet/localview.png" alt="localview"></p><p><strong>权重共享</strong><br>传统的神经网络的参数量巨大，例如对1000X1000像素的图片做一次全连接操作，需要（1000X1000）10的6次方个参数。而CNN除全连接层外，卷积层的参数完全取决于滤波器的设置大小，比如10x10的滤波器，仅有100个参数。整个图片共享一组滤波器的参数，参数数量少，计算简单。<br><strong>多卷积核</strong><br>一种卷积核代表的是一种特征，为获得更多不同的特征集合，允许有多个卷积核，卷积生成的feature map有几个channel就有几个卷积核。</p><h4 id="dropout技术"><a href="#dropout技术" class="headerlink" title="dropout技术"></a>dropout技术</h4><p>dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，<strong>随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5）</strong>，与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。<br><img src="/images/CNNnet/dropout.png" alt="dropout"><br><strong>dropout的实现：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元</span></span><br><span class="line"><span class="comment">#dropout函数的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(x, level)</span>:</span></span><br><span class="line"><span class="keyword">if</span> level &lt; <span class="number">0.</span> <span class="keyword">or</span> level &gt;= <span class="number">1</span>:<span class="comment">#level是概率值，必须在0~1之间</span></span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'Dropout level must be in interval [0, 1[.'</span>)</span><br><span class="line">retain_prob = <span class="number">1.</span> - level</span><br><span class="line">    <span class="comment">#我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样</span></span><br><span class="line"><span class="comment">#硬币 正面的概率为p，n表示每个神经元试验的次数</span></span><br><span class="line"><span class="comment">#因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。</span></span><br><span class="line">sample=np.random.binomial(n=<span class="number">1</span>,p=retain_prob,size=x.shape)<span class="comment">#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了</span></span><br><span class="line"><span class="keyword">print</span> sample</span><br><span class="line">x *=sample<span class="comment">#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0</span></span><br><span class="line"><span class="keyword">print</span> x</span><br><span class="line">x /= retain_prob  <span class="comment"># 归一化</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#对dropout的测试</span></span><br><span class="line">x=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],dtype=np.float32)</span><br><span class="line">dropout(x,<span class="number">0.4</span>)</span><br></pre></td></tr></table></figure></p><p>dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。<br><strong>dropout能防止过拟合：</strong></p><ul><li>多样化学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。</li><li>阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不应该依赖于另外一个神经元。</li></ul><h3 id="CNN经典框架："><a href="#CNN经典框架：" class="headerlink" title="CNN经典框架："></a>CNN经典框架：</h3><h4 id="LeNet："><a href="#LeNet：" class="headerlink" title="LeNet："></a><strong>LeNet：</strong></h4><p>开始用于手写数字字体识别32*32，处理不了大型的图片，用于缺少计算机资源的时候。3个卷积层大小为5x5，2个pooling 层，大小为2x2。<br><img src="/images/CNNnet/Lenet.png" alt="Lenet"></p><ul><li>输入层，尺寸大于任何一个字母，以保证每个字母都会出现在第七层单元的感受野的中心。</li><li>中间五层分别是：卷积层→降采样层→卷积层→降采样层→卷积层。</li><li>第一个卷积层使用了六种滤波器，因此具有六个通道的 feature maps 。</li><li>第二个卷积层上升到16个通道。每一个通道与前6个通道的关系都不一样，见上图，目的是破坏对称性，迫使每个通道学习不同的特征（理想情况是互补特征）。</li><li>在全连接层，特征进行内积和非线性激活。</li><li>最后是输出层，10种数字对应10个输出单元，分别计算输出向量和该分类参考向量的欧式距离。</li><li>loss 为 MSE loss，输出向量和分类参考向量最近则将其判为这一类。<h4 id="AlexNet："><a href="#AlexNet：" class="headerlink" title="AlexNet："></a><strong>AlexNet：</strong></h4>AlexNet在2012年imageNet比赛上大放异彩，引发了神经网络的高潮，AlexNet共有5个卷积，5个pool，loss为softMax loss。<br><img src="/images/CNNnet/AlexNet.jpg" alt="AlexNet"></li></ul><p>该网络有以下的创新：<br>A. ReLU<br>之前使用的 tanh 和 sigmoid 激活函数都存在饱和区。改用无饱和的 ReLU ，收敛速度可以达到数倍于 tanh ！<br>B. Training on Multiple GPUs<br>2个 GPU 协同，最直接的作用是加快了训练速度。作者尝试将网络改为单GPU，同时保证参数数量不变，速度略逊于双 GPUs 。<br>C. Overlapping Pooling<br>实验证明，重叠池化可以更好地抑制过拟合，使准确率提高约0.4%和0.3%。<br>D. Data Augmentation<br>最简单的抑制过拟合技术，就是 label-preserving transformations 。简单来说，就是让图像进行各种不影响目标本质的变换，扩大数据量。</p><pre><code>- 镜像对称变换；- 图像光照强度和色彩变换。</code></pre><p>第二点具体而言：</p><pre><code>- 先提取 RGB 三通道分量；- 对每一个通道分别进行主成分分析，提取出主成分；- 然后再进行三通道的随机系数线性组合。</code></pre><p>E. Dropout<br>如果我们有多个不同的模型合作进行预测，那么泛化误差将会有效降低。问题是，训练多个模型的计算成本很高昂。Dropout 为我们提供了新思路：让这些模型分享相同的权重系数，但神经元的输出结果不尽相同。<br>具体而言，是让 hidden neuron 的输出有50%的概率被置零。这样，每次反向传播时，参考的 loss 都是由不同模型计算得到的。<br>总的来说，<strong>Dropout 技术打破了神经元之间的依赖性，强迫网络学习更鲁棒的神经元连接。</strong>我们只在全连接层使用，因为全连接层的连接非常多。在测试阶段不采用 Dropout 。Dropout 会延长收敛时间，但能有效抑制过拟合。</p><h4 id="VGG-Net："><a href="#VGG-Net：" class="headerlink" title="VGG Net："></a><strong>VGG Net：</strong></h4><p>VGG相对Googlenet虽然精度略逊些，但其整体网络框架还是延续了Alexnet及更早的Lenet等的一贯思路，此外还更深入的探讨了ConvNet深度对模型性能可能的影响。由于其整个网络结构的简单、强大，VGG16/VGG19曾一度广泛被用作各种检测网络框架像Faster-RCNN/SSD等的主干特征提取网络，直到Resnet提出之后，它才渐渐完成了其历史使命，退居二线。<br><img src="/images/CNNnet/VGGnet.jpg" alt="VGGnet"><br>VGGnet有许多中深度的版本，他们基本采用了3x3的Conv kernel，pad/stride为1，只是在其中的若干Conv层后会置MaxPool层来作特征的上采样以高度抽象特征，节省后续的计算。然后在每个网络的最后则是同其它分类网络一样的若干个FCs层及Softmax。其中VGG16与VGG19最为受人欢迎（最深）。</p><p>作者表明：<strong>两个级联的3x3 conv或三个级联的3x3 conv分别在理论上等价于一个5x5 conv及一个7x7 conv。</strong>不过它们所具的模型参数要大大小于后面两者的参数。同时作者实验表明更深（层数更多）而非更宽（conv channels更多）的网络有着自动规则自己参数的能力，因此有着更好的学习能力。VGG使用与AlexNet相同的SGD对网络进行训练。VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），<strong>采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）</strong>，相比于AlexNet使用更小的卷积核级联，更深的网络。</p><h4 id="GoogleNet：（inception）"><a href="#GoogleNet：（inception）" class="headerlink" title="GoogleNet：（inception）"></a><strong>GoogleNet：（inception）</strong></h4><p>尽管VGG可以在ImageNet上表现很好，但是将其部署在一个适度大小的GPU上是困难的，因为需要VGG在内存和时间上的计算要求很高。由于卷积层的通道数过大，VGG并不高效。<br>在此之前经典的CNN模型像LeNet/Alexnet/VGG等无不是一个模子即使用Conv/Pool/Normalization/Activation等层来不断累积而成。模型对数据集概率分布的表达能力则往往通过单纯增加模型的深度（层数）或宽度（层的channels数）来提高（当然这也亦是当下深度学习领域的共识）。但这样进行网络设计一般会等来巨量的计算开销，因为每一层channels数目的增加都会随着层深而指数级增加，这大大地限制了模型的实际应用。</p><p>GoogleNet则从提高精度以及减少计算量的角度出发，想通过一种spared layer architecture来实现较优的多维度特征表达（inception module），然后通过对这种结构进行叠加，中间不时再插入一些MaxPool层以减少参数数目（从而节省内存与计算开销），最终就形成了Inception v1分类模型。<br><img src="/images/CNNnet/inception.jpg" alt="inception"><br>GoogleNet团队计算效率以及GPU对密集计算的优化等等，选择了<strong>密集计算子结构组合而成的稀疏模块</strong>来用于特征提取及表达，这就是用于构建Inception v1的Inception module如上图中a所示。其中1x1/3x3/5x5这三种Conv kernels的选择决定是基于方便，因为这几种kernels用的多，而且比较容易对齐,padding。<br>但是a中的模型计算量太大，因此作者在每个子conv层里使用了<strong>1x1的conv</strong>来作上一层的输入<strong>feature maps的channels数缩减、归总</strong>。例如：<br>假设输入时 256 个 feature map 进来，256 个 feature map 输出，假设 Inception 层只执行 3x3 的卷积，那么这就需要这行 (256x256) x (3x3) 次卷积左右（大约 589,000 次计算操作），此时每一个特征的channel为256。<br>现在 Bottleneck layer 的思想是先来减少特征的通道数， 操作量(每次卷积核参数)是：<br>256(channel)×64(个) × 1×1 = 16,000s  -&gt; 与1x1的卷积层做一次卷积，通道数缩减为64<br>64(channel)× 64(个) × 3×3 = 36,000s<br>64× 256(个) × 1×1 = 16,000s<br>上诉处理能够大大减小计算量。<br>模型的最后会选通过一个7x7的AvgPool层来处理最终的feature maps，大大降低了参数量。然后再由FC层汇总生成1000个输出，进而由Softmax来得到1000类的概率分布。</p><h4 id="ResNet："><a href="#ResNet：" class="headerlink" title="ResNet："></a><strong>ResNet：</strong></h4><p>Resnet分类网络是当前应用最为广泛的CNN特征提取网络。它的提出于2015年。<br><strong>残差学习：</strong><br>若将输入设为X，将某一有参网络层设为H，那么以X为输入的此层的输出将为H(X)。一般的CNN网络如Alexnet/VGG直接通过训练学习出参数函数H的表达，即直接得到H(X)。<br>而残差学习则是学习输入、输出之间的<strong>残差即H(X) - X</strong>。即学习得到 (H(X) - X) 。最终的网络输出为：<strong>残差+X，其中X直接由identity mapping得到</strong>，而H(X) - X则为有参网络层要学习的输入输出间残差，优化难度大大减小。<br><img src="/images/CNNnet/residual.jpg" alt="residual"><br><strong>identity mapping：</strong>我们在输入与输出之间建立了一条连接，成为identity map，主要作用是将X传递到输出中，当输出与输入的channel数不一致时，通过直接补0或者用1x1 conv来映射。<br>在处理一些很复杂的数据集时，作者引入bottleneck结构，即下图的1x1 的conv，第一个conv用来降低通道数，最后一个conv用来恢复通道数，这样的操作是的中间的conv维度不受输入影响，降低运算量。<br><img src="/images/CNNnet/bottleneck.png" alt="bottleneck"></p><p><strong>退化现象：</strong>退化现象产生的原因在于当模型的结构变得复杂时，随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。通过建立identity map可以将浅层的信息传入深层网络，可以很好的缓解退化现象。</p><h4 id="inception-V2-V3："><a href="#inception-V2-V3：" class="headerlink" title="inception V2/V3："></a><strong>inception V2/V3：</strong></h4><p>inception V2/V3遵循上面的思路，进一步对inception v1结构中较大的卷积核进行分解。例如将5x5的卷积核分解成两个级联的3x3的卷积核，减少参数的同时，增加了网络的学习能力。<br><img src="/images/CNNnet/convsmall.jpg" alt="convsmall"><br><strong>更高效的下采样方式：</strong><br>由于对features map做pooling将会损失掉一部分的信息，为了减少这种信息的损失，在VGGnet中，通常的做法是pooling 的同时增大features map的channel的数量。googlenet中的做法是，分类对features map进行conv以及pooling，然后将最后得到的feature maps进行组合，得到最终的feature map。<br>作者认为，inception v1 中的辅助分类器起到的作用是对网络底层的参数进行归一化的作用，因此inception v3 在inception v2的基础上在辅助分类器中使用BN对参数进行regularization。同时在最终的loss中增加了标签平滑，用label的先验避免过拟合发生。</p><h4 id="inception-v4"><a href="#inception-v4" class="headerlink" title="inception v4"></a><strong>inception v4</strong></h4><p>inception v4使用tensorflow完成，涉及结构更加复杂，计算量也相比比较小。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中常用的技术（面试考点）</title>
      <link href="/2019/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%88%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%EF%BC%89/"/>
      <url>/2019/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%88%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="深度学习中常用的技术（面试考点）"><a href="#深度学习中常用的技术（面试考点）" class="headerlink" title="深度学习中常用的技术（面试考点）"></a>深度学习中常用的技术（面试考点）</h3><p>（一）神经网络中，防止过拟合的方法有：</p><ul><li>early stop（及早停止），当在测试集上出现错误率上升时，及时停止。</li><li>data expanding (扩大训练数据)</li><li>dropout 技术（随机丢弃）</li><li>加入正则项</li><li>BN（让激活函数的输入分布保持在一个稳定状态来尽可能避免它们陷入梯度饱和区。）</li></ul><h4 id="dropout技术"><a href="#dropout技术" class="headerlink" title="dropout技术"></a>dropout技术</h4><p>dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，<strong>随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5）</strong>，与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。<br><img src="/images/trick/dropout.png" alt="dropout"><br><strong>dropout的实现：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元</span></span><br><span class="line"><span class="comment">#dropout函数的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(x, level)</span>:</span></span><br><span class="line"><span class="keyword">if</span> level &lt; <span class="number">0.</span> <span class="keyword">or</span> level &gt;= <span class="number">1</span>:<span class="comment">#level是概率值，必须在0~1之间</span></span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'Dropout level must be in interval [0, 1[.'</span>)</span><br><span class="line">retain_prob = <span class="number">1.</span> - level</span><br><span class="line">    <span class="comment">#我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样</span></span><br><span class="line"><span class="comment">#硬币 正面的概率为p，n表示每个神经元试验的次数</span></span><br><span class="line"><span class="comment">#因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。</span></span><br><span class="line">sample=np.random.binomial(n=<span class="number">1</span>,p=retain_prob,size=x.shape)<span class="comment">#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了</span></span><br><span class="line"><span class="keyword">print</span> sample</span><br><span class="line">x *=sample<span class="comment">#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0</span></span><br><span class="line"><span class="keyword">print</span> x</span><br><span class="line">x /= retain_prob  <span class="comment"># 归一化</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#对dropout的测试</span></span><br><span class="line">x=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],dtype=np.float32)</span><br><span class="line">dropout(x,<span class="number">0.4</span>)</span><br></pre></td></tr></table></figure></p><p>dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。<br><strong>dropout能防止过拟合：</strong></p><ul><li>多尺度学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。</li><li>阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不依赖于另外一个神经元。</li></ul><h4 id="Batch-Normalization-参考链接"><a href="#Batch-Normalization-参考链接" class="headerlink" title="Batch Normalization 参考链接"></a>Batch Normalization <a href="https://zhuanlan.zhihu.com/p/34879333" target="_blank" rel="noopener">参考链接</a></h4><p>深层网络难以训练，由于底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；参数的变化导致每一层的输入分布会发生改变，进而上层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。<br><strong>Internal Covariate Shift：</strong> 在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。<br>因此而带来的问题：</p><ul><li>上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低</li><li>网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（可以使用线性整流函数ReLU因为它可以在一定程度上解决训练进入梯度饱和区的问题）</li></ul><p><strong>缓解Internal Covariate shift</strong><br>ICS产生的原因是由于参数更新带来的网络中每一层输入值分布的改变，并且随着网络层数的加深而变得更加严重，因此我们可以通过固定每一层网络输入值的分布来对减缓ICS问题。常用的方法如下：<br><strong>白化</strong>：<br>使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1；而ZCA白化则保证了所有特征分布均值为0，方差相同；去除特征之间的相关性。<br>但是由于白化操作计算成本高，且将会改变网络每一层参数的分布，使得网络底层学到的信息被丢弃<br><strong>batch normalization</strong><br> 单独对每个特征进行normalizaiton(每一层)，让每个特征都有均值为0，方差为1的分布，减少计算量。线性变换操作，让网络恢复本身的表达能力。<br>BN插在在全连接层之后如下图：<br><img src="/images/trick/bn.png" alt="bn"><br>BN操作如下：<br><img src="/images/trick/bnstep.png" alt="bnstep"></p><ol><li>对输入取均值</li><li>对输入取方差</li><li>计算normalize后的输入（其中 $\epsilon$ 是为了防止方差为0产生无效计算）</li><li>反标准化进行学习</li></ol><p>反标准化是为了让神经网络能够学习batch normalization的平移拉伸，让数据再能够尽可能恢复本身的表达能力就好，达到学习的目的。</p><p><strong>BN作用：</strong></p><ul><li>BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度</li><li>BN使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定。<strong>BN不会受到权重scale的影响</strong>，因此其能够使模型保持在一个稳定的训练状态；而没有加入BN的网络则在一开始就由于学习率过大导致训练失败BN的网络能够克服如此bad的权重初始化</li><li>BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题</li><li><strong>BN具有一定的正则化效果</strong>：在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，在一定程度上对模型起到了正则化的效果。</li></ul><h4 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h4><p><strong>L1 正则项：</strong> L1是模型各个参数的绝对值之和,将它添加到损失函数上：<br>$$\min  \frac{1}{N}\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_1<br>$$<br><strong>L2 正则项：</strong>是模型各个参数的平方和的开方值：<br>$$<br>\min  \frac{1}{N} \sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_{2}^{2}<br>$$<br>添加L1和L2正则项之后的损失函数如下：<br><img src="/images/trick/normal.jpg" alt="normal"><br>如图可以看出，如果仅有损失函数的话，优化目标为损失函数最内圈的紫色的环。但是给loss function加上正则化项，能使得新得到的优化目标函数h = f+normal，需要在f和normal中做一个权衡（trade-off），即最优解应该使得正则项和模型损失函数之和最小。</p><p>可以看出来，<strong>L1正则项与loss更多的相交于坐标轴，因此L1更容易产生稀疏解。L2的解比较接近与坐标轴，L2范数能让解比较小（靠近0），但是比较平滑（不等于0）</strong>。</p><p><strong>正则项降低过拟合程度：</strong></p><ul><li>L1正则化：在loss function后边所加正则项为L1范数，加上L1范数容易得到稀疏解（0比较多），能够避免过拟合。有助于生成一个稀疏权重矩阵，进而可用于特征选择。</li><li>L2正则化：在loss function后边所加正则项为L2范数的平方，L2控制w的大小，则w的幅度较小且较均匀。一般认为参数值较小的模型比较简单，能适应不同的数据集，一定程度上避免了过拟合。（缺点是L2对离群点敏感，而且容易造成梯度爆炸）</li><li>在Faster RCNN中，边框回归通常情况下，使用平方误差最小，即L2loss，但是由于，L2 loss对离群点比较敏感，同时，当预测边框距离真值边框比较远的时候，容易出现梯度爆炸的问题，因此使用smooth L1替代L2 loss，smooth L1 相比于正常的L1它是可导的。且导数是一个常数。</li></ul><p><strong>如何处理数据特征缺失项：</strong></p><ul><li>如果数据集样本很多，可以删除掉缺失的特征的个别样本。</li><li>用平均值，中位数，众数进行替换补全。（人为的增加了噪声）</li><li>使用一些机器学习的算法对数据特征进行恢复，如EM算法等等，KNN算法</li></ul><p><strong>异常值的检测：</strong></p><ul><li>当数值在$(\mu -3\sigma,\mu+3\sigma)$之外时，属于异常数值。</li><li>使用K nearnest neighbour计算每一个点的K近邻，然后距离临近点距离最远，而且周围的邻居位置很稀疏的情况下，这个点很可能是异常点。</li></ul><p><strong>canny边缘检测介绍：</strong><br>canny边缘检测是一个基于图像梯度的边缘检测算法。由于图像边缘即图像中的高频部分，噪音也属于高频信息，因此首先需要对图像进行去噪（高斯滤波器），然后提取图片梯度，然后对提取的梯度做一些例如非极大值抑制等处理，总之canny算子没有考虑到图片全局的信息，仅仅使用了梯度来提取边缘。对于一些梯度不明显的边缘信息可能无法很好的提取。</p><p><strong>max pooling 与 average pooling的应用有何不同：</strong></p><p>使用pooling技术将小邻域内的特征点整合，同时保持某种不变性（旋转、平移、伸缩等）。<strong>average-pooling对领域内特征取平均值</strong>，结果融合了所有的特征。平均操作类似与平滑处理，能够保留图片的低频信息，即更多的保留图像的背景信息。因此更多用在最后的分类中。<br>max-pooling对领域内的特征值取最大值，即能够极大的保留图片的边缘信息，纹理信息。一张图片的高频信息能够极大程度的表示一个物体，因此进行下采样特征缩减时更多用到max-pooling。</p><p><strong>训练过程中学习率如何调整：</strong></p><ul><li>从大到小依次衰减</li><li>或者使用RMSprop更新法，在累计梯度的平方项上进行衰减。</li></ul><p><strong>CNN网络中全连接层的作用：</strong><br>全连接层将学到的“分布式特征表示”映射到样本标记空间（进行分类）。全连接层参数过多（一个大型的分类问题，参数量通常占到80%）不宜有太多层全连接层。<br>是把卷积提取的特征看做多层感知机的输入节点，后面只需要接两层全连接理论上就可以拟合任意非线性函数，</p><p><strong>GAP（全局平均池化）：</strong><br>将每张feature的值全部加起来，取平均，每一个均值代表一个类别。比如有10个类，就在最后输出10个 feature map，每个feature map中的值加起来求平均值，这十个数字就是对应的概率或者叫置信度。然后把得到的这些平均值直接作为属于某个类别的 confidence value，再输入softmax中分类。用GAP代替全连接层可以大幅减小参数量，同时检测效果不会变差。</p><p><strong>维度灾难：</strong><br>对于大多数数据，在一维空间或者说是低维空间都是很难完全分割的，但是在高维空间间往往可以找到一个超平面，将其完美分割。于是我们将维度提升，例如从2维到3维这样就可以区分开物体了。但是无限制的增大数据的纬度，会出现分类进度极速下降的问题。即分类器过拟合，出现维度灾难。</p><p><strong>聚类方法：</strong><br>K-means 聚类</p><ul><li>首先确定样本的类别数n，然后在样本上随机确定n个中心</li><li>然后计算每一个样本到样本中心的距离，将该样本划分到距离它最近的那一类中</li><li>对划分过的样本重新计算各类的类中心</li><li>重复上述步骤，直到类中新位置不发生明显变化为止</li></ul><p>基于密度的聚类方法(DBSCAN)</p><ul><li>首先确定半径r和minPoints. 从一个没有被访问过的任意数据点开始，以这个点为中心，r为半径的圆内包含的点的数量是否大于或等于minPoints，如果大于或等于minPoints则该点被标记为central point，反之则会被标记为noise point。 </li><li>重复上面的步骤，如果一个noise point存在于某个central point为半径的圆内，则这个点被标记为边缘点，反之仍为noise point。重复上述步骤，直到所有的点都被访问过。 </li></ul><p><strong>混合高斯模型（GMM）最大期望（EM）聚类：</strong></p><ul><li>选择簇的数量（与K-Means类似）并随机初始化每个簇的高斯分布参数（均值和方差）。</li><li>给定每个簇的高斯分布，计算每个数据点属于每个簇的概率。一个点越靠近高斯分布的中心就越可能属于该簇。 </li><li>基于这些概率我们计算高斯分布参数使得数据点的概率最大化，可以使用数据点概率的加权来计算这些新的参数，权重就是数据点属于该簇的概率。 </li><li>重复迭代2和3直到在迭代中的变化不大。</li></ul><p><strong>自顶向下的层次分类：</strong></p><ul><li>将所有样本视为一类，然后对样本进行m次二分实验，然后选择一种分类，分类后的两簇SSE（Sum of the Squared Error）之和最小。</li><li>选择最大SSE的簇，然后对他重复上述分类，直到分类到k个簇。</li></ul><p><strong>L1 loss 为什么会导致稀疏解：</strong><br>如下图，原函数设为L，它的极小点为绿色的点，不在原点。加上L2 loss之后L+L2的极小点为黄点。加上L1后L+L1的极小点为红点。<br><img src="/images/trick/L1loss.jpg" alt=""></p><p>为什么L1 loss的最小点就是原点呢？<br>要形成极小值点，以上图为例，x<0 时="" l+c|x|="" 的导数要小于0(函数减)，同理x="">0 时导数&gt;0 (函数增)，x从左边趋近于0 时，C|x|的导数是-C，假设此时 L 的导数为 La ，必须有 La -C &lt;0，即C&gt;La，同理x从右边趋近于0时，必须有 Lb + C &gt; 0 ，即C&gt;-Lb，所以说C要大于L在0点附近的绝对值。<strong>即原点左右两边的导数正负不同，原点为一个极小点。</strong></0></p><p><strong>海量数据球中位数：</strong><br>使用堆的思想。查找中位数，也就是找出中间最大的数字，总共10G的数据，查找第5G大的数据，创建一个1G的大顶堆，遍历一遍这个10G的数据，找出前1G大的数据，在这个大顶堆中找出最小的值，这个最小的值就是这10G数据中第1G大的元素，然后利用这个元素在创建大顶堆，比这个元素小的才能进堆，那么就创建了从1G到2G的元素，这么一来，就找到了第2G大的元素，利用第2G大的元素就可以找到第5G大的元素，这么一来就可以找到中位数了。</p><p><strong>pooling 层如何进行反向传播：</strong></p><ul><li>max pooling层：对于max pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项的值都是0；</li><li>mean pooling层：对于mean pooling，下一层的误差项的值会平均分配到上一层对应区块中的所有神经元。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN详解</title>
      <link href="/2019/02/14/Faster-RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/14/Faster-RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="Faster-RCNN详解"><a href="#Faster-RCNN详解" class="headerlink" title="Faster RCNN详解"></a>Faster RCNN详解</h3><p>Faster RCNN 是在Fast RCNN的基础上，进一步改进，解决select search 算法选择候选框速度太慢的问题。</p><blockquote><p>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks<br>submit time: 2016<br><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>fast R-CNN和faster R-CNN之间的区别在于我们不使用特殊区域提议方法来创建region  proposal。而是训练一个<strong>region proposal network（RPN）</strong>，<strong>该网络将features map 作为输入并输出region proposals。然后将这些proposal输入Fast R-CNN中的RoI池化层</strong>。以下是fast RCNN与Faster RCNN的网络结构对比图。<br><img src="/images/fasternet/structure.png" alt="structure"><br><strong>Faster RCNN 关键步骤：</strong></p><ul><li>Conv layers。作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层<strong>提取image的feature maps</strong>。该feature maps被共享用于后续RPN层和全连接层。</li><li>Region Proposal Networks。<strong>RPN网络用于生成region proposals</strong>。该层通过softmax判断anchors属于foreground或者background，<strong>再利用bounding box regression修正anchors获得精确的proposals</strong>。</li><li>Roi Pooling。该层收集输入的feature maps和proposals，综合这些信息后<strong>提取proposal feature maps</strong>，送入后续全连接层判定目标类别。</li><li>Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。</li></ul><p>Faster RCNN 网络是用于目标检测的一种比较流行的框架。它主要由以下四个部分组成</p><ul><li>分别是conv layer 输入为原始图片，用于提取图片的feature map</li><li>RPN网络，输入为features map，用于生成region proposal，该层为features map 上每个像素生成若干个anchors（9个），随后通过softmax 判断每个anchor是属于foreground（目标）或者background（背景），再利用bounding box regression修正anchors获得精确的proposal位置。</li><li>RoI pooling，该层输入为proposal位置信息和features map，通过proposal的位置信息在features map 上提取region features map候选区，然后通过pooling产生一个固定长度的特征，送入全连接层进行目标判别。</li><li>classification，利用proposal feature maps计算proposal的类别，同时再次进行一次bounding box regression，对proposal位置进行精修，随后将结果输出。</li></ul><p>总结一套介绍网络框架的先后顺序的方法。</p><font color="red"> 可以先大后小，按照先后顺序从前到后，按功能性介绍一件事情，每件事情的功能介绍的时候，说清楚输入，工作流程附带其具体功能，输出。</font><p><strong>Faster RCNN 详细网络结构如图：</strong><br><img src="/images/fasternet/fasterrcnn_structure.jpg" alt="fasterrcnn_structure"></p><p>将一副任意大小PxQ的图像，首先缩放至固定大小MxN，然后将MxN图像送入网络；而卷积层 Conv layers中包含了<strong>13个conv层+13个relu层+4个pooling层</strong>；<strong>RPN网络</strong>首先经过3x3卷积，再分别生成foreground anchors与bounding box regression偏移量，然后计算出proposals；而<strong>Roi Pooling层则利用proposals以及feature maps，提取proposal feature</strong>送入后续全连接和softmax网络作classification。</p><h4 id="conv-layer"><a href="#conv-layer" class="headerlink" title="conv layer"></a>conv layer</h4><p><img src="/images/fasternet/vgg.jpg" alt="vgg"></p><p>Conv layers部分共有13个conv层，13个relu层，4个pooling层。</p><ul><li>所有的conv层都是： kernel_size=3 ， pad=1 ，stride=1，因此conv层不改变原图大小</li><li>所有的pooling层都是： kernel_size=2 ，pad=0 ， stride=2，pooling 层将原图缩小为原来的一半</li><li>经过Conv layer后，一个MxN大小的矩阵将变为(M/16)x(N/16)</li></ul><h4 id="Region-Proposal-Networks-RPN"><a href="#Region-Proposal-Networks-RPN" class="headerlink" title="Region Proposal Networks(RPN)"></a>Region Proposal Networks(RPN)</h4><p>Faster RCNN 层在fast RCNN 的基础上，对提取候选框进行优化。</p><p><img src="/images/fasternet/RPN.jpg" alt="RPN"></p><p>RPN网络分为2条线，上面一条通过<strong>softmax分类anchors获得foreground和background</strong>（检测目标是foreground），<strong>下面一条用于计算anchors的bounding box regression偏移量</strong>，以获得精确的proposal。而最后的Proposal层则负责综合foreground anchors和bounding box regression偏移量获取proposals，同时剔除太小和超出边界的proposals。其实整个网络到了Proposal Layer这里，就完成了相当于目标定位的功能。</p><h5 id="anchors"><a href="#anchors" class="headerlink" title="anchors"></a>anchors</h5><p>anchor为由一个中心点，周围生成了9个矩形，矩形长宽比由三个尺寸<code>1:1,1:2;2:1</code>三种，如下图，基本覆盖了各种尺寸和形状，引入检测中常用到的多尺度方法。<br><img src="/images/fasternet/anchor.jpg" alt="anchor"><br>Faster RCNN遍历Conv layers计算获得的feature maps，<strong>为feature map上每一个点都配备这9种anchors作为初始的检测框</strong>。这样做获得检测框很不准确，之后将会在RPN层，以及最后进行2次的bounding box regression修正检测框位置。<br><img src="/images/fasternet/convmap.jpg" alt="convmap"><br>如上图，对于每一个点的k个anchor来说，从conv layer提取出得特征具有256维，对于每一个anchor，需要分foreground与background，因此共有2k个score，对于每一个anchor共有$(x_1,y_1,x_2,y_2)$四个坐标值。因此共有4k个coordinates。在训练阶段，程序将会从这些anchor中挑选出一些合适的anchor进行训练。<br><strong>因此RPN最终就是在<font color="red">原图尺度上</font>，对每一个像素设置9个尺度的候选anchor。然后用cnn去判断哪些Anchor是里面有目标的foreground anchor，哪些是没目标的backgroud。所以，仅仅是个二分类而已！</strong><br>那么Anchor一共有多少个？原图800x600，VGG下采样16倍，feature map每个点设置9个Anchor，所以：<br>$$<br>ceil(800/16) \times ceil(600/16) \times 9=50\times38 \times9=17100<br>$$<br>其中ceil()表示向上取整，是因为VGG输出的feature map size= 50*38。</p><p><img src="/images/fasternet/generateAnchor.jpg" alt="generateAnchor"></p><h4 id="softmax判定foreground与background"><a href="#softmax判定foreground与background" class="headerlink" title="softmax判定foreground与background"></a>softmax判定foreground与background</h4><p>RPN网络中利用anchors和softmax初步提取出foreground anchors作为候选区域。<br><img src="/images/fasternet/softmax.jpg" alt="softmax"><br>features map 首先做一个1*1的卷积，这个卷积的作用是生成一个$W*H*(9*2)$大小的矩阵。该矩阵用于存储上面提到的foreground与background信息（2*k score）。将该特征后接softmax分类获得foreground anchors，也就相当于初步提取了检测目标候选区域box（一般认为目标在foreground anchors中）。前后两个reshape 操作目的为便于程序实现。<br>clc layer输出预测区域共k个，每个有的2个参数，即预测为前景的概率和背景的概率，损失用softmax loss（cross entropy loss）。监督信息是Y=0,1，表示这个区域是否为groundtruth。确定groundtruth时，我们需要确定k个区域中的各个区域是不是有效的，是前景还是背景。<br>K个区域分配标签规则：</p><ul><li>与某个ground truth(GT)的IoU最大的区域的分配正标签</li><li>与任意GT的IoU大于0.7的区域分配正标签</li><li>与所有GT的IoU都小于0.3的区域分配负标签</li></ul><h4 id="bounding-box-regression原理"><a href="#bounding-box-regression原理" class="headerlink" title="bounding box regression原理"></a>bounding box regression原理</h4><p>对于窗口一般使用四维向量  (x, y, w, h) 表示，分别表示窗口的中心点坐标和宽高。对于图 11，红色的框A代表原始的Foreground Anchors，绿色的框G代表目标的GT，我们的目标是寻找一种关系，使得输入原始的anchor A经过映射得到一个跟真实窗口G更接近的回归窗口G’，即：<br><img src="/images/fasternet/bbox.jpg" alt="bbox"></p><p>给定：$anchor A=(A_{x}, A_{y}, A_{w}, A_{h}) 和 GT=[G_{x}, G_{y}, G_{w}, G_{h}]$<br>寻找一种变换F，使得：$F(A_{x}, A_{y}, A_{w}, A_{h})=(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})，$其中$(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})≈(G_{x}, G_{y}, G_{w}, G_{h})$<br>那么经过何种变换F才能从图10中的anchor A变为G’呢？ 比较简单的思路就是先做平移，然后进行缩放，边框回归与RCNN中边框回归相同。<a href="https://blog.csdn.net/u014433413/article/details/78194855" target="_blank" rel="noopener">bounding box 原理参考链接</a><br>RPN中所涉及的边框回归首先经过一个1*1的卷积层，输出一个$W*H*(9*4)$的矩阵，用于存储box的坐标信息（4k coordinate）<br><img src="/images/fasternet/rpnbbox.jpg" alt="rpnbbox"></p><font color="red">RPN值得注意的地方: </font><br>- RPN在原图的尺度上选择anchor的大小<br>- anchor的数目是feature map上每个像素选择9个长宽比不同的矩形<br>- soft Max层用于判断anchor是否为前景（含有目标）<br>- bounding box regression 预测的输出是anchor的偏移变换<br>- proposal层，结合前景的anchor（背景anchor被忽略）与anchor偏移变换，对anchor位置进行调整，计算出proposal的精确位置。<br>- bounding  box 本质上是学习一个W权重矩阵，即那个1*1的网络的参数（输出为4K regreason,对应anchor的（x，y,w,h）四个偏移），利用W参数乘以 CNN pool5层输出的features map，通过最小二乘，得到anchor的偏移。<br>- 为什么bounding box regression不直接预测坐标呢？ 因为坐标间的关系不是简单的一维关系，难以优化。当anchor 与 ground truth比较接近时，他们之间的位置关系（偏移）就可以用一维关系来近似。<br>- proposal层输出的proposal坐标是在原图的尺度上的proposal坐标。<br><br>#### proposal layer<br>RPN 最后一层为proposal layer，用于前景anchors，以及anchor对应的边框回归微调参数$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$和im_info=[M, N, scale_factor]（传入Faster RCNN前首先reshape到固定MxN，im_info则保存了此次缩放的所有信息）来计算产生的proposal位置，<strong>此时输出的proposal坐标为原图尺度上的proposal坐标</strong>。<br><br><strong>Proposal Layer forward（caffe layer的前传函数）按照以下顺序依次处理：</strong><br><br>- <strong>生成anchors</strong>：利用$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致）<br>- 按照输入的foreground softmax scores<strong>由大到小排序anchors</strong>，<strong>提取前pre_nms_topN(e.g. 6000)个anchors，</strong>即提取修正位置后的foreground anchors。<br>- <strong>限定超出图像边界的foreground anchors为图像边界</strong>（防止后续roi pooling时proposal超出图像边界）<br>- <strong>剔除非常小（width&lt;threshold or height&lt;threshold）的foreground anchors</strong><br>- <strong>进行nonmaximum suppression</strong><br>- <strong>再次按照nms后的foreground softmax scores由大到小排序fg anchors，提取前post_nms_topN(e.g. 300)结果作为proposal = [x1, y1, x2, y2]输出。</strong><br>输出的proposal=[x1, y1, x2, y2]，由于在第三步中将anchors映射回原图判断是否超出边界，所以<strong>这里输出的proposal是对应MxN输入图像尺度的</strong>。<br>RPN网络结构主要步骤如下：<br><strong>生成anchors -&gt; softmax分类器提取前景 anchors -&gt; bbox reg回归前景 anchors -&gt; Proposal Layer生成proposals</strong><br><br>#### RoI pooling layer<br>RoI Pooling layer负责收集proposal，并计算出proposal feature maps，送入后续网络。Rol pooling层有2个输入：<br>- 原始的feature maps<br>- RPN输出的proposal boxes（大小各不相同）<br><br><strong>RoI Pooling layer forward过程：</strong><br><br>- 由于proposal是对应$ M\times N$ 尺度的，所以首先使用spatial_scale参数将其映射回 $(M/16)\times(N/16) $大小的feature map尺度；<br>- 再将每个proposal对应的feature map区域水平分为 $\text{pooled_w}\times \text{pooled_h} $的网格；<br>- 对网格的每一份都进行max pooling处理。<br><br>经过上述处理后，即使大小不同的proposal输出结果都是 $\text{pooled_w}\times \text{pooled_h}$ 固定大小，实现了固定长度输出。<br><br>#### Classification<br><br>Classification部分利用已经获得的proposal feature maps，通过full connect层与softmax计算每个proposal具体属于那个类别（如人，车，电视等），输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置偏移量bbox_pred，用于回归更加精确的目标检测框。<br><img src="/images/fasternet/classfication.jpg" alt="classfication"><br>从PoI Pooling获取到7x7=49大小的proposal feature maps后，送入后续网络，可以看到做了如下2件事：<br>- 通过全连接和softmax对proposals进行分类<br>- 再次对proposals进行bounding box regression，获取更高精度的rect box<br><br>#### Faster R-CNN训练<br>Faster R-CNN的训练，是在已经训练好的model（如VGG_CNN_M_1024，VGG，ZF）的基础上继续进行训练。实际中训练过程分为6个步骤：<br><br>- 在已经训练好的model上，训练RPN网络<br>- 利用步骤1中训练好的RPN网络<br>- 第一次训练Fast RCNN网络<br>- 第二训练RPN网络<br>- 再次利用步骤4中训练好的RPN网络<br>- 第二次训练Fast RCNN网络<br>可以看到训练过程类似于一种“迭代”的过程，不过只循环了2次。至于只循环了2次的原因是应为作者提到：”A similar alternating training can be run for more iterations, but we have observed negligible improvements”，即循环更多次没有提升了。<br><br><img src="/images/fasternet/train.jpg" alt="train"><br><br>#### RPN 训练<br><br>与检测网络类似的是，依然使用Conv Layers提取feature maps。整个网络使用的Loss如下：<br>$$<br>L({p_i},{t_i})=\frac{1}{N_{cls}}\sum_{i} L_{cls}(p_i,p_i^*)+\lambda \frac{1}{N_{reg}}\sum_{i} p_i^* L_{reg} (t_i,t_i^*)<br>$$<br><br>上述公式中 i 表示anchors index，$ p_{i}$ 表示foreground softmax probability，$p_{i}^{*}$代表对应的GT predict概率（即当第i个anchor与GT间IoU&gt;0.7，认为是该anchor是foreground，$p_{i}^{*}=1$；反之IoU&lt;0.3时，认为是该anchor是background，$ p_{i}^{*}=0 $；至于那些0.3&lt;IoU&lt;0.7的anchor则不参与训练）；t代表predict bounding box，$ t^{*} $ 代表对应foreground anchor对应的GT box。可以看到，整个Loss分为2部分：<br><br>- cls loss，即rpn_cls_loss层计算的softmax loss，用于分类anchors为forground与background的网络训练<br>- reg loss，即rpn_loss_bbox层计算的soomth L1 loss，用于bounding box regression网络训练。注意在该loss中乘了 $p_{i}^{*}$ ，相当于只关心foreground anchors的回归（其实在回归中也完全没必要去关心background）。<br><br><font color="red">Smooth L1 loss 相比于L2 loss对离群点更加不敏感，更加鲁棒。当预测值与目标相差很大时，L2 loss的梯度是x-t，容易产生梯度爆炸，而L1的梯度为常数，使用L1 loss 可以防止梯度爆炸。 </font><p>关于softMax loss 和 边框回归loss与fast RCNN 相同。<a href="http://perper.site/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener">链接</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fast RCNN详解</title>
      <link href="/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="Fast-RCNN详解"><a href="#Fast-RCNN详解" class="headerlink" title="Fast RCNN详解"></a>Fast RCNN详解</h3><p>SPP-Net改造了RCNN，使用SPP layer使得输入图片大小不受限制，同时使用region proposal映射的方式，大大加速了目标检测的速度，但是SPP-net训练需要花费很多时间，同时fine-tune不能越过SPP层，因为pyramid BP开销太大了（金字塔感受野比较大），只能fine-tune全连接层，tune不到卷积层，所以在一些较深的网络上准确率上不去。<br>Fast RCNN 受到SPP-Net网络，在网络卷积层后加入ROI层（region of interesting）。此外，损失函数使用了多任务损失函数(multi-task loss)，将分类和边框回归两个loss统一到一个网络中一起训练。</p><blockquote><p>Fast RCNN<br>submit time: 2015<br><a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>Fast RCNN网络结构如下：<br><img src="/images/fastnet/fastnet.jpg" alt="fast RCNN"><br><strong>Fast RCNN关键步骤：</strong></p><ul><li>select search 算法提取2k个region proposal 区域</li><li>将整张图片输入CNN网络中，提取出整张图片的特征</li><li>将2k个region proposal区域映射到feature maps上（RoI projection）</li><li>通过RoI pooling layer，将features map上的大小不一致的region proposal变成固定长度的特征向量。</li><li>将特征向量通过一系列FCs层分别输入softMax，以及bbox regression。利用Softmax Loss(探测分类概率) 和Smooth L1 Loss(探测边框回归)对分类概率和边框回归(Bounding box regression)联合训练。</li></ul><h4 id="ROI-pooling-layer"><a href="#ROI-pooling-layer" class="headerlink" title="ROI pooling layer"></a>ROI pooling layer</h4><p>RoI池化层使用<strong>最大池化</strong>将任何有效区域内的特征转化成一个小的<strong>带有固定空间范围HxW（比如7×7）的特征图</strong>，其中H和W是层的超参数，和任何特定的RoI无关。本文中，一个RoI是针对卷积特征图的一个矩形窗口。每个RoI定义成四元组（r, c, h, w），左上角为（r, c），高和宽是（h, w）。<br>RoI最大池化将hxw的RoI窗口分成HxW的子窗口网格，每个子窗口大小大约是h/H x w/W。然后每个子窗口进行最大池化放入网格对应的单元。池化以标准最大池化的形式独立应用在每个特征图的channel上。RoI层是SPPnets中的空间金字塔层的一个特例，因为他是一个一层的金字塔结构。<strong>即将一个h<em>w大小的框转化为H</em>W大小的框，每个H*W的网格为h/H x w/W区域内最大的值(max-pooling)表示。</strong></p><h4 id="为目标检测任务做微调"><a href="#为目标检测任务做微调" class="headerlink" title="为目标检测任务做微调"></a>为目标检测任务做微调</h4><ul><li>分层采样得到SGD的<strong>mini-batch</strong>，首先采样N个images，然后每个image采样R/N个ROIs。来自同一个image的ROIs在前向后向传输时共享计算和内存，减小N 则能降低mini-batch的计算。这种分层采样的策略实际中不会减慢收敛速度。作者使用N=2, R=128， 并发现SGD迭代次数比R-CNN的还少。</li><li>联合优化softmax分类器和bbox regressor回归器</li></ul><h4 id="Multi-task-Loss"><a href="#Multi-task-Loss" class="headerlink" title="Multi-task Loss"></a>Multi-task Loss</h4><h5 id="softmax类别分类器"><a href="#softmax类别分类器" class="headerlink" title="softmax类别分类器"></a>softmax类别分类器</h5><p>R-CNN与SPPNet均使用SVM作为分类器，而Fast R-CNN使用softmax作为分类器，以下为真实类属u的log loss，即p的值越到loss越接近1。<br>$$<br>L_{cls}(p, u) = -logp_u<br>$$</p><p>softmax函数可以将连续数值转换为相对概率：<br>$$<br>P_i= \frac{e^{V_i}}{\sum_i^C{e^{V_i}}}​<br>$$<br>实际应用中，<strong>使用 Softmax 需要注意数值溢出的问题</strong>。因为有指数运算，如果 V 数值很大，经过指数运算后的数值往往可能有溢出的可能。所以，<strong>需要对 V 进行一些数值处理：即 V 中的每个元素减去 V 中的最大值</strong>。<br>$$<br>\begin{align}<br>D = \max(V) \nonumber\\<br>P_i= \frac{e^{V_i-D}}{\sum_i^C{e^{V_i-D}}} \nonumber<br>\end{align}<br>$$<br>由于log函数不会改变函数单调性，所以通常对softMax函数取一个 $-\log$，表示损失函数。</p><h5 id="边框回归loss："><a href="#边框回归loss：" class="headerlink" title="边框回归loss："></a>边框回归loss：</h5><p>边框回归使用$L_1$ loss，第二个loss $L_{loc}$是定义真值和预测值上，第一个是针对类u的真实标注约束框回归目标 $v=(v_x, v_y, v_w, v_h)$，第二个也是针对类u的预测值$t^u = (t^u_x, t^u_y, t^u_w, t^u_h)$。对于约束框回归，边框回归的loss为：<br>$$<br>L_{loc}(t^{u},v) = \sum_{ i \in {x,y,w,h}} smooth_{L_{1}}(t_i^u - u_i)<br>$$<br>其中：<br><img src="/images/fastnet/L_1loss.png" alt="L_1loss"></p><h5 id="联合loss："><a href="#联合loss：" class="headerlink" title="联合loss："></a>联合loss：</h5><p>$$<br>L(p,u,t^u,v) = L_{cls}(p,u)+\lambda[u\geq 1]  L_{loc}(t^{u},v)<br>$$</p><p>其中中括号项代表这样一个函数：当u ≥ 1时，返回1，否则返回0。根据约定代表全部剩余一切的背景类标注成u=0。所以对于背景RoI而言，没有真是标注框信息，因而$L_{loc}$就忽略了。</p><h4 id="Mini-Batch-采样"><a href="#Mini-Batch-采样" class="headerlink" title="Mini-Batch 采样"></a>Mini-Batch 采样</h4><p>微调阶段，每次SGD迭代所用的mini-batch从N=2个images中获取， 这N个images随机选择，mini-batch的大小为128，每个image中采样64个ROIs。其中25%的样本为正样本，也就是IOU大于0.5的，其他样本为负样本，同样使用了困难负样本挖掘的方法（hard negative mining），也就是负样本的IOU区间为[0.1，0.5），负样本的u=0，$[u\geq 1]$函数为艾弗森指示函数。</p><h4 id="RoI-反向传播"><a href="#RoI-反向传播" class="headerlink" title="RoI 反向传播"></a>RoI 反向传播</h4><p>不同于SPPNet，ROI Pooling可以反向传播，以Max Pooling为例，根据链式法则，对于最大位置的神经元偏导数为1，对于其他神经元偏导数为0。ROI Pooling 不用于常规Pooling，因为很多的region proposal的感受野可能是相同的或者是重叠的，因此在一个Batch_Size内，我们需要对于这些重叠的神经元偏导数进行求和，因此反向传播公式如下：<br>$$<br>\frac{\partial L }{ \partial x_{i}} = \sum_r \sum_{j} [i = i^*(r,j)]\frac{\partial L }{\partial y_{rj}}<br>$$</p><ul><li>$i^*(r, j) = argmax (i)∈R(r,j)$，也就是在R(r, j)这个区域中做max pooling得到的结果</li><li>$[i =  i  * (r, j)]$ 是一个条件表达式，就是判断input的xi是否是max pooling的结果，如果不是，输出的梯度就不传到这个值上面,不提供loss</li><li>r是RoI数量，j是在一个region中，与x对应的输出个数</li><li>$y_{rj}$是第j个跟x对应的输出</li></ul><p>如下，RoI层反向传播例子：<br><img src="/images/fastnet/roiBP.png" alt="roiBP"><br>fast rcnn的网络结构如下：<br><img src="/images/fastnet/structure.png" alt="structure"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SPP-Net详解</title>
      <link href="/2019/02/13/SPP-Net%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/13/SPP-Net%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="SPP-Net详解"><a href="#SPP-Net详解" class="headerlink" title="SPP-Net详解"></a>SPP-Net详解</h3><p>在fast RCNN 之前，RCNN的进化中SPP Net的思想对其贡献很大，下面先介绍一下SPP Net。</p><h4 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h4><blockquote><p>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition<br>submit time: 2015<br><a href="https://arxiv.org/pdf/1406.4729.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>空间金字塔池化spatial pyramid pooling，是一种词袋(Bag-of-Words, BoW)模型的扩展。池袋模型是计算机视觉领域最成功的方法之一。它将图像切分成粗糙到精细各种级别，然后整合其中的局部特征。SPP-net允许任意尺寸的输入，也允许图像可以有各种尺寸和缩放尺度。SPP使用了多级别的空间箱(bin)，而滑窗池化则只用了一个窗口尺寸。多级池化对于物体的变形十分鲁棒。<br><strong>RCNN的不足之处</strong><br> 1）<strong>输入图像需要crop成固定尺寸将导致失真</strong>：rcnn里将所有的region warp成固定尺寸，导致图片会出现不同程度的缺失和失真扭曲<br>2）时间和空间成本高：对每个region proposals都需要过一遍AlexNet，且需要落盘到本地磁盘，存储量大<br>3）检测速度慢：对每个regions proposals均需要分别提取特征，用VGG16一幅图片需要47s</p><p><strong>SPP-Net关键步骤：</strong></p><ul><li>通过<strong>select search算法</strong>提取出2k个proposal region</li><li>将整张图片输入CNN中提取特征，得到整张图片的feature maps</li><li>将选择性搜索得到的2k个proposal区域<strong>映射</strong>到feature maps上(RCNN需要对每一个proposal提取一次特征，SPP-net只需要提取一次)</li><li>对feature map上的候选框采用<strong>金字塔空间池化</strong>，提取出固定长度的特征向量，输入FC层(SPP-net不需要对图片进行crop等操作)</li><li>将proposals区域的特征向量输入SVM分类器中进行类别分类。</li></ul><p><img src="/images/sppnet/whole.png" alt="whole"></p><h4 id="SPP-Net-解决了下面几个问题："><a href="#SPP-Net-解决了下面几个问题：" class="headerlink" title="SPP-Net 解决了下面几个问题："></a>SPP-Net 解决了下面几个问题：</h4><ol><li><font color="red">如何解决输入图片尺寸必须固定的要求？</font><h5 id="金字塔池化"><a href="#金字塔池化" class="headerlink" title="金字塔池化"></a>金字塔池化</h5> <img src="/images/sppnet/pooling layer.png" alt="pooling layer"><br>如上图由features map上确定的region proposal大小不固定，将提取的region proposal分别经过三个卷积4*4，2*2，1*1，都将得到一个长度为21的向量(21是数据集类别数，可以通过调整卷积核大小来调整)，因此不需要对region proposal 进行尺寸调整。<br> <img src="/images/sppnet/crop.png" alt="crop"></li><li><font color="red">如何解决只进行一次特征提取的要求?</font><br> SPP-Net在原图上选择region proposals区域，随后对图片提取特征，得到整张图片的features map，然后通过映射将region proposals区域映射到features map上，得到region proposal区域的特征。因此仅仅需要对原图提取一次特征即可。<br> <img src="/images/sppnet/compare.png" alt="compare"></li><li><font color="red">如何将region proposal映射到特征空间?</font><br>SPP-Net在提取完整图像的feature map后，要将候选框的位置映射到feature map中得到对应特征。映射原则如下：<br>假设(x,y)是原始图像上的坐标点，(x′,y′)是特征图上的坐标，<strong>S是CNN中所有的步长的乘积</strong>，那么左上角的点转换公式如下：<br>$$x′=\frac{x}{S}+1$$<br>右下角的点转换公式为：<br>$$x′=\frac{x}{S}−1$$<br>计算S有下面例子：<br><img src="/images/sppnet/stride.png" alt="stride"><br>论文中使用的ZF-5: S = 2*2*2*2 = 16<br>Overleaf-5/7：S = 2*3*2 = 12</li><li><font color="red">SPP-Net训练策略：</font><br>理论上，无论输入什么尺寸的图像，都可以输入SPP-net中进行训练。但是实际上由于GPU实现中，更适合在固定尺寸的输入图像上，因此提出了一些训练策略。</li></ol><ul><li>Single-size training:使用固定的224x224的输入，是从原始图像中裁切得到的，目的是为了数据扩增；对于给定的输入尺寸，可以预先计算出空间金字塔池化需要的bin size，假如feature map是axa的大小，那么在SPP layer中，窗口尺寸$win=\frac{a}{n}$上取整，步长$stride=\frac{a}{n}$下取整。</li><li>Multi-size training：考虑两种输入，180x180和224x224，这里不再用裁切，而是直接进行缩放，比如把224x224的图像直接缩放为180x180，它们之间的区别只是分辨率不同。实现两个固定输入尺寸的网络，训练过程中先在1号网络上训练一个epoch，然后用它的权重去初始化2号网络，训练下一个epoch；如此转换训练。通过共享两种尺寸输入的网络参数，实现了不同输入尺寸的SPP-Net的训练。</li></ul><h4 id="原始图片中的ROI如何映射到到feature-map"><a href="#原始图片中的ROI如何映射到到feature-map" class="headerlink" title="原始图片中的ROI如何映射到到feature map"></a>原始图片中的ROI如何映射到到feature map</h4><p><strong>感受野：</strong><br>卷积神经网络CNN中，某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。感受野的大小是由kernel size，stride，padding , outputsize 一起决定的。<br><img src="/images/sppnet/inspect field.jpg" alt="inspect field"><br><strong>经过一层卷积后输出的features map大小计算：</strong><br>   $$W_2 = （W_1- K + 2P）/S + 1$$<br>（其中 $W_1$是输入卷积层的特征的尺寸，K是卷积核大小，P是填充padding，S是步长stride）<br><strong>上一层features map大小计算：</strong><br>  $$W_1 = (W_2 - 1)*S -2P+K$$ </p><p><strong>感受野的计算：</strong><br>感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。<br>当已知上一层的感受野计算下一层的感受野时有：<br>$$<br>r = (m-1) <em> stride+ksize<br>$$<br>其中m为上一层的感受野。<br><strong>空洞卷积的感受野计算：</strong><br>dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\</em>3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。<br><strong>感受野坐标映射：</strong><br>     $$p_i = s_i \cdot p_{i+1} +( (k_i -1)/2 - padding)$$<br>     <strong>SPP-Net中的坐标映射：</strong><br>     SPP-Net 是把原始ROI的左上角和右下角 映射到 feature map上的两个对应点。 有了feature map上的两队角点就确定了 对应的 feature map 区域(下图中橙色)。变换公式见上。<br>     <img src="/images/sppnet/spp.png" alt="spp"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p> SPPNet在R-CNN的基础上提出了改进，通过候选区域和feature map的映射，配合SPP层的使用，从而达到了CNN层的共享计算，减少了运算时间，允许输入图片的大小不固定。Fast R-CNN受SPPNet的启发，进一步改进完网络。</p><p> <img src="/images/sppnet/spp_net.png" alt="spp net"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RCNN详解</title>
      <link href="/2019/02/11/RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/11/RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><p>目标检测任务主要有两个不同的思路。一种思路是借鉴语义分割的做法，这方面的工作有YOLO和SSD另一种思路是把目标检测看作分类任务（bounding box中对象的类别）和回归任务（回归bounding box）的组合。主要的工作有R-CNN，SPP-Net，Fast R-CNN，Faster R-CNN。方法一速度快但精度稍差，方法二速度慢但精度高，是主流方法。</p><h4 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h4><p>RCNN: Region-based Convolutional Network<br>Submitted on 2014 </p><p>RCNN目标识别的主要任务为检测物体类别以及边框的大小以及位置。<br><strong>主要贡献：</strong></p><ul><li>根据Selective search 算法提取Region proposal。</li><li>将每个Region Proposal 缩放到统一大小后输入CNN，输出固定大小的特征。</li><li>将特征用SVM进行分类。</li><li>训练一个回归器，对边框（bounding box）进行微调。</li></ul><p><strong>边框的选择：</strong><br>原始产生边框的方法为通过滑窗的方式产生region proposal，作者做过实验，原话如下：</p><blockquote><p>我们也考虑了采用滑动窗口方法。然而，在我们的网络中，具有五个卷积层的单元在输入图像中具有非常大的接收场（195×195像素）和步进（32×32像素），这使得在滑动窗口内的精确定位成为开放的技术挑战。</p></blockquote><p><strong>selective search 算法</strong></p><ul><li>使用一种过分割手段，将图像分割成小区域 (2k~3k 个)</li><li>查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置</li><li>输出所有曾经存在过的区域，所谓候选区域</li></ul><p>selective search 合并规则：<strong>颜色相近(颜色直方图)；纹理相近(梯度直方图)；合并后总面积小的；合并后总面积在其BBOX中所占比例大的(保证合并后形状规则)</strong></p><p><strong>多样化与后处理</strong><br>为尽可能不遗漏候选区域，上述操作在多个颜色空间中同时进行（RGB,HSV,Lab等）。在一个颜色空间中，使用上述四条规则的不同组合进行合并。所有颜色空间与所有规则的全部结果，在去除重复后，都作为候选区域输出。</p><p><img src="/images/selective search.png" alt="selective search"></p><h4 id="RCNN卷积："><a href="#RCNN卷积：" class="headerlink" title="RCNN卷积："></a><strong>RCNN卷积：</strong></h4><p><img src="/images/RCNN.png" alt="RCNN"><br>将生成的region proposal <strong>减去像素平均值</strong>后，使用<strong>各向异性</strong>的缩放方式（直接缩放），将图片缩放到<strong>227*227</strong>大小，随后对每个proposal 提取特征，<strong>对每个proposal经过五层卷积层以及两层全连接层，在cf7层得到提取出的4096维特征。</strong>提取特征使用了<strong>pre-training的AlexNet网络</strong>，作者原文如下：</p><blockquote><p>检测面临的第二个挑战是带标记的数据很少，目前可用的数量不足以训练大型CNN … 本文的第二个主要贡献是识别网络在大型辅助数据集(ILSVRC)上进行监督预训练，然后对小数据集(PASCAL)进行指定域的微调，这是在数据稀缺时训练高容量CNN模型的有效方法。</p></blockquote><p><strong>即提取特征需要训练一个大型的CNN识别网络</strong>，作者使用了hinton在2012年image net上做识别的AlexNet，此网络提取的特征为4096维，之后送入一个4096-&gt;1000的全连接(fc)层进行1000个类别的分类，学习率0.01。<strong>针对特定的小数据集对该识别网络进行微调</strong>。同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。 学习率0.001，网络各层参数不变。每一个batch包含32个正样本（属于20类）和96个背景（背景多于正样本是因为实际图片中背景部分就是比样本要多）。网络结构如下：<br><img src="/images/提取特征.png" alt="提取特征"></p><h4 id="目标类别与分类器"><a href="#目标类别与分类器" class="headerlink" title="目标类别与分类器"></a>目标类别与分类器</h4><p><font color="red"><strong>作者在cf7层提取出特征后，未直接通过最后一层softMax层进行分类，而是将cf7层提取出的特征用于训练SVM分类器。</strong></font>原因在于： svm训练和cnn训练过程的正负样本定义方式不同，softmax得到的结果比svm精度低。</p><ul><li>cnn在训练的时候，对训练数据做了比较宽松的标注（例如bounding box只包含物体的一部分，我们也把它标注为正样本），采用这个方法的主要原因在于<strong>CNN容易过拟合，要扩大正样本的样本量</strong>，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松<strong>(IOU只要大于0.5的region proposal都被标注为正样本)</strong></li><li>svm分类器原理是最小距离最大化，样本的定义越严格分类效果越好，所以对于训练样本数据的IOU要求比较严格<strong>（大于0.7为正样本）</strong></li></ul><p><strong>SVM训练</strong><br>对每一个类别训练一个二分类器，我们用IoU重叠阈值来解决正负样本的问题，<strong>在0.3阈值以下的区域被定义为负样本，0.3-0.7阈值的样本被忽略，0.7-1.0的样本被定义为正样本。</strong>（重叠阈值0.3是通过在验证集上尝试了0,0.1,…,0.5的不同阈值选择出来的。选择这个阈值是很重要，将很大程度上影响最后的结果。）正样本被简单地定义为每个类的检测框真值。我们提取了特征并应用了训练标签，就可以对每一个类别训练一个线性SVM，当我们用CNN提取2000个候选框，可以得到2000 * 4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096 * N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，就可以得到结果。</p><p><strong>边框回归</strong><br>学习一个<strong>线性回归器</strong>，用于bounding box的边框回归，<strong>输入为Alexnet pool5的输出</strong>。bbox回归认为候选区域和ground-truth之间是线性关系(因为在最后从SVM内确定出来的区域比较接近ground-truth,这里近似认为可以线性关系)。<br>训练回归器的输入为N对值，${(P^i, G^i)}_{i=1,2,…,N}$，分别为候选区域的框坐标和真实的框坐标。这里选用的Proposal必须和Ground Truth的IoU大于0.6才算是正样本(避免一些远离groundtruth的边框参与计算)，通过学习四个变换函数，得到变换后的边框坐标。<br><img src="/images/边框回归.png" alt="边框回归"><br>对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。所谓脊回归，就是对于一个线性模型，在原来的损失函数加入参数的l2范数的惩罚项。<br>当使用最小二乘法计算线性回归模型参数的时候，如果数据集合矩阵（也叫做设计矩阵(design matrix)）XX，存在多重共线性，那么最小二乘法对输入变量中的噪声非常的敏感，其解会极为不稳定。为了解决这个问题，就有了这一节脊回归（Ridge Regression ）。<br><strong>脊回归</strong><br>当矩阵存在多重共线性的时候（数学上称为病态矩阵），最小二乘法求得的参数W在数值上会非常的大，输入变量X有一个微小的变动，其反应在输出结果上也会变得非常大，因而结果对输入变量噪声非常敏感。</p><p>如果能限制参数W的增长，使W不会变得特别大，那么模型对输入W中噪声的敏感度就会降低。这就是脊回归和套索回归（Ridge Regression and Lasso Regrission）的基本思想。为了限制模型参数W的数值大小，就在模型原来的目标函数上加上一个惩罚项，这个过程叫做正则化（Regularization）。</p><ul><li>如果惩罚项是参数的$l_2$范数，就是脊回归(Ridge Regression)</li><li>如果惩罚项是参数的$l_1$范数，就是套索回归（Lasso Regrission）</li><li>正则化同时也是防止过拟合有效的手段</li></ul><p><strong>非极大值抑制（NMS）：</strong><br>RCNN 网络会对一个目标标定了多个标定框，使用极大值抑制算法滤掉多余的标定框。<br><img src="/images/beforeNMS.png" alt="beforeNMS| center"><br>NMS算法搜索局部的极大值，并且抑制那些分数低的窗口。首先对RCNN产生的边框分类概率从大到小排序，将最大概率边框设置为保留边框，并选择与该边框重合IoU大于某一个阈值的所有边框，将他们过滤，接下来从剩下的边框中重复上述步骤，直到所有边框都被处理过。<br><img src="/images/afterNMS.png" alt="afterNMS | center"></p><p>RCNN网络结构图：<br><img src="/images/rcnn1.png" alt="rcnn1"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MAC 私人订制</title>
      <link href="/2019/02/07/MAC-%E7%A7%81%E4%BA%BA%E8%AE%A2%E5%88%B6/"/>
      <url>/2019/02/07/MAC-%E7%A7%81%E4%BA%BA%E8%AE%A2%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h4 id="配置git"><a href="#配置git" class="headerlink" title="配置git"></a>配置git</h4><p>Mac上安装Xcode命令行工具，命令行工具包是一个小型独立包,可供下载独立于Xcode的和允许您执行命令行开发OS X:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-select --install</span><br></pre></td></tr></table></figure></p><p>设置用户名，邮箱：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;wenhui-zhou&quot;</span><br><span class="line">git config --global user.email &quot;765647930@qq.com&quot;</span><br></pre></td></tr></table></figure></p><p>创建ssh-key：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></p><p>在当前目录下找到/.ssh/id_rsa.pub，将其中的内容配置到GitHub账号中的ssh中完成配置。<br>验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></p><p>若输出一下内容则说明配置成功。</p><blockquote><p>Hi WenHui-Zhou! You’ve successfully authenticated, but GitHub does not provide shell access.</p></blockquote><h4 id="网络端口"><a href="#网络端口" class="headerlink" title="网络端口"></a>网络端口</h4><p>80端口：http端口，用于网页访问<br>443端口：https访问端口，用于https的网页访问<br>http与https是两种不同的协议，https协议安全xing</p><h4 id="Mac-系统环境配置"><a href="#Mac-系统环境配置" class="headerlink" title="Mac 系统环境配置"></a>Mac 系统环境配置</h4><p>Mac系统的环境变量，加载顺序为：</p><ol><li>/etc/profile </li><li>/etc/paths </li><li>~/.bash_profile </li><li>~/.bash_login </li><li>~/.profile </li><li>~/.bashrc</li></ol><p>/etc/profile和/etc/paths是系统级别的，系统启动就会加载，后面几个是当前用户级的环境变量。后面3个按照从前往后的顺序读取，如果~/.bash_profile文件存在，则后面的几个文件就会被忽略不读了，如果~/.bash_profile文件不存在，才会以此类推读取后面的文件。~/.bashrc没有上述规则，它是bash shell打开的时候载入的。</p><h4 id="windows上hexo博客迁移到Mac上的方法"><a href="#windows上hexo博客迁移到Mac上的方法" class="headerlink" title="windows上hexo博客迁移到Mac上的方法"></a>windows上hexo博客迁移到Mac上的方法</h4><ul><li>安装node.js</li><li>安装git</li><li>安装hexo（使用npm安装）</li><li>新建博客文件夹，依次<code>hexo init,sudo npm install</code></li><li>将原来文件夹中的文件替换Mac文件夹中的文件</li><li>博客恢复使用</li></ul><h4 id="安装anaconda后设置iterm的默认python版本"><a href="#安装anaconda后设置iterm的默认python版本" class="headerlink" title="安装anaconda后设置iterm的默认python版本"></a>安装anaconda后设置iterm的默认python版本</h4><p>打开iterm环境配置文件：<code>vim ~/.zshrc</code><br>在文件末尾添加指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### Mac选择大段文字的方法</span><br><span class="line"></span><br><span class="line">由于使用触控板，抛弃了鼠标，但是选择大段文字则成了一个问题，还好有解决方案：</span><br><span class="line">选择段落：鼠标在段落内点击三下即选中</span><br><span class="line">选择大段篇幅：按住shift，鼠标在起始位置点击一下，在末尾点击一下即选中。</span><br><span class="line"></span><br><span class="line">#### 电池使用次数</span><br><span class="line"></span><br><span class="line">mac居然有点电池的充放电次数一说，以后使用电脑尽量插着插头。</span><br><span class="line">人事有代谢给我一个启发就是，万事万物都有尽头的一天，比如一个茶杯，身体，细胞等等，每天都在消耗，只是没人给你列一个上限而已。</span><br><span class="line"></span><br><span class="line">#### MAC 开启本地服务器</span><br><span class="line">MAC 开启本地的服务器，可以通过http的方式传递文件，具体做法如下：</span><br><span class="line">1. 打开终端，移动到需要分享文件的文件夹下；</span><br><span class="line">2. 在终端中输入：`python -m http.server 80`，开启web服务；</span><br><span class="line">3. 查询本机ip（百度输入本机IP即可），随后访问 `http://ip` 即可。</span><br><span class="line">4. 该方法下载文件夹：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">wget -r -np -nH -R index.html http://include/file</span><br></pre></td></tr></table></figure></p><ul><li><code>-r</code> : 遍历所有子目录</li><li><code>-np</code> : 不到上一层子目录去</li><li><code>-nH</code> : 不要将文件保存到主机名文件夹</li><li><code>-R index.html</code> : 不下载 index.html 文件</li></ul>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法-递归</title>
      <link href="/2019/01/30/%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/"/>
      <url>/2019/01/30/%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h4 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h4><p>递归(recursion)，是指函数的定义中使用函数自身的方法。用于表示用相似的方法重复事物的过程。</p><h5 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h5><p>从 1~n 这 n 个整数中随机选取任意多个，输出所有可能的选择方案。</p><h5 id="输出格式："><a href="#输出格式：" class="headerlink" title="输出格式："></a>输出格式：</h5><p>输入一个整数n。</p><h5 id="输出格式：-1"><a href="#输出格式：-1" class="headerlink" title="输出格式："></a>输出格式：</h5><p>输出所有的方案。</p><h5 id="数据范围："><a href="#数据范围：" class="headerlink" title="数据范围："></a>数据范围：</h5><p>1 $\leq n \leq15$</p><h5 id="输入样例："><a href="#输入样例：" class="headerlink" title="输入样例："></a>输入样例：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure><h5 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">3</span><br><span class="line">2</span><br><span class="line">2 3</span><br><span class="line">1</span><br><span class="line">1 3</span><br><span class="line">1 2</span><br><span class="line">1 2 3</span><br></pre></td></tr></table></figure><h4 id="方案一："><a href="#方案一：" class="headerlink" title="方案一："></a>方案一：</h4><p>主循环确定方案的长度，循环里头进一个dfs()，来控制填入的数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">20</span>];<span class="comment">//记录序列</span></span><br><span class="line"><span class="keyword">int</span> vis[<span class="number">20</span>]; <span class="comment">//记录是否访问过</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> pos,<span class="keyword">int</span> tar,<span class="keyword">int</span> start)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(pos == tar+<span class="number">1</span>)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=tar;i++)&#123;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;a[i]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = start;i&lt;=n;i++)&#123;</span><br><span class="line"><span class="keyword">if</span>(!vis[i])&#123;</span><br><span class="line">vis[i] = <span class="literal">true</span>;</span><br><span class="line">a[pos] = i;</span><br><span class="line">dfs(pos+<span class="number">1</span>,tar,i+<span class="number">1</span>);</span><br><span class="line">vis[i] = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; n;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;= n;i++)&#123;</span><br><span class="line">dfs(<span class="number">1</span>,i,<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="二进制优化："><a href="#二进制优化：" class="headerlink" title="二进制优化："></a>二进制优化：</h4><p>用二进制表示选了哪些书，用来代替之前使用的a[20]数组。<br><strong>| 或操作将i位置置为1（选中）：</strong>  <code>state |= 1&lt;&lt;(i-1)</code><br><strong>^ 异或操作将i位置还原为0（未选）：</strong> <code>state ^= 1&lt;&lt;(i-1)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">bool vis[20];</span><br><span class="line">void dfs(int pos,int tar,int start,int state)&#123;</span><br><span class="line">if(pos == tar+1)&#123;</span><br><span class="line">for(i = 1;i&lt;=n;i++)&#123;</span><br><span class="line">if((state&gt;&gt;i)&amp;1) cout &lt;&lt; i&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">for(int i = start;i&lt;=n;i++)&#123;</span><br><span class="line">if(!vis[i])&#123;</span><br><span class="line">vis[i] = true;</span><br><span class="line">state |= 1&lt;&lt;(i-1);</span><br><span class="line">dfs(pos+1,tar,i+1,state);</span><br><span class="line">state ^= 1&lt;&lt;(i-1);</span><br><span class="line">vis[i] = false;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">cout&lt;&lt;endl;</span><br><span class="line">cin &gt;&gt; n;</span><br><span class="line">for(int i =1;i&lt;= n;i++)&#123;</span><br><span class="line">dfs(1,i,start = 1, 0);</span><br><span class="line">&#125;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="状态压缩递归："><a href="#状态压缩递归：" class="headerlink" title="状态压缩递归："></a>状态压缩递归：</h4><p>用一个$2^n$的数的各个位上取0或取1来表示选中或未选中。</p><blockquote><p>000 ： \n<br>001 ： 1<br>010 ： 2<br>011 ： 3<br>……</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">int n;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">cin&gt;&gt; n;</span><br><span class="line">for(int state = 1;state&lt; 1&lt;&lt;n;state++)&#123;</span><br><span class="line">for(int j = 0;j&lt;n;j++)&#123;</span><br><span class="line">if(state&gt;&gt;j&amp;1) cout&lt;&lt;j+1&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="状态压缩的递归："><a href="#状态压缩的递归：" class="headerlink" title="状态压缩的递归："></a>状态压缩的递归：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int n;</span><br><span class="line">//u表示当前枚举到的数，state表示二进制的表示，记录哪些数字被选过</span><br><span class="line">void dfs(int u,int state)&#123;</span><br><span class="line">if(u == n)&#123;</span><br><span class="line">for(int i = 0;i&lt;=n;i++)&#123;</span><br><span class="line">if(state &gt;&gt; i &amp;1)&#123;</span><br><span class="line">cout&lt;&lt;i+1&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">cout&lt;&lt;endl;</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">dfs(u+1,state); // 不用u这个数</span><br><span class="line">dfs(u+1,state|(1&lt;&lt;u)); //用u这个数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">cin &gt;&gt;n;</span><br><span class="line">dfs(0,0);</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循环神经网络RNN,LSTM</title>
      <link href="/2019/01/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-LSTM/"/>
      <url>/2019/01/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-LSTM/</url>
      
        <content type="html"><![CDATA[<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><h4 id="RNN适用背景"><a href="#RNN适用背景" class="headerlink" title="RNN适用背景"></a>RNN适用背景</h4><p>当一段序列是连续的，且序列长度不一（音频序列），难以直接差分成一个个独立的样本来训练DNN/CNN，传统的神经网络无法用前面的场景来影响后面的预测。此时，可以使用RNN来解决这个问题。</p><p>循环神经网络内部具有循环边，允许信息持续存在。前一个节点传递消息给他的后继者。结构如下图：<br><img src="/images/RNN.jpg" alt="RNN"><br>正是借助于这个链式的信息传导结构，RNN在处理序列相关的数据时，具有先天的优势。</p><h4 id="RNN的缺点"><a href="#RNN的缺点" class="headerlink" title="RNN的缺点"></a>RNN的缺点</h4><p>在需要利用的历史信息离当前节点较近时，RNN能够利用该信息去进一步学习。但是当需要的背景信息离当前的节点距离较远时，RNN无法学到这些信息，即RNN无法处理这种需要长连接的信息。</p><h3 id="LSTM-NetWork"><a href="#LSTM-NetWork" class="headerlink" title="LSTM NetWork"></a>LSTM NetWork</h3><p>长短式记忆模型是一种特殊的RNN模型，能够解决长依赖无法学习的问题。<br>所有循环神经网络均具有相同的模块链，在标准的RNN中，该重复的模块链是一个简单的tanh层。<br><img src="/images/RNN module.jpg" alt="RNN module"><br>LSTM中的重复模块则由四个部分组成。<br><img src="/images/LSTM.jpg" alt="LSTM"></p><h4 id="LSTM背后的思想"><a href="#LSTM背后的思想" class="headerlink" title="LSTM背后的思想"></a>LSTM背后的思想</h4><p>LSTM关键是细胞的状态，表示细胞状态的这条水平线从图中顶部穿过。细胞在链上运行，其下有一些小的线性操作作用在它的上面。<br><img src="/images/cell state.jpg" alt="cell state"><br>LSTM模型中具有很多门（gate）结构。他有一个sigmoid神经节点和一个点乘运算组成。sigmoid输出0到1之间的数字，表明这个组件可以有多少信息可以通过。LSTM中有三个门，用于控制细胞的状态。<br><img src="/images/gate.jpg" alt="gate"></p><h4 id="一步步拆解LSTM"><a href="#一步步拆解LSTM" class="headerlink" title="一步步拆解LSTM"></a>一步步拆解LSTM</h4><p>LSTM第一步为决定从输入中丢弃什么信息，这一步称为<strong>遗忘门</strong>，遗忘门的输入为$h_{t-1}$（前一个细胞的输出）与$X_t$（当前细胞输入），通过一个sigmoid，输出0-1之间的数，添加到上一个细胞的状态$C_{t-1}$中。<br><img src="/images/loss gate.jpg" alt="loss gate"><br>下一步决定细胞需要的存储信息。该部分由两步构成。sigmoid层决定了哪些值需要更新，接下来一个tanh层创建候选向量$C_t$，该向量将会被加入到细胞状态中。<br><img src="/images/input gate.jpg" alt="input gate"><br>更新上一个状态值$C_{t-1}$，生成$C_{t}$<br><img src="/images/output_gate_2.jpg" alt="output_gate_2"><br>最后决定我们要输出什么，此输出将局域我们的细胞状态，首先先运行一个sigmoid层，他决定我们要输出的细胞状态的哪些部分。随后将单元格通过tanh（将值规范化到-1到1之间），并乘以sigmoid 输出，得到最后的$h_t$部分。<img src="/images/output.jpg" alt="output"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol><li><strong>为什么具有记忆功能</strong>：由于存在递归结构，上一时刻的隐层的状态参与到了这个时刻的计算过程中，即每一步的选择和决策参考了上一次的状态。</li><li><strong>为什么LSTM的记忆时间长（解决长连接问题）</strong>：由于传统的RNN在训练过程中引入一个激活函数，经过多步推导之后，这个乘子连乘，当参数发生轻微变化时，梯度将发生距离的波动，甚至将导致梯度消失问题。为了解决这个问题，特意设计了一个CEC常数误差流，即激活函数是线性的，将上一个节点的output由连乘改为连加。$|f_{ij}(x) W_{ij}| = 1,W_{ij}$是上一个状态与下一个状态的权值连接。误差没有衰减，使得序列很长之前带来的影响仍然能够保持到最后。LSTM在原来RNN的基础上是一个叫做CEC的部件，这个部件保证了误差将以常数的形式流动。同时添加输入门和输出门，使得模型变成非线性的。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目总结</title>
      <link href="/2019/01/25/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"/>
      <url>/2019/01/25/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="sketch2Cloth虚拟试衣总结"><a href="#sketch2Cloth虚拟试衣总结" class="headerlink" title="sketch2Cloth虚拟试衣总结"></a>sketch2Cloth虚拟试衣总结</h3><p>虚拟试衣允许用户定制衣服的纹理，颜色。能够改善生成图像的真实感。虚拟试衣项目分成训练数据的处理以及GAN图片生成。</p><h4 id="Human-parsing："><a href="#Human-parsing：" class="headerlink" title="Human-parsing："></a>Human-parsing：</h4><p>输入一张人像图片，使用DeepLab+SSL框架对人体图像不同部位进行解析标记。从而根据不同分类的标记信息可以将图片分割成人体皮肤部分，服饰部分，首饰部分等等。<br><img src="/images/data processing.jpg" alt="data processing"><br>根据不同的标注信息，仅保留含有人体皮肤，脑袋的图片；以及保留仅含有服饰的图片。随后对含有服饰的图片<strong>提取边缘信息</strong>，得到服饰的边缘纹理。最终将人体皮肤信息与服饰边缘信息相结合，得到最终的图片和标记，完成数据的预处理。这样处理的好处是，<strong>保留了绝大部分人体皮肤，头发等信息</strong>，利用GAN进行服饰样式生成时，仅需要生成服饰的颜色，纹理信息，尽可能保证图片的真实感。</p><h4 id="DeepLab-v2"><a href="#DeepLab-v2" class="headerlink" title="DeepLab v2"></a>DeepLab v2</h4><ul><li>将多孔卷积应用到密集预测任务上，有效扩大感受野。</li><li>采用多看空金字塔模型，使用不同采样率多尺度获取图像上下文信息。</li><li>将DCNN与完全连接条件场（CRFS）结合，增强物体边界定位。</li><li>SSL：引入自监督结构敏感学习方法进行训练，将人体姿态引入解析结果中，提升实验性能。</li></ul><h4 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h4><ul><li>canny 算子：通过计算像素梯度幅值，方向，确定图片的边缘信息。使用费最大值抑制使得边缘更加清晰。比较看重像素的梯度变化，不看重整体的空间信息。</li><li>edge detection using structure forest：使用随机森林算法学习一个隐状态，将图形映射成边缘。</li><li>HED：整体嵌套边缘检测，将多次度的Edge进行融合，得到整体信息对边缘信息的反映。HED有vgg改造而来，可提取图片特征信息，多次度同和，反映了空间特征。</li></ul><h4 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h4><p>在CGAN的基础上加上L1约束，作为图片的生成器。</p><ul><li>GAN 生成对抗网络，同时训练一个生成器和判别器。优化生成器使其生成的东西更接近原始样本，优化判别器，使其能够更好地判断样本的真假。JS散度：度量两个概率分布的相似度，但是当两个分布距离很远时，将会导致梯度消失。因此引入wasserstein（earth-mover距离）：能够在联合分布的下，样本间的距离，当两个分布距离很远时，也可以提供梯度。</li><li>CGAN条件生成网络，GAN生成数据太过于自由，数据不可控。因此条件生成对抗网络，在生成器与判别器作用是加入一个条件概率，使得结果更符合实际条件。</li><li>pix2pix：在CGAN的基础上加入L1约束（模糊图片），使得生成图像更接近真实图。自动学习损失函数。使用U-net,使得上层图像获取更多的底层图像信息。</li></ul><h3 id="海量地震数据三维可视化"><a href="#海量地震数据三维可视化" class="headerlink" title="海量地震数据三维可视化"></a>海量地震数据三维可视化</h3><ul><li>地震数据segy文件解析：segy文件为GB级别的数据，对多种格式的解析，里头包含了五种不同的数据存储格式，需要对地震数据进行解析以及筛选合适的数据这些操作。</li><li>地震数据预处理：使用SVD分解技术，留下数据中分量比较中的那部分数据</li><li>数据分块读取：按切片载入内存，设计颜色传递函数，使用shader将绘制部分迁移到GPU上执行。使用shader进行绘制。Shader上分为上色，</li></ul>]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AutoMatic Image Colorization 整理</title>
      <link href="/2019/01/23/AutoMatic-Image-Colorization-%E6%95%B4%E7%90%86/"/>
      <url>/2019/01/23/AutoMatic-Image-Colorization-%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>《<strong>Let there be Color:</strong>  Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simutaneous Classification》 是由三位知名的日本学者，发表在2016年的SIGGRAPH上，该模型实现的图片颜色恢复效果十分的好。<br>原文地址：<a href="http://iizuka.cs.tsukuba.ac.jp/projects/colorization/data/colorization_sig2016.pdf" target="_blank" rel="noopener">Let there be Color:</a><br>项目地址：<a href="http://iizuka.cs.tsukuba.ac.jp/projects/colorization/en/" target="_blank" rel="noopener">Automatic Image Colorization</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文利用CNN提取图片全局先验信息(global priors)和局部图片特征信息(local image features)，并对特征进行融合，端对端(end to end)的对灰度图片进行自动上色。</p><blockquote><p>图片语义信息：<br>&emsp;视觉层： 即底层颜色，纹理，形状等等。<br>&emsp;对象层： 属性特征，如某一对象某一时刻的状态<br>&emsp;概念层： 最接近人类理解，如室内，室外，沙子，海水等</p></blockquote><p>全局特征将反映：概念层信息，如室内室外，白天黑夜等等<br>局部特征信息反映：局部材质，物体的位置信息等</p><h3 id="色彩空间"><a href="#色彩空间" class="headerlink" title="色彩空间"></a>色彩空间</h3><p>作者采用Lab颜色空间，L表示亮度，a，b表示颜色光谱绿-红和蓝-黄。Lab编码中有一个灰度层，颜色层变为两个，因此只需要预测两个通道。<br><img src="/images/color_space.jpg" alt="Lab颜色空间"><br>由图可以看出人们对亮度信息比较敏感。人眼中有94%的细胞由于探测亮度，6%的细胞用于探测颜色。因此我们将图片保存成灰度图即保留了图片大部分的信息，又节省空间。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/images/model.png" alt="网络结构"><br>网络结构大体由两部分组成。<br><strong>第一部分：</strong> low-level features 低特征提取，mid-level features 中特征提取，fusion layer 融合层，colorization network上色层组成。<br><strong>第二部分：</strong> low-level features 低特征提取，全局特征提取两部分组成。<br>网络的输入为灰度图，第一部分输入是原图，由于第一部分只有卷积操作，因此对图片尺寸没有要求。第二部分输入是经过resize成224<em>224大小的图片。包含全链接层，对输入大小有限制。<br><em>*预测流程：</em></em>将图片输入，经过低特征，中特征和全局特征的提取，一起来预测两个色彩图层即a和b，然后通过上采样，恢复到原图大小，与灰度图层L融合一起组成lab图片。</p><h4 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h4><p>第一部分包含上色层，可以对图片进行上色，但是由于未加入全局的语义信息，所以效果不好。可以这样认为，根据全局特征得到的图片语义信息（室内或室外），利用全局语义信息进一步决定对图片的上色方案。<br><img src="/images/color compare.png" alt="Alt text"></p><h4 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h4><p>网络第二部分是一个标准的卷积神经网络，全局特征提取层输出是一个1*1*256的一个张量，通过融合层将语义信息加入第一部分网络中。整个网络的损失函数为：<br>$$<br>L(y^{color},y^{class}) = ||y^{color} - y^{color,*}||^2_{FRO} - \alpha (y_{l^{class}}^{color} - \log(\sum^{N}_{i = 0} exp(y_i^{class})))<br>$$</p><p>前半部分是一个预测颜色和真实颜色间的一个MSE Loss，后半部分是预测一个分类交叉熵loss。由于分类loss不影响上色，将$\alpha$设置为0，仅适用上色部分的loss。</p><h3 id="融合层"><a href="#融合层" class="headerlink" title="融合层"></a>融合层</h3><p>$$<br>y_{u,v}^{fusion} = \sigma (b + W [y^{global},y^{mid}_{u,v}]^T)<br>$$</p><p>其中$y^{global}$是一个1*1*256的张量，b是一个$\frac{H}{8}*\frac{H}{8}*256$的一个长方体，将y与b头尾拼在一起，构成一个$\frac{H}{8}* \frac{H}{8}*512$的张量。</p><h3 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h3><p>将第二部分的输入换成一张其他风格的图片，图片类型要求相同，最终形成的图片的风格将发生改变。<br><img src="/images/style_change.jpg" alt="风格迁移"></p><h3 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h3><ul><li>网络输入为多分辨率图片</li><li>网络中无池化层</li><li>上采样过程采用最近邻算法</li><li>所有的上色模型无法解决毛衣的上色问题，因为毛衣颜色不存在先验，是不确定的。如天空，海洋的颜色则是确定的。</li></ul><h3 id="PREFERENCE"><a href="#PREFERENCE" class="headerlink" title="PREFERENCE"></a>PREFERENCE</h3><ul><li><a href="https://blog.csdn.net/u010030977/article/details/78846198" target="_blank" rel="noopener">preference1</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型性能评估指标概要</title>
      <link href="/2019/01/23/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E6%A6%82%E8%A6%81/"/>
      <url>/2019/01/23/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E6%A6%82%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<p>模型性能评价指标能够对模型预测结果性能好坏进行评价。以下列举了常用的模型评价指标。</p><h3 id="AUC评价指标"><a href="#AUC评价指标" class="headerlink" title="AUC评价指标"></a>AUC评价指标</h3><p>AUC（area under thr curve）指标常用来评估二分类模型的性能，指的是ROC曲线与x轴围成的面积。AUC不依赖于判决阀值。<br>判别矩阵如下:</p><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:right">正样本</th><th style="text-align:center">负样本</th></tr></thead><tbody><tr><td style="text-align:left">预测为正</td><td style="text-align:right">TP(真正例)</td><td style="text-align:center">FP(假正例)</td></tr><tr><td style="text-align:left">预测为负</td><td style="text-align:right">FN(假负例)</td><td style="text-align:center">TN(真负例)</td></tr></tbody></table><p>随着阈值t的取值不同，有：<br>真正率（正例预测为真/所有正样本）：<br>$$<br>TPR = \frac{TP}{TP+FN}<br>$$<br>假正率（负例预测为假/所有负样本）：<br>$$<br>FPR = \frac{FP}{FP+TN}<br>$$<br>因此TPR与FPR是关于t的一个函数：<br><img src="/images/predict_matrix.jpg" alt="判别参数关系图"></p><p>AUC即为如下曲线下的面积：<br><img src="/images/AUC.jpg" alt="AUC为曲线下方面积"><br>$$<br>AUC = \int_{t = 0}^{1} y(t) dx(t)<br>$$<br>AUC实际表现为把正样本排在负样本前面的概率。同时AUC对政府样本的比例不敏感。AUC越大表明模型区分正例和负例的能力越强，AUC常常依赖于具体的任务。</p><p><strong>精确率：</strong><br>$$<br>Pricision = \frac{TP}{TP+FP}<br>$$<br>精确度pricision指的是我判断为真的里头，确实为真的概率。</p><p><strong>召回率：</strong><br>$$<br>Recall = \frac{TP}{TP+FN}<br>$$<br>召回率recall指的是我判断是真的里头，确实为真的占样本所有为真的概率。</p><p><strong>F1 score:</strong><br>$$<br>\frac{1}{F_{1}} = \frac{1}{Precision}+\frac{1}{Recall}<br>$$<br>F1是precision和recall的调和均值， F1 score作为正负样本不均衡的评价方式.<br><a href="https://blog.argcv.com/articles/1036.c" target="_blank" rel="noopener">参考链接</a></p><h3 id="mAP"><a href="#mAP" class="headerlink" title="mAP:"></a>mAP:</h3><p>mAP指mean average precision，即各个类别AP的平均值。</p><p>AP：指precision与recall曲线的下面部分。</p><p>对于IoU = 0.5:0.05:0.95分别计算mAP，随后平均得到最后的mAP：指的是将IoU从0.5一直递增到0.95，然后每一个IoU均计算一个AP值，然后对所有的AP值取平均，得到最终的mAP。</p><h3 id="BenchMark，SOTA-与Baseline"><a href="#BenchMark，SOTA-与Baseline" class="headerlink" title="BenchMark，SOTA 与Baseline"></a>BenchMark，SOTA 与Baseline</h3><p>一个算法的benchmark指的是，它的<strong>性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏</strong>。<br>state-of-the-art（SOTA）：能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。</p><p>baseline：表示<strong>比这个算法性能还差的基本上不能接受的</strong>，除非方法上有革命性的创新点，而且还有巨大的改进空间和超越benchmark的潜力，只是因为是发展初期而性能有限。所以baseline有一个自带的含义就是“<strong>性能起点</strong>”。</p><p>总结一下就是：<strong>benchmark是属于较好的水准，baseline则代表了及格线。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 模型评价 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>human head detect summary</title>
      <link href="/2019/01/23/human%20head%20detect%20summary/"/>
      <url>/2019/01/23/human%20head%20detect%20summary/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ 刷题常用数据及函数的语法记录</title>
      <link href="/2019/01/21/C-%E5%88%B7%E9%A2%98%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/"/>
      <url>/2019/01/21/C-%E5%88%B7%E9%A2%98%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<ul><li><h3 id="字符串操作："><a href="#字符串操作：" class="headerlink" title="字符串操作："></a>字符串操作：</h3><p> <strong>int to string：</strong> &emsp;<code>string a  = to_string(int)</code><br> <strong>string to int：</strong>&emsp; <code>int a = stoi(string)</code><br> <strong>char to int：</strong> &emsp;  <code>int a = char_b - 48</code><br> <strong>字符串中查找字符： </strong></p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> a = <span class="string">"abcd"</span>;</span><br><span class="line"><span class="built_in">string</span> b = <span class="string">"ab"</span>;</span><br><span class="line"><span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> pos = a.find(b,start); <span class="comment">// start可省略，默认从0开始</span></span><br><span class="line"><span class="comment">//如果查找不存在返回string::npos</span></span><br><span class="line"><span class="keyword">if</span>(a.find(b) == <span class="built_in">string</span>::npos) <span class="built_in">cout</span>&lt;&lt;<span class="string">"dont exist"</span>;</span><br></pre></td></tr></table></figure><p> <strong>截取子串： </strong>&emsp; <code>string a  = astring.substr(startpos,length)</code></p></li><li><h3 id="vector操作："><a href="#vector操作：" class="headerlink" title="vector操作："></a><strong>vector操作：</strong></h3><p> <strong>vector 删除：</strong><br> <code>vector_a.erase(iter_pos)</code>,<code>vector_a.erase(iter_begin(),iter_end())</code><br> <strong>vector排序：</strong>匿名函数的形式<br> <code>nums.sort(nums.begin(),nums.end(),[](int a,int b){return a&gt;b;})</code></p></li><li><h3 id="unordered-map操作"><a href="#unordered-map操作" class="headerlink" title="unordered_map操作:"></a><strong>unordered_map操作:</strong></h3><p>  unordered_map实现使用了哈希表，可以在$O(1)$时间复杂度访问到对应元素，缺点为要花费较高的空间复杂度。<br>  map实现使用的对应结构为红黑树（类似平衡树），查找元素使用的复杂度为$O(\log n)$。<br>  <strong>unordered_map声明：</strong> &emsp;<code>unordered_map&lt;char,int&gt; map;</code><br>  <strong>unordered_map插入键值对：</strong><br>  &emsp;<code>map[&#39;a&#39;] = 1;</code>,<code>map.insert(make_pair(&#39;a&#39;,1));</code><br>  <strong>unordered_map查找元素：</strong><br>  &emsp; <code>if(map.find(&#39;B&#39;) == map.end()){dont exist}</code>，<br>  &emsp; <code>if(map.count(&#39;B&#39;) == 0){dont exist}</code><br>  <strong>unordered_map移除元素：</strong><br>  &emsp;<code>map.erase(map.begin())</code>,<br>  &emsp;<code>map.erase(map.begin(),map.end())</code>,<br>  &emsp;<code>map.erase(&#39;A&#39;)</code></p></li><li><h3 id="中值的取法："><a href="#中值的取法：" class="headerlink" title="中值的取法："></a><strong>中值的取法：</strong></h3>  防止整数溢出：<code>int mid = left + (right-left)/2;</code></li><li><h3 id="大数组开成全局变量："><a href="#大数组开成全局变量：" class="headerlink" title="大数组开成全局变量："></a><strong>大数组开成全局变量：</strong></h3>  <code>int weight[N][M];</code><br>  原因是计算机会将把虚拟内存空间分配给程序。虚拟内存空间分为栈空间和堆空间。所有开在函数内部的变量会开在栈里，所有开在静态变量，全局变量会开在堆里。C++默认栈空间大小为4M，所以一般将大数组开到全局变量中去。</li><li><h3 id="异或的作用（-）："><a href="#异或的作用（-）：" class="headerlink" title="异或的作用（^）："></a><strong>异或的作用（^）：</strong></h3><ol><li>用异或实现配偶：0^1=1，1^1=0</li><li><p>lowbit运算：给一个n快速找到二进制中最低的一个1，lowbit(100100) = 100 -&gt;树状数组的基本操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int lowbit(int n)&#123;</span><br><span class="line">      return (~n + 1) &amp; n; // return (-n)^n; 补码就是负数</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>位运算与底层的电路实现有关，无论什么操作都只用O(1)时间。</p></li></ol></li></ul><ul><li><h3 id="STL中的全排列操作："><a href="#STL中的全排列操作：" class="headerlink" title="STL中的全排列操作："></a><strong>STL中的全排列操作：</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">while(next_permutation(A.begin(),A.end()))&#123; ... &#125; //从小到大产生排列组合，当排列组合全部产生结束时返回false</span><br><span class="line">prev_permutation(A.begin(),A.end());   // 从大到小生成排列数，直接改变vector里头的值</span><br></pre></td></tr></table></figure></li><li><h3 id="sprintf"><a href="#sprintf" class="headerlink" title="sprintf()"></a>sprintf()</h3><p>   C 库函数 int sprintf(char <em>str, const char </em>format, …) 发送格式化输出到 str 所指向的字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sprintf(str, &quot;Pi 的值 = %f&quot;, M_PI); // str = &quot;Pi 的值 = 3.141593&quot;</span><br><span class="line">sprintf(str,&quot;%02d:%02d&quot;,h,m); // %02d 指的是整数h的宽度为2，如果不够的话前面补0.(3-&gt;03)</span><br></pre></td></tr></table></figure></li><li><h3 id="set用法：-set是一个内部元素唯一的集合，定义：set-lt-vector-lt-int-gt-gt-res"><a href="#set用法：-set是一个内部元素唯一的集合，定义：set-lt-vector-lt-int-gt-gt-res" class="headerlink" title="set用法： set是一个内部元素唯一的集合，定义：set&lt;vector&lt;int&gt;&gt; res;"></a><strong>set用法：</strong> set是一个内部元素唯一的集合，定义：<code>set&lt;vector&lt;int&gt;&gt; res;</code></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> iter = res.begin();iter!=res.end();iter++) ...</span><br><span class="line">res.clear(); <span class="comment">//删除所有的元素</span></span><br><span class="line">res.empty(); <span class="comment">//判断是否为空集合</span></span><br><span class="line">res.rbegin() == res.end();</span><br></pre></td></tr></table></figure></li><li><h3 id="vector的用法："><a href="#vector的用法：" class="headerlink" title="vector的用法："></a>vector的用法：</h3><p>  初始化：<code>vector&lt;int&gt; vec(size,0);</code><br>  添加元素：<code>vec.push_back(val);vec.insert(vec.begin(),val);</code><br>  删除元素：<code>vec.pop_back();vec.erase(vec.begin())</code></p><pre><code>`vec.erase(vec.begin(), vec.begin()+3);`</code></pre><p>  查找：<code>find(vec.begin(),vec.end(),val) != vec.end()</code><br>  排序:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sort(vec.begin(),vec.end()); </span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">myfun</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> a&lt;b; <span class="comment">// 生序</span></span><br><span class="line">&#125;</span><br><span class="line">sort(vec.begin(),vec.end(),myfun); </span><br><span class="line">sort(vec.begin(),vec.end(),[](<span class="keyword">int</span> a,<span class="keyword">int</span> b)&#123;<span class="keyword">return</span> a&lt;b;&#125;)</span><br></pre></td></tr></table></figure></li><li><h3 id="lambda-表达式："><a href="#lambda-表达式：" class="headerlink" title="lambda 表达式："></a>lambda 表达式：</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> func = [c](<span class="keyword">int</span> a,<span class="keyword">int</span> b) &#123; <span class="keyword">return</span> a &lt; b; &#125;;</span><br></pre></td></tr></table></figure><p>  其中c为表达式外边的变量，a,b为传入表达式的变量。</p></li><li><h3 id="string-中find函数"><a href="#string-中find函数" class="headerlink" title="string 中find函数"></a>string 中find函数</h3><p><code>int pos = str.find(char,int begin = 0,int end = str.size())</code></p><p><code>//if(pos == string::npos) cant find it else return the index of char</code></p></li><li><h3 id="string-中的substr"><a href="#string-中的substr" class="headerlink" title="string 中的substr"></a>string 中的substr</h3><p><code>string str = s.substr(begin,num)//表示从begin开始，共num个数</code></p><p><code>string str = s.substr(begin)//表示从begin开始到最后</code></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Github 建站</title>
      <link href="/2019/01/19/Github-%E5%BB%BA%E7%AB%99/"/>
      <url>/2019/01/19/Github-%E5%BB%BA%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>github上搭建一个博客网站（windows）</p><p><strong>1. 前期准备</strong></p><ul><li><strong>node.js:</strong> 2009年由Ryan推出的，基于javascript（负责解释并执行代码）与google 浏览器V8引擎（c++编写的一个超快的解释器）的一个后端服务器应用程序。旨在增大服务器并发连接的数量（非阻塞，时间驱动I/O）。</li><li><strong>git:</strong>开源分布式版本控制系统。<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">见链接</a></li><li><strong>hexo:</strong>一个快速简洁的博客框架。<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">见链接</a>，hexo支持makdown，<strong>是一个生成静态网页，并将网页上传到服务器上的工具。</strong></li></ul><p><strong>2. Github上创建一个registry</strong></p><ul><li>Github上新建项目，项目必须要遵守格式：账户名.github.io，同时勾选Initialize this repository with a README。（eg：WenHuiZhou.github.io）</li></ul><p><strong>3. 下载安装node.js，以及git</strong><br><strong>4. 安装hexo</strong></p><ul><li>命令行内输入指令：<code>npm install -g hexo-cli</code><br>&emsp;&emsp;npm (node package manager)：运行在node.js上的一个使用javascript写的类库管理器，npm内置于node.js中，作为node.js的包管理器。可以使用npm来查找安装一些库(nmp install jquery.js)。<br>&emsp;&emsp;有时使用npm进行下载文件时经常出现网络上的问题，此时可以对npm换源。<code>npm config set registry https://registry.npm.taobao.org</code></li><li>创建文件夹，作为hexo博客文件存储文件夹，输入指令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init&lt;blog&gt;</span><br><span class="line"><span class="built_in">cd</span> &lt;blog&gt;</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><pre><code>完成创建后hexo将生成如下文件：</code></pre><p><img src="/images/hexo_forder.jpg" alt="hexo生成目录结构"></p><ul><li>正常使用中修改最多的文件夹为<strong>_config.yml</strong>，其中包括博客的基础配置以及模板信息。<strong>source</strong>为写文章所需的目录，如果要针对下载的模板修改，那么需要修改<strong>themes</strong>模板目录。</li><li><strong>启动hexo：</strong><br><code>hexo g</code>：hexo生成网页（generate），<br><code>hexo s</code>：hexo启动服务器server。</li></ul><p><strong>5 . hexo 连接 github</strong></p><ul><li>打开git bash，进入blog文件夹</li><li><p>配置用户名，以及邮箱输入：<br><code>git config --global user.name WenHuiZhou</code><br><code>git config --global user.email myemail</code></p><p>  每次使用git进行commit时都需要用到用户名和邮箱记录。用于指定push到的github。</p></li></ul><p><strong>6. SSH密钥登陆：</strong></p><ul><li>利用密钥生成器制作一对密钥——一只公钥和一只私钥。将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。<ul><li>生成密钥对：<code>ssh -keygen -t rsa -C &quot;myemail.com&quot;</code>，将生成id_rsa 和 id_rsa.pub两个文件。</li><li>添加密钥对到ssh-agent：<code>eval &quot;$(ssh-agent -s)&quot;</code></li><li>添加生成的SSH key到ssh-agent：<code>ssh-add ~/.ssh/id_rsa</code></li></ul></li></ul><p><strong>7 .设置github的ssh密匙</strong></p><ul><li>打开github setting，将添加ssh key，将id_rsa.pub内容复制进去即可。</li><li>在git bash上输入<code>ssh -T git@github.com</code> 此时返回 hi WenHuiZhou表明配置成功。</li></ul><p><strong>8 . 配置_config.yml文件</strong></p><ul><li><p>在_config.yml文件最后添加：<br><code>deploy:type:gitrepository:git@github.com:WenHui-Zhou/WenHuiZhou.github.io.gitbranch: master</code></p><p>  repository地址可以从github上download那得到。</p></li></ul><p><strong>9. 在hexo上写博客</strong></p><ul><li><code>hexo new post &quot;blog name&quot;</code>，hexo将会在<strong>source</strong>文件夹中生成.md文件，编辑.md文件写博客。</li><li><code>hexo s</code>: 进入本地博客地址观察效果</li><li><code>hexo d -g</code>: 将博客上传至github上</li><li>输入github上的访问地址：<strong><a href="https://wenhui-zhou.github.io/">https://wenhui-zhou.github.io/</a></strong>即可博客网站。</li></ul><p><strong>10. 总结</strong></p><ul><li>使用hexo和github搭建了一个博客</li><li>使用hexo模板 maupassant对博客进行美化，<a href="https://www.haomwei.com/technology/maupassant-hexo.html" target="_blank" rel="noopener">见链接</a></li><li>该模板还需要做大量的个人定制工作，这是接下来要做的。</li></ul><p><strong>PREFERENCE</strong></p><ul><li><a href="https://www.jianshu.com/p/1c888a6b8297?utm_source=oschina-app" target="_blank" rel="noopener">reference1</a></li><li><a href="https://buptwc.com/2018/05/10/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%B6%85%E9%AA%9A%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%9F/" target="_blank" rel="noopener">reference2</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 建站 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> netStation </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
