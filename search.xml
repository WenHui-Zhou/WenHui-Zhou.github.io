<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[bert的一些思考]]></title>
    <url>%2F2019%2F12%2F19%2Fbert%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[观其大致，能够比较好的融会贯通，理解整个任务。这是这篇post的主要目的。 Bert的应用模式 bert在应用到具体的任务上时，通常采用两阶段策略： 第一阶段利用通用语言模型任务，采用自监督的学习方法，选择某个具体的特征抽取器，来学习预训练模型 第二个阶段，根据手头具体的监督学习任务，采取特征集成或finetune的应用模型， 总之，加载预训练模型，然后为不同的任务定制第二阶段的定制网络 特征集成任务 ELMO方法是典型的特征集成方式，把当前要判断的输入句子，走一遍ELMO预训练好的的双层双向LSTM网络，然后把每个输入单词对应位置的高层LSTM激活embedding（或者输入单词对应位置的若干层embedding进行加权求和），作为下游任务单词对应的输入。 这是一种典型的应用预训练模型的方法，更侧重于单词的上下文特征表达方面。 finetune模式 GPT和bert采用finetune应用模式，在获得了预训练模型以及对应的网络结构（Transformer）后，第二个阶段仍然采用与预训练过程相同的网络结构，拿出手头任务的部分训练数据，直接在这个网络上进行模型训练，以针对性地修正预训练阶段获得的网络参数，一般这个阶段被称为Fine-tuning。 搜索引擎的未来就是QA和阅读理解：搜索引擎通过理解文本，对于用户提出的问题直接给出答案。 Bert生成式任务 例如将bert用在生成式摘要任务中。从技术角度上来讲，生成式任务符合典型的encoder-decoder框架。encoder部分好解决，只需要用预训练好的Bert模型初始化encoder部分的transformer即可。另一方面是decoder端。大量的实验证明直接将bert的预训练参数用来初始化decoder的部分效果都不好。主要原因是bert预训练的时候使用的是双向的语言模型，而一般的decoder任务是从左到右依次生成的，无法利用bert在预训练阶段学到的上下文信息。这也是bert在做生成类任务时遇到的最大问题。 如何用bert 简而言之，使用bert的核心在于使用transformer作为特征提取器，用bert预训练模型初始化transformer参数，然后再用当前的任务去finetune。]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch 重点回顾]]></title>
    <url>%2F2019%2F12%2F09%2Fpytorch-%E9%87%8D%E7%82%B9%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[pytorch 在日常实践中的一些常用的函数，工作流。 pytorch 简介pytorch是一个基于torch的python开源库。前身torch是一个有大量机器学习算法支持的科学计算框架，以及与numpy类似的张量操作库。通过pytorch的反向求导技术，可以实现动态的修改神经网络，实现速度快是一大特点。 缺点是全面性不如TensorFlow，移动端的部署性能有待提升。 张量tensors张量在神经网络中大量的应用，支持pytorch的反向求导，可以和numpy库互换，GPU计算，是pytorch中的砖块的角色。 创建张量 在深度学习中，torch.float类型使用比较多，常见的，当我们使用tensor申请参数的时候，常用的函数： 1234567891011# 申请一个未初始化的矩阵x = torch.empty(3,3) # 大小为3x3的一个矩阵，数字可以无限加，每一个数值表示一个矩阵# 随机初始化，感觉这个会用的比较多一点x = torch.rand(24,24,3，dtype = torch.float) # 大小为24x24x3，dtype = floatx = torch.zeros(3,3,3) #维度为3x3x3# 直接使用数据来构造x = torch.tensor([5.1,1]) # 使用已经存在的数据来构造x = x.new_ones(5,4,dtype= torch.double)x = torch.randn_like(x,dtype = torch.float) # 维度与之前的x相同x.size() # 返回一个tuple，表示tensor的维度 张量操作 1234567891011121314151617181920212223242526272829303132333435#加法z = x + y#减法z = x - y# 获得float的输出（而不是tensor）x.item()# 改变tensor的形状x.view(16) # 变成1*16的向量x.view(-1,4)# 4x4的向量x.view(-1,2,2)# 2x2x2的向量# tensor支持所有的numpy切片操作x[:10]# cat拼接向量torch.cat((x,y),dim = 0) # y轴方向torch.cat((x,y),dim = 1) # x轴方向# chunk，向量拆分x.chunk(chunks = 3,dim = 0) # y方向，等分成三份，第三份可能会少一点x.chunk(chunks = 3,dim = 1) # x方向# 截断x.clamp(0.3,0.7) # 数值限制在这个范围x.sort(dim = 0) # 沿着x方向排序，返回下标x.flatten() # 将向量展成一列# 选择前topKx.topk(2,dim=0) # 返回 值以及下标x.numel()#返回所有元素torch.stack((x,y), dim = 0/1) # 保留维度，然后将向量组合在一起x.permute(2,0,1) # 调整每一维度向量的先后x.squeeze(dim = 1) # 维度为1的坍缩x.unsqueeze(dim = 0) # 增加一个维度为1的x.cuda() # 放回在GPU上的拷贝torch.where(x&gt;0,x,y) # x&gt;0 返回x，否则返回yx.round() # 取整x.contiguous() # 转成连续存储模式 x.numpy() # 返回numpy格式x = torch.from_numpy(a) # numpy转成tensor pytorch自动微分autograd包是pytorch所有神经网络的核心，autograd为tensor上所有的操作提供自动微分。当我们在定义一个tensor的时候，将requires_grad设置成true，pytorch将会开始跟踪该tensor的所有操作。backward()将会自动计算所有的梯度。 要停止计算梯度可以使用detach()，或者使用with torch.no_grad()包起来。每个张量都有一个grad_fn的属性，这个属性保存着一个Function的引用，保存计算过程的完整信息。 123456789x = torch.ones(2,2,requires_grad = True)"""x = tensor([[1,1], [1,1]],requires_grad = True)"""y = x + 2"""y = tensor([[3,3],[3,3]],grad_fn = &lt;AddBackward0&gt;)""" 搭建神经网络神经网络可以通过torch.nn来构建。一个nn.Module包含层以及一个正向传播的方法,forward()。一个典型的神经网络训练过程包括以下几点： 定义一个包含可训练参数的神经网络 迭代整个输入 通过神经网络处理输入 计算loss 反向传播梯度到神经网络的参数 更新网络的参数，使用一些优化器等 123456789101112131415161718192021222324252627class net(nn.Module): def __init__(self): super(net,self).__init__() # 定义一些层 . def forward(self,x): # x 为输入，下面是定义网络正向传播的过程 .nets = net()print(nets) # 输出net的结构信息net.parameters() # 得到net中的所有的参数net.zero_grad() # 将所有参数梯度缓存置零output = nets(input)target = torch.rand(10)target = target.view(1,-1)criterion = nn.MSELoss() # 定义loss# 参数更新规则import torch.optim as optimoptimizer = optim.SGD(net.parameters(),lr = 0.01)optimizer.zero_grad()output = nets(input)loss = criterion(output,target)loss.backward()optimizer.step() 处理数据 处理图像时，我们可以使用pillow，opencv这些库 处理语音时，我们可以使用scipy，librosa 处理文本，可以使用python的基础数据加载模块，或者使用NTLK，SpaCy这些库 GPU数据处理 如何将数据转移到GPU上： 1234device = torch.device('cuda:0,1,2,3' if torch.cuda.is_available() else 'cpu')net.to(device)# 输入，输出也有传输到gpu上inputs,labels = inputs.to(device),labels.to(devices) pytorch默认使用一个GPU，我们可以通过DataParallel()来设定模型在GPU上跑。 12import torch.nn as nnmodel = DataParallel(model) 尽管我们的模型只获得一个输入，执行一个线性操作，然后输出。数据并行操作自动拆分了你的数据，将任务单发到多个GPU上。当每一个模型都完成自己的任务，DataParallel收集这些结果，然后返回到输出中。（代码形式是线性的，但是程序执行的时候是并行的） 代码见github链接。 数据类 123456789101112import torchimport torch.nn as nnfrom torch.utils.data import Dataset,DataLoaderclass own_dataset(Dataset): def __init__(self,data): self.data = data def __getitem__(self,index): return self.data[index] def __len__(self): return len(self.data)data_loader = DataLoader(own_dataset,batch_size = 4,num_works = 2,shuffle = True) 继承Dataset需要实现其中的__getitem__()，__len__()方法。 继而实现dataLoader类，作为一个迭代器，每次向model中喂数据，batch_size这些参数都在这里设置。 如何将自己的数据转化成DataLoader的类型： 123456789import torch.utils.data as Datax = torch.rand(10,10)y = torch.rand(10,1)# 转换成datasetdatas = Data.TensorDataset(x ,y)lloader = DataLoader(datas,batch_size=4,shuffle=True)for data_x,data_y in lloader: print(data_x,data_y) break python pytorch 迁移学习事实上，很少人从头开始训练一个完整的网络。通常的做法是在一个很大的数据集上进行预训练，得到网络的初始化参数，或者固定这些参数，去优化下游任务。 保存、加载模型 123456789101112131415161718# save 参数torch.save(model.state_dict(),'my_resnet.pth')resnet = ResNet()resnet.load_state_dict(torch.load('my_resnet.pth'))# save 模型结构torch.save(model,'my_resnet.pth')resnet = torch.load('my_resnet.pth')# 保存checkpointtorch.save(&#123; 'epoch':epoch, 'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict(), 'loss':loss, .&#125;, PATH)# DataParallel模型的保存使用：torch.save(model.module.state_dict(),PATH) 加载部分预训练参数 有些场景我们基于一个基础网络做的，因此我们需要为主干网络进行初始化： 12345pretrain = model_zoo.load_url(model_urls['resnet152'])model_dict = model.state_dict()pretrain = &#123;k:v for k,v in pretrain.items() if k in model_dict&#125;model_dict.update(pretrain)model.load_state_dict(model_dict) 当一个batch中，句子不等长的时候123456789101112131415import torch.nn.utils.rnn as rnn_utilsfrom torch import nnfrom torch.utils.data import DataLoaderimport torch.utils.data as datatrain = [tensor([1,1,1,1,1,1,1]),tensor([3,3,3,3,3]),tensor([6,6])]# 将train 变量的长度补全后面补上0，使得其长度一致x = rnn_utils.pad_sequence(train, batch_first=True)# 由于直接用上面的变长变量，会增加很多工作，因此我们需要pack，将向量的长度减小# 其中第二个参数为每一个序列，实际的长度# 返回值为：data=tensor([1., 3., 6., 1., 3., 6., 1., 3., 1., 3., 1., 3., 1., 1.]),# batch_sizes=tensor([3, 3, 2, 2, 2, 1, 1]))x = rnn_utils.pack_padded_sequence(x,[7,5,2],batch_first = True)# 下面函数为上面函数的逆函数，恢复填充0之后的tensorx = rnn_utils.pad_packed_sequence(x,batch_first = True) pytorch库的大致功能 12345import torch.nn as nn # 包含的大量的网络层nn.Linear() 等等from torch.utils.data import Dataset,DataLoader # 包含了数据读取的方式import torch.nn.functional as F # 包含了激活函数等import torch.optim as optim # 包含了优化器import torch.nn.utils.rnn as rnn # rnn中的一些方法 机器翻译模型将词转化成可以输入网络的格式： 123456789101112131415import torch.nn as nn# 首先经过一系列的分词，去除不正确的词# 建立词向量表，用随机值初始化embed = nn.embedding(n_vocabulary,embedding_size) #字典的字数，每个词向量的长度# embedding是一个二维的矩阵，y轴方向为每个单词，x轴为词向量的具体表示def word2vec(input_seq): # input_seq是一个batch，含有多个句子，但是句子的长度不一致， # 因此需要将句子的长度补充到一致的水平 # 可以使用nn.utils.rnn.pad_sequence(x,batch_first = True) words = nn.utils.rnn.pad_sequence(x,batch_first = True) # 输入的数据每次喂给模型的为batch中句子的第n列词，因此需要把维度改为seq*batch words = word.T embed_word = embed(words) # 将词替换成词向量 # 下一步送入模型之前，对填充变量进行压缩 x = rnn_utils.pack_padded_sequence(x,lengths = [7,5,2],batch_first = True) 上述过程就得到了输入数据的格式。通常机器翻译模型由encoder和decoder的机构组成。 Encoder将句子编码成一个语义向量，decoder一个一个产生目标单词，根据之前的单词，产生之后的单词： 具体如何选择encoder和decoder有非常多的选择（LSTM，GRU）等等。 下面实现encoder部分: 12345678910111213141516171819202122# 搭建encoder模型"""encoder的输入input_seq大小为【最大句子长度*batch-size】"""class EncoderRNN(nn.Module): def __init__(self,hidden_size,embedding,n_layers=1,dropout=0): super(EncoderRNN,self).__init__() self.n_layers = n_layers self.hidden_size = hidden_size self.embedding = embedding self.gru = nn.GRU(hidden_size,hidden_size,n_layers,droput=(0 if n_layers==1 else dropout),bidirectional=True) def forward(self,input_seq,input_lengths,hidden=None): embedded = self.embedding(input_seq) # 转化成词向量 packed = nn.utils.rnn.pack_paded_sequence(embedding,input_lengths)# 压缩 # 整体的一个output，和最后一层的hidden输出 outputs,hidden = self.gru(packed,hidden) # 将tensor填充到维度一致，还返回一个每个句子的长度 outputs,_ = nn.utils.rnn.pad_packed_sequence(outputs) # 将正反两向的值相加 outputs = outputs[:,:,:self.hidden_size] + output[:,:,:self.hidden_size] return outputs,hidden GRU的使用 123456gru = torch.nn.GRU(input_size,hidden_size,n_layers)# 这里的input_size就是词向量的维度，hidden_size就是RNN隐藏层的维度，这两个一般相同就可以# n_layers是GRU的层数# GRU实现自身迭代，不需要时间步数# GRU的输入是经过pack后的向量# GRU的输出有两个，分别为整体的输出和最后一层的hidden 注意力机制的应用： 上面$h_s$表示GRU向上的所有输出，用来分类。$h_t$表示GRU向右的输出，是隐藏状态值。 由上面分析，最终权重将会有三种计算方式： 第一个是直接将输出和隐藏状态的输出相乘，linear层的输出作为权重。 第二种方式是加入一个linear层，输入为output。linear的输出再乘以hidden。 第三种首先hidden转化为output的shape，然后将hidden和output串在一起，经过一个linear层，之后用tanh激活函数，最后用hidden_shape的value乘以tanh的输出，得到最后权重 但是这个还没完，最后还要经过一个softmax，才能得到最终的权重，然后乘以output，作为decoder的输入。 下面是attention第三种公式的实现部分： 12345678910111213class atten(nn.Moudle): def __init__(self,hidden_size): super(atten,self).__init__() self.fc = linear(hidden_size*2,hidden_size) self.v = nn.Parameter(torch.FloatTensor(hidden_size)) def forward(self,hidden,encoder_output): x = torch.cat((hidden.expand(encoder_output.size(0),-1,-1), encoder_output),2) x = self.fc(x) # shape = [hidden_size,hidden] x = F.tanh(x) x = torch.sum(self.v * x,dim = 2) x = F.softmax(x.T,dim = 1).unsqueze(1) return x 最后的输出转置之后，经过一个softmax转换成概率之后，输出。 decoder接受encoder部分的hidden-state，即句子的深层特征。然后输入全是&lt;SOS&gt;，即句子的结束符。所以首先decoder需要进行word2vec，然后接受encoder的中间层的输出，最后得到decoder的output（可能会有全连接层），然后输出结果和target计算一个loss。 下面实现以下decoder的部分，包括输入的形成以及decoder最后的输出： 1234567891011121314151617181920212223242526272829# decoder 部分class decoder(nn.Module): def __init__(self,embedding,hidden_size,n_layers = 1,dropout=0.1): super(decoder,self).__init__() self.hidden_size = hidden_size # encoder,decoder都会用到 self.n_layers = n_layers self.dropout = dropout # 定义decoder的层 self.embedding = embedding self.embedding_dropout = nn.Dropout(dropout) self.gru = nn.GRU(hidden_size,hidden_size,n_layers,dropout) self.fc1 = nn.Linear(hidden_size*2,hidden_size) self.fc2 = nn.Linear(hidden_size,hidden_size) self.attn = atten(hidden_size) def forward(self,inputs,last_hidden,encoder_output): embedd = self.embedding(inputs) embedd = self.embedding_dropout(embedd) # 进入GRU网络 rnn_output,hidden = self.gru(embedd,last_hidden) # 然后rnn_output作为是一个输出结合连个输出的attention，去做分类的工作 attention = self.attn(rnn_output,encoder_output) x = torch.cat((rnn_output,attention),1) x = self.fc1(x) x = torch.tanh(x) x = self.fc2(x) x = F.softmax(x,dim = 1) return output,hidden # 返回输出和最终隐藏状态（每一个词的长度都是词向量的长度） 下面调用encoder和decoder，使得整个网络连贯起来： 1234encoder_outputs, encoder_hidden = encoder(input_variable, lengths)attens = atten(encoder_hidden,encoder_output)encoder_outputs = encoder_outputs*attensdecoder_output,decoder_hidden = decoder(inputs,encoder_outputs,encoder_hidden) 定义损失函数： 由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地考虑张量的所有元素。我们定义maskNLLLoss可以根据解码器的输出张量、 描述目标张量填充的binary mask张量来计算损失。该损失函数计算与mask tensor中的1对应的元素的平均负对数似然。 123456def maskNLLLoss(inp, target, mask): nTotal = mask.sum() crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1)) loss = crossEntropy.masked_select(mask).mean() loss = loss.to(device) return loss, nTotal.item() 本文github地址：https://github.com/WenHui-Zhou/NLP_pratice/blob/master/pytorh_review.ipynb inference https://www.cnblogs.com/duye/p/10590146.html https://plmsmile.github.io/2017/10/12/Attention-based-NMT/ http://www.nlpuser.com/pytorch/2018/11/04/Attention-In-TextClassification/]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP实践 基于注意力机制的文本匹配]]></title>
    <url>%2F2019%2F12%2F05%2FNLP%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[文本匹配是一个宽泛的任务，只要是研究两端样本之间的关系，都可以将这个问题看成文本匹配的问题。常见的任务场景有： 相似度计算，复述识别 问答系统 对话系统 自然语言推理、文本蕴含识别 信息检索中的匹配 机器阅读理解 通用baseline对于这种匹配问题，直接上一个SiameseCNN模型，即孪生模型将textA，textB输入两个模型中，如果是计算两个文本的相似性，可以直接采用cosine，L1距离，欧式距离等得到两个文本之间的相似性。 匹配问题可能还会涉及到问答关系，文本蕴含关系等等，因此我们可以通过两个子模型生成了textA，textB的向量来构造出更加适合的feature，如A-B，A*B等等。然后用额外的模型（如MLP）来学习文本之间的映射关系。 孪生模型 孪生模型的含义指的是神经网络连体，通过权值共享的方式，组成一个完整的网络： Network1与Network2有着相同的网络和相同的权重。他的作用是衡量两个输入的相似性。具体的应用有QA问答系统，手写体识别等等。 应用场景 相似度计算 判断两个文本是否表达相同的含义，构成复述关系 有些数据集给出相似度等级，有些数据集则给出0/1标签 问答匹配 问答问题可以视为是一个分类问题，但是通常情况下，但是实际场景是从若干候选中找出正确的答案，相关数据集是通过一个匹配正例和若干负例组成的，往往建模成rank问题 学习方法上，不仅可以使用分类方法来做（pointwise-learning），还可以使用pairwise-learning（同问题的一对正负样本作为一对正负样本），listwise-learning（同问题的全部样本序列作为一个样本）。 对话匹配 对话系统是问答系统的升级，主要的不同有：对话匹配引入了历史轮，因此回答需要参考历史 对话匹配的回复空间比问答系统要大很多，甚至存在一些万能回复。 自然语言推理、文本蕴含识别 如果一直句子A，能够推导出句子B为正，则A蕴含B，若推导出B为假，则说明，A与B相互矛盾，如无法推导出B为真为假那么A与B独立。 可以将这个问题看成是一个3-way classification的问题 信息检索匹配 query-title匹配、query-document匹配等信息检索场景下的文本匹配问题。不过，信息检索场景下，一般先通过检索方法召回相关项，再对相关项进行rerank。对这类问题来说，更重要的是ranking，而不是非黑即白或单纯的selection 机器阅读理解 在文本中找到答案片段 学习方法基于表示的文本匹配方法（simaese结构）与基于交互的匹配方法（花式attention交互）纷争数年，最终文本匹配问题还是被BERT方法给终结了。 基于表示的孪生结构 这种结构有两个改进方向，一种是使用更加强大的encoder，第二种为使用更加花哨的相似度计算函数。基于这两个方向的工作也很多 基于交互attention结构 首先通过attention为代表的结构来对两段文本进行不同粒度（词，短语级别）的交互，然后将各个粒度的匹配结果通过一种结构聚合起来，作为一个超级特征向量得到最终的匹配关系。 然后这种结构往往在某个场景中有很好的性能，换一个场景性能可能就会变差（因为设计出来的结构迎合了某个特定数据集的数据分布）。 attention机制attention是一个用于提升RNN在encoder-decoder中性能的机制，在机器翻译，语音识别，图像标注中得到广泛的应用。attention为句子中的每个词赋予了不同权重，使得神经网络学习变得更加的灵活（soft），同时可以反应在翻译，识别过程中的一种对齐关系。 attention帮助模型对输入的x的每个部分赋予不同的权重，抽取出更加关键的信息，使得模型做出更加准确的判断，同时不会产生过大的计算和存储的开销。 attention模型以经典的Bahdanau attention 为例： 经典的attention结构主要由三个部分： source function：度量环境向量与当前输入向量的相似性，找到当前环境下应该focus那些信息 $$\begin{equation}e_{i j}=a\left(c, y_{i}\right)=v_{a}^{T} \tanh \left(W_{a} c+U_{a} y_{i}\right)\end{equation}$$ alignment function：计算attention weight，通常使用softmax进行归一化 $$\begin{equation}\alpha_{i j}=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1}^{T_{x}} \exp \left(e_{i k}\right)}\end{equation}$$ generate context vector function: 利用attention weight对输出赋予新的权重。 $$\begin{equation}z_{i}=\sum_{i} \alpha_{i j} * y_{i}\end{equation}$$ attention机制通常和seq2seq一起介绍： 脱离seq2seq结构，使用下面的方式计算attention： 首先计算key和query的相似性，得出权重。然后通过sotfmax进行归一化得到结构之后与value相乘，得到最后的attention value。 实现数据集：https://nlp.stanford.edu/projets/snli/ SNLI1.0包含570，000的人工手写英文句子对。针对 推理前提(premise)与推理假设(hypothesis)之间是否存在逻辑关系，人工标注了以下三种标签： entailment) 蕴含、推理 p⇒h contradiction 矛盾、对立 p⊥h neutral 中立、无关 p⇎h 明天要做的事： 把数据集的文件整理好 然后把网络结构搭建起来 整理一下思路 跑代码，完成蕴含关系的实验 把照片找出来 inferencehttps://www.jiqizhixin.com/articles/2019-10-18-14]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP实践 文本分类任务]]></title>
    <url>%2F2019%2F12%2F02%2FNLP%E5%AE%9E%E8%B7%B5-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[文本分类是NLP中的一个很经典的问题，通过这个问题可以熟悉NLP在处理这类问题的一个大致的思路，达到快速入门的目的。 nlp中token，tokenize，tokenizer token：令牌，表示关键字，变量名，标点，括号等标记符号 tokenize：令牌化，解析标记，将一个句子中关键字等令牌解析出来 tokenizer：令牌解析器，具有解析的功能的类 任务简介文本分类的数据集，数据格式如下：$$X = {(x^1 , y^1 ),(x^2,y^2) · · · , (x^N , y^N )}$$其中$ x_i $表示一组文本，$ y_i $可以为一组标签如词性，也可以是一个标签，即文本的类别。本文的最终目标就是希望达到：$$f(x_i) \to y_i$$下面来深入解决这个问题。 向量化在机器学习算法中，样本实例一般是以连续变量或离散变量的形式存在的。因此我们在分类之前，需要将文字转化为特征向量。 词袋模型 一种简单的方法就是认为文本是由字，词组成的无序，多重集合，不考虑语法和词序。这就是在自然语言处理中常用的词袋模型。磁带模型可以看车以词为基本单位的向量空间模型。 N元特征 在实际场景中词序是十分重要的，可能影响句子含义的表达。因此我们需要在特征中保留单词的词序。 N 元特征(N-gram 特征),顾名思义,就是由 N 个字或词组成的字符串,单元可以 是字或词。这里N是大于等于1的任意整数。如果N 为2,就叫做二元特征,如果N为 3,就叫做三元特征以此类推。 以中文句子“机器学习算法”为例,以字为基本单位的二元特征集合为:{机器,器 学,学习,习算,算法}。集合中每一项都是由二个相邻的字组成的的子串,长度为 2。 有了 N 元特征集合,就可以利用词袋模型将文本表示为向量形式。随着 N 的增加, 可以抽取的特征就会越多,特征空间也会呈指数增加。这些高阶的特征出现的频率也会相对较低,对分类不但没有太多帮助,还会直接影响着后续处理的效率与复杂度。因此在一般的文本分类任务中,N 取 3 就足够了,并且同时也使用一元和二元特征,防止出现过拟合。 特征分类经过特征的抽取之后，一个模型就可以认为是k维特征空间上的一个点，需接下来就要寻找一些超平面来对空间进行划分，也就是对文本进行分类。 二分类问题 $$ \hat y =sign((f(z))) = sign(\theta^Tz+\theta_0) $$ sign为符号函数，取判别函数f(z)的正负号，为方便，简写判别函数为 $$ f(z) ＝ \theta^Tz+\theta_0 = \sum_{i=1}^{k}\theta_iz_i + \theta_0 = \sum_{i=0}^{k} = \hat \theta^T \hat z $$ 其中$z_0=1$,$\hat\theta,\hat z$分别称为增广权重向量和增光特征向量。 $$ \hat z = \left( \begin{array} {ccc} 1 z_1 . . z_k \end{array} \right) = \left( \begin{array}{ccc} 1 z \\end{array} \right) $$ $$ \hat \theta = \left( \begin{array} {ccc} \theta_0 \theta_1 . . \theta_k \end{array} \right) = \left( \begin{array}{ccc} \theta_0 \theta \\end{array} \right) $$ 后面的分类器描述中,我们都采用简化的表示方法,并直接用 $θ , z$ 来表示增广权重向量和增广特征向量 多分类问题 对于 C 类分类问题,需要定义 C 个判别函数。但是这种表示一般适用于类别 y 为离散变量的情况。在自然语言处理的很多学习任务,类别 y 可以是更复杂的结构,比如多标签、层次化以及结构化等形式。为了更好的描述这些情况，可采用如下形式： $$ \hat y = \mathop{argmax}_yf(\phi(x,y),\theta)$$ 这里$\phi(x,y)$是包含了样本x和类别y混合信息的特征向量，$\theta=[\theta_1;\theta_2…;\theta_C]$，$\phi(x,y)$ 为特征表示，$f(\phi,\theta)$为模型，一般在文本分类中为线性模型（由于我们可以构建足够复杂的特征表示，在高维空间中总是线性可分的），argmax 为解码过程，即寻求y解的过程，对于分类问题，看得分取高分即可。机器学习要学的参数是$\theta$。 算法实现数据集：https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews 数据集由train.tsv和test.tsv组成，tsv即数列的分隔符是tab，数据的格式如下： 每一行由短语id，句子id，句子，类型四列组成。句子类型分为五类： 0 - negative 1 - somewhat negative 2 - neutral 3 - somewhat positive 4 - positive 数据处理 nltk：一个专门处理英文文本的库 beautifulsoup：构建，解析分析树 nlp数据预处理的流程： bs4等工具去除标签，或手工的方式，去除数据中不需要的内容 拼写错误检查，通常使用 pyenchant工具包 词干提取（stemming），词形还原（lemmatization），这两种方法都是要找到词的原始形式。即对于一些复数，过去式等英文的还原。stemming方法更加激进一些，还原后的词不一定是原词的词干，通常使用nltk工具包 下面是具体的实现，在拿到原始的数据之后，我们需要对数据进行一些处理，处理的代码如下： 12345678910111213141516171819# 下面这个函数用来去除html标签# 去除非文本内容# tokenize句子，即分词# lemmatize句子，即词性还原def clean_sentences(df): reviews = [] for sent in tqdm(df['Phrase']): review_text = BeautifulSoup(sent).get_text() # 去除html review_text = re.sub('[^a-zA-Z]',' ',review_text) # 去除非文本部分 # tokenize the sentences words = word_tokenize(review_text.lower()) # 令牌化 lemma_words = [lemmatizer.lemmatize(i) for i in words] # 词形恢复 reviews.append(lemma_words) return reviews# clear the datatrain_sentences = clean_sentences(train)test_sentences = clean_sentences(test)print(len(train_sentences))print(len(test_sentences)) 上述代码对这个数据集进行统一的处理，将文本中的html部分去掉，非文字部分去掉。将单词还原到原始的拼写方式上，最终将得到一个每个句子都转变为一行单词组成的list中。 标注数据为5个类别，通过keras.utils中的to_categorical方法将target转变为one-hot的形式。 1234# 将标注转变为one-hot格式target = train.Sentiment.valuesy_target = to_categorical(target)num_classes = y_target.shape[1] 使用sklearn对训练集进行划分： 12# split the data into train and valx_train,x_val,y_train,y_val = train_test_split(train_sentences,y_target,test_size = 0.2,stratify=y_target) 划分完训练集和测试集只有，训练集中不同单词的个数可能减少了，我们希望得到一个当前训练集的一个词汇全集，并且记录一下最长的句子的长度。得到词汇全集是为了之后做token以及句子的序列化将会使用到。记录句子的最大长度是为了对句子长度进行对齐的时候们将会使用到。 123456789# 去除重复出现的词，unique_words里头是一个单词的全集unique_words = set()len_max = 0for sent in tqdm(x_train): unique_words.update(sent) if(len_max &lt; len(sent)): len_max = len(sent)print(len(list(unique_words)))print(len_max) 下面利用keras的方法，对句子进行重新的token，这里的目的和最开始做token的目的不同，这里是为了得到句子的序列表示，得到序列表示以及词汇表之后，就可以使用embedding层，对句子进行word2vec变换了。 12345678910111213# 对句子再次进行tokenizer操作tokenizer = Tokenizer(num_words = len(list(unique_words)))tokenizer.fit_on_texts(list(x_train)) # 用数据初始化tokenizer# tokenizer.word_count 返回一个字典，字典的key为词，val为出现的个数# tokenizer.word_index 对词集合中每一个词编号,key为词，val为编号# 将句子中的词替换成词的编号x_train = tokenizer.texts_to_sequences(x_train)x_val = tokenizer.texts_to_sequences(x_val)x_test = tokenizer.texts_to_sequences(test_sentences)# 由于每个句子的长度不一样长，因此需要对齐，通过pad在短的句子开头补上0x_train = sequence.pad_sequences(x_train,maxlen=len_max)x_val = sequence.pad_sequences(x_val,maxlen=len_max)x_test = sequence.pad_sequences(x_test,maxlen=len_max) 最终得到长度一致的一个句子序列化结果，上述代码即完成了所有的数据处理的操作。 网络搭建12345678910111213141516# 设置early stopearly_stopping = EarlyStopping(min_delta=0.001,mode ='max',monitor='val_acc',patience = 2)callback = [early_stopping]# keras搭建模型model = Sequential()# embedding(input_dim(词汇表长度),output_dim(输出的vector的长度)，input_length(输入句子的长度))# 等于输入了词汇表，句子的sequences，然后去学习word2vec的参数，得到表示句子的vector，长度通常设置成128或300model.add(Embedding(len(list(unique_words)),300,input_length=len_max))# embedding 起到word2vec的作用# LSTM return_sequences=true表示输出全序列的输出，False只输出最后一个LSTM的输出model.add(LSTM(128,dropout=0.5,recurrent_dropout=0.5,return_sequences=True))model.add(LSTM(64,dropout=0.5,recurrent_dropout=0.5,return_sequences=False))model.add(Dense(100,activation='relu'))model.add(Dropout(0.5))model.add(Dense(num_classes,activation = 'softmax'))model.compile(loss = 'categorical_crossentropy',optimizer=Adam(lr = 0.005),metrics=['accuracy'])model.summary() 模型结果如下： embedding 层用于skip-gram方法得到词向量，最后一层softmax，使用交叉熵计算误差。 下面开始模型的训练过程： 12# 往模型中加入数据history = model.fit(x_train,y_train,validation_data,(x_val,y_val),epochs=6,batch_size = 256,verbose=1,callbacks=callback) 包含了验证集的验证： 绘制训练结果： 12345678910import matplotlib.pyplot as plt%matplotlib inlineepoch_count = range(1,len(history.history['loss']) + 1)plt.plot(epoch_count,history.history['loss'],'r--')plt.plot(epoch_count,history.history['val_loss'],'b--')plt.legend(['Training loss','validation loss'])plt.xlabel('epoch')plt.ylabel('loss')plt.show() 生成测试集的预测结果，代码结束： 12345# submissiony_pred = model.predict_classes(x_test)sub_file = pd.read_csv(os.path.join(root,'sampleSubmission.csv'),sep=',')sub_file.Sentiment = y_predsub_file.to_csv('submission.csv',index = False) 模型结构看完代码最后来总结一些模型的结构： 通过数据的预处理部分，将文本中句子整理成一个【句子个数，句子最大长度】的一个矩阵，每一个位置上为一个单词。如果句子长度不够长的话，就在句子的前面用0来填充。 随后将每个句子，每个词进行word2vec，即embedding处理。keras.layers.embedding层完成词嵌入的工作。本质是一个全连接层，embedding是一个【总词汇数量，每个词编码长度】的一个权重矩阵，每一行表示一个词的向量，embeding层训练好词向量之后，将这些词向量赋予给句子中的词 每一个句子将得到一个【句子最大长度，词向量长度】的矩阵。 RNN LSTM类似于cv领域的CNN，值得好好琢磨一下（虽然现在transform更加的流行） 传统的RNN如下： 可以看出隐层间的信息传递，$\hat{h}$与h以及x有关，每一个RNN输出的y仅与$\hat{h}$有关，通过softmax进行分类，通过训练网络得出W的参数。RNN与DNN相同，当网络比较深的时候，同样面临梯度消失的问题，当两个词相距比较远的时候，前一个词难以影响到后面的词（但是有时候这种长连接的词能够决定句子的含义）。 LSTM LSTM包含三个数据的输入，C的输入为简单的相乘与相加，因此能够保留较长序列的信息。LSTM之间传递的h信息，有一份来自前一层的信息以及当前LSTM的输入信息。LSTM中间分层三个部分，分别为遗忘门，记忆门，选择输出门。 GRU Gate Recurrent Unit是循环神经网络的一种，和LSTM相似，用来解决长期记忆和反向传播中梯度等问题而提出来的。GRU和LSTM的表现类似，但是GRU的计算复杂度比较小。 即： GRU用一个1-z的方式，用同一个门代替了遗忘门和记忆门的工作，在使用的时候，GRU参数较小，能够使得算法复杂度下降。 总结nlp和cv问题在处理上比起来，一个很大的不同在于数据预处理部分有比较多的工作需要完成。这些工作包括了文本数据的清洗，单词的划分tokenize，对每个句子生成word2vec，然后下面才搭建模型，和cv部分就比较类似了。 我觉得从上面的代码里头可以总结从一份代码，这份代码专门处理文本数据的预处理问题。 本文的代码地址：https://github.com/WenHui-Zhou/NLP_pratice/tree/master/text_classification inferencehttps://www.kaggle.com/chiranjeevbit/movie-review-prediction]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[图像的去噪]]></title>
    <url>%2F2019%2F12%2F02%2F%E5%9B%BE%E5%83%8F%E7%9A%84%E5%8E%BB%E5%99%AA%2F</url>
    <content type="text"><![CDATA[噪声在图像上通常表现为引起较强视觉效果的孤立像素点或像素块。通常噪声信号与要研究的对象不相关，以无用的信息的形式出现，下面的任务就是将噪声部分消去，使其对图像的影响最小。 噪声概述噪声的来源 （1）图像获取过程中 两种常用类型的图像传感器CCD和CMOS采集图像过程中，由于受传感器材料属性、工作环境、电子元器件和电路结构等影响，会引入各种噪声，如电阻引起的热噪声、场效应管的沟道热噪声、光子噪声、暗电流噪声、光响应非均匀性噪声。 （2）图像信号传输过程中 由于传输介质和记录设备等的不完善，数字图像在其传输记录过程中往往会受到多种噪声的污染。另外，在图像处理的某些环节当输入的对象并不如预想时也会在结果图像中引入噪声。 噪声类型 图像中常见的噪声基本上有四种： 高斯噪声 泊松噪声 乘性噪声 椒盐噪声（真没写错） 噪声的图像由原图，一直到椒盐噪声，从上到下： 传统去噪方法传统的去噪算法分为空间域法和变换域法： 空间域去噪方法的思想就是在原图像上对图像灰度值进行处理，通常采取“平均”或“平滑”的方法，将突变的噪声分量分散到周围像素中去，使图像变得较为平滑，降低噪声的影响。常用的空间域去噪方法有：均值去噪法，中值去噪法，高斯去噪法、维纳滤波去噪法等。 变换域去噪方法的思想是将原图像进行相关的变换，将图像信息变换到变换域中,再通过一定的方法来对图像信息进行处理，之后再通过反变换恢复图像信息，以达到图像去噪的目的。常用的变换域去噪方法有：傅里叶变换去噪方法，小波变换去噪方法等。 常用去噪算法 均值滤波去噪 中值滤波去噪 高斯滤波去噪 傅里叶变换去噪 下面介绍深度学习在图像去噪上的一篇最新的论文：Noise2Noise: Learning Image Restoration without Clean Data ICML 2018 Noise2Noise: Learning Image Restoration without Clean Data概述 这篇文章的主要亮点在于训练网络的时候不需要提供清晰的图像，。作者将另一个不清晰的图像作为GT进行网络的训练，最终也能够得到较好的结果。 理论依据 先看一种简单的情况，假设我们对某个物理量（如房间的温度）多次测量，得到一系列不可靠的测量值（y1,y2,…)一种估计真实值的通用方法是找到一个数z，使其与这些测量值有最小的平均偏差，即优化下面损失函数：$$argminz𝔼y{L(z,y)}\arg\min_z \mathbb{E}_y{L(z,y)}$$对于L2 损失$L(z,y)=(z-y)^2$ ，该损失函数的最优解在测量值的算数平均值(期望)处取到：$$z=\mathbb{E}_y{y}$$对于L1,损失$L(z,y)=|z-y|$，该损失函数的最优解在测量值的中值处取到：$$z=median{y}$$对于L0损失 ,$L(z,y)=|z-y|_0$ ，该损失函数的最优解近似在测量值的众数处取到：$$z=mode{y}$$从统计学角度，这些通用的损失函数都可以解释为似然函数的负对数，而对这些损失函数的优化过程可以看做为最大似然估计。训练神经网络回归器是这种点估计过程的推广。已知一系列输入-目标对$(x_i,y_i)$，典型的网络训练形式是优化下列目标函数：$$\arg\min_\theta\mathbb{E}_{(x,y)}{L(f_θ(x),y)}$$通过调节参数theta，使得x与y之间的误差最小。事实上，使用上面的Loss，结果和GT不是一一对应的关系，而是一个多值映射的关系，网络学习到所有的输出结果的平均值。 这意味着对于L2 loss来说，我们在目标图像上加上一个均值为0的随机噪声，例如高斯噪声，泊松噪声等，根据上面的方程，在目标上加上一个均值为0的噪声对方程的结果没有影响（均值为0的噪声期望为0），因此：可以通过含有噪声的图像最为训练数据，GT为在目标上加上均值为0而生成的噪声数据，这样训练的结果和直接使用干净的GT的结果理论上来说是相同的，实验结果表情，精度仅仅相差了一点点。 应用场景 看这个文章的时候我一直很疑惑，实验假定了存在一个含有随机噪声的图像，以及一张和它对应的，在干净的图像上加上均值为0的某个噪声分布的图像作为label，在这个基础上进行训练，得到的训练结果和clear图像的训练结果十分相似。疑惑的点在于，我认为这种假设现实生活中是难以满足的，事实上，作者在做实验的时候，也是在GT上加了均值为0的噪声来做实验的。 但是也有一些人说这个方法可能可以用在一些特定的领域，例如医疗MRT图像，难以获得清晰的图像版本，但是可以通过多次观测得到多个含噪声的医疗MRT图像，利用这些成对的含噪声的图像进行去噪处理。但是从实验角度出发，噪声的分布并不满足均值为0，因为效果可能还是不好。 实验 作者分别做了Guassian Noise，possion noise，monte Carlo rendering，MRT图像上的实验。实验结果表明，在加上均值为0的噪声后，同样能够得到去噪后的结果。 inference 传统去噪算法： https://www.voidking.com/dev-gp-image-denoise/]]></content>
      <categories>
        <category>3D重建</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP模型finetune:GPT到Bert（三）]]></title>
    <url>%2F2019%2F12%2F01%2FNLP%E6%A8%A1%E5%9E%8Bfinetune-GPT%E5%88%B0Bert%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[NLP模型的预训练方式有ELMO的方式，基于特征的融合，通过学习句子的上下文语境来判断句子中多义词的含义，解决多义词歧义的问题，从而提升模型的性能。 另一种更类似于图像领域的预训练方式为fine tuning模式，该模式有一个代表，即GPT网络。 word embedding to GPTGPT的网络结果如下： GPT是Generative Pre-Training的简称，模型分为两个部分，第一个阶段利用语言模型进行预训练，第二个阶段利用fine tune解决下游的任务。上图的预训练过程与ELMO类似，也是分为两个阶段，下面回顾一下ELMO： ELMO利用语言模型得到一个不可区分多义词的word embedding，然后通过下游任务来微调这个word embedding使得其适应具体的语境。 GPT与ELMO的区别有两个： GPT使用transformer结果替代ELMO中的LSTM GPT采用单向的语言模型，GPT仅利用到语言的上文信息，而ELMO则是双向模型（可以算一个 缺点） 使用GPT预训练参数GPT利用语言模型就是预训练之后，对不同的下游任务，设计网络结构，这个结构朝GPT看齐。这样在下游任务中，利用GPT的参数去初始化下游模型，然后根据具体数据来对网络 进行 fine tune，这个过程和cv领域的预训练模型一模一样。 接下来的 问题就转变为，如果将一个下有任务改造成类似GPT的 结构。 对于常见的任务，GPT的改造 如下： 对于GPT来说，一个值得改进的地方是他使用的单向的语言模型，因此在这之后，Bert就填补了这个遗憾。 Bert bert借鉴了GPT中使用的transformer以及ELMO中使用的双向语言模型。使用过程同样分为两步，第一步训练双向语言模型进行参数的预训练。第二步根据具体的下游任务，改造为bert结构。 Bert的演化过程如下： transformer在做双向的时候，采用的是CBOW的方法，即将当前要预测的词扣掉，利用这个词的上下文来预测，具体做法 如下： Masked双向语言模型：随机选择语料中15%的单词，把它抠掉，也就是用[Mask]掩码代替原始单词，然后要求模型去正确预测被抠掉的单词。但是这里有个问题：训练过程大量看到[mask]标记，但是真正后面用的时候是不会有这个标记的，这会引导模型认为输出是针对[mask]这个标记的，但是实际使用又见不到这个标记，这自然会有问题。为了避免这个问题，Bert改造了一下，15%的被上天选中要执行[mask]替身这项光荣任务的单词中，只有80%真正被替换成[mask]标记，10%被狸猫换太子随机替换成另外一个单词，10%情况这个单词还待在原地不做改动。这就是Masked双向语音模型的具体做法。 Bert在NLP的各大任务中均大方异彩，出现了一统江湖的趋势，成为NLP领域内的一个标杆工作。]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP之transformer（二）]]></title>
    <url>%2F2019%2F11%2F29%2FNLP%E4%B9%8Btransformer%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[NLP任务的输入往往是一句话或者是一篇文章，他有几个特点： 输入是一个一维线性序列 输入是不定长的 输入单词的相对位置非常的重要 句子中的长特征对理解句子非常的重要（距离很远的词） 一个合格的特征抽取器应当很好的适配领域问题的特点，能够充分抽取数据中的特征。 NLP领域主要任务该部分在上一篇文章中有简要提到，下面详细记录一下这些任务主要解决的问题： 序列标注：这是NLP典型的任务，包括中文分词，词性标注，命名实体识别等等。 特点：模型根据上下文给每个单词分配一个类别 分类任务：常见有的文本分类和情感计算 特点：不论文章多长，总体给出一个分类类别 句子关系判断：问答系统，语义改写，自然语言推理 特点：给出两个句子，判断这两个句子是否具有某种语义关系 生成式任务：机器翻译，文本摘要，写诗造句，看图说话 特点：输入文本后，需要自主生成另一段文字 从模型的角度来看，模型的特征抽取能力是至关重要的，下面开始详细介绍NLP的三个抽取器。 久经沙场RNNRNN引入NLP之后，一直是一个明星模型，在各种模型中被广泛的应用。它采用线性序列结构不断从前往后收集输入信息。但是这种结构在反向传播过程中存在优化的困难。因为反向传播路径过长，导致严重的梯度消失或爆炸问题。于是很快建LSTM引入RNN作为标准模型中。 下面是非常典型的使用RNN来解决NLP任务的基本框架： RNN本身结构就是个可以接纳不定长输入的由前向后进行信息线性传导的网络结构，而在LSTM引入三个门后，对于捕获长距离特征也是非常有效的。所以RNN特别适合NLP这种线形序列应用场景，这是RNN在NLP界如此流行的根本原因。 但是对于RNN来说，来自一些新型的特征提取器的挑战，以及RNN并行能力差的问题，导致了它很可能被替代。 RNN并性能力差的原因：RNNT时刻有两个输入，一个输入为当前的文本，另一个输入为T-1时刻隐藏层的输出S(T-1)，这是最能体现RNN的一点，RNN的历史信息就是通过这个传输渠道向后传的。因此T时刻计算依赖于T-1时刻的结果，因此网络必须按照时序的顺序一个一个往后走。 而CNN与transformers不存在这种问题，他们是天生的并行计算结构。 RNN在并行化上也做了一些工作，通常的做法有打断隐层的连接，或者打断部分的连接，层间并行。 改造CNN2014年CNN最早被引入NLP中： 每一行为一个单词的数值编码，卷积层将数值编码分割，在编码维度上移动，得到卷积后的特征，但仅仅在句子分类的任务上性能不错。 但是单个卷积层难以捕获远距离的特征，因此解决的方案有把卷积层做深；使用dilated 孔洞卷积。CNN能够捕获向量的位置信息，但是pooling结构通过会破坏掉这种顺序，因此通常使用全连接层替换掉pooling结构。 目前使用的比较多的CNN如下： 上图是现代CNN的主体结构，通常由1-D的卷积层来叠加深度，使用skip-connection来辅助优化，也可以使用dilated等手段。CNN在nlp中的引入，能够保持数据间的时序信息，要设法将CNN的深度做起来。 transformer结构Transformer模型有很多好处，它改进了RNN最被人诟病的训练慢的缺点，利用self-attention机制实现快速并行。且Transformer可以增加到非常深的深度，充分发掘DNN模型的特性。下面具体的讲解一下transformer的机制。 下面通过引入一个NLP中经典问题的方式来解释这个结构： 我们打算将英语翻译为西班牙语： X = [‘Hello’, ‘,’, ‘how’, ‘are’, ‘you’, ‘?’] (Input sequence)Y = [‘Hola’, ‘,’, ‘como’, ‘estas’, ‘?’] (Target sequence) transformer中encoder部分负责提取句子信息，decoder部分负责将encoder的输出与target相结合，得到接近target的翻译结果。 transformertransformer结构是一个由encoder，decoder，ski-connection，layerNorm，FF共同作用的一个结构，在数据特征提取上有着明显的优势。 编码和解码的部分分别都由六个编码器组件组合而成： 将encoder与decoder模块展开来看： encoder部分由一个自注意力层和一个前向网络构成，其中自注意力层关注句子中的每一个单词对当前编码单词的关系。 decoder部分由三层构成，其中中间那一层，用来关注句子中的相关部分（和seq2seq类似）。 decoder模块decoder模块是对nlp数据提取特征的模块，将每一个编码器单元展开如下： 数据流动 将单词转化成词向量（词向量的长度固定，BERT中为512），输入的维度：句子长度*词向量长度 生成一个句子长度*词向量长度的位置编码信息，添加到输入中 输入数据经过N个encoder单元，生成句子长度*词向量长度大小的向量 第一步对句子进行分词，将单词转化为词向量： 当我们训练一个batch的数据的时候，我们需要对一些较短的句子进行补充，通过在句首添加padding的方式，将句子长度对齐。 [“”, “”, “”, “Hello”, “, “, “how”, “are”, “you”, “?”] → [5, 5, 5, 34, 90, 15, 684, 55, 193] 第二步，对位置信息进行编码，然后将位置信息加入到输入当中，对位置信息进行编码采用以下的公式： 其中i表示y方向即每一个单词，j表示在词向量的长度（emb-dim）上的位置，因此最终得到下面的结果： 将输入与上面的位置编码相加，得到最终的输入数据。 encoder block 接下来进入encoder内部，编码器内部采用一层的自注意力层以及一个前向的全连接层。将数据输入编码器，首先遇到的是 multi-head attention结构。 multi-head attention结构共同训练h次注意力层，这种做法能够扩展专注于不同位置的能力，同时给出了注意力层的多个表示子空间。 对于每一个head来说，我们训练三个向量，Q，K，V，与输入embedding向量相乘得到中间结果，用于最后计算每一个词最终的得分： 将上面的运算合并为矩阵运算，则算法如下： 利用上面的结果计算每个单词的得分：$$\begin{equation}\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\end{equation}$$ 对于multi-head来说，我们将X输入h个head中，将会得到h个句子不同词之间的得分Z: 对于一个句子来说，我们只希望得到一组表示词语间的相互关系，于是我们将Z拼接起来，通过训练一个权重$W^0$使得最终得到一个 句子长度*词向量长度。 通过融合注意力机制的多头的结果，每个词与句子的其他成分之间的关系得到了充分的挖掘： 当我们计算出句子单词之间的注意力分布，下一步为添加残差后归一化： 完成残差之后是一个正向的全连接层（Free Forward），即一个两层的全连接层，第一层的激活函数为ReLU，第二层的激活函数为线性激活函数：$$\begin{equation}\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}\end{equation}$$其中W1位第一层，W2为第二层，max函数表示ReLU激活函数，b2为线性激活函数的偏移。最终的输出添加残差，归一化之后得到一个decoder的输出，随后将这个输出输入下一个decoder模块中，直到所有的模块都完成输出，将输出传至decoder模块。 DecoderDecoder部分网络结构相比较于decoder部分，多出了一个encoder to decoder的模块，这个模块的的输入来自于decoder的输出： encoder和decoder中信息传播如下： 每一个decoder模块都将接受encoder的输出。Decoder的一个单元具体结构如下： 数据流动 首先将target进行分词，编码成词向量，维度为 target句子长度*词向量长度 将第一步得到的数据输入N个Decoder模块中，在每次迭代过程中，接收decoder的输出作为一个额外的输入，最终得到的输出维度为 target句子长度*词向量的长度 将decoder得到的输出，输入到一个全连接层，并且每一层做一个逐行的softmax，最终得到的输出是翻译的结果，即维度为句子长度*每个单词的长度 输入 由于input的句子长度和target的句子的长度不一致，因此首先对target句子分词后，进行偏移： [“Hola”, “, “, “como”, “estás”, “?”]→[“”, “Hola”, “, “, “como”, “estás”, “?”] train vs test train阶段和test阶段对于decoder部分来说有一个重要的差别： 在test阶段，我们不知道groundTruth，因此我们将会根据之前给出的单词来预测当前位置的单词，即无法使用当前位置之后的单词的信息。 在train阶段，我们知道GT，我们会直接告诉模型我们的target是什么，然后根据和test一样的顺序进行预测，但是这将会出现一个问题，模型可能根据target句子本身的位置关系来预测target，也就是使用了target的信息，这是不允许的，因为在实际情况中我们不可能提前知道target，因此这样的训练是不充分的。 因此我们在Decoder的训练阶段必须消除target提供当前词之后的词所提供的信息。例如下面例子，当要预测estás的时候，我们就只能使用绿色部分所使用的信息，而红色部分的信息不能使用： 为了解决上面这个问题，我们提出了mask multi-head attention，即对output的数据进行处理。 mask multi-head attention 首先通过与encoder相同的操作，即multi-head attention得到一个 target句子长度*词向量的一个输出矩阵，然后进行mask操作，即将矩阵右上角的数值置为负无穷。 原始multi head结果： mask后的结果： 这就意味着当前单词的预测无法使用其后出现的单词信息。 Encoder to decoder 将上述的输出添加输入以及归一化之后，输入到下一层encoder to decoder，这一部分接受的输入由两部分组成，第一部分就是decoder的第一阶段的输出，另一个部分就是encoder最终的输出。 与decoder同样的操作，我们训练三个向量，Q，K，V，与输入embedding向量相乘得到中间结果，用于最后计算每一个词最终的得分，唯一的不同在于这三个向量使用的训练数据不同，如下图： 即Q向量由decoder第一阶段的数据来训练，K，V由encoder最后输出的数据来训练。 同样的利用与encoder相同的attention公式计算每一个词与句子中其他的成分的关系：$$\begin{equation}\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\end{equation}$$接下来与encoder相同，训练h个head，然后组合在一起通过一个$W^0$矩阵进行组成得到输出，最后传入decoder模块的第三阶段，即全连接层进行前向的传播。 linear and softmax 重复上面decoder的基础模块N次，最后得到的输出的维度为 target句子长度*词向量长度，然后将这个向量输入一个linear全连接层中，全连接层输出的维度为翻译后句子的真实长度，其实际含义在对每一个词赋予一个权重：$$\begin{equation}x W_{1}\end{equation}$$最后，将上面的输出输入到softmax当中，计算出当前位置上，所有可能出现的翻译的结果的概率，然后根据最大的概率得到模型预测的翻译的结果： 根据第一行的结果，我们可以判断，ss对应的翻译是hello。 最后放一张encoder和decoder的合照，以便于回顾transformer的各种细节： 最最最后小彩蛋： inference https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f https://jalammar.github.io/illustrated-transformer/ https://zhuanlan.zhihu.com/p/54356280 https://zhuanlan.zhihu.com/p/54743941 https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP之Word2Vec（一）]]></title>
    <url>%2F2019%2F11%2F29%2FNLP%E4%B9%8BWord2Vec%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[NLP领域有着四个比较大的方向： 文本分类 序列标注 文本匹配 文本生成 在NLP里头，最细粒度的就是 词语，由词语组成句子，由句子组成文章继而表达一些语言层面上的含义。因此本文从NLP的根源问题 词语表达 开始讲起，即word2vec，NLP领域重要的预训练方法。 word2vec考古史Word2vec最早出现是以一个副产品的身份出现的。它是在实现语言模型过程中出现的一个惊喜的意外。简而言之，就是在做实现语言模型的过程中，我们得到了词语的数值表达，这也就是word2vec的精髓。 词语是人类对语言在符号上的抽象总结，通过word2vec，将符号语言转化为数值表达，方便计算机寻找语言背后的抽象逻辑。 语言模型 生成word2vec的语言模型是个什么东西呢？如下图： 语言模型就是量化的衡量哪一个句子更像是人说的，核心函数p的思想是说，通过一系列的前导词，预测出后面跟着哪一个词的概率最大。 数据的输入问题，第一步是将每个词用一个向量来唯一表示（one-hot），然后才可能对这个向量进行编码，得到具有语言意义的一个向量（word2vec）。 one-hot的实现过程为建立一个长度为V的表，假设这个V表示世界上所有词语的词语。当我们对出现的一个词语进行编码的时候，只需要将这个词语出现的位置置为1，其他为0，即得到了这个词语的唯一表达（one-hot形式）。 语言网络的设计，加入你设计出了如下的结构： 这就是大名鼎鼎的神经网络语言模型，由Bengio 2003发表在JMLR上，2013年深度学习升温后，才慢慢进入了神坛。 他的核心思想即是最大似然估计的思想：$$\begin{equation}\left.P\left(W_{t}=\operatorname{‘Bert’} | W_{1}, W_{2}, \ldots W_{(} t-1\right) ; \theta\right)\end{equation}$$即如果当前位置出现了’Bert‘，要求网络预测前t-1的参数，使得当前出现Bert的概率最大。网络的输入，我们最初说使用one-hot的形式，但是为了另其具有语言的含义，我们在将词语输入网络之前，使用矩阵Q进行语义上的转换。从而得到词语的word embedding表达。 矩阵Q就是所谓的word2vec的转换矩阵，它包含V行，每一行表示一个单词的vector值，有一点值得注意的是，Q矩阵一开始是用随机值进行初始化的，矩阵Q参与网络的训练，当网络训练好之后，矩阵Q就被正确赋值了。 word2vec有两种训练方式： CBOW：从一个句子中将一个词抠掉，用这个词的上下文去预测这个词。 skip-gram：用一个词去预测这个词的上下文。 ELMO克服word2vec的多义词缺陷word2vec对下游的nlp任务有一些帮助，但是帮助却不是那么大。一个比较严重的问题在于多义词的问题，例如bank这个单词，可以指银行也可以指河床，但是在矩阵Q中，这个单词只有一种特征的编码。 如何解决这个问题呢，ELMO模型提出了一种想法，利用上下文场景来确定多义词的语义。 ELMO的本质思想是：事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分。在下游任务中，实际使用Word Embedding的时候，单词已经具备了特定的上下文，这个时候可以根据上下文单词的语义去调整单词的Word Embedding表示，经过调整后的Word Embedding更能表达在这个上下文中的具体含义，即确定了多义词的具体语义。 ELMO采用典型的两阶段： 第一个阶段利用语言模型进行word embedding的预训练 第二个阶段是提取对应单词网络各层的word embedding作为新特征，补充到下游任务中 上图是第一阶段的预训练过程，网络结构采用双层的word embedding作为新特征补充到任务中。网络结构采用双层的LSTM，左端正向表示正向的编码器。右边逆向，表示逆向的编码器。从两个方向来预测扣掉的那一个词。 使用这个网路，每次输入一个句子网络将会输出三个向量，分别是 单词特征，句法特征，语义特征。 这三个特征如何使用呢，在下游的任务中，我们给每一个vector一个权重，然后将三个特征相加，整合成一个特征输入下游的任务中。这个权重需要通过网络的学习得到。EMLO效果相比较于传统的word2vec性能上得到了比较明显的提升。 ELMO有什么缺点呢： LSTM抽取特征的能力远弱于transformer 拼接方式双向融合特征，融合能力偏弱 接下来，我将在另外的文章中介绍transformer。 inferencehttps://zhuanlan.zhihu.com/p/49271699]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(九)杂项讨论]]></title>
    <url>%2F2019%2F11%2F26%2Feffective-cpp-%E4%B9%9D-%E6%9D%82%E9%A1%B9%E8%AE%A8%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[2019/11/26 effective cpp 第九章 杂项讨论 这是这本书的最后一章，今晚应该就能够阅读完！在开始阅读之前，我想感慨一下，最后的几章难度太大，一知半解的看下来，我想原因是相关张章节的实践不多导致的，因此日后有需要要回来重新阅读它们，时间很快大概花了一个月的空闲时间来阅读这本书，收获满满！ 这一章主要说了三个问题：编译器的警告要重视；C++标准库的一个总览；boost一个泛用性C++库的总览。 53 条款：不要轻视编译器的警告 54 条款：让自己熟悉包括TR1在内的标准程序库 55 条款：让自己熟悉Boost 53 条款：不要轻视编译器的警告编译器作者在触发一个warning的时候，他比你更加明白将来会发生什么严重的错误，因此我们需要在对待编译器警告的时候更加的小心。 当出现一个编译器warning的时候，我们应该需要知道它的意图以及真正的意义。 总结 严肃对待编译器发出的警告，争取无警告荣誉 不要过度依赖编译器的报警功能，因为不同的编译器对待事情的反应是不同的 54 条款：让自己熟悉包括TR1在内的标准程序库C++standard定义了C++语言及其标准程序库的规范，里头包含以下： STL 标准模板库 Iostream 国际化支持 数值处理 C89标准程序库 异常阶层体系 此外C++的新特性被记录在TR1的文档内，在下一次更新将会加入到标准库中。 总结 C++标准库的主要机能由STL，iostreams，locates组成。并包含C99标准程序库。 TR1添加了智能指针，一般化函数指针，hash-based容器，正则表达式以及另外10个组件的支持 TR1自身只是一份规范。 55 条款：让自己熟悉Boost如果你在找一个高质量，源码开放，平台独立，编译器独立的程序库，那么Boost是一个很好地选择。他的网址是：http://boost.org。 总结 Boost是一个社群，也是一个网站，致力于免费，源码开放，同僚复审的C++程序库开发。Boost在C++标准化过程中扮演深居影响力的角色。 Boost提供许多TR1组件实现品，以及其他许多程序库。 最后告诫一下自己，熟悉STL，在开始用C++写一个东西之前，应当要过一遍这9篇博客！]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(八)定制new和delete]]></title>
    <url>%2F2019%2F11%2F25%2Feffective-cpp-%E5%85%AB-%E5%AE%9A%E5%88%B6new%E5%92%8Cdelete%2F</url>
    <content type="text"><![CDATA[2019/11/25 effective cpp 第8章 定制new和delete C++在内存管理，垃圾回收机制上常常受到人们的讨论。下面这一章将讨论C++的内存管理例程。 49 条款：了解new-handler的行为 50 条款：了解new和delete的合理替换时机 51 条款：编写new和delete时需固守常规 52 条款：写了placement new也要写placement delete 49 条款：了解new-handler的行为当operator new无法满足某一内存分配的需求时，它将会抛出异常。当operator new发生异常，它会先调用一个客户指定的错误处理函数，即new-handler函数。为了指定这个用以处理内存不足的函数，客户必须调用set_new_handler，那是声明与&lt;new&gt;的一个标准程序库函数。 1234namespace std&#123; typedef void (*new_handler)(); new_handler set_new_handler(new_handler p) throw();&#125; 从上面可以看出来new_handler是一个typedef。定义出一个指向函数的指针，该函数没有返回任何东西，set_new_handler则是接受一个指针，返回一个指针，并且不允许抛出任何的异常。 Set_new_handler的使用方式如下： 12345678910void outOfMem()&#123; std::cerr &lt;&lt; "unable doing something"; std::abort;&#125;int main()&#123; std::set_new_handler(outOfMem); int* pBig = new int[12323232333333]; // 当new无法分配这么多空间的时候，将会去调用outOfMem报错。&#125; 在实现new-handler的时候，有几点注意： 让更多的内存可被使用，一个做法是程序开始执行的时候就分配了一大块内存，当调用handler的时候，释放给程序使用 安装另一个new-handler，如果目前这个new-handler无法处理这个异常，它可以通过调用其他的handler来分配内存。 卸除new-handler，就是讲null指针传给set_new_handler，一旦没有安装任何new-handler，operator new会在内存分配不成功时抛出异常。 跑出bad_alloc异常，这样的异常不会被operator new捕获，因此会被传播到内存索求处。 不返回，通常调用abort，exit来中断程序。 总结 set_new_handler允许客户指定一个函数，在内存分配无法获得满足时被调用 Nothrow new是一个颇为局限的工具，因为它只适用于内存分配，后续的构造函数调用还是可能抛出异常。 50 条款：了解new和delete的合理替换时机通常我们选择替换new和delete会出于几个原因： 用于检测运用上的错误 为了强化效能 为了收集使用上的统计数据 此外，在了解何时可在 全局性或 class专属的基础上合理替换缺省的new和delete： 为了检测运用上的错误 为了手机动态分配内存之使用统计信息 为了增加分配和归还的速度 为了降低缺省内存管理器带来的空间额外开销 为了弥补缺省分配器中的非最佳齐位 为了将相关对象成簇集中 为了获得非传统的行为 总结 有许多理由需要写个自定义的new和delete，包括改善效能，对heap运用错误进行调试，收集heap使用信息。 51 条款：编写new和delete时需固守常规让我们从实现operator new开始，实现一致性operator new必须返回正确的值，内存不足的时候必须调用new-handling函数，必须有对付零内存需求的准备，还需避免不慎掩盖正常形式的new。 operator new其实比较单纯，如果能够申请到空间，就返回正确的值，如果申请不到空间就返回一个bad-alloc。但是他也有不单纯的一面，因为operator不止一次的申请内存，如果new-handling有能力做一些操作释放内存出来，因此只有在new-handling返回null的时候才会抛出错误。 如果你打算控制operator new[]的行为，你唯一要做的事情就是分配一块未加工的内存。因为你无法知道array中将会保存什么东西。 对于operator delete来说，我们要确保的是 删除null指针永远安全。 总结 operator new应该内含一个无穷循环，并在其中尝试分配内存，如果它无法满足内存的需求，就调用new-handler。它应该也有能力处理0byte申请。class 专属版本则应该处理 比正确大小更大的错误。 operator delete应该受到null指针时不做任何事，class专属版本则还应该处理 比正确大小更大的申请。 52 条款：写了placement new也要写placement deleteplacement new和placement delete应当也成对的出现。 1widget* pw = new widget; 当我们通过上面的代码的时候，实际上做了两件事情，第一件是new，第二件是调用了widget的default构造函数。如果在第二种情况下发生了异常，new成功执行。这种情况下我们要去释放new所申请的空间，但是我们手上并没有申请得到的指针，因此释放内存的重任就交给了C++。 如果当前面对的是拥有正常签名的new和delete函数，那么系统在运行期间就会主动去调用相应的delete函数。 但是如果我们使用的new是我们修改过的，带有附加参数的new，这时候我们需要制定一个与之对应的delete函数。 此外，由于成员函数名称将会覆盖其外围作用域的相同名称，你必须小心避免掉这种覆盖。一个简单的做法就是建立一个base class，内含所有正常形式的new和delete，凡是想以自定形式扩充标准形式的客户，可利用继承机制及using声明式来取得标准形式。 总结 当你写一个placement operator new。请确定也写出对应了placement operator delete函数，如果没有这样做的话，你的程序可能会发生隐微而断续的内存泄漏。 当你声明placement new和placement delete，请确定不要无意识地掩盖了他们的正常版本。 一知半解。。。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(七) 模板与范型编程]]></title>
    <url>%2F2019%2F11%2F19%2Feffective-cpp-%E4%B8%83-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E8%8C%83%E5%9E%8B%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[2019/11/19 effective cpp 第七章 模板与范型编程 C++ template最初是为了让我们建立类型安全的容器，如vector，list，map等等，后来随着越来越多的人用上模板之后，人们发现，template这种代码与其处理对象类型分离，彼此独立的风格很好，于是人们道出了模板元编程，template的作用越来越大。 本章主要解决在使用template上遇到的一些可以避免，优化的问题。 41 条款：了解隐式接口和编译期多态 42 条款：了解typename的双重含义 43 条款：学习处理模板化基类内的名称 44 条款：将与参数无关的代码抽离template 45 条款：运用成员函数模板接受所有兼容类型 46 条款：需要类型转换时请为模板定义非成员函数 47 条款：请使用traits classes表现类型信息 48 条款：认识template元编程 41 条款：了解隐式接口和编译期多态面向对象编程总是以显式的接口和运行期多态来解决问题，它具有两个特点： 必须在子类总的各种方法，且他的代码在源码中是明确可见的。 由于widget的某些成员函数是virtual，w对于那些函数的调用将表现出运行期间的多态，根据运行期间w的动态类型来决定调用哪一个函数。 在template的泛型编程中，我们将函数转变为函数模板： 12345678template&lt;typename T&gt;void doProcessing(T&amp; w)&#123; if (w.size() &gt; 10 &amp;&amp; w!= someWidget)&#123; T temp(w); temp.normalize(); ... &#125;&#125; 从上面的代码，我们可以认为T这种类型应该具有size(),normalize()这些函数，允许进行大小的比较。但是实际上，对于模板类来说，他不一定必须要具备这些，这就是和显示接口的一个重大的不同。 对于显式接口来说，他由函数的签名式构成，即包含函数的名称，参数类型，返回类型。 123456class widget&#123; widget(); virtual ~widget(); virtual void normalize(); ...&#125; 对于隐式接口来说，他并不是基于函数签名式，而是由有效表达式组成的，如上的第一份代码。 由于操作符允许重载，因此在实现上述接口的时候，类型T不必要满足支持size成员函数，operation成员函数等。对于size()可由他的父类来提供。对于operator&gt;来说，只要存在一个隐式转换就能够进行类型的转换，将操作符两边的对象转换为同一种对象即可。 总结 classes和templates都支持接口和多态 对class而言，接口式显式的，以函数签名为中心，多态则是通过virtual函数发生于运行期。 对template参数而言，接口式隐式的，基于有效表达式。多态则是通过template具现化和函数重载解析与编译期的。 42 条款：了解typename的双重含义在template的声明式中，class和typename没有不同。 12template&lt;class T&gt; class widget;template&lt;typename T&gt; class widget; 当我们在声明参数的时候，上面的两种表达方式完全相同。 在template中，我们存在着两种类型的变量。 从属名称：template内部出现名称依赖于某个template参数。如果存在嵌套的话，则称为嵌套从属名称，如C::iterator，类型C的从属名称。 非从属名称：对于类似于int那种名称，不依赖于template。 对于从属名称来说，typename有时候表示为一种类型，而有时候则是一个成员白能量，例如： 1234template&lt;typename T&gt;void func(const C&amp; container)&#123; C::const_iterator*x;&#125; 当上式C::const_iterator表示一个变量的时候，上面变成一个乘法的表达式，如果他是一个类型的话，那就表示声明了一个local的指针。 C++是如何区分这种情况的呢，C++在默认的情况下，处理从属关系的时候优先认为这是一个变量，而不是一个类型，除非你告诉编译器。 显式告诉编译器这是个类型的方式是通过typename来实现的： 1234template&lt;typename C&gt;void func(const C&amp; container)&#123; typename C::cosnt_iterator iter(container.begin());&#125; typename只被用来确定嵌套从属类型的名称，在其他地方不要去使用它。 123template&lt;typename C&gt;void f(const C&amp; container, // 一定不要使用typename typename C::iterator iter); // 一定要使用typename 此外，在typename在一个特殊的例子中是不允许使用的，就是 base class list 以及mem init list即父类列表，以及成员初始化的初始化列表中不允许使用。 当我们在使用嵌套类型的时候，有时候类型名非常的长，我们希望通过typedef来给他重命名，可以将typedef typename一起连用： 1typedef typename std::iterator_traits&lt;iterT&gt;::value_type value_type; 总结 声明template参数时，前缀关键字class和typename可互换。 请使用关键字typename标识嵌套从属类型的名称，但不得在base class lists或mem init list以他作为base class修饰符。 43 条款：学习处理模板化基类内的名称template的继承和显式的继承有些不同之处： 123456789template&lt;typename company&gt;class Loggin:public MsgSender&lt;company&gt;&#123; public: void sendClearMSG(const MsgSender&lt;Company&gt;)&#123; // do something sendClear(info); // 调用父类中的sendClear函数 // do something &#125;&#125; 上面的代码如果实在class的继承中，一定是成立的，但是template继承中则会出错，因为在继承MsgSender&lt;company&gt;的时候，编译器并不知道这是个什么样的class，也就自然不知道这个class中是否有一个sendClear函数了，因此上面的调用将会出错。 解决方法： 在base class函数调用动作之前加上this-&gt; 123456789template&lt;typename company&gt;class Loggin:public MsgSender&lt;company&gt;&#123; public: void sendClearMSG(const MsgSender&lt;Company&gt;)&#123; // do something this-&gt;sendClear(info); // 调用父类中的sendClear函数 // do something &#125;&#125; 使用using声明式，是的父类的方法能够在子类中可见 12345678910template&lt;typename company&gt;class Loggin:public MsgSender&lt;company&gt;&#123; public: void sendClearMSG(const MsgSender&lt;Company&gt;)&#123; // do something using MsgSender&lt;company&gt;::sendClear; sendClear(info); // 调用父类中的sendClear函数 // do something &#125;&#125; 明确指出函数在base class内 123456789template&lt;typename company&gt;class Loggin:public MsgSender&lt;company&gt;&#123; public: void sendClearMSG(const MsgSender&lt;Company&gt;)&#123; // do something MsgSender::sendClear(info); // 调用父类中的sendClear函数 // do something &#125;&#125; 在template继承的时候，子类对父类的方法一无所知，因此我们需要通过this，或者明确指出父类方法的方式得到函数的声明。 总结 可在derived class templates内通过this-&gt;指涉base class template内的成员名称，或由一个明白写出的base class资格的修饰符，使用using 或直接由类调用。 44 条款：将与参数无关的代码抽离templatetemplate是一个节约时间与避免代码重复的一个方法。但是有时候我们可能会导致代码膨胀。 一些指针，vector，list等等，位于父类函数中，将会造成代码的膨胀。 总结 template生成多个class和多个参数，所以任何template代码都不该与某个造成膨胀的template参数产生相依的关系。 因非类型末班参数而造成的代码膨胀，往往可以消除，做法是用函数参数或class成员变量替代template参数 因类型参数而造成的代码膨胀往往可以降低，做法是让带有完全相同的二进制表述的具现类型共享实现码。 45 条款：运用成员函数模板接受所有兼容类型智能指针是行为上像是一个指针的对象，它提供了指针的所有机能，在STL容器中，我们总是使用智能指针。此外指针的另一很好的优点在于支持隐式转换，即子类指针可以隐式的转换为父类指针。但是这种关系在template类模板中是不存在的。 用具有base-derived关系的对象去具现化某个template的时候，产生出来的的具现体并不具有base-derived的关系。 一个可行的方法就是实现一个template构造函数，即构造模板： 123456template&lt;typename T&gt;class SmartPtr&#123; public: template&lt;typename U&gt; SmartPtr(const SmartPtr&lt;U&gt;&amp; other); // 将一个具现化的u转型为t&#125;; 这一构造函数根据对象u创建对象t，而u和t的类型是同一个template的不同具现体，我们称这个函数为泛化copy构造函数。需要注意的是，上面的前提是说，一个U可以被转型为T。 我们同样可以在构造函数中完成我们想要达到的转化： 123456789template&lt;typename T&gt;class SmartPtr&#123; public: template&lt;typename U&gt; SmartPtr(const SmartPtr&lt;U&gt;&amp; other) :heldPtr(other.get())&#123;...&#125; // 使用u的指针去初始化t变量的指针 private: T* heldPtr;&#125;; 同样的，上述的做法是在 U指针可以隐式转换为T*的基础上才成立的。 泛化copy构造函数与普通的copy构造函数之间不存在冲突，因此具现化后的类，依旧会为这个类实现一个copy构造函数。 总结 请使用member function templates成员函数模板，生成可接受所有兼容类型的函数。（即上面的u-&gt;t）。 如果你声明member templates用于泛化copy构造或泛化assignment操作，你还是需要声明正常的copy构造函数和copy assignment操作符，因为编译器默认生成的函数不会因为生成泛化copy构造函数受到影响。 46 条款：需要类型转换时请为模板定义非成员函数当我们在使用template来定义非成员函数，同时这个成员函数的参数需要隐式的转换的话，我们可能会遇到问题： 123template&lt;typename T&gt;const Rational&lt;T&gt; operator* (const Rational&lt;T&gt;&amp; lhs,const Rational&lt;T&gt;&amp; rhs)&#123;...&#125; 当我们调用上面代码： 1Rational&lt;int&gt; result = onehalf*2; 将会出现编译错误，因为template类型Rational&lt;T&gt;在具现化的时候需要确定T的类型，当遇到2的时候，C++无法推断出T为int，因此无法通过编译。 此路不通，我们曲线救国，通过将Rational&lt;T&gt;申请为class Rational的friend函数的方式来实现。 12345template&lt;typename T&gt;class Rational&#123; public: friend Rational operator*(const rational&amp; lhs,const&amp; rhs);&#125; 通过友元的方式来制定一个具体的函数，从而避免template进行参数的推导。 但是上面方法同样会引发一个问题，就是我们通过友元的方式，使得我们可以通过友元来确定函数，但是仅仅是个声明，没有函数的实现，一个最直接的方法就是我们直接将函数的本体定义在Rational乘法里头。 总结 当我们需要编写一个class template，而他所提供的与此template相关的函数支持所有参数隐式类型转换时，请将那些函数定义为class template内部的friend函数。 47 条款：请使用traits classes表现类型信息在一些状况下，我们需要知道一个类的某些信息。traits构件就是做这件事情的，他是一种技术，也是C++程序员所遵守的一种协议。我们将trait放入一个template中去： 12template&lt;typename TT&gt;struct iterator_traits; 接下来我们确认一个traits中应该包含哪些信息： 确认若干你希望将来可取得的类型的相关信息，例如对于迭代器，我们希望将来可取的他的分类。 为该信息选择一个名称 提供一个template与一组特化版本，内含你希望看到的相关信息 接下来是如何使用traits： 建立一个重载函数或函数模板，彼此的差异在于各自的trait参数； 建立一个控制函数或函数模板，用于调用上述的函数，并传递trait信息。 总结 traits class使得类型相关信息在编译期可用，它以template和templates特化完成实现。 整合重载技术后，trait class有可能在编译期对类型执行if … else 操作。 48 条款：认识template元编程template metaprogramming元编程是编写template-based c++程序并执行与编译期的过程。 总结 元编程可将工作由运行期移往编译期，因而得以实现早期错误侦测和更高的执行效率 TMP可被用来生成 基于政策选择组合的客户定制代码，也可用来避免生成对某些特殊类型并不适合的代码。 it is a little difficult for me,but never mind !]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(六) 继承与面向对象设计]]></title>
    <url>%2F2019%2F11%2F16%2Feffective-cpp-%E5%85%AD-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[2019/11/16 effective cpp 第六章 继承与面向对象设计 面向对象编程成为一个风靡一时的重要特性，关于C++在面向对象上的一些特性，将在本章进行详细的介绍。 32 条款：确定你的public继承塑膜出is-a关系 33 条款：避免遮掩继承而来的名称 34 条款：区分接口继承和实现继承 35 条款：考虑virtual函数与外的其他选择 36 条款：绝不重新定义继承而来的non-virtual函数 37 条款：绝不重新定义继承而来的缺省参数值 38 条款：通过符合塑模出has-a或“根据某物实现出” 39 条款：明智而审慎地使用private继承 40 条款：明智而审慎地使用多重继承 32 条款：确定你的public继承塑膜出is-a关系作者通过一个例子表明立场，说明一个戒慎恐惧的东西，将会使人们记得异常牢固。接下来他说我们应该用同样的心态记住下面的话： public继承意味着是一种is-a关系，即子类通过public的方式继承父类，那么子类在任何场合都可以直接转变为父类。 即D以public的方式继承自B，意味着B比D表现出更一般化的概念，D比B则表现出更加的特殊化。B可以使用的地方D一定可以使用，D可以使用的地方B不一定可以使用。 12class Person&#123;...&#125;;class student:public Person&#123;...&#125;; 上诉的代码表明是一个学生一定是一个人。任何函数希望得到一个person参数的时候，通常也愿意接受一个student对象。即给父类参数传递一个子类对象作为参数，是符合继承的观点，合法的。 总结 public继承意味着“is-a”的关系。适用于base classes身上的每一件事情一定也适用于derived class 身上，因为每一个derived classes 对象也都是一个base classes对象。 33 条款：避免遮掩继承而来的名称这个内容与作用域相关，指的是在不同的作用域之中，变量的遮掩。编译器从local领域从发，向外一步步直到找到变量。 当我们在谈论继承的时候，当位于一个derived class成员函数的内指涉base class内的某物，编译器可以找出所指涉的东西，因为derived classes继承了声明与base class内的所有东西。子类的作用域嵌套在base class作用域内，子类对象可以调用父类的成员。 例如下面例子： 1234567891011121314class base&#123; private: int x; public: virtual void mf1() = 0; virtual void mf2(); void mf3(); ...&#125;;class Derived::public Base&#123; public: virtual void mf1(); boid mf4();&#125;; 上述例子中混合了public，private名称，以及一组成员变量和成员函数名称，包含了pure virtual，virtual，non-virtual三种，假设mf4函数实现如下： 12345void Derived::mf4()&#123; ... mf2(); ...&#125; 当编译器遇到mf2的时候，必须估算他所指涉的东西，编译器的做法是查找各个作用域，看看有没有mf2的声明式，首先是local，然后是外围作用域，base的作用域，最外层的global作用域。 下面我们考虑一个重载带来的问题： 12345678910111213141516class base&#123; private: int x; public: virtual void mf1() = 0; virtual void mf1(int); virtual void mf2(); void mf3(); void mf3(double); ...&#125;;class Derived::public Base&#123; public: virtual void mf1(); void mf3();&#125;; 我们重载了mf1和mf3函数，base class中的mf1和mf3都被子类的函数所代替，但是此时对于父类中的重载函数将会发生错误： 12345Derived d;d.mf1(); //正常调用d.mf1(x); // 含参数的那个函数也被mf1函数所覆盖，因此调用出现问题d.mf3(); // 正常调用d.mf3(x); // 出错 为了解决上面出现的遮掩行为造成的错误，我们可以使用using声明式来达到目的： 123456class Derived:public Base&#123; using Base::mf1; using Base::mf3; void mf1(); void mf3();&#125; 使用using机制使得继承可以得到完美的实现。子类中调用d.mf3(x)将会到父类中寻找d.mf3(x)函数进行调用。 这意味着你继承base class并加上重载函数，而你又希望重新定义或覆盖其中的一部分，那么你必须为那些原本会遮掩的每个名称引入一个using声明式，否则某些你希望的名称将会被遮掩。 另一种情况是，当我们只希望继承父类重载的多个函数中的一个函数的时候，我们使用转交函数的方式，在子类函数中调用父类的函数，使其成为inline： 123456class Derived:private Base&#123; public: virtual void mf1()&#123; // 转交函数，只实现了一个版本，有参数的那个版本在子类中未继承 Base::mf1(); // 使其成为inline &#125;&#125; 总结 子类内的名称会遮掩base classes内的名称，在public继承下从来没有人希望如此 为了让遮掩的名称重见天日，可以使用using 声明式或转交函数。 34 条款：区分接口继承和实现继承在类的继承中，可以通过三种方式进行继承： 继承一个接口（pure virtual） 继承接口以及接口的部分实现，子类选择覆盖这些实现（impure virtual） 继承接口以及接口的部分实现，子类不覆盖这些实现（non-virtual） 成员函数的接口总是会被继承 pure virtual函数最突出的特性，他们必须被任何继承了他们的具象class重新声明，而且他们在抽象class中通常没有定义。 12345class shape&#123; public: virtual void draw() const = 0; ...&#125; 声明一个pure virtual函数的目的是为了让derived classes只继承函数接口。 对于shape::draw函数来说，这样是十分合理的，因为每个shape对象都应该有一个draw函数，同时由于shape子类形状各异，因此父类无法提供一个缺省（通用的）实现方式。 但是令人意外的是：我们可以为纯虚pure virtual函数提供一份实现代码，但是调用他的唯一途径就是明确指出class的名称。但是pure virtual依然无法创建对象。 1234shape* ps = new shape;shape* ps1 = new Rectangle;ps1-&gt;draw(); // Rectangle的draw函数ps1-&gt;shape::draw(); // 调用了父类的draw函数 声明非纯impure virtual函数的目的，就是让derived classes继承该函数的接口和缺省实现。 12345class shape&#123; public: virtual void error(const string&amp; msg); ...&#125; 上面代码表示每个class都必须支持一个“当遇到错误时可调用”的函数，但每个class可自由处理错误。如果不愿意自己处理错误的话，也可以使用父类的缺省实现。 但是这就会出现一个问题，当我们继承了一个韩非纯函数的父类的时候，我们可能会忘记实现自己的版本，此时编译器就会为了安排默认的版本，而引发错误，下面这种做法就是为了解决这个问题： 12345678910class Airplane&#123; public: virtual void fly(cosnt sAirport&amp; destination) = 0; ... protected: void defaultFly(cosnt Ariport&amp; destination);&#125;;void Airplane::defaultFly(const Airport&amp; destination)&#123; //fly函数中的实现部分改到这里来写&#125; 上述操作将fly函数又impure设置成pure函数，意味着子类必须有自己实现的版本，在缺省的实现部分转移到defaultFly当中去，如果子类不实现fly函数则会报错，如果希望用缺省方式的话，则调用defaultFly函数。 但是上面这种做法将会导致代码的重复这种情况。 另一种做法是将默认的实现部分转移到纯虚函数的实现中。 123456789101112131415class Airplane&#123; public: virtual void fly(cosnt Airport&amp; destination) = 0;&#125;;void Airplane::fly(cosnt Airport&amp; destination)&#123; //缺省行为，将飞机飞至指定的目的地&#125;class ModelA:public Airplane&#123; public: virtual void fly(const Airport&amp; destination)&#123; Airplane::fly(destination); // 使用缺省的方式实现 &#125;&#125;；// 如果你要自己实现fly这个函数的话，可以自己写相应的方法 这种方式避免了再去定义一个defaultFly函数。现在的fly函数被切割成两个部分，其声明部分表现的是接口，其定义部分表现出缺省行为。 声明non-virtual函数的目的就是为了令derived classes继承函数的接口及一份强制性的实现。 由于non-virtual函数代表的意义是不变性凌驾于特异性之上，我们绝对不要在子类中重新定义父类中的non-virtual函数。 总结 接口继承和实现继承不同。在public继承之下，derived classes总是继承base class的接口。 pure virtual函数只具体指定接口继承。 非纯的函数具体制定接口继承及缺省实现继承。 non-virtual函数具体指定接口继承以及强制性实现继承。 35 条款：考虑virtual函数与外的其他选择我们可以使用一些其他的方式来代替virtual的使用 template method模式 这种模式为将虚函数修改为public的non-virtual函数，然后其具体的实现通过定义一个private的virtual函数来实现： 12345678910111213class GameCharacter&#123; public: int healthValue() const&#123; ... // 调用前准备 int retval = dohealthValue(); ... // 调用后处理 return retval; &#125; private: virtual int dohealthValue() const&#123; ... &#125;&#125;; 上面的设计令用户通过public non-virtual成员函数佳节调用private virtual函数的模式（NVI non-virtual interface），把non-virtual函数作为一个外覆器，在调用前后都可以进行一些处理，这是这种方法的一个优点，但是缺点是我们需要定义很多private virtual函数。 籍由Function Pointers实现strategy模式 利用传入一个函数指针的方式，进行实际的操作。 函数指针的定义： 12345int defaultHealth(const GameCharacter&amp; gc);//函数指针如下return_types (*func_pointer)( data_types arg1, data_types arg2, ..);int (*defaultHealth)(const GameCharacter&amp;);//使用上面的定义之后，就可以用指针defaultHealth来调用函数了 上述这种方法提供了某种弹性，在调用不同的类型的时候，传入不同计算方法的函数的指针，得到不同的计算方式。当我们使用了类外的方法的时候，我们可能会陷入一个陷阱中，就是这个函数只能访问类的public部分，如果我们想进一步的话，就只能降低函数的封装级别了。 籍由tr1::function完成strategy模式 C++ Technical Report 1 （TR1）是ISO/IEC TR 19768, C++ Library Extensions（函式库扩充）的一般名称。TR1是一份文件，内容提出了对C++标准函式库的追加项目。这些追加项目包括了正则表达式、智能指针、哈希表、随机数生成器等。 function 是一种通用、多态的函数封装。std::function 的实例可以对任何可以调用的目标进行存储、复制、和调用操作，这些目标包括函数、lambda 表达式、绑定表达式、以及其它函数对象等。（c++11起的版本可用） function（和bind一样）可以实现类似函数指针的功能，却比函数指针更加灵活（体现在占位符上面），尤其是在很多成员调用同一个函数（仅仅是参数类型不同）的时候比较方便。 C++中的函数签名(function signature)：包含了一个函数的信息，包括函数名、参数类型、参数个数、顺序以及它所在的类和命名空间。 function对象只要签名式满足要求，那么这个对象就可以存储任何可调用物。下面我们使用function来替代上面的函数指针： 12345678910class GameCharacter&#123; public: typedef std::str1::function&lt;int (const GameCharacter&amp;)&gt; healthCalFunc; explicit GameCharacter(HealthCalcFunc hcf = defaultHealthCalc):healthFunc(hfc)&#123;&#125; int healthValue() const&#123; return healthFunc(*this); &#125; private: HealthCalcFunc healthFunc;&#125; 由上面代码可以看出来，我们只要传入一下接受一个const reference参数的任意函数都可以，我们可以使用函数，函数对象，成员函数等等。 古典的strategy模式 传统的strategy做法将一个健康的计算函数做成一个分离的继承体系中的virtual成员函数。 替代方案 本条条款的核心就是可以通过一下几种方式来找到virtual的替代方案： 使用non-virtual interface手法，那是template method设计模式的一种特殊形式，它以public non-virtual成员函数包裹较低访问性的virtual函数。 将virtual函数替换为函数指针成员变量，这是strategy设计模式的一种分解形式。 以tr1::function成员变量替换virtual函数，因而允许使用任何可调用物来搭配一个兼容于需求的签名式。 将继承体系内的virtual函数替换为另一个继承体系内的virtual函数，这是strategy设计模式的传统实现方法。 总结 virtual 函数的替代方案包含NVI，以及strategy设计模式的多种形式，NVI手法是一个特殊形式的template method模式。 将机能从成员函数一道class外部函数，带来一个缺点，非成员函数无法访问class的non-public成员。 tr1::function对象行为就像一般函数指针，这样的对象可接纳与给定目标签名式兼容的所有可调物。 36 条款：绝不重新定义继承而来的non-virtual函数在一个类中，我们定义了non-virtual函数，意味着我们遵循设计原则，认为这个函数的不变性要大于特异性，因此我们不可以在子类中对这个函数进行覆盖。否则，将同一个元素赋值给父类和子类，将导致不同的行为，这是我们不希望看到的。 总结 绝对不要重新定义继承而来的non-virtual函数 37 条款：绝不重新定义继承而来的缺省参数值当我们继承一个父类的时候，如果父类中的virtual函数带有缺省值，我们选择不去重写这个缺省值。原因是： virtual函数系动态绑定，而缺省参数值确实静态绑定。因此缺省的参数值在定义的时候就会被确定，缺省值就是定义这个函数的类给赋予的。如下面代码： 1234567891011121314151617181920class Shape&#123;public: enum shapecolor&#123;red,green,blue&#125;; virtual void draw(shapecolor color = red) const = 0;&#125;;class rectangle:public Shape&#123;public: virtual void draw(shapecolor color = green) const;&#125;;void rectangle::draw(Shape::shapecolor color) const &#123; cout &lt;&lt; "---"; cout &lt;&lt; color; cout &lt;&lt; "---";&#125;Shape *ps = new rectangle();rectangle* rec = new rectangle();ps-&gt;draw(); // 使用静态绑定的shape中的缺省值rec-&gt;draw(); // 使用静态绑定的rectangle中的缺省值 上述代码就可以看出矛盾，同一个对象却有不同的表现，导致缺省值的不同。上述代码的一个解决方案就是使用NVI方式，用non-virtual去调用virtual函数： 12345678910111213141516class Shape&#123;public: enum shapecolor&#123;red,green,blue&#125;; void draw(shapecolor color = red)&#123; doDraw(color); &#125;private: virtual void doDraw(shapecolor color) const = 0;&#125;;class rectangle:public shape&#123; public: ... private: virtual void doDraw(shapecolor color) const; // 这里不需要指定缺省的参数值&#125;； 由于non-virtual函数是不会被子类覆盖。这个设计保证了参数值一定是一致的。 总结 绝对不要重新定义一个继承而来的缺省参数值，因为缺省参数值都是静态绑定的，而virtual函数（你唯一需要覆盖的东西）是动态绑定的。 ###38 条款：通过符合塑模出has-a或“根据某物实现出” has-a表现出来的是一种复合关系（composition），当某种类型的对象内含它种类型的对象，便是这种关系。 1234567class Person&#123; ... private: Address ad; // 其他类型的生成对象 string name; PhoneNumber num;&#125; 除此之外，还有另一种关系，成为 is-implemented-in-terms-of 关系，例如我们实现一个set，直觉上我们可以继承标准库中的set，但是为了资源等考虑，我们打算另辟蹊径。我们可能就会考虑到list的实现，但是我们不能直接继承list，因为list与set不是is-a的关系。但是我们可以在函数中多次使用list结构来构造一个set，这就是根据某物实现出的这种关系。 总结 复合的意义和public继承完全不同 在应用域，复合意味着is-a关系。在实现域，复合意味着根据某物来实现。 39 条款：明智而审慎地使用private继承private继承不是一个is-a继承，而是一种子类实现需要使用父类的某些函数性质的 “implemented-in-terms-of”的关系。 对于private的选择，我们通常会考虑：当一个意欲成为derived class者想要访问一个意欲成为base class者的protected成分，或者成为重新定义一个或多个virtual函数。如果满足这个条件的话，我们会考虑使用private继承，但是很多情况下，我们使用复合，将private继承的类作为一个成员变量的方式，能够提供能多的灵活性。 即：我们可以使用复合的方式来代替private的继承，保证更大的灵活性。 但是如果我们追求一种更加激进的空间优化，我们会选择使用private继承来代替复合。 如果我们使用的类满足不带数据成员，没有virtual等条件，满足空白基类最优化EBO的情况下，我们应该优先考虑private继承，但是这种情况基本很少见。 总结 private继承意味着 根据某物实现出的关系，它通常比复合的级别要低，当时当子类需要访问protected base class的成员，或需要重新定义继承而来的cirtual函数时，是合理的。 和复合不同，private继承可以造成empty base最优化，这对于严格要求“对象尺寸最小化”的程序开发者而言是很重要的。 40 条款：明智而审慎地使用多重继承当我们设计到多重继承的时候，在子类的使用上将会面临起义的一个问题，共同父类中相同的函数，必须通过类名的方式进行调用。 对于钻石形的继承关系，我们使用virtual来继承，使得每一个子类都有一份供自己使用的父类成员变量。但是使用virtual将会导致C++编译器在处理这类继承时，生成体积较大的对象，访问速度也比较慢，virtual继承付出的代价更加的明显，规则复杂不够直观。 忠告 非必须使用virtual bases的时候不要使用它，大部分情况使用non-virtual继承 如果必须使用virtual base继承，那么尽量避免在其中放置数据，使得类小一点，以及不会出现难以察觉的赋值问题。 但是有些时候，双重继承也有其合理的用途，保留使用多重继承的看法。如果能用单一继承代替多重继承的话，单一继承是一个非常好的选择。 总结 多重继承比单一继承复杂，他可能导致起义性，以及对virtual继承的需要 virtual继承会增加大小，速度，初始化复杂度等成本，如果virtual base classes不带任何的数据，将会是多重继承最具有使用价值的情况。 多重继承的确有正当用途，其中一个情节涉及public继承某个interface class和private继承某个协助实现的class的两相组合。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(五) 实现]]></title>
    <url>%2F2019%2F11%2F10%2Feffective-cpp-%E4%BA%94-%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[2019/11/10，effective cpp第五章 实现 cpp在实现上存在着很多高效率，代码优化的细节。 26 条款：经可能延后变量定义式的出现时间 27 条款：尽量少做转型动作 28 条款：避免返回handles指向对象内部成分 29 条款：为异常安全而努力是值得的 30 条款：透彻了解inlining 的里里外外 31 条款：将文件间的编译依存关系降至最低 26 条款：经可能延后变量定义式的出现时间我们定义一个变量需要承担它的构造成本以及析构成本，如果我们在程序中，由于一些判断条件未能使用到这些变量，那么将造成大量的时间浪费，于是我们应当尽量的延后变量的定义。 第二个优化的地方在于在定义变量的时候，通过调用构造函数来初始化变量，而不是通过赋值的方式。（通过赋值的方式将会浪费一次系统默认的赋值时间） 第三个优化的地方，如果我们需要在一个循环中使用变量的话，我们应该在循环的内部定义变量，除非析构与构造的成本比较高，且你的代码对效率高度敏感。 总结 尽可能延后变量定义式的出现，这样做可以增加程序的清晰度，并改善程序的效率。 27 条款：尽量少做转型动作首先是结论：优良的C++代码很少使用转型 C++的设计目标之一就是保证类型错误绝不可能发生，尽量保证任何转型动作尽可能少的发生。转型动作破坏了类型系统，导致一些很隐晦的错误。C++提供的转型变换如下： const_cast&lt;T&gt; (expression)，通常用于对象的常量性移除，将常量去除 dynamic_cast&lt;T&gt;(expression)，主要用于执行“安全向下转型”，用来决定某对象是否归属继承体系中的某个类型。可能耗费比较大的运行成本。 reinterpret_cast&lt;T&gt;(expression)，执行低级转型，例如将point to int 转成int。 static_cast&lt;T&gt;(expression)，用来强迫执行隐式转型，将int转成double等等。 旧式的转型： (T)expression T(expression) 旧式的两种写法功能相同，建议使新式的转型方法，因为他们在代码上容易辨认，且各个转型动作目标比较窄，容易排查错误,例如只有const_cast方法才能实现对象的常量移除。 关于dynamic_cast方法，例如我有有些时候，希望在子类函数调用的时候先调用父类的函数，会写出下面的代码（错误的）： 1234567class special: public window&#123; public: virtual void onResize()&#123; static_cast&lt;window&gt;(*this).onResize(); ... &#125;&#125; 上诉代码将this转为window的指针，但是他调用的并不是当前对象上的函数，转型动作将产生一个this对象的base class的成分的一个副本。因此window上的onsize操作只是在一个副本上执行操作的，并不会改变this对象的内容。解决的方法是直接调用父类的onsize方法： 1234567class special: public window&#123; public: virtual void onResize()&#123; window::onResize(); ... &#125;&#125; 使用dynamic_cast的场景通常说，我们手上只有一个base class的指针，但是想希望通过它来执行子类的一些操作： 1234567typedef vector&lt;tr1::shared_ptr&lt;window&gt;&gt; vpw;vpw winptr;... for(vpw::iterator iter=winptr.begin();iter!=winptr.end();++iter)&#123; if(special* psw=dynamic_cast&lt;special*&gt;(iter-&gt;get())) psw-&gt;blink(); &#125; 上面代码效率比较低，而且令人担心，因此最后直接用子类的容器存储指针： 123456typedef vector&lt;tr1::shared_ptr&lt;special&gt;&gt; vpsw;vpsw winptr;...for(vpsw::iterator iter = winptr.begin();iter!=winptr.end();++iter)&#123; (*iter)-&gt;blink();&#125; 但是上面的代码童谣失去了指向所有可能子类的可能，一个可行的解决方案就是为在base class提供一个缺省实现的blink函数声明。或者是直接用上述方式写出子类 不论是哪一种写法：使用类型安全容器，或将virtual函数往继承体系上方移动，都是一个替代dynamic_cast 的可行方案。 绝对需要避免的一种写法是连串使用多个dynamic_cast，这种代码将又大又慢，同时十分的不安全。 总结 如果可以，尽可能避免转型，特别在注重效率的代码中避免使用dynamic_cast 如果转型是必要的，试着将它隐藏呀某个函数背后，供客户调用 宁可使用C++新式的转型，因为容易辨认，同时便于排查错误。 28 条款：避免返回handles指向对象内部成分handles指的是诸如reference，指针，迭代器这种用来取得某个对象的变量，我们应当避免直接返回指向对象内部数据或函数的handle出现。 如下，我们打算实现一个矩阵类： 1234567891011121314151617181920class point&#123; public: point(int x,int y); ... void setX(int val); void setY(int val);&#125;;//定义角struct RectData&#123; point ulhc; point lrhc;&#125;;//定义矩阵class Rectangle&#123; ... private: tr1::shared_ptr&lt;RectData&gt; pData; public: point&amp; upper() const &#123;return pData-&gt;ulhc;&#125;&#125; upper函数取得矩阵左上角的点，返回一个引用，这个引用指向了矩阵内部的点，就会引发一个矛盾，我们使用一个const函数，但是返回的值是private数据，且可以被修改。 12const Rectangle rec(coord1,coord2);rec.upper().setX(50); //被修改 从从上面我们可以得出两条结论， 第一条，成员变量的封装性只能等于返回其reference的级别，即引用的级别决定了封装性。 第二条，如果const成员函数传出一个reference，后者所指的数据与对象自身有关联，而他又被存储与对象之外，那么这个函数的调用者可以修改那笔数据。 一个好的解决办法就是在函数调用的时候，将返回值的内容设置成const： 1const Point&amp; upperLeft() const &#123;return pData-&gt;ulhc;&#125; 但是即使如此，如果直接返回代表对象内部数据的handle的话，有可能这个handle的生存周期比对象本身的生存周期要长，那么将导致空悬指针的发生（dangling handles）。 因此：尽量避免将对象内部的handles传出去。 总结 避免返回handles指向对象内部，遵守这个条款可以增加封装性，使得const更加像一个const，并避免虚调handles的发生。 29 条款：为异常安全而努力是值得的对于一个异常安全性的函数来说，他通常有两个条件： 不泄漏任何资源 不允许数据败坏：即出现类似空指针，指向已经销毁的对象这种情况 第一种情况可以通过资源管理类来完美的解决，下面专门来解决第二种情况 异常安全函数提供以下三种程度的保证： 基本承诺：如果异常被抛出，程序内的任何事物仍然保持在有效状态下 强烈承诺：如果异常被抛出，程序状态不改变，如果函数成功就完全成功，如果函数失败，就恢复到调用函数之前的状态。 不抛掷保证：承诺不抛出异常，他们总能完成承诺的功能，例如一些内置类型等。 1int doSomething() throw(); 上面的函数带有指定的空白异常，也就是说上述函数抛出异常的话，将会产生很严重的后果，但是该函数并不能提供任何异常安全的保证，异常安全的保护正完全由实现来决定。 对于异常安全来说，保证不抛出异常基本难以实现。基本上能够实现强烈承诺或基本承诺就可以满足需求了。 实现强烈承诺，即出现异常情况对象的状态不发生改变，有一个策略称为：copy and swap，即为打算修改的对象提供一份副本，并在那个副本上做一切必要的修改，如果出现异常，则原对象未发生改变，如果正常则将副本和原对象进行交换。 12345678void pretty::changeBackground(istream&amp; imgSrc)&#123; using std::swap; Lock ml(&amp;mutex); // 获得mutex的副本 tr1::shared_ptr&lt;PMImpl&gt; pNew(new PMImpl(*pImpl)); pNew-&gt;bgImage.reset(new Image(imgSrc)); ++pNew-&gt;imageChanges; swap(pImpl,pNew); // 释放mutex&#125; 从上面可以看出来，对函数的异常保证将花费大量的资源，因此如果强烈保证不能满足的情况下，你就应该转向基本满足的情况。 对于一个对象来说，它的异常保证的级别取决于最差的一个异常保证函数。 总结 异常安全函数即使发生异常也不会泄露资源或允许任何数据结构败坏，这样的函数区分为三种可能的保证：基本型，强烈型，不抛异常型 强烈保证往往能够以copy and swap实现出来 函数提供的异常安全保证，通常最高值等于其所调用的各个函数的异常安全保证种最弱的 30 条款：透彻了解inlining 的里里外外inline函数，使用起来像函数，调用他们又不用蒙受额外的函数调用所导致的开销，编译器的最优化机制通常被设计成用来浓缩那些不含函数调用的代码，因此inline函数也会得到编译器在当前语境下的最优化处理。 但是过度使用inline同样会导致很多问题，首先是使得程序的目标码过大，导致一些效率上的损失。 总之，如果inline函数的本体很小，编译器对函数本体所产出的代码可能比函数调用所产出的代码要小，这种情况将函数inlining确实可以导致较小的目标码和较高的指令高速缓存装置的击中率。 inline函数的做法：隐喻的做法是将函数定义在class内，自动就完成了inline的操作。明确声明的做法则是在函数前面加上inline关键字。 inline函数通常一定被放置于头文件内，因为大多数的生成环境在编译过程中进行inline，需要知道函数本体长什么样子。 模版类templates也通常被置于头文件内，因为它一旦被使用，编译器为了将它具体化，需要知道它长什么样子。但是templates与inline没有直接的联系，如果你觉得该templates内的函数都比较简单，可以进行inline的话，才会去定义为inline。 inline是一个申请，编译器可以拒绝 也就是说，一个函数最终实现方式是否是inline，取决于编译器是否同意该函数满足inline的条件。 例如大部分过于复杂（含循环，递归等）的函数，virtual声明的函数，通常都会被定义为outline函数。 有些编译器有意愿inlining某个函数，但是也可能为函数生成一个函数本体。例如程序要取得某个inline函数的地址，编译器通常必须为此函数生成一个outline函数本体。 1234inline void f() &#123;...&#125; //假设编译器有意愿inline对f的调用void (*f)() = f;f(); // 调用inlinepf(); // 调用outline的本体 有时候，编译器会为析构函数和构造函数生成一个函数的副本，这样他们就可以获得指针指向那些需要指针的函数，但是这样一来，导致了析构函数和构造函数的赋值过程。 实际上析构函数，构造函数往往是inline糟糕的候选人，因为C++在创建对象的时候，将构造对象，析构对象，异常处理等一些操作隐藏在析构函数和构造函数内部，因此函数内部存在着很多的对象。但是对这些对象的副本往往会造成很大的资源消耗。 因此，是否将构造函数和析构函数inline化，是一个慎重的考虑。 inline函数修改后必须重新编译 此外，inline函数还存在一个问题。当我们对inline函数进行修改的时候，原来函数的本体因为已经编译进程序的内部了，无法通过函数的链接步骤实现修改，而是需要对整个程序进行重新编译。 总结 将大多数inlining限制在小型、被频繁调用的函数身上，这可使得日后的调试过程和二进制升级更加容易，也可使潜在的代码膨胀问题最小化，使得程序速度提升最大化。 不要滥用inline，不用只因为function templates出现在头文件中就将他们声明为inline，因为很多时候，这些函数不符合inline标准，编译器还是会为他们生成outline版本 31 条款：将文件间的编译依存关系降至最低文件之间的依存关系越是复杂将会导致函数之间的耦合度越高，对修改代码带来不便。 例如你仅仅对class进行轻微的修改，但是这将导致所有用到这个文件的程序都需要进行重新编译，这一连串的编译依存关系将导致难以形容的灾难。 例如下面的代码： 1234567891011121314#include&lt;string&gt;#include "data.h"#include "address.h"class Person&#123; public: Person(const string&amp; name,const Date&amp; birthday); string name() const; string birthday(); private: string thename; Data theData; address add;&#125;; 上面的类别的私有变量中，string，Data需要用到其他的头文件来创建（实现细则），这些头文件任意一个被修改后都将导致Person class重新编译。 针对这种形式，我们可以这样做： 把person分割为两个classes，一个只提供接口，另一个负责实现该接口。 12345678910111213#include&lt;string&gt;#include&lt;memory&gt;class Date; // 类的前置声明class Address;class Person&#123; public: Person(const string&amp; name,const Date&amp; birthday); string name() const; string birthday(); private: str1::shared_ptr&lt;PersonImpl&gt; pImpl;&#125;; 类PersonImpl为person类的实现，这样的话，修改Data类就不需要对Person函数进行重新编译，将person与其他类进行分离。 这个分离的关键在于：使用声明的依存性来代替定义的依存性，尽量让头文件自我满足，万一无法做到，那么让它和其他文件内的声明式相依（而不是定义式）。 下面一些准则都是这个原则下完成的： 如果使用object references 或objects pointers可以完成任务，就不要使用object，即使用声明式来代替定义式。 尽量以class声明式代替class定义式。 为声明式和定义式提供不同的头文件，为一个文件提供函数的声明，而不是而代替提供class的定义式，这样可将文件见的编译依存关系去掉。因此我们需要定义两个文件，一个是声明式，另一个是定义式。 上面这个实现使得代码编，让Person变成一个handle class。 抽象基类 通过制作抽象类的方式，也可以实现这种操作。通过定义抽象类函数接口，创建不同类型的的派生类对象。 handle classes 和interface class解除了接口和实现之间的耦合关系，从而减低了文件间的编译依存关系。但是也在某种程度上使得每个对象超额付出若干的时间以及空间的成本。 总结 支持编译依存最小化的一般构想是：相依与声明式，不要相依于定义式，基于此的构想的两个手段是 handle classes，interface classes。 程序库头文件应该以完全且仅有的声明式的形式存在，这种做法不论是否涉及templates都适用。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(四) 设计与声明]]></title>
    <url>%2F2019%2F11%2F09%2Feffective-cpp-%E5%9B%9B-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E%2F</url>
    <content type="text"><![CDATA[2019/11/09 effective cpp 第四章 良好的cpp接口的设计以及声明是可以令软件作出其最正确的事，包括正确，高效性、封装性、维护性、延展性、以及协议一致性。 18 条款：让接口容易被正确使用，不易被误用 19 条款：设计class犹如设计type 20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value 21 条款：必须放回对象时，别妄想返回其reference 22 条款：将成员变量声明为private 23 条款：宁以non-member、non-friend替换member函数 24 条款：若所有参数皆需类型转换，请为此采用non-member函数 25 条款：考虑写出一个不抛异常的swap函数 18 条款：让接口容易被正确使用，不易被误用接口开发的目标在于：让接口容易被正确使用，不易被误用 但是由于有时候会遇到用户传入的参数和接口能够接受的参数不同，可能会导致错误，这个时候最后通过 类型系统的方式来预防，通过导入新的类别来限制数据类型。 1234567class Date&#123; public: Date(const Month&amp; m,const Day&amp; d,const Year&amp; y)&#123; ... &#125;&#125;Date d(Month(3),Day(30),year(1995)); 对数据的限制部分在每一个数据类型的函数内部。明智地选择合适的新类型，能够有效的防止接口被误用。 另一个预防客户错误的方式是限制类型内可做什么事情，不能做什么事情，常见的限制加上const，阻止用户自定义类型错误。 另一个准则为除非有好的理由，否则应该尽量令你的types的行为和内置的type的行为一致。例如STL中的所有类均有一个size方法，表示长度。 如果在接口内部有资源的申请，申请的资源必须在最后得到销毁。因此最好的方法就是将函数的返回值设置为shared_ptr： 1str1:：shared_ptr&lt;invest&gt; create(); 此外，shared_ptr还允许绑定一个对象释放函数，当对象释放的时候，shared_ptr调用这个函数来释放对象。定义方式为： 1str1::shared_ptr&lt;invest&gt; pInt(ptr,deleteMethod); str1::shared_ptr会自动调用每个使用它的指针专属的删除器，避免跨DLL文件delete导致运行期的错误。shared_ptr会调用指针的专属删除器。 shared_ptr在效率和空间上是用指针的两倍大，使用辅助动态内存，比原始指针要大。 总结 设计不容易出错的接口 保证接口之间的一致性 阻止误用，建立新类型的方式限制类型上的操作，消除客户资源管理的任务 Tr1::shared_ptr支持定制删除器，防范DLL问题 19 条款：设计class犹如设计type当你定义了一个新的class，也就定义了一个type，设计好的type有自然的语法和直观的语义，有一下的设计规范： 新type的对象应该如何创建和销毁 对象初始化和对象的赋值该有什么样的差别 新type对象如果被传值（passed by value）该在copy函数中写实现方法 对type的合法值进行约束 新的type是否需要配合继承图系 新type需要什么样的类型转换 什么样的操作符和函数对新type是合理的 什么样的标准函数需要驳回 谁该去用新type成员 什么是新type的未声明接口 type的一般化程度 你真的需要一个新type吗 总结 设计一个class的时候，需要充分考虑上面的问题，具体所指可以参考书本84页。 20 条款：宁以 pass-by-reference-to-const 替换 pass-by-valueC++默认以传值的方式给函数传递参数，这一过程函数参数的初值都是调用对象的构造函数来实现，当离开这个函数的时候，通过析构函数来回收这些资源，因此传值的方式将会耗费大量的资源和时间。 一个很好的优化方法就是使用const 引用的方式，这种方式没有任何的构造函数被调用。之所以使用const，是为了保证传入的参数对象不会被改变。 此外如果直接传值，对于参数类型为父类的情况，传入子类对象，会造成子类特化功能被切割，参数的行为与父类相同，但是如果使用传引用的方式，这种现象不会发生。 说到这里，我们会好奇，引用到底是个什么东西呢，其实际上运用是通过指针的方式来实现的，传递引用等同于传递指针，对于内置类型来说，传值方式会比传指针的方式更加高效。 对于int，float这些类型，直接通过传值的方式更加的高效。 总结 尽量以传const引用的方式替换传值的方式，前者通常比较高效，避免对象切割问题 对于内置类型以及STL迭代器，函数对象来说，直接传值比较高效 21 条款：必须放回对象时，别妄想返回其reference当我们尝试消灭所有的传值行为的时候，我们可能会对函数的返回值下手，这种做法是不可取的。 所谓的引用，即表明它所指代的对象一定要存在，在函数中我们有两种方式创建对象： 创建对象在stack内存上 stack内存存放函数的参数，局部变量值，由编译器自动释放： 1234const Ration&amp; operator*(const Ration&amp; lhs,const Ration&amp; rhs)&#123; Ration result(lhs.n*rhs.n); return result&#125; 上买代码返回了一个局部变量的引用，但是由于出了这个函数，局部变量就会被销毁，因此这个reference将毫无意义。 创建对象在heap内存上 用户自己分配，自己销毁的资源都会分配在heap内存上，有new-delete对来管理。 1234const Ration&amp; operator*(const Ration&amp; lhs,const Ration&amp; rhs)&#123; Ration* result = new Ration(lhs.n*rhs.n); return *result;&#125; 上面返回的引用是有意义的，但是当我们使用完这个 内存之后，由谁去销毁呢，在一些很复杂的操作里面，程序员往往无法保证资源的完全回收。 使用static变量 在函数内部定义static变量，该变量的生命周期是整个程序的生命周期，static变量，全局变量他们的值都是存放在同一块区域，由程序结束后统一回收。 但这又引发了另一个问题，你想要比较两个数相乘后与另外两个数相乘的大小，但是结果存放在static当中，程序只会保存一份static的结果，因此永远无法比较。 因此，如果函数要求返回一个对象，那么我们就承担返回值所产生的构造和析构成本，不要试图去放回引用。 总结 不要返回一个指针或引用指向一个local对象，或指向heap-allocated对象，或指向static对象，而是直接返回该对象（传值）。 22 条款：将成员变量声明为private为保证成员便来那个的约束性，对用户隐藏变量，使得类中的约束条件总会收到维护。如果将一个变量声明为public，破坏了封装性，在我们修改该变量的时候，我们无法预知这个变量所涉及的一切，可能会对程序造成极大的破坏。因此保护类的封装性。protected类型与public相似，其实只有来那个两种访问权限：private（提供封装）和其他（不提供封装） 总结 切记将成员变量声明为private，这可赋予客户访问数据一致性，细微划分访问控制，允许约束条件获得保护，并 提供class作者充分的实现弹性。 23 条款：宁以non-member、non-friend替换member函数这个条款的核心在于：越少的操作直接接触到数据，对类的封装性，代码的维护越好。因此如果一些操作可以由非成员函数来完成的话，就不要去写那个成员函数的版本。 越少的函数接触到数据，我们在改变数据的时候，就可以有越大的灵活度修改这个数据。 有几种方式可以去实现非类内函数来完成这个操作： 例如我们指提供了一个完成基础操作的类，我们可以选择另一个类中的函数，传入这个对象，来实现你想要的操作，而不用为基础类添加成员 C++的一个常用的做法是，将non-member函数与类写在同一个命名空间中，命名空间可以跨越多个源码文件。将所有便利函数放在多个头文件内，但同属于一个命名空间，以为着用户可以轻松扩展这一组便利函数 12345678910111213//头文件webbrowser.hnamespace webbrowserStuff&#123; class webbrowser&#123;...&#125;;&#125;//头文件webbrowserbook.hnamespace webbrowserbook&#123; ...&#125;// 头文件webbrowsercookies.hnamespace webbrowsercookies&#123; ...&#125; 通过include需要的头文件的方式来管理标准程序库，使得那一小部分系统形成编译相依的关系。 123456789101112131415161718192021222324//web.h#include &lt;string&gt;namespace wweb&#123; class web&#123; public: string get_name()&#123; return name; &#125; web(string n):name(n)&#123;&#125; void say_hi(); private: string name; &#125;;&#125;//web.cpp#include "web.h"#include &lt;iostream&gt;using namespace::wweb;void web::say_hi() &#123; cout &lt;&lt; "hihi";&#125; 总结 宁可用non-member函数替代member函数，这可增加类的封装性，包裹性，机能扩充性。 non-member的函数通常与class定义在同一个命名空间内 24 条款：若所有参数皆需类型转换，请为此采用non-member函数当我们传入参数都需要进行类型转换的时候，如果将类函数写成如下情况： 123456789class Ration&#123; public: ... const Ration operator* (const Ration&amp; rhs) const;&#125;Ration oneE(10);Ration result = oneE*2; // C++将2转换成Ration类型Ration result = 2*oneE; // 编译错误，因为this不可以作为类型转换的变量 只有当参数可位列于参数列中内，这个参数才允许隐式转换，因此一个比较好的方法就是非类内函数去实现。 123const Ration operator*(const Ration&amp; lhs,const Ration&amp; rhs)&#123; ...&#125; 能够避免使用友元的情况就一定要避免使用它。 总结 如果需要为某个函数的所有参数进行类型的转换，那么这个函数必须是个non-member。 25 条款：考虑写出一个不抛异常的swap函数swap函数的实现如下： 12345678namspace std&#123; template&lt;typename T&gt; void swap(T&amp; a,T&amp; b)&#123; T temp(a); a = b; b = temp; &#125;&#125; 只要支持copying，swap就会完成交换。但是上面这种方法需要不断的构造，析构。于是我们选择特性化swap，通过置换指针的方式就可以达到置换的效果。 1234567891011121314class widget&#123; public: void swap(Widget&amp; other)&#123; using std::swap; //令std内的swap函数可见 swap(pInt,other.pInt); &#125;&#125;namespace std&#123; template&lt;&gt; //告诉编译器，这是个全特化的版本 void swap&lt;Widget&gt;(Widget&amp; a,Widget&amp; b) &#123; a.swap(b); &#125;&#125; 因此优化copy： 提供一个public swap成员函数，让它高效置换你的类型的两个对象值，且不能抛出异常。（置换基本类型）。 在class或template所在命名空间中提供一个non-member swap函数，并令他调用上述的swap成员函数。 如果你正编写一个class，为你的class特化std::swap，并调用你的swap。 总结 当std::swap对你的类型效率不高的时候，提供一个swap成员函数，并确保不抛出异常 提供一个member swap函数，也应该提供一个non-member swap用来调用前者，对于classes也请特化std::swap。 调用 swap时应该针对std::swap使用using声明式，然后调用swap并且不带任何命名空间资格修饰。 为“用户定义类型”进行std::template全特化是好的但是千万不要尝试在std内部加上对std而言全新的东西。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[EncNet结合上下文的语义分割]]></title>
    <url>%2F2019%2F11%2F06%2FEncNet%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[《Context Encoding for Semantic Segmentation》是发表在2018年cvpr上的文章，文章的主要insight在于将图像中的内容信息加入到语义分割的网络中，通过一个context encoding module突出图像类别，对分类类别进行简化，降低分割的难度，提升分割的精度。 概述目前的分割网络主要的关注点在于pixel-level predict，即对每个像素进行类别的分类。从2016年提出的FCN分割网络开始，图像分割实现了一个端到端的分割，当时由于CNN-pooling的网络设计，使得FCN网络对数据的丢失严重。为了解决这个问题，人们提出了dilated conv以及特征金字塔等（deeplab）结构来解决这个问题，即扩大feature map的感受野的同时，保证feature map的分辨率，保留大部分的数据。 EncNet另辟蹊径，认为通过图像中给出的类别信息能够对分割种类进行缩小，找到一个比较小的子集，在该类别的子集上进行语义的分割，简化分割问题。本文给出了两个主要的贡献： 本文提出了一个context encoding mudule模块，以及一个SE-Loss，一个简单的单元来利用全局的场景内容信息学到不同channel的权重，以及学到场景中所包含的类别。 EncNet，作者的第二个贡献就是提出了EncNet这个网络，能勾在许多公开的语义分割的数据集上取得state of the art的效果。 下面来看一下作者具体是怎么实现的： Context Encoding Modulecontext Enocding 作者通过使用一系列的卷积层（空洞卷积）去学习一个内在的语义字典的表示，将这个字典作为编码语义，为了方便使用上下文，去学习预测了一组缩放因子用于突出和类别相关的特征图。 将feature map的大小reshape成二维（WxH）x C，去学习codebook $D = {d_1,d_2,…d_k}$ ,以及一组和视觉中心平滑因子$S = {s_1,s_2,…s_k}$,编码层输出残差编码，通过soft-assignment进行聚合，$e_k = \sum_{i=1}^{N}e_{ik}$，其中$e_{ik}$ 如下：$$\begin{equation}e_{i k}=\frac{\exp \left(-s_{k}\left|r_{i k}\right|^{2}\right)}{\sum_{j=1}^{K} \exp \left(-s_{j}\left|r_{i j}\right|^{2}\right)} r_{i k}\end{equation}$$其中$r_{ik} = x_i - d_k$作为残差加入计算，其中$e = \sum_{k=1}^{K}\phi(e_k)$，对所有的ek进行batch normalization得到e，作为编码层的输出。 feature attention 通过编码层输出的e，来学习一组缩放因子，用于强调和抑制一些不同的类别。缩放因子通过全连接层进行学习，最得到一组缩放因子如下：$$\gamma = \sigma(We)$$其中w为全连接层的参数，$\sigma$为sigmoid函数，最终将得到的缩放因子与输入的深度图进行相乘得到最终权重改变后的feature map。 Semantic Encoding Loss 作者为了能够更好的理解图片与类别之间的关系，从图像中直接预测出图像中所包含的类别，将编码层的输出传入另一个全连接层中，GT为图片中已有的类别，通过最小化SE-Loss，即二次的交叉熵loss，判断60个类，存在或不存在的方式，来建立图像全局信息与类别之间的映射关系。最终对图像中的类别进行一个削减。 Context Encoding NetworkEncNet网络的backbone使用的是resnet，同时使用了之前证明有效的dilated conv，在深度图的state3，和4阶段使用了空洞卷积： 在stage3位置上同样适用了SE-loss，作为一个额外的正则化的操作，encnet在FCN的基础上进行一些小的改动，通过增加一些轻微的计算量就可以达到一个很好的效果。 评价指标pixAcc：像素类别预测正确的像素除以所有像素的比例。 mIoU：每一类预测结果与GT的结果的IoU的平均值。 总结看完整篇文章，这篇文章最大的亮点就是认为飞机不会出现在房间里，利用图像的feature map，与类别GT，建立一个映射，从而在做最终的逐像素的语义分割的问题时，没必要在所有的类别上做，而是直接在根据图像feature map上映射得到的类别上做，降低了语义分割的难度。 对图像整个内容信息的提取上，主要由两部分构成，一部分对不同的channel学习一个重要性权重，另一个直接通过图像内容学习一个图像中含有的类别。]]></content>
  </entry>
  <entry>
    <title><![CDATA[推荐系统之评分预测（三）]]></title>
    <url>%2F2019%2F11%2F06%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[评分问题，根据已有的评分，或者用户、物品的评分规则对物品进行评分的预测。 离线实验方法 评分的预测基本上都是通过离线实验进行研究的。研究者通过将数据分成训练集和测试集的方式，根据训练好的兴趣模型，对测试集进行评分。一般使用的度量方法为RMSE：$$\operatorname{RMSE}=\frac{\sqrt{\sum_{(u, i) \in T}\left(r_{u i}-\hat{r}_{u i}\right)^{2}}}{|\mathrm{Test}|}$$ 评分预测算法平均值通过计算训练集中的全局平均值，作为测试集中的评分。 用户评分平均值 用户的评分平均值为用户历史评分的平均值，作为他之后评分的一个值。 物品评分平均值 对物品的所有评分计算平均值，作为它在训练集中的所有评分的平均值。 用户分类对物品分类的平均值 同类的用户对同类的物品的评分的平均值作为物品的评分。 用户和物品的平均分 将用户和物品按照评分从高到低分成平均分成N类。 用户活跃度和物品流行度 用户活跃度和物品的流程度从大到小平均分成N类。 基于领域的方法基于领域的方法认为一个用户对一个物品的评分需要参考和着高哟高糊兴趣相似的用户对该物品的评分。$$\hat{r}_{u i}=\bar{r}_{u}+\frac{\sum_{v \in S(u, K) \cap N(i)} w_{u v}\left(r_{v i}-\bar{r}_{v}\right)}{\sum_{v \in S(u, K) \cap N(i)}\left|w_{u v}\right|}$$其中w为用户之间的相似度，可以通过皮尔逊系数来计算：$$w_{u v}=\frac{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right) \cdot\left(r_{v i}-\bar{r}_{v}\right)}{\sqrt{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right)^{2} \sum_{i \in I}\left(r_{v i}-\bar{r}_{v}\right)^{2}}}$$基于五瓶的领域算法在预测用户对物品的评价的时候，会参考用户对相似物品评价的评分：$$\hat{r}_{u i}=\bar{r}_{i}+\frac{\sum_{j \in S(u, K) \cap N(u)} w_{i j}\left(r_{u j}-\bar{r}_{i}\right)}{\sum_{j \in S(i, F) \cap W(u)}\left|w_{i j}\right|}$$其中w为普通的优先相似度、皮尔逊系数，修正的余弦相似度三种之一，具体那种效果好，需要看具体的实验。 隐语义模型与矩阵分解模型评分系统可以写成一个评分矩阵R，其中每一个位置就是用户对物品的一个评分。传统的方法通过降维的方式对评分矩阵进行填充。 传统的SVD分解 一个直观的想法就是，补全之后的矩阵对不全之前的矩阵扰动最小，补全后的特征值和补全之前的特征值相互差异不大。 一开始可以使用全局平均值对矩阵进行填充，然后进行矩阵的SVD分解，然后选择其中特征向量topN保留，得到一个降维之后的评分矩阵。 SVD分解有一个问题，就是它本上是十分稀疏的，95%都是空的，但是通过这种方式进行填充之后变得非常的大，计算复杂度很高，难以实际应用。 simon Funk SVD simon对传统的SVD进行改造，直接将评分矩阵分解成两个低维度的矩阵相乘：$$\hat{r}_{u i}=\sum_{f} p_{u f} q_{i f}$$于是通过最小化RMSE误差，加上参数的正则化项，从而得到：$$C(p, q)=\sum_{(u, i) \in \mathrm{Train}}\left(r_{u i}-\sum_{f=1}^{F} p_{u f} q_{i f}\right)^{2}+\lambda\left(\left|p_{u}\right|^{2}+\left|q_{i}\right|^{2}\right)$$通过随机梯度下降法，去学习p，q矩阵，最终得到评分表中的缺失的评分。 加入偏执的LFM 在上一个方法的基础上，有人提出了许多改进的方法，提出了很多偏执，对算法进行修正：$$\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}$$u为评分的全局平均数，b为用户喜好的偏执（用户评分随意或者很苛刻的情况），后一个b为物品品质的偏执（评分都很高，或都很低的情况）。 加入时间信息 基于领域的融合时间的模型，考虑用户评分年时间对推荐结果的影响：$$\begin{equation}\hat{r}_{u i t}=\frac{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right) r_{u j}}{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right)}\end{equation}$$ $$\begin{equation}\begin{array}{c}{f\left(w_{i j}, \Delta t\right)=\sigma\left(\delta \cdot w_{i j} \cdot \exp \left(\frac{-|\Delta t|}{\beta}\right)+\gamma\right)} \ {\sigma(x)=\frac{1}{1+\exp (-x)}}\end{array}\end{equation}$$ 随着$\Delta t$d的变大，影响力就会变小。 模型的融合 模型融合基本上分成两种方式： 模型级联融合，上一个模型的输出最为下一个模型的输入，每个模型在上一个模型的基础上进行学习。 模型加权融合，用K个模型去预测最终的结果，首先将训练集A分成A1，A2，然后在A1上训练K个模型，利用A2训练集，去学习每个模型的权重。然后在B上进行最终的评分预测，这样的好处就是防止模型过拟合。 其他时间上上下文信息 用户的兴趣以及推荐的物品与时间的关系十分的相关，必要将时间加入到推荐算法当中去。例如在协同过滤的基础上加上时间衰减函数，如判断两个物体的相似性：$$\begin{equation}\operatorname{sim}(i, j)=\frac{\sum_{u \in N(0) \cap N(i)} f\left(\left|t_{u i}-t_{u |}\right|\right)}{\sqrt{|N(i)||N(j)|}}\end{equation}$$其中时间衰减函数如下：$$\begin{equation}f\left(\left|t_{u i}-t_{u j}\right|\right)=\frac{1}{1+\alpha\left|t_{u i}-t_{u j}\right|}\end{equation}$$当两个商品购买的时间相差比较远的话，时间衰减函数那一项就会比较小。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(三) 资源管理]]></title>
    <url>%2F2019%2F11%2F05%2Feffective-cpp-%E4%B8%89-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[2019/11/05 effective cpp 第三章 CPP程序运行中，将会动态申请内存、文件描述器、互斥锁等一些重要的资源，必须及时归还系统。 13 条款：以对象管理资源 14 条款： 13 条款：以对象管理资源若一个基类通过一个工厂函数，得到若干个子类的地址指针，在使用完这些子类之后，需要将他们回收，下面写一个回收的函数对他们进行回收： 12345void f()&#123; Invest* ptr = create(); ... delete ptr;&#125; 上述的代码可以完美的运行，但是在一些特定的情况下，如果程序在delete之前中途退出了，这将导致分配的资源无法得到释放。一个比较可靠的做法是： 把资源放进对象内，当需要销毁资源的时候，使用C++的析构函数自动调用机制，确保资源的释放。 auto_ptr 许多资源被动态分配到heap内，被用于函数内。它们应该在控制流离开那个函数的时候被释放，auto_ptr智能指针就是为此设计的一个类指针对象，由析构函数对其所指对象调用delete。 123void f()&#123; auto_ptr&lt;invest&gt; Ptr(create());&#125; 上述的做法体现了两条回收资源的设计： 获得资源后，立即放入管理对象内：资源对象创建的最佳时期就是资源获取的时机。最好的方式是获取资源的同一个语句内使用它初始化某个管理对象 管理对象运用析构函数确保资源被释放：不论控制流如何离开区块，一旦对象被销毁，析构函数自动销毁所获得的资源。 auto_ptr对象离开它的有效范围之后，就将自动销毁分配的资源。但是有一个缺陷，它不允许多个auto_ptr指向同一块区域，这样会造成一个对象被多次的删除。为了防止这个问题，auto_ptr中有一个特性，如果通过拷贝函数复制他们，之前的指针将会变成null，复制后的指针得到资源的唯一拥有权。 12auto_ptr&lt;invest&gt; ptr1(create());auto_ptr&lt;invest&gt; ptr2(ptr1); // 此时ptr1变成null auto_ptr的替代方案使用tr1::shared_ptr，这个对象类将持续追踪共有多少指针指向某个资源，但是在环形引用时无法打破。 1234void f()&#123; tr1::shared_ptr&lt;invest&gt; ptr(create()); tr1::shared_ptr&lt;invest&gt; ptr1(ptr); // ptr，ptr1指向同一个对象&#125; 上述例子告诉我们，当我们手动释放资源的时候，容易发生错误，罐装式的资源管理类如auto_ptr, shared_ptr可以比较好的准守这条规则。 总结 防止资源浪费，使用RAII对象，在他们的构造函数中获得资源，在析构函数中释放资源。 使用RAII中的tr1::shared_ptr，auto_ptr是两个比较好的选择，shared_ptr具有比较正常的copy。 14 条款：在资源管理类中小心copying行为通常使用auto_ptr,shared_ptr作为资源管理类，但是有些资源并非在heap-based，不实用使用上述的两种资源管理类，因此需要建立自己的资源管理类。 自己定义的资源管理类通常在构造函数的部分申请得到资源，在析构函数中释放资源，这种类型的资源包括了互斥锁。 123456789class Lock&#123; public： explicit Lock(Mutex* pm):mutexPtr(pm)&#123; // 在初始化资源类的时候，初始化资源 lock(mutexPtr); &#125; ~Lock()&#123;unlock(mutexPtr);&#125; private: Mutex* mutexPtr;&#125; 同样的，对于资源管理类来说，如果对象被复制，我们需要处理对象的复制问题。可以让它继承UnCopyable对象，禁止对象的复制。或者使用shared_ptr的方法，使用引用计数法，使用shared_ptr来定义指针。 1shared_ptr&lt;Mutex&gt; mutexPtr; 这时候就可以不用定义虚析构函数了，当指针被回收的时候，资源就会被回收。 转移底层的资源拥有权 使用类似于auto_ptr的做法，copy的时候，保证资源的唯一性。 总结 复制RAII对象（资源管理对象）需要一并复制它所管理的资源，资源的copying行为决定了RAII对象的copying行为。 普遍常见的RAII copying行为通常为：抑制copying，使用引用计数法，转移底层资源的拥有权。 15 条款：在资源管理类中提供对原始资源的访问资源管理类通常是我们设计来保证资源的正常申请和销毁的，但是有些情况是，我们调用一些函数的时候需要直接访问内部的资源（例如一些指针类）： 12str1::shared_ptr&lt;Invest&gt; pInt(create()); // pInt是一个资源类对象int daysHeld(const Invest* pi); // pi是一个invest* 对象 当我们要调用daysHeld()函数的时候，传入的参数如果为pInt的话会发生错误，因为pInt是一个资源类对象，因此我们需要从这个资源类对象中取出其中的指针资源。 1daysHeld(pInt.get()); shared_ptr,auto_ptr继承了原是指针中的-&gt;,*操作，并且可以通过get函数得到资源的直接访问。 当我们选择自己实现资源管理类的时候，我们也需要实现一个get函数，实现显示的函数变换。 12345678class Font&#123; public: explicit Font(Fhandle fh):f(fh)&#123;&#125; ~Font()&#123;release(fh);&#125; FHandle get() const &#123;return fh;&#125; // 实现直接获取资源的函数 private: FHandle fh;&#125; 通过实现operator FHandle() const {return fh;}函数可以实现隐式的变换，但是这样容易造成错误的发生，因此建议使用显式的变换（get的方式）。 总结 API中往往要求访问原始资源，所以每一个RAII类中应该要实现一个直接获取志愿的方法（get方法）。 对原始资源的访问可能是显式变换或者隐式的变换，一般而言显式变换比较安全。 16 条款：成对使用new和delete时要采取相同形式new在被使用的时候，可以申请单个内存（new int）或多个内存（new int[10]），delete再回收内存的时候，也有回收单一内存和连续内存的区别，需要注意的是，new和delete行为必须一致（单一内存和多内存的一致。） 总结 new中使用[]必须在delete中也使用[]（连续内存），new中不使用[]，delete中也不能使用[]（单一）。 下面补充一下CPP中new和delete的用法： new的使用 new负责C++中的动态内存分配，动态内存位于heap上。在不使用这段内存的时候，程序需要负责将这段内存回收掉。 new指令初始化内存，返回内存分配的初始地址： 12pointer-variable = new data-type;int* p = new int; 可以使用括号的方式初始化对象： 1int* p = new int(10); 使用中括号[]的方式分配一整块内存空间： 1int* p = new int[10]; 传统的申请内存的方式为int a[10]; 这个空间由编译器申请，在使用结束之后也由编译器进行回收。但是自己申请的内存会一直存在，直到自己delete处理掉。 delete的使用 使用delete对new申请的数组进行清空： 12delete p; // 删除单个元素delete[] p; // 删除整段空间 17 条款：以独立语句将newed对象置入智能指针可以使用智能指针的方式来管理new申请的内存： 1str1::shared_ptr&lt;Widget&gt; pw(new Widget); 存在一种情况，当我们使用资源管理类来管理内存的时候，可能会出现内存泄漏。 1process(str1::shared_ptr&lt;Wdiget&gt;(new Widget),priority()); 上面代码可能的执行顺序是(顺序不一定)： new widget priority Shared_ptr构造函数 如果第二步抛出异常，那么造成内存泄漏，因此：newed对象应当写一个单独的语句。 12str1::shared_ptr&lt;Widget&gt; pw(new Widget);process(pw,priority()); 总结 以单独的语句将newed对象存储在智能指针内，确保资源不会泄露。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[推荐系统之用户标签数据(二)]]></title>
    <url>%2F2019%2F11%2F05%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[推荐系统的目的是链接用户的兴趣和物品，通常的连接方式可以通过： 推荐与用户喜欢的物品相似的物品 推荐与用户兴趣相似的人所喜欢的物品 给用户推荐那些他喜欢的特征，例如利用用户标签 标签是一种无层次化结构的，用来描述信息的关键词，它可以用来描述物体的语义。 标签系统中推荐问题用户为什么进行标注 用户通常会给予社会维度、功能维度、传达信息的维度上对物品进行标注。 用户如何打标签 用户打标注的标签同样符合一个长尾分布，一些不流行的标签呈现一个长尾。 用户打什么样的标签 表明物品是什么 物品的种类 用户的观点 谁拥有用户 用户相关的标签 用户的任务 类型 时间，人物，地点，语言，奖项 基于标签的推荐系统数据的设计 一个用户标签的行为的数据集一般由一个三元组的集合表示：(u,i,b)表示用户u给物品i打上了标签b。将数据随机分成10份，分割的键值是用户和物品，其中9份作为训练集，1份作为测试集。 实验指标 准确率、召回率、覆盖率、余弦相似度、新颖性（平均热门度） 一个简单的算法 利用用户标签进行个性化的推荐，一个直接的想法： 统计每个用户最常用的标签 对每个标签，统计被打过这个标签次数最多的物品 对每个用户找到他最常用的标签，然后给他推荐具有这些标签的最热门的物品 因此可以归纳出兴趣公式：$$p(u, i)=\sum_{b} n_{u, b} n_{b, i}$$$n_{u,b}$表示用户u打过标签b的次数，$n_{b,i}$ 表示物品i被打过b标签的次数。 算法的改进：TF-IDF 对于热门标签，它在许多物品上都有出现过，因此上述的公式对热门标签对应的热门物品给了过大的权重，系统将会倾向于推荐热门的物品，因此将降低推荐结果的新颖性，因此对热门标签进行惩罚：$$p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} n_{b, i}$$此外对热门物品进行惩罚：$$p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} \frac{n_{b, i}}{\log \left(1+n_{i}^{(u)}\right)}$$数据稀疏性 对于一些新用户或新物品，用户集合中的标签数量很小，可以我们可以将与已有标签相似的标签加入到用户标签中。 可以利用基于领域的方法，当两个标签同时出现在许多物品的标签集合中时，我们就可以认为这两个标签具有较大的相似度，可以使用余弦相似性进行计算，计算的方式时两个标签的交集除以他们的各自的平方开根号。$$\operatorname{sim}\left(b, b^{\prime}\right)=\frac{\sum_{i \in N(b) \cap V(b)} n_{b i} n_{b ; i}}{\sqrt{\sum_{i \in N(b)} n_{b, i}^{2} \sum_{i \in N(b)} n_{b^{\prime}, i}^{2}}}$$标签清理 有许多标签仅仅反应了用户的心情（例如不好笑），不能作为用户的兴趣，我们需要对这类标签进行过滤。去除一些停止词，同义词，等等方式去除不良标签。 给用户推荐标签给用户推荐标签指给出一些选项供用户选择，这样的好处有： 方便用户输入标签 提高标签的质量 如何给用户推荐标签 给用户推荐系统中推荐最热门的标签 给用户推荐物品i上最热门的标签 给用户推荐他常用的标签 结合上述两种方法的加权结果（用得最多）]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp (二) 构造、析构、赋值运算]]></title>
    <url>%2F2019%2F11%2F02%2Feffective-cpp-%E4%BA%8C-%E6%9E%84%E9%80%A0%E3%80%81%E6%9E%90%E6%9E%84%E3%80%81%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[2019/11/02，effective cpp 第二章 05条款：了解C++默默编写并调用哪些函数 06条款：若不想使用编译器自动生成的函数，就该明确拒绝 07 条款：为多态基类声明virtual 析构函数 08 条款：别让异常逃离析构函数（不传播） 09 条款：绝不在构造和析构过程中调用virtual函数 10 条款：令operator= 返回一个reference to *this 11 条款：在operator=中处理自我赋值 12 条款：复制对象时勿忘其每一个成分 05 条款：了解C++默默编写并调用哪些函数在一个类中，当你自己没声明，C++编译器将会替你生成的函数有： 1234567class entry&#123;public: entry()&#123;...&#125; //默认构造函数 ~entry(const entry&amp; rth)&#123;...&#125; // copy 构造函数 ~entry()&#123;...&#125; // 析构函数 entry&amp; operator=(const entry&amp; rhs)&#123;...&#125; //等号运算符重载&#125; 上述的四个函数，分别负责对象的创建和销毁工作。其中default和析构函数用于防止一些幕后的代码，如调用父类的构造函数等。 copy构造函数和等号函数，起到的作用是将对象内每一个元素拷贝到目标对象上。 存在一个例外，如果成员变量不可以改变值的时候，例如成员变量含引用的时候（string&amp; name;）,含有const成员的时候，由于这些类型初始化之后，不允许改变它的值，因此系统不会为这些类生成copy构造函数以及重载等号初始化。 总结 编译器可以暗自生成构造函数，析构函数，copy构造函数，copy assignment操作符。一些含reference，const成员的函数，将不会产生copy，等号重载这两个函数。 06 条款：若不想使用编译器自动生成的函数，就该明确拒绝某些情况你不希望对象具有copy，等号这些操作，你就该明确拒绝。可以将copy，copy assignment申明成private，并且故意不去实现他们（只有声明没有实现），这样就能有效的阻止人们调用它，同时当类的friend函数调用的时候，将返回连接错误。 此外，还可以继承一个不可拷贝的对象，如： 123class homeforsale:private Uncopyable&#123; ...&#125;; 其中Uncopyable的copy和copy assignment函数声明为private，而且未提供实现，这样可以将赋值的错误转移至编译期间。 总结 为了阻止编译器自动添加一些函数，可将相应的成员函数声明为private并且不写实现过程。使用Uncopyable这样的base class也是一种方法。 07 条款：为多态基类声明virtual 析构函数例如一个基类实现了计时的功能，然后它派生出去的许多类，分别代表了不同特点的时钟。因此可以设计factory工厂方法，返回指针指向一个父类的计时对象，父类对象根据子类的指针类型得到一个子类的指针对象。 当我们通过上述的方法，生成了很多basic class指针（指向派生类），当我们希望回收内存的时候，使用delete方法释放内存，这时候C++只会调用basic class的non-virtual的析构函数。因此只对属于basic class部分的成员内存进行了释放，子类的内存无法得到释放。 解决上面的问题就是将basic class的析构函数定义为virtual，这样在释放指针所指空间的内存的时候，就可以就调用相应的子类的析构函数，销毁整个对象。 通常基类都会定义virtual的函数，供不同的子类指针调用，通常这类函数都需要有一个virtual的析构函数： 12345class entry&#123;public: ... virtual ~entry();&#125; 不含virtual的类基本上也不会加virtual的析构函数，因为加上virtual之后函数器对象需要加上徐函数的指针表，对象的大小会增加。 也不要在程序中继承一些带有non-virtual析构函数的class，因此如何你打算回收这个对象的时候，往往没办法完全回收内存。 倘若你想要将基类设计成一个抽象类，即不能实例化的一class，你可以选择将析构函数做成一个纯虚的析构函数，并且提供一份空的定义： 123456class AWOV&#123; virtual ~AWOV() = 0; ...&#125;AWOV::AWOV()&#123;&#125; // 提供一份空的实现 当执行析构的时候，最深层的派生class的析构函数最先被调用，因此调用到AWOV这个类的析构函数。 总结 含多态性质的base class应该声明一个virtual析构函数，如果class 带有任何virtual函数，他就应该拥有一个virtual析构函数。 classes的设计目的如果不是作为base classes使用，或不是为了具备多态性，就不该声明virtual 08 条款：别让异常逃离析构函数（不传播）C++你并不能禁止析构函数吐出异常，因为例如在程序销毁的时候，析构函数将会销毁其构建的所有对象，当重复的对象在销毁的时候抛出异常，那么所有的这些对象在销毁的时候，都将会抛出异常，而多于一个异常被抛出的情况，将会导致不明确的行为。 1234567class DBConn&#123;public: ... ~DBConn()&#123; db.close(); // 在DBConn的析构函数中，将会调用db.close()，然而db.close可能会发生异常，导致不明确的事情 &#125;&#125; C++不喜欢析构函数吐出异常，这将导致函数的提前结束或出现不明确的行为 因此，如果在析构函数中出现异常，函数应该选择吞下这个异常，而不是抛出异常。如果必须对这个异常进行处理的话，应该提供一个普通函数来处理这个异常，而不是在析构函数中。 1234567891011121314151617181920212223DBConn::DBConn&#123; public: try&#123;bd.close();&#125; catch&#123;...&#125;&#123; std::abort(); // 终止程序,主动对异常进行捕获，而不是抛出 &#125;&#125;// 或者在一个普通函数中进行异常的捕获void close()&#123; db.close(); closed = true;&#125;~DBConn()&#123; if(!closed)&#123; try&#123; db.close(); &#125; catch(...)&#123; ... &#125; &#125;&#125; 总结 析构函数绝对不要吐出异常，如果一个被析构函数调用的函数可能抛出异常，那么析构函数应该去捕获异常，（try，catch）然后吞下它们或结束程序。 如果客户需要对某个函数在运行期间抛出的异常做出反应，那么class应该提供一个普通函数执行该操作。 09 条款：绝不在构造和析构过程中调用virtual函数在构造或析构函数中，如果在函数中调用虚函数，在子类的构造函数往回回溯的时候。这时候在父类中执行构造函数，构造函数内部的虚函数调用的是base class的版本，而不是子类的版本。 在derived class对象的base class构造期间，对象的类型是base class，而不是derived class版本。如果使用了运行期类型信息，那么这时候也是base class的类型信息。 1234567class transaction&#123; public: transaction()&#123; logtransaction(); // 构造函数中的virtual函数只会使用base class（本类）的版本 &#125; virtual void logtransaction() const;&#125; 总结 在构造和析构期间不用调用virtual函数，因为这类调用从不下降至derived class（即这个版本的virtual函数不是你想要的那个。） 10 条款：令operator= 返回一个reference to *this关于重载等号=赋值运算符，由于赋值运算符可以连续赋值，形如：x=y=z=15，因此赋值运算符必须返回一个reference指向操作符的左侧实参，这是你为class需要遵循的协议： 123456789class Widget&#123; public: ... widget&amp; operator=(const widget&amp; rhs)&#123; ... return *this; // this调用=运算符，rhs为参数，返回this等于返回左边元素的引用 &#125; // 上述协议同样适用于+=，以及参数是其他类型的情况&#125; 上述写法只是一个协议，在CPP所有内置类型以及标准程序库中提供的类型都将共同准守。 总结 令赋值操作返回一个reference to *this的引用。 11 条款：在operator=中处理自我赋值自我赋值指的是自己给自己赋值的情况，这种情况通常出现在引用后指针的自我赋值上。例如一个类用来保存一个指针指向一块动态分配的位图： 12345678910class Bitmap&#123;...&#125;;class widget&#123; private: Bitmap* pb; widget&amp; operator=(const widget&amp; rhs)&#123; delete pb; // 这种方式可能造成不安全，当pb和rhs.pb指向同一块地址的时候，两个指针的对象会被删除 pb = new Bitmap(*rhs.pb); return *this; &#125;&#125; 上述的危险可以使用验证是否相同的方式来化解： 1234567891011121314widget&amp; widget::operator=(const widget&amp; rhs)&#123; if(*this == &amp;rhs) return *this; delete pb; pb = new Bitmap(*rhs.pb); return *this;&#125;//但是每次都要进行判断，效率不是很高，下面通过调换赋值的顺序，达到同样的效果widget&amp; widget::operator=(const widget&amp; rhs)&#123; Bitmap* pOrig = pb; pb = new Bitmap(*rhs.pb); // 令pb指向一块新的pb的副本地址 delete pOrig; return *this;&#125; 总结 确保当对象自我赋值的时候，operator=有良好的行为，利用来源对象和目标对象的地址，语句的顺序等等，避免将自身对象删除。 确保当函数操作一个以上对象的时候，它的行为是正确的。 12 条款：复制对象时勿忘其每一个成分当我们为一个类写copy构造函数和copy assignment构造函数的时候，编译器则会有一个报复行为，就是当你的类中新添了成员变量的时候，而未修改copy构造函数为这个值赋值的时候，编译器也不会报错： 12345678910111213141516class Customer&#123; public: ... Customer(const Customer&amp; rhs); Customer&amp; operator=(const Customer&amp; rhs); private: string name;&#125;Customer::Customer(const Customer&amp; rhs):name(rhs.name)&#123; do something else;&#125;Customer&amp; Customer::operator=(const Customer&amp; rhs)&#123; name = rhs.name; do something else; return *this;&#125; 上面的代码可以正常的执行，但是当加入一个int age;的成员变量的时候，如果你忘记修改了上面的copy，assignment函数，编译器也不会提醒你，因此： 如果你为class添加了一个成员变量，你必须同时修改copy和assignment，否则编译器也不会提醒你。 当你为一个子类函数重写copy和assignment函数的时候，这种事情仍然会发生： 12345678910111213141516class Customer: public Person&#123; public: ... Customer(const Customer&amp; rhs); Customer&amp; operator=(const Customer&amp; rhs); private: string name;&#125;Customer::Customer(const Customer&amp; rhs):name(rhs.name)&#123; do something else;&#125;Customer&amp; Customer::operator=(const Customer&amp; rhs)&#123; name = rhs.name; do something else; return *this;&#125; Customer继承自Person对象，现实Customer的copy的时候没有对Person对象传递参数，那么编译器将会调用default构造函数，Person的数据并不会被拷贝到新的对象中，因此： 我们在重写子类的copy函数的时候，需要调用base class 的copy函数。 12345678Customer&amp; Customer(const Customer&amp; rhs):Person(rhs),name(rhs.name)&#123; do something else;&#125;Customer&amp; Customer::operator=(const Customer&amp; rhs)&#123; Person::operator=(rhs); do something else; return *this;&#125; 因此当你编写一个copying函数，请确保（1）复制多有的local变量。（2）调用所有base classes内的适当copying函数。 总结 copying函数应当确保复制对象内的所有成员变量，以及所有base class成分 不要尝试以某个copying函数实现另一个copying函数，可以将相同代码的部分单独提取出来，放到init函数中。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[推荐系统之协同过滤（一）]]></title>
    <url>%2F2019%2F11%2F02%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[基于领域的算法是推荐系统中最为基本的算法，这篇post主要针对其中重要的两类算法：基于用户的协同过滤，基于产品的协同过滤进行介绍。 长尾效应在需求曲线中，少量的需求会形成一条长长的尾巴，将所有非流行的需要累加起来，将会形成一个比流行市场还要庞大的市场。 长尾效应最直接的原因就是强调用户的个性化，将市场需求细分，这些小的需求市场的累积效应将形成巨大的理论。 推荐系统的一个迫切需求在于，存在信息过载以及用户需求不明显的问题，因此需要将用户感兴趣，或有潜在兴趣的商品推荐给用户。 实验设计在介绍协同过滤之前，我们粗略设计一下算法的流程。 将用户数据均匀成M（m = 8）份，挑选其中一份作为测试集。重复进行M次实验。（交叉验证，防止过拟合） 在训练集上训练用户兴趣模型，在测试集上进行预测，统计评测指标。 将M次实验结果的平均值作为最后的测评指标。 测评指标 召回率：recall = (用户感兴趣 与 推荐商品交集) / （推荐商品的总数） 准确率：precision = (用户感兴趣 与 推荐商品交集) / （用户感兴趣物品集合） 覆盖率：coverage = （推荐商品） / （总商品） 平均流行度：每个物品流行度的对数值（流行度满足长尾，取对数更加的稳定） 新颖度：新颖度可由流行度度量，负相关。 基于用户的协同过滤算法基于用户的协同过滤算法是推荐算法中最古老的算法，在1992年被提出（很年轻的领域）。主要包括两个部分： 找到和目标用户兴趣相似的用户集合 找到这个集合中用户喜欢的，但目标用户中没有产生过行为的，推荐给目标用户 找出目标用户兴趣群 如何判断两个用户的相似性，可以使用用户感兴趣物体N(u)的相似性来代替用户的相似性，使用Jaccard相似度，计算u，v用户的相似度：$$w_{u v}=\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}$$或者使用余弦相似度计算：$$w_{u v}=\frac{|N(u) \cap N(v)|}{\sqrt{|N(u)||N(v)|}}$$在具体的计算时，我们只关注两个用户之间存在交集的那部分商品： 首先建立一个商品为表头的链表，链表上的节点是对该商品发生过行为的用户。 随后建立一个用户与用户之间的相似矩阵，如果这两个用户出现在同一个链表中k次，则用户之间的数组值为k。相似矩阵作为余弦相似度的分子，总数作为分母，计算得到用户之间的相似度。 给目标用户提供与他相似度topK用户喜欢的产品。 用户相似性的改进： 对于一些热门的产品，大家可能都会去购买，比如面包大家都会买，但是购买用户之间的相似性就天差地别了，换句话说，冷门商品更能说明用户兴趣，因此需要对热门商品进行惩罚：$$w_{u v}=\frac{\sum_{i \in N(u) \cap N(v)} \frac{1}{\log (1+|N(i)|)}}{\sqrt{|N(u)||N(v)|}}$$分子是u，v用户共同感兴趣的物品i，N(i)表示对i发生过行为的所有人的集合，i越热门惩罚越大。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[effective cpp(一) 让自己习惯cpp]]></title>
    <url>%2F2019%2F10%2F31%2Feffective-cpp-%EF%BC%88%E4%B8%80%EF%BC%89-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFcpp%2F</url>
    <content type="text"><![CDATA[2019/10/31，effective cpp第一章： 01条款：视c++为一个语言联邦 02条款：尽量以const, enum,inline替换 #define 03条款：尽可能使用 const 04条款：确定对象被使用前已被初始化 01 条款：视c++为一个语言联邦c++最初从c语言发展而来，最初的名称是c with classes，同时这们语言接受了很多的不同的观点，特性，和编程的设计。使得cpp有着巨大的弹性和威力，因此在cpp不同的语言领域内，将有不同的最优用法。 cpp有着四个主要的次语言： C语言，cpp很多编程上的特性继承至C语言 面向对象的C++：很多关于类的操作在这一部分引入 template C++：C++的范型编程，唯template适用 STL：标准模板库，里头有着大量的容器，迭代器等 总结 C++由上面四种次语言组成，不存在一组高效编程的守则，而是视适用的次语言而定。 02 条款： 尽量以const, enum,inline替换 #define将cpp程序转化成机器能够看懂的语言，需要经过预处理，编译，汇编，链接这些步骤。#define在预处理阶段就会被处理： 1#define RATIO 1.25 在编译器处理源代码阶段，define定义的符号将会被移走，因此RATIO可能根本就没进入符号表。当出现错误的时候，根据报错信息将很难定位错误，因此最好将define进行替换，也就是编译器替换预处理器。 符号表 符号表在程序的编译阶段，将函数以及变量名地址记录起来，在链接阶段，根据符号表中记录的内容，去链接程序。 用const替换define 1const double ratio = 1.25; 由于常量的定义经常在头文件之中，因此定义常量指针的时候，通常也将指针定义成const。 1const char* const author = "names"; 当我们需要创建一个类的常量的时候，需要在声明的时候，加一个static，使得这个常量只有一份实体，而且将这个常量的定义域限制在类内。 最后可以使用enum来代替define： 12enum&#123;num1 = 1,num2 = 2&#125;;cout &lt;&lt; num1 &lt;&lt; num2; enum将数字符号化，也无法取到enum的地址。 此外，使用宏定义的另外一部分作用是定义一个简单的函数，避免函数调用带来的麻烦，同时不必要制定变量的类型（需要是同一个类别的），在宏定义的时候，注意为我每一个变量添加一个括号。 但是我们完全没必要去定义define，而是使用inline去替代： 1234template&lt;typename T&gt;inline void callwith(const T&amp; a ,const T&amp; b)&#123; f(a&gt;b ? a:b); // 谁大调用谁&#125; 总结 对于单纯的变量，使用const，enum替换define 对于宏定义的函数，改成template + inline的形式 条款 03：尽可能使用 constconst的原则，你在可以使用它的时候就使用它， const 是一个语义的束缚，说明内容不可修改，因此只要有这样的一种约束在，就应该声明出来，获得编译器的协助。 const声明指针的时候有以下几种方式： 12345char greeting[] = "hello";const char* p = greeting; // 指针所指内容为constchar const* p = greeting; // const在*左边，与上相同char* const p = greeting; // 指针为const，内容可变const char* const p = greeting; //指针，内容都不变 令函数的返回值为一个常量值，往往可以降低造成意外的风险 函数的返回值，正常不应该作为一个变量来被其他赋值，因为这个不符合逻辑，如果可以被直接赋值的话，函数就没什么用了。因此对于大多数函数的返回值来说，可以加上const。 const成员函数 const成员函数指的是在一个类里头，这个函数用const进行了标注，表明这个函数是只读的不可以在函数内部对数据成员进行修改，格式如下,const在函数的最后： 123456class A&#123;public: const char&amp; operator[](int position) const&#123; return tex[position]; &#125;; &#125; 将函数定义成const，可以容易得知这个函数无法修改对象的值；同时使得操作const对象成为可能。 真实程序中，const对象大多用于传参数，passed-by-pointer-to-const；passed-by-reference-to-const. 123void point(cosnt TextBlock&amp; ctb)&#123; cout &lt;&lt; ctb[0];&#125; 在一些类中，const标注的函数其内部不允许对成员数据进行修改，但是也存在例外，mutable变量定义的变量将改变一些值的const属性，允许在const函数中修改： 12345678910class block&#123;public: mutable int len; int length() const;&#125;int block::length() const&#123; len = 10; return len; &#125; const和non-const函数允许函数进行重载，但是在使用的时候应该避免写两个函数，而是在non-const函数中，通过类型的转换来调用const类型的函数。 1234567891011class block&#123;public: const char&amp; operator[](int position) const&#123; ... &#125; char&amp; operator[](int position)&#123; return const_cast&lt;char&amp;&gt;(static_cast&lt;cosnt block&amp;&gt;)(*this)[position]; // const_cast 去掉const // static_cast 将this转换为const类型，调用上一个函数 &#125;&#125; 总结 const可以施加于任何作用域内的对象，函数参数，返回值，成员函数。 在能够使用const的时候尽量使用const，利用编译器规则为你排除错误。 编译器强制实行bitwise constness，编写程序的时候应该遵守逻辑上的const（避免const函数，有些指针是const，但是其内部的值可以修改）。 const和非const函数有本质上的相似的话，应该使用non-const的版本去调用，避免代码重复。 条款 04：确定对象被使用前已被初始化由于cpp是一个语言联邦，因此它并不保证所有的对象都会被初始化。因此：在使用对象之前先将对象进行初始化。 特别值得注意的是，在对成员函数进行初始化时，在构造函数本体内进行的的并非初始化，而是赋值操作。cpp规定，对象的成员变量的初始化动作发生在进入构造函数本体之前。因此将成员初始化写在初始化成员列表中，如下： 123456789101112131415class AB&#123;public: int aa; int bb; AB(int a,int b);&#125;AB::AB(int a,int b)&#123; // 这种方式时赋值，初始化之后又做一遍赋值，效率很低 aa = a; bb = b;&#125;// 修改版本如下：AB::AB(int a,int b):aa(a),bb(b) // 构造初始化表，效率比较高&#123; ...&#125; 此外，对于不同单元内定义的static变量，他们的初始化次序是不确定的。static对象，他们的寿命从构造出来一直到函数的结束。定义在函数内部的称为local static，定义在其他地方位置的称为non-local static，由于定义在不同编译单元的non-local-static中初始化的顺序不同，如果另一个初始化单元，用到了一个未被初始化的static的话，可能会发生很不好的事情，因此：将每个non-local-static对象搬到自己的专属函数内，这些函数返回一个reference对象，然后指针直接调用这些函数。这样你在调用这个函数之前，这个变量将会被初始化。 总结 为内置的对象进行初始化，cpp不会保证初始化 构造函数最好使用成员初始化列表的方式进行初始化，成员的次序应该于定义的顺序相同 为了免除跨编译单元初始化次序问题，最好将non-local-static变量变为local static，定义在函数内部，函数返回一个该对象的引用。]]></content>
      <categories>
        <category>effective cpp</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FastFCN: 大工不巧]]></title>
    <url>%2F2019%2F10%2F31%2FFastFCN-%E5%A4%A7%E5%B7%A5%E4%B8%8D%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[FastFCN是自动化所2019年cvpr上的一个工作，提出JPU模块，代替dilated conv，在保证网络精度的前提下，大大降低网络的计算复杂度，是的FPS得到提升。 这些年来计算机视觉得到广泛的发展，网络结构也越来越复杂，这篇文章做了一些下修改，可以说耳目一新，结构十分简单，结果十分有效。 语义分割常用的提取feature map a）FCN结构：通过一个全卷积的网络，直接得到图像分割后的结果。缺点是图像中的特征丢失。 b）encoder-decoder结构：encoder结构得到高层次的特征，decoder阶段通过结合多层次的特征来得到一个多尺度融合的feature map，缺点是仍然存在数据的丢失（pooling 结构） c） DilatedFCN：利用空洞卷积替换pooling层，扩大feature map感受野的同时，没有降低feature map的分辨率。但是这种结构导致了很大的计算量。 ###JPU结构 作者提出JPU（joint pyramid upsampling）结构，替换DilateFCN中的空洞卷积结构，能够大大的减少内存以及时间上的消耗。 ###FastFCN结构 FastFCN的backbone采用的是原始的FCN的结构，将FCN的最后三层输入JPU模块中进行训练，最终在许多任务上都得到一个性能一致，但速度得到提升的网络。 mIoU：对每一类计算真实标签和预测标签的交并比，然后对所有类别求一个平均得到最后的结果。 总结这篇文章对FCN的网络中的dilated conv进行了一个很小的修改，达到一个比较合理的结果，文章非常的简单，不过可能是因为过于简单的原因，文中也有许多可有可无的内容，总之，对于做工程来说，得到一个FPS比较快的网络还是比较好的。]]></content>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于职业生涯规划以及时间安排的一些思考]]></title>
    <url>%2F2019%2F10%2F30%2F%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <tags>
        <tag>职业规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译器gcc，g++，clang，cmake，make介绍]]></title>
    <url>%2F2019%2F10%2F27%2F%E7%BC%96%E8%AF%91%E5%99%A8gcc%EF%BC%8Cg-%EF%BC%8Cclang%EF%BC%8Ccmake%EF%BC%8Cmake%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[这篇post主要介绍在mac上使用CLion编写cpp代码的时候，cpp编译以及链接的一些知识。 cpp程序编译执行过程 编译：将源代码翻译成机器语言，生成目标文件 预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。 编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。 汇编：将汇编代码翻译成目标机器代码.o文件。 链接：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。 cpp使用的编译器gcc，g++，clang gcc: 最开始的时候是 GNU C Compiler, 如你所知，就是一个c编译器。但是后来因为这个项目里边集成了更多其他不同语言的编译器，GCC就代表 the GNU Compiler Collection，所以表示一堆编译器的合集。 g++：是GCC的c++编译器。 clang：是mac上另起炉灶写的一个C语言、C++、Objective-C、Objective-C++语言的轻量级编译器。源代码发布于BSD协议下。Clang将支持其普通lambda表达式、返回类型的简化处理以及更好的处理constexpr关键字。 clang和gcc相比比gcc编译速度更快一些，而且错误提示更人性化。 make，cmake光有gcc还不够，如果这时候我们开发的工程使用的文件很多，那就需要一个一个去编译，工作量很大。一些大型的IDE如VS studio，CLion使用clang编译器，使用cmake链接工具，对源码进行编译。 make make类似于一个目录，是一个文件编译的批处理工具，本身没有编译的功能。make的作用就是告诉编译器，各种各样的编译规则，先做什么后做什么，这些规则写在makefile文件中。 make用于构建项目，其中一条很重要的规则就是依赖关系，当某些文件发生改变，直接或间接依赖这些文件的目标就要进行重新的构建。make用来构建管理文件，不一定用于编译。 cmake 构建一个项目需要了解构建的规则，并写出makefile文件，但是编译构建本身是个复杂过程，不同的项目构建规则会有所不同，要自己写出一个makefile文件比较困难。 cmake工具是根据平台（跨平台）和配置自动生成项目的makefile文件，然后给make使用。 cmake根据CMakeLists.txt文件（组态档）去生成makefile。在不使用CLion等这类IDE的情况下，这个CMakeLists.txt需要自己来写，下面是一个CMakeLists.txt： 1234567cmake_minimum_required(VERSION 3.8)project(First_Code)set(CMAKE_CXX_STANDARD 11)#set(CMAKE_CXX_FLAGS "-std=c++0x $&#123;CMAKE_CXX_FLAGS&#125; -g -ftest-coverage -fprofile-arcs")#set(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11")set(SOURCE_FILES main.cpp test.cpp assignment.cpp)add_executable(First_Code $&#123;SOURCE_FILES&#125;) 但是不用担心，CMakeLists.txt IDE也会负责生成。 C++11 C++11，（即ISO/IEC 14882:2011），是目前的C++编程语言的最新正式标准。它取代了第二版标准(第一版公开于1998年，第二版于2003年更新，分别通称C++98以及C++03，两者差异很小)。新的标准包含核心语言的新机能，而且扩展C++标准程序库。C++11新标准由C++标准委员会于2011年8月12日公布，并于2011年9月出版。此次标准为C++98发布后13年来第一次重大修正。 gcc4.7以及之后，全面支持c++11。 MAC更换CLion编译器在terminal输入gcc -v发现出来的是APPLE的clang编译器，由于更习惯使用GUN的gcc编译器，因此打算安装一个，同时保留原有的clang。 12brew search gcc // 查看有哪些gccbrew install gcc //安装最新版本的gcc，目前电脑上用的是gcc9.2 上诉过程安装完成之后，gcc的位置在： 1/usr/local/Cellar/gcc/9.2.0_1/bin 将这个路径加入到CLion所使用的编译器上，同时修改cmake参数(preference 中修改)： 1-D CMAKE_CXX_COMPILER=/usr/local/bin/g++-9 CLion 中新建项目的目录结构CLion是通过cmake来构建文件的，手动在CLion中生成cpp文件，系统件制动修改cmakeLists.txt]]></content>
      <tags>
        <tag>learning cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp STL方法介绍]]></title>
    <url>%2F2019%2F10%2F27%2Fcpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[这篇post主要目的是对cpp提供的Standard Template Library标准模板库中一些重要的方法进行学习，记录，以便今后学习。 STL概述在开始STL之前，像大家介绍一下一个全能的头文件： 1#include&lt;bits/stdc++.h&gt; 这个头文件include了在STL中所有的头文件，方便我们使用而不用去担心这些方法所在的库。 STL库中有四类重要的部分： Algorithm：该部分提供的算法定义在容器上，用于操作容器上的元素。 containers：定义了一些常用的容器，如vector，map等等 functor：算子，是个函数，用于定制化STL函数，如sort，传入functor定制排序方式 iterator：迭代器，用于遍历整个序列 algorithmsort(begin_adress,end_adress,compare) 排序算法是定义在所有容器上的一个排序函数，其内部实现是快排，时间复杂度是$O(nlogn)$. 12345678910111213int arr[10] = &#123;9,4,5,3,6,2,7,0,1,8&#125;;sort(arr,arr+10); //升序排序sort(arr,arr+10,greater&lt;int&gt;()); // 降序排序// 特殊数组的排序struct interval&#123; int val1; int val2;&#125;;interval arr[] = &#123;&#123;2,2&#125;,&#123;4,3&#125;,&#123;3,4&#125;,&#123;1,0&#125;&#125;bool compareInterval(interval v1,interval v2)&#123; return v1.val1 &lt; v2.val2; // 如果第一个数小的话，先排序&#125;sort(arr,arr+10,compareInterval); // 得到按第一个元素排序的数组 bool binary_search(start_adress,end_adress,value_find) 二分搜索查找value_find这个元素，该数组已经被排序过了，复杂度为$O(logn)$。 1234int arr[10] = &#123;1,3,2,4,5,8,7,6,9,0&#125;;if(binary_search(arr,arr+10,2))&#123; cout &lt;&lt; "get it ";&#125; bool all_of(begin_adress,end_adress,lambda_func) 该函数判断是否arr中的所有元素都满足lambda中的规则 1234void STL_allof(int*a)&#123; int lens = sizeof(a)/ sizeof(a[0]); all_of(a,a+lens,[](int x)&#123;return x &gt;= 0;&#125;) ? cout&lt;&lt;"all are positive" : cout&lt;&lt;"no all positive";&#125; bool any_of(begin_adress,end_adress,lambda_func) 只要有一个满足要求的，就返回true 1any_of(arr_begin,arr_end,[](int x)&#123; return x == 0;&#125;) //返回bool bool none_of(begin_adress,end_adress,lambda_func) 所有都不满足情况的时候，返回true 1none_of(arr_begin,arr_end,[](int x)&#123; return x == 0;&#125;) //返回bool copy_n(arr1,size,arr2) 将arr1中的前size个元素拷贝到arr2中。 123int arr[10] = &#123;1,2,3,4,5,6,7,8,9,0&#125;;int arr2[10];copy_n(arr,10,arr2); containers序列容器 vector向量是一个动态数组，数组的大小随着元素的个数而变化，内存空间是连续分布的，因此可以使用迭代器。向vector末尾插入元素要花费的时间是不确定的，因为有时候vector可能会扩容，此外插入和删除要花线性的时间。 iterators vector是在内存上连续的一段存储空间，因此允许使用迭代器，vector的迭代器有： 123456789vector&lt;int&gt; vec;vec.begin(); // 指向第一个元素vec.end(); // 指向最后一个元素for(auto i = vec.begin();i!=vec.end();i++)&#123;...&#125;vec.rbegin(); //指向最后一个，反向迭代vec.rend(); // 指向第一个，作为后向的终点for(auto i = vec.rbegin();i!=vec.end();i++)&#123;...&#125;// 此外上诉两种指针都有一个c（const）的版本，如vec.rbegin()//这个版本返回的迭代器是const类型的，不可改变迭代器所指向元素的值 capacity vector是一个可变长度的向量，当vector在添加元素的时候，会选择增长向量的容量： 123456vector&lt;int&gt; vec;vec.size(); //实际长度vec.capacity(); //已经分配的长度vec.max_size(); // 可分配的最大长度vec.empty(); // 判断是否为空vec.shrink_to_fit(); // 将容量减小到容器的容量大小 访问元素 123456vector&lt;int&gt; vec = &#123;1,2,3,4,5&#125;;vec[1];vec.front();vec.back();vec.at(pos);vec.data(); // 返回指针指向第一个地址 修改元素 12345678910vector&lt;int&gt; vec;vec.assign(val,time); //vec赋值，time个val的值vec.push_back(val);vec.pop_back(val);vec.insert(insert_adress,val);vec.erase(adress);vec.clear(); // 清空vec.emplace(adress,val); // 插入元素，并且避免不必要的复制vec.emplace_back(val); // 末尾插入vec.swap(vec2); // 交换vec和vec1的元素 listlist是由双向链表实现的数据结构，它在空间中不连续，元素的访问速度不如vector，但是对元素的删除，插入操作十分的快速。 他的很多函数与vector类似，下面列举一下特殊的一下操作： 123456789list&lt;int&gt; ll = &#123;1,7,3,8,2,6,4,9&#125;;ll.sort();ll.reverse();ll.push_front();ll.erase(adress) or ll.erase(begin,end);ll.remove(val); //删掉valll.unique(); // 删除重复元素ll.splice(l1.begin(),l2); // 链表的拼接ll.merge(12); // 两个排序后的链表融合 deque 双向队列，可以两头操作，效率比vector高，但是不一定保证地址是连续的。 deque和vector的操作基本一致，唯一的不同在于deque允许头插。 123deque&lt;int&gt; que;que.push_front(val);que.pop_front(val); froward_list 单向链表，与list类似，但只支持一个方向，同时所占用的存储空间更小。基本操作和list类似。 queue 单向队列，基本方法如下： 12345queue&lt;int&gt; que;que.push(val); // 插到队列尾巴que.pop(); // 删除队列头部元素queue.empty();queue.size(); priority queue 优先队列中，队头的元素是最大的，但是队列的排列顺序不是按照顺序排序的。优先队列使用起来应该很方便， 12345priority_queue&lt;int&gt; que;que.push(val);que.push(val);que.pop();que.top(); 优先队列是一种最大堆的结构。也可以用优先队列构建最小堆。 1priority_queue&lt;int, vector&lt;int&gt;,greater&lt;int&gt;&gt; gg; stack 栈是先进先出的一个结构，只有一端开放。 1234stack.empty();stack.push(val);stack.pop();stack.top(); 关联容器 set 集合容器，他要求内部元素没有重复的，他的常用的方法有： 123456789set&lt;int&gt; gg;set&lt;int,greater&lt;int&gt;&gt; gg; //从大到小begin();end();empty();gg.insert(val); // set中的元素都是有序的set&lt;int&gt; gg = &#123;vec.begin(),vec.end()&#125;;gg.lower_bound(val); //. 返回低于或等于valgg.upper_bound(val); // 返回高于或等于val的第一个迭代器位置 multiset 这个容器类似于set，但是和set有一个不同之处在于multiset可以允许重复。 map 字典，键值对。 12345678map&lt;int,int&gt; amap;amap.insert(pair&lt;int,int&gt;(1,21));amap.insert(pair&lt;int,int&gt;(2,23));cout &lt;&lt; amap[1];auto ptr = amap.begin();cout &lt;&lt; ptr-&gt;first&lt;&lt; " "&lt;&lt; ptr-&gt;second;amap.erase(amap.begin());amap.erase(4);//key multimap 操作基本与map相同，不相同的是，multimap允许有相同的key。 unordered_set 背后使用hash表来存储，key没有顺序： 123unordered_set&lt;string&gt; stringset;stringset.insert("code");stringset.find(key); //返回一个迭代器的位置 unordered_multiset 与unordered_set相似，但是允许元素重复。 unordered_map 与map相似，但是其中的元素key的顺序不是按顺序的。 1234unordered_map&lt;string,double&gt; umap;umap['id'] = 11;umap.insert(make_pair("e",2.33));umap.find(key); unordered_multimap 与unordered_map相类似，但是允许有key的重复。]]></content>
      <tags>
        <tag>learning cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp语法快速回顾]]></title>
    <url>%2F2019%2F10%2F25%2Fcpp%E8%AF%AD%E6%B3%95%E5%BF%AB%E9%80%9F%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[cpp的一些基本的语法的回顾，主要是一些比较小规模的语法特性的记录。 ​ 第一个可执行的cpp代码 1234567#include&lt;iostream&gt;int main()&#123; cout &lt;&lt; "hello world" &lt;&lt; endl; return 0;&#125; cpp程序编译执行过程 编译：将源代码翻译成机器语言，生成目标文件 预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。 编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。 汇编：将汇编代码翻译成目标机器代码.o文件。 链接：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。 #define宏定义 宏定义用一个字符串代替一串字符串，在cpp编译的预处理阶段，将字符串的位置替换成原来的长字符串，这种设计方式的好处是1）修改代码方面。2）对一些很短的代码，如果写成一个函数，将花费大量的系统调用时间，因此宏定义可以提升代码效率，但是目标代码空间就会变大。 123#define pi 3.14 //对象宏，定义变量// 函数宏，这种方式直接将字符串展开，需要注意代码运算优先级的问题#define MIN(A,B) ((A) &lt; (B) ?(A):(B)) 条件编译 123#ifdef NULL #define NULL 0#endif #与##运算符 #起到将指令变成字符串的作用： 12#define MACRO(x) #xcout&lt;&lt;MACRO(HOW ARE)&lt;&lt;endl; // "HOW ARE" ##起到链接前后内容的作用，将参数连在一起。 12#define ACFUNS(x,y) x##ycout&lt;&lt;ACFUNS("aa","bb")&lt;&lt;endl; // aabb typedef申明 1typedef short int wchar_t; 使用wchar_t来表示short int 这种类型，起了一个新名字。 enum枚举类 123enum color&#123;red,blue,black&#125; c; //值为0，1，2c = blue; //等于为c赋值为1cout &lt;&lt; c; // 1 声明与定义 cpp语言支持分离时编译，允许将程序分割成多个模块，声明与定义分离（.h / .cpp）,静态库(lib)包含声明以及方法，动态库(.lib,dll)仅包含声明，dll中为方法。 声明的作用是在编译器链接代码的阶段，告诉程序该变量的存在。可以在多个文件中，多次声明，使用关键字： extern int a;声明了一个变量a。定义的过程只能有一次。 extern关键字常用在多个文件同时使用同一个变量或者函数的时候。 变量的初始值 当一个变量是全局变量，系统会默认初始值为0。当变量是局部变量，系统不会赋初始值。 定义常量 常量不可以修改它的值，两种方式定义常量： 12#define WIDTH 10const int HEIGHT = 20; 修饰符类型 修饰符用于改变基本数据类型char，int，double的含义。可以使用的修饰符有： signed,unsigned,long short。 12int* restrict restar = (int *)malloc(10 * sizeof(int));制定只有restar这个指针可以指向这一块内存，其他指针都不能访问 存储类 auto 关键字声明变量根据初始化值自动推断变量的类型，声明函数返回的占位符。 12auto f = 3.14;auto s = "hello"; static告诉编译器在程序声明周期内保持局部变量的存在，在编译阶段进行赋值，其他阶段不会进行初始化操作。 123456789101112void func()&#123; static int i = 5; cout&lt;&lt;i&lt;&lt;'\n'; i--;&#125;int main() &#123; for(int i = 0;i&lt;10;i++)&#123; func(); &#125; return 0;&#125;// 输出为5，4，3，2，1.... 其中static i只会被初始化一次 thread_local关键字声明的变量仅仅可以在其上创建的线程上访问，仅仅可以用来声明变量。 thread_local int x; 位运算符 1234567891011A = 00111100B = 00001101A&amp;B = 00001100A|B = 00111101A^B = 00110001~A = 11000011A &lt;&lt;= 1; //A = 01111000A &gt;&gt;= 1; //A = 00011110sizeof(A); //返回A的大小b = &amp;A; // 取地址c = *b; // 取出b中的值 函数定义 123456789int sum(int a,int b)&#123; if(a &gt; b)&#123; return a; &#125; else&#123; return b; &#125;&#125;//传参数方式可以分为传值，传指针，传地址三种 lambda表达式 12345[capture](parameter)-&gt; return-type&#123;body&#125;int s = 1;auto funa = [s](int a,int b)-&gt; int&#123;return a+b+s;&#125;;cout &lt;&lt; funa(1,2); 数学运算 数学运算的方法在头文件中。 随机数 1j = rand() 数组 123int a[10];int a[10] = &#123;10,10,1&#125;;int a[] = &#123;1,2,3&#125;; 字符串 12345678//c风格字符串char gre[] = &#123;'a','b','c','d'&#125;;cout&lt;&lt;gre;strcpy(str1,str2); // str2给str1赋值strcat(str1,str2); // str1+str2strcmp(s1,s2);//比较s1，s2strchr(s1,ch); // 返回指针，指针位置为ch第一次出现的位置strstr(s1,s2);// 放回指针，指向第一次出现s2的位置 string 字符串操作 12345678string a = "hello";string b = "el";a.find_first_of(b); // 等于a.find(b);a.find_last_of(b);s.size();if(a.find(b) == string::npos)&#123; return “dont exists”;&#125; 指针 cpp中每个变量都有一个内存位置，这个内存位置可以通过&amp; 取址符来得到，他表示内存中的一个地址。 指针是一个变量，它的值就是地址。 12345678910int *ip;int var = 10;ip = &amp;var;cout &lt;&lt; *ip; //取去ip中的值int *ptr[10]; //指针数组，数组中存指针//指针可以允许加减，数组和指针很类似，一个定义在数组开头的指针用法和数组相同int var[5] = &#123;1,2,3,4,5&#125;int *ip = var;ip++;cout &lt;&lt; ip[1]; 引用 引用变量是为变量起了一个别名，引用在创建的时候必须初始化。 1234int a = 1;int&amp; r = a;//传参数的时候可以使用引用，不用传值，快。// 函数返回类型为引用类型的时候，操作和其他类型的一样，返回一个引用，就可以对这个引用进行赋值的过一些操作了。 结构体 cpp中定义数据类型使用结构体 12345678910111213141516struct Book&#123; int count; string name;&#125;;struct Book b1;//使用typedef定义别名typedef struct Book&#123; int count; string name;&#125;Book;Book b1,b2;//调用cout &lt;&lt; b1.name;//指针调用Book *ptr = &amp;b1;cout &lt;&lt; ptr-&gt;name; 类 类是cpp的核心，通常被用与用户定制自己的数据以及方法 12345678910111213class Box&#123; public: int width; int height; Box(); //构造函数，函数进行定义，初始化的入口 int get_area()&#123; return width*height; &#125;&#125;;Box b1; //定义了一个Box的类型变量cout&lt;&lt; b1.width;Box* ptr = &amp;b1;cout &lt;&lt; ptr-&gt;get_area(); 拷贝构造函数 利用已经存在的类对象，对新类进行初始化。 1Box b2 = b1; 友元函数 友元函数设计的思路是说，一个非A类内的函数，希望获得完整的A类内成员的访问权限，这时候需要在A类对该函数进行一下注册，用friend最为前缀（适用于多人协作的项目）。 123456789class A&#123; int val; public: int mon; friend void detial(A a1);&#125;void detail(A a1)&#123; cout &lt;&lt; a1.val; //允许访问私有变量&#125; this 指针 成员函数均有一个隐含的this指针参数，用于指向对象。 类内静态成员变量，静态函数 类中允许定义static变量，该变量在所有类的对象中是共享的，该变量属于类，不属于对象，不可以在类的构造函数中初始化static变量，而是通过A::变量 = init的方式进行初始化。 static声明的函数，与任何对象都没有关系，该函数与类同在，只能访问静态成员变量，与其他静态成员函数。 继承 我理解继承是这种大型工程中非常有灵性的一种设计，通过底层写一些通用的模版类，底下的继承类就有很好的一致性，以及少写了很多重复性的工作，此外通过子类中定制自己的成员，呈现一种放散式的结构。 1234567891011121314151617181920class book&#123; public: int page = 1; string name = "island"; void detail()&#123; cout&lt;&lt; this.page &lt;&lt; this.name; &#125;&#125;class finance: public book&#123; public: int profit = 0; finance(int pro); void detail();&#125;finance::finance(int pro):book()&#123; this.profit = pro;&#125;void finance::detail()&#123; cout &lt;&lt; this.page &lt;&lt; this.name &lt;&lt; this.pro;&#125; 具体来说，继承不会继承积累的构造函数，友元函数，重载运算符。从设计的角度上看，友元这一类函数会破坏类的封装性，子类不接受友元是很正确的决定，而构造函数有专门的作用，因此，不继承构造函数也是可以理解的。 基类构造函数 所谓的基类构造函数，构造的时候，需要对父类进行初始化，很容易理解。初始化的方式就是通过构造函数表来初始化，在构造函数定义的时候使用，成员变量也允许那时候初始化。 1finance::finance(int profit,int page,string name):Book(page,name),profit(profit)&#123;&#125; 重载运算符 我认为这一步的设计思路是是我们设计的类和基础类型的变量能够使用一些类似于+，-，x，/这种方便的操作。 12345678910class Box&#123; public: int width; Box operator+(Box b)&#123; Box box; box.width = this.width + b.width; &#125;&#125;Box b1,b2;b = b1 + b2; 重载函数 重载函数指的是同一个函数，但是随着输入的参数不同，调用的具体函数也是不同的。这样的设计思路在于，是一个函数用起来更加灵活，例如对于不同级别的类别都需要登入操作，但是入口不同。就可以利用重载的思路来实现。 1234567class log&#123; public: int user = 1; int vip = 1; void log(int user); void log(int user,int vip);&#125; 多态 多态的设计思路，有这样一种情况，当子类与父类中同时有某个方法。我们可以用父类的指针来存放所有的子类的地址。但是每个子类调用一个工友的方法，各自应该有各自的方案。例如大家办护照都去公安局，但是每个人有不同的办理方案，这种情况就是多态。 要实现多态的话，在需要实现多态的函数前加上virtual关键字，告诉编译器，在编译的时候不要链接该函数，而是得到调用函数的时候，看变量的类型来确定用什么函数。这个叫做动态链接。 静态链接则是写死了，每次用父类的对象调用的都是父类的方法。 123456789101112131415161718192021222324252627282930313233343536class shape&#123; public: int width = 0; int height = 0; shape(int w,int h):width(w),height(h); virtual int area()&#123; cout &lt;&lt; "shape" ； return 0; &#125;&#125;class triangle:public shape&#123; public: triangle(int a,int b):shape(a,b)&#123;&#125; int area()&#123; cout &lt;&lt; "triangle area"&lt;&lt;endl; return a*b / 2; &#125;&#125;class rectangle:public shape&#123; public: rectangle(int a,int b):shape(a,b)&#123;&#125; int area()&#123; cout &lt;&lt; "rectangle area" &lt;&lt; endl; return a*b; &#125;&#125;shape* sh;rectangle rec(1,2);triangle tri(1,2);// 正方形面积sh = &amp;rec;sh-&gt;area();// 三角形面积sh = $tri;sh-&gt;area(); 虚基类virtual 虚基类提出的设计思路是说，如果一个类同时继承两个类，而这两个类又同时继承自同一个父类，因此在子类这就会出现最高父类的两个拷贝。因此多继承很多时候会产生很多二义性的问题，因此在设计函数的时候要尽可能避免。出现这种情况可以用virtual进行虚继承。class B : virtual public A{...}。 抽象类 设计抽象类的设计思想是说，面向对象的系统可能会使用一个抽象基类为所有的外部应用程序提供一个适当的、通用的、标准化的接口。因此会在基类设计一个virtual抽象类，规定一下子类的接口参数的格式。 12345678910111213141516class shape&#123; public: int width; int weight; shape(int a,int b):width(a),weight(b)&#123;&#125; // 提供纯虚函数接口，子类必须覆盖 virtual int get_area() = 0;&#125;class rectangle&#123; public: rectangle(int a,int b):shape(a,b)&#123;&#125; int get_area()&#123; return this.width*this.weight; &#125;&#125; 文件的读写 文件的读写定义在两个库函数中，ifstream,ofstream，写入过程使用&lt;&lt;，读出过程使用&gt;&gt;。 异常处理 cpp中提供了try,catch,throw用来保护代码，抛出错误。 12345678910111213try&#123; //保护代码&#125;catch(ExceptionName e1)&#123; //catch 内容&#125;catch(ExceptionName e2)&#123; // something&#125;//catch 模块if(error)&#123; throw "error message";&#125; cpp动态内存 栈：在函数内部声明的所有变量都将用栈来存储 堆：这部分内存程序未使用，在程序运行时可动态分配内存。 cpp允许使用new给变量分配堆内内存，返回动态内存的起始位置，同时可以使用delete将这部分内存删除。 12345678910111213141516double* ptr = new double;*ptr = 12.32;//数组申请空间int * ptr = new int[10];//释放delete[] ptr;// 二维数组int ** ptr = new int *[10];for(int i=0;i&lt;10;i++)&#123; ptr[i] = new int[10];&#125;class Box&#123; ...&#125;Box* ptr = new Box[4];delete [] ptr; 命名空间 123456namespace first_space&#123; void func()&#123; ... &#125;&#125;first_space::func(); cpp模板 模板指函数模板和类模板，是一种参数化类型机制，在泛型编程（泛型允许程序员使用未指定类型的变量，在实例化时作为参数指明这些类型）中十分的重要。常用的cpp模版例如vector。 123456789101112131415161718192021222324//函数模板template&lt;typename T&gt; // 用T表示一种类型的变量T Max_val(T a,T b)&#123; return a &gt; b ? a:b;&#125;//调用Max_val(1,3);Max_val(1.2,3.4);//类模板template&lt;class T&gt;class stack&#123; private: vector&lt;T&gt; elems; public: void push(T const&amp; val);&#125;template&lt;class T&gt;void stack&lt;T&gt;::push(T const&amp; val)&#123; elems.push(val);&#125;//调用stack&lt;int&gt; int_stack;stack&lt;string&gt; str_stack; const&amp; 在一些库函数，模板类的函数中进场发现这种传参数，传指数的方法,这种方法用引用减少数值传递过程中需要消耗的时间。返回值是const&amp;是个引用，如果是const的话，程序还需要另外开辟空间。同时这样使用可以函数返回值还可以作为左值，因此建议今后写代码带上引用。 void* void *是一种指针类型，常用在函数参数、函数返回值中需要兼容不同指针类型的地方。它类似于指针类型中的原始基类，所有的指针可以对它赋值，它也可以转化为任何指针类型，但是是否合理需要看函数的原始定义。 12345void* c;int a = 0;int * ptr = &amp;a;c = ptr;int * d = (int *) c; cpp多进程/线程 进程：程序需要并发执行 线程：一个进程中含多个线程，线程负责同一段程序中的并发 使用 POSIX 编写多线程 C++ 程序。POSIX支持linux上的并行： 123456789101112131415161718192021222324#include &lt;pthread.h&gt;// 线程的运行函数void* say_hello(void* args)&#123; cout &lt;&lt; "Hello Runoob！" &lt;&lt; endl; return 0;&#125; int main()&#123; // 定义线程的 id 变量，多个变量使用数组 pthread_t tids[NUM_THREADS]; for(int i = 0; i &lt; NUM_THREADS; ++i) &#123; //参数依次是：创建的线程id，线程参数，调用的函数，传入的函数参数 int ret = pthread_create(&amp;tids[i], NULL, say_hello, NULL); if (ret != 0) &#123; cout &lt;&lt; "pthread_create error: error_code=" &lt;&lt; ret &lt;&lt; endl; &#125; &#125; //等各个线程退出后，进程才结束，否则进程强制结束了，线程可能还没反应过来； pthread_exit(NULL);&#125; cpp中的STL（standard template library） STL库中包含了许多模板类，实现了很多容器，算法以及迭代器等等。 算法algorithm：这些算法类大多是作用在容器上 容器：如vector，map，set等等 迭代器 Functors：算子，类似于sort的时候用算法自定义排序的方式，作为参数传入 为STL专门开一个post，日常使用和刷题都会比较经常使用：链接 cpp标准库 这个库是继承自C语言的，包括标准函数库和标准对象库。 #include cpp中include一个头文件在编译阶段等同于件这个头文件中的代码展开，因此cpp中发生相互引用时将会报错，当你在不确定是否存在相互引用的时候，建议加上include保护： 123#ifndef FOLDER_METHOD_H_#define FOLDER_METHOD_H_#endif Google 开源风格指南中建议的include顺序： dir/foo.cc 或 dir/foo_test.cc 的主要作用是实现或测试 dir2/foo2.h 的功能, foo.cc 中包含头文件的次序如下: dir2/foo2.h (优先位置, 详情如下) C 系统文件 C++ 系统文件 其他库的 .h 文件 本项目内 .h 文件 这种优先的顺序排序保证当 dir2/foo2.h 遗漏某些必要的库时， dir/foo.cc 或 dir/foo_test.cc 的构建会立刻中止。因此这一条规则保证维护这些文件的人们首先看到构建中止的消息而不是维护其他包的人们。 .cpp中要包含include自己的h文件，在程序编译阶段include尽量都写在头文件中，源文件就可以很少的引用头文件。 总结重新回顾了一下cpp的一些语法重点，发现这本语言相比较于其他语言来说，有很大的自由度，自由发挥的地方非常的多。同时有为写一些大工程而设计上的思路。总体来说，比较感兴趣，由于使用CLion来作为编辑器，通过一种更加原生的方式写代码，编译代码，感觉要比直接用VS studio要有深刻的理解。 这一页博客要常常回来回顾回顾！]]></content>
      <tags>
        <tag>learning cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLab 总结]]></title>
    <url>%2F2019%2F10%2F22%2FDeepLab-%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
      <tags>
        <tag>项目总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp工程文件的总结]]></title>
    <url>%2F2019%2F10%2F21%2Fcpp%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[cpp学习的第一轮，首先从以前的盲区开始杀进去，解决的第一个问题是 人们说cpp工程文件，说的都是什么。 打开vs，创建一个控制台的应用。（CLion用cmakeList链接文件，感觉可以学习一下）这时候会产生很多中间系统文件以及文件夹。]]></content>
      <tags>
        <tag>learning cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文献阅读：基于RealSense和模型库的人体建模方法]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8ERealSense%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BA%93%E7%9A%84%E4%BA%BA%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这篇论文是张远师兄的毕业论文，主要的思路是通过深度模型预测类别，进而补全模型深度信息，然后通过学习模型参数，最终实现对人体的建模以及测量。 摘要人体建模经历了 1. 基于回归分析的人体建模 2. 基于三维扫描人体建模 3. 基于数据库人体建模。人体建模的精度越来越高，对场景的约束越来越低。 本文通过基于RGBD信息与模型数据库的人体建模技术，提升人体建模的精度。主要的工作有： 提出一种基于RGB数据的人体深度类别预测方法 提出一种基于深度类别信息的人体深度数据补全与优化方法 提出一种基于RGBD数据和模型参数的人体建模方法 基于RGB预测人体深度类别基于RGB数据来预测人体的深度信息，本文提出了两阶段的网络结构，用于RGB图像中的人体深度类别预测。该部分主要分为两部分： 预测图像中的人体分割 预测人体分割对应的深度信息 针对人体不变的局部特征和多变的全局特征，作者采用多尺度信息融合的方式提取特征，采用跳跃层结构，使用Stacked hourglass network作为基本网络，使用交叉熵作为损失函数，分别应用与人体部件分割以及深度类别的预测上。 针对这两个问题，作者使用Varol et al.(CVPR 2017) 提到的方法对人体进行分割以及预测人体的深度类别信息。该网络深度信息预测结果不好，作者通过扩充网络，将网络修改成二阶段的网络，获取原始数据多尺度的结果之后得到一个较好的恢复结果。 左图第二行是分割信息，有图中间一列是Varol的结果，最后一列是本文结果。 基于深度类别信息的人体深度数据补全与优化对RGB图像进行标定，作者使用realsense内部的标定算法实现标定。接下来对深度数据进行恢复，主要有两种方案，一种是基于滤波器的方法，另一种则是基于图像修复重建的方案。第一种方案难以修复比较大的空洞，第二种方案引入图像修复技术，通常会假设人体深度数据与RGB数据呈现局部线性关系，作者认为由于人的衣服颜色相同，因此不适用于这两种方案。 作者使用快速行进法（Telea 2004）(FMM)进行空洞的补全，该方法的思路是从已知的像素点和位置的像素点的边界开始计算，逐渐扩展到所有位置的像素点，求解出深度图。作者首先对其RGBD图像之后，对目标图像I上的任意一点深度，采用对周边点的一阶泰勒展开来得到。使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：$$I(p)=I(q)+\nabla I_{p}(q)(p-q)$$使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：$$I(p)=\frac{\sum w(p, q)\left[I(q)+s \cdot \nabla C_{p}(q)(p-q)\right]}{\sum w(p, q)}$$通过快速行进法，使用RGB梯度代替目标图像的梯度的方式，作者命名为GradientFMM，梯度的快速行进法。 在图像滤波上，作者使用了引导滤波的方法，对整张深度图像进行滤波。 基于RGBD数据和模型参数的人体建模与测量作者基于数据库学习出一种人体模型的参数表示方式，能够很好的表示出人体姿势的变化，从而使一个标准的人体形变后和点云数据相互拟合。随后建立一个融合点云数据和人体参数的能量优化模型，得到配准的人体三维模型。 能量函数（Bouaziz et al 2014）提出一种 能量函数泛式来解决配准问题，他包含数据匹配和参数先验能量。$$E = E_{match} + E_{prior}$$作者研究，对于刚体形变或非刚体形变本质上都是期望最大化算法。EM算法本上是一个非凸优化问题。因此上诉配准问题不一定能收敛到最优解。 作者使用SCAPE数据集，里头包含1517个男性和1531个女性在不同姿势下的模型，对于每一个人人体模型，都包含12500个顶点和25000个三角面片。对于人体的三维变形，本质上就是对人体网格的三角面片进行变形。 作者通过计算标准模型到每一块面片的参数变换的Q，R，S矩阵，得到整个数据集所有的变换矩阵。因此可以通过不用的姿势，体型参数，可以得到一组Q，R，S然后从标准的模型中，得到目标的模型。 随后利用能量函数（数据匹配能量以及人体先验能量函数）来无限的拟合人体参数模型和采集到的深度数据之间的距离，得到一个较为真实的人体模型。项目到此结束。 一些想法做鱼类RGBD数据的三维重建工作，我觉得我的工作可能集中在深度数据的恢复，水下场景的去噪算法，光线折射的还原，空洞的补全这些部分上。对于最后和标准的三维模型去拟合这一部分的工作我可能没办法完成了。 然后使用到cpp，绘制部分的工作可以用恢复了一部分的深度数据来完成。 那么近期的工作就十分的清楚了，关注人体的恢复实验，找到一些深度学习的算法，恢复出人体，然后针对鱼进行优化。]]></content>
      <tags>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何读论文]]></title>
    <url>%2F2019%2F10%2F16%2F%E5%A6%82%E4%BD%95%E8%AF%BB%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[对于近期在读论文上效率比较低，读完收获比较小的问题，我从知乎上找到了一些比较好的读论文，做笔记的方法，在这里记录一下。 读论文筛选论文，确定是否值得读 feel free to stop reading the article at any point 拿到一篇论文先看论文题目，keywords，若你不感兴趣，you stop 阅读 abstract，你可以快速地了解整篇文章。 阅读 conclusion，从结论中你可以看出来这篇文章是否和你研究的问题相关。 阅读 论文 图片，表格，标题，从这些地方你可以花很少的时间，搞清楚作者是如何做这项工作的 到这里，如果你认为这篇文章还可以继续的话，你就可以接着往下进行了。 精度论文 阅读 introduction，该部分你将读到整个文章的背景，以及作者做这篇文章的主要目的。 文章的最重要的核心是 the result and the discussion，你应该在这上面花主要的时间，如果你觉得差不多了，你就可以停止了。 但是你如果觉得这篇文章和你的工作的相关性比较大的话，那你就应该dig extremely into the experience section。在这一部分你就可以清楚的知道作者是如何做这件事的。 当你阅读完这篇论文的时候，适当的做些笔记，这些笔记将会在你未来的研究中为你省下很多的时间。 读论文的一些tips 参考文献中信息很多，可以花时间找一些参考文献中的文章是否和你当前的问题相关，减少调研的工作量。 关注近五年的文献。 关注核心期刊、会议以及一些学科大牛。 如何记笔记记笔记在阅读完论文后，进行简要的记录： 论文出处 论文背景 论文工作 论文创新 不足以及研究方向 自己的想法 参考链接 https://www.zhihu.com/question/304334959/answer/553782865]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[resume detail 2019/10/15]]></title>
    <url>%2F2019%2F10%2F15%2Fresume-detail%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <tags>
        <tag>项目总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepMVS:Learning Multi-view Stereopsis]]></title>
    <url>%2F2019%2F10%2F14%2FDeepMVS-Learning-Multi-view-Stereopsis%2F</url>
    <content type="text"><![CDATA[该篇论文通过一系列的图像，生成这些图像所对应的深度信息。]]></content>
      <tags>
        <tag>3D重建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[State of Art on 3D Reconstruction with RGB-D Cameras 三维重建综述]]></title>
    <url>%2F2019%2F10%2F10%2FState-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[这篇论文是发表在欧洲计算机图形学协会2018上的一篇综述文章，下面将精读这篇论文，对其中的重点内容进行记录。 introduction近些年来，基于结构光（structure light）和TOF（time of flight）方法的深度相机得到了大规模的商用，很多基于RGB-D数据的三维重建算法达到了很好的重建效果。一些具有创新性的方法得到了发展、一些基于RGB-D用于还原3D结构的方法、一些基于RGB-D研究物体其他属性的方法（材料，反射模型）也相继被提出。 RGB-D cameras and their characteristics目前，深度距离检测上存在两种方法，一种为三角测距（triangulation），另一种为TOF（time of flight），三角测距可以是被动式（立体视觉），也可以是主动式（结构光）。stereo vision方法计算两张不同角度的照片的差异，而结构光同样是发射红外线，通过分析红外线的扭曲程度三角测量的方式得到深度信息。TOF方法则是通过发射红外光，通过测量接收到反射光的时间来判断物体的深度信息。 static Scene Reconstruction（静态场景重建） 在线的静态场景重建直接相关的技术有SLAM（simultaneous Localization and Mapping），这个技术主要的关注点在于在未知环境中机器人的导航，主要针对离散稀疏的点云建模。另一方面，静态稠密点云的重建也引起很大的关注。 在线重建的发展使得一些如kinect Fusion算法，possion surface reconstruction（柏松重建算法）的研究成为一个热门的方向。 静态场景重建的基础pipeline第一步：深度图的预处理，噪声的消除，外部（outlier）信息的移除这些处理方法会首先对RGB-D数据进行处理。 第二步：从输入的深度图序列中提取出额外的信息，存储起来。 第三步：相机位姿的估计以及转换矩阵T的估计 第四步：深度图的融合，将所有计算出的点融合到模型M中。 深度图的预处理深度图中噪声的长生由多种因素影响，常用的方法有使用双边滤波的方式（bilateral filter）来过滤噪声，此外对于一些特定的模型，姿态估计等等方法也会被使用。 camera pose Estimate对每一张RGB-D图像，计算6-DOF pose T。]]></content>
      <categories>
        <category>论文阅读</category>
        <category>3D重建</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[3D重建论文阅读]]></title>
    <url>%2F2019%2F10%2F08%2F3D%E9%87%8D%E5%BB%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[本篇博客的主要目的是为了记录所读的有关于三维重建的文章，对每篇文章的insight进行简要的总结。 State of Art on 3D Reconstruction with RGB-D Cameras该论文是发表在eurographics 欧洲计算机图形学协会2018上，对当前的RGB-D图像三维重建进行了一个综述整理。 这是明天的任务。 Underwater 3-D Scene Reconstruction Using Kinect v2 Based on Physical Models for Refraction and Time of Flight Correction该论文被2017年IEEE access收录，论文主要的思路是搭建一个防水装置，将kinect v2放入水中，利用kinect v2来采集RGB图像以及深度图像。然后通过水下数据采集，相机矫正，噪声过滤，TOF矫正，反射矫正等步骤恢复深度数据，最后通过kinect Fusion等到三维重建后的效果。 数据获取采集部分采用加入防水外壳的kinect v2。 水下滤波部分，在kinect fusion算法中，针对空气中的滤波采用bilinear filter，水下环境复杂，作者采用5 x 5的median中值滤波。 kinect TOF矫正，由于在水下红外线的传播速度与空气中传播的速度不同，因此需要对检测到的深度信息进行矫正。水中传播的距离需要根据水中的红外线传播的速度进行修正。 水下折射矫正，kinect v2捕捉到的图像、深度信息在水下存在一定程度上的偏移，因此需要进行水下的折射矫正。 在三维恢复性能比较方面，作者采用物体的三维模型或者激光采集到的三维数据作为ground truth进行对比，得出性能的优劣。 2019/10/8]]></content>
      <categories>
        <category>3D重建</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[3D重建综述]]></title>
    <url>%2F2019%2F09%2F26%2F3D%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[双目重建问题是一个计算机视觉领域一个比较经典的问题。通过两个固定、水平放置的相机，对同一个物体各个角度采集照片，利用成像原理预测物体的深度信息，进行三维场景的重建。 亚像素：面阵摄像机的成像面以像素为最小单位，像素间距为5.2微米。在宏观上可以认为像素是连续的，但是在微观上，5.2微米之间的部分我们称为亚像素，可以利用软件恢复出来。 6 DOF：六自由度，指的是刚体在三维空间中运动的自由度，特别是指刚体可以在前后、上下、左右三个相互垂直的坐标轴上平移，也可以在三个垂直的坐标轴上旋转。 数据集benchmark：立体视觉是计算机视觉中最为重要的方向之一，在视差检测方面KITTI、 MiddleBury 提供的数据集常被作为Benchmark。 Image-based 3D Object Reconstruction:State-of-the-Art and Trends in the Deep Learning Era3D重建问题研究上的pipeline如下： 物体【generic objects 】-&gt;数据【single images,multiple RGB】-&gt;研究方法【shape representations，network architecture，training mechanism】 此外对一些特殊的物体，例如人体、人脸等问题，也有着很多的三维重建的工作。 问题的定义数据输入为一系列的RGB图片，输出为物体的三维重建的结果。三维重建网络的含义在于学习一个预测器，通过这个预测器学习到物体的三维表达，然后与GT之间计算一个最小的重建误差。 数据的输入形式有单张图片，多张图片，视频流。此外可以添加一些额外的预测信息，例如图像的轮廓，分割的结果以及语义标签进行共同预测。 encoding state该部分用于提取图片中的深层次的特征将输入I映射到一个潜在的空间中。$$x = h(I)$$对于映射函数h有以下的要求： 在I空间中相似的两个物体，在x空间中仍然十分的接近。 在x空间中小小的扰动（perturbation）可以反应到I空间中的扰动。 映射函数不受相机参数、位姿的影响。 3D模型和2D图像可以映射到x空间中的同一个点，这样的目的可以消除模型的二义性。 隐空间有多种类型，离散、连续、层级以及开放（disentangled）的空间。 离散的隐空间 最高由Wu等将一个3D的encoding 网络引入三维重建中用于映射一个3D的体素空间。此后标准的vanilla结构的网络，以及他的变种被引入三维重建中，其他工作如pooling layer，RELU，residual networks（resnet）等也被引入三维重建中。 连续的隐空间 一些网络如VAE（variational Autoencoders）或者他的变种，他们的隐空间均设计成连续的。该类型网络将数据映射到高斯分布的一个空间中。利用高斯分布生成一个连续的3D表达。 层级隐空间（hierarchical latent spaces） 一些工作将输入映射到层级空间中，利用特征各个尺度维度的信息，能够很好的完成任务。 解构的表示空间（disentangled representation） 影响图像中物体的成像因素有很多，例如相机的位姿、光照条件等等。通过不同的网络的结构，来解析表示这些部分。 体素解析（volumetric decoding）体素网格用来表示离散空间中3D物体的3D形状。目标是重建3D体素网格使得它能够与真实的3D物体相近。这样做的一个优点是，很多2D的网络结构可以很轻易的转化成3D的结构。 二次网格： 若当前的网格属于物体则为1，否则为0 概率网格： 每一个像素表示一个该像素属于物体的概率 SDF体素到物体表面的距离： 体素表示该位置到物体表面距离的数值，正数表示内部负数表示外部。 截断距离：定义一个截断规则，将SDF距离进行截断。 上诉四种表示方式中概率网格的表示方式最适合深度学习系统。 低分辨率的3D体素重建在得到隐空间中的特征表达之后，需要通过一个decoder结构，恢复出物体的三维结构。常用的结构为up-convolutional network，与encoder形成一个镜像映射。使用一些3D卷积结构，从一系列图片中得到物体的三维体素表达。 之后补上：由于对这个领域实在不熟悉，需要先看几篇论文熟悉一下，才能明白作者行文过程所做的分类的含义，以免现在一知半解浪费时间，耽误好文章。]]></content>
      <categories>
        <category>3D重建</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Stanford cs231A]]></title>
    <url>%2F2019%2F09%2F19%2FStanford-cs231A%2F</url>
    <content type="text"><![CDATA[Stanford cs231A与cs231N是分别从传统方法和深度学习方法介绍计算机视觉的一些技术与应用。这本课程适合作为计算机视觉的入门课程，分别从目标的几何学和语义学上两个角度对图像进行分析。 slide 10: Active stereo &amp; Volumetric stereo 使用一个光源发射器来代替相机，能够解决两张图片之间的关联问题。 通常可以使用激光，从上到下扫描这个物体的表面，可以获得一个非常精确的三维结构信息。 traditional stereo传统的三维成像的方法： volumetric stereo slide 2019/09/26 silde 9: Detectors and descriptorsDetectors: 边缘: 图片中深度不连续，表面朝向不连续，反射、光照不连续的位置。 可以使用传统的canny算法进行边缘的检测，通常图片可以进行平滑或求导处理。 角点corner/blob光斑识别：角点通常较为突出，且具有重复性，局部性。可以使用harris角点检测算法来检测。 光斑可以使用拉普拉斯或高斯来检测： 常用的检测器SIFT： HOG: slide 2019/09/25 slide 8: Fitting and Matching问题定义： 特征点匹配问题存在着许多难以解决的问题： nosiy outliers（外点） missing data intra-class variantion 拟合方法least square methods： 最小二乘法用来拟合数据，可以一定程度上对较小的噪声鲁棒，但是对于较大的噪声处理效果不好。 RANSAC： 通常样本中包含正确数据(inliers，可以被模型描述的数据)，也包含异常数据(outliers，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。 RANSAC为Random Sample Consensus的缩写，它是根据一组包含异常数据的样本数据集，计算出数据的数学模型参数，得到有效样本数据的算法。它于1981年由Fischler和Bolles最先提出 。 RANSAC算法的输入是一组观测数据（往往含有较大的噪声或无效点），一个用于解释观测数据的参数化模型以及一些可信的参数。RANSAC通过反复选择数据中的一组随机子集来达成目标。 被选取的子集被假设为局内点，并用下述方法进行验证： 随机选择一组样本子集，并假设所选择的子集都为局内点 寻找一个模型适应于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。 用1中得到的模型去测试所有的其它数据，若某个点适用于估计的模型，认为它也是局内点inlier 如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。 用所有假设的局内点去重新估计模型（譬如使用最小二乘法） 最后，通过估计局内点与模型的错误率来评估模型。 上述过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为比现有的模型更好而被选用。 霍夫变换： 霍夫变换(Hough Transform)是图像处理中的一种特征提取技术，它通过一种投票算法检测具有特定形状的物体。该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。 起初的方法要求知道物体边界线的解析方程，但不需要有关区域位置的先验知识。这种方法的一个突出优点是分割结果的Robustness , 对数据的不完全或噪声不是非常敏感。 例如使用霍夫变换来找出图像中的直线（某些特定的形状），将原图中的每个点所在直线的参数空间画出来。当在参数空间中重叠最大的那个参数证明是所有数据都经过该参数的直线，因此可以认为参数所表示的直线为图中的直线。 图中每一个点都将对应到一条参数空间上的曲线，找到参数重叠最大的一个参数，即是大多数数据经过的直线的参数。 解释链接：https://zhuanlan.zhihu.com/p/47649796 使用hough算法变换之后，能够更好的进行图片之间的匹配。 slide 2019/9/25 slide 7: Multi-view geometry问题描述： 从m张照片中的n个点中，去估计、还原出m个仿射矩阵，以及n个3D的点。 三维空间中的点和图像二维上的点存在一个仿射关系： 将三维空间中的点，通过这种映射关系映射到二维平面上。 factorization method(因式分解方法)centering the data: 提出去图像点之间的质心：$$\hat{\mathbf{x}}_{i j}=\mathbf{x}_{i j}-\frac{1}{n} \sum_{k=1}^{n} \mathbf{x}_{i k}$$将仿射变换代人上式，得到三维空间中的质心位置： 经过数据的centering之后，每张图片的质心都将会映射到3D点云的质心上，将这个质心视为世界坐标系原点，进一步简化公式： 构造一个m x n的矩阵，表示不同视点拍摄的n个点的位置信息，如下： 对D矩阵进行SVD分解，选取前三大的奇异值构成一个新的矩阵（当rank=3时能够最小化F模使得其更加接近D矩阵）。 利用MS恢复出三维像素点云信息。 该方法的确定是难以解决视觉上的歧义、结构的相似性问题。 slide 6: Stereo(立体) Systems Multi-view geometry接上一章，使用多视角的几何方法需要找到两个图像之间的关联点，得出他们的焦点即物体实际的位置，即得到了物体的三维点云表达。 通常的做法是将图像内物体的位置调整成水平平行的方式，关键点匹配效果好。 当特征点在同一个水平位置时更容易计算深度： methodwindow base correlation: 上诉方法对图片光线不敏感，匹配效果不好，改进方案如下： 匹配问题存在很多难点，常常导致匹配错误： 使用下述方法可以提升精度： SFM: structure from motion problemSFM方法通过相机的移动来确定目标和几何关系，是三维重建的一种常见方法，使用RGB图像即可对图像进行恢复。 SFM算法流程： 特征点提取(SIFT) 特征点匹配 基础矩阵估计F（5/8点法） 本质矩阵估计E 本质矩阵分解为R和T（SVD分解） 三维点云计算（三角形法） 重投影（将三维点云重新投影到平面的方法，用于计算误差） 重构的细化与优化 slide 2019/9/24 slide 5: Epipolar Geometry (对极几何) 从单张图片中重建出物体的三维结构，存在着巨大的困难。需要对物体的位置，姿态进行定位，需要从场景中的线、无穷远点判断场景的结构以及相机内参K。此外还需要一些其他先验，例如点、平面等的对应关系。由于视点的空间感很弱，因此画面存在歧义，重建难度大。 三角测量通过两个视点来观察整个场景： 使用上诉的三角测距方法，其中两个相机的内参K已知： 通过找到两个图片的关联点，最小化距离。 Multi(stereo)-view geometry (多视角几何)camera geometry：找到两张图像中的对应点，找出相机的内参矩阵，位置，以及位姿。 scene geometry： 从二维图像中恢复出三维场景的结果。 给出A图片中的一个点，如何从另一张图片中找出其对应点？ 计算两张图像中，关联点的关联关系： 对于相机来说，我们通过调节相机参数使得两个视角的K均为单位矩阵简化函数的运算。 如上图，找到一个向量垂直于对极几何平面，得到上诉等式。 对上式进行变换： 进一步对上式进行分析，得到F变量： 已知F变量可以从一张图片中得到另一张图片的对应点,F变换包含了对极几何的两个视点以及相机内参的信息。此外F还反映了在视点下场景的变换关系： F变换的估计得到两张图片的F变换矩阵可以得到两张图像的关联点，于是有很多算法为估计F而提出：the eight-point algorithm八点法，通过选择图上的8个关联点，联立方程$P^{T}Fp’ = 0$,得到最终的结果。此外可以选择过完备的关联点对，联立方程通过SVD分解最小化误差的方式估计F。以及正则化八点法等等。 silde 2019/9/23 slide 4: Single View Metrology2D环境下的变换等距变换：$$\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{ll}{\mathrm{R}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{e}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]$$该变换对原始图片进行旋转和平移，不改变物体的相对位置和大小。 相似变换：$$\left[\begin{array}{l}{x^{\prime}} \ {y^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{S R} &amp; {t} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]=H_{s}\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]$$对原始物体进行旋转、平移、缩放等操作，改变了物体的大小。 仿射变换：$$\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{a}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]$$该变换在一个方向上对图像进行拉伸。 投影变换：$$\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {\mathrm{V}} &amp; {\mathrm{b}}\end{array}\right]\left[\begin{array}{c}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{p}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]$$交叉比例： 灭点和线平面中的直线方程可以用矩阵来表示，两条直线叉乘得到垂直于该平面的垂线。 对于两条平行线，在齐次空间中，他们存在一个焦点（灭点）。该灭点位于垂直于两条线的一个方向向量上。 空间中的点或线都会在一个无限远的平面上汇聚于一个灭点： 图像中两条线相交于一个灭点，直线与夹角间存在下面的计算关系： silde 2019/9/23 从单张图片中估计物体的几何结构 根据上一页的ppt可以看出来，当夹脚为0的时候，K变量中有5个自由度，需要通过三个角度来计算相机的内参k： extension计算出k之后，可以根据k去恢复相机坐标系中的场景朝向： slide 3: camera calibertion相机的标定是十分重要的一个步骤，从图片中预测出相机的位姿和焦距等。 下面是坐标映射方程：$$\mathrm{P}^{\prime}=\mathrm{M} \mathrm{P}_{\mathrm{w}}=\mathrm{K}[\mathrm{R} \quad \mathrm{T}] \mathrm{P}_{\mathrm{w}}$$相机标定的目的是从图像中估计出相机的内参和外参。 相机标定的目标为：已知物体在实际环境中的坐标，物体在图像中的坐标，预测映射矩阵M。映射矩阵M由相机的外参，内参矩阵，共有11个未知量。因此需要11个方程，6个correspondences可以解决这个问题。实际场景中，我们可以加入更多的约束，使得结果更加的robots。$$p_{i}=\left[\begin{array}{c}{u_{i}} \ {v_{i}}\end{array}\right]=\left[\begin{array}{c}{\frac{\mathbf{m}_{1} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}} \ {\frac{\mathbf{m}_{2} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}}\end{array}\right]=M P_{i}$$常用标定板进行相机的标定，用相机各个角度多次拍摄同一块标定板，然后将图片以及标定板间距输入程序中，即可算出相机的内参K（焦距，物距，倾斜度等等）。 slide 2019/09/20 slide 2: camera models这一课主要对相机的历史，成像原理进行介绍。 1452年leonardo发现了暗箱开始，一直到1822年第一张相片问世，1908年出现彩色的相机，直到现在相机的性能有了巨大的提升。 小孔成像 pinhole camera 小孔成像原理如上，利用光线直线传播性质，通过相似三角形的比例关系得到成像的尺寸位置。成像的比例关系为物距和焦距的比例。 小孔的大小越大成像越模糊，因为光线存在部分的重叠。当小孔变小之后光线之间分离，得到清晰的成效效果。 使用凹透镜来实现光线的聚焦，在成像位置实现模糊和聚焦的区域。凹透镜同样使得相机拍摄的场景发生扭曲。 坐标系统将场景转换到坐标系统上，在视网膜上，设置一个坐标原点添加坐标偏移，其中k，l表示一个缩放单位，即焦距长度转换为焦距需要一个变换： 三维到二维的转换如下：$$P=(x, y, z) \rightarrow P^{\prime}=\left(\alpha \frac{x}{z}+c_{x}, \beta \frac{y}{z}+c_{y}\right)$$ 齐次坐标系（homogeneous coordinates）在传统的笛卡尔坐标系统中，两条平行线是永远不会相交的，但是在透视坐标系中，在无穷远处所有的平行线都会汇聚到一个点，这个点常常被称为灭点。 齐次坐标系常常用N+1个数字来表示N维坐标。用w表示与透视距离有关的系数，两个系统相互转换的关系如下： 进一步提取出一个相机内部参数矩阵，完成这种转变。 相机位置发生偏移时，通过调节camera matrix可以得到精确的坐标位置：$$P^{\prime}=\left[\begin{array}{cccc}{\alpha} &amp; {-\alpha \cot \theta} &amp; {c_{x}} &amp; {0} \ {0} &amp; {\frac{\beta}{\sin \theta}} &amp; {c_{y}} &amp; {0} \ {0} &amp; {0} &amp; {1} &amp; {0}\end{array}\right]\left[\begin{array}{c}{x} \ {y} \ {z} \ {1}\end{array}\right]$$将一个眼前的物体拍摄到相机中，然后构建他的世界坐标系坐标，步骤如下： 首先通过小孔成像的映射关系将实际物体的坐标映射到相机坐标中，需要提前获取的位置信息有物体的实际坐标，相机的内参即焦距、物距、倾斜角度。 得到物体的相机坐标之后将这个坐标转换到世界坐标系中，即进行旋转、平移变换。 图像坐标—投射变换—&gt;摄像机坐标—刚体变换—&gt; 世界坐标 对于整个变换矩阵M，他还有着一些性质，可以直接判断相机是否有歪斜、单元横纵比等。 Slide 2019/9/20 slide 1: introduction第一节课对计算机视觉两个关键技术进行一个的简要的回顾，这也是这门课之后的大纲内容。 Geometry物体的几何学，需要从2D的图像中抽取出3D的信息，重点内容包含相机的标定，相机参数的估计（姿态和焦距）。单图片视角的重建，多图片视角的重建。对极几何等数学映射，结构光以及volumetric stereo（3D物体的体积估计）。 Semantics语义分割对图像的理解，包括目标的分类、标定。这里头也面临很多困难，例如视角的不同，尺度的差异，关照的不同，形变，遮挡等等。 slide 2019/9/19]]></content>
      <categories>
        <category>3D重建</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[some tip about resume]]></title>
    <url>%2F2019%2F09%2F18%2Fsome-tip-about-resume%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>项目总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux 环境安装]]></title>
    <url>%2F2019%2F09%2F06%2Flinux-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[linux 环境下的python3.6安装，以及Linux系统的一些设置。 前言今天进行了linux环境的配置，感觉十分的尽兴，安装过程十分的舒适，一些配置环节比较知道来龙去脉，配置起来很过隐。感触是对linux环境比较熟悉，对这一块的帮助是很大的，其次是也知道了其他人做法其中的道理。 python3.6的安装linux系统默认的python版本有两个，分别是python2.7和python3.5，这次想安装一个比较常用的python3.6。现实条件是我只是一个用户权限的使用者，因此很多sodu操作无法执行。下面基础部分我跳过，重点放在linux环境的配置上。 去官网下载python3.6.tgz安装包，然后安装的时候因为没有root权限（正常安装python3.6，安装文件会放在/usr/bin,/local/bin这些地方），我在目录下新建了一个python3.6目录用来存放安装文件。安装过程：https://my.oschina.net/moonrain/blog/739612，其中`./configure` 修改为./configure --prefix=./python36。 因为默认的python的版本是2.7,这时候需要修改成python3.6，（其实比较明智的做法是用virtualenv创建一个以pyhton3.6版本的环境就可以了。）首先在.bashrc中添加python3.6中bin的路径： 1PATH=&apos;./python/bin:$PATH&apos; 然后创建别名： 1alias python=./python3.6/bin/python3.6 最后source ./bashrc修改完成。 然后还差一点，pip指向的是系统的python2.7，pip3指向的是python3.6，我尝试过修改别名，发现不起效果，最后发现原来系统配置的时候都会source 一下系统的bash，将pip修改为原来的。没办法着时候转向virtualenv。 virtualenv用了好久了virtualenv之后，现在才意识到这个环境包的好用之处，相比annaconda简洁多了，推荐指数max。安装过程如下： 1pip3 install virtualenv virtualenv中默认使用的python是当前python指向的python版本，当然也可以自己设置成自己指定python的版本。 1virtualenv -p ./python3.6/bin/python3 zhou_env 激活virtualenv： 1source zhou_env/bin/activate 下面就可以正常的在python3.6的环境中使用pip了，嗑盐了。 退出虚拟环境： 1deactivate 下面贴一个关于linux文件夹先后顺序的链接： https://perper.site/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/]]></content>
      <categories>
        <category>tool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Image Super-Resolution Using Very Deep Residual Channel Attention Networks(RCAN)]]></title>
    <url>%2F2019%2F09%2F05%2FImage-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-RCAN%2F</url>
    <content type="text"><![CDATA[RCAN这篇文章是2018年发表在ECCV上的一篇poster，作者Yunlun Zhang也是该领域的一个大牛。在文中作者对比了各项性能指标，均达到了state of the art的效果。在目前超分辨率领域越做越细的前提下，以提升指标性能为目的的文章越来越不好发表了。下面介绍一下文章的思路、highlight希望能够有点启发。 arxiv： https://arxiv.org/pdf/1807.02758.pdf github：https://github.com/yulunzhang/RCAN 摘要在超分辨率领域中，深度的卷积模型十分的重要，但是训练起来十分的困难；低频的输入或特征中有着很丰富的信息，但是这些信息在网络中被同等的对待，阻碍了卷积网络表达特征的能力。 为了解决上述问题，作者提出一个残差通道注意力网络（RCAN），通过提出RIR（residual in residual）模块来构建深度的网络，RIR中包含着许多的RG（residual group），RG中包含着许多的residual block，以及许多长连接跳跃（LSC）。RIR允许低频信息通过多个跳跃直接传播，使得网络集中学习图像中的高频部分。作者提出CA（channel attention） 通道注意力机制，通过考虑通道间的相互依赖性，来重新调整通道特征。 介绍作者在这部分内容中列举了很多网络，目的是说明深度的网络在超分辨率问题上是有效果的。作者提出的RIR结构，提升网络的深度。对于低频信息的相互依赖性问题，作者提出了CA方法来调整通道的特征。 Residual Channel Attention Network（RCAN）RCAN的网络结构如下图所示： RCAN网络结构由四部分组成，第一部分是卷积浅层特征提取模块，第二部分是RIR深层特征提取模块，第三部分是上采样模块，第四部分是重建模块，网络最后的卷积层具有三个通道，表示输出的颜色。 RCAN网络损失函数采用L1损失：$$L(\Theta)=\frac{1}{N} \sum_{i=1}^{N}\left|H_{R C A N}\left(I_{L R}^{i}\right)-I_{H R}^{i}\right|_{1}$$ Residual in Residual (RIR)RIR结构中包含着若干个（10）residual groups（RG）结构以及long skip connection。每一个RG中包含着如果个（20）residual channel attention block（RCAB）模块，内部含有许多短的连接。 RIR结构通过堆叠残差块，利用skip connection这种结构来克服网络难以训练的问题。 channel attention（CA） 输入是一个 H×W×C（64） 的特征，我们先进行一个空间的全局平均池化得到一个 1×1×C 的通道描述。接着，再经过一个下采样层和一个上采样层得到每一个通道的权重系数，将权重系数和原来的特征相乘即可得到缩放后的新特征，整个过程实际上就是对不同通道的特征重新进行了加权分配。 其中，下采样和上采样层都利用 1×1 的卷积来实现，下采样层的通道数减少 r 倍，激活函数为 Relu，上采样层的激活函数为 Sigmoid。在论文中，作者采用的通道数 C=64，r = 16。 Residual channel attention Block（RCAB） 输入一个特征 input，我们首先进行一个卷积-Relu-卷积操作得到 f，然后 f 再经过一个 CA 模块进行重新缩放得到 x，最后将 x 和 input 相加得到输出特征。其中，卷积操作都采用 3×3 的卷积核。 实现的细节RIR中RG个数：10；RG中RCAB的个数：20，conv的大小：3 x 3，channel：64 通道下采样的scale：16，C/16 = 4。]]></content>
      <categories>
        <category>super resolution</category>
      </categories>
      <tags>
        <tag>SR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超分辨率论文摘要阅读]]></title>
    <url>%2F2019%2F09%2F03%2F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[这篇博客的主要目的为了记录阅读的超分辨率论文的摘要部分，了解超分辨率领域的研究前沿进度。 值得注意的网页 github上关于超分辨率领域的SOAT论文的整理：https://github.com/YapengTian/Single-Image-Super-Resolution 知乎上关于超分辨率一些大牛的主页： https://www.zhihu.com/search?type=content&amp;q=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87 论文阅读Xuaner Zhang, Qifeng Chen, Ren Ng, and Vladlen Koltun. Zoom to Learn, Learn to Zoom, CVPR 2019. [Paper]作者将超分辨率方法应用在数字变焦中，他认为真实的图片能够比生成的图片更能保留数据的细节，网络的性能也将更好。那些在制作的数据集上训练的模型，通常在实际场景下性能不好，因此本文使用单反去直接制作数据集。高分辨率使用长焦距拍摄，低分辨率使用短焦距拍摄。 由于使用单反采集的数据高低配置无法完全对齐，因此作者提出了CoBi loss function，完美的解决了这个问题。这就是本文的主要insight。 Image Super-Resolution Using Very Deep Residual Channel Attention Networks]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>超分辨率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电阻率成像数据分析]]></title>
    <url>%2F2019%2F08%2F30%2F%E7%94%B5%E9%98%BB%E7%8E%87%E6%88%90%E5%83%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[电阻率成像(ERI) 是一种地球物理技术，用于通过在表面或在一个或多个钻孔中的电极进行的电阻率测量来对底层亚表面结构进行成像。 电阻率数据的采集方位电阻率成像测井是在双侧向测井基础上发展起来的，在主电极或屏蔽电极中部沿圆周剖分成12个长方形小电极（见图），每个电极的定向方位成30°辐射，12个方位电极电位彼此相等。 电流的大小反映了该方向内地层电阻率的变化。测量每个方位电极的供电电流和环状监督电极M 3 （M 4 ）相对铠装电缆钢丝外皮的电位，可计算该方向地层的视电阻率。 地层中不同的岩石（泥岩、砂岩、石灰岩）、流体其电阻率是不同的，通过测量井壁 各点的电阻率值，然后将电阻率值的相对高低用灰度或色度图表示出来。井壁可以表示成一张黑白/彩色图像。 颜色映射如下： 得到的电阻率成像图像如下： 电阻率数据的分析微电极测井使用的电极紧贴井壁，电阻数据是测井井周一圈的数据，因此同一个水平面上数据的空间位置十分的接近。数据在空间关系上有一定的相关性。  上图中的绿线是地层的分层线。对电阻率的分析过程是将电阻率数据传入一个专业软件中，将会自动生成一些简单的分层线，然后采用人工标注的方式，对电阻率数据标注进行完善。最终得到完善的电阻率标注图。 对超分辨率问题来说，有什么内在的约束？ 得到新数据时，需要明白测量的精度（2.5mm），井口的大小这些数据。 反演的概念：通过一些观察到的局部信息，反推相关过程发生的原因以及机制。根据结果或信息反推事件发生的过程称为反演，而对事件发生过程的预测则称为正演。例如根据地表上探测到的部分数据，来推测地表以下的地质结构。]]></content>
      <categories>
        <category>super resolution</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[并查集，python示例]]></title>
    <url>%2F2019%2F08%2F27%2F%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%8Cpython%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[并查集是一种数据结构，在合并不相交的集合，用来判断一个图中是否有环这种问题时，具有很高的性能。 并查集并查集的主要操作就是为一个集合中的元素找到一个代表（根节点）。并查集的基本操作是合并两个集合，当拿到两个节点，第一步需要找到各自节点的根，然后选择一个节点作为新的代表，那么就完成了两个集合的合并。 并查集实现并查集可以使用一个数组来表示，数组表示图上的节点，下标表示节点的编号，数组的值表示该下标的父节点是哪一个。例如A[0] = 1 表示节点0的父节点是节点1. 并查集的实现过程主要分为两步，一步是实现节点的根的查找，另一步是实现两个集合的合并，这里包含了节点的路径压缩。 下面实现find_root算法： 12345678joint = 10parent = [-1]*10def find_root(parent,x): x_root = x while parent[x_root] != -1: x_root = parent[x_root] return x_root 上面代码说明当x不是根节点时，循环继续往上找，当x时根节点时则返回。 下面是union的算法： 123456789def union_joint(parent,x,y): x = find_root(parent,x) y = find_root(parent,y) if x == y: print('circle') return 0 else: parent[x] = y return 1 上诉代码如果返回的结果是0的话则说明存在一个环，否则不存在环。 存在一种极端的情况，即每次union合成的集合它形成了一个很长的链，每次寻找一个节点的根需要遍历一下整个节点，复杂度太高，下面在union中引入路径压缩的思想，即引入另一个数组rank，表明当前节点的位置，当进行union的时候，rank小的数连接到rank大的树底下，当两个rank相同的时候，可以随意连接，但是连接之后作为父节点的rank需要加1： 123456789101112131415rank = [0]*jointdef union(parent,x,y,rank): x = find_root(parent,x) y = find_root(parent,y) if x == y: print('circle') return 0 else: if rank[x] &gt; rank[y]: parent[y] = x elif rank[x] &lt; rank[y]: parent[x] = y else: parent[x] = y rank[y] += 1 在判断一个图是否存在环的时候，依次遍历图的所有边，如果union返回的结果是0的话，表明有环。 下面是一道lettcode的题目，思路就是用并查集来求解： 547.Friend Circles 思路是将朋友的关系用边来表示，最后看parent数组中有多少根节点（等于-1）。 解法代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution(object): def findCircleNum(self, M): """ :type M: List[List[int]] :rtype: int """ edge = [] if M == [] or M[0] == []: return 0 for i in range(len(M)): for j in range(len(M[0])): if i &lt;= j: break if M[i][j] == 1: edge.append([i,j]) parent = [-1]*len(M) rank = [0]*len(M) def find_root(parent,x): x_root = x while parent[x_root] != -1: x_root = parent[x_root] return x_root def union_joint(parent,x,y,rank): x = find_root(parent,x) y = find_root(parent,y) if x != y: if rank[x] &lt; rank[y]: parent[x] = y elif rank[x] &gt; rank[y]: parent[y] = x else: parent[x] = y rank[y] += 1 for e in edge: union_joint(parent,e[0],e[1],rank) ans = 0 for i in parent: if i == -1: ans += 1 return ans]]></content>
      <categories>
        <category>算法扫盲</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表，python示例]]></title>
    <url>%2F2019%2F08%2F25%2F%E5%93%88%E5%B8%8C%E8%A1%A8-python%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[哈希表一直都是一个很重要的数据结构，从上大学开始，一直有听闻，面试题也有相当的涉及，接下来继续扫盲。 哈希表哈希表根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值通过哈希函数映射到表中一个位置来访问记录，以加快查找的速度。 哈希表的工作原理如下 首先拿到key值，通过哈希函数将key值转化为数组的下标，在插入元素之前，判断该下标位置上是否已经存在元素，若已经存在元素则称为collision（碰撞）。 当元素发生碰撞时，存在很多方法来处理这种碰撞，常用的方法有链接法（java hashmap的实现），每一个index位置连一个链表，用来存储发生碰撞的元素。 另一种解决碰撞的方法为开放寻址法（python中dict的实现）。 开放寻址法指当前位置发生了碰撞，采用某种方法（线性，二次，双倍散列）对哈希表中其他位置进行访问。如果哈希表全都装满了则需要对哈希表进行扩容。 python 中dict常用方法遍历操作： 123for i in dicts: print(i) print(dicts[i]) 删除操作： 123dicts.pop(key)dicts.popitem() #删除最后一个加入的元素del dicts #直接删除元素]]></content>
      <categories>
        <category>算法扫盲</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序，python实现]]></title>
    <url>%2F2019%2F08%2F22%2F%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%8Cpython%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[堆排序这个名称一直困扰着我，现在扫一下盲。 堆首先介绍一下堆的概念：堆是一棵完全二叉树，即指允许最后一层的叶子是不满的，其他层都是满的。叶子节点的出现顺序也是从左边开始向右边累加，不允许中断。父结点必须比子节点要大。 堆排序堆排序的算法复杂度是O(nlog(n))。由于节点满足完全二叉树，因此可以通过下标的关系找到父节点，子节点。 例如当前节点为i，父节点：(i - 1) /2。左孩子：2i+1,右孩子：2i+2。因此堆排序的策略如下： 堆排序步骤 构造堆结构，从最后一个元素（叶子）的父节点开始，循环到根节点，每次执行heapify函数（三个节点，找最大的放到根位置）。 位于根节点的元素是最大的，每次将根节点的数拿出来，作为排序的最后一个值。然后将最后一个叶节点放到根的位置。依次循环下去，直到结束。 实现代码1234567891011121314151617181920212223242526272829303132333435nums = [9,3,4,1,5,6,8,7]def heapify(nums,n,i): ''' i 表示要进行调换的根节点位置 ''' c1 = 2*i + 1 c2 = 2*i + 2 max_index = i if c1 &lt;= n and nums[c1] &gt; nums[i]: max_index = c1 if c2 &lt;= n and nums[c2] &gt; nums[max_index]: max_index = c2 if max_index != i: nums[max_index],nums[i] = nums[i],nums[max_index] heapify(nums,n,max_index)def build_heap(nums): n = len(nums) - 1 last_index = (n - 1) // 2 for i in range(last_index+1)[::-1]: heapify(nums,n,i)def heap_sort(nums): print(nums) build_heap(nums) print(nums) for i in range(len(nums))[::-1]: print(i) nums[0],nums[i] = nums[i],nums[0] heapify(nums,i-1,0) print(nums) heap_sort(nums)]]></content>
      <categories>
        <category>算法扫盲</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习代码的框架]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[以pytorch为例，梳理一下深度学习中，数据的读取，神经网络的搭建，NMS，以及各个指标的计算流程。 main 函数，程序入口，以及代码配置通常main函数中，通过实现argparse功能包，从函数的外部接受参数的传入，对数据，网络等进行一些基本的配置。argparse的使用方法：https://docs.python.org/zh-cn/3/library/argparse.html main函数中一些常用的配置项： 数据集的格式：coco，csv，pascal voc等等 数据的路径，包括训练集，测试集的路径等等 网络的一些细节配置，如深度，backbone 类型 一些功能的开关设置，如数据的增强等 训练过程中，一些变量的设置，比如epoch的设置，batch_size的设置等等 数据读取部分数据读取部分的操作包括数据集文件的读取，对图片进行数据的增强，继承dataloader实现数据的批量读取。 数据文件的读取这部分读取任务主要包括读取annotation文件，以及class_id文件，这里以csv格式的数据集文件为例。 首先实现一个CSVDataset类，继承至torch.utils.data.Dataset类。该类必须实现__len__,__getitem__两个方法。 在CSVDataset方法的__init__中，进行数据集文件的读取，最终将得到： self.classes self.image_names : list 包含所有的数据集图片路径 self.image_data: dict[image_name] = [ {x1,y1,x2,y2,class_name},…] __getitem__函数中需要实现的方法有根据下标来得到image，以及其对应的标注。最终返回的格式为： sample = {&#39;img&#39;: img, &#39;annot&#39;: annot}。在返回之前，如果有数据增强部分，还需要进行数据的增强。 数据增强数据增强的方法有很多种，常用的图片的翻转，切割，resize，归一化等等。数据增强利用一张图片，得到它的许多副本，有效的增大数据集。数据增强能够起效果的一个本质因素在于，卷积操作对位移，视角，图片大小，光照等因素具有不变性。数据增强有线下增强和线上增强两种方式，后一种方式在dataloader提取数据的时候，才对数据进行增强。 数据增强的方法通常可以写成一个类，通过pytorch中的transforms.Compose([Augumenter(),Resizer()]) 来对所有的增强方法进行整合。 Normalizer 实现一个Normalizer类，覆盖其中的__call__方法，对每张图片做一个正则化。 1234567891011class Normalizer(object): def __init__(self): self.mean = np.array([[[0.485, 0.456, 0.406]]]) self.std = np.array([[[0.229, 0.224, 0.225]]]) def __call__(self, sample): image, annots = sample['img'], sample['annot'] return &#123;'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots&#125; argument 实现对图片的翻转，需要注意对标注也要进行处理。 Resizer 该方法意图将图片的大小限制在一定范围以内。因此在缩放的时候，需要找到最大的缩放比例,同时保证图片能够被32整除。 123456789101112131415161718192021222324252627282930313233class Resizer(object): """Convert ndarrays in sample to Tensors.""" def __call__(self, sample, min_side=608, max_side=1024): #将图片resize到608，1024以下的大小 image, annots = sample['img'], sample['annot'] # 不能超过这个尺寸（有一边等于这个尺寸） rows, cols, cns = image.shape smallest_side = min(rows, cols) # rescale the image so the smallest side is min_side scale = min_side / smallest_side # check if the largest side is now greater than max_side, which can happen # when images have a large aspect ratio largest_side = max(rows, cols) if largest_side * scale &gt; max_side: scale = max_side / largest_side # resize the image with the computed scale image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale))))) rows, cols, cns = image.shape pad_w = 32 - rows%32 pad_h = 32 - cols%32 new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32) new_image[:rows, :cols, :] = image.astype(np.float32) # 两个边长需要保证被32整除，少掉的的那部分使用0来补全 annots[:, :4] *= scale return &#123;'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale&#125; 数据调用 dataloaderpytorch通过实现dataloader方法来实现网络训练时，每次iteration的数据的输出。dataloader的逻辑是，每次从dataset中调用__getitem__()获取单个数据，然后组合成batch，在使用collate_fn参数对batch进行一些操作。 torch.utils.data.Dataloader中的参数： dataset(Dataset) – dataset from which to load the data. batch_size(int, optional) – how many samples per batch to load (default: 1). shuffle(bool, optional) – set to Trueto have the data reshuffled at every epoch (default: False). sampler(Sampler, optional) – defines the strategy to draw samples from the dataset. If specified, shufflemust be False. batch_sampler(Sampler, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last. num_workers(int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0) collate_fn(callable, optional) – merges a list of samples to form a mini-batch. pin_memory(bool, optional) – If True, the data loader will copy tensors into CUDA pinned memory before returning them. drop_last(bool, optional) – set to Trueto drop the last incomplete batch, if the dataset size is not divisible by the batch size. If Falseand the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False) timeout(numeric, optional) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0) worker_init_fn(callable, optional) – If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None) 算法中使用如下参数： 1dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler) 其中dataset_train为Dataset类的对象，如上实现数据问价读取的部分。num_workers设置了这个类的线程数。batch_sampler 设置了每次从数据集中返回一个batch的sample的策略。collate_fn 将一系列的样本融合成一个小的mini-batch。 首先是batch_sampler: 继承至采样器类，需要实现其中的__len__方法，__iter__方法。该参数的作用是将数据集做成许多group组成的一个list。 12345678910111213141516171819202122232425class AspectRatioBasedSampler(Sampler): def __init__(self, data_source, batch_size, drop_last): self.data_source = data_source self.batch_size = batch_size self.drop_last = drop_last self.groups = self.group_images() def __iter__(self): random.shuffle(self.groups) for group in self.groups: yield group def __len__(self): if self.drop_last: return len(self.data_source) // self.batch_size else: return (len(self.data_source) + self.batch_size - 1) // self.batch_size def group_images(self): # determine the order of the images order = list(range(len(self.data_source))) order.sort(key=lambda x: self.data_source.image_aspect_ratio(x)) # divide into groups, one group = one batch return [[order[x % len(order)] for x in range(i, i + self.batch_size)] for i in range(0, len(order), self.batch_size)] 如上，这个方法将数据分别存入group中，然后组成一个groups的list。通过一个__iter__()方法，迭代的方式将数据输出。每次输出一个batch大小的数据。 collate_fn参数： 该参数接受来自batch_sampler的数据，对数据进行进一步的处理。 12345678910111213141516171819202122232425def collater(data): imgs = [s['img'] for s in data] annots = [s['annot'] for s in data] scales = [s['scale'] for s in data] widths = [int(s.shape[0]) for s in imgs] heights = [int(s.shape[1]) for s in imgs] batch_size = len(imgs) max_width = np.array(widths).max() max_height = np.array(heights).max() padded_imgs = torch.zeros(batch_size, max_width, max_height, 3) for i in range(batch_size): img = imgs[i] padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img max_num_annots = max(annot.shape[0] for annot in annots) if max_num_annots &gt; 0: annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1 if max_num_annots &gt; 0: for idx, annot in enumerate(annots): #print(annot.shape) if annot.shape[0] &gt; 0: annot_padded[idx, :annot.shape[0], :] = annot else: annot_padded = torch.ones((len(annots), 1, 5)) * -1 padded_imgs = padded_imgs.permute(0, 3, 1, 2) return &#123;'img': padded_imgs, 'annot': annot_padded, 'scale': scales&#125; 上面的操作，将同一个batch中的图片的大小统一同样的大小。annotation的维度也统一到同样大小的维度。然后进行RGB通道的变换之后，放回一个dict。 上面这些步骤就完成了数据的loader，通过for循环从其中取得元素。 retinanet网络结构下面从数据流动的角度分析一下retinanet的各个结构的组成。 retinanet的特征提取部分，使用的是resnet，resnet有多种深度的选择，分别有18，34，50，101，152五种深度。常用的网络深度为50，101: 123456789def resnet50(num_classes, pretrained=False, **kwargs): """Constructs a ResNet-50 model. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet """ model = ResNet(num_classes, Bottleneck, [3, 4, 6, 3], **kwargs) if pretrained: model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], model_dir='.'), strict=False) return model 让我们一行一行来看，第一个调用了ResNet()类，创建了一个ResNet对象。ResNet继承至nn.Module,需要实现函数__init__以及forward()两个方法，通常将可学习的参数放到构造函数__init__()中，在forward中实现网络数据的流动，即可实现网络的自动求导机制。 ResNet resnet首次提出残差的思想，传统的卷积网络或者全连接网络在信息传递的时候或多或少会存在信息丢失，损耗等问题，同时还有导致梯度消失或者梯度爆炸，导致很深的网络无法训练。ResNet通过学习残差的方式，在一定程度上解决了网络退化和梯度消失的问题。ResNet通过大量叠加残差块的方式，加深网络的深度的同时，保证了网络的梯度不消失。ResNet有着两种不同的残差单元。分别是basicBlock 和 bottleneck结构。深层次网络使用bottleneck结构，每次经过残差结构之前都对数据进行一次降维，大大降低了网络的参数量。 bottleneck的结构feature经过第一个1x1的卷积层，将特征的维度压缩，对压缩后的特征进行3x3的卷积，然后经过1x1卷积层，将特征的维度放大到原来的大小。 bottleneck的代码如下： 1234567891011121314151617181920212223242526272829303132class Bottleneck(nn.Module): expansion = 4 def __init__(self, inplanes, planes, stride=1, downsample=None): super(Bottleneck, self).__init__() self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False) self.bn1 = nn.BatchNorm2d(planes) self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(planes) self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False) self.bn3 = nn.BatchNorm2d(planes * 4) self.relu = nn.ReLU(inplace=True) self.downsample = downsample self.stride = stride def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) if self.downsample is not None: residual = self.downsample(x) out += residual out = self.relu(out) return out pytorch中常用的搭建网络的函数如下： Conv2d卷积： 12345678910111213141516import torch.nn as nnnn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)参数：in_channels(int) – 输入信号的通道out_channels(int) – 卷积产生的通道kerner_size(int or tuple) - 卷积核的尺寸stride(int or tuple, optional) - 卷积步长padding(int or tuple, optional) - 输入的每一条边补充0的层数dilation(int or tuple, optional) – 卷积核元素之间的间距groups(int, optional) – 从输入通道到输出通道的阻塞连接数bias(bool, optional) - 如果bias=True，添加偏置输入：input: (N,C_in,H_in,W_in) 输出：output: (N,C_out,H_out,W_out)计算公式：Fout = (Fin + 2*padding-kernel)/stride + 1 batchNorm2d： 在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。 在验证时，训练求得的均值/方差将用于标准化验证数据。 12345678BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)参数：num_features： 来自期望输入的特征数，该期望输入的大小为'batch_size x num_features x height x width'eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。momentum： 动态均值和动态方差所使用的动量。默认为0.1。affine： 一个布尔值，当设为true，给该层添加可学习的仿射变换参数。输入：（N, C，H, W) - 输出：（N, C, H, W）值得至于的是，参数num_feature写channel数即可。 ReLU：修正线性单元函数 1234nn.ReLU(inplace=False)参数：inplace：表示是否进行覆盖计算，节省内存不会引起数据维度的变化 MaxPool2d 层 1234567891011nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)参数：kernel_size(int or tuple) - max pooling的窗口大小stride(int or tuple, optional) - max pooling的窗口移动的步长。默认值是kernel_sizepadding(int or tuple, optional) - 输入的每一条边补充0的层数dilation(int or tuple, optional) – 一个控制窗口中元素步幅的参数return_indices - 如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助ceil_mode - 如果等于True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作输入: (N,C,H_&#123;in&#125;,W_in) 输出: (N,C,H_out,W_out)计算公式：Fout = (Fin + 2*padding - kernel)/stride + 1 nn.Upsample 上采样操作对channel进行采样： 12nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None)给定上采样策略mode，上采样的大小：scale_factor nn.Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。 12345downsample = nn.Sequential( nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(planes * block.expansion), ) 网络结构类继承至nn.Module,需要实现函数__init__以及forward()两个方法，通常在init中完成网络层的初始化工作，定义各类的网络层。在forward中完成网络层数据的流动。 retinanet金字塔模型的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class PyramidFeatures(nn.Module): def __init__(self, C3_size, C4_size, C5_size, feature_size=256): super(PyramidFeatures, self).__init__() # upsample C5 to get P5 from the FPN paper self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=1, stride=1, padding=0) self.P5_upsampled = nn.Upsample(scale_factor=2, mode='nearest') self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1) # add P5 elementwise to C4 self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=1, stride=1, padding=0) self.P4_upsampled = nn.Upsample(scale_factor=2, mode='nearest') self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1) # add P4 elementwise to C3 self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=1, stride=1, padding=0) self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1) # "P6 is obtained via a 3x3 stride-2 conv on C5" self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=3, stride=2, padding=1) # "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6" self.P7_1 = nn.ReLU() self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=2, padding=1) def forward(self, inputs): C3, C4, C5 = inputs P5_x = self.P5_1(C5) P5_upsampled_x = self.P5_upsampled(P5_x) P5_x = self.P5_2(P5_x) P4_x = self.P4_1(C4) P4_x = P5_upsampled_x + P4_x P4_upsampled_x = self.P4_upsampled(P4_x) P4_x = self.P4_2(P4_x) P3_x = self.P3_1(C3) P3_x = P3_x + P4_upsampled_x P3_x = self.P3_2(P3_x) P6_x = self.P6(C5) P7_x = self.P7_1(P6_x) P7_x = self.P7_2(P7_x) return [P3_x, P4_x, P5_x, P6_x, P7_x] retinanet在金字塔之后，接了一个回归网络以及分类网络，分别对边框位置以及类别进行分类。 回归网络简单的接了五个卷积层，保持feature的大小不变，每一个channel的维度最终降为num_anchors x 4，即每一个channel需要回归出num_anchors x 4 个坐标点。 1234567891011121314151617181920212223242526272829303132333435363738class RegressionModel(nn.Module): def __init__(self, num_features_in, num_anchors=9, feature_size=256): super(RegressionModel, self).__init__() self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=3, padding=1) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act2 = nn.ReLU() self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act3 = nn.ReLU() self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act4 = nn.ReLU() self.output = nn.Conv2d(feature_size, num_anchors*4, kernel_size=3, padding=1) def forward(self, x): out = self.conv1(x) out = self.act1(out) out = self.conv2(out) out = self.act2(out) out = self.conv3(out) out = self.act3(out) out = self.conv4(out) out = self.act4(out) out = self.output(out) # out is B x C x W x H, with C = 4*num_anchors out = out.permute(0, 2, 3, 1) return out.contiguous().view(out.shape[0], -1, 4) 上诉最后一行值得注意一下view()函数相当于numpy中的reshape函数，但是要求数据必须在内存中是连续存储的。由于permute函数，改变了数据的分布（浅拷贝）。因此在使用view之前，需要执行contiguous函数使得数据内存连续分布。最终out的shape为[batch_size，w x h ，4]。上诉得到的out最终输入criterion中，计算loss。 分类模型的网络结构和回归模型的结构相同，唯一不同的地方在于最终输出的channel的大小。分类模型输出的channel大小为anchor的数量乘以类别（num_anchor x num_classes）。即每一个框都要预测一个类别信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class ClassificationModel(nn.Module): def __init__(self, num_features_in, num_anchors=9, num_classes=80, prior=0.01, feature_size=256): super(ClassificationModel, self).__init__() self.num_classes = num_classes self.num_anchors = num_anchors self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=3, padding=1) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act2 = nn.ReLU() self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act3 = nn.ReLU() self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1) self.act4 = nn.ReLU() self.output = nn.Conv2d(feature_size, num_anchors*num_classes, kernel_size=3, padding=1) self.output_act = nn.Sigmoid() def forward(self, x): out = self.conv1(x) out = self.act1(out) out = self.conv2(out) out = self.act2(out) out = self.conv3(out) out = self.act3(out) out = self.conv4(out) out = self.act4(out) out = self.output(out) out = self.output_act(out) # out is B x C x W x H, with C = n_classes + n_anchors out1 = out.permute(0, 2, 3, 1) batch_size, width, height, channels = out1.shape out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes) return out2.contiguous().view(x.shape[0], -1, self.num_classes) 最后一行首先将out的维度控制在anchor x num_classes，然后通过一个view将其变为[x.shape[0],W x H x anchor, num_classes]，每一个值表示一个框的类别，然后到criterion中去做预测。 Torch.cat 用法：https://blog.csdn.net/qq_39709535/article/details/80803003 接下来需要生成anchor。 anchor的生成anchor的设置上面，对于retinaNet最终的P3，P4，P5，P6，P7均有一个不同的设置。anchor的长宽比和scale的大小分别有三种设置，一共有9种组合。anchor的大小与feature map的大小也是相关的。 12self.ratios = np.array([0.5,1,2])self.scales = np.array([2**0,2**(1.0/3.0),2**(2.0/3.0)]) 几个常用的函数： 1234a = [1,2,3]a = np.tile(a,(2,3))# a = [[1,2,3,1,2,3,1,2,3] [1.2,3,1,2,3,1,2,3]] np.repeat 1234a = [1,2,3]a = np.repeat(a,2)# a = [1,1,2,2,3,3]# 与np.tile的区别是，他是一个元素一个元素的增加后进行排序的。tile则是一起增加。 生成anchor的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293class Anchors(nn.Module): def __init__(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None): super(Anchors, self).__init__() if pyramid_levels is None: self.pyramid_levels = [3, 4, 5, 6, 7] if strides is None: self.strides = [2 ** x for x in self.pyramid_levels] if sizes is None: self.sizes = [2 ** (x + 2) for x in self.pyramid_levels] if ratios is None: self.ratios = np.array([0.5, 1, 2]) if scales is None: self.scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]) def forward(self, image): # image = [2,3,640,832] image_shape = image.shape[2:] image_shape = np.array(image_shape) image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in self.pyramid_levels] # compute anchors over all pyramid levels all_anchors = np.zeros((0, 4)).astype(np.float32) for idx, p in enumerate(self.pyramid_levels): anchors = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales) shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors) all_anchors = np.append(all_anchors, shifted_anchors, axis=0) all_anchors = np.expand_dims(all_anchors, axis=0) return torch.from_numpy(all_anchors.astype(np.float32)).cuda()def generate_anchors(base_size=16, ratios=None, scales=None): """ Generate anchor (reference) windows by enumerating aspect ratios X scales w.r.t. a reference window. """ if ratios is None: ratios = np.array([0.5, 1, 2]) if scales is None: scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]) num_anchors = len(ratios) * len(scales) # 9个点 # initialize output anchors anchors = np.zeros((num_anchors, 4)) # 每一个位置上都有9个点，每个点都有四个坐标值 # scale base_size,feature 的大小与scale相乘，得到每一层anchor的大小 anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T # compute areas of anchors areas = anchors[:, 2] * anchors[:, 3] # correct for ratios 构造长宽比 anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales))) anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales)) # transform from (x_ctr, y_ctr, w, h) -&gt; (x1, y1, x2, y2) anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T return anchors def shift(shape, stride, anchors): shift_x = (np.arange(0, shape[1]) + 0.5) * stride shift_y = (np.arange(0, shape[0]) + 0.5) * stride shift_x, shift_y = np.meshgrid(shift_x, shift_y) # shifts = [shape[0]*shape[1],4] shifts = np.vstack(( shift_x.ravel(), shift_y.ravel(), shift_x.ravel(), shift_y.ravel() )).transpose() # add A anchors (1, A, 4) to # cell K shifts (K, 1, 4) to get # shift anchors (K, A, 4) # reshape to (K*A, 4) shifted anchors A = anchors.shape[0] K = shifts.shape[0] # 下面这一行进行了广播赋值，每一行都赋予维度不同的行进行广播， # 最终形成[1,A,4] + [k,1,4] = [k,A,4],其中k = shape[0]*shape[1] # 也就是说每一个像素位置都将产生9个anchor，每个anchor有四个坐标。 shape的大小则是由计算产生的 # 每张图片在每个level处的大小在__init__处进行初始化 all_anchors = (anchors.reshape((1, A, 4)) + \ shifts.reshape((1, K, 4)).transpose((1, 0, 2))) all_anchors = all_anchors.reshape((K * A, 4)) return all_anchors 每一行进行分析就是先设置每一层feature map的level，stride，sizes，ratios，scales的值。然后在forward里面generate_anchor()，对每一个level的feature生成符合要求的size的anchor，长宽比组合后共9种anchor。具体的设置可看代码。 然后进入shift()函数，shift()函数的作用是将anchor散布到每一个位置上。流程大概是，一张图片进来，分别计算出这种图片在每一层level上的size大小，然后根据每一层的anchor的大小，每一个像素点位置取9个anchor，然后返回一个$[shape[0]shape[1]9,4]$ 大小的矩阵。 几个函数： 123456789np.meshgrid(x,y)# 将x中元素与y中元素一一对应起来组合成坐标的形式。np.vstack((x,y))# 将x，y中元素按照垂直方向叠加#ravel()a = [[2,2],[1,1]]a.ravel() # 将多维数组拉平，不存生新的副本 a = [2,2,1,1]a.flatten() # 作用与上面函数相同，将返回一个数据副本np.squeeze([[1],[2],[3]]) # 对维度为1的数据进行压缩，得到[1,2,3]a = a.reshape(-1) # 同样能够得到1维的数据a.transpose() # 不指定参数表示对矩阵进行转置 经过上面的过程，在for循环部分，将5层的anchor全部装入一个list中，anchor生成完毕。 torch.cat函数 1234a = [1,2,3]b = [3,4,5]torch.cat((a,b),0) # 垂直方向 [[1,2,3],[3,4,5]]torch.cat((a,b),1) # 水平方向 [[1,2,3,4,5,6]] focalLoss部分focalLoss紧接着上面的一部分。现在回过头来梳理一下网络中数据流动到的位置： 将图片输入ResNet中，通过一个多层金字塔结构，输出5个不同深度feature map（P3，P4，P5，P6，P7），依次将这些层输入到regression网络和classification网络中，每一层都将得到$[batch,wh,4]$的输出和$[batch,wh*anchors,class_nums]$的输出，然后将所有结果cat到一起（水平拼接），即所有level上的anchor 的预测框会被cat到regression_anchor 和classification_anchor中。接下来要做的是判断这些anchor的好坏。根据我们的先验知识，我们产生了一部分anchor的设置，我们将网络产生的anchor和我们预生成的anchor输入focalLoss中，对anchor进行过滤，计算产生的loss。 下面介绍focalLoss： focalLoss部分按batch为单位，每次输入一个batch的数据，然后进行loss的计算。首先计算预设置的anchor与当前图片GT的IoU。（重叠部分 / 相并部分） 12345678910111213def calc_iou(a, b): area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1]) iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) -\ torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0]) ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) -\ torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1]) iw = torch.clamp(iw, min=0) ih = torch.clamp(ih, min=0) ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih ua = torch.clamp(ua, min=1e-8) intersection = iw * ih IoU = intersection / ua return IoU focalLoss主要对每一个anchor进入classification的分类结果，focalLoss的原理如下： 整个网络的loss其实由两部分组成，一部分是分类loss，一部分是回归loss。分类loss即focal loss，回归部分的loss为边框回归的loss。实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126class FocalLoss(nn.Module): #def __init__(self): def forward(self, classifications, regressions, anchors, annotations): alpha = 0.25 gamma = 2.0 batch_size = classifications.shape[0] classification_losses = [] regression_losses = [] anchor = anchors[0, :, :] anchor_widths = anchor[:, 2] - anchor[:, 0] anchor_heights = anchor[:, 3] - anchor[:, 1] anchor_ctr_x = anchor[:, 0] + 0.5 * anchor_widths anchor_ctr_y = anchor[:, 1] + 0.5 * anchor_heights for j in range(batch_size): classification = classifications[j, :, :] regression = regressions[j, :, :] bbox_annotation = annotations[j, :, :] bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1] if bbox_annotation.shape[0] == 0: regression_losses.append(torch.tensor(0).float().cuda()) classification_losses.append(torch.tensor(0).float().cuda()) continue classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4) IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4]) # num_anchors x num_annotations IoU_max, IoU_argmax = torch.max(IoU, dim=1) # num_anchors x 1 #import pdb #pdb.set_trace() # compute the loss for classification # target 的维度为类别的个数 targets = torch.ones(classification.shape) * -1 targets = targets.cuda() # lt : less than 如果IoU_max的面积小于0.4，那么就认为没有匹配上 targets[torch.lt(IoU_max, 0.4), :] = 0 positive_indices = torch.ge(IoU_max, 0.5) num_positive_anchors = positive_indices.sum() # IoU_argmax记录着当前的anchor与哪一个GT比较匹配 # 下面这个赋值语句就是给对应的anchor选择一个GT # 第一个参数选择候选的anchor，第二个参数将候选anchor的坐标值都取到 assigned_annotations = bbox_annotation[IoU_argmax, :] targets[positive_indices, :] = 0 # 下面一句表明对每个满足IoU条件的anchor，赋予一个类别。形成一个one hot编码（原先target的维度长度等于类别的个数） targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1 alpha_factor = torch.ones(targets.shape).cuda() * alpha alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor) # 对focal weight进行统一的计算，然后赋值 focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification) focal_weight = alpha_factor * torch.pow(focal_weight, gamma) # 当y=1,即只有targets=1参与计算 当y=0，即只有targets=0参与 bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification)) # cls_loss = focal_weight * torch.pow(bce, gamma) cls_loss = focal_weight * bce # 注意对target的处理，当IoU在【0.4，0.5】之间时target=-1，不提供loss，其他情况均赋予一个cls_loss cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape).cuda()) # 计算所有的loss在正例中的平均值 classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=1.0)) # compute the loss for regression #只有预测为正例的部分参与边框的回归，下面一部分为回归loss。 if positive_indices.sum() &gt; 0: assigned_annotations = assigned_annotations[positive_indices, :] anchor_widths_pi = anchor_widths[positive_indices] anchor_heights_pi = anchor_heights[positive_indices] anchor_ctr_x_pi = anchor_ctr_x[positive_indices] anchor_ctr_y_pi = anchor_ctr_y[positive_indices] gt_widths = assigned_annotations[:, 2] - assigned_annotations[:, 0] gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1] gt_ctr_x = assigned_annotations[:, 0] + 0.5 * gt_widths gt_ctr_y = assigned_annotations[:, 1] + 0.5 * gt_heights # clip widths to 1 gt_widths = torch.clamp(gt_widths, min=1) gt_heights = torch.clamp(gt_heights, min=1) targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi targets_dw = torch.log(gt_widths / anchor_widths_pi) targets_dh = torch.log(gt_heights / anchor_heights_pi) targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh)) targets = targets.t() targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda() negative_indices = 1 - positive_indices regression_diff = torch.abs(targets - regression[positive_indices, :]) regression_loss = torch.where( torch.le(regression_diff, 1.0 / 9.0), 0.5 * 9.0 * torch.pow(regression_diff, 2), regression_diff - 0.5 / 9.0 ) regression_losses.append(regression_loss.mean()) else: regression_losses.append(torch.tensor(0).float().cuda()) return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True) 边框回归部分学习一个边框的平移以及缩放关系： 最终将得到的分类loss以及regression loss的平均值整合成一个stack，返回下一步。 几个函数： 12345torch.cat(a,b) #水平方向将a与b进行拼接torch.clamp(a,min_val,max_val) # 将a中的值控制在min_val与max_val之间，小于取min_val，大于取max_valmax_val, max_index = torch.max(a,dim = 1) # 返回每一列最大值以及每一列的最大值的索引torch.lt(a,0.4) # 返回a中值小于0.4的元素的下标，ge均类似torch.where(condition,true_val,false_val) # 如果满足条件者该位置为true_val,否则为false_val,其中参数的维度均相同（比如都为三维） 训练阶段训练部分有几个需要完成的工作： 初始化网络，设置优化器等等 将数据从dataloader中取出来 将数据输入网络中，得到网络的loss值 对loss进行反向传播，一些操作如learning rate的降低，梯度的裁剪可以在其中完成 打印出每个batch训练的结果 当训练次数到达一定的epoch时，对网络进行evaluate 保存mAP较高的网络 下面通过代码来解读： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 将训练过程迁移到gpu上 use_gpu = Trueif use_gpu: retinanet = retinanet.cuda()retinanet = torch.nn.DataParallel(retinanet).cuda()retinanet.training = True # 设置优化器为adamoptimizer = optim.Adam(retinanet.parameters(), lr=1e-5) # ；learning rate的缩减器scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)loss_hist = collections.deque(maxlen=500) # 实现了两端的快速添加删除retinanet.train()retinanet.module.freeze_bn()print('Num training images: &#123;&#125;'.format(len(dataset_train)))# 从dataloader中取数据 for epoch_num in range(parser.epochs): retinanet.train() retinanet.module.freeze_bn() epoch_loss = [] for iter_num, data in enumerate(dataloader_train): try: # 清空梯度，由于pytorch在每次backward的时候， # 会进行梯度的累积，这样的做法方便训练RNN模型 # 但是在训练普通模型的时候，需要将累积的梯度清空。 # 清空后做backward梯度方向有利于梯度的整体下降 optimizer.zero_grad() # 将数据传入网络中，得到loss classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']]) classification_loss = classification_loss.mean() regression_loss = regression_loss.mean() loss = classification_loss + regression_loss if bool(loss == 0): continue # 误差的反向传播 loss.backward() # 梯度裁剪函数,第二个参数表明允许最大的梯度为0.1 torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1) optimizer.step() loss_hist.append(float(loss)) epoch_loss.append(float(loss)) print('Epoch: &#123;&#125; | Iteration: &#123;&#125; | Classification loss: &#123;:1.5f&#125; | Regression loss: &#123;:1.5f&#125; | Running loss: &#123;:1.5f&#125;'.format(epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist))) del classification_loss del regression_loss except Exception as e: print(e) continue if parser.dataset == 'coco': print('Evaluating dataset') # 验证集验证模型的有效性 coco_eval.evaluate_coco(dataset_val, retinanet) elif parser.dataset == 'csv' and parser.csv_val is not None: print('Evaluating dataset') mAP = csv_eval.evaluate(dataset_val, retinanet) scheduler.step(np.mean(epoch_loss)) # 保存训练好的模型 torch.save(retinanet.module, '&#123;&#125;_retinanet_&#123;&#125;.pt'.format(parser.dataset, epoch_num)) retinanet.eval()torch.save(retinanet, 'model_final.pt'.format(epoch_num)) 需要注意的点： 在网络进行训练或验证时，通常先进行一次： 123model.train()# or evaluatemodel.eval() 这样的目的是模型在train和eval的时候，需要执行的操作是不一样的。例如batchNorm和Dropout在eval的时候是不需要执行的。因此需要提前对网络进行设置。 eval 验证eval作为验证网络的性能，被安排在网络执行的最后，在每个batch结束，或者达到设定的epoch的时候，对网络进行测试。并以此为依据，是否对网络进行存储。 eval部分常用的指标是mAP，该指标通过计算recall以及precision的值来得到最终的结果。首先得到网络的eval的结果，然后从标注数据中得到anno的结果，进行mAP的计算。 得到网络的结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def _get_detections(dataset, retinanet, score_threshold=0.05, max_detections=100, save_path=None): """ Get the detections from the retinanet using the generator. The result is a list of lists such that the size is: all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes] # Arguments dataset : The generator used to run images through the retinanet. retinanet : The retinanet to run on the images. score_threshold : The score confidence threshold to use. max_detections : The maximum number of detections to use per image. save_path : The path to save the images with visualized detections to. # Returns A list of lists containing the detections for each image in the generator. """ all_detections = [[None for i in range(dataset.num_classes())] for j in range(len(dataset))] retinanet.eval() with torch.no_grad(): for index in range(len(dataset)): data = dataset[index] scale = data['scale'] # run network scores, labels, boxes = retinanet(data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0)) scores = scores.cpu().numpy() labels = labels.cpu().numpy() boxes = boxes.cpu().numpy() # correct boxes for image scale boxes /= scale # select indices which have a score above the threshold indices = np.where(scores &gt; score_threshold)[0] if indices.shape[0] &gt; 0: # select those scores scores = scores[indices] # find the order with which to sort the scores # 得到score从大到小的下标，然后选择其中的max_detections那么多个 scores_sort = np.argsort(-scores)[:max_detections] # select detections score从大到小 image_boxes = boxes[indices[scores_sort], :] image_scores = scores[scores_sort] image_labels = labels[indices[scores_sort]] image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1) # copy detections to all_detections for label in range(dataset.num_classes()): # 每一张图片均表示成一个index，对所有的label都遍历一边，每个label保存若干个anchor,没有的话则不保存 all_detections[index][label] = image_detections[image_detections[:, -1] == label, :-1] else: # copy detections to all_detections for label in range(dataset.num_classes()): all_detections[index][label] = np.zeros((0, 5)) print('&#123;&#125;/&#123;&#125;'.format(index + 1, len(dataset)), end='\r') return all_detections 从标注文件中读取图片的标注信息： 123456789101112131415161718def _get_annotations(generator): """ Get the ground truth annotations from the generator. The result is a list of lists such that the size is: all_detections[num_images][num_classes] = annotations[num_detections, 5] # Arguments generator : The generator used to retrieve ground truth annotations. # Returns A list of lists containing the annotations for each image in the generator. """ all_annotations = [[None for i in range(generator.num_classes())] for j in range(len(generator))] for i in range(len(generator)): # load the annotations annotations = generator.load_annotations(i) # copy detections to all_annotations for label in range(generator.num_classes()): all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy() print('&#123;&#125;/&#123;&#125;'.format(i + 1, len(generator)), end='\r') return all_annotations 得到标注数据之后，开始计算mAP指标，mAP指标由recall（判断正确的占所有正确类别的百分比），precision（判断正确的占预测结果中认为正确的百分比）。通过对这两个指数的积分来计算最终的mAP结果。 recall = TP/(TP + FN) 即真正预测对的，占所有正类的比例 precision = TP/(TP + FN) 即真正预测对的，占预测结果为正的比例 TP,FP,TN,FN这几个指标第一个字母表示预测是不是对的，第二个字母表示，预测的内容是什么（正类或者负类）。关于mAP的计算可以看： 这里 下面代码计算mAP的内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117def compute_overlap(a, b): """ Parameters ---------- a: (N, 4) ndarray of float b: (K, 4) ndarray of float Returns ------- overlaps: (N, K) ndarray of overlap between boxes and query_boxes """ area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1]) iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0]) ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1]) iw = np.maximum(iw, 0) ih = np.maximum(ih, 0) ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih ua = np.maximum(ua, np.finfo(float).eps) intersection = iw * ih return intersection / uadef _compute_ap(recall, precision): """ Compute the average precision, given the recall and precision curves. Code originally from https://github.com/rbgirshick/py-faster-rcnn. # Arguments recall: The recall curve (list). precision: The precision curve (list). # Returns The average precision as computed in py-faster-rcnn. """ # correct AP calculation # first append sentinel values at the end mrec = np.concatenate(([0.], recall, [1.])) mpre = np.concatenate(([0.], precision, [0.])) # compute the precision envelope for i in range(mpre.size - 1, 0, -1): mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i]) # to calculate area under PR curve, look for points # where X axis (recall) changes value i = np.where(mrec[1:] != mrec[:-1])[0] # and sum (\Delta recall) * prec ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1]) return apdef evaluate( generator, retinanet, iou_threshold=0.5, score_threshold=0.05, max_detections=100, save_path=None): """ Evaluate a given dataset using a given retinanet. # Arguments generator : The generator that represents the dataset to evaluate. retinanet : The retinanet to evaluate. iou_threshold : The threshold used to consider when a detection is positive or negative. score_threshold : The score confidence threshold to use for detections. max_detections : The maximum number of detections to use per image. save_path : The path to save images with visualized detections to. # Returns A dict mapping class names to mAP scores. """ # gather all detections and annotations all_detections = _get_detections(generator, retinanet, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path) all_annotations = _get_annotations(generator) average_precisions = &#123;&#125; for label in range(generator.num_classes()): false_positives = np.zeros((0,)) true_positives = np.zeros((0,)) scores = np.zeros((0,)) num_annotations = 0.0 for i in range(len(generator)): detections = all_detections[i][label] annotations = all_annotations[i][label] num_annotations += annotations.shape[0] detected_annotations = [] for d in detections: scores = np.append(scores, d[4]) if annotations.shape[0] == 0: # 表示当前图片没有标注，因此你的标注结果都是错误的 false_positives = np.append(false_positives, 1) true_positives = np.append(true_positives, 0) continue overlaps = compute_overlap(np.expand_dims(d, axis=0), annotations) assigned_annotation = np.argmax(overlaps, axis=1) # 对每个框找出覆盖最多的一个标注,返回标注所在的下标 max_overlap = overlaps[0, assigned_annotation] if max_overlap &gt;= iou_threshold and assigned_annotation not in detected_annotations: false_positives = np.append(false_positives, 0) true_positives = np.append(true_positives, 1) detected_annotations.append(assigned_annotation) else: false_positives = np.append(false_positives, 1) true_positives = np.append(true_positives, 0) # no annotations -&gt; AP for this class is 0 (is this correct?) if num_annotations == 0: average_precisions[label] = 0, 0 continue # sort by score indices = np.argsort(-scores) false_positives = false_positives[indices] true_positives = true_positives[indices] # compute false positives and true positives # 得到一个累加的数组的结果 false_positives = np.cumsum(false_positives) true_positives = np.cumsum(true_positives) # compute recall and precision recall = true_positives / num_annotations precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps) # compute average precision average_precision = _compute_ap(recall, precision) average_precisions[label] = average_precision, num_annotations print('\nmAP:') for label in range(generator.num_classes()): label_name = generator.label_to_name(label) print('&#123;&#125;: &#123;&#125;'.format(label_name, average_precisions[label][0])) return average_precisions 几个函数： 123np.argsort(scores) # 根据从小到大返回元素的下标，小的在前np.argmax(overlaps,axis = 1) # 找出每一列的最大值，返回他的下标np.cumsum(nums) # 返回一个数组，数组中内容从头开始累加到当前位置 总结经过上面几个流程我们大致梳理了一下一个网络的搭建，数据的传递，loss的计算，以及最后的验证的过程。 总结一下： 构造dataloader，在这里头完成数据的读取，增强等工作 完成网络的搭建 完成网络的训练 完成验证集的测试工作]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[normalization]]></title>
    <url>%2F2019%2F07%2F24%2Fnormalization%2F</url>
    <content type="text"><![CDATA[Normalization 正则化在wikipedia上的解释是，使得某个东西更加正规和正常化的一个过程。深度学习中，正则化使用十分广泛，通常网络通过修改loss，添加参数的正则项，对参数的分布进行控制；或是在数据预处理阶段，对数据进行正则化操作。正则化操作通常指的是将数据大小范围缩放到[0,1]之间。 对数据集的正则化操作 Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as k-nearest neighbors and artificial neural networks. 正则化使用场景是数据特征范围差异大，且数据的分布未知。 对于一般的数据集来说，我们不需要对其进行正则化操作。但如果数据集不同特征的数据范围相差过大时，我们需要对其进行正则化操作。因为数据范围大的数据，其波动对精度的影响很大，而数据范围小的特征，数据波动的影响不会有这么大，这样造成了结果精度无法提升。因此需要对数据进行正则化操作。使得数据局限在一个固定的范围内。 正则项我们知道，当一个网络与数据过度拟合，这个网络能够很好的反应训练数据，但是它的泛化性能也会大大下降。为了避免这种过拟合现象，做法通常有： 削减特征的数量（难以确定哪些特征是需要丢弃的） 减少特征的参数，控制参数的分布，即使用正则项方法 正则项的目的是为了对参数进行控制，包括： 实现参数的稀疏化，即某些参数为0。参数的稀疏化能够自动对数据的特征进行筛选，过滤掉一些不需要的特征，同时起到简化模型的作用，避免过拟合。 最小化正则项能够尽量保持参数较小，参数小的好处在于计算方便，且在网络求导的过程中，产生的导数通常比较小，结果比较稳定。 范数 （norm）在线性代数领域中，范数是一个函数，它为向量空间中的每个向量分配严格正长度或大小 。 L0 范数：指向量空间中非0向量的个数 无穷范数：指所有向量中欧式距离的最大值作为无穷范数 参数正则项L0正则项：模型参数中，不为0的参数的个数 ​ L0正则化通过最小化不为0的参数的个数，以达到参数稀疏化的目的，使得模型自动选择特征。在使用时，由于L0正则项是一个NP hard问题，L1是L0的最优凸优化，因此通常用L1来代替L0。 L1正则项：各个模型参数的绝对值之和 ​ 最小化L1正则项能够将模型的参数变小，沿着0的方向靠近，降低网络的模型复杂度。添加L1正则项后方程如下：$$L = L_0 + \frac{\lambda}{n}\sum_{w}|W|$$L2 正则项：各个参数的平方和再开根号。 ​ 最小化L2正则项可以使得参数变小接近于0，当参数不会变成0（可以看下面的图来理解），因此L2将选择更多的特征，权重比较小，避免过拟合。方程如下：$$C=C_{0}+\frac{\lambda}{2 n} \sum_{w} w^{2}$$lasso回归与岭参数 L1正则化又称为losso回归，将L1正则项作为loss的惩罚函数。L2正则项又称为岭参数。同样可以将L2正则项作为公式的约束项。可以画图如下,其中等值线为原始的Loss，L1为正方形（绝对值），L2为一个圈（平方根）。可以看出来，图中的交点满足条件的点，因此可以看出L1正则项可以得到更多的稀疏解。 标准化操作（standardization） Standardization is useful when your data has varying scales and the algorithm you are using does make assumptions about your data having a Gaussian distribution, such as linear regression, logistic regression and linear discriminant analysis. 标准化使用场景是数据特征范围差异大，假设数据服从高斯分布。 将数据标准化是指将数据rescale，使得数据的 $mean = 0,\sigma = 1$。数据的标准化操作如下：$$z=\frac{x-\mu}{\sigma}$$标准化操作对于很多机器学习的算法，在网络训练上有着很重要的作用。例如对于梯度下降法来说，处于中心（mean = 0）范围的数据，中心权重的参数更新将会加快。对于一些loss而言（MSE），利用欧式距离作为网络优化的目标，因此标准化操作是很重要的。 Batch Normalization（批量标准化）其步骤如下，对一个batch中的数据进行标准化后，并学习$r,\beta$ 两个参数，对得到标准化后的值进行一个偏移，得到最终的结果： 当进来一个batch的时候，具体的做法是，在数据输入到下一层神经元激活函数之前，计算整个batch的mean，variance，偏移后最终得到下一层的输入。 为什么要加入Batch Normalization层？ 由于深层网络的输入，经过多层神经网络层的作用后发生偏移（ReLu激活函数输出均大于0，因此整体输出的mean将往大于0的方向偏移）。导致网络训练难以收敛，落入梯度饱和区导致梯度消失等问题。BN层重新通过将数据拉回N(0,1)的正态分布上，是的输入值落入激活函数梯度敏感的区域，避免梯度消失，加速网络的训练。（输入变小也有助于降低模型计算复杂度）。 但是仅仅做到这一步还不行，由于我们引入非线性的激活函数，使得网络能够学到一些非线性的性质。我们通过BN将输出拉回到N(0,1)分布上，削弱了激活函数的非线性部分的作用。因此BN通过学习两个参数$\gamma, \beta$ 来对输出做一个scale和shit操作。恢复学习到的非线性部分知识。最终得到的$y_i$ 在正态分布和非线性性质中做了一个trade off。 Batch Normalization的作用 batch normalization极大的提升了网络训练的速度 每次BN都将网络的输出控制在一个范围内，近似于符合正态分布，能够起到正则项的作用 对参数的初始化要求降低，调参变得简单 layer normalization layer normalization 正则化的方向是沿着feature的方向对CHW归一化，batch normalization 正则化的方向是以sample为单位，对NHW做归一化。]]></content>
      <categories>
        <category>super resolution</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[image upsample-downsample method]]></title>
    <url>%2F2019%2F07%2F23%2Fimage-upsample-downsample-method%2F</url>
    <content type="text"><![CDATA[图像尺度的放大，缩小是图形学中一个十分常见的问题。然而这个过程并不是无损的，缩放的过程是一个非线性的过程，因此存在许多算法在效率，平滑度，清晰度和速度上进行一些权衡（trade-off）。在图形的缩放过程中，存在插值，采样等一些关键的步骤，下面对一些在图像缩放过程中使用的算法进行简要的介绍，这些算法均有其优缺点。 参考资料：https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic 问题定义在处理图片的缩放问题时，需要解决的问题是： 在放大过程中，新增的像素的颜色如何确定。 在缩小过程中，哪些像素需要被保留。 图形缩放下面用一个1D的问题举例,如下图，y轴表示灰度图的灰度值: 现在对这个图形进行进行放大，有两种做法： 使用最近邻方法，用左边的像素填补这个位置的像素 使用线性插值的方法，利用前后位置的像素值生成该位置上的像素 将这个问题一般化，我们通过引入卷积来完成这个操作。例如对于最近邻方法，可以使用[1,1,0]卷积核，对于插值法，可以使用[0.5,1,0.5]卷积核。 与上述思路相同，我们将卷积核推广到2D的情况，同时在x和y方向上做卷积，各个像素的取值由卷积权重决定。 Nearest Neighbor Resampling（最近邻采样） 用这种方式得到的图像块状比较明显，但是这种方法执行效率最快。 Bilinear Resampling (B-spline order 1) （双线性插值） 上诉公式是沿着x方向的线性差值的值，对于y方向同样用这种方式进行插值。 Bicubic Resampling （双三次插值） 该方法需要选取的最近的16个像素点作为计算目标图像B(X,Y)处像素值的参数。每个位置的权重与像素值，以及像素的变化率有关。当a取-0.5是，bicubic函数有以下的形状： 该算法在各中图像的缩放过程中使用的最多。其中心点像素计算公式如下：$$\sum_{i=0}^{3} \sum_{j=0}^{3} a_{i j} x^{i} y^{j}$$其中参数a需要根据临近的四个点的像素值，偏导数等等来计算。具体的计算过程可以看wiki上的解释。 最后在处理具体问题时，我们知道一张图片在显示屏上是以点阵的方式排列的。当我们要放大，或者缩小时，例如用双三次插值时，对于每个像素点，无论是放大还是缩小，我们总能找到最邻近的16个位置，可以很方便的对图片进行缩放。此外，用卷积的方式进行求解，能够并行对图片进行处理，提高图片的处理效率。]]></content>
      <categories>
        <category>super resolution</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning for image Super-resolution: a Survey]]></title>
    <url>%2F2019%2F07%2F23%2FDeep-Learning-for-image-Super-resolution-a-Survey%2F</url>
    <content type="text"><![CDATA[本篇论文是2019年2月份，发表在arxiv上的篇关于超分辨率的一篇综述。这篇文章系统且全面的介绍了一些基于深度学习的超分辨率方法。其中包括： 超分辨率问题的定义 (problem setting) benchmark datasets 性能评价指标 (performance metrics) 基于深度学习的超分辨率方法 特定领域的超分辨率应用 (domain-specific application) 此外作者对比每个超分辨率方法，指出了网络的优点以及局限。最后对该领域的一些开放性问题(open issuse) 以及挑战提出了未来研究的方向。 超分辨率问题的定义（problem setting）图像的超分辨率要解决的问题是：从一张低分辨率（LR）的图像中，恢复出一张高分辨率（HR）的图像。 通常来说，我们通过下面的方式得到低分辨率的图像：$$I_{x}=\mathcal{D}\left(I_{y} ; \delta\right)$$$I_x$ 表示低分辨率图像，$I_y$ 表示高分辨率图像，$D()$ 表示下采样的映射函数，$\delta$ 表示映射函数的参数。图片清晰度不够的原因可能有很多种，例如聚焦，图片压缩，传感器噪声等问题。一些学者提出了下面的模型来模拟这种失真的映射。$$\mathcal{D}\left(I_{y} ; \delta\right)=\left(I_{y} \otimes \kappa\right) \downarrow_{s}+n_{\zeta},{\kappa, s, \zeta} \subset \delta$$$I_{y} \otimes \kappa$ 表示HR图片与模糊核（blur kernel）k的卷积操作，下箭头表示下采样，$n_{\zeta}$ 表示方差为$\zeta$ 的白高斯噪声。 目前大多数的数据库，产生LR图像的方法是直接对SR图像做一些下采样(双三次插值算法(bicubic interpolation))，同时对图片作抗锯齿（anti aliasing），去模糊等操作(blur) 。关于下采样，上采样的一些方法可以看 这个课件，或这里。 关于超分问题，我们更关注的是如何由低分辨率的图片得到高分辨率的图片，即：$$\hat{I}_{y}=\mathcal{F}\left(I_{x} ; \theta\right)$$其中$\mathcal{F}()$ 为超分模型，由低分辨率图片生成高分辨率的图片。 对于一个典型的超分辨率问题来说，我们需要从一个LR图像中恢复出它的HR版本。模型的目标是最小化我们恢复出来的图片与原始HR图片的差距，目标方程如下：$$\hat{\theta}=\underset{\theta}{\arg \min } \mathcal{L}\left(\hat{I}_{y}, I_{y}\right)+\lambda \Phi(\theta)$$其中$\mathcal{L}\left(\hat{I}_{y}, I_{y}\right)$ 为生成的HR图像与原始图像的Loss，公式尾项是一个正则项。目前使用较多的loss为像素级别的MSE loss，同时一些组合型的loss也经常被使用。引入正则项的目的是控制参数的变化，使得网络更容易收敛。正则项可以看这里。 Benchmark dataset在一个典型的超分辨率的文章中，通常需要对一些公开数据集上进行试验，在这些公开数据集上的效果指标作为这个算法性能的评价标准。主要使用的数据集有： Image Quality Assessment图片质量的评价是一个与感知，视觉相关的问题。通常存在客观和主观的两类方法。其中客观方法根据指标计算模型直接计算得出，如MSE。主观方法则与人们的感知更为接近。下面介绍一下常用的评价方法。 Peak Signal-to-Noise Ratio(峰值信噪比)峰值信号比是一种图像的客观评价标准。他用最大值信号与背景噪声信号（重建与原始信号的差）的比值作为评价标准：$$\begin{aligned}\operatorname{MSE} &amp;=\frac{1}{N} \sum_{i=1}^{N}(I(i)-\hat{I}(i))^{2} \\\operatorname{PSNR} &amp;=10 \cdot \log _{10}\left(\frac{L^{2}}{\mathrm{MSE}}\right) \\\end{aligned}$$其中L为图像点颜色的最大数值，若采样点采样8位表示，那么L = 255。该指标更加注重像素点之间的误差。典型的PSNR值在20到40之间。指标越高越好。 但是由于PSNR指标更多的放映相同位置上像素值的差异，而未考虑到人眼的视觉感知，因此作为质量评价指标是存在缺陷的。但这个指标仍是目前使用最多的一个指标。 人眼视觉特征 对空间频率较低的对比差异敏感度高 人眼对亮度对比差异的敏感度较色度高 人眼对一个区域的感知结果会影响到周围邻近区域 SSIM（Structural Similarity 结构相似性）SSIM分别从亮度，对比度，结构三个方面度量图片的相似性。 首先计算图片的mean和variance：$$\begin{aligned}\mu_{I} &amp;=\frac{1}{N} \sum_{i=1}^{N} I(i) \\\sigma_{I} &amp;=\left(\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)^{2}\right)^{\frac{1}{2}} \\\end{aligned}$$亮度（luminance）指标（$\hat{I}$ 指生成的图片）:$$\mathcal{C}_{l}(I, \hat{I})=\frac{2 \mu_{I} \mu_{\hat{I}}+C_{1}}{\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}}$$对比度（contrast）指标：$$\mathcal{C}_{c}(I, \hat{I})=\frac{2 \sigma_{I} \sigma_{\hat{I}}+C_{2}}{\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}}$$结构对比度（structure comparison）指标：$$\begin{aligned}\sigma_{I \hat{I}} &amp;=\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)\left(\hat{I}(i)-\mu_{\hat{I}}\right) \\\mathcal{C}_{s}(I, \hat{I}) &amp;=\frac{\sigma_{I \hat{I}}+C_{3}}{\sigma_{I} \sigma_{\hat{I}}+C_{3}} \\\end{aligned}$$其中$C_1 = (K_1L)^2$,$C_2 = (K_2L)^2$,$C_3 = C_2 / 2$。 SSIM的指标有三面三个指标组合而成：$$\operatorname{SSIM}(I, \hat{I})=\left[\mathcal{C}_{l}(I, \hat{I})\right]^{\alpha}\left[\mathcal{C}_{c}(I, \hat{I})\right]^{\beta}\left[\mathcal{C}_{s}(I, \hat{I})\right]^{\gamma}$$通常使用下面这个形式：$$\operatorname{SSIM}(I, \hat{I})=\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(\sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\overline{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\tilde{I}}^{2}+C_{2}\right)}$$一般的，$k_1 = 0.01,k_2 = 0.03, L =255$。 此外还有一些主观的评价方法（mean opinion score），利用志愿者对生成图片的质量进行五个等级的评价，来确定图片的质量。 对于图片的颜色空间来说，常用的颜色空间有RGB空间与YCbCr。 基于有监督的超分辨率方法超分辨率框架分类超分辨率框架总结下来有以下四种： Pre-upsampling Super-resolution Post-upsampling Super-resolution Progressive Upsampling Super-resolution Iterative Up-and-down Sampling Super-resolution 如下图： Pre-upsampling Super-resolution 该方法在将图片送入网络前先用传统方法进行图片的放大（bicubic interpolation上采样），将图片放大到输出的要求大小，然后送入CNN网络中，学习一个端到端的从LR到HR的映射。 该方法的优点在于神经网络仅需要学习一张粗糙的（传统方法放大的）图片到HR图片的映射，大大降低了网络学习的难度；同时这种结构可以任意控制图片放大倍数。该方法框架也成为了一种较为主流的框架。 该方法的缺点在于：传统的图片放大算法中通常需要包含去噪，去模糊等操作，需要花费很大的时间以及空间。 Post-upsampling Super-resolution 该方法将LR到HR的整个过程作为网络学习的目标，上采样层在网络的末端，这种设计可以极大发挥网络的潜力，同时能够显著降低网络训练时消耗的时间与空间。在train和inference阶段速度带来了很大的提升。 缺点：仅通过一个upsample层来放大图片，使得网络学习的难度大大提升；由于upsample层的放大尺度是固定的，如果更换一个倍数，就要更换一个训练模型。 Progressive Upsampling Super-resolution 渐进式的上采样可以解决上诉post结构的问题（例如LapSRN网络 laplacian pyramid SR network）。该结构采用许多CNN的级联结构，每个阶段进行一个上采样重构HR，生成放大2倍，4倍，8倍等结果。 该模型的缺点是结构复杂，训练难度大等等。 Iterative Up-and-down Sampling Super-resolution 该结构反复的放大，缩小图片，试图学习到一种后映射（back projection）的关系，该模型可以很好的学习到LR与HR之间的映射关系。基于该框架的网络DBPN也获得了NTIRE 2018的冠军。尽管这种up-down的结构设计标准还未确定，DBPN网络中存在着大量的复杂的结构设计以及繁重的人工设计过程，但是这种结构有很大的研究潜力。还需要进一步探索。 传统插值上采样算法 最近邻插值 线性插值 双三次插值 详见这里 事实上，所有的差值算法完全通过图片自身的内容来实现超分辨率，因此他们并不能提供多于图片的信息，此外这些差值算法还引入了一些边界效应，例如计算复杂度，噪声，模糊等等。 基于学习的上采样方法转置卷积层 （transposed/ deconvolution layer） 转置卷积层的作用与正常卷积层的操作是相反的。转置卷积通过在像素间插入0来扩大图片的分辨率。下面是转置卷积层的工作原理： 首先对一张图片，每个像素点之间添加一个0值，然后用一个3 X 3 的卷积核，padding= 1 ，stride = 1对它进行卷积操作，最终得到一个大小为原先两倍的图片。 这种做法能够使得网络实现端到端的映射，但是他的缺点是，产生的图片会产生一些不等的重叠，从坐标轴上看，容易形成棋盘的割裂感，一定程度上伤害了SR的性能。 子像素卷积（sub-pixel layer） 子像素卷积在超分辨率领域使用十分广泛，用于扩大图片的像素。他的工作原理是执行一次卷积之后，产生一个多通道的feature map。然后将这些多通道的像素reshape到一个二维平面上。原理图如下： 例如要将原始的feature map大小变大s倍，那么卷积核的channel数达到$s^2$。例如输入图片的大小为$w*h*c$，经过卷积操作后变为$w*h*s^2 c$ ，然后进过reshape成$sh*sw*c$，即完成了放大的操作。在原图的基础上放大了s倍。 子像素的上采样方法有一个重要的优点在于他有更大的感受野，能够提供更多的图片信息。但是感受野的分布是不对齐的，同时卷积层使用重复的感受野会导致不同卷积边界的不真实感。 网络的设计超分辨率发展到今天，需有有效的网络结构得到了验证，例如残差学习，密集连接块。这些结构结合上面提到的四种框架能够组合出各种有效的网络结构。 残差学习 （residual Learning） 残差学习最早由何凯明的resNet提出，在超分辨率领域残差学习主要有以下两种结构： 全局残差学习 global residual learning 由于在SR问题中，网络通常是端到端的，输入的图片与输出的图片有着很大的相关性。因此有些研究者通过直接学习输入与输出之间的残差，在输入与输出之间连接一条high way达到这个目的。因此网络仅仅需要学习输入与输出之间的残差部分（图片中的高频部分数据）。由于残差网路中绝大多数的区域值接近零，因此在网络的学习过程中能够大大降低运算量，尤其在pre-upsample框架中。 局部残差学习（local residual learning） 局部残差学习与resNet中的残差模块类似，在缓解网络退化，改善网络的学习能力上具有很好的效果。 递归学习（Recursive Learning） 为了不引入过多的参数同时实现更大的感受野并学习更高级别的特征，递归学习（其是指以递归方式多次应用相同模块）被引入到超分辨率领域中。很多工作中引入卷积结构、残差结构作为递归块，均在performance上有比较好的表现。 很多学者提出了很多与递归块结合的网络结构，例如将一个大的缩放因子分解成很多子问题，然后用力对结构解决这些子问题；将image upsample作为递归块等等。由于递归块同样面临着梯度的消失和梯度爆炸的问题，因此很多残差学习，多监督学习通常也会被引入到地柜结构中，来解决这些问题。 多路径学习（multi-path learning）多路径学习将特征传入模型的不同分支中，每个分支有着不同的结构，以此来提高模型的超分能力。 全局多路径学习 Global Multi-path Learning 全局的多路径学习通过利用不同路径来学习图片中的不同特征，例如用一些分支学习一些亚频特征；学习visible特征；学习全局结构；学习低频或高频部分；用于upsample图片等等 这种思路能够提升网络的特征提取能力。 局部的多路径学习（local multi-path learning） 受到inception结构的影响，引入一个block，这个block中使用不同的路径，进行不同尺度的特征提取。如下图： 分别对feature map应用一个3X3和5X5大小的核，在不同的尺度上对特征进行提取。通过这种方式可以在不同尺度上对特征进行提取，能够有效的提升网络的性能。 特定尺度的路径学习（scale-specific multi-path learning） 由于多分辨率问题对图片的方法尺度不同，网络需要重新训练，但是网络结构都是相同的。这种策略就是保留网络的主干部分（结构以及参数），在网络的头部和尾部添加一个与尺度相关的预处理路径以及一个upsample路径，每次对于特定的分辨率需求，选择相关的路径，而网络的特征提取以及中间部分都得到了保留。 密集连接块（Dense Connections）只从密集连接块被提出之后，这种结构就广泛的应用在超分辨率领域，结构如下： 该种结构将当前层之前的feature map都作为这一层的输入，能够有效的避免梯度消失，增强信号的传递、特征的复用等。此外还有很多结构是在块级上做密集的连接，该结构证明在超分辨率领域中同样有效。 通道注意力机制（channel attention）通道注意力机制目的是给不同的channel赋予不同的权重，不同的channel在超分辨率问题上的作用是不同的，作者使用“压缩激发模块（squeeze-and-excitation）”对不同通道进行权重的赋值。 作者通过一个全局pooling将image的size变成1 X 1 X C，然后通过两个卷积层，得到每一个channel的权重。然后对feature map重新赋值，得到赋予权重的feature map。 先进的卷积层（advanced convolution）空洞卷积 dilated convolution 空洞卷积即在原始的卷积的基础上加上空洞，目的是为了增加图片的感受野。 将这种卷积应用在超分辨率问题上也能够使得模型性能得到提升。 分组卷积（group convolution） 分组卷积的概念是对feature map进行分组（channel维度上的划分），按童谣的比例划分卷积核，然后将每个分组再进行卷积，最终将卷积结果组合成一个feature输出。这种卷积的方式大大减少了参数的计算量，在性能上仅仅下降了一点。 像素递归学习 pixel recurisive大多数的SR方法在处理图像时像素之间是独立的，无法得到像素间的相关性，因此一些学者提出pixel by pixel的生成器，通过两个网络，分别学习图像的纹理结构信息以及像素间的序列依赖关系来生成HR图像。这种方法在某些方面有一个比较好的效果，但是训练过程十分的困难，计算量比较大。 金字塔pooling引入金字塔模型能够有效的利用图片全局以及局部的特征，在EDSR-PP网络中使用金字塔模型能够有效的提升网络的精度。 小波变换小波变换可以很方便的的将图片的信号分解成高频的纹理细节和低频的拓扑结构。将小波变换应用在超分辨率问题上，从低分辨率的图片中提取出低频信息作为输入，输出高分辨率的高频信息。 学习策略Loss Functions​ 在超分辨率领域，损失函数用来衡量生成的HR图片与原始的HR图片之间的差距，同时指导模型的优化。下面简要介绍一下存在的一些损失函数的形式。其中$\hat{I}$ 表示原始超分辨图像，$I$ 表示生成的超分辨率图像。 像素级别的loss （pixel loss） 对比GT与生成的图片在像素级别上的L1以及L2 loss：$$\begin{aligned}\mathcal{L}_{\text {pixel_L1 }}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left|\hat{I}_{i, j, k}-I_{i, j, k}\right| \\\mathcal{L}_{\text {pixel_L2}}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left(\hat{I}_{i, j, k}-I_{i, j, k}\right)^{2} \\\end{aligned}$$L2 loss 相比较于L1 loss 来说，更加的惩罚比较大的误差，而对一些小的误差的容忍度更大。L1 loss在对性能和最终的收敛上比L2更好。对于指标PSNR来说，最小化pixel loss就可以达到最大化PSNR的目的。但是pixel loss没有将图片的质量考虑在内，因此生成的图片过于平滑，失去了高频的细节信息。 满意度损失（content loss） 基于感知的满意度损失，这个loss是一个L2 loss。他的不同点在于，我们将GT与生成的图片，分别输入一个欲训练好的分类网络中，取其高层特征（第$l$ 层）进行pixel wise上的loss计算。$$\mathcal{L}_{\text {content }}(\hat{I}, I ; \phi, l)=\frac{1}{h_{l} w_{l} c_{l}} \sqrt{\sum_{i, j, k}\left(\phi_{i, j, k}^{(l)}(\hat{I})-\phi_{i, j, k}^{(l)}(I)\right)^{2}}$$其中h,w,h是抽取出来的特征层的大小。 这个loss更加强调图片在生成上的相似性，最常用的分类网络是VGG，resNet。 纹理损失（Texture Loss） 一些文章认为图片的纹理由特征不同通道的相关性组成，定义为下面Gram matrix：$$G_{i j}^{(l)}(I)=\operatorname{vec}\left(\phi_{i}^{(l)}(I)\right) \cdot \operatorname{vec}\left(\phi_{j}^{(l)}(I)\right)$$上式中表示两个不同通道的向量的点乘结果。即第 $l$ 层特征向量的i通道和j通道的点乘结果。纹理损失依旧是L2损失，输入是生成图片和GT之间的纹理表示。$$\mathcal{L}_{\text {texture }}(\hat{I}, I ; \phi, l)=\frac{1}{c_{l}^{2}} \sqrt{\sum_{i, j}\left(G_{i, j}^{(l)}(\hat{I})-G_{i, j}^{(l)}(I)\right)^{2}}$$通过这种损失可以很好的得到较为真实的图片。但是仍然有一个难以解决的问题是，用于计算纹理损失的图片patch（方块，补丁）大小的确定依旧要根据经验来确定，太大或太小的patch使得生成的纹理不够真实。 对抗损失（adversarial loss） 我们使用一个SR模型作为生成器，另外我们需要定义一个判别器，下面的判别器D使用交叉熵来表示。生成器希望生成的样本判别器无法辨认，判别器希望能够鉴别出生成器生成的样本是假的。$$\begin{aligned}\mathcal{L}_{\text {gan_ce_g}}(\hat{I} ; D) &amp;=-\log D(\hat{I}) \ \mathcal{L}_{\text {gan_ce_d }\left(\hat{I}, I_{s} ; D\right)} &amp;=-\log D\left(I_{s}\right)-\log (1-D(\hat{I})) \\\end{aligned}$$下面还有使用最小平方差最为判别器，能够得到更加真实的且高质量的结果。$$\begin{aligned}\mathcal{L}_{\text{gan_ls_g}}(\hat{I} ; D) &amp;=(D(\hat{I})-1)^{2} \ \mathcal{L}_{\text{gan_ls_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=(D(\hat{I}))^{2}+\left(D\left(I_{s}\right)-1\right)^{2} \end{aligned}$$下面是使用hinge loss形式的对抗损失：$$\begin{aligned} \mathcal{L}_{\text{gan_hi_g}}(\hat{I} ; D) &amp;=-D(\hat{I}) \ \mathcal{L}_{\text{gan_hi_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=\min (0, D(\hat{I})-1)+\min \left(0,-D\left(I_{s}\right)-1\right) \\\end{aligned}$$使用对抗损失很大程度上带来的感知质量的提升，虽然PSNR指数有所下降，但是MOS指数有上升，取得了一个很好的视觉效果，生成的图片更加的真实。 循环连续损失 （Cycle Consistency Loss） 改损失受到循环GAN的启发，所用的网络不仅需要从LR到SR，还需要从SR到LR，重新生成的LR需要和输入一致，因此loss 如下：$$\mathcal{L}_{\text {cycle }}\left(I^{\prime}, I\right)=\frac{1}{h w c} \sqrt{\sum_{i, j, k}\left(I_{i, j, k}^{\prime}-I_{i, j, k}\right)^{2}}$$总差异损失（total variation loss） 这个算是是为了压制在生成图像过程中生成的噪声对图像质量产生的影响。他的loss有相邻像素的差异组合成。$$\mathcal{L}_{\mathrm{TV}}(\hat{I})=\frac{1}{h w c} \sum_{i, j, k} \sqrt{\left(\hat{I}_{i, j+1, k}-\hat{I}_{i, j, k}\right)^{2}+\left(\hat{I}_{i+1, j, k}-\hat{I}_{i, j, k}\right)^{2}}$$基于先验损失（prior based loss） 对于特定的数据，可以引入一下数据所特有的先验特征。通过这种先验特征可以很快的提升网络对这类数据恢复的性能。 Batch NormalizationBN的提出是为了消除网络训练过程中内部参数的偏移问题。具体做法是对每一个bach做一个归一化操作，并且训练两个变量用于还原网络的表达能力。因此我们在训练过程中可以使用更高的学习率，以及不用太在意参数的初始化值。因此BN在SR网络中同样得到了广泛的应用。 但是有一些学者认为BN使得网络丧失了尺度信息，使得网络失去灵活度，同样有些网络中去除BN后，取得了一个很好的性能。 课程学习 Curriculum learning渐进性的课程学习方法指的是网络从一个简单的任务出发，逐渐增加问题的难度，以此来得到一个鲁棒的模型。 超分辨率问题本质上是一个病态问题（ill-posed problem），即一些干扰对结果的影响非常的大，且系统十分不稳定，难以从结果反推回输入。这些干扰包括噪声，图片的模糊度，以及超分辨的倍数等等。 课程学习可以通过渐进学习的方式来解决这些问题，对于放大倍数很大（例如8）的任务，可以利用该思想，现训练简单的情况，例如可以先放大2，4，8倍来解决这个问题，这种方式能够大大缩短网络的训练时间，提升性能。 多监督问题 （multi-supervision）多监督问题在loss 中增加一些变量，用来对某些信号进行监督，最终能够得到一个性能较好的模型。 其他有用的方法context-wise network fusion 这种方式使用多个不同结构的网络，分别进行超分辨率的训练，然后依次将这些训练结果通过卷积层组合最终的结果（SRCNN），使用这种方法能够也能够达到state of art的效果，同时效率也是可以接受的。 data augmentation 数据增强方面，常用于网络中的方法有random cropping, flipping,scaling,rotation, color jittering, 此外还有一个特殊的增强方式，random shuffle RGB,随机打乱RGB的颜色值，这种方法能够消除颜色带来的偏差。 multi-task learning 多任务学习指的是将多种任务于SR任务结合，例如语义分割网络于SR网络结合（SFT-GAN）等，将去噪声网络和SR网络结合（DNSR），这种方式能够提供数据的先验，能够更好的提升SR的效果。 network interpolation 网络的结合，将基于pxiel loss和基于感知loss的两种方法结合起来，得到一种中间状态的网络，这种网络同时在PSNR和真实感上有很好的表现。 无监督的方法在超分辨率问题上，由于很难获得真实数据的超分辨率结果，因此 通常的做法是使用一个下采样方法，从超分辨率图像中得到他的低分辨率版本你，组成一个数据对，因此监督学习更像是学习这个方法的逆方法，人们通常忽略了提前定义好的下采样方法给数据带来的副作用。对于无监督方法来说，直接使用高分辨率的图片，更加符合现实中的场景。无监督方法上，目前仍然有很多值得探索的地方。 zero-shot super-resolution这个方法训练了一个预测核函数直接针对每张图片都生成一个下采样（degradation）核方法，使用这个核方法来构造数据集，采用不同的缩放尺度得到测试数据，然后训练一个CNN网络来实现SR。由于这个模型需要为每一张图片构造一个函数，因此需要更多的时间。 weakly-supervised Super-resolution弱监督的学习方法有两个思路，第一种是不是用传统的HR-to-LR的退化函数，而是学习一个网络来实现这个过程，然后构造一个数据集，然后使用这个数据集来训练SR模型。另一种是cycle-in-cycle的方法，同时学习LR-to-HR和HR-to-LR两方面。 learning degradation 有学者提出了一个两个阶段的学习网络，提出一个GAN网络，学习HR to LR，用这个网络生成一个LR-HR配对的数据集，然后训练一个LR to SR的GAN网络使用上诉的数据集进行训练，最终结果能够显著提升数据恢复的真实性。 cycle in cycle super resolution CinCGAN网络使用了四个生成器，两个判别器。生成器分别为noise LR -&gt; clean LR -&gt; clean HR，另外两个生成器进行反方向的生成。然后生成器用于判别生成了LR和SR的真实性，这其中引入了大量的损失函数，来保证这一过程的合理性。此外，这个方法还有很多改进的地方，来降低它训练的难度。 图像的深度先验使用一个随机初始化参数的CNN，对一张输入的图像，直接恢复他的超分辨率图像，仅仅利用CNN的结构先验来解决这个问题。模型的效果比传统的双线性插值要好些，但是效果不如其他监督方法，这种方法给我门提供了一种思路，仅仅利用一些手工制作的先验对图像进行超分辨率的恢复。 领域相关的应用高光谱影像 （Hyperspectral Image Super-resolution）高光谱影像在视觉任务中有着很多的用途，但是由于硬件的约束，收集到高质量的高光谱数据是十分的困难的，高光谱数据的分辨率因此也十分的低。因此在高光谱数据领域应用超分辨率方法是很有前景的。 基于高光谱的超分辨率工作有以下几种： W. Huang, L. Xiao, Z. Wei, H. Liu, and S. Tang, “A new pan- sharpening method with deep neural networks,” GRSL, vol. 12, 2015. G. Masi, D. Cozzolino, L. Verdoliva, and G. Scarpa, “Pansharp- ening by convolutional neural networks,” Remote Sensing, vol. 8, 2016. Y.Wei,Q.Yuan,H.Shen,andL.Zhang,“Boostingtheaccuracyof multispectral image pansharpening by learning a deep residual network,” GRSL, vol. 14, 2017. Y. Qu, H. Qi, and C. Kwan, “Unsupervised sparse dirichlet-net for hyperspectral image super-resolution,” in CVPR, 2018. 未来的研究方向网络结构设计结合图片局部和全局信息： 更大的感受野能够帮助网络获得更多图片的纹理细节。 结合图片中的高低频数据：cnn网络的浅层部分能够获取图像的颜色和边界信息，深层网络能够获取图像的语义信息。 纹理注意力机制：不同的纹理反应出来的细节特征是不同的，引入注意力机制能够增强图片的真实性。 轻量级的结构：预测一张DIV2k的图片，EDSR模型需要花费20s，这是难以接受的，因此我们需要精简网络结构。 上采样层：当前使用的上采样层均存在着不同程度的缺陷，提出一个好的上采样层，能够提升网络效能。 学习策略损失函数： 当前仍未找到一个很好的损失函数，能够兼顾感知和pixel wise Normalization：BN归一化方法十分花费时间，需要找到它的替代结构 评价指标当前的评价指标有PSNR，SSIM，MOS三种，其中PSNR容易生成过于平滑的图像，SSIM根据图片的光照，对比度，结构来评价，当时离人的感知还有一定距离，MOS与人的感知比较接近，但是统计起来十分的耗费人力及复杂。 现实场景的使用无监督学习方向上，可以学习一个degradation函数，用于数据的上采样，更符合现实数据的现状。 一些特定领域的应用方面，超分辨率可以作为整个流程的一部分。]]></content>
      <categories>
        <category>super resolution</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些提升效率的方法]]></title>
    <url>%2F2019%2F07%2F23%2F%E4%B8%80%E4%BA%9B%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在word或ppt中插入公式 使用mathpix snipper工具，从截图中获取latex公式。 进入这个网站：https://www.latex4technics.com/ 输入latex公式，在右下角转化为mathml格式。 打开word，插入公式。以纯文本的格式粘贴mathml代码，word自动转化为公式。 ppt中需要从word得到的公式复制过来，不支持直接转换。 使用jupyter链接服务器jupyter有几个好处，他可以单步执行，单步调试。可以在浏览器上看执行的结果，包括图片的显示这些。当跑的代码比较简单，是测试功能的代码的时候，可以使用jupyter。 jupyter的配置：jianshu.com/p/4012f7149eb8 用mac连接远程服务器： 服务器端输入：jupyter notebook –no-browser –port=8898 本地输入：ssh-N -f -L 127.0.0.1:8898:127.0.0.1:8898 zhouwenhui@remote-machine 最后在浏览器访问：http://127.0.0.1:8898/]]></content>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xigua-支持向量机]]></title>
    <url>%2F2019%2F07%2F21%2Fxigua-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[支持向量机主要目的在于找到 一个位于两类训练样本的正中间，该分界面对样本的局部扰动的鲁棒性最好。通过该分界面能够最大限度的对数据进行分类。]]></content>
      <categories>
        <category>xigua</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[xigua-神经网络]]></title>
    <url>%2F2019%2F07%2F20%2Fxigua-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[“神经网络是具有适应性的简单单元组成的广泛，并行互连的网络，能够模拟生物神经系统对真实世界物体所作出的交互反应。” 神经网络的发展1943年，神经网络模型最早是由心理学家和数理逻辑学家在提出的MP模型，它揭示了“大脑活动是靠脑细胞的组合连接实现的。” 1949年，心理学家Hebb提出 “脑细胞间某种通路在参与某种活动时被加强。” 用现在的观点来看这一说法，即我们可以通过调整网络参数（权重），来改善网络的性能。 1956年，达特茅斯会议上，明斯基，麦卡锡，西蒙等人首次提供人工智能的概念，使得人工智能在成为计算机科学的一个分支。 1962年，感知机模型正式提出，它具有输入层，输出层和中间层。 1969年，明斯基的《percetion》一书出版，指出感知机不能解决高阶谓词问题，人工智能发展陷入低谷。 1982年，hopfield向美国科学院提出了关于神经网络的报告，引起美国军方的注意，引起了神经网络的第二次高潮。在这次高潮中，hopfield网络，boltzmann机以及BP算法得到提出。 2006年之后，hiton提出深度学习，引起了神经网络的第三次浪潮。 神经网络模型1943年提出的“M-P神经元模型”如下： 输入乘以权重之后，减去一个偏置$\theta$ ，然后通过激活函数，得到这个神经元的输出。在早期，使用的激活函数为sigmoid函数： $$\sigma(z)=\frac{1}{1+\mathrm{e}^{-z}}$$sigmoid函数如图： sigmoid 的导数形式如下：$$\sigma(z)’=\frac{\mathrm{e}^{-z}}{(1+\mathrm{e}^{-z})^{2}} = \frac{1+\mathrm{e}^{-z}-1}{(1+\mathrm{e}^{-z})^{2}} = \sigma(z)*(1 - \sigma(z))$$由于sigmoid的导数函数形式简单，取值变化范围在(0,1)之间。神经网络就是有无数个像这样的神经元结构组合而成的一个包含许多参数的数学模型。 激励函数激励函数的作用是将无限域的变换指定到有限范围内进行输出。同时增加网络的非线性建模能力，复杂程度。 Bengio对激活函数有如下的定义： 激活函数是映射h：R-&gt;R，且几乎处处可导。 具有软饱和函数的性质：$\lim_{s-&gt;\inf} f’(s) = 0$ ，软饱和性质只当x趋向去正无穷或负无穷的时候，函数的导数为0。硬饱和指存在一个区域c，当x接近c边缘时，导数值变为0. ReLu激活函数：该激活函数能够在一定程度上克服梯度消失的问题。 relu在$x&lt;0$部分为硬饱和，导数为0。在$x&gt;0$部分，导数为1，能够保持网络梯度不衰减，缓解梯度消失问题。 当部分输入落入饱和区时，将导致网络的稀疏性，同时导致对应的权重无法更新（神经元死亡）。relu的输出同时具有偏移现象，即输出的值均值大于0，偏移与神经元死亡是其主要弊病。 误差反向传播BP算法沿着负梯度方向减小误差，利用链式法则对每一个梯度求一个$\Delta$ 值，用于更新网络的参数。当网络陷入一个极小点时，在该点处不存在负梯度方向，因此参数无法进行更新。此时网络可能陷入局部极小点或全局最小点。 如果网络陷入局部极小点，我们希望在网络的训练过程中，函数能够跳出该极小点。可以使用的方法有 模拟退火法，即在每一步迭代，以一定的概率接受次优解，可以一定程度上避免陷入局部极小。 随机梯度下降法，每次选择部分数据进行梯度的计算，因此该梯度方向不一定是全局的下降方向，随着函数的迭代，网络误差可以慢慢降到一个可以接受的水平。 深度学习深度学习模型是深层次的神经网络，通过增加网络的层次，提高网络的容量，使得它能学到更加复杂的问题。但是多层神经网络难以用传统的BP算法进行训练，因此后来的学者们也提出了许多其他的算法。 神经网络的实现pytorch中的torch.nn包pytorch中关于网络结构的函数在torch.nn这个包里头，此外torch.nn.functional中也有于torch.nn对应的相关函数。他们的区别在于torch.nn中的参数是可训练的，可变的。torch.nn.functional中的函数是不可训练的，进行一些数学运算，类似于tensor于Variable的区别。因此搭建网络结构的时候使用torch.nn，激活函数则使用torch.nn.functional。 贴一个解释很清楚的文章：https://blog.csdn.net/hawkcici160/article/details/80140059 pytorch中的torch.autograd包autograd.Variable是包的中央类，包含一个张量，并支持几乎所有定义的操作，在完成计算后，调用.backward()并自动计算所有梯度。可以通过.data属性访问原始张量，而将此变量的梯度累加到.grad。 Variable类中比tensor类多了几个其他的属性：data,grad_fn,grad,variable变量可以用来计算梯度。 下面这个文章有有详细介绍：https://www.jianshu.com/p/cbce2dd60120 可以用variable来定义网络的参数。]]></content>
      <categories>
        <category>xigua</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[19/7/2019 preview]]></title>
    <url>%2F2019%2F07%2F19%2F19-7-2019-preview%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! U2FsdGVkX1+mDbiPkulkQa1DeUYJr9RxVHQMAQZn3Vy58lmUsy6mg1l8EwZGM3iH9i5b45nUYwwZy1Fe02ueh+IOQeuQpKkNO3/x/1ZNfdGEkKO1JHM9I3g/JIX3ve7P2WoYCDPIw1fqfEZxMkJDT7pIofEJHNe0u+o63yfoeET37Fw35fl10jYViU16UM9tke3qKdsX/GxIRTboWpTlU6lkUPu9daX/tD/2HV1GE61VV5yt9kxqB3gBbsXLl7xHmpY972e0YhcOqHwSo/7u5iaUi+4NQ3nGgXEUnryjIS0crg0e9MlDJ4ZVAFo/dRyXfHbAObnSTPVCIWYYoMRghUF32ZrUU3Op1LExoPXnNCCmpvzKNYGOaKMOGxh9EQg8NJ6NNmqal3CiyoSq1LHp7LZMNO/rtierbbVuSRx3iZCUPfTbc68r3uXDVxYhB6fv0K1AiFTmeKjci2NUNjifF0o0hxPNpkslLLzzvffXe8/4RSHzN0F0ZiRSzkZ4M0hm7ISJ0Y3SEon2Qo1uYS7Al+g3xTbsQlmi2v/Z28HoBX5icwnF3FoVcsEcR5VEpEHG3VXNDgvU1RG2b431RL9axdwB2eDExaqf+EW5JBVJx3kTCJOe06qtQ6SC+1HtNvPLp1n7xIuPn9+9DcXqQF60zChYkwJjvW9DQaatc6ZF+pxovKPO67eog0e+7w6KkD41jXJx/L1YZWq8bxoNDwZkIeP5aTw1csuCcZkvRxjIPF1vdMVs3/A/U1PxJS1LMFW+H9Fke2Eip/ZLTWn21zvNry2wzyaX5QsYiW/CnjvJy8g4f4AdUxGBk1epwxIk9gxaVcBLYoS62WSBhwQjWLMUtUo51KR1cqQnhM2LL878pfc2bE0Lly5tbXNcOegVB6ezYC2FUEwdJFcabnCFhcMw+11dLqrVl9yk9yE2boQn6l9DOK+aZ6qUc9rSMS8jT/ba05cemHPR1pF8hh0qk3A+Y+m0erYrPpK2rwvfXhoRELVtMXmHDkNwdlxsi9epPNec23rgZe0ukmEMNWDP3VNr8OOrCGe2wuqQAp8/gZZNNdKXnxpm1GxxtA9A1pHiHD4pP0tD5UuIFygIdqHEKJgJLgF7/GiDujM6RH5r3RZMcHXhq8mD6s2007qpo0bzHjKmEG59xuWjmQBBnEy1be6NtypY8RJbwBnz5i89Cwbw1hZYhiJAIUIO5OA35Tfc3ngnHbUVJiKzcJ0/8ea9GVpb1ROWrRXVsU+MyQMr6OjV79lJ3voNeJGU5O6wNZaja9I0RA+/p1uoAIh3Bcu5IcOTn1uifxeLdJcup8zvkS8QkFHCABuAm7q5eNf2eC9xeOByUDAUaaiI6vCJ7cAJkVYgoXwCISQs/Oobj1ICKiBDVbzYXZ0ApRA2VP31UTQ3sqdiXKzF4FCGcTNWSVZuVJENivwZ6L/Xpf1rWnnwIxZGgWACfvDrxvsbih0reJJFRV5aXZFniXE/QG65xnooXCtmiZdPrK574OaG32TpEwSqJ3jHEmfMakFIi+aOcv5DnOkBqTENNpuj4DNCnfVQYyt3fjxFWkSvNaP68jmXFMcU1vSw49f4gGWxCoLm67GH8KqHcgyb2SJkjKFHxtF4beif6kkVo2dBeRZnI9HxLZ2HSW9Wr4X3NWrjrAm7c+zXTJvRjq6IZu/0Wp3NscDwC+YSQQjT9pZU3OZclcPT5jFyLlNLSGNjUeq94OkYojbt5W7fq+reGLWX2ddEXppJQFAcuGl5iRvq9hOmetyji2KcAIeZugjIUonItuDmxL+Ni6rylDGX/cJtqYFs60WHbQYtF5nMyYiQwfMGHgs91CCjdRr7imgPuEadEjLT0LjNj0JBPAmfxvw98HaOiTEvySCf9yr/Ved4HXloEmVfRBdvql+dS6ZIZx3ISWa8wjUsifYqQ/Oge0uKrHxgcyQVIDFiloZg+OmdaLHhBxnL4iLJRYc1aR3OOqslc2H0G9s8Y21VSMFItuOwlx3O+YOW/4nPwSlpATmE2jkBvZC+eEnby/XvMNqARY9oHnqezO4c1xkObAnhmgPqmt+HzEvtwc7jqEG50WqGYcSTllzTr8hrgF+x9E4dl+530UAa8CAN9CXeE/FLG8I3Qemophv5j7k8cqgA+8sPxDeUkAwvpHUN3y9f7yR2NeQJ6S6CicEnUe/10jA3Nf+8ISpaW9EHvwYd5Ur8u00MsZ1sjjkzWgNZD3YQ6afUyYk+2SoAf1GDROT3DCzTQAq2RWe68wTorehILDWOt1HFEChAeXq6u5qynlIckNG2VYnUJ30or6T+Louhjidw56/FXQ1Oi9fyw+wypUQV7kzvejYdq3A4ikeLbQir4HOkP8gwapqBaUT6i3tDpabMeM+4lGqa9CQk80tw8JmnlxlpG275FC7XrsfUUa5BAqYd5H91FGubJ+FbutB+jkojS/kb8KrqETjo6fuSYncvpQXLMUyiptTyx/uA44UOsfO9LkCeX1a0indONr/yG2beQJdOoaJ/k8DvBKGToOrAmBKaM0QyWaDJrOejfEtYVu1kmFTw4M8B7wJNqG0P3K0Io5SZk9o2Lnat64TYoZDoP3qAgSa6Zt+35JnNhZlAhI5VNCcIzpDfVR9dCuPfX1l6Ci/HMikurzPEZ/NRW648qbK7Qr4OjzqbHkw4owysJpLnesHsYHjnF0bO/hNr2xAyIv58uz+I+QTHwqpQoeUoUK+7q0ec+AakcRKyzwhlofCu8aX3qadheJsvhKU3ptxr0aZqYubkxhOFlv110oICItO7hnFQqOf9FXf2ArA/+A18H1+YEUPm7tb6mirHcWzItzI1tln0NZiluLEV7YxrtlFgCcfOpS7vRG9ba0zyhdGHsigTXa4DY7T52hcKA6XOHfXYIWBqJmGLWvI+WtsKolKSiBaO/mjLVNHEGVTSqPbPoih1dFO+CJFUD+ZBnTiM02VdpKdphXBJipl/d5JIFmKbBhyhAHaCRqS+iEdqP8aKmmDPvO1yKVaV83vK9zqiHEBRnak8GUebxt7TjiRdcRQjVwCWfSjs5hsZHlagXKuEF7j38avXWELrTbhBGdSRTch9m8JDxkO0jgux2WPh9IsiYJ0grYdDiM7Jk/p/lwTBRF0Agcdu1pIT8PviX5Ye+iCPTUmyK9Rkt3BrGRDVj8rkmasOrovrEOs+aF/idXgR3q4HvEoxLlmF5iUR01nsosr0+35i7Q7VyiP938V8avtZd1WgKcariBkH6RT1Rl+tNAcToAuFIt/5w+rG9LJbLQpMd7gr6BfP57vgxVPHLcCRT4feJg6QUto/AtdHbpVCPa3foUy2iTlNT5Y9PwhdhoqyemRtBg3lsaMWbxyDld7njcoBf/bXP/0hI5xo1wx46KsinmUkCvrgjnXgmeNl09W+RTeZjyhh2SIo1YYlMrPXHo+SKlLTfFbgIDZ3d8Bzo0VdWPI2a0bc5qXAtuTq9+AZp20Yjrj9QYEB6D5YXY7Oeeo5Cmynk9eKXTQqqnXj1W5TUDgc05ORo/IfWHMrPE3CWikmTxlaSDM7DamTi/+QFoX7zDqcxWM8kMj5TCciqn6bwjOHT3rSqetHnW0JeWRf5oBJL+kk6kr89QZB58Nb1wGdHXTtE1kw7oHUnT9EdIre//TYpHvdaAhds0xZAYuyMEMZlahIHRah88IGATNeuddaMixKAejoWPBJleZHkXmejgzng0rqT9fxikE3JCGX6LUWViyzZoGoO3mxCLh/Cb8GWQ5MbUnGHK9BkNZQzwwoJKT/jOXB7g1WyegjJMIvkZnjD4KNLeiRmquVWMvamWFw26nJ9r/er9r++dEEV7Gs90898bhx39us+oApvqNwlQoBgFUDfO6uml1LyMSN1A/WTpcZZpiXvwmcAzTnuTM/asy+03KyCKz+jxIZGAZnDbs+ZEWHm5VcC+lDqVZFXKDAVOfdZe0Mez/66ZTfvXj1y+8RxpdsmI+UQRZL8FgxgpbEpa0OmiRZiEUCfo8ujkjwGYMvgCWLij5jktOLnIoGCeBpA9fSGi/TcQMb09s9teunAQXqcOKT3w03VZIVBm+ZJ/4+1NgnKDaob58iTegbUItPu7MIQh7l9Qs8FgTOLMCYPKWHXsThWEqLty90aYkO1baglCjbwKafkJc3TyCYo3+A0akwIscSYtrM0Q3o2XIgBfOEPOSbNhn/of4IuhtAhb1YcULLxP2NQGvgqn/9hW5OIZbElx/YcYPxPI94vExC7uqCc1CWjfsNO3p0Dw4g3gClUzKrrf+0nJ+IEBiPb6IW7I4K9fVIA+Y7J3zj1uWk3mujIFr/ruYrrLe1XDTv6yJcLSvh7k64u2Ve+23X5Vt5QcjSzx3xjzUZxBenIGPFT4uqltS9TTQztklxkyx/hrW5txxe5cSaNntb3FEejRZ8kWsN9jThjLF4/XmF3/yT2upD+BJ3NYbL9cMkOSMquNxo/91pn7IuJg1nAu4QE87IAS13Y3fzC8lAYULYJBYPNw8RjEHhEgKDwU7gCV+i+vIDDysybxk3DaaERyNlQ0He+RtlbZDFXNB+KWUbzBynndXnbV19IORal3A+v1J2pAIyEzgynjD8DuomQRMnmty1iiwQqOIh5A5PSjEcsmHU3YCmpBfiCSxaZXVwEYEk1Fbkbz8WNu8u599MWDWD3pJuv6OHD1shXbHqlRa1nPP8VdA6h6v4jSJn22+k147pRKusL7BcneRkPfgqnLJLvX1kNJbQU5tEvTwv/ILYQ6EX0lOOJmZvgwp/FOEPCku+IBIqkznuT0BJws6vO7Ci6G4TZZkKah0766doXQaPdiHHb9UW+H0iaRUet9sp2nMOBpTUCd4krMhrC9+kkVrgN2p6dyrsdSDhfgVrDHG62VMOCXjMfM1U3W4KalHgmvVjM1c7EBSBRkiQSOg81QV0rGI0Ji9Do/bhwNMc1Vsn7MLLEHAbiIIKTqzFyUlUfqy34HdlNf2Xp5dv1qRcACuPJ83Ru1/Z046s3mjsA/LpXwYtlGlmaVOfz8NKGpYqh/GxFC3eXn38rr5Us+0EBNjy3XEgPRkQVZzO06+NeT1r4EByL28aw76TpDC8SVnBx5x4xNGmwJNXDBXlj4utbRCFI8rk1bzfdF9NcwFJstFZMmWnt5J+ns5e87MOn+J5/7yyfjwyMwM33a4IwXIyLFvNxuqHNbtz4Ct5F9PtbTb7rUmwPJXnXg9dt1TUwJcf7jIGCgHHH+H+RTkg7LZHGgIztBXBqxpKv1x7gz5LmIdip2WJaBqWXzBoAoW/Xkq0kFJS9iQKFp4GGTjOBUju7418MCB5VBwCrmL8P5HeCDEB1kpUeIDUIVRGamqyVv79s6t1kILNBaTeUWbWmPqwv+jWkvJL4sap7WCtfOHY3IZpPgyfCLeplGOvjxjEHyTAx2vuBrHUB0n2e/bllGEp+GULiwpK6VmrlqmcTbJqoiWu+ryRcK5La41N+MaLkfXR7TRiGWbveVDZgG5TWqd38t6sLXPxOOoUOq13iP6bcxb6SwHFpQPvxbU/qrE3E+qbqkz+sYgZMNF3HXFH4FrzWUVmaVVe1Qbza0ZMA0KGYU5H+5O6aPnUx/oLjVYbfy1z87XjsBJ3RB0feT77VeRTAknDEixPWhA7/rwVdpJoFf819ld+DetwRknkaogmjExWAez6Z2d3NSQRZuouJ5Hp8fWSraSYMYwGd8RRKPtbBgrbbbKudV+QEBL7R3GpoLcCO3ZUYpSeuGcdeSHWpgel0lSEnH/SKm4I2ktLvHSb96CdlgpUWv57z2J0WpwuOS1tZp0e3Ep5VUAN8BfHLV9qu0VKaIncl/u8J5qOt88PNnNmwyJsCZDfdam4vVw+KM5VtYCzx5nzvtfM9hsMoJ8furP+XYzu//S+BCosozFU8/QNrnltd59+69DQ6Et7IQdBAHggoxn5JE6ez0FAo42e1Sp0nnOvnhNbztkPhQ7JEaSfJEyEovvzZdWSED7DY4C1+KdbM6LjcdHBYesZaF/cjt2AgdynaMvFw6kWqhpf/Ks1X50d9a4Ik1nSYbGPhDDbRLoKgd5RU8AKq/vm/Pnd5le5TpzucqGtFgGEruBNqcxhewnkJsinYL+ogl+ohpvB/oh5b65E2Oe+wxKzULgfwDUjRh7CGzkD53dV+5QIxN26E4dkDLGb+TUwqqqWudj8Nf/OoyjTDkVtcyhDW1nSwEux0eT0LcrMGyU9AhS8l1bMQCaV+Om8C/hqj0XiT9FUvtPAPPtgHwwVFutfElyO1xnael5Iuh48hK8zWe/+oqYGWKcnTorGyqct0NzZqo4swYXsEtC8UaNtQoP83G2jpnqdq+x1uCuGbc0DorQfHyGleOlK82pT+OAtM/hNEAWt8TS8UBatvNe6p6d5AGp30vR4NLfMRQVHVzo67yRVhUUvAz8FnXhWMr/+MtOBSyqIHN68SItKmPFE0JJRRhqtfGAzG7iAGWOFq0XYQU9OIU8UbpPfG3wo1+npCh8EKGulW84OyXVNn83SYobpJI1wBnXbJ+R1WqD9NBO7JKC/Vf8iXGrq1l7bml62uZJNXreugajh1fXXZ4saNIzj3kQn0mzdAjl0I7NZ8XIrzfODsTN89MRMODM+JXiH5k+DsEXVZggMb40FL7yyEl6OohaQf8ZziHVoe9wxqL/H3y3ZAlfj+vrCqRh5GXpDmiG8UPJyQmnkOVJmIbsnXh0Nrv9kJJgazA0C/26Ee7CV01D4a7e3VcqUP14gkDn0lEIOtJMZqMQ2YEmF+nkiQqX+wGOu7PZKpjcLFB/TTfdCS7cS4hV4milLGwiOoi3dKLsCrZTifuya6i9JnHpEdj/jhOqMD0fptJRM9iAUJW73ELX6R0s6GPLlSDDBRwoO6Ofg+/9Owdlrff/v00oamSMGeRwjcMIXPUcqpSQEhqjnGP52ynTgDPevDY+znity5w76u6+YI6mGw7AIdkf69jy91k8B4tvCnq33dYB6rdh8jEikeHaMV9IhZ4PjtiS+k0p8dnlssQ0esaVUVxAlkeSYlb/YTqBSYXQ9VyuyIo3BWoJg3+abpbRrC+BNM9VdyM3+QQ3FrgD7vJjf/sUNs/kjMVpO8XNHWm14Ezi8U030ZNWhAZJt/0PKHf022Y6MxBpNBGm93o4v+3NXIXg5y1XHUhOEKls+gKChyYBuRoQ0PUW3209LAFCung+g5ms8lqOTzja740g//nzDBEntXmz2Pd9hf9WVsZkxo1403NRWvtFXQgeU3bnWWcbGDD7uPe75ANZ+TwBJcB/hJvWb13D0n5dK4qjZ4OisSsDem7Mjdd8ENGxvhUhz7Z3CDwki3wO/SjrBFbyxoUPlH7xcF8wN9Zb+92a2m2FQ/mAF/PNmrId9SokrTK9nX26EnwIWiIvfb+Sgp5klkEcsRioE8Q5s/5cds3dckjjlP3JN7lMw6bGLHAwI/T330l7ESX/w+7KS5un2dS0Zy2hR3gjZ+MxJ+UqtYqGg6JvbnkO//o6Ufj7Si981UuzwoBKt/lPrrPTlCLPrN8Sy+WegcRbt+W/jpgxwJxZlik3PyhQWIjpqDlGdRRhj7ztK7Qu1hRpmprtcHUPle4YUvfvpYldVWnWN0ki3DDsURz8CiUHKGmAWZ9TmfKgBCpOV+n5wBQpBZUxnQacAo2g8lRTYjbX6iUfzACIveBt5g1x3k5BhwDePWBm983j6sYsSDogphkgOJpgY8jACKayrZcjtvJTHjOYRVKebvVcroM5kCZAFWxUvDpV7bSm70aKZ/CtrTPSgeviHVoFNL7guAtNY2YCagMBgl4cac9HIYxKXweOqic3y9PKbvFNU+ZJ+e/lYdWozEM28KOM2LS1XnUrKL1UX6OC4u5KKXyOfMJ7+tUayOJG7VlUVyJHKVuKaMgPqzeEqSvyRnkGL8qWT0pfiuO/CK/9l/GuCKUZRfEafEc91rJ/36/oHIfPPOUnxRhcYItBtnrFhGGuX0x97Kkc4GW6n4rmilIv75ozH5BQlLsisAgTuVS0HZayWP5pOX+Fix16voFMKuIyd5sRRIJCBULrSOjJ22CYJWD/EIh0a5dkLaRue2FeqEJ9xiMZBvQdbHdUVyKpleM7J/ICic5YEGYR33ix0HtU/hfIAbnpY4e5y1y7lGAdzZizgChu0BNFxG5e0R44bWPmtW3Eor8UgnyhVSg8x5dGYw9+vg1GVGP+rDcucXA0xVPsCN48ADrNijcncfP9o+Zu1pvn/Vs0TSCTThj6UfY35UsvnL/4KODYHMAxRxJb8GrNeeoVt2KMbizmich/+JJ6woF+yNDtzydk+6Wk0E7j/wlc2acZmzmwK9FUDpJ1Zg4VLDWVG1OKFdttssa4uvFzdl01HUxM2eaYv8klqj+kUl/RVPMP/zvEvq4hQt+hOCrpIsvcI+xVYGGbSbSsrD3Ou0dWW/wI2vqDGh6X+5LB3aSI3DnkJbzE7CeTWP47gW3oS1WFkxVJ/PMr3x/RPUgz/6lO5YLVdn/i2jY6IF1a42+KNm6LEV1VSB1gvnlWl74ibfTsagiCBEGcfeCGBAebkTCKMJXFMkAI9IS6CY0kgeiccFXdd910Tm/6DtTa3DFm8UWPQ6UnCDB3vn/D4R1ch5yefDH3VY0Gt1tD2Udi5s9mPNrll1+GYln64UwGbQLMp7bQwuLP+WyZDWx0Uitvr3FZKL+McQ3oVWd293zZ0MQtOBnr7lpdV0Aj6bjsVACQcVkWxRjftruSJOr8OpiNyB8/MkURSNzx0TT7H/cweoWLWLIBfrEBVaM0ml8bVEKzf7CU2+yvmDkWiJhbB7Pzz4O54EF+tODHaTzlOYctgMjliIJlWnfVmDBSjzpQ6tIFKQHYEDL81Skk8NRLNjKs++a+OnFNxm7WP1pCvB9YgPFVEDBtuTnHRfgcnCJMQUsfFadiD6FN+xFlvRcVPnr+ZpZDbzX0GWI/bKZlgDVlBDTOy3fYUF52c8QblEL6XoayBWmt6vLQ4CBs8hYJ89yogb9hNyL4tSjxnp45XeyR+DzqwNrV63kCY8GFSTNG3D7MZuM87U3wK2ejcGincJk4P+m/W9inAzLCWrlS59ioLWJPmLDDPHKBHY1VSf0IhLI9afXg/Fvljy6vvdSKQzKzj34oOx7plISlRAtKTMjqh4MgvFGIMwlJfQcZn8M7tR1w+etaVja0OBXVYmDpRNWpJspdduNF1shy2NwVmk8+hqx/5CcqfNfoxW6ikP+4+1OSgg/zo/7fVrsO6ap4Zf0HxO+hYQ9LD0HdJtnylO8CIORJCZOhN0CTOdN+Onzk6Bi2ZOqlTjlRMaCfgESl9c4WQksEcd19HO41CLt9l4ijUObtwZFA5el4DRGrQliO/Ff318tjpnyep/bU7ASnaG8irgYJUDZAalxmDF8LLAhN6zsP1aTEjMokFsvATjoixqBDXmGdyTdtM2zfu6xJLSVGRrBHNgQ0+oMeDZonDMK/slefYO5ITHCcl/Z+VhP8ujP216odPlCvL5aZBIjspyfp383MJBb7LXIHgTd5ixU1V/Q4HzC1ItoiwfOAsfpoNIY/bGHSECkHwfE60N/5BkIJTqUGTNAuQfhXHNlh75QPl342JQeY15VHg3tHWAoV1wUfMKKavnh8QkNXcwgfpnhLtWdHUUNY3pam/nhVzRWHT49Ytc2fVmdFB7VGDZkH1jFqgRmYMPO4FDZ0gzqeMxjX1UAqMzdvgRQZwHoQ7Tkk50mcFBGzC6bgGQEGwaGycDhYKwuvuzOagcd4SQVdtTmBl2xvpu90gLGciRTeLr3ofyqPE8dDoOxl1x35pxS1zGuOoN8uvUr4uKYr3RTBi6GyyNnToAUY6ABbBJ0WJF1RJXCEHBxcIdYVI2X9s4iEJJ9oKcEtwdIH4SHKEdjwb0voND0FYP/JJGaQwKp2sl0eVqJFTgsaN4ibKX8YZ7wzP845a3+SQw9ZU3MyF6ypyErwVkHhPOEgEnmAnBq+OCTmTDvmVNJeAwppKJekFrXwpZNhHkbRLbddeerqz6AhtgqEYS8IzOwM/3MFkA59FFtxS86I/RYhdOGfnV3Yuc18v2mDuMMKJEnAtjzx6ec+GeJm8DtTjNgz38DFyy28NcW+MtQki9K3MDElQrdKDWv5XDMM095faKhr6O/VWmElpgkKIDpd4rcOaTs0Ot47oiXK9KcjqoAnEgRynqSOSoN5bDyz81EtCCByBA8AdwSpG96JyNKfkeMqY94qRhFUBbMK3VNPpSS2OW427lP+9J2bVUPG47Py1p1TG1nLQwUj1YBckgzbK5XLc7Q7WSNeswkunOTAVHZlanlwpGltYE3X1VFxTT8oZ0cMtXjQk9vh2gr/EcsHk1OGSiayXbDvAI6VtdvXts0Yr+aM+QlWw1fKjQMqp6oYg+Gykww8sJdnBIg0yOsdJR4lHJ6Av1gbV+rq9nA5BKrHSKZI4Q+FgD9790bjmWds80aWDCGSZvpzwyZ+3FhY4/GyS30KoH0SeQihMjraUu94xnp6hPFCebtisY1E1p6MUsDO1x13uyphqq7+uFdNL5WYuWq3vKHcmJsNrzFBxxdrn80rC63FaYWoS8+xJkyTPGRtpA0pg99Og1sw8G2BhDnZxfYNDki53u/zJuOKBaRbwG6EXmS1FAWs+FfEQyN1BOt2QqCWXJaN7uSnoHGkZdDvNruyU8/y3AK4bTCU3N3WcyHib68GLTKt2Kop+vqwKwYQ6JhK0CiG/tZ7RnnjTn88gZPK0XR4blOi4iLZerFTAnaUYQDbqgfmWjoBnKduXuoh8KYbk+vjickeU/iNnbECq4NP01V7xfdA3W6UAUHCibezVDw5fe4g22qYmgExPIdH7O9SRdq/wi/EnLpb10IxnCdrPX6afTwXKGp0OG8LJA87sw/bqEoZD4QAOmTRaILcJitvAYCifuIjgluE5uQHiISEGy4PDmWszyi3O37XoThduZgifj7ZnczubOGdrKc4dKMFcHquBKWSUo/Lt4zm9LIpCv83+lEr08pjKrPCwiBQat5n55sgTS11veB0+oouQozhQhHbHHUtDMLSkABGyHHxB9QHNNmfIVUOvUdHM0K2N9GEx71vWyzIxek2jVFbJR5rel1h3MsIVIRN1orNydvLengiTMNnwNh29Qcq/B8Wsno3qzL/Xvmf0JjgHiFaloqy6ANWEfZelavERAnfkyhpDswTvnZViiHtFCNlL8P4Z5wzHh7CLByUh9cyX75Br+PheU/6hP7hw3X3+l11oOJ7C/niayS0UFyTLWyglOrIpLolnWNdFqvTp/DdXCzlsecuw7qiGyeNCNIo34JqHckKeZ2OFMcVJF99t45PoQ1mVczAiSsm+2Mebdwx0CQyeTJvvt75p9QSsIy93YffrXPv/qxZuBun3P5f9ocnWour5PkuglT3FH7+6keQBVN0XYtnteRAG/YYXlZqGDRBOK62a10vo4U8+uvR1rqlHRE4FePPiqaFsafGk5Mzdd/1SI5N5r5scKm6LAzpX8wgeH0fiw+h1DMMXkEhtE3R29v7MgANGV6LuhCvHgTofzHZ8r2kzPze5NyW6TIGm8fKj4cBbSyNNy+wQ9Ughcb16zGncRCBb04YC4jnK+uNYTJ8a34Agp+fdHmU+syKzczVLPSHaqkxUvvbH3/L84542j8T11M2UoGglAnVPOS6VqCIiScFEuUpGD1gWTffxnxkDaNzqeQ4E16jZc+4puiHn57Gpn3X+58rQDKDJIO13OKEx2lPzu5RIoJU0Ah2aJItUKZ6cJvVx8so1PTdiDHa0diB7W2mXbG/nibaU8Bc/FCQkZWr5XskVzuBCYWFJf2UCV6syxyTUPcpaAKJV7YXA13IZ7bJJhUEiZaFjzI2o/X1EFbDx25ZDGu36cIt4Vm0NcRLfpcZwNNPfzmaUEhpC2JuZxVhQF/AsCYZ6XpCxgzpaFCX8MLn1FTDfhsNCLFpLPWN0bmBS5GZIz3ayScuCA260ah2Bv0UjCUGE9f995clvAsG9p2iwarRrc8dHyqS/QiJlLU3MZa6YE6XokvF7nQDPpxzG1bUCek+kEKTFqIe4xIKHEbWvmOvy2e2zSDYMJBkFbRkEs3ez3DpHx5rfcBTDs1DAIV+qYpguAUkjmKTXVlz14awJDJfep3zdhTPKVNb1AGjMN4kx++E9rHE440oLUyDuONcHC6thsm27pxHZPsF5azN5OKMPwHSIiowNvJ4ZqPzDIDYC7lSiEBWKq0Y0qLMEK7QNM8LuPAG8ZZsxe2LJbTeX8Sek08dz2nXWbkqAM0DhsQVTIq9w/GKKa4eXj5rFC8ihkOXK+551DaTzPp2KZEfJwbHYY2npMCe8OAK9WBwHBpmJP/y8ACPOAFtOfgsX2HZiC4pIBemEqZ/OG3xBx9M3Gthr4kIU/SK/mXMZFBa5IcxXYjRmNz1mrq5ohb/xKR3BcWW4pJaKF2MemGqtTArGAMFz2I2211RVG92N8ww3JNhRl6xzst8yF+CEjYYkGcv8Y1cxAuRF31ZS/U+oqjsUsAnNOjWYT071IhBYIJz1H+1BP5Pq49JCP5Q/mAvMlrF4EvmdoDCLEHHPgzh82UNscNyidiB3+sS3pKLV7NSmWpqu1bimPrPMYGQGp6FRpyGtE5RnJevfojLMaH9dczNEAWPp95TmLCuxxJTBy1CvxIOai3q8P6XF+VVu7A0XUEqIhSx8fETcn9aiEffnnbK13D19AwJZ7PDCniUfg6A/1Fs60hK9/k4jIbmsx5fZ7lDDUejzYDt3zZ8rPkKNh7UcVvRRmcVk+kQDPcr9e+jkMq7ZfddaRsig2nB5bHYYjUrVSzEnRsyUDbOeYNUVp458v6Y7zsDgrDjT/WQyWUQrFTrIiqZk/Yc3dVqbm2MGeJb8PHr22OJCfdms0fDLYAnR56rXQiZeCXdRD6W2Ig7AtFIE9Wjlb+u0GH3Qpij/z8AWbys8RPpjDpUrLrkiHLLRTyjQ+y41qPRnLRsAwo62bRdJPWVn1Izxqw/pWjERBzUNxS1jzYkBqJroZKbSWyuBH79JUAdhNUmYXnkZ46WQo3yMrdzaZrbJqOvgkCISLDSEjV0a2argTqWpLIZB5JpF8JkSn4kLMbi1C59Nb5KlSQixqtM/xHPM/HsNPsztx8zCq0GWeUF6KP5aKATIDZjdneU405tq3x6I9A35tKlBd64uuz+jPp4rVAZuCA0kk6HXjbnwFKDQWHhYk+mmMZttIiYmsad8zYVmIpOdtcWVQnnpneLndKa+TF//yqu6Yf8nPdZzYjtwFW0MXiYGVT00jOlqCnwtt0EtpzCmm5IoM3r+OL8Biew+f0ww0QsnqaZ7sNmLjdb5Z+pWraiLsLjegGNKpCSdapxPMkxwmmv0PhpFZcr+ANLqiJjty7IXMYdvtXv8VGh+rLxx/ySjVXkWCPiL5q9oUaAELQHaM216m/zZ466nwMTdi0VRxMK9Ha8cjp3anpqCicqqs5ow2SB+nJD5L70Zu/eRmOjs96Wz/UhPEMbKNqy5iL91YBETvNeJRzwqHqc38yXq5Di1lDA4fqvcymvY7HhcYtbFv67NKmQL85e0IVF8CNx4TtKdhxigEOscZzO9WXnMjDbsb6VrRy8noe2fwq65mtSyWzKRUfARqKNif6sZsJoceOVAg02azLcSgh7kexqgf2nLDVDeWGmLp63f+sXHG/ruKsnrKoAlrrS4xI5X6/guEf+oM5yn/fD32t5ybiSAx+puqAn7p9pbRhAeMWq4IUOprpW/Nh9r3FCMPLA5nuHABa75dY+VE+jSmMh1HNWVGofdzuw2rovuOL8LiFgLOxLOzOu88I/lqdr/Mq2kpPnMSETew6yNyqAG+pJ6whRfHcLiN7cvOq3UI/gTgaukZ7k0jxQzF0+7gheaBCut7eCMQplGij83kSYoYHHBF6/W52CzgMAPaJQeDemdaJQdsLMZw1e4Q7XQET/+7n6YhijhpdmmIpLNxdZ2Uej3ZWOrNVjw8y0tBJczEocKOBBsdW0l535B0TGKJUIPUQypFLyOWKuO9fPG61jxJ9E6zeultmjX3Nx4Kkwzq3KsvaFcvfoKUw7o97b9R4rEa4wPoMiOuv+4QTaNdJNTQju31Igq2Uge0pOy4TtGerVwHA7FhnBSW4DYGwV/hw1j8ao9n2Ydcl7vhfT792FHQEqT3PoMtBJMGXbv7K78CMNqd1Tbn7oj6l3e35udJRFNUMPvBqTySnKHWCngYLI7lyK4/HV0oqOou2H9dxdASSm63Rdty/kglZtXu2hUhQ3D5zPbBn8HMHpEXLvqJvsgRsdEefUTONHyO6ovYd5bCn+zVc1vZFBLJcwfAQ/Ij7YUgkgsxJsOOSEDOW5trUvYYGA3ehbMwSmGYk4nsWQz4NTISkWD2f94hZ6gjA+M8shZWuFlUPR7xOCiVZp+Ux4K13nlQgyJ63dOfnV24vKnhxUR0uhF1YdZp9vrbcOY1TFsRD7Q9JN70TuU7NtU+hBzV8V+isP9Y1S8P5T+phkm/SA4J9PIXq25TcOQLJ+7V3nj6bmLMCqBLFDnBZb6mxtMjp329SlH8ApCtLAPBmNMcGiE2v5QYQRCFtLkfZHPem+nxhAuXm24snJwnOWp19BXtj/4CH9PLML4p9fTJWOZ9857DL/Fnx/R8kbKpIQU7ablxu9c4aVU1bSCNcVJXKwQe+K749OvhSKCL0Pfy36QF5BNWU9hp9lGuNPup56hQ8v0gI0tSQ6nkCVgnNGbby8tEPIcl6ch7cUGM8GD4WLs4xLmy1ZmdxXPzmaWmV2tw+26uDmCAsaKIVFA+wVqCukOnpVAuFnhFlhnawPchp4KZG5qbtcH911i9mLqrKBi5pJjg8QdmTkAmG6e6XzJJidSvfHdBoOAVtvqg70F1EZT41u7vY17HyazPtmzAQOJoIcNe99tM2u0mzzOhWCO/vN82Ajtr+gOEGO/a14yISvIS0WgTBliz2jlBTDQzwjDJAXaFP1igEhtziBYfyR6tUu+fYZeMIk/j5yAoo5VbhLzZBZlue/W6mTWua5B3ggIHleJUquxRJmNA3CrvIegfAxgwGkC9tnCC7sFe4kssUb2L3EYgioGxAK+tdBNcKXC6m1CMyzV0PP6O8QQd9M6V/Y9IAykVYndc4tZxsBtdit0yJ3eJQE08008ms7bXaXyLGWOe6GN43UH15dUKVL2KTQgugMjSbEVXYAfc6haJDRkcKzu/bDljAorJbRhJBTxKMZGO4JYdiURbWVMfWT6xjNFZSxnUUN89upjo1V8ka0HiJm8DNAhZ9lnsGNbQf7BDzmtsntQOl2BHnkwSHbirlPMcPm/9OV2nz9S6lG3gsEH7T3ytQHymiRF72CHNuFs5ybBNHw0VnECzDFAJuCJv/wuQEIsqKAJsbkYUMOWAKu1HtboAkd3UxnlpGHzcjWtSi5eK34oRrKw5ZXFTitgBuzMr2rWVAo4yfko8WijcX78poofn7doB80dd7tbU+eXM7ct0Uh/jhbhfy1pk+wuSTXgtxAQm1wCN+i3xJDjzc3BJysSsc37nuYAW+82TUgooNCa4CBqxg2qsw/2DP5XT+cMEtwjoExtIydz2u5Xu5OCCXKxbG7i0sNNjzqcrLh14xmOmRRWkWscRZi42NEQR9ZdhgqeVJLL/uax/cdVK03o3iZJCd5UzsRPxj2pbcmjXTL9DXZd8E7Kgf8GZfoUJh812Ad4ZEdDz36fn75yNEF6aNMl0zzQauEiLURk7PNNqLRWtDbPEHZKwJuWz6YRtFk9mW/CgZEUS46WU2fxpimp63dbGUOUOoML/kih+d/wYDRbbRk6xpwLgc+WaJ2qxy0KxM8IdOD+HPeH0zB1VKZQotk/NPSMUa7fAajvTPJeIjfdyK5U+vj6GFUTmrImqM0LE9UAf7kZ2iKCdImBvv+dkFZl3Kh6ZMH614YpLL++1P1mD7E4zK6odDGw5gcK9JiOIjPniu5b5JlukVgOH+u3GzdsEbHfDkb5tMJhPEnaoYxqmM+Z2TyfmohWJOMMML13QPz1HET6oH6PKF/A1mQUWaxg8FDycYpUH7KNixC3kwPLSKumM11Qj+O2RQOtBt2+06N3UdPDngLFTlVeidg5m1G3r7zpX5MzV9/NRLJdv8bnuj8IYIYFFtmORExxIh+QoF11doLsHuXobGTFWJn/Sg8T8rW7dJzHKTF43zt4c6slY+Fyj9VqICRAuax7AKG4zL2fxSXU6jzOhTdzLcnMXXUmKjJqs1l6uR6V61jMsI/W67XPwsZSxhnupocRJI3+eV4YrH4NB1uY2GE+frR4XzUbm4WhmXSLWat+VensTgh3RWCe5SGo28U7jaUSdFJHC0eqMPMsFz+ExyI0ghOiE4ulSiVfurjnQb8OeYOCnZh4lYGK+XSGhqgVXcQItlymIvb/BZp49XJDsOdnX5FtCEilMjCFZ50e0ZIcBH2bDyvavyVjojgAYjnVEnSuk/Z5QxOX2bW3uYKlKvaSiiO/J1lj9mQZXPHMWqCpd6kS8krmFx9uywoFur2zuwuWqOJi06ortvqLFf3Z3vYVwcXZbXHH8A2+ujRBBdpA8+yUR4oPnoN0caebVZgJRwfrkicncdBZKDVQYSgjsj3Tryq4vQpsuhgV25TZO1dLdTgst6zxJKjnSx9jP+xcfYSJwnZqORaJtg97S07v/MzkF+EiuEziGFHPXbCF+bo42yUH5YIq5nGExebk+RKmY0xySO/84d4lxf6/+l3JV7/sKdqtUANT66/2cj+xW/UREP5IgIXzxR4Qos3v6kgSz1wUPAZq7ls1mI7dDfuZJHS3jhQhIU8rjO/6PWg5ntjoQ1fxaqOfH/+kacjyCBNXfzJJWC7/O6CLAIptFzgyvk3lnj1ncpne3HxqgO7ML4218Of2L0DMkLXVm4ftksHtXxXn+qSllYceQqVxgEh2wpgNbnoMhaGXLJzbrHcY1PgbxldMN7IFx2Dl57rQ/Kp9DhyNEyaxDM7EtNsJPN5ZREDwYA1GZVd53C+SVbWgUrE5pIeocezoTjaIQcPSjWBvzDwd0TO6X38HCItUopI/L0uqgu0Q6yuqKkAZUFUvYOftbU1epCxgqhMY8RPfaH7Jb630Wlg0gxp1VZvkHhtBxK8xP1HU5ufg3xXnUm221qTi7Uk/hoW97u10xAt4lj1UPMcmyWdPmwdD7HIaWQnk81Gyg9NTeEDGz4K5ymn4iOAyyjrjD1G8r0+onSOPzL2tF24oK6jHX/Uj/fWBvWTki/aBZBlAP3R2M+ihu3J6q5Ivw1pTC/X6nLeX1rMoUY3mB8Ajw/9Dx4tVNHyexxfV0uxKhQbiP4bgyN6wSEi5FMfSE9tq6yly19gTBiBnEZa8XEM3zDeLDinweU8dCcgjYBn2XcAynVbmGyeoU+74fV9M7iMN6WaQVByUg4jakCRxo2osrXxOmxfan4o94WDcG+yXET8hgwBHZKJpNOLuZEdqKZqsKIjZ1HN2rG9AYGwHq1GQL4fpvsQV9dfrSNNRY3d8r2JmbxNjEy7hcPMpeQdsWR7WkgRSl8U8LoJFujkFt3UV6GkINfKUovPXyhqr/s9Z/t+i5I6HiB3YFlDbL35I8Qn3K+R1gFRyZ5kQllhS7qiWWvdm+eTMmpZStturzfy6DVesZGDTcHcaRgwibf6OqIaPpk4uJtuk6HKODNJ2U1S3bUBwxctN6W4XdPCcp1dyYQg+T5GtQXLWPjtaZ9gs2U3/XOMwFP1A5curwuCVMN3VzAx746Fi3godyeIBG/PoHeB3jqB5tYrk8J+3T/mgZRkX9TEsTS0ouas/gYpnrkdZDVKgCDHLxCdj5RNUsCL9x+JiYdYgIrfgAZO4f0CTPsE2WYgQ48a8klg+zrCFpDJ2vO/G7uQDBXKjYzR9GxAu1ZOr+ujqLpDa3Tf7mt5b4uBBe/mxdhIuWJ4g3zJHQ3R7W+A5XkVn4oLp8FO4ah8aH3K2bjL2TgUiALqfNlZ32wEClrjFt4cIxNU3qOzk0UYv+LpdfhVwFhBAoc1xIb4giy8jCqBk8+gIn1a0qeFTy8ngHx1ryyKZC2n9mUzZJWTs1AOuTXXgtEwZVeIVuKRWQAZlyV78+Hs/+X3aBQ7xppEp5L82jRkOOQ5BUjlSAa9aTJtKYxodko1GexmqWib1MaG8RXmMyv+c6AUydtg+JWnWkIIGbWf8CUEg+PkV7Erif1YxQAsB2wC91OjEzMhxsJu1lh9rIwLcF7Irw57f7SiBc4BzCglsIZZ+L8cDZ4lrMubntt3vObSLGB63kT9wh15ANFmaAz7Kb/vD7wfU5OqtxY1wmn6qn0FLRvZKOTjUreYw9dhj+HRIFhWtQqxfN9OLT4zn1zU2Ha+UwYCh6DbfaJBvHbRoqkQ5L0JCLSoMrRJHiHMpaQnzHa3wWOb+aQqtXdSJl3i/W2mDT0Kl7PL42Mg7k8mIC37O4S/9QQ87HRfVLjptCGD8In6xQUxmuKBGSS69i2tpCefuCi/YhRYzkN3teImjHrVcSC/NfhcBDImFmbB/TbEt/VUpoKnI3R/UjuoEwTaR+6+X4AP8dZCszhe8JunSeztcgGEobC/PrxFtfWv8AQSAyFlspoqqdWsfe3jwYVMhv1ApVYBZzYvoZalY0hJbVALJnA/bp/wnXZ7ZJtyTWh2QA6Fi/y8fj7bYuLADUiWLSw0lFCsikmibY5sMTz9+iGgy9nuaggNCTHCa09m0D9ZHqC4eVmnHY5Zp6BH+eNtNNsUF4VdW+YWXHya13JsymTyCZ1fwh+EGDnUqtdvLXVVPKc+Lk1PkObU4huhClsZJ/SS1fUP2NlCM/XFFi8PJGpkBxfJMYnCNUe6//RA06IgIySjpk1a1WIHurXP0Zor/GZaxdrbOS4A+Ij1BtAbizXCj4H0/vqEGyaXjadj4DYURjgKRyxWnB0aI3bXVrXGdCitk0vPVxXm91VOOXKHbdThdu2D/VNKOX6Dh0d3Jp3RNb9Zz1LnYfzNJKplvUD+Mbxv6xVvkOBNEn8jg6UCI/SyCFZRN4qF2k+uHsuuip641IfH4n9L0WO9yRqSCzL62W/L9CL5jGbn2s7jT3kX40dD1MC7Cav3MhQworKACKlh2l0EtZVoa7VqsOwRTMLPPx7kW9XiqVP5jQdGkvdL+qoJMeNHFji+JjVVWza3z4o69bRBPDAGwVCj0j1eQeFeccTP5aXspy18gi0oIC6FfGbw64VvHu1AvaVYy5thsdmhGLbqvrjvOJbmH0Gf9AwLSmEyQB4v7tr5sYyzNXSfxrhgcrXaVHwzv190n7rXWckWnNc4NErYQ2Idvjn9X3h0KUtuuVyO6f2UVBnMrIDSBbt3vI5Aw89k40kMhyK79JgvoAFoGsKjNIGylvm7W/LdUdiWrHngJm0dWSJqE13TkAsCubumqa0iw2QUFhOgmJlo64+lryLHOk+jGLGF7VkXmDTmcZDS+7bjOBqkSKjAMdg8600l3J7MHlIhnTtuux8fq8xwM6m38gVLL49M5ZOvlch5B0wT9H5PwVIweau22BCF004yRXx7oEfFv06sQfX2O2ogIE7WI0+vRCzGgYczaJ00d6eYk8J9G9PzITG9pKpag1E4ZpL688WRQGgWzu1xxQyVVcRmjdtiBBxz2v/MsoT7OmFOkhv7ugjId3uCVWXXHRU3YRq7ENHCbBd81BWxOKwLdFM8ukGjYRaPBH+x9umOe/NmdiMqMZ24EjG+90gkM4iX1cvn+JjvQcIUXwXObba2IScpv8l7TLWiY9CWstCOJtR0fK3nApskvESmrO7bidRH9LZJspTcpG+29XQKnxcnvAzkf8nrrv2Pn5MHKQ+PFUG8fxHu1IyaTSngLKCkg79bc7BRn0XuyJCC63DRbx6Bt1yWloLKtOO/j6PtnvYHo98ClyQmZvnNfuGas9wOeq7mgaZUS0gPGjzHp5MMoCZBwwbmhjXt5Jc5t0Z5YlSLKxsXVSVhvEtKPQmBfxoF67SbfqgAcP5yLwfK8GGqyDK+9o8St3FiEK/7lZTk/QRhD3ZR4x8mKLBC9NduBPc6Pls0CpLzv88z7C1p0sazOmWGrrR4WkU6saWzJBYbqdh9mCa69bh/tY3hRbQbdMoZLXqVhy7jANBTbsXclQCRKvnS8T002lMrnAz8w2ooDk6+RiC4IfrcvXDeYtMGsKB2Ct5DTi7X1fY84lOD/wQkvHSNzRmVqHPb2lA+bE2CjyY4Ntk2MHdcSGF4Jdllz7sgusD7mutlKpSXbdx//md3l0pr++FCxkR7ORWRXteJhU3Skc7PnKRCEheIKtHHbrTVMVl8Hz+yW0wrgIBfwCNp++poitrjZGZBZc+bdYMVW73PUixcrwz20fFBtj92v/cWzTDvPi+wH+XBeNfKElntxG4NyztwDjmxBnobWKkCmMpFp4EfRqL+TZ27XpPFuAtgj543BcRAgIEwKB/Cr7axrA6nJz6HfgayuOygBjapead+IYh+dK8UGqwQ/Xd/q1hkWc5M+GzVpMOnJYeaZMJLHF+KMgbBTeFUCjDH4Yj/eoXg3iLdm5HWZDwLkfBcbdqB+7mm8Y7kAZZ0zWQCyM+lwTfT6hgvA4f71sTY7CfQhCBE1T7UU3uEnRsqtqJsMLuS1dX4HfYQ22wzG16HtyvxfA2Q8qZHhJNRmJtBZRI3WRSwtX/oeVhmKqxo/6u9+x2GTX3kGyyneYl8ZT2nDlhu+5rL1uDDcAIS+pqn1pGdL3y76OgGWVeml9dUJluJRJ8T4A0v9i0FT3UvK+tmXMnpVxOxK8W3EbX1GCDnSPvtEHBvkUqy1WTiucRDwLtCo/saXLQz85GO77q1X+cmV9G292YVX5vQqhF9H4P5i0jBHwCxMRF3MP6ULHXLoUADM+da+fMZ+61JGRRy4GFiD8GjLTtIbzKZmVFtaby6rXcPXqCHEgiNjd9FEq03sjPVHrSGglNA6hgJwsHvdnysnCfxImtpHmXLBUV/6Im58ii23jgp/q/NQ1SGb8axaQdVGxlgFSPJgqSyHvl31KvywksgsV348Y1OhoiSpbmMU5iQMWEAh2oVPzgnDQHmpLyS4uFoOmstmI3BkZzBn/n3p680a3Ox7xNFh1HmOsYEsDLmOITsKV/9OpK+wv7YkVOlCMU756tb2w5mbeTr8Y3aIZEVJO1P/+7KNF97VJyv52hPHdRBzsxr4lhC/cI56MqZf5H2RMB5NRpGMFPxZzs7GjAbMpJ3paBWiEyoLhcHtrKipKhKeX6TBQQ9UH/eE0cjcSA9iJvEQ75EiCg3kzQlBv9Rv44RmlW8IQXwKJubAeGNhKb/GQmTJrUebAgpx/NX/3v4h56HUMX4uVCq0/x25PdjumF82wyJDUWEtMS3uIQbw6w139sULh/3TbKajQX0lueI85GjvDnXVSg519mwZSk59ULnPtrWh/KSHOlncVlomiWZNp45DI7O21Z79Hjr88NCvaQtlyjdAiGMbHyvzD604tVc4L41naldw1ZgXysgu492vC7jClE0B0Hxc4U3petVx/xrEuVgogRJyJrM3swN1DsZiwWYtHJFqNW8uZf8AD/y1ok6jxWpQSUA2zVYkyqEXEqcde+bBnmoHP6oVwLfcyztEXLwjLe9yL4qSnieUtGZXDcVe/4Q3IJiP7Adk/yhjgrPJ7BXK/hcPxSmX9y8OzC/qDlVdAnpZ6GVFz0NnEHo7UoIUXTQV6mYFUUJ7p38MDke1dXFzQBj+of7MnmjGjAnyVjaQcy3rfbgs96iO+IpJGDxmRTvXjN9xjqQyS4Re1Z6uqXD6sCNOampuImoigzRoNnf/Gf4/SciBr4Yypa4Z2A1P1ZpYGfV2RokHsYxaA5BrvOMMVr8bcntbhhULlC1qoDyzKedF+T3ckrXEAEgghFBnHpjlLIUh+8/4DOffarFRd+HGpI2ZW8e4rvo6ngJ+0RKrQIOJZdhSD2J4p5g2cIttB74OXMzJopBkrf2s02CwRpTDOdCHxIEeu6dHYRFTtOi1nj81OLrtMjPlwzYx0xclEQ69ouuSjNEmDcNldEFt7uiFKaIO5qsmocMs4L0h9GHXCGJaXi19WacL+rVWRwdT9juo+NXJmvWj6Zrnnk1R06CtOmqeuuC2v0pntNWmUMnoRHJdKVUJ1INX0t1yTpSJLs8oD+19fDusVt7C5iIOetlM7GcagnMfXiU1kXJvMsZnwHeNQQ2P/s40dfxMKrUwWnbYRIPQCVQrfloRY5EeptGWvc9PwLbU90avSOZNQjvz3XaEiuVOZq7o17QNPwuWEFMRbAy3VA+P0xWypGwcPXxJlFCl5eLbBe4g328FEisqPMckG60yIAp6KrmX4Taj4r4shvO9lUWSemTNTwJ/vDykBE9CaTQWj9UhMXTEXDPx8/2PGt4gT2/tlotgqPlyhoowMGzpBD65gEcS7MZyhgvO4XwRk9Fq+Pf5k4iTC1jvgDx9bNRVtjdMBzWZEsZNrxc1+hRm1q0ALb9e8pC51Vz5lP01ODU62NAkax4OzB84/lsU4rDXkv/CPmlMuIqxyPQ7FbVV4trvJ98wwvMvxAT5uzjhcSTUHGG13QGUSfPbKGMJddrJ1OM5PogdlsKLFFCSg5dEBZ6SANgXtwlPrxVMf5w2ODXWrZBghQRD55bQJHtxLBdtCEZsNiF0hpzm604sVfmqQ6eX4R5+Yu+F8i4+TdXbSjeByMxqetya4X5qH1+doXJGdfobZswiH1hiTG1GNAM02Lr/7BcyZ8XXxmH54ZTjS/vA2ftMwskpwV9oS4yfK5gNMcMrCS+tzISBV/ijcRcicSOzq66Nv22SV47j/nXGNu1OFEL1X5LTkL8kh2iFj0DE9WhUQwBueZjQ4chGKCELk5uSHDSnWFPFWwlppp/+VYZI7fnyEH8JMLWafbFlAXil1QhTemFRoWGoTbWmVGQGsOmlHD/7do0l+Bgej5YjXSeT1+iUNEGkzdsFY7TlwJRohsV9RXFILh4zHOhhaOh1E4Vv1ACIBD090XYD/mtMDeeUAaMgVbCMZ4DTcW5meVfVmqzF9A+fB93hHAuGPXX5UN9ZOAyvznQHmFgKQYESBNp0CulF/LuE/3OND8d+hKoo7zOG9jDKpoyq2BOdwKufaZYLph+TAbp/J3rSpRyxN+RA7xf0jqSINEq+88ZygTh/MaiIg8lY+xX2ZON6QP2jI4oJjeiza2ePp4Xu8IWl/h2GB85ij//m3utbCwPytdifj0PDonSbb7IEM8dxIUl+b9MGmN926/RYIYutpo8ikZm3bQRBf0vHhv57cAaU3PzgU5cFf6e4ZutXgqr4IvI8E4ghUNaDzaomBezh7kov2pJmrxvBVW06BiOFchETeJiXBQ6Dxj5/hvKCWgCDaSxf7FRDo4HQQymmzf1/lC/EuOsk04KdqvnnyN3CyJu3wAyUqT6qr+EbRTk=]]></content>
      <tags>
        <tag>dialog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前缀树🌲:trie]]></title>
    <url>%2F2019%2F07%2F17%2F%E5%89%8D%E7%BC%80%E6%A0%91%F0%9F%8C%B2-trie%2F</url>
    <content type="text"><![CDATA[前缀树是一种存储数据的树形结构。是一种高效的检索字符串的方法，是一种多叉树的结构。它的插入与删除的效率比较高，时间复杂度为O(m). 前缀树前缀树的结构如下图所示： 前缀树的结构特点为： 根节点不包含字符，除根结点外，其他节点只包含一个字符 从根节点出发叶子结点，组成一个完整的字符串 每个节点包含的字符均不相同 前缀树的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Trie(object): def __init__(self): """ Initialize your data structure here. """ self.res = &#123;&#125; def insert(self, word): """ Inserts a word into the trie. :type word: str :rtype: None """ a = self.res for i in word: if i not in a: a[i] = &#123;&#125; a = a[i] a['end'] = &#123;&#125; def search(self, word): """ Returns if the word is in the trie. :type word: str :rtype: bool """ a = self.res for i in word: if i not in a: return False a = a[i] if 'end' in a: return True else: return False def startsWith(self, prefix): """ Returns if there is any word in the trie that starts with the given prefix. :type prefix: str :rtype: bool """ a = self.res for i in prefix: if i not in a: return False a = a[i] return True # Your Trie object will be instantiated and called as such:# obj = Trie()# obj.insert(word)# param_2 = obj.search(word)# param_3 = obj.startsWith(prefix) 上面代码用dict代替书的结构，一级一级的向下延展，前缀树由根节点往下，每一个节点的字节点就是他的key的数目，选择其中一个key，然后一级一级往下，当一个单词结束的时候，填入end作为终结符。]]></content>
      <tags>
        <tag>— leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xigua:决策树]]></title>
    <url>%2F2019%2F07%2F14%2Fxigua-%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[决策树是一类常见的机器学习算法，决策过程是基于树的结构进行的。叶子结点对应了树的决策结果，子节点对应了属性的测试（例如西瓜的颜色）。决策树的最终目的是产生一棵泛化能力强的树。 决策树基本知识决策树子节点的生成决策树的生成方式是一个递归的过程，有根结点开始，生成子节点的情况有下面三种： 当前节点包含的样本全属于一个类别，无需划分 当前节点上所有样本的属性为空（例如缺失了身高这个数据），因此设置节点时，将该节点设置成样本中类别比例最大的那个。 当前节点所包含的样本集合为空时，采用样本的先验概率（例如身高为170的样本最多）来设置样本类 信息熵熵： entropy，希腊语原意为 内向性，即一个系统不受外部干扰时，往内部最稳定状态发展的特性。 熵同时可以作为一个系统的混乱程度的度量，即根据热力学第二定律，一个系统倾向于向增加混乱的程度发展，例如抛一枚硬币，最终的统计结果是正反面都是0.5的概率，对于预测来说，预测正面或者反面的不确定性都是最大的。 信息熵： 信息熵是指接受数据中包含的信息量的平均值，是一种不确定性的度量，越随机的信源，熵越大。熵定义为概率分布的对数的相反数。也即是说，当一个事件发生的可能性越小，当这个事件出现的时候，提供的信息就越多，不确定性越大，熵就越大。$$\mathrm{H}(X)=\mathrm{E}[\mathrm{I}(X)]=\mathrm{E}[-\ln (\mathrm{P}(X))]$$当数据取自有限样本是：$$\mathrm{H}(X)=\sum_{i} \mathrm{P}\left(x_{i}\right) \mathrm{I}\left(x_{i}\right)=-\sum_{i} \mathrm{P}\left(x_{i}\right) \log _{2} \mathrm{P}\left(x_{i}\right)$$信息增益： 信息增益指期望信息的有效减少量。例如决策树，在一个分支上，选择一个属性进行划分，得到的信息增益越大证明划分结果不确定性越小，纯度越高。$$\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} E n t\left(D^{v}\right)$$然而信息增益趋向于选择分类更加细致的属性（分类越多，每一类的纯度也会越大），为了克服这个毛病，引入了信息增益率：$$g_{R}(D, A)=\frac{g(D, A)}{H_{A}(D)}$$其中：$$H_{A}(D)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|}$$信息增益率趋向于选择分类少的属性。（分类多，分母大） 基尼指数： 基尼指数比较直观，他反映了连续抽取两个样本，他们不一样的概率。因此越小表明纯度越纯。$$\operatorname{Gini}(\mathrm{p})=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}$$决策树缺失属性的处理情况： 当属性缺失的情况下，选择最优的属性划分：可以修改信息增益函数，加上无缺失样本所占比例，无缺失样本中第k类所占比例，以及无缺失样本中某个属性所占比例等修正，得到划分的标准 当选定划分属性时，该属性缺失：将这些样本按照不同的概率，加入到所有的分支中]]></content>
      <categories>
        <category>xigua</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[xigua:线性模型(linear model)]]></title>
    <url>%2F2019%2F07%2F14%2Fxigua-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-linear-model%2F</url>
    <content type="text"><![CDATA[线性模型形式简单，易于建模，具有很好的解释性质。 基本概念线性模型试图学到一个通过属性的线性组合来进行预测的函数，线性模型将要学到下面的一个函数形式：$$f(x) = \omega^T x + b$$简单的来说，即通过训练数据 (x,y) 来学的线性模型的$\omega$ 和b，即可确定模型。 线性模型 pytorch实现在实现一个线性模型之前，我们首先确定一下算法实现的pipeline。 数据准备：训练数据，label，以及测试数据的格式与读取形式。 模型的建立：模型类继承torch.nn.Module，实现其中的__init__(),forward()函数。 确定网络的criterion以及optimizer。 训练过程：每过一个step进行参数的更新。 数据准备部分在这个例子中，我们使用较为简单的数据作为输入： 1234import torchfrom torch.autograd import Variablex_data = Variable(torch.Tensor([[1.0],[2.0],[3.0]]))y_data = Variable(torch.Tensor([[2.0],[4.0],[6.0]])) Vari3able 变量于Tensor的区别在于variable变量是可以计算梯度的，在梯度反向传播的时候进行梯度的计算。 模型的建立pytorch中模型类均需要继承一个父函数：torch.nn.Module. torch.nn.module 是所有网络的基类，我们定义的网络类，都需要继承自这个类。torch.nn这个类中包含各种网络层结构，linear，conv等等。对于我们的线性模型来说，我们可以定义一个网络类，然后在init中定义linear。 1234567891011121314151617class LinearRegressionModel(torch.nn.Module): """ 定义自己的网络需要继承torch.nn.Module类，实现其中的init以及forward方法: torch.nn.Module: torch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络 nn.Module是nn中十分重要的类,包含网络各层的定义及forward方法。 一般把网络中具有可学习参数的层放在构造函数__init__()中 """ def __init__(self): super(LinearRegressionModel,self).__init__() """ 线性模型：torch.nn.Linear(in_features,out_features,bias=True) """ self.linear = torch.nn.Linear(1,1) # one in one out def forward(self,x): y_pred = self.linear(x) return y_pred criterion and optimizerCriterion 即为网络训练过程中，输出的预测值与groundTruth之间的差距，通常在二分类问题上可以使用MSE loss，crossentropy等等。如torch.nn.MSELoss() Optimizer 可以使用torch.optim.SGD(linear_model.parameters(),lr = 0.01)。 train网络训练过程中，设置训练的次数，首先将数据传如入网络中，然后使用criterion求出输出与groundtruth之间的偏差。在每一次参数更新时，首先将梯度置零，然后进行梯度的向后传播。 1234567for epoch in range(500): pre = linear_model(x_data) loss = criterion(pre,label) # 清空参数 optimizer.zero_grad() loss.backgrad() # 参数向后传播 optimzer.step() evaluate网络测试部分比较简单，将输入输入网络中，得到其输出。 12result = linear_model(new_var)print('result &#123;&#125;'.format(result.data[0]))]]></content>
      <categories>
        <category>xigua</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Something about keras]]></title>
    <url>%2F2019%2F05%2F24%2FSomething-about-keras%2F</url>
    <content type="text"><![CDATA[PART I : keras progress prepare data,process data create model,loss,optimizer feed data to model,set hyperparamers add some callbacks method train and save model,save the log there is a example go through the process PART II: data prepare 生成数据部分，数据基本上是存储为coco，或csv格式。将数据从硬盘中读入内存。然后构造一个生成器，目的在于批量的（batch size大小）读出数据，预处理数据。生成器简单的使用如下： 12345def generate_func(): for i in range(10): yield ifor item in generate_func(): print(item) 另一种做法是实现类的__next__()方法，每次调用一次该类，即间接调用该方法。 1234567class generate(object): def __init__(self): pass def __next__(self): ... data processing return batch_size data 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import numpy as npimport mathfrom keras.models import Sequentialfrom keras import layers# some layer in layers Dense,Dropout,Activation,Flatten# cnn layerfrom keras.layers import Convolution2D,MaxPooling2Dfrom keras.utils import np_utils # useful to transfrom datafrom keras.datasets import mnistfrom keras.callbacks import ModelCheckpoint # save modelfrom keras import callbacksfrom keras.models import load_model# prepare data(x_train,y_train),(x_test,y_test) = mnist.load_data()print(x_train.shape)#from matplotlib import pyplot as plt#plt.imshow(x_train[0])# tensorflow input(HxWxC)x_train = x_train.reshape(x_train.shape[0],28,28,1)x_test = x_test.reshape(x_test.shape[0],28,28,1)x_train = x_train.astype('float32') /255x_test = x_test.astype('float32') /255print(x_train.shape)print(y_train.shape)# convert label to one hotprint(y_train[:10])y_train = np_utils.to_categorical(y_train,10)y_test = np_utils.to_categorical(y_test,10)print(y_train[:10])### define modelmodel = Sequential()# 32,3,3 : output channel ,kernel_sizemodel.add(Convolution2D(32,3,3,activation = 'relu',input_shape=(28,28,1)))print(model.output_shape)model.add(Convolution2D(32,3,3,activation='relu'))model.add(MaxPooling2D(pool_size = (2,2)))model.add(layers.Dropout(0.25))model.add(layers.Flatten())model.add(layers.Dense(128,activation='relu'))model.add(layers.Dropout(0.5))model.add(layers.Dense(10,activation='sigmoid'))### define loss and optimizer,and then compile itmodel.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])print(model.summary())#print(model.get_config())# callback，when a epoch/batch_size start/end,it will be calledcheckpointer = ModelCheckpoint(filepath='best_model.h5',verbose=1,save_best_only=True)earlyStopping = callbacks.EarlyStopping(monitor='loss',patience=20,verbose=1,mode = 'auto')reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss',factor = 1/math.e,verbose=1,patience=10,min_lr=0.0001)tensorboard = callbacks.TensorBoard(log_dir='./log')# write log to csvcsv_historyger = callbacks.CSVLogger('training.history',separator=',',append='True')### feed data to the network#print('exist model')#del model#print('loading model ...')#model = load_model('./best_model.h5')history = model.fit(x_train,y_train,batch_size=32,epochs=2,verbose=1,validation_data=(x_test,y_test),callbacks = [checkpointer,earlyStopping,reduce_lr,tensorboard,csv_historyger])score = model.evaluate(x_test,y_test,verbose=0)print(score)print(history.history)print(history.epoch)print(history.history['val_loss']) 数据读取部分主要读取csv文件的image name，以及annotation。]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RetinaNet 原理记录]]></title>
    <url>%2F2019%2F05%2F16%2FRetinaNet-%E5%8E%9F%E7%90%86%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[RetinaNet作为一个one stage 的检测算法，通过对图片进行网格划分。在每个feature上选取anchor，然后对这些anchor进行边框回归以及类别的回归。 RetinaNet和大多数的one stage算法相同，直接对图片进行边框的回归，这导致了在一开始回归的时候，算法产生了大量的anticipate anchor（two stage 算法产生anchor的方式是通过region proposal的方式产生1k～2k的边框），这些anchor大部分都不包含object，即作者提到的easy negativate。 因此anchor导致了正负样本的不均衡。 正负样本不均衡主要有以下两个问题： 在网络进行训练时，一些easy negativate 样本对loss不起作用，网络收敛速度很慢。 由于存在大量的easy negativate 样本，因此在loss回归的过程，easy negativate样本将会覆盖掉真正有益的收敛方向，导致模型精度下降。 基于上面的分析，作者提出了一种对新型的loss，这种loss能够对不同的easy，hard样本进行权重的赋值。使得loss更加倾向于学习一些hard样本。 Focal Lossfocal loss 由标准的cross entropy loss 演化而来，为了简单期间，我们从二分类的cross entropy入手，开始介绍： 从上面的loss可以看出来，当一个样本为正样本时，其预测值越高，CE loss就越小。但是这个loss对所有的anchor都同等对待，当一些样本p很大或很小的时候，基本可以断定它的类别，这些样本对边框回归，类别分类的时候，起到很小的作用，因此需要被忽略，但是CE loss无法突出这一点，因此RetinaNet的focal loss就是为了解决这个问题提出来的。 当p很大时，即可以轻松判断这个anchor的类别的时候，1-p将取得一个较小的值，通过前面的参数，可以大大减小其对loss的影响。即降低了对简单样本的权重，同样的，对于难分样本来说，loss的形式可以增加其在loss中的权重。 RetinaNetRetinaNet是作者为了验证这个loss的有效性而提出的。RetinaNet主要由一个resnet作为backbone，分类部分使用了FPN，特征金字塔的形式进行特征的分类。它的网络结构如下如所示： 事实上，RetinaNet最终输出了五层feature map，在这五层feature map进行anchor的选取。 首先由Resnet 最后的三层C3，C4，C5产生P3，P4，P5，然后在C5的后面接着生成了P6，P7。 由于不方便画图，放一下keras retinanet的代码：github 12345678910111213141516171819202122232425262728293031323334def __create_pyramid_features(C3, C4, C5, feature_size=256): """ Creates the FPN layers on top of the backbone features. Args C3 : Feature stage C3 from the backbone. C4 : Feature stage C4 from the backbone. C5 : Feature stage C5 from the backbone. feature_size : The feature size to use for the resulting feature levels. Returns A list of feature levels [P3, P4, P5, P6, P7]. """ # upsample C5 to get P5 from the FPN paper P5 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C5_reduced')(C5) P5_upsampled = layers.UpsampleLike(name='P5_upsampled')([P5, C4]) P5 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P5')(P5) # add P5 elementwise to C4 P4 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C4_reduced')(C4) P4 = keras.layers.Add(name='P4_merged')([P5_upsampled, P4]) P4_upsampled = layers.UpsampleLike(name='P4_upsampled')([P4, C3]) P4 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P4')(P4) # add P4 elementwise to C3 P3 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C3_reduced')(C3) P3 = keras.layers.Add(name='P3_merged')([P4_upsampled, P3]) P3 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P3')(P3) # "P6 is obtained via a 3x3 stride-2 conv on C5" P6 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P6')(C5) # "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6" P7 = keras.layers.Activation('relu', name='C6_relu')(P6) P7 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P7')(P7) return [P3, P4, P5, P6, P7] anchor的设置在设置anchor的时候，作者选用了一下几种设置： anchor-size = [32, 64, 128, 256, 512] 对应P3～P7 anchor—scale = [2 xx0 ，2 xx(1/3 )，2 xx (2/3)] anchor-wh = [1:2 ，1 ，2:1] 每一层anchor的大小为anchor-size 乘以 anchor-scale。然后使用三种长宽比，每一层，每一个位置得到九种大小的anchor。随后对这些位置的anchor进行边框回归以及类别的回归。 Loss 的形式以及计算稍后补充]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pytorch 张量操作]]></title>
    <url>%2F2019%2F05%2F12%2Fpytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[在编写网络，传入传出数据时，对数据的维度的操作，把握是很重要的，因此这篇文章介绍一下pytorch在数据维度的改变上的一些方法。 对于两个数组来说，融合方式有很多种，最常见的是沿着横向融合以及沿着纵向融合。在方法的参数体现上： dim = 0 ：数据沿着纵向融合。 dim = 1： 数据沿着横向融合。 torch.cat() torch.cat 方法对数据沿着不同方向进行如何，dim参数决定了融合的方向，需要注意的是需要融合方向上维度需要一致： 1234567891011121314&gt;&gt;&gt; atensor([[1., 1., 1.], [2., 2., 2.]])&gt;&gt;&gt; btensor([[3., 3., 3.], [4., 4., 4.]])&gt;&gt;&gt; torch.cat((a,b),0) # 纵向tensor([[1., 1., 1.], [2., 2., 2.], [3., 3., 3.], [4., 4., 4.]])&gt;&gt;&gt; torch.cat((a,b),1) # 横向tensor([[1., 1., 1., 3., 3., 3.], [2., 2., 2., 4., 4., 4.]]) torch.view() torch.view 在保证数组个数不变的前提下，任意改变数组的形状（需要注意的是 -1参数表明在满足其他维度大小的需求后，该维度的大小）： 12345678910111213141516&gt;&gt;&gt; atensor([[1., 1., 1.], [2., 2., 2.]])&gt;&gt;&gt; a.view(1,-1)tensor([[1., 1., 1., 2., 2., 2.]])&gt;&gt;&gt; a.view(3,-1)tensor([[1., 1.], [1., 2.], [2., 2.]])&gt;&gt;&gt; a.view(1,2,3)tensor([[[1., 1., 1.], [2., 2., 2.]]])&gt;&gt;&gt; a.view(2,1,3)tensor([[[1., 1., 1.]], [[2., 2., 2.]]]) torch.squeeze() 压缩维度，使得为1的维度塌陷，维度缩减方向为dim = 0纵向，dim=1横向： 1234567891011121314151617181920212223&gt;&gt;&gt; btensor([[[1., 1., 1.], [2., 2., 2.]]])&gt;&gt;&gt; b.shapetorch.Size([1, 2, 3])&gt;&gt;&gt; b = torch.squeeze(b,dim = 0)&gt;&gt;&gt; btensor([[1., 1., 1.], [2., 2., 2.]])&gt;&gt;&gt; b.shapetorch.Size([2, 3])&gt;&gt;&gt; b = a.view(1,2,3)&gt;&gt;&gt; btensor([[[1., 1., 1.], [2., 2., 2.]]])&gt;&gt;&gt; b.shapetorch.Size([1, 2, 3])&gt;&gt;&gt; b = torch.squeeze(b,dim = 0) #纵向&gt;&gt;&gt; btensor([[1., 1., 1.], [2., 2., 2.]])&gt;&gt;&gt; b.shapetorch.Size([2, 3]) torch.Tensor.narrow() 删除元素的维度缩减方式，torch.Tensor.narrow(dim,start,length),dim表示缩减的方向（0，1），start表示起始的位置，length表示保留维度的长度： 123456&gt;&gt;&gt; atensor([[1., 2., 3.], [4., 5., 5.]])&gt;&gt;&gt; a.narrow(1,1,2)tensor([[2., 3.], [5., 5.]]) torch.Tensor.permute() 张量维度之间的顺序调换： 1234567&gt;&gt;&gt; atensor([[1., 2., 3.], [4., 5., 5.]])&gt;&gt;&gt; a.permute(1,0)tensor([[1., 4.], [2., 5.], [3., 5.]])]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIT]]></title>
    <url>%2F2019%2F05%2F06%2FGIT%2F</url>
    <content type="text"><![CDATA[github本质上是一个存储代码的工具，如果你暂时没有这个需求的话，其实可以不用在意这个东西，但是如果你在开发一个项目，希望将代码存在云上，并且实时更新与本地一致，那么github以及git操作就显得很重要了。（以上全是废话，ps：第一次以对话的方式写博客有点🦢慌） 下面教程从github上创建一个repository开始，重复一下比较常用的重要的git步骤 👇 创建repository手动上github官网，可视化方式创建一个repository，并添加上REMEAD.md等。由于我正在做深度学习作业，因此下面都将以DL_HW repository为例。 git clonegit clone git@github.com:WenHui-Zhou/DL_HW.git 通过上面语句将项目clone到本地（前提是安装了git）。然后接下来所有操作都将在这个DL_HW文件夹下进行操作。 添加.gitignore.gitignore 文件是用来告诉git什么文件不需要上传，比如你写了一个深度学习的作业，其中用到的数据集图片，就可以不需要上传。例子如下： 123tmp # 忽略文件夹*.jpg # 忽略文件.DS_Store 关于.gitignore还有很多灵活的用法，但是我是二八原则的拥护者，留下个链接表示一下：gitignore 用法 add and commit本地的git维护着三棵树，第一个是工作目录，即本地的DL_HW。第二个是缓冲区index，临时保存改动，第三个是head，保存最后一次的提交结果。 git add * : 将所有修改添加到index中去，保存零时改动。比如刚刚写了一个.gitignore文件，这条指令把它添加到index 上。 git commit -m &quot;代码提交信息&quot;：将index中保存的改动提交到head上去。 git push前一步的操作仅仅是在本地进行的，并没有将代码真正的更新到GitHub上 git push origin master： 将head上的改动提交到master分支上，也可以换成其他分支。 分支老实说现在用不到，留着以后补充 some tip1.Git clone的时候会clone下来所有的历史内容，可以限制仅仅clone最近改动后的版本。 1git clone git@github.com:WenHui-Zhou/DL_HW.git --depth=1 2.当有多个机子clone了相同的项目，要保证本地的代码为最新的，需要如下操作： 1git pull origin master(分支可改) last分享一个很不错的 教程链接]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dog and cat -- USE tf.contrib.slim]]></title>
    <url>%2F2019%2F05%2F06%2Fdog-and-cat-USE-tf-contrib-slim%2F</url>
    <content type="text"><![CDATA[深度学习作业之一：猫狗分类。使用tensorflow的一个轻量级的库 tf.contrib.slim实现。 数据准备猫狗分类的数据可以从gaggle官网中下载：数据链接 解压后发现文件分为train和val，但并没有label，它的label通过文件名来区分。 将下载下来的猫狗图片转化为tfrecord格式tf.record: 二进制格式文件 To read data efficiently it can be helpful to serialize your data and store it in a set of files (100-200MB each) that can each be read linearly. This is especially true if the data is being streamed over a network. This can also be useful for caching any data-preprocessing. The TFRecord format is a simple format for storing a sequence of binary records. tensorflow使用其Dataset API来管理数据，将数据直接放在graph中进行处理，整体对数据集进行上述数据操作，使代码更加简洁。将图片，label转化为tf.record格式，方便大数据集的分批，快速读取，同时在进行数据预处理时简化代码，加快处理速度。 TFRecord 的核心内容在于内部有一系列的 Example ，Example 是 protocolbuf 协议下的消息体。定义了你需要的数据集的信息。 protocolbuf： protocolbuf是 Google出品的一种轻量 &amp; 高效的结构化数据存储格式，具体介绍可以看 这里 即通过将结构化的数据进行序列化(转为二进制)，更小更易于维护。 因此这一部分的目的就是将猫狗的数据，以及对应的label，重新生成为tf.record格式文件，随后使用tensorflow提供的API进行数据的读取。 ps: 123for i in range(10000): filename = "%05d.txt" % i open(filename, "w") 上面代码命名文件时，i长度不足10000时前面补0，保证长度为5。]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux配置环境]]></title>
    <url>%2F2019%2F04%2F24%2Flinux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[linux 环境配置是一个很重要又很烦人的过程，下面简要记录一下环境变量配置的方法与原则。 系统配置文件的加载顺序登入linux并启动一个bash shell，默认情况下这时候系统将会去寻找环境变量的设置文件，为环境变量赋值。系统环境文件读取顺序如下： 用户登录系统后首先会加载/etc/profile全局环境变量文件，这是Linux系统上默认的shell主环境变量文件。系统上每个用户登录后都会加载这个文件。 之后执行/etc/profile.d目录下的所有脚本文件，完成一些字体，颜色的设置 之后开始运行～/.bash_profile(用户环境变量文件)，在这个文件中，又会去找$~/.bashrc（用户环境变量文件） 。在$～/.bashrc文件中又会去找/etc/bashrc（全局环境变量文件），若没有则不执行。 对于Vim的配置来说，在vim开启的时候将会对其进行一些基础的配置。全局配置一般在/etc/vim/vimrc或者/etc/vimrc，对所有用户生效。用户个人的配置在~/.vimrc，打开vim时自动执行。 linux bash查找执行的顺序shell执行命令时将去linux系统中寻找指令的执行代码。寻找顺序如下 别名，使用alias创建的命令 关键字，如if，for 函数 内置指令，如cd等等 外部指令，在PATH路径中寻找 Linux 系统目录结构​ 以前很多的环境变量配置不明白，就是由于不清楚linux的目录结构，以及每个文件的位置。 /bin普通用户可以使用的命令的存放目录，十分重要。例如cp，cd这种。类似的目录：/usr/bin，/usr/local/bin等等。这个目录中的文件都是可执行的。作为基础系统所需要的最基础的命令就是放在这里。 /lib此目录下包含系统引导和在根用户执行命令时候所必需用到的共享库。类似的目录还/usr/lib，/usr/local/lib。 /home在Linux机器上，普通用户主目录通常直接或间接地置在此目录下。用户可以在自己的目录下保存仅对自己的配置文件，定制文件，文档，数据等。 /root用户root的$HOME目录。 /etc全局的配置文件存放目录。系统和程序一般都可以通过修改相应的配置文件，来进行配置。类似的目录有 /usr/etc。用户也可以直接在HOME目录底下写配置文件，系统读取配置文件时，先读取HOME目录底下的文件，优先级最高。如果不存在配置文件的话，才去/etc下读取系统配置。 /usr安装程序的时候，默认就是安装在此文件内部某个子文件夹内。输入命令后系统默认执行/usr/bin下的程序。当然/usr/bin 需要加入PATH中。 /usr/local安装本地程序的一般默认路径。当我们下载一个程序源代码，编译并且安装的时候，如果不特别指定安装的程序路径，那么默认会将程序相关的文件安装到这个目录的对应目录下。例如，安装的程序可执行文件被安装(安装实质就是复制到了/usr/local/bin下面），/usr/local/include则用来存放文件。 环境配置因此看到这里，环境变量的配置就是针对我们安装的第三方库，它们一般存在于/usr/下的目录中，因此PATH需要添加到/usr/的路径。此外还有一种情况，就是当安装一个库时，可能会修改掉系统的文件的软链接，导致之前系统很多库无法使用。此时的做法是在用户目录下，创建虚拟环境，在虚拟环境的进行环境的配置，将配置文件写在/home/.bashrc 等文件中即可。 上面泛泛而谈，还需要大量实践来查缺补漏。 例子安装python3.7，同时保留python3.6，python2.7等：【链接】]]></content>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 编程]]></title>
    <url>%2F2019%2F04%2F10%2Fshell-%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[shell 编程中常见，常用的语法。 在日常Linux上编写代码，整理文件时发现，学一点shell语句能够大大加快工作效率，事不宜迟，开始学习！ shell 简介shell脚本通常是以：#!/bin/bash 开头的一个文件。/bin/bash是bash编译器的路径。 bash命令序列通常使用分号 ; 或者换行符来表示。 终端的输出使用echo 来输出。下面是一个简单的shell脚本。 12#!/bin/bashecho hello world 变量shell中所有变量的类型都是字符串，且无需提前定义。此外shell中规定了一些环境变量来存储操作系统中一些特殊的值。 变量的赋值： val=“value” ，切记等号前后没有空格。val = value 这种形式是判断相等的操作。 输出变量：echo $val 或 echo ${val} 环境变量： 定义在系统父进程中，用于系统的设置，如HTTP_PROXY用与设置代理服务器。 export 命令可以用来设置环境变量，至此之后，shell脚本执行任何应用都会继承整个变量。 最常用接触到的环境变量为PATH，PATH变量通常包含以下： 12echo $PATH/home/zhouwenhui/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr /games PATH中路径根据 : 做为分割符，每当用户执行一条指令时，linux根据PATH中路径从前往后寻找可执行文件。PATH通常定义在 /etc/environment 或 /etc/profile 系统层次，或 ~/.bashrc 这种用户层次上。可以通过一下方式，增加寻找的路径： 1export PATH="$PATH:/new/folder" 补充trick： 1cat a.txt | tr 'replace' 'value' 将输出中的replace替换成value。 字符串长度： 12var=1234length=$&#123;#var&#125; UID 是用户类型的一个标示，root用户的UID是0. shell 数学计算let 语句可以直接执行基本的算术操作，在变量名前不需要添加$. 1234567#!/bin/bashno1=4;no2=5;let result=no1+no2let no1++;let no1--;let no1+=1 操作符[ ] 使用方法与let类似： 1result=[ $no1 + no2 ]; 上诉的指令只能用来进行整数操作，浮点数操作将使用到bc工具包： 123&gt;&gt; echo "4 * 0.56" | bc&gt;&gt; 2.24&gt;&gt;result='echo "$no1 * 1.5"|bc' 文件描述以及重定向将输出内容保存到temp.txt中： 1echo "this string will be save" &gt; temp.txt 追加内容： 1echo "add to the file temp" &gt;&gt; temp.txt 数组1arr=(1,2,3,4,5,6) 创建别名1alias new_command = 'command sequence' 直接写入配置文件： 1echo 'alias cmd="command seq"' &gt;&gt; ~/.bashrc 函数12345678910111213141516function fname()&#123; statements;&#125;# 调用fname; # 执行#传递参数fname arg1,arg2;fname()&#123; echo $1; # 第一个参数 echo $2; # 第二个参数 echo $@; # 所有参数，"$1" "$2" ...&#125; for 循环1234for var in list;do commanddone; while 循环1234while condition;do commanddone; util语句123456x=0;until [ $x -eq 9 ];do let x++; echo $x;done 逻辑运算，简短比较12[ condition ] &amp;&amp; action; # 若condition成立则执行action[ condition ] || action; # 若condition不成立，则执行action 比较与测试12345678if condition;then commands;else if condition; then; commands;else commands;fi 算术比较12[ $var -eq 0 ] # 判断是否相同[ $var -ne 0 ] # 当var非0时为真 -gt：大于 -lt：小于 -ge：大于或等于 -le：小于或等于 结合多个条件测试： 12[ $var1 -ne 0 -a $var2 -gt 2 ] # 使用逻辑与-a[ $var1 -ne 0 -o $var2 -gt 2 ] # 逻辑或 -o 文件属性测试123456[ -f $file_name ] file_name是一个正常的文件[ -x $var ] var 是可执行文件[ -d $var ] var是目录[ -e $var ] var是文件[ -w $var ] var为可写文件[ -r $var ] var为可读文件 字符串的比较12345678[[ $str1 = $str2 ]] # 字符串比较最好放在双中括号中，判断相等[[ $str1 &gt; $str2 ]] # 判断字符串大小[[ -z $str1 ]] # 字符串为空则为真[[ -n $str1 ]] # 字符串非空则为真if [[ -n $str1 ]] || [[ -z $str2 ]];then echo 'something'fi 执行Linux指令12345678910a=$(ls)for file in $a;do if [ -f $file ]; then echo 'afile' else echo 'not file' fidone cat 拼接1234cat file1 file2 file3cat -s file # 输出过滤掉多余的空行cat -T file # 显示制表符cat -n file # 显示行号 文件查找find12345678find base_path # 找出所有bash_path 底下的所有文件名find . -name 'car*' # 找含特定字符的文件find . \( -name "*.txt" -o -name "*.pdf" \) # 匹配多个find /home/ -path "*/slynux/*" # 匹配路径以及文件名find . ! -name '*.txt' # 不找txt结尾的find . -maxdepth 1 -name 'f*' # 深度为1，只找当前目录find . -type d #将所有目录输出来 f为普通文件，l为软链接find . -type f -name "*.swp" -delete # 删除匹配的文件 find选项-exec 与其他指令结合使用12find . -type f -name ".c" -exec &#123;&#125;\; #&#123;&#125;将匹配所有的文件，然后执行find . -type f -name ".jpg" -exec cp &#123;&#125; ./file/ \;# 拷贝 玩转 xargsxargs以标准的输入作为主要的数据流：command| xargs。xargs从stdin接收到的数据重新格式化，将其作为参数提供给其他指令。]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VOC 数据集]]></title>
    <url>%2F2019%2F04%2F09%2FVOC-%E6%95%B0%E6%8D%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[本篇文章介绍VOC数据集的格式以及将CSV标注转化成CSV格式文件的方法。 VOC 数据集VOC 数据集可以从官网下载，通常有 train： VOCtrainval_11-May-2012.tar，VOCtrainval_06-Nov-2007.tar test：VOCtest_06-Nov-2007.tar 解压后得到的文件目录结构如下： VOCDevkit: Annotations：存放着图片类别以及box信息,一张图片对应一个xml文件 ImageSets：里头有几个文件夹，目标检测问题只要关注Main，里头将保存训练集，测试集的图片名，用txt文件进行保存。 JPEGImages：保存着数据集图片 SegmentationClass SegmentationObject 对于目标检测问题关注以上三个文件夹就可以了。 将scv文件转化为voc格式csv格式为： 1image_url,x1,y1,x2,y2,label 且同一张图片由于可能会有多个框，所以会有多条记录，代码需要完成图片的软链接建立，图片的命名，并建立新名字的txt文件，包括train和text。同时生成每张图片的xml。 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import csvimport osimport globfrom PIL import Imagefrom traceback import print_excimport syscount = 1def write_anno_xml(img,annos): anno_folder = "./Annotations" im = Image.open('./JPEGImages/' + img) width, height = im.size xml_file = open((anno_folder + '/' + img.split('.')[0] + '.xml'), 'w') xml_file.write('&lt;annotation&gt;\n') xml_file.write(' &lt;filename&gt;' + img + '&lt;/filename&gt;\n') xml_file.write(' &lt;folder&gt;cartoon_VOC&lt;/folder&gt;\n') xml_file.write(' &lt;size&gt;\n') xml_file.write(' &lt;width&gt;' + str(width) + '&lt;/width&gt;\n') xml_file.write(' &lt;height&gt;' + str(height) + '&lt;/height&gt;\n') xml_file.write(' &lt;depth&gt;3&lt;/depth&gt;\n') xml_file.write(' &lt;/size&gt;\n') for anno in annos: xml_file.write(' &lt;object&gt;\n') xml_file.write(' &lt;name&gt;' + anno[-1] + '&lt;/name&gt;\n') xml_file.write(' &lt;pose&gt;Unspecified&lt;/pose&gt;\n') xml_file.write(' &lt;truncated&gt;0&lt;/truncated&gt;\n') xml_file.write(' &lt;difficult&gt;0&lt;/difficult&gt;\n') xml_file.write(' &lt;bndbox&gt;\n') xml_file.write(' &lt;xmin&gt;' + anno[0] + '&lt;/xmin&gt;\n') xml_file.write(' &lt;ymin&gt;' + anno[1] + '&lt;/ymin&gt;\n') xml_file.write(' &lt;xmax&gt;' + anno[2] + '&lt;/xmax&gt;\n') xml_file.write(' &lt;ymax&gt;' + anno[3] + '&lt;/ymax&gt;\n') xml_file.write(' &lt;/bndbox&gt;\n') xml_file.write(' &lt;/object&gt;\n') xml_file.write('&lt;/annotation&gt;') xml_file.close()for file_name in ['train','test']: ftxt = open(file_name+'.txt','w') with open(file_name+'_dataset.csv','r') as f: reader = csv.reader(f) img = '' pre_img = '' annos = [] reader = list(reader) for line in reader: if img != line[0] and img != '': # ceate soft link pos = line[0].split('/')[-1].find('.') img_id = '0'*(5-len(str(count)))+str(count) count += 1 try: os.symlink(line[0],'JPEGImages/'+img_id+line[0].split('/')[-1][pos:]) except Exception as e: print(e.__class__.__name__) print_exc() ftxt.write(img_id+'\n') write_anno_xml(img_id+line[0].split('/')[-1][pos:],annos) img = line[0] annos.clear() annos.append(line[1:]) else: img = line[0] annos.append(line[1:]) sys.stdout.write('&#123;&#125;/&#123;&#125;\r'.format(count,len(reader))) sys.stdout.flush() ftxt.close()]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch 基本语法]]></title>
    <url>%2F2019%2F03%2F29%2Fpytorch-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本篇文章将记录pytorch使用过程中的一些值得记录的trick。 pytorch 基本工作流【0】引入必要的包 123import torchimport torch.nn as nnimport numpy as np 【1】准备数据： 123a = torch.tensor(1.,requires_grad=True)x = torch.randn(10,3) # 10*3的矩阵y = torch.randn(10,2) # 10*2 【2】网络搭建 12345# 定义网络层，网络输入输出参数等等，下面使用pytorch内置的函数linear = nn.Linear(3,2) # 搭建一个输入channel为3，输出channel为2的全连接网络print(linear.weight) # torch以及替我们定义好了参数print(linear.bias) 【3】损失函数以及优化器 12criterion = nn.MSELoss()optimizer = nn.optim.SGD(linear.parameters(),lr = 0.01) 【4】网络正向传播 1234pred = linear(x)# 计算lossloss = criterion(pred,y)print(loss) 这一点和tensorflow很不一样，tensorflow要先搭建好整个网络，然后将数据feed进去，pytorch则是动态构建网络图，边搭建网络边进行传值。 【5】网络后向传播 123456789# 后向传播loss.backward()print('dl/dw',linear.weight.grad)print('dl/db',linear.bias.grad)# 使用optimizer的方式更新参数optimizer.step() # 一次更新参数pred = linear(x)loss = criterion(pred,y) ## 重复上诉步骤直到完成参数拟合 torch与numpy相互转化123456import numpy as npimport torchx = np.array([[3,2],[1,4]]) # numpy.arrayy = torch.from_numpy(x) # torch.tensorz = y.numpy() # tensor to numpy torch 导入数据的pipline（流程）torchvision是torch中一个用于 生成图片，数据集，模型类，欲训练模型的包。它主要包含一下几个部分： torchvision.datasets: 用于导入一些比较流行的开源数据集（cifar等） torchvision.models: 包含了很多流行的网络框架，包括alexnet，VGG，resnet，以及一下欲训练模型 torchvision.transforms: 定义了一些常用的数据预处理的函数，如random crop，rotate等等 torchvision.utils: 里头定义了很多好用的函数，如保存图片等 torchvision.datasets 的使用下载，导入数据，以及按一定的batch取出数据： 12345678# get the datasettrain_data = torchvision.datasets.CIFAR10(root='.',train=True,transform=torchvision.transforms.toTensor(),download = True)image,label = train_data[0]# load dataloader = torch.utils.data.Dataloader(dataset = train_data,batch_size = 64,shuffle=True)#每次load 一个大小为64的batch的数据train_iter = iter(loader)image,label = train_iter.next() pytorch 训练minist数据集中的一些方法123456## 读取数据train = torchvision.datasets.MNIST(root='./',train=True,transform=torchvision.transforms.ToTensor(),download = True)# data loaderdata_loader = torch.utils.data.DataLoader(dataset = train,batch_size = 100,shuffle = True)for image,label in data_loader: pass 训练阶段123456789for epoch in num_epoch: for i ,(image,label) in enumerate(train_loader): output = model(image.reshape(-1,28*28)) loss = criterion(output,label) optimizer.zero_grad() #切记，在计算导数前要将导数置零 loss.backward() optimizer.step() if i+1 == 100: print('epoch:&#123;&#125;/&#123;&#125;,step:&#123;&#125;/&#123;&#125;,loss:&#123;:.4f&#125;'.format(epoch+1,num_epochs,i+1,total_step,loss)) 测试阶段1234567891011# 不算梯度with torch.no_grad(): correct = 0 total = 0 for image,label in val_loader: output = model(image.reshape(-1,28*28)) _,predict = torch.max(output.data,1) total+= label.size(0) correct += (predict == label).sum().numpy()print('accuracy: &#123;&#125;'.format(correct/total))torch.save(model.state.dict,'model_param.ckpt') 其中val,index = torch.max(matrix,1)，计算matrix中每一列的最大值，返回最大值以及他的下标。 构建网络结构torch.nn 主要复制网络的构建，但是很多时候，torch.nn中不满足我们需要的网络，因此我们需要自己定义。torch.nn继承至nn.Module，nn.Module为所有网络的基类。当我们的网络类继承这个方法时，需要实现__init__(),forward()两个函数。 1234567891011class NerualNet(nn.Module): def __init__(self,input_size,hidden_size,output_size): super(NerualNet,self).__init__() self.fc1 = nn.Linear(input_size,hidden_size) self.ReLu = nn.ReLU() self.fc2 = nn.Linear(hidden_size,output_size) def forward(self,x): out = self.fc1(x) out = self.ReLu(out) out = self.fc2(out) return out 调用时model = NerualNet(input_size,hidden_size,output_size)，每次使用model(x)即自动执行forward。 卷积层1nn.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True) 构建一个sequencesequence 将在其中的网络层从上到下连接上一层的输出作为下一层的输入。 1234567891011121314# Example of using Sequentialmodel = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() )# Example of using Sequential with OrderedDictmodel = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) 图片预处理集合123456# Image preprocessing modulestransform = transforms.Compose([ transforms.Pad(4), transforms.RandomHorizontalFlip(), transforms.RandomCrop(32), transforms.ToTensor()]) 其中transforms.ToTensor()将 PIL image tensor (H, W, C) in range [0,255] to a torch.Tensor(C, H, W) in the range [0.0, 1.0]。 pytorch 保存以及导入预训练参数12345678model = ResNet(residual,[2,2,2]).to(device)...torch.save(model,'model.ckpt') # save the structuretorch.save(model.state_dict(),'model_para.ckpt') # save the parameter# loadmodel = torch.load('model.ckpt')# 下面的resnet结构需要提前定义好 resnet.load_state_dict(torch.load('model_para.ckpt')) resent实现需要注意的地方1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# Residual blockclass ResidualBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(ResidualBlock, self).__init__() self.conv1 = conv3x3(in_channels, out_channels, stride) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(out_channels, out_channels) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return out# ResNetclass ResNet(nn.Module): def __init__(self, block, layers, num_classes=10): super(ResNet, self).__init__() self.in_channels = 16 self.conv = conv3x3(3, 16) self.bn = nn.BatchNorm2d(16) self.relu = nn.ReLU(inplace=True) self.layer1 = self.make_layer(block, 16, layers[0]) self.layer2 = self.make_layer(block, 32, layers[1], 2) self.layer3 = self.make_layer(block, 64, layers[2], 2) self.avg_pool = nn.AvgPool2d(8) self.fc = nn.Linear(64, num_classes) def make_layer(self, block, out_channels, blocks, stride=1): downsample = None if (stride != 1) or (self.in_channels != out_channels): downsample = nn.Sequential( conv3x3(self.in_channels, out_channels, stride=stride), nn.BatchNorm2d(out_channels)) layers = [] layers.append(block(self.in_channels, out_channels, stride, downsample)) self.in_channels = out_channels for i in range(1, blocks): layers.append(block(out_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): out = self.conv(x) out = self.bn(out) out = self.relu(out) out = self.layer1(out) out = self.layer2(out) out = self.layer3(out) out = self.avg_pool(out) out = out.view(out.size(0), -1) out = self.fc(out) return out 这段代码在结构设计上，将residual从整个网络中剥离出来。residual部分在resnet中多次使用，可以起到代码复用。这residual这一部分同样继承了nn.module，在resnet中进行调用。在整个网络反向求导的过程中，同样可以反向传播。 12out = out.view(out.size(0),-1) # 即保持第一维不变，然后后面的所有的维度特征进行flatten展开。类似于reshape。out = out.shape(out.size(0),-1) 在对resent进行evaluate的时候，需要先执行model.eval()。这是因为bn，dropout这些操作在训练和测试的阶段不一样。 pytorch中的LSTM的调用1234567891011121314151617181920# Recurrent neural network (many-to-one)class RNN(nn.Module): def __init__(self, input_size, hidden_size, num_layers, num_classes): super(RNN, self).__init__() self.hidden_size = hidden_size self.num_layers = num_layers self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) self.fc = nn.Linear(hidden_size, num_classes) def forward(self, x): # Set initial hidden and cell states h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # Forward propagate LSTM out, _ = self.lstm(x, (h0, c0)) # out: tensor of shape (batch_size, seq_length, hidden_size) # Decode the hidden state of the last time step out = self.fc(out[:, -1, :])# 因为有许多层，只要最后一层 return out 其中LSTM调用： 12345nn.LSTM(input_size,hidden_size,num_layers，batch_first=True)# input_size 指输入的一个数据含有的特征数（维度）# hidden_size 指隐藏输出具有的特征# num_layer 指共有多少个LSTM层叠在一起# batch_first 指LSTM输出的h和c第一个维度都为batch h：hidden 12345h0 = torch.zeros(self,num_layers,x.size(0),self.hidden_size)# 指hidden处的参数# num_layers值共有几层# batch_size=x.size(0) 共有几个batch# hidden_size: 输出的hidden特征数 c： 12c0 = torch.zeros(self.num_layers,x.size(0),self.hidden_size)# 参数与上相同 调用： 1out,(hn,cn) = self.lstm(x,(h0,c0)) 一个较大项目的代码布局逻辑train.py : 程序开始执行的地方，作为整个项目的核心指挥，负责对个个部分进行调度。他的主要思路如下： 【1】通过argparse接受传入的各种配置参数，包括数据集的路径，model的存储路径等等。 1234if __name__ = '__main__': parse = argparse.ArgumentParser() parse.add_element('--model_path',type=str,default='./models',help='saving training model') ... 【2】调用main() 函数，开始执行程序。 123456789101112131415161718192021222324# 首先执行image progressing步骤，对图片进行预处理部分transform = transforms.Compose([ transforms.RandomCrop(args.crop_size), trnasforms.RandomHorizontalFlip(), ...])# build data loader# 此处实现了一个继承torch.utils.data.Dataset的数据集处理类，实现了__init__以及__getitem__。data_loader = get_loader(args.image_dir, args.caption_path, vocab,transform, args.batch_size,shuffle=True, num_workers=args.num_workers) # build the model# 此处实现了一个model类，继承至nn.Moduleencoder = EncoderCNN(args.embed_size).to(device)decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers).to(device)# 显示loss以及optimizercriterion = nn.CrossEntropyLoss() params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters()) optimizer = torch.optim.Adam(params, lr=args.learning_rate) ## train the model,通过data loader来产生数据for epoch in range(args.num_epochs): # 获取batch数据，进行训练以及预测]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSD 复现]]></title>
    <url>%2F2019%2F03%2F29%2FSSD-%E5%A4%8D%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[SSD是经典的one-stage目标检测框架，在速度和精度上都比Faster RCNN，YOLO（V1？）要更胜一筹。这次复现SSD作为理解网络以及学习pytorch的一个机会，这篇文章将尽可能的详细记录SSD的复现细节。（好大的flag🍐） 在复现SSD之前，我想就pytorch的两大部件进行一下介绍，分别是数据集模块（torch.utils.data.Dataset）以及网络模块(torch.nn.Module)。 数据集模块 pytorch数据读取主要有三个类： Dataset DataLoader DataLoaderIter 他们使用的方式为Dataset做为参数传入DatasetLoader中，DataLoader做为参数传入DataLoaderIter中。 因此完成pytorch数据集读取模块第一步要做的是： 【1】定义数据集类。 torch.utils.data.Dataset 是一个抽象类，因此继承Dataset需要实现他的两个方法，__len__()，__getitem__()。 12345678910111213141516import torchimport torch.utils.data as datadata_set = &#123;1:'a',2:'b',3:'c'&#125;class CustomDataset(data.Dataset):#需要继承data.Dataset def __init__(self): # 1. Initialize file path or list of file names. self.data = data_set def __getitem__(self, index): # 每次读取一张图片以及对应的label， # 可以对图片进行一些flip等操作（torchvision.Transform). # 最终返回的是一个含有(image,label)的pair # 可以在init()函数的位置处生成csv_reader,或是一些list，集合 return index, self.data[index] def __len__(self): return len(self.data) 对于这个Dataset这个类，只要实现了这两个函数，然后每次调用的的时候都能出来一个img，label，内部无论是list，generator都是可行的。 在__getitem__() 处可以执行一些图片变换等工作，torchvision.transforms中有着许多对图片的增强操作。常用的有Resize , RandomCrop , Normalize , ToTensor (这个极为重要, 可以把一个PIL或numpy图片转为torch.Tensor） 【2】定义dataLoader dataLoader的定义如下： 1class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False) 其中dataset即上面定义的dataset，batch_size指一次调用该函数，输出的样本个数。num_workers指线程数，当大于等于1时就表示多线程。collate_fn 用于定制输出的batch，通过传入lambda表达式来实现，即当一张图片对应多个边框的时候，就需要进行图片以及边框的匹配。 dataLoader还实现了一个__iter__() 函数，这个函数输入为dataLoader，输出为dataLoaderIter，是一个迭代器。 具体使用如下： 1234567dataset = CustomClass()dataloader = data.DataLoader(dataset,batch_size = 10,...)for data in dataloader: # data[0]为图片 # data[1]为标准 # 共有10对 pass 网络结构模块pytorch 使用nn.Module 来构建网络，在pytorch中每一个网络层都是一个nn.Module类，并且类之间相互嵌套。nn.Module中有两个比较重要的部分，分别是 __init__() ：完成逻辑模块的初始化。 forward()：完成计算图的正向传递的过程。例如nn.Linear模块的定义如下： 12345678910class MyLinear(nn.Module): def __init__(): super(MyLinear,self).__init__() self.w = nn.Parameter(torch.randn(outp,inp)) self.b = nn.Parameter(torch.randn(outp)) def forward(self,x): x = x @ self.w.t() + self.b return x pytorch中提供了许多现成的类可供使用： nn.conV2d nn.MaxPool2d nn.ReLu nn.BatchNorm2d 同时nn.Sequential实现了一个序列，用来构建网络模块。 1234567self.net = nn.Sequential( nn.Conv2d(in_size,out_size,kernel_size,1,1) nn.MaxPool2d(2,2) nn.ReLu() nn.BatchNorm2d(32) ...) 输入将按照网络层从上到下进行参数的传递。 此外nn.Module类还会对网络的参数进行管理，nn.parameters()中将会保存着网络所有的参数。便于参数的管理。 我们可以使用nn.module构建许多的网络层，然后通过输入输出传值的方式将他们连成一个计算图。 下面将按照数据的读入，网络的搭建，网络的训练，以及效果的评估几个方面进行。 SSD 复现参考github链接。 【1】数据的准备 数据集是一些由视频切帧而来的图片，一秒切一帧，对于每张图，由相应的标注信息，标注信息csv格式。通过读取csv数据集的方式，来完成数据的读取（github版本为使用pycocotool读取数据）。通过继承data.Dataset以及实现dataLoader的方式来获取数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import torchimport torch.utils.data as dataimport torchvision.transforms as transformsimport csvimport numpy as npimport cv2# csv格式为：url,x1,y1,x2,y2,labelTRAIN_ROOT = './data/train_dataset.csv'VAL_ROOT = './data/val_dataset.csv'def detection_collate(batch): targets = [] imgs = [] for sample in batch: imgs.append(sample[0]) targets.append(sample[1]) return imgs,targetsclass csv_loader(data.Dataset): def __init__(self,data_root,transform = transforms.ToTensor()): self.data_root = data_root self.dataset = &#123;&#125; self.imgs_index = &#123;&#125; self.transform = transform self.index = 0 with open(self.data_root,'r') as f: lines = csv.reader(f) for line in lines: if line[0] in self.dataset: self.dataset[line[0]].append(line[1:5]) else: self.dataset[line[0]] = [line[1:5],] self.imgs_index[self.index] = line[0] self.index += 1 def __getitem__(self,index): img_path = self.imgs_index[index] label = self.dataset[img_path] img = cv2.imread(img_path) img = self.transform(img) for i in range(len(label)): label[i][0] = float(label[i][0]) label[i][1] = float(label[i][1]) label[i][2] = float(label[i][2]) label[i][3] = float(label[i][3]) label = np.array(label) return img,label def __len__(self): return self.index+1dataset = csv_loader(TRAIN_ROOT)dataloader = data.DataLoader(dataset,batch_size = 2,collate_fn = detection_collate)for img,label in dataloader: print(img) print(label) break 如上，可以看出我们使用detection_collate方法来对每个batch size中读到的数据进行二次组织。 【2】网络的构建 数据已经准备好了，接下来要做的就是将网络搭建起来，然后将数据输入。 ssd的网络的backbone是vgg网络，利用vgg网络提取图片特征。 vgg的结构如下： 实现backbone的代码如下： 12345base = &#123; '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M', 512, 512, 512], '512': [],&#125; hard negative miningSSD 中对feature map位置的提取6个或4个边框，这些边框的尺寸由一些超参数决定。在进行网络训练之前，需要对生成的这些边框进行正负样本的标注，标注的标准在于这些边框与GT边框的IoU重合度，如果重合度大于0.5，则表示这个边框是证样本，小于0.3表示这个边框是负样本。 在对正负样本进行标注时，一般要保证正样本：负样本的个数为1:3。但是对于一张图片来说，其上大部分的框都是负样本，因此需要进行hard negative mining将一些得分较高的negative 做为hard negative。 hard negative mining一般是，有正负样本，然后分类器分出来一些分错的负样本（容易将负样本看成正样本的那些样本），即假阳性(false positive )，也就是说在对负样本分类时候，loss比较大（label与prediction相差较大）的那些样本，这些就是hard negative/困难样本，进行重新训练。 网络搭建部分主要继承nn.Module模块，继承init以及forward模块，实现网络结构的搭建，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205#!/usr/bin/env python #-*- coding: utf-8 -*-import torchimport torch.nn as nn# 记录各层的channelbase = [64,64,'M',128,128,'M',256,256,256,'C',512,512,512,'M',512,512,512] # M表示floor（边角舍弃）方式的Maxpooling，C表示ceil（补全）方式的Maxpooling# vgg之后的各各层extras = [256,'S',512,128,'S',256,128,256,128,256]#每一层每个像素位置将取出的边框个数mboxes = [4,6,6,6,4,4]def vgg(base,input_channel,batch_norm=None): ''' base: 各层的channel input_channel：传入数据的维度 batch_norm：是否使用bn 这个函数主要使用一个list，将每一层的函数存储起来，用base来控制当前层是什么 ''' layers = [] in_channels = input_channel for v in base: if v == 'M':# 表示是一个maxpooling layers += [nn.MaxPool2d(kernel_size=2,stride=2)] elif v == 'C': layers += [nn.MaxPool2d(kernel_size=2,stride=2,ceil_mode=True)] else: conv2d = nn.Conv2d(in_channels,v,kernel_size=3,padding=1) if batch_norm: layers += [conv2d,nn.BatchNorm2d(v),nn.ReLU(inplace=True)] # inplace=True 指它将直接修改input的值，而不重新分配空间 else: layers += [conv2d,nn.ReLU(inplace=True)] in_channels = v pool5 = nn.MaxPool2d(kernel_size=3,stride=1,padding=1) conv6 = nn.Conv2d(512,1024,kernel_size=3,padding=6,dilation=6) conv7 = nn.Conv2d(1024,1024,kernel_size=1) layers += [pool5,conv6,nn.ReLU(inplace=True),conv7,nn.ReLU(inplace=True)] return layersdef add_extras(extras,in_channel,batch_norm=None): # extra layers added to vgg for feature scaling layers = [] in_channels = in_channel flag = False for k,v in enumerate(extras): if in_channels!='S': if v == 'S': layers += [nn.Conv2d(in_channels,extras[k+1],kernel_size=(1,3)[flag],stride=2,padding=1)] else: layers += [nn.Conv2d(in_channels,v,kernel_size=(1,3)[flag])] flag = not flag in_channels = v return layersdef multibox(vgg,extras_layers,mbox,num_classes): loc_layers = [] conf_layers = [] vgg_source = [21,-2] # vgg的21层即conv4_3,和-2层即fc7 for k,v in enumerate(vgg_source): loc_layers += [nn.Conv2d(vgg[v].out_channels,mbox[k]*4,kernel_size=3,padding=1)] # location 有四个参数 conf_layers += [nn.Conv2d(vgg[v].out_channels,mbox[k]*num_classes,kernel_size=3,padding=1)] # 类别预测将有class_num个数 for k,v in enumerate(extras_layers[1::2],2): # 这里就是说取extras中奇数层，然后取bounding box，从第二层开始 loc_layers += [nn.Conv2d(v.out_channels,mbox[k]*4,kernel_size=3,padding=1)] conf_layers += [nn.Conv2d(v.out_channels,mbox[k]*num_classes,kernel_size=3,padding=1)] return vgg,extras_layers,(loc_layers,conf_layers)class priorBox(obejct): """ 在feature map上计算初始边框的坐标 """ def __init__(self,cfg): # 将config中的一些超参赋值过来 self.image_size = cfg['min_dim'] self.num_priors = len(cfg['aspect_ratios']) self.variance = cfg['variance'] or [0.1] self.feature_maps = cfg['feature_maps'] self.min_sizes = cfg['min_sizes'] self.max_sizes = cfg['max_sizes'] self.steps = cfg['steps'] self.aspect_ratios = cfg['aspect_ratios'] self.clip = cfg['clip'] self.version = cfg['name'] for v in self.variance: if v &lt;= 0: raise ValueError('Variances must be greater than 0') def forward(self): mean = [] for k ,f in enumerate(self.feature_maps): f_k = self.image_size / self.steps[k] s_k = self.min_sizes[k] / self.image_size s_k_prime = sqrt(s_k*(self.max_sizes[k]/self.image_size)) for i,j in product(range(f),repeat=2): # unit center x,y cx = (j + 0.5) / f_k cy = (i + 0.5) / f_k #aspect_ratio: 1 mean += [cx,cy,s_k,s_k] mean += [cx,cy,s_k_prime,s_k_prime] for ar in self.aspect_ratios[k]: mean += [cx,cy,s_k*sqrt(ar),s_k/sqrt(ar)] mean += [cx,cy,s_k/sqrt(ar),s_k*sqrt(ar)] # back to torch land output = torch.Tensor(mean).view(-1,4) if self.clip: output.clamp_(max=1,min=0) return outputclass SSD(nn.Module): def __init__(self,phase,size,base,extras,head,num_classes): ''' phase: train,test size: ssd输入图片的大小，也即是版本把 base: vgg的网络结构 extras: vgg之后的那些层 head: loc，conf 的boxes ''' super(SSD,self).__init__() self.phase = phase self.num_classes = num_classes self.cfg = (coco,voc)[num_classes == 21] # config.py 中对数据集的一些配置 self.priorbox = PriorBox(self.cfg) self.priors = Variable(self.priorbox.forward(),volatile=True) self.size = size ## ssd net self.vgg = nn.ModuleList(base) self.L2Norm = L2Norm(512,20) self.extras = nn.ModuleList(head[1]) self.loc = nn.ModuleList(head[0]) self.conf = nn.ModuleList(head[1]) if phase == 'test': self.softmax = nn.Softmax(dim = -1) ## detection.py self.detect = Detect(num_classes,0,200,0.01,0.45) def forward(self,x): sources = list() loc = list() conf = list() # apply vgg to conv4_3 relu for k in range(23): x = self.vgg[k](x) s = self.L2Norm(x) sources.append(s) # apply vgg up to fc7 for k in range(23,len(self.vgg)): x = self.vgg[k](x) sources.append(x) # apply extra layers for k,v in enumerate(self,extras): x = F.relu(v(x),inplace=True) if k%2 == 1: sources.append(x) for (x,l,c) in zip(sources,self.loc,self.conf): loc.append(l(x).permute(0,2,3,1).contiguous()) conf.append(c(x).permute(0,2,3,1).contiguous()) loc = torch.cat([o.view(o.size(0),-1) for o in loc],1) conf = torch.cat([o.view(o.size(0),-1) for o in conf],1) if self,phase == 'test': output = self.detect( loc.vire(loc.size(0),-1,4), self.softmax(conf.view(conf.size(0),-1,self.num_classes)), self.priors.type(type(x.data)) ) else: output = ( loc.view(loc.size(0),-1,4), conf,vire(conf.size(0),-1,self.num_classes), self.priors ) return output def load_weights(self,base_file): other,ext = os.path.splitext(base_file) if ext == '.pkl' or '.pth': self.load_state_dict(torch.load(base_file, map_location=lambda storage,loc:storage)) else: print('sorry wrong')def build_ssd(phase,size=300,num_classes=21): if phase != 'test' and phase != 'train': print('error') return if size != 300: print('error') return base_,extras_,head_ = multibox(vgg(base[str(size)],3),add_extras(extras[str(size)],1024), mbox[str(size)],num_classes) return SSD(phase,size,base_,extras_,head_,num_classes)]]></content>
      <categories>
        <category>论文复现</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手撕mAP]]></title>
    <url>%2F2019%2F03%2F22%2F%E6%89%8B%E6%92%95mAP%2F</url>
    <content type="text"><![CDATA[mAP在很多检测任务中使用十分频繁，微软的COCO数据集专门提供了一套API，实现预测模型的mAP计算（pycocotools），本篇文章打算用最原始的方式手撕mAP，希望使得对整个指标更好的理解。文章参考Retina-net，并在其基础上进行修改。 mAP是什么？mAP： mean Average Precision, 即各类别AP的平均值，例如COCO数据集，共有80+1类（背景），对每一个类别的物体求一个AP，mAP即为所有目标AP的平均值。 AP：AP为PR曲线（precision-recall）与x轴围成的面积 Pricision：TP/（TP+FP），即预测为真（预测结果放后面即TP）当中，真正为真的比例。 Recall：TP/（TP+FN），即预测为真当中真正为真的个数，占所有样本中真个数的比例。 对于TP，FP，TN，FN表示四种情况，其中T，F是从结果来看，是否预测正确。P，N则是从预测来看，预测正误。 TP：预测是对的，预测样本结果为真。该类样本的个数 FP：预测是错的，预测样本为真。该类个数。 TN：预测是对的，预测样本为假。该类个数。 FN：预测是错的，预测样本为假。该类个数。 真假鉴定：当预测边框与GT的边框重合程度，PASCAL数据集中，认为IoU大于0.5认为是真，小于0.5认为是假。 IoU：预测边框与GT边框的 重叠面积/两个边框并集 mAP-IoU[0.5, 0.95]：COCO要求IOU阈值在[0.5, 0.95]区间内每隔0.05取一次，将这个IoU作为真假边框的评判边界。可以计算出10个IoU下的mAP值，然后这10个还要再做平均，即为最后的mAP。 疑问指标虽然很多，但是都是很简单的指标，耐心的理解一下，也不辛苦的。看完上面的指标有几个疑问： IoU计算的时候需要边框与GT对应起来，每个GT对应一个边框后不再参与后面边框的匹配。那么与哪个GT边框对应呢，这是个问题？（置信度+IoU最大） AP在计算的时候需要计算AP曲线下方的面积，这个该怎么算呢？ 计算precision，recall的时候需要每个类单独算，然后用于之后算AP，感觉是几个循环，外循环是个遍历类别，内循环对每个预测边框做一下循环，具体怎么实现呢？ 实作这一部分将按照输入数据，数据处理，计算IoU，计算Precision，Recall，计算AP等步骤。 预测结果数据：假设经过模型预测得到一个csv格式的预测结果，格式如下： 1/path/to/1.jpg,10,78,25,34,face,0.9 分别是图片的位置，预测的边框（左上）（x,y,w,h)，label，以及置信度。 GT数据： 1/path/to/1.jpg,15,80,30,32,face 分别是图片的位置，边框位置以及标签。 数据处理： 为了更好的计算每一个类别预测的precision以及recall，直觉上来说，应该需要一个比较好的格式方便计算，我们可以将这种格式设置如下： 1all_detections = [img_index][label][box_index] 意思为每一个图片，对应若干个label（例如一张图上对应桌子，人），每个label对应若干个边框，（例如一张图片中有多个人）。 因此第一步需要把csv格式的数据转换为上面的格式，在转换之前需要借助道dcit字典。目的是为了对相同的图片的label。boxes进行汇总。dict的格式如下： 1234[ img1:&#123;label1:[[box1],[box2]...],label2:[[box1],[box2]...]..&#125; img2:&#123;label1:[[box1]]&#125; ] 即外围是一个list[],保存每一张图片的信息。每个图片是一个字典，key为图片名，val是另一个保存label和boxes的字典，这个字典的key为label名，val为多个boxes的list结构。 下面代码是读取csv文件，并将数据转化为上诉格式： 1234567891011121314151617181920212223242526272829303132import csvimg_name = &#123;&#125; # imgId: 1boxes_label_scores = &#123;&#125; # imgId: [[x,y,w,h,score],...]class_num = 1 # 表示类别个数pre_gt_csv = 'score_mintest.csv' with open(pre_gt_csv,'r') as f: reader = csv.reader(f) lines = list(reader) for line in lines: if len(line) &lt; 7: line.append('1') # 当为GT的时候，最后需要添上置信度为1 if float(line[-1]) &lt; score_threshold: continue if line[0] not in img_name.keys(): img_name[line[0]] = 1 temp = line[1:5] temp.append(line[-1]) # [x,y,w,h,score] box_dict = &#123;&#125; box_dict[line[5]] = [temp] # label:[[],[]] #&#123;img: &#123;label_name:[x,y,w,h,socre],[x2,y2,w2,h2,score2]...&#125;,img:&#123;...&#125;.. &#125; boxes_label_scores[line[0]] = box_dict else: # the image is exist temp = line[1:5] temp.append(line[-1]) if line[5] in boxes_label_scores[line[0]].keys(): boxes_label_scores[line[0]] [line[5]].append(temp) else: boxes_label_scores[line[0]][line[5]] = [temp] 在进行边框对比的时候，我们希望对置信度高的边框提前进行IoU的判断，因此对boxes_label_scores中的boxes进行置信度的排序(解决第一个问题)，如下： 123456for img in boxes_label_scores: labels = boxes_label_scores[img] for label in labels.keys(): boxes = boxes_label_scores[img][label] boxes = sorted(boxes, key=lambda x: float(x[-1]),reverse=True) boxes_label_scores[img][label] = boxes 由于上面字典的结构，key与label均为真实值，然后我们希望用all_detections这个list的结构来代替，因此需要引入图片与下标，label与下标的一一对应关系。 图片与下标对应：我们对测试集中读取的图片从上到下，依次进行计数。该数对应该图片的Id（切记，在进行GT比较时，顺序不能乱）。 label与下标对应： 将其转化为下标，从0开始一次进行计数。 也可以专门生成一张数字与图片，数字与类别一一对应的表格，比较直观。上诉方法则比较方便，但是容易混乱。因此将字典结构赋值给三重数组代码如下： 1234567891011# all_detections : [img1[label1],[label2]..] ; img2: label1,label2...all_detections = [[None for i in boxes_label_scores[img].keys()] for img in boxes_label_scores.keys()] #inds_keys = list(img_name.keys()) # [img1,img2,...n-1]inds = img_name.keys() # 充当图片的id，与图片一一对应# ind与图片路径一一对应for ind,img in (enumerate(inds)): # 每次得到img_name 即图片路径 # index 与label一一对应 for index,label in enumerate(boxes_label_scores[img].keys()): all_detections[ind][index] = boxes_label_scores[img][label] ## ind为图片，index为类别，从0开始return all_detections 计算precision，recall 生成数据之后需要根据数据去计算TP，FP，TN，FN等参数。一个直观的想法就是大循环是个label，然后每次算出一个类的AP之后，保存一下，循环结束了算一个平均。 计算precision即计算预测边框中真正预测对的部分占预测为真的个数。计算recall即计算预测边框中TP与总的GT的比例。因此我们以label为大循环，一次去遍历每一张图片，然后去更新TP，FP的值。如下代码： 1234567891011121314151617181920212223242526272829inds = list(range(len(img_name.keys()))) # 充当图片的id，与图片一一对应 for label in range(class_num): # false_positives = np.zeros((0,)) # precision = TP/（TP+FP）Recall = TP/（TP+FN） true_positives = np.zeros((0,)) scores = np.zeros((0,)) num_annotations = 0.0 for i in inds: detections = all_detections[i][label] # image：i，class：label annotations = all_annotations[i][label] num_annotations += len(annotations) #.shape[0] # boxes的个数 detected_annotations = [] for d in detections: scores = np.append(scores, float(d[4])) #if annotations.shape[0] == 0: if len(annotations) == 0: # 预测为真，但这个label的个数是0 false_positives = np.append(false_positives, 1) true_positives = np.append(true_positives, 0) continue overlaps = compute_overlap(np.expand_dims(d, axis=0), annotations) assigned_annotation = np.argmax(overlaps, axis=1) max_overlap = overlaps[0, assigned_annotation] if max_overlap &gt;= iou_threshold \ and assigned_annotation not in detected_annotations: # IoU满足条件，分配的标注没有被标注过 false_positives = np.append(false_positives, 0) # FP += 0 true_positives = np.append(true_positives, 1) # TP += 1 detected_annotations.append(assigned_annotation) else: # 标注已经使用过 false_positives = np.append(false_positives, 1) true_positives = np.append(true_positives, 0) 值得注意的是，false_positives与true_positives并不是直接算个和，而是将每一张图片是否为TP，FP按照1，0保留下来。如下： 1false_positives = [0,1,0,1,1,1] # 下标表示图片的序号，0表示否，1表示真 这样存储的好处在于随后计算AP（PR曲线下方面积）时，方便计算。 计算单个 label的AP上一个部分代码得到了每张图片的PR值结果。计算AP值即算PR曲线的下方面积，因为不能直接算积分，因此我们需要想想办法。PR图是一张recall为x轴，precision为y轴的曲线，随着图片进行叠加，分别计算出P，R值，然后绘制出曲线。为了保证PR值尽量准确，我们首先对图片进行置信度从高到低的一个排序，然后累加计算其PR值。 1234567891011121314151617 # no annotations -&gt; AP for this class is 0 (is this correct?)if num_annotations == 0: average_precisions[label] = 0, 0 continue # sort by scoreindices = np.argsort(-scores)false_positives = false_positives[indices] true_positives = true_positives[indices]# compute false positives and true positivesfalse_positives = np.cumsum(false_positives) # 依次累加true_positives = np.cumsum(true_positives)# compute recall and precision num_annotations也是据图片累加的recall = true_positives / num_annotationsprecision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps) 上诉代码首先根据scores对PR值进行排序，然后对每张图片从1…n累加计算出TP，FP值，因此最终得到的TP，FP也是一个长度为图片个数的数组。 计算AP的方法： 计算AP通常有两种方式，一种是07年以前的11点法，第二种是则是对每一个点都计算差值。 Calculating the interpolation performed in all points该部分参考github上的讲解。先看图，对于Precision与Recall的插值如下， 也就是说，对于precision来说，从末尾开始，precision每个点的取值都等于其前一个点与当前点的最大值，即mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])。当遇到更大的precision时，重新开始重复上面计算，得到许多矩形框如下,计算该面积即可： 代码如下： 12345678910111213141516171819202122232425def _compute_ap(recall, precision): """ Compute the average precision, given the recall and precision curves. Code originally from https://github.com/rbgirshick/py-faster-rcnn. # Arguments recall: The recall curve (list). precision: The precision curve (list). # Returns The average precision as computed in py-faster-rcnn. """ # correct AP calculation # first append sentinel values at the end mrec = np.concatenate(([0.], recall, [1.])) mpre = np.concatenate(([0.], precision, [0.])) # compute the precision envelope for i in range(mpre.size - 1, 0, -1): mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i]) # to calculate area under PR curve, look for points # where X axis (recall) changes value i = np.where(mrec[1:] != mrec[:-1])[0] # and sum (\Delta recall) * prec ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1]) return ap 计算IoU当我们在计算Precision与Recall的时候需要判断样本是否是真样本，因此需要计算IoU值，计算IoU的大致思路如下，首先对一张图片，拿到一个置信度最高的边框，然后对该边框与该图片所有的GT边框都计算一个IoU，选出一个IoU值最大的GT边框作为与该边框匹配的边框。 1234import compute_overlapoverlaps = compute_overlap(np.expand_dims(d, axis=0), annotations) assigned_annotation = np.argmax(overlaps, axis=1) max_overlap = overlaps[0, assigned_annotation] 其中compute_overlap库是一个动态链接库，即为一个.so文件，通过.c文件编译而来。overlap代码github地址。算法就是那样了，retina-net作者偷懒，直接用了fast rcnn的代码，我也偷个懒😂。 值得注意的是，每当一个GT边框被使用过之后，需要将其标记一下，避免下次重复计算。 总结求mAP的方法需要通过预测网络提前生成测试集的box，然后将pred_csv, GT_csv传入方法中，最终求返回每个类别的AP。]]></content>
      <categories>
        <category>手撕系列</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python Tip]]></title>
    <url>%2F2019%2F03%2F20%2Fpython-Tip%2F</url>
    <content type="text"><![CDATA[字符串查找元素123astr = '1234'astr.find('1') # 返回下标或-1astr.rfind('1') # 反向查找 python lambda 表达式12345678910g = lambda x:x+1 # x为输入，x+1为输出: g(1) = 2# python 中自带的lambda表达式# foo =[2, 18, 9, 22, 17, 24, 8, 12, 27]# 输出：[18, 9, 24, 12, 27]filter(lambda x:x%3 ==0,foo)# map,将foo中每个元素都算一下#输出：[14, 46, 28, 54, 44, 58, 26, 34, 64]map(lambda x: x * 2 + 10, foo)#reduce 类加reduce(lambda x, y: x + y, foo) 获取图片大小123from PIL import Imageim = Image.open('whatever.png')width, height = im.size python 🀄️的类123456class Animal(object): def __init__(self,name): self.name = name self.__sex = man ## 在属性前加上两个_ 变成私有变量 def greet(self): print('hello'+self.name) python中前后都有双下划线的变量是特殊变量，如__ver__,可以直接访问，定义式避免这种定义方式。例外，仅有一个下划线，如_name,这种变量表示不要轻易访问，但是它是可以被直接访问的。 获取变量信息例如dog = Animal(&#39;dog&#39;): type(dog) 来获取dog的类型。 isinstance(dog,Animal) 判断dog的类型 hasattr(obj, attr) 判断类是否有attr方法/属性 getattr(obj,attr[,default]):得到属性的值 setattr(obj, attr, value): 设置属性的值 dir(dog): 获取dog的所有属性和方法 类方法，静态方法可以使用类或实例直接访问： 1234567class A(object): @classmethod def class_info(cls): print(cls) @staticmethod def static_info(): print('something') 定制类以及魔法方法python中有一类方法，使用双下划线包裹起来：__new__等等，这类方法称为魔法方法，可以对类提供特殊的功能，方便定制类。 __new__(cls): 当创建一个类时，首先调用__new__(cls)方法，之后再调用__init__() __str__: 当我们直接输出一个实例时，如print(dog),得到的输出为：&lt;__main__.Animal object at 0x10c37aa50&gt;,通过覆盖__str__ 方法可以输出我们想要的内容。 __repr__: 当我们不用print时，调用该方法 1234567class A(object): def __str__(self): return 'Animal object (name: %s)' % self.name def __repr__(self): return 'lalal'print(Animal(dog)) ## 调用__str__()Animal(dog) ## 调用 __repr__() __iter__(),__next__(): 定义该方法使得类允许迭代调用,首先调用__iter__() 获得一个迭代器，然后每次迭代调用next。（可以不定义iter）。 __geitem__ 用于获取值，类似地，__setitem__ 用于设置值，__delitem__ 用于删除值，让我们看下面一个例子： 123456789101112131415161718192021class Point(object): def __init__(self): self.coordinate = &#123;&#125; def __str__(self): return "point(%s)" % self.coordinate def __getitem__(self, key): return self.coordinate.get(key) def __setitem__(self, key, value): self.coordinate[key] = value def __delitem__(self, key): del self.coordinate[key] print 'delete %s' % key def __len__(self): return len(self.coordinate) __repr__ = __str__ 调用： 1234567891011121314151617&gt;&gt;&gt; p = Point()&gt;&gt;&gt; p['x'] = 2 # 对应于 p.__setitem__('x', 2)&gt;&gt;&gt; p['y'] = 5 # 对应于 p.__setitem__('y', 5)&gt;&gt;&gt; p # 对应于 __repr__point(&#123;'y': 5, 'x': 2&#125;)&gt;&gt;&gt; len(p) # 对应于 p.__len__2&gt;&gt;&gt; p['x'] # 对应于 p.__getitem__('x')2&gt;&gt;&gt; p['y'] # 对应于 p.__getitem__('y')5&gt;&gt;&gt; del p['x'] # 对应于 p.__delitem__('x')delete x&gt;&gt;&gt; ppoint(&#123;'y': 5&#125;)&gt;&gt;&gt; len(p)1 __getattr__() 只有在属性不存在的情况下才会被调用。 与 __getattr__ 一起使用的还有 __setattr__, __delattr__，类似 obj.attr = value, del obj.attr: 12345678910111213141516171819202122232425262728293031323334353637383940class Point(object): def __init__(self, x=0, y=0): self.x = x self.y = y def __getattr__(self, attr): if attr == 'z': return 0 raise AttributeError("Point object has no attribute %s" % attr) def __setattr__(self, *args, **kwargs): print 'call func set attr (%s, %s)' % (args, kwargs) return object.__setattr__(self, *args, **kwargs) def __delattr__(self, *args, **kwargs): print 'call func del attr (%s, %s)' % (args, kwargs) return object.__delattr__(self, *args, **kwargs)&gt;&gt;&gt; p = Point(3, 4)call func set attr (('x', 3), &#123;&#125;)call func set attr (('y', 4), &#123;&#125;)&gt;&gt;&gt; p.z0&gt;&gt;&gt; p.z = 7call func set attr (('z', 7), &#123;&#125;)&gt;&gt;&gt; p.z7&gt;&gt;&gt; p.wTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 8, in __getattr__AttributeError: Point object has no attribute w&gt;&gt;&gt; p.w = 8call func set attr (('w', 8), &#123;&#125;)&gt;&gt;&gt; p.w8&gt;&gt;&gt; del p.wcall func del attr (('w',), &#123;&#125;)&gt;&gt;&gt; p.__dict__&#123;'y': 4, 'x': 3, 'z': 7&#125; __call__ 方法,对实例进行调用就好像对函数调用一样。 12345class A(object): def __call__(self): return 1+1a = A()a() # 将调用__call__方法 使用 __slots__ 来告诉 Python 只给一个固定集合的属性分配空间，如下： 12345678class Point(object): __slots__ = ('x', 'y') # 只允许使用 x 和 y def __init__(self, x=0, y=0): self.x = x self.y = ya = Point()a.z = 1 # 报错，只允许对x,y赋值 定义@property以及@setter 方法，第一个将方法当作属性来用，第二个将这个方法当作属性来赋值。 1234567891011121314151617181920212223242526class Exam(object): def __init__(self, score): self._score = score @property def score(self): return self._score @score.setter def score(self, val): if val &lt; 0: self._score = 0 elif val &gt; 100: self._score = 100 else: self._score = val&gt;&gt;&gt; e = Exam(60)&gt;&gt;&gt; e.score60&gt;&gt;&gt; e.score = 90&gt;&gt;&gt; e.score90&gt;&gt;&gt; e.score = 200&gt;&gt;&gt; e.score100 super():当使用子类与夫类方法相同时会发生覆盖，如果希望保留父类则调用super方法。 12345678910class Animal(object): def __init__(self, name): self.name = name def greet(self): print（111）class Dog(Animal): def greet(self): super().greet() print 'WangWang...' 使用元类：元类主要用来拦截类的创建，修改类的定义 1234567891011121314151617class PrefixMetaclass(type): def __new__(cls, name, bases, attrs): # 给所有属性和方法前面加上前缀 my_ _attrs = (('my_' + name, value) for name, value in attrs.items()) _attrs = dict((name, value) for name, value in _attrs) # 转化为字典 _attrs['echo'] = lambda self, phrase: phrase # 增加了一个 echo 方法 return type.__new__(cls, name, bases, _attrs)class Foo(metaclass=PrefixMetaclass): name = 'foo' def bar(self): print 'bar'class Bar(Foo): prop = 'bar' 创建迭代器： 123456789101112class Fib(object): def __init__(self): self.a, self.b = 0, 1 # 返回迭代器对象本身 def __iter__(self): return self # 返回容器下一个元素 def __next__(self): self.a, self.b = self.b, self.a + self.b return self.a __iter__() 创建迭代器，__next__()每次迭代均调用该方法取得迭代值。 创建生成器： 1234567891011&gt;&gt;&gt; def fib():... a, b = 0, 1... while True:... a, b = b, a + b... yield a...&gt;&gt;&gt; f = fib()&gt;&gt;&gt; for item in f: # 每次执行到yield返回一个值并停止，第二次调用f.next()时冲yield处开始执行... if item &gt; 10:... break... print item Python OS模块123456789101112131415import osfor dir in os.listdir('./'): # 当前路径下的所有文件 print(dir)os.path.abspath('.') # 得到绝对路径os.path.dirname('file.txt') # 获取当前文件的父目录os.path.basename('./path/to/file.txt') # 输出file.txt，得到文件名os.path.splitext('afile.txt') # 输出(afile,txt),分离文件名和扩展名os.path.split('/path/file.txt')# (path,file.txt)，分离目录与文件os.path.isfile/os.path.isdir() #判断是否是目录或文件##遍历目录for root, dirs, files in os.walk('/Users/ethan/coding'): print root print dirs print files python zip函数123a = [1,2,3]b = [4,5,6]zipped = zip(a,b)#[(1,4),(2,5),(3,6)] print 重定向12345with open('afile.txt','w') as f: a = 'this is a string' b = 11 print &gt;&gt; a,b## 重定向将a,b输入afile.txt 中 sys.stdout 标准输出12sys.stdout.write('&#123;&#125;/&#123;&#125;\r'.format(step,len(lines)))# 控制台输出sys.stdout.flush() # 将控制台输出的抹掉 xlsx文件读取123456789101112131415161718import xlrdXLSX_PATH = './video_id.xlsx'workbook = xlrd.open_workbook(XLSX_PATH)print(workbook.sheet_names()) #得到所有表的表名id_list = []for sheet in workbook.sheet_names(): booksheet = workbook.sheet_by_name(sheet) # 根据表名得到表 col = booksheet.col_values(0)[1:] # 得到表的第一列 id_list += col print('sheet name: '+ sheet) print(col)print('total account:' +str(len(id_list)))from_slsx_get_video(id_list) progressbar 进度条的使用1234from progress import *progress = ProgressBar()for i in progress(range(1000)): pass python enumerate使用12for i,label in enumerate(labels): print(i,label) python argsort()argsort是numpy的一个函数，这个函数的作用是返回从小到大排序后的元素下标。 1234import numpy as npa = np.array([1,2,4,-1])sort_index = np.argsort(a)a = a[b] # 进行排序 numpy cumsum()cumsum()这个函数用来对数组依次累加。 123import numpy as npa = np.array([1,2,3])b = np.cumsum(a) # b = [1,3,6] numpy maximum()这个函数的输入为两个数组，然后生成一个数组，每个位置上为这两个数组中较大的那个。 1234import numpy as npa = np.array([1,2,3])b = np.array([2,2,2])c = np.maximum(a,b) # c = [2,2,3] python 排序算法123a = [3,2,4]a.sort() # 输出为空，直接改变asorted(a) # 输出排序后的结果，但不改变a Python 中的序列序列是python 中最基本的数据结构。序列对象均可以进行索引，分片，迭代，加，乘操作，可以用in判断元素是否存在序列中。其中list，tuple，str都属于序列。 list 列表list是可修改的一个变量，可以对他进行任意的修改。可以使用list()函数，对str字符串，和tuple进行转化成list。下面对list的各种函数进行讲解： index1234# index 用于从列表中寻找第一个出现元素的下标nums = [1,2,3,4,5,6,7]nums.index(2)nums.index(9) # 如果找不到则抛出异常 count12# 用于计算一个元素出现的个数nums.count(1) append123# 用于在元素末尾增加元素nums.append(8)nums.append([9,8]) # 将[9,8]作为一个整体加入 nums = [1,2,..,[8,9]] extend1234567# 将list进行融合a = [1,2,3]b = [4,5,6]a.extend(b) # a = [1,2,3,4,5,6]## extend 元素不允许直接添加一个元素a.extend(3) # 报错a.extend([3]) insert123#insert(pos,val)a = [1,2,3]a.insert(1,4) # a = [1,4,2,3] pop1234# 用于移除list中的元素，默认是最后一个,返回值为移除的数a = [1,2,3,4]a.pop() # a = [1,2,3]a.pop(1) # a = [1,3] remove1234# remove(val) 移除list中值为val的元素a = [1,2,2,3,3,4]a.remove(2) # 移除第一个相同的，a = [1,2,3,3,4]a.remove(8) # 若不在list中，则抛出异常 reverse123# 反转数组a = [1,2,3]a.reverse() # a = [3,2,1] sort12345678910111213141516# 该方法直接对list进行排序，修改list的值a = [3,1,2]a.sort() # 直接修改a, a = [1,2,3]a.sort(reverse=True) # 反向排序# 此外可以指定key，进行一些多列的排序student_tuples = [ ('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10),]sorted(student_tuples,key=lambda student:student[2])# cmp 指定函数def compare(x,y): return x-ysorted(alist,cmp = compare) sorted123# 该方法不是list的方法，返回值为排序结果，不改变aa = [3,1,2]sorted(a) # 返回值为[1,2,3]，a不变 tuple元组是一种不可变的序列，不可对tuple进行修改，它用()来表示。 1234a = (1,2,3)b = (1,) # 当仅有一个元素的时候，必须叫上一个逗号c =() # 空元组tuple # 可以进行索引分片，与正常的序列相同 字符串字符串是一种序列，满足索引，分片，加法，乘法等操作，并且字符串也是不可变的变量。 find12345# find函数用于找字符串中的子串的位置astr = 'this is a dog'astr.find('is') # 返回第一个子串出现的位置astr.find('is',4) # 指定起始位置astr.find('is',4,7) # 指定起始和结束位置 split123# split 指定一个分割符对字符串进行分割a = 'a,b,c,d'a.split(',') # 返回一个list数组 join123# join 函数类似于split的逆函数','.join(['1','2','3']) # 得到一个字符串：'1,2,3'''.join(['a','b','c']) # 得到一个字符串：‘abc’ strip12345# 用于删除左右两边的空格a = ' sdssd 'a.strip() # a = 'sdssd'a = '##sadsd sasd%%%'a.strip('#%') # 删除左右两边的#与% replace123# 用于体会匹配项a = 'this is a dog'a.replace('is','isnt') # a = 'this isnt a dog' lower/upper123# 返回字符变大或者变小的结果a = 'ABC'a.lower() # 放回abc，但是a仍然不变 dict 字典dict是有key-value组成的一个类型。 创建，遍历字典 1234567adict = &#123;&#125;adict['a'] = 1# 遍历for k in adict: print(k,adict[k])for k in adict.keys(): print(k,adict[k]) 判断元素是否在字典中 12345d = &#123;&#125;d['a'] = 1d['b'] = 2if 'b' in d: print('b is a key') clear1d.clear() # 清空所有项 copy12345# 浅复制d2 = d1.copy() # 对d2的改变同样也会改变d1# 深复制，生成许多独立的样本from copy import deepcopyd2 = deepcopy(d1) # d2与d1无关 get123#访问字典中的元素d.get('key_val') # 返回值，如果没有的话返回Noned.get('key_val'，；'default val') # 如果无，放回default val update1234#将两个字典进行相加a = &#123;'a':1&#125;b = &#123;'b':2&#125;b.update(a) # b = &#123;'a':1,'b':2&#125; Items,keys,values12345678#items将dict项以list的方式返回，keys将key以list的方式返回d = &#123;'a':1,'b':2,'c':3&#125;for k ,v in d.items(): passfor k in d.keys(): passfor v in d.values(): pass pop1234#删除keyd = &#123;'a':1,'b':2&#125;d.pop('a') # 返回a的val 1d.popitem() # 随机删除掉一对键值对 对字典进行排序1234student = [&#123;'name': 'john', 'score': 'B', 'age': 15&#125;, &#123;'name': 'jane', 'score': 'A', 'age': 12&#125;, &#123;'name': 'dave', 'score': 'B', 'age': 10&#125;]sorted(student,key = lambda stu:stu['age']) setset是一个元素不重合的集合。 123456a = set()a.add('0') # 添加元素#遍历集合for e in a: print(e)e.remove('0') # 删除元素 交集，并集，差集1234567s1 = &#123;1,2,3&#125;s2 = &#123;3,4,5&#125;s3 = s1&amp;s2 # 交集，s3 = &#123;3&#125;s4 = s1|s2 # 并集，s4 = &#123;1,2,3,4,5&#125;s5 = s1 - s2 # 差集，s5 = &#123;1,2&#125;# 判断是否是子集s1.issubset(s2) # s1是否是s2的子集 参数组合12345def func(x, y, z=0, *args, **kwargs): pass# 其中x,y为必须传入的参数，z默认参数，# *args 接受无限制的值参数，变为一个list#**kwargs 接受键值参数，最后变成一个dict map1234def square(x): return xa = [1,2,3]map(square,a) # 返回值为[1,4,9] reduce1reduce(lambda x, y: x * y, [1, 2, 3, 4]) # 相当于 ((1 * 2) * 3) * 4 filter1filter(lambda x: x &lt; 'g', 'hijack') # 返回 ac 装饰器12345678def makeitalic(func): def wrapped(): return "&lt;i&gt;" + func() + "&lt;/i&gt;" return wrapped@makeitalicdef hello(): return 'hello world' 即调用hello的时候会提前调用makeitalic，对hello进行装饰。 pdb python调试工具pdb是调试代码的一个工具包，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等。 1234567import pdb a = "aaa"pdb.set_trace() b = "bbb"c = "ccc"final = a + b + c print final 代码在set_trace()处进入暂停，输入n + enter进入下一行，下一次敲回车将重复上一个操作。输入q退出程序。在控制台允许执行print等代码来获取结果。 查看当前位置前后11行的代码。 1l 查看当前所有的代码。 1ll 添加断点： 12b line-numbertbreak line-number # 添加临时断点 清除断点： 12cl # 清除所有断点cl line-number # 清除该行断点 打印变量： 1p expression 逐行调试： 123456n 下一条s 下一行，能进入函数题r 跳过函数体c 跳到下一个断点unt line-number 一直执行到line-numbera 查看函数参数 关于python的相对导入问题python包导入的时候不同的层级关系可以使用.. 或. 来表示上一层目录和当前目录。这种层级关系是通过module中__name__字段来定义的，如下： 123456package/ __init__.py subpackage1/ __init__.py moduleX.py moduleA.py 在这个package的同级目录中调用moduleX.py文件时，该文件__name__就.package.subpackage1.moduleX，因此该moduleX反过来去调用moduleA，可以写作from .. import moduleA 。但是如果在同一个文件目录下执行脚本的话，该文件夹下就会变成top-level script，name就变成了__main__，因此层级结构就会失效。 因此含有这些层级结构的脚本，不允许直接运行，而是需要由外层的文件来间接调用。 python 捕获异常1234567from traceback import print_exctry: if something wrongexcept Exception, e: print 'type is:', e.__class__.__name__ print_exc() # print "exception happened!"]]></content>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Faster RCNN 复现]]></title>
    <url>%2F2019%2F03%2F16%2FFaster-RCNN-%E5%A4%8D%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Faster RCNN是目标检测领域的一个benchmark，具有很好的借鉴意义。Faster RCNN详解介绍了Faster RCNN的网络结构，检测流程，以及一些训练过程等，接下来主要想通过github上的repo来复现一下论文，并在自己的数据集上跑一下结果。 准备环节.so文件：.so文件是Linux下共享库文件，也是ELF格式文件。类似于DLL。.so文件能够节约资源，加快代码速度，方便代码的升级。 .o文件：目标文件,相当于windows中的.obj文件 .a文件：静态库,是好多个.o合在一起,用于静态连接 其中这些共享链接文件与操作系统相关，换一个系统时需要重新生成。 pycocotools:这个文件库的作用是操纵coco数据集的一些api。安装方法如下： 1pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI' 环境的配置参考tensorpack的 readme。将所有环境配置好，以及数据集的格式。 COCO train2017数据标注格式：整个json共有一下几个字段： 1234567&#123; "info": info, "licenses": [license], "images": [image], "annotations": [annotation], "categories": [category]&#125; 其中info,licenses字段表示一些数据集以及证书信息。 images字段表示图片路径信息，有以下几个字段： 1234567891011"images": [ &#123; "license": 4, "file_name": "000000397133.jpg", "coco_url": "/val2017/000000397133.jpg", "height": 427, "width": 640, "date_captured": "2013-11-14 17:02:52", "flickr_url": url, "id": 397133 &#125;, 关键字段为coco_url，即为图片的路径名，id:与annotations字段image_id相对应的一个id。 annotation字段包含以下内容： 123456789annotation&#123; "id": int, "image_id": int, "category_id": int, "segmentation": RLE or [polygon], "area": float, "bbox": [x,y,width,height], "iscrowd": 0 or 1,&#125; image_id:与images字段中id对应，找到图片的真实路径 category_id：images box中的类别信息 segmentation：mask的区域，即多边形区域 bbox：目标boundding box[top left x position, top left y position, width, height] iscrowd：0 or 1，0表示segmentation为RLE格式，1表示其为polygon格式。 将原有标准修改为COCO格式由于源码中大量使用道其他字段，因此基本上都需要补充完整。 源码解析对于大部分的源码思路都可以视为： 准备数据，配置网络，设置holder 设置权重和bias 搭建网络 设置损失函数，设置优化器 step by step训练网络 参数配置1234567import argparseparser = argparse.ArgumentParser()parser.add_argument('--logdir', help='log directory', default='train_log/maskrcnn')...args = parser.parse_args()## 使用print(args.logdir) COCO数据集中有81类，我们使用的数据集仅有两类，因此需要对数据集部分进行修改。]]></content>
      <categories>
        <category>论文复现</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk,grep 学习]]></title>
    <url>%2F2019%2F03%2F16%2Fawk%2Cgrep-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[awk是一个文本解释型语言，在文本处理领域十分的常用。awk的典型用途如： 文本处理 执行算术运算 执行字符串操作 awk的工作流：awk的工作流十分简单：读取-&gt;执行-&gt;重复 read：从标准输入流中读取一行 execute：所有awk执行对文本中每一行都执行处理 repeat：处理过程不断重复，直到文件到达结尾 awk命令行awk的命令行格式为： 1awk [option] afile.py 我们可以使用单引号来指定awk命令，例如： 1awk '&#123;print&#125;' afile.py 以下语句输出数据中第三列和第四列： 1awk -F , '&#123;print $3 "\t" $4&#125;' marks.txt 其中-F设置分割符为,，awk默认分割符号为空格。在使用程序语句如print时，需要加上大括号。其中$3,$4表示数据中的第3列和第4列。$0表示一整行都输出。 以下语句输出匹配字符(不指定输出则输出一整行)： 12awk '/a/' aw.txt # 输出含有a的一整行awk '/a/ &#123;print $1 $2&#125;' aw.txt # 输出含有a的行的1,2列 重定向输出：即将awk的输出，输出到文件中： 1awk '/a/' aw.txt &gt;&gt; new.txt 不显示重复行： 1awk -F , '!seen[$1]++' aw.txt 其中seen可以看成一个字典dict，当没有这个值的时候!seen[$1] == 0,因此允许输出。但当这个值以及存在时，则不输出。 单引号内可以使用各种判断语句： 1awk -F , '$1&gt;$2 &#123;print $0&#125;' aw.txt 例子： 1234567891011121314151617#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）$ awk '&#123;print $1,$4&#125;' log.txt# 指定 , 为分割符（-F），将字符串分割$ awk -F, '&#123;print $1,$2&#125;' log.txt# 多个分割符，先用 空格后用 ,$ awk -F '[ ,]' '&#123;print $1,$2,$5&#125;' log.txt# 设置变量 -v$ awk -va=1 -vb=s '&#123;print $1,$1+a,$1b&#125;' log.txt# 过滤出第一列大于2的数$ awk '$1&gt;2' log.txt # CSV_PATH为输入，TRAIN_PATH为输出 ,-v 为定义变量awk -v min_area=$&#123;MIN_AREA&#125; -F ',' '&#123; area=(($4-$2)*($5-$3)); if(area&gt;min_area)&#123; print $0; &#125;&#125;'&lt;$&#123;CSV_PATH&#125; &gt;&gt; $&#123;TRAIN_PATH&#125; awk参考链接 grepgrep是类unix系统中执行正则表达式的命令 ,下面是grep使用的15个场景： 下面语句判断文件中是否含有搜索的内容： 12grep 'tf' afile.pycat afile.py |grep 'tf' 从多个文件中查找指定字符： 123# 文件夹有 demo_1.txt,demo_2 文件grep 'this' demo_1.txt demo_2.txtgrep 'this' demo_* 忽略大小写(-i)： 1grep -i 'The' demo.txt 在文件中匹配正则表达式： 1grep 'a*b' demo.txt grep -w 完全匹配 12grep -w 'ab' demo.txtgrep -iw 'ab' demo.txt # 不区分大小写 grep显示匹配出的前后几行 123grep -A 3 'a' demo.txt # 显示a出现的行，以及后三行grep -B 3 'a' demo.txt # 显示a出现的行，以及前三行grep -C 3 'a' demo.txt # 显示a出现的行，以及上下三行 用GREP_OPTIONS来让查找的项醒目 1export GREP_OPTIONS='--color=auto' GREP_COLOR='100;8' 用grep -r来搜索所有的文件及子目录 1grep -r 'file' * 显示不匹配的项 1grep -v 'match' demo.txt 匹配多个项 12grep -e '1' -e 'a' -e 'q' demo.txtgrep -v -e '1' -e 'q' demo.txt # 输出一个都不匹配的项 计算匹配的项 12grep -c 'a' aw.txtgrep -v -c 'a' aw.txt # 不匹配的项 显示匹配的文件名: 1grep -l 'a' a* #输出a开头且匹配的文件名 只显示匹配的字符串： 1grep -o 'a.*b' aw.txt # 而不是显示一行 显示匹配字符的行号: 1grep -n 'a' aw.txt 显示匹配字符的字节位置： 1grep -b 'a' aw.txt]]></content>
      <categories>
        <category>tool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vim 学习]]></title>
    <url>%2F2019%2F03%2F13%2FVim-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Vim 简介Vim是在Linux环境下的一种强大的文本编辑工具，之所以学习它，是由于在服务器上写代码需要直接在服务器上操作，不像windows上有那种简单课操作的编辑器，如sublime等等。 Vim 模式Vim与大多数文本编辑器不同，它的默认模式为移动光标，删除文本等，而不是大多数编辑器那样直接为插入模式。 普通模式： 普通模式能进行的操作如移动光标，删除文本等。 删除指令： dd ：删除当前行 d+ 上下左右移动指令，分别表示删除上一行，左一个，下一行，或右一个 2dd: 删除两行 插入模式： 在普通模式按i，或a进入插入模式，ESC推出插入模式。 可视模式： 这个模式类似与普通模式，对样本有高亮 命令行模式： 在命令行模式中可以输入会被解释成并执行的文本。例如执行命令（:键），搜索（/和?键）或者过滤命令（!键） 游标使用：h，j，k，l：分别表示上下左右移动 w: 向下一个单词，b: 向上一个单词 进入插入模式i : 当前光标出插入 A: 当前光标所在行最后一个位置插入 o: 当前光标的下一行插入 a: 当前光标的后一个位置 退出Vim模式:x: 保存并退出，等同于:wq :q!: 强制退出，不保存 :q: 退出不保存 shift + zz: 退出并保存 删除文本普通模式下的删除文本操作。 x: 删除当前光标处的一个字符 X:删除光标前一个字符 dd: 删除整行 dw: 删除整个单词 D: 删除至句尾 d^: 删除至句首 dG: 删除至文章末尾 d1G: 删除至文章开头 重复执行上次命令普通模式下.表示重复执行上一次命令。执行相同执行操作代码：N&lt;command&gt;,如10x,20dd,d5w。 显示行号: :set nu 行间跳跃NG: 游标跳到第N行 gg: 游标跳到第一行 G: 游标跳到最后一行 ctrl + o: 回到上一次跳转的位置 行内跳跃w: 跳到下一个单词的开头 e: 当前单词的结尾 0: 跳到行头 $: 跳到行尾 f 字母：向后搜索字母并跳到第一个该字母的位置 F 字母：向前搜索字母，第一个字母位置 t 字母： 向后搜索字母，并跳到这个字母的前一个数 T 字母： 向前搜索字母，并跳到其后一个数 ~: 将字母大小写转换 文本的复制yy: 复制游标所在的整行 3yy：复制3行 y0: 复制到行首 y$: 复制到行尾 字符替换及坐标操作r + &lt;替换字母&gt;: 替换掉光标所在位置的字母 R： 连续替换，知道按下esc cc: 删掉这一行，换为插入模式 cw: 删掉一个词然后进入插入模式 C: 删除光标位置一直到行末，进入插入模式 u: 撤销当前操作 U: 撤销当前所有操作 指令替换1%s/imgs/car_openimg\/imgs # 使用car_openimg/imgs替换imgs 缩进shift + &gt;: 向右缩进 shift + &lt;: 向左缩进 查找/ + word: 表示查找word，输入n或N查找下一个位置 ? + word: 与上相同，只不过查找方向不同 \*: 查找游标所在位置的单词 g\*： 查找部分符合要求的单词 视窗:new: 新建视窗 :close: 关闭视窗 :q: 同上 执行外部shell命令:! command:执行外部shell 命令 :w filename: 将当前编辑的文件另存为filename vim 确认当前的括号： shift + e: 光标跳到当前内容的第一个框 重复上次操作：小数点 . VIM 打开多个文件12vim 1.py 2.py:bn ## 切换 Vim 行移动1dd,k,p k为向上移动，当移动到合适的位置时用p粘贴。 tabe 多标签切换:tabe a.txt： 打开a.txt 文件 gt: 在多标签中切换 :tabc 关闭标签，或:x等 vim 跳转到变量或函数的定义处12[ ,ctrl+i #跳转ctrl + o : #跳转回来 查找鼠标所在位置的字符：gd]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux trick]]></title>
    <url>%2F2019%2F03%2F13%2Flinux-trick%2F</url>
    <content type="text"><![CDATA[pickle 文件pickle文件的解释如下： It is used for serializing and de-serializing a Python object structure. Any object in python can be pickled so that it can be saved on disk. 即用来将python对象序列化后存放在磁盘上的一个工具包。 Pickling is a way to convert a python object (list, dict, etc.) into a character stream. pickle主要有两个功能，dump 以及load： pickle has two main methods. The first one is dump, which dumps an object to a file object and the second one is load, which loads an object from a file object. dump用来将dict，list等等保存成pickle文件： 12345import picklea = &#123;'a':1,'b':2,'c':3&#125;file = open('pickleObject.pickle','wb')pickle.dump(a,file)file.close() load用来将pickle文件读出来，还原成python object 1234import picklefile = open('pickleObject.pickle','rb')b = pickle.load(file) # b == a is a dictprint(b['a']) linux 操作： 管道命令? 查看文件夹下文件个数： ls -l |grep &quot;^-&quot;|wc -l 写txt文件： 12345a = &#123;'a':1,'b':2,'c':3&#125;f = open('a.txt','w')for key in a.keys(): f.write(key+'\n')f.close() 读txt文件： 123f = open('a.txt','r')for line in f.readlines(): print(line,end = '') assert语句： 在发生错误时让算法崩溃。其用法如下： 1assert expression,'报错语句' 等价于： 12if not expression: raise AssertionError 例子： 1assert type(a_str)== str 读当前文件夹下的文件名： 123import osfor path in os.listdir('./'): print(path) 复制：将文件file1复制到dir1下： 1cp file1 dir1 python 找到最后一个.的位置： 1str.rfind('.', beg=0 end=len(str)) python set操作set 中保存不重复的key。 创建： 1aset = &#123;'apple','orange','pea'&#125; 判断set中是否含有key： 12if 'apple' in aset: pass set集合的交并集操作： 1234a-b # a中包含而b中不包含的元素a|b # a与b的元素并集a&amp;b # a与b中元素的交集a^b # 不同时包含于a与b中元素 Set 删除操作： 1aset.remove('apple') Linux 复制文件夹： 1cp -r dirname . Vim 撤销：u python 在指定文件位置处添加字符后重新保存。 1234567f1.open('a.txt','r')content = f1.read()pos = content.find('word')content = content[:word+4]+'add something'+content[word+4:]f1.close()f2 = open('a.txt','w')f2.write(content) shell 语言用shell写成的文件通常被保存为.sh后缀。被称为脚本Bash的应用程序。 可以理解为在linux电脑上的一系列系统操作，比如下载文件，进入某个文件夹，下载某个文件等等。即可以通过shell程序来指挥kernel，让系统达成我们需要的硬件任务。 示例： 123456789#!/bin/bash# Program:# This program shows "Hello World!" in your screen.# History:# 2015/07/16 VBird First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHecho -e "Hello World! \a \n"exit 0 第一行：#!/bin/bash 作用为宣告这个档案内的语法使用bash的语法，所有的sh文件必须有这一句。其他的# 则表示注释作用。 # 号注释部分：建议你一定要养成说明该script的习惯：1.内容与功能； 2.版本资讯； 3.作者与联络方式； 4.建档日期；5.历史纪录等等 PATH部分为主要的环境变量，用来保存当前的路径信息。 echo那一句为程序的主要执行部分。 使用sh hello.sh 来执行代码。 shell变量： 变量名不加美元符号，而且变量名和等号之间不能有空格。使用变量是在变量名之前加上美元符： 12your_name='zhouwh'echo $your_name 定义只读变量： 123#!/bin/bashmyUrl="http://www.google.com"readonly myUrl # 之后无法修改 删除变量： 1unset variable_name Shell 字符串： 12str='单引号，双引号，不用都行'str="this is \" $your_name \"" #需要转义的情况，双引号里头允许出现 字符串拼接：直接使用双引号即可： 123# 使用双引号拼接greeting="hello, "$your_name" !"echo $greeting 获取字符串长度： 123string="abcd"echo $&#123;#string&#125; #输出 4echo $&#123;string:1:3&#125; # 输出 bcd 子串 控制语句： 12345678910111213141516171819# if 语句if conditionthen command1 command2 ...else commandN fi# for 语句for loop in 1 2 3 4 5do echo "The value is: $loop"done#while语句while conditiondo commanddone awk 语句：awk是一个强大的文本分析工具，简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。其基本的用法如下： 1awk '&#123;[pattern] action&#125;' &#123;filenames&#125; 例子： 1234567891011121314151617181920212223#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）$ awk '&#123;print $1,$4&#125;' log.txt# 指定 , 为分割符（-F），将字符串分割$ awk -F, '&#123;print $1,$2&#125;' log.txt# 多个分割符，先用 空格后用 ,$ awk -F '[ ,]' '&#123;print $1,$2,$5&#125;' log.txt# 设置变量 -v$ awk -va=1 -vb=s '&#123;print $1,$1+a,$1b&#125;' log.txt# 过滤出第一列大于2的数$ awk '$1&gt;2' log.txt # CSV_PATH为输入，TRAIN_PATH为输出awk -v min_area=$&#123;MIN_AREA&#125; -F ',' '&#123; area=(($4-$2)*($5-$3)); if(area&gt;min_area)&#123; print $0; &#125;&#125;'&lt;$&#123;CSV_PATH&#125; &gt;&gt; $&#123;TRAIN_PATH&#125;## 删除第一列awk '&#123;$1="";print $0&#125;' file.txt## 删除第一行awk -F '\t' 'NR==1&#123;next&#125; &#123;print $0&#125;' # 当NR==1时跳过 CSV 文件（Comma Separated Values file，即逗号分隔值文件）为一种纯文本文件。 python 读取csv文件： 1234567import csvwith open('stocks.csv') as f: f_csv = csv.reader(f) headers = next(f_csv) for row in f_csv: # Process row ... python保存csv文件： 1234import csvwith open('some.csv', 'w', newline='') as f: writer = csv.writer(f) writer.writerow([1,2,3,4]) python dict合并： 1merge_dict = dict(dict1.items()+dict2.items()) Python virtualenvvirtualenv`创建一个拥有自己安装目录的环境, 这个环境不与其他虚拟环境共享库, 能够方便的管理python版本和管理python库。 安装： 1pip install virtualenv 创建新环境： 1virtualenv zhou_env 激活： 1source ./bin/activate 退出虚拟环境： 1deactivate matplotlib 画图123456789101112131415161718192021222324import matplotlib.pyplot as pltimport numpy as npimport matplotlibdata = np.array([1,2,3,4,5,6,7,8,1,1,1,1,1])print(type(data))"""绘制直方图data:必选参数，绘图数据bins:直方图的长条形数目，可选项，默认为10normed:是否将得到的直方图向量归一化，可选项，默认为0，代表不归一化，显示频数。normed=1，表示归一化，显示频率。facecolor:长条形的颜色edgecolor:长条形边框的颜色alpha:透明度"""plt.hist(data, bins=40, normed=0, facecolor="blue", edgecolor="black", alpha=0.7)# 显示横轴标签plt.xlabel("区间")# 显示纵轴标签plt.ylabel("count")# 显示图标题plt.title("bbox—count")plt.savefig('aimg.jpg')plt.show() 文件传输rz: 在iterm2中输入rz指令，将会出现一个窗口选择文件，开始上传到当前文件夹。 sz filename: iterm2 弹出一个窗口，选择保存文件的地址。 vim 隐藏到后台：ctrl + z 命令行调出vim：fg linux看文件大小： 12ls -lshdu -sh * 打包文件压缩：tar czvf file.tar ./filename,czvf表示create zip view file解压缩：tar xzvf file.tar，xzvf表示extract zip view file 过滤数据集中不合适的记录 找出不合适的记录： 1cat all_box.csv | grep '不合适记录名' # grep拿cat的输出当作输入 维护一个delete_imgs.txt 文件，用来存放不合适记录 使用delete_imgs.txt 文件中不合适记录来查看all_box.csv(数据集)中不合适的记录。 1grep -f delete_imgs.txt all_box.csv 删掉不合适记录，得到合适记录的输出，将输出存成一个新的new_box 1grep -v -f delete_imgs.txt all_box.csv &gt; new_box.csv 查看剩下的合适条数： 1cat new_box.csv |wc -l # -l 行数 -w 字数 命令行输出1cat *.csv &gt; all_box.csv awk判断字段1不重复的记录数： 1awk -F ',' '!seen[$1++]' train_set.csv |wc -l linux 查看显卡运行状态： 1nvidia-smi python shuffle操作shuffle操作将数据集打乱： 123import randomlist = [1,2,3]random.shuffle(list) tmux: tmux 可以在终端软件重启后通过命令行恢复上次的 session ,即当你训练网络中断时，下次开启仍然可以重新连接。 1234567tmux ls # 列出所有的tmux会话tmux new -s zhouwenhui # 创建新的会话tmux -2 attach -t zhouwenhui # 重新进入原来的sessionctrl + b , d # 暂时退出当前会话ctrl + b , c # 新建窗口ctrl + b , w # 切换窗口exit # 退出当前窗口 Linux创建账号123useradd zhouwhpasswd zhouwhuserdel [-r] zhouwh # 删掉用户 Linux 给用户赋予root权限 vim /etc/passwd 文件，找到新创建的用户所在行，把用户ID修改为 0即可，如下。 zhouwh​：x:0:1002::/home/zhouwh:/bin/bash Linux用户切换新建的用户的目录在/home/zhouwh底下，使用如下语句可以实现自由的切换。 12su - zhouwh # 切换到zhouwh 用户su - root # 切换到root 用户 Linux 安装anaconda在anaconda上下载相应版本的安装软件，然后执行以下操作： 1234bash Anaconda3-4.4.0-Linux-x86_64.sh ## 安装echo 'export PATH="~/anaconda3/bin:$PATH"' &gt;&gt; ~/.bashrc# 环境变量conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 国内镜像rm -rf anaconda # 卸载 Json 的读写123456# Writing JSON data:&#123;'a': 'Runoob', 'b': 7&#125;with open('data.json', 'w') as f: json.dump(data, f)# Reading data backwith open('data.json', 'r') as f: data = json.load(f) dict to json12with open('data.json','w') as f: json.dump(data,f) 打开文件头几行/末尾几行12cat afile.txt|head -n 100cat afile.txt|tail -n 100 指定运行的GPU1CUDA_VISIBLE_DEVICES=1,2 python train.py 实时显示GPU使用率1nvidia-smi -l 1 执行程序时滚动屏幕1ctrl+b 之后 + [ .bashrc基于linux/unix的系统一般情况下都将 bash 作为默认的终端 shell。因此可以通过修改 bashrc 配置文件对执行的命令进行一些自定义。 .bashrc是一个纯文本文件，用于保存和加载不同用户的终端首选项和环境变量,bash 在每次启动时都会自动载入 bashrc 配置文件中的内容。每次修改.bashrc文件后使用source ~/.bashrc进行环境的激活。 终端首选项：最常用的一种方式为为linux系统命令定义别名，方便定制输入。 环境变量：Linux是一个多用户操作系统，可以在linux中为不同的系统定制不同的环境变量。 环境变量的设置环境变量可以分为系统环境变量和用户环境变量。 系统环境变量：系统变量的设置将对所有的用户均生效。 对/etc/profile文件添加环境变量将对所有用户均有效。例如添加CLASSPATH变量。 12vim /etc/profile export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib 用户环境变量在用户目录下修改文件.bash_profile,改变的量仅对该用户有效。如下： 12vim ~/.bash.profileexport CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib 直接在命令行运行：export 变量名=变量值仅对当前的shell有效。 .bashrc,profile,.bash.profile 的区别 Linux 中常见的环境变量PATH：指定命令的搜索路径,中间用冒号隔开。 1PATH=&lt;PATH1&gt;:&lt;PATH2&gt;:&lt;PATH3&gt;:&lt;PATH4&gt; 在配置文件中修改PATH： 1export PATH='~/anaconda3/bin/:$PATH' HOME：指定用户的主工作目录 HISTSIZE：指保存历史命令记录的条数 LOGNAME：指当前用户的登录名。 HOSTNAME：指主机的名称 SHELL：指当前用户用的是哪种Shell LANG/LANGUGE：和语言相关的环境变量 Linux 查看环境变量 echo 显示某个环境变量值 echo $PATH export HELLO=”hi” 设置新的环境变量 env 显示所有环境变量 linux 创建快捷键1alias ict="ssh xxx@ictvr.ml -p 11111" Linux 打印出目录下文件决定路径1for f in 'ls cat';do echo '/data/cartoon_detect_data/'$f;done &gt; total.txt python 查看文件大小1ls -lht 下载视频runonce服务器上,sh tmp.sh,/root/cartoon_data_prepare，其中需要视频id，从表格中读取。 linux截取字符串前n个字符1cut -c1-100 file.py # 前100个字符 linux shell判断外部传入的参数12345678910#!/bin/bashif [ ! -n "$1" ] ;then # 判断是否有个参数 echo "you have not input a word!"else echo "the word you input is $1"fi## if [-e "$1"] ; then #判断传入的参数是否是个文件/目录 linux 批量更改文件名1rename 's/search/replace/;' test*.jpg linux awk复制文件1awk -F ',' '&#123;print $1&#125;' ~/zhouwenhui/mAP/test_set.csv| while read day ; do cp "$day" "./aaa"; done 创建软链接1ln -s a/path to/soft_path soft_path为软链接。 linux 批量删除文件1rm -rf PAD8_*.jpg 传输大文件mac上通过rz,sz与服务器之间传输文件，由于文件过大（百兆）容易导致内存不足。因此需要先将文件拆分后一个一个上传（下载）。 12345split -b100k ev.zip ev # 将ev.zip文件分成每个文件100k的小文件，由ev开头，如evab ...md5sum ev.zip # 查看原文件的md5值sz ev* # 将小文件依次下载cat ev* &gt; ev.zip #本地将所有小文件还原md5sum ev.zip #查看还原文件的md5值，是否之前相同 查看后台进程1ps aux 杀死进程当执行一个多线程的任务的时候，使用 ctrl+z停止进程，然后根据进程的id号，依次杀死进程。]]></content>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow 笔记（CNN分类器VI）]]></title>
    <url>%2F2019%2F03%2F13%2FTensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88CNN%E5%88%86%E7%B1%BB%E5%99%A8VI%EF%BC%89%2F</url>
    <content type="text"><![CDATA[CNN分类网络CNN网络在原来网络的基础上加入了卷积层，对特征进行提取后分类，能够提升网络的分类准确率，同时在网络中加入了dropout，缓解网络的过拟合。 写一个分类器的基本思路如下： Assemble graph: read data create placeholder create weight and bias in a layer create a net structure specify loss function create optimizer train model: specify the epochs,iteration,batch-size initial variables step by step run the optimizer（use feed_dict to feed data into x,y placeholder） tf.Session() encapsulates the environment 对于mnist分类来说，需要注意的是，我们将输入向量的大小设置成28*28*1的形式，然后通过卷积进行操作。如下： 12xs = tf.placeholder(tf.float32,[None,784])x_image = tf.reshape(xs,[-1,28,28,1]) # [nsample,width,height,channel] 对于卷积层tensorflow中使用tf.nn.conv2d来创建。该函数的参数如下： 12345tf.nn.conv2d(input,W,stride,padding)# input表示输入的参数# filter:W表示卷积核的参数即：[kernel_w,kernel_h,in_channel,out_channel]# stride表示步长：[1,x_move,y_move,1]# padding = 'SAME' / 'VALID' 卷积后大小不变 / 卷积后大小变小 创建一个卷积层： 1234567def conv2d(x): # conv weight: [kernel_w,kernel_h,in_channel,out_channel] Weights = tf.truncated_normal([5,5,1,32],stddev = 0.1) bias = tf.constant(0.1,[32]) # stride = [1,x_move,y_move,1] output = tf.nn.conv2d(x,Weight,[1,1,1,1],padding = 'SAME') return output+bias 对于池化层，tensorflow中使用的函数tf.nn.max_pool，该函数的参数如下： 12345tf.nn.max_pool(input,ksize,stride,padding)# input为输入的数据# ksize:表示卷积核大小，[1,kernel_w,kernel_h,1]# stride: [1,x_move,y_move,1]# padding = 'SAME' / 'VALID' 创建一个max pooling 层: 12def max_pooling(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides = [1,2,2,1],padding = 'SAME') dropout层： 1234tf.nn.dropout(x,keep_prob = 0.5)# x: 输入的向量# keep_prob：dropout的比例# keep_prob通常是一个tf.placeholder,在训练时设为一个小数，在测试时设为1 完整代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import osos.environ['KMP_DUPLICATE_LIB_OK']='True'import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# load datamnist = input_data.read_data_sets('MNIST',one_hot=True)# create placeholderwith tf.name_scope('input'): xs = tf.placeholder(tf.float32,[None,784])/255. ys = tf.placeholder(tf.float32,[None,10]) keep_prob = tf.placeholder(tf.float32) # dropout rate x_image = tf.reshape(xs,[-1,28,28,1]) # nsample,28,28,channelwith tf.name_scope('conv1'): Weights = tf.Variable(tf.random.truncated_normal([5,5,1,32],stddev=0.1)) bias = tf.Variable(tf.constant(0.1,shape = [32])) out_conv1 = tf.nn.conv2d(x_image,Weights,[1,1,1,1],padding='SAME')+bias # 28,28,32with tf.name_scope('pool1'): out_pool1 = tf.nn.max_pool(out_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') # 14,14,32with tf.name_scope('conv2'): Weights = tf.Variable(tf.random.truncated_normal([5,5,32,64],stddev=0.1)) bias = tf.Variable(tf.constant(0.1,shape = [64])) out_conv2 = tf.nn.conv2d(out_pool1,Weights,[1,1,1,1],padding='SAME') #[14,14,64]with tf.name_scope('pool2'): out_pool2 = tf.nn.max_pool(out_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')#[7,7,64] out_pool2 = tf.reshape(out_pool2,[-1,7*7*64]) # nsample,7*7*64with tf.name_scope('fc1'): Weights = tf.Variable(tf.random.truncated_normal([7*7*64,1024],stddev=0.1)) bias = tf.Variable(tf.constant(0.1,shape = [1024])) out_fc1 = tf.nn.relu(tf.matmul(out_pool2,Weights)+bias) drop_out_fc1 = tf.nn.dropout(out_fc1,keep_prob) # nsample,1024with tf.name_scope('fc2'): Weights = tf.Variable(tf.random.truncated_normal([1024,10],stddev=0.1)) bias = tf.Variable(tf.constant(0.1,shape=[10])) prediction = tf.matmul(drop_out_fc1,Weights)+bias # nsample,10# create running environmentsess = tf.Session()## compute accuracydef compute_accuracy(X,Y): pred = sess.run(prediction,feed_dict=&#123;xs:X,keep_prob:1&#125;) correct = tf.equal(tf.argmax(pred,1),tf.argmax(Y,1)) accuracy = tf.reduce_mean(tf.cast(correct,tf.float32)) return sess.run(accuracy)# losswith tf.name_scope('loss'): loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys))with tf.name_scope('optimizer'): optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)#initializationinit = tf.global_variables_initializer()sess.run(init)# visualizationwriter = tf.summary.FileWriter('./log',sess.graph)# trainfor step in range(1000): x_batch,y_batch = mnist.train.next_batch(100) sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch,keep_prob:0.5&#125;) if step%50 == 0: print(compute_accuracy(mnist.test.images[:1000],mnist.test.labels[:1000])) Tensorflow 保存变量12345678910import tensorflow as tfw = tf.Variable([[1,2],[3,4]],dtype = tf.float32,name = 'weight')b = tf.Variable([[1,2,3]],dtype = tf.float32,name = 'bias')init = tf.global_variables_initializer()saver = tf.train.Saver()with tf.Session() as sess: sess.run(init) save_path = saver.save(sess, "my_net/save_net.ckpt") print("Save to path: ", save_path) 提取变量restore12345678910111213import tensorflow as tf# 先建立 W, b 的容器W = tf.Variable(np.arange(6).reshape((2, 3)), dtype=tf.float32, name="weights")b = tf.Variable(np.arange(3).reshape((1, 3)), dtype=tf.float32, name="biases")# 这里不需要初始化步骤 init= tf.initialize_all_variables()saver = tf.train.Saver()with tf.Session() as sess: # 提取变量 saver.restore(sess, "my_net/save_net.ckpt") print("weights:", sess.run(W)) print("biases:", sess.run(b))]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SSD M2Det 详解]]></title>
    <url>%2F2019%2F03%2F10%2FSSD-M2Det-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[SSD是经典的one-stage算法，可以认为是关于类别的多尺度分类网络，作为很多one-stage网络的基础框架，有必要阅读一下。 M2Det是今年（2019）CPVR论文，基于SSD框架的扩展，M2Det 若采用 single-scale inference 可达到 11 FPS, AP 41 的准确率，采用 multi-scale inference 可达到 AP 44.2 的准确度。 SSD 详解 SSD: Single Shot MultiBox Detector submit time：2015 arxiv link 网络的背景及作用当前网络通过提取候选框等方式进行目标检测，运行速度对于一些应用场景来说太慢了。 SSD是一种使用单个深度神经网络来检测图像中的目标的方法，SSD 速度的根本改进来自消除边界框proposal和随后的像素或特征重采样阶段。他的主要特点如下： one-stage检测器，用于多个类别目标检测，比先前技术相比（YOLO）速度更快，且更准确。 SSD方法的核心是使用小卷积滤波器来预测特征图上固定的一组默认边界框的类别分数和位置偏移。 为了实现高检测精度，我们从不同尺度的特征图产生不同尺度的预测，并且通过宽高比来明确地分离预测。 这些设计特性得到了简单的端到端训练和高精度，进一步提高速度和精度的权衡，即使输入相对低分辨率图像。 网络结构 SSD的检测过程如下： SSD输入为包含类别以及真实框标记的图片数据。 卷积处理时，我们在具有不同尺度（例如（b）和（c）中的8×8和4×4）的若干特征图中的每个位置处选择不同横宽比的小集合（例如4个）默认框。 对于每个默认框，我们预测对所有对象类别（c 1，c2，…，cp）的形状偏移和置信度。在训练时，我们首先将这些默认框匹配到真实标签框。 例如，两个默认框匹配到猫和狗，这些框为正，其余视为负。 模型损失是位置损失（例如平滑L1 [6]）和置信损失（例如Softmax）之间的加权和。 SSD方法基于前馈卷积网络，采用多尺度特征度检测的方式，产生固定大小的边界框集合和框中对象类别的分数，接着是非最大化抑制步骤以产生最终检测,如下图： 输入：300x300 经过VGG-16（只到conv4_3这一层，由于更深的网络特征难以恢复） 经过几层卷积，得到多层尺寸逐渐减小的feature map 每层feature map分别做3x3卷积，每个feature map cell对应k个类别和4个bounding box offset，同时对应原图中6（或4）个anchor，即每一个位置将会预测4或6个anchor，然后每个anchor有k个类别概率值以及4个位置偏移值。 38x38层, 最后3x3层, 1x1层三个feature map的每个feature map cell只对应4个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，其他feature map的feature map cell对应6个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，1:3， 3:1两种。因此总共有$$38* 38*4+19*19*6+10*10*6+5*5*6+3*3*4+1*1*4=8732$$个anchor。 anchor的中心：每层的feature map cell对应的anchor中心的计算方法如下$$(\frac{i+0.5}{|fk|},\frac{j+0.5}{|fk|})$$其中i,j是当前的位置，fk是当前feature map的大小。 anchor缩放因子:$$S_k = S_{min}+\frac{S_{max}-S_{min}}{m-1} (k-1),k\in[1,m]$$ 缩放因子指不同大小的feature map对应不同大小的anchor。m表示最终有m个 feature maps将要作为预测,对每一个k层的feature map计算其anchor的大小，即$ S_k$。 此外$S_{min}$ 为 0.2，$S_{max}$ 为 0.9。因此对于所有层，scale都在[0.2,0.9]之间。 对于每一个尺度，都可以计算其相应的anchor大小，如下：$$\begin{align}w_k^{\alpha} &amp;= S_k \sqrt{\alpha_r} \\h_k^{\alpha} &amp;= S_k \sqrt{\alpha_r}\\\alpha \in &amp;{1,2,3,\frac{1}{2},\frac{1}{3}}\end{align}$$特别的，当 $a_r=1$ 时，增加一种 $s_k = \sqrt{s_{k-1}{s_{k+1}}}$ ，对应6种anchor的长宽比，对于4个anchor来说，不使用3和$\frac{1}{3}$。 网络损失函数SSD的损失函数由两部分组成，分别是置信度损失（softmax loss)以及位置损失（L1 loss），如下：$$L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))$$其中N是匹配的GT框个数，当N = 0时loss等于0。$\alpha$是置信度与位置loss之间的一个权衡因子。 对于置信度loss ：$$L_{conf}(x,c) = - \sum_{i\in Pos}^N x_{ij}^p log(\hat{c}_{i}^p) - \sum_{i\in Neg} log(\hat{c}_{i}^0)\quad where \quad\hat{c}_{i}^p=\frac{exp^{c_{i}^p}}{\sum_p exp(c_{i}^p)}$$即softmax的交叉熵loss。 位置损失如下：$$\begin{align}L_{loc}(x,l,g)&amp;=\sum_{i\in Pos}^N \sum_{m \in {cx,cy,w,h}}x_{ij}^k smooth_{L1}(l_i^m-\hat{g}_j^m) \\\hat{g}_j^{cx}&amp;=(g_j^{cx}-d_i^{cx})/d_i^w \quad \hat{g}_j^{cy}=(g_j^{cy}-d_i^{cy})/d_i^h\\\hat{g}_j^{w}&amp;=log(\frac{g_j^w}{d_i^w})\quad \hat{g}_j^{h}=log(\frac{g_j^h}{d_i^h})\end{align}$$其中g表示GT的边框中心，d表示预测的边框的中心，该loss与Faster RCNN的loss 相同。即我们去学习的是边框的偏移量，而不是直接预测边框。当预测值l与g的指标相同时即完成，反向可推导出目标的边框。 样本选择正样本：预测框与GT的重叠程度大于0.5的认为是正样本 副样本：将边框置信度排序，找出置信度高的边框，保持正负比例为1:3. train trick SSD使用了诸如数据增强，空洞卷积等操作，是的进度进一步提升。 数据增强的方式为： 整图输入 截取图上一部分进行输入 随机crop 将上面的图片都resize到一个固定大小，输入网络 MS COCO上的精度SSD在coco上的精度如下： M2Det 详解M2Det是一个one-stage的目标检测网络。基于SSD框架扩展而来。主要的思想是Multi-Level Feature Pyramid Network(MLFPN)，多层次的特征金字塔网络。 网络的背景及应用论文中提出物体分类和物体检测问题上的缩放尺度变化矛盾，即物体分类模型提取高层次的特征，高层次的特征往往更容易学到具有辨别力的信息，模型会专注于一些辨认力强的点，例如鸟🐦，倾向于检测翅膀。 但是由于物体检测问题需要将整个物体框起来，仅仅识别出有辨别力的点无法保证完全把目标框起来，因此作者提出使用浅层的特征来辅助学习目标的检测任务，即确定边框位置。 因此高阶的特征有助于分类，低价的特征有助于物体的检测。 作者提出，通常解决尺度变化的问题采样的方法是从输入图像提取出的特征金字塔，从而克服原始图片的缩放问题。该方法可以同时用于训练和测试阶段中，相对开销较小，易于集成，适合end-to-end。本文的目的即是构造一个更加高效的金字塔模型用于检测不同缩放大小的对象。作者将该结构加入到SSD中去，取得了超过benchmark的成绩。 网络结构作者通过对比多种金字塔特征提取方式，总结了这些模型的确定，并提出自己的特征提取方式。 先前模型的缺点： 先前的模型都是基于分类网络作为特征提取的主干网络，对目标检测任务而言，先前金字塔结构提取的特征表达不足以预测目标位置。即特征太少。 每个feature map仅由主干网络的single level给出，仅含单层信息不够全面。 SSD型：使用了主干网络的最后两层，再加上4个使用stride=2卷积的下采样层构成； FPN型：也称为U型网络，经过上采样操作，然后对应融合相同的scale； STDN型：基于DenseNet的最后一个dense block，通过池化和scale-transfer操作来构建； MLFPN型：Multi-level&amp;Multi-scale MLFPN结构如下，对主干网络(vgg)提取到的特征进行融合；然后通过TUM和FFM提取更有代表性的Multi-level&amp;Mutli-scale特征；最后通过SFAM融合多级特征，得到多级特征金字塔用于最终阶段的预测。 FFMv1FFMv1整合了VGG网络中浅层conv4_3的特征以及深层conv5_3的特征作为base feature（从Figure1中可以看出）。其结构如下所示，先进行一个1*1的卷积压缩channel，然后upsample到相同的大小，进行如何得到base feature。 ###TUM TUM的结构是一个U-Net的结构，如Figure1所示。他的内部结构如下： TUM结构输出的左右feature map均输入SFAM中，同时将最大一个feature map(128,40,40)传入FFMv2中作为下一次TUM的输入。 FFMv2FFMv2输入为base feature与上一层最大的feature map结构如下： 通过堆叠TUM以及FFMv2产生不同层次的feature map，最终分别提取出图片的shallow，medium，deep的特征。每个TUM以及FFMv2的输出特征计算如下： 尺度特征聚合模块SFAMSFAM负责将每个金字塔的输入聚合起来，得到Multi-level feature pyramid。然后输出值prediction layer。 每个TUM都会输出一个六层的特征金字塔，SFAM首先对每一层相同channel的特征进行融合。第二步采用SENet的方法，即是透过 Fully-connected layer 来学习每个 feature 应该给多少权重。最终 prediction layer 会接受的是 i 个不同尺度的 Feature maps。 模块配置 M2Det 网络采用VGG-16和ResNet-101作为特征提取的主干网络。 MLFPN的默认配置包含有8个TUM，每个TUM包含5个跨步卷积核5个上采样操作，输出为6个不同scale的特征。 在检测阶段，为6组金字塔特征每组后面添加两个卷积层，以分别实现位置回归和分类。 后处理阶段，使用soft-NMS来过滤无用的包围框。 网络损失函数网络的顺势函数沿用了SSD的方法，即置信度softmax损失以及边框回归损失。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[data training tip]]></title>
    <url>%2F2019%2F03%2F08%2Fdata%20training%20tip%2F</url>
    <content type="text"><![CDATA[Json 文件格式切换数据集中Json文件挤在一堆，需要将其格式化输出，Json文件格式化代码如下： 1234567import jsonjson.dumps(&#123;'a': 'Runoob', 'b': 7&#125;, sort_keys=False, indent=4, separators=(',', ': '))# 输出如下：#&#123;# "a": "Runoob",# "b": 7#&#125; 文件改写实现代码如下： 12345import jsonwith open('../dataset/train_round1/train_no_poly.json', 'r') as fin: js = json.load(fin) with open('train_no_poly.json', 'w+') as fout: json.dump(js, fout,sort_keys=False, indent=4, separators=(',', ': '),ensure_ascii=False) Json 处理字符串读写和文件读写： 处理字符串：json.loads(fileDir)得到字符串，json.dumps(dataDict)得到Json文件。 处理文件： 123456# Writing JSON datawith open('data.json', 'w') as f: json.dump(data, f)# Reading data backwith open('data.json', 'r') as f: data = json.load(f) MAC git 使用安装Git：链接 验证是否成功链接远程github：ssh -T git@github.com，如果正确返回 hi wenhui-zhou. 提交本地项目到GitHub上： 在GitHub网站上创建一个仓库 复制其clone 链接，将仓库clone到本地: git clone git@github.com:WenHui-Zhou/learnGit.git 打开learnGit文件夹，将工程文件保存在这个目录下 提交修改，将工程上传到GitHub上 git add fileName：在仓库目录下，将文件添加到本地仓库。 git add . ：将所有文件添加到本地仓库。 git commit -m &quot;some comments&quot;：添加评论。 git push：上传到远端仓库。 github 更新文件 git status：查看仓库状态，如果有所不同的话，会显示不同的文件。 git add file：将更改的文件加入到本地仓库。 git commit -m &quot;comment&quot;：添加评论。 git push：将代码提交到GitHub上。 git getch当与人协作时，远程主机有了更新，可以通过git fetch 来取得更新的内容。 git fetch origin master:tmp，在本地创建一个tmp分支，将远程master 分支的代码下载到tmp分支上。 git diff tmp，比较本地代码与从远端下载下来的代码的区别。 git merge tmp，合并分支到本地的master。 git branch -d tmp，如果不想要tmp分支的话，则可以删除。 git pullgit pull：将远端代码与本地代码直接融合，等于上面的git fetch + git merge。 git push将本地更新的分支推送到远程主机。因此我们每次进行远端数据的更新操作之前需要更新一下本地的分支。即： 123git add .git commit -m "comment" // 在本地分支上添加文件并添加评论git push // 将远端分支进行更新 fork在GitHub上点击fork将其他用户的仓库更新到自己的GitHub下，然后进行clone到本地，进行一些工程上的修改。这个库当前属于你，照样执行上面的git push等操作。完成后在GitHub上发起pull request，然后系统会对比两个工程的修改之处，然后发起request，在其他用户那边将会多一个request操作，可以同意，则进行merge。 同步fork的库与原始的库使用指令如下： 1234git remote add //添加本地库git fetch // 将远端的不同fetch到本地git merge // 融合git push // 更新到自己的GitHub上 iteration、epoch、batchsize的含义 epoch：数据集所有数据训练过一遍为一个epoch，类似于一本书，epoch为几就是要看几遍。 batch-size：一次迭代（更新参数）所使用的数据数量。类似于书中每个章节。 iteration：总共的迭代次数，一次迭代所用的数据为一个batch-size，即一次看一章。因此迭代的次数为dataset/batch-size，每本书看epoch次，因此iteration = epoch * (dataset/batch-size)。 python dict的用法12345678adict = &#123;'a':1,'b':2,'c':3&#125; #创建dict(zip(['a', 'b', 'c'], [1, 2, 3])) print(adict['a']) # 访问adict['a'] = 2 # 修改adict.pop('a') # 删除adict.get('a') # 如果没有这个key返回Nonefor key,values in dict.items(): # 同时获得key和val print(key,values) python 中的类12345678910111213141516class Student(object): # 继承object # 数据成员 def __init__(self,name,score): # 类函数的第一个参数固定为self self.name = name self.score = score ## 私有成员,变量名前加上两个下划线__,只能类函数内部访问 self.__name = name # 方法成员 def getname(self): return self.name def getscore(self): return self.score#创建对象stu = Student('xiaoming',100)print(stu.getname())stu.sex = 'man' # 外部添加数据变量 继承和多态12345678910111213141516171819class Animal(object): def run(): print('animal is runing')class cat(Animal): passacat = cat()acat.run() # 调用父类的run函数class cat(Animal): def run(): print('cat is runing')acat.run() # 执行自己的run函数#多态def runrun(animal): animal.run()# 调用runrun(animal) # animal类runrun(cat) # animal 子类runrun(aman) # 类中含有run()的类也可以 property属性12345678910111213class Student(object): @property def socre(self): # 把socre变成一种数据属性，对象可以直接赋值 return self._score @birth.setter def score(self, value):# 对于score赋值的规则限制，在setter里头 if value&gt;100: raise ValueError('score must between 0 ~ 100!') self._score = value# 调用s = Student()s.score = 100print(s.score) classmethod 类12345678910 class A(object): bar = 1 def func1(self): print ('foo') @classmethod def func2(cls): # 方法类必须使用cls作为参数，不需要初始化 print ('func2') print (cls.bar) cls().func1() # 调用 foo 方法A.func2() # 不需要实例化 staticmethod12345 class A(object): @staticmethod def func2(): # 静态方法，对参数没有要求 print ('func2')A.func2() # 不需要实例化 下载单个文件夹在github上进入该文件夹所在的目录，复制文件夹链接： https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN 随后在服务器上输入： 1svn checkout https://github.com/tensorpack/tensorpack/trunk/examples/FasterRCNN]]></content>
      <categories>
        <category>比赛</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLO V2,V3详解]]></title>
    <url>%2F2019%2F03%2F08%2FYOLO-V2-V3%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[YOLO V2,YOLO V3是基于YOLO V1 的基础上，对网络进行改进，使得mAP，检测精度提升，同时仍保持较快的检测速度。本文将详细介绍V2，V3的特点。 YOLO V2 详解 YOLO9000: Better, Faster, Stronger submit time: 2016 arxiv link YOLO V2 在保持与V1基本框架相同的情况下，对网络进行了各种调优，主要做的修改如下： batch normBatch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。 high resolution classifier当前大部分网络的预训练模型都是在ImageNet上224*224大小的图片上进行fintune的，YOLO V2首次用448*448大小的图片对分类网络进行fintune（10 epoch），使用高分辨率分类器后，YOLOv2的mAP提升了约4%。 Convolutional With Anchor BoxesYOLOv1直接对目标进行边框预测，由于目标的尺度变换范围很大，导致了YOLOv1在精确定位方面表现较差。YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框。YOLOv2借鉴了Faster R-CNN中RPN网络的先验框策略。RPN对CNN特征提取器得到的特征图（feature map）进行卷积来预测每个位置的边界框以及置信度（是否含有物体）。 YOLOv2采用 416 * 416大小的图片作为输入。下采样的总步长为 32，对于 416*416大小的图片，最终得到的特征图大小为13*13，维度是奇数，这样特征图恰好只有一个中心位置。对于一些大物体，它们中心点往往落入图片中心位置，此时使用特征图的一个中心点去预测这些物体的边界框相对容易些。YOLO V2每个cell与yolov1类似，都分别去预测目标的IoU，以及每个框的类别预测值。使用anchor之后精度有点下降，但是YOLO V2的召回率（预测为真的占GT中真的比例）大大提升。原因是使用了anchor每张图片预测的边框数大大提升。 Dimension Clusters在预测边框时传统的如Faster RCNN使用的是手工设置边框大小，yolov2中采用kmeans聚类的方法，选用box与聚类中心box之间的IOU值作为距离指标，即离的则认为是那一类，作者选择了五个先验框作为聚类中。 New Network: Darknet-19YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。 Direct location predictionyolov2 采用不同于RPN的边框回归的方法，yolov2回归的目标是预测边界框中心点相对于对应cell左上角位置的相对偏移值。 yolov2为每个cell预测5个bounding box，为每个bounding box预测五个坐标值，使用如下的公式进行边框的回归。 结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。 Multi-Scale Training由于YOLOv2模型中只有卷积层和池化层，为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔一定的iterations之后改变模型的输入图片大小。YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值. YOLO V2 训练YOLOv2的训练主要包括三个阶段。 第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224 * 224 ，共训练160个epochs 第二阶段将网络的输入调整为 448*448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs 第三个阶段就是修改Darknet-19分类模型为检测模型，并在检测数据集上继续finetune网络 其网络结构为：链接 YOLO V3 YOLOv3: An Incremental Improvement Submit time: 2018 arxiv link YOLO V3在速度和精度上比YOLO V2有了很大的提升，同时网络结构也复杂了不少，通过改变网络来权衡速度和精度。YOLO V3 的主要改进如下： Darknet-53YOLOV3作者使用了Darknet 53作为特征提取网络， Darknet 53是一个在Imagenet.做预训练的网络，YOLOV3 共有106 fully convolutional 。因此在速度上较YOLOV2慢一些。网络结构如下： Detection at three Scales 多尺度预测v3最显着的特点是它可以在三种不同的尺度上进行检测（32，16，8）。YOLO是一个完全卷积网络，通过在网络中的三个不同位置处应用1 x 1内核进行预测，每个尺度均预测三个边框，每一个边框的参数为$N ×N ×[3∗(4+1+80)] $，4表示边框的偏离值，1表示目标预测，80表示共80个类别。 多尺度的检测很好的客服了小物体的预测问题。 No more softmaxing the classes作者使用sigmoid函数代替原来的softmax。由于softmax函数存在一个先验假设，即一个物体只能属于一个类别，这种假设在COCO集合上不成立。例如一个目标同时属于person和women，因此作者选择了sigmoid。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 笔记（分类器 III）]]></title>
    <url>%2F2019%2F03%2F08%2FTensorFlow-%E7%AC%94%E8%AE%B0%EF%BC%88%E5%88%86%E7%B1%BB%E5%99%A8-III%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇文章详细的从头到尾实现一下mnist分类器。 综述建立一个mnist数据集的数字分类器，需要做的主要有， 从数据集中下载数据。 添加网络层（参数为，输入，输入size，输出size，激活函数）， 定义输入数据的placeholder，构建网络结构，定义层。 定义loss，优化器. 定义计算精度的函数 定义train过程，以及精度的输出过程 读取数据123import tensorflow as tffrom tf.examples.tutorials.minst import input_datamnist = input_data.read_data_sets('MNIST',one_hot = True) 添加网络层123456789def add_layer(input,in_size,out_size,activation_Function=None): Weights = tf.Variables(tf.random.normal([in_size,out_size])) bias = tf.Variables(tf.zeros([1,out_size])+0.1) Wx_add_b = tf.matmul(input,Weights)+bias if actication_Function is None: outputs = Wx_add_b else: outputs = activation_Function(Wx_add_b) return outputs 构建网络结构网络为三层网络，一个输入层，一个隐藏层，一个输出层。均为全连接。 123xs = tf.placeholder(tf.float32,[None,784])ys = tf.placeholder(tf.float32,[None,10])prediction = add_layer(xs,784,10,None)#仅有一层 Loss，优化器分类问题的损失通常选用交叉熵，优化器可以选用SGD来优化。 123loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction,labels = ys)optimizer = tf.train.GradientDescentOptimizer(0.2).minimize(loss)sess = tf.Session() 计算精度这里要算的数据是预测值与GT之间的差。数据格式为one-hot类型，因此计算步骤先判断每一行是否相等，然后去平均即可,传入的数据为测试集数据。 123456def computeAccuracy(xtest,ylabel): pred = sess.run(prediction,feed_dict=&#123;xs = xtest&#125;) correct = tf.equal(tf.argmax(pred,1),tf.argmax(ylabel,1)) accuracy = tf.reduce_mean(tf.cast(correct,tf.float32)) result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;) return result train 过程使用batch-size SGD的方式进行训练更新： 1234567init = tf.global_variables_initializer()sess.run(init)for step in range(1000): x_batch,y_batch = mnist.train.next_batch(100) sess.run(opertimizer,feed_dict = &#123;xs:x_batch,ys:y_batch&#125;) if step%50 == 0: print(computeAccuracy(mnist.test.images,mnist.test.labels)) 整个过程完成，可以通过增加网络层，修改激活函数，learning rate等方式来测试结果。 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import osos.environ['KMP_DUPLICATE_LIB_OK']='True'"""写一个分类器，首先定义数据然后定义判别层，层包括输入，输入维度，输出维度，激活函数,权重然后是构造结构写loss写opertimizer然后开始训练"""import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data#get the datamnist = input_data.read_data_sets('MNIST',one_hot=True)# 添加层def add_layer(input,in_size,out_size,activation_Fcuntion = None): Weights = tf.Variable(tf.random.normal([in_size,out_size])) bias = tf.Variable(tf.zeros([1,out_size])+0.1) Wx_add_b = tf.matmul(input,Weights)+bias if activation_Fcuntion is None: outputs = Wx_add_b else: outputs = activation_Fcuntion(Wx_add_b) return outputs# 构造一个三层的神经网络用于mnist 的分类，分别是输入层，输出层，隐藏层#定义输入xs = tf.placeholder(tf.float32,[None,784])ys = tf.placeholder(tf.float32,[None,10])#构造层次prediction = add_layer(xs,784,10,tf.nn.leaky_relu)# lossloss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys)optimizer = tf.train.GradientDescentOptimizer(0.2).minimize(loss)sess = tf.Session()# 计算精度def computeLoss(xtest,ylabel): pre = sess.run(prediction,feed_dict=&#123;xs:xtest&#125;) correct_rate = tf.equal(tf.argmax(pre,1),tf.argmax(ylabel,1)) accuracy = tf.reduce_mean(tf.cast(correct_rate,tf.float32)) result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;) return result# traininit = tf.global_variables_initializer()sess.run(init)for step in range(1000): x_batch,y_batch = mnist.train.next_batch(100) sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch&#125;) if step%50 == 0: print(computeLoss(mnist.test.images,mnist.test.labels))]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[YOLO V1 详解]]></title>
    <url>%2F2019%2F03%2F07%2FYOLO-V1-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[YOLO 系列检测方法是不同于RCNN系列检测方法的另一种思路，其速度相比于Faster RCNN要快很多，但是精度上基于Faster RCNN框架的算法表现要更好一些，下面介绍YOLO V1. You Only Look Once:Unified, Real-Time Object Detection Submit time: 2016.5 arxiv link 网络的作用及背景YOLO在做目标检测时将任务作为一个空间上分开的目标框及其类别置信度的回归问题。单个神经网络一次计算就能够直接从整幅图象预测目标框和类别置信度（one-stage）。 YOLO的训练基于整幅图像，而且能够直接对检测任务进行优化。这个统一的模型在目标检测方面相比传统方法有多个好处。 YOLO极其之快，YOLO是一个回归问题，省去了复杂的pineline YOLO是在整幅图像上全局检测。检测过程中能够包含全局的上下文信息 YOLO学习到的是物体更加泛化的表示。在如艺术画像上，性能较优 精度上，YOLO的精度略差于最优的精度 YOLO V1的网络结构yolo的训练思路为对一张图片划分成S*S大小的网格，然后每个网格预测B的检测框，以及这些检测框的置信度（与GT的IoU程度）。每个边框包含5个变量，分别是(x,y,width,height,confidence)。其中x,y指边框的中心，confidence指置信度。 对于每一个网络，我们同时计算一下其内含每种物品类别的条件概率：$Pr(Class_i|Object)$，条件概率不受检测的边框数影响，因此对于每个网格还需要预测C个类别的条件概率（是否包含该类别的概率）。当我们测试时，将C个类别的条件概率与边框预测值执行度相乘，得到：$$Class-confidence = Pr(Class_i|Object) * IOU_{truth}^{predict}$$从而得到每个检测框各个类别的分类置信得分。这些分数就同时包含了检测框中出现某类的概率以及检测框和目标的匹配程度。 网络结构：网络一共有24个卷积层和两个全连接层。模型初始的卷积层从图像中提取特征，而全连接层则预测输出概率和坐标。 训练过程以及Loss计算YOLO中每个网格可以预测多个检测框。在训练阶段对于一个物体的预测，只分配一个预测框，这种分配是基于与GT当前的IOU最大的预测。这会导致不同检测框之间的特殊化。每一个预测都会在预测特定的尺寸、长宽比、物体种类方面有更好的表现，从而提高整体的召回率。 网络优化的loss 如下： 其中$\mathbb I_{i}^{obj}$表示网格i中出现了物体 ，$\mathbb I_{ij}^{obj}$ 表示网格i中第j个框负责预测。loss中第一项表示预测边框与GT边框中心的MSE loss，第二项表示预测边框与GT边框长宽的MSE loss，第三项表示对含有物体的网格的每个预测边框置信度的MSE loss，第四项是对不含有物体的网格的每个边框置信度的MSE loss，第五项是对每个网格含有C个类别的条件概率的MSE loss。 为了训练过程更加的稳定，使用loss从小到大，同时使用dropout和数据增强，防止过拟合。 YOLO V1 特点 YOLO 在推理时，即图片预测时预测速度非常快，只需要一次网络评估。在Pascal VOC上，每张图像上网络预测98个边界框和每个框的类别概率。 YOLO对相邻物体检测效果不好：由于每个网格只预测两个检测框并且只能用有一个类别。这种设置限制了小目标，以及密集目标的检测效果。 很难泛化到一些新的或者不寻常的长宽比的检测目标：由于模型是直接从数据中学习边框预测，因此对于一些边框不规则的情形难以检测。 损失函数对大检测框和小检测框的误差是相同对待的。一个小的误差对于一个大的检测框通常都是比较温和可以接受的，但是一个小的误差对一个小的检测框的IOU有着较大的影响。主要的误差来源就是不准确的坐标定位。 总结YOLO V1在先对图片划分S*S个网格，然后对每个网格均做2个边框的预测，以及对所有C个类别计算每个类别对象存在网格内部的条件概率。因此对每个网格检测的变量如下： 对于每一个对象，用对象中心的落在的网格来预测这个对象的边框，如下图： 最终通过最小化loss，对边框进行预测。 最终得到预测结果。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bag of Freebies for Training Object Detection Neural Networks]]></title>
    <url>%2F2019%2F03%2F05%2FBag-of-Freebies-for-Training-Object-Detection-Neural-Networks%2F</url>
    <content type="text"><![CDATA[这是一篇关于目标检测，语义分割领域，数据预处理以及网络调参的技巧文章。这些技巧对一些强大的算法，如Faster-RCNN，YOLO的性能有很大的提升。 Bag of Freebies for Training Object Detection Neural Networkssubmit time: 2019.2arxiv link 这篇文章在没有损失网络速度的前提下，介绍了一些通用的微调方法，使得网络的性能得到了大大的提升，网络的精度得到大幅提升。 作者首先探讨数据增强方面，图像mixup的方法。随后作者探讨了在目标检测训练的pipeline，例如 learning rate scheduling, weight decay ，synchronized BatchNorm. 第三，作者探讨了将上面这些方法共同作用在一个两步或一步检测网络中所带来的性能提升。 mixup本文的研究者认识到了多目标检测任务的特殊性质有利于实现空间不变的变换，因此提出了一种用于目标检测任务的视觉相干（visually coherent）图像混合方法。使用mixup，但是beta分布选择较大a&gt;=1,b&gt;=1(而不是传统的0.2)，融合后的图片显得和现实一致。同时没有对mixup进行空间上的扭曲，使用几何形状保持的对齐方式对图片进行融合。如上图第一中传统mixup的方式作者认为仅仅是引入了一些noise。第二种mixup的方式不对图片进行distort，同时与视觉一致，数据增强效果更好。 Classification Head Label Smoothing大部分的目标检测或语义分割网络中使用的loss 是基于softmax的交叉熵loss，这种loss 鼓励检测到的目标类别为正类别为1，其他为0。softmax函数如下：$$p_i = \frac{e^{z_i}}{\sum_j e^{z_j}}$$因此loss鼓励$e^{z_i} &gt;&gt; e^{z_j},i != j$这种极端情形，十分容易发生过拟合现象。因此使用label smoothing 来缓解这一现象。具体做法如下：我们对groundtruth q进行smoothing操作，q在变换前是one hot编码形式，通过如下变换：$$q_i = (1 - \epsilon )q_i + \frac{\epsilon}{K}$$其中$\epsilon$ 是一个很小的数，完成smoothing 操作。 Data Pre-processing作者采用了一下的数据增强方式： 随机几何变换. 包括随机裁剪, 随机扩张, 随机水平翻转，随机缩放等等。 随机颜色抖动：包括亮度，色调，饱和度，对比度。 cosine learning rate decay and Warm up learning rate通常在训练过程中，学习率都是从一个较大的值开始然后在训练过程中不断减少，最常用的是 Step schedule（阶梯式衰减）。例如，训练一定的Epoch之后，学习率衰减为原来的 0.1。Step schedule 使得急剧学习率的急剧下降，造成训练不稳定的问题。因此作者选择更为平滑的 Cosine 学习率衰减策略。 Synchronized Batch Normalization在多GPU环境下，对于一些batch size很小网络，在训练的时候BN会导致一些性能的下降。这个问题可以通过同时进行BN来解决。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNet V2 详解]]></title>
    <url>%2F2019%2F03%2F04%2FMobileNet-V2-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MobileNet V2 是在V1的基础上做了一些结构上的调整，主要有inverted residual 以及Linear Bottlenecks的改进。使得mobileNet v2 的精度进一步提高，结构进一步合理。 MobileNetV2: Inverted Residuals and Linear Bottleneckssubmit time: 2018arxiv link mobileNets的背景及作用mobileNet V1在设计的时候使用deepwise separable conv代替传统的卷积，大大降低了模型的计算量和复杂度，但是其仍然存在以下两个缺陷： 直筒型的结构影响网络性能，后续的网络如ResNet等，在网络中重复使用图像特征能够提高网络的性能。（引入inverted residual） depthwise Convolution 导致特征退化问题：由于depthwise conv使用很小的卷积核（1x1），经过BN归一化，以及relu激活之后很容易变为0，即变成死节点,导致特征退化。（我的理解是，对于一个1x1的kernel来说，归一化过程可能会把它变成负数，然后relu激活后就会变成死节点。但是对于kernel size比较大的卷积，要使整个卷积核上的数都变成负数要难很多，因此不会有很严重的特征退化问题。）（引入linear bottlenecks）. mobileNet v2 通过引入inverted residual，将图像中的特征反复使用，提高网络的性能。对于特征退化的问题，通过linear bottleneck，去掉网络中的relu等步骤，能够缓解特征的退化。 网络结构MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性激活函数。 线性瓶颈的倒置残差结构：模块的输入为一个低维的压缩表示特征，首先将其扩展到高维并用轻量级depthwise conv 进行卷积。随后用线性卷积（linear conv）将特征投影回低维表示。 MobileNet v2 模型的特点： 如上图，mobileNet v2在V1基础上进行了改进。 相同点：mobileNet v2由v1发展而来，继承了深度可分卷积（depthwise seperable conv），采用深度卷积和逐点卷积来代替传统的卷积操作，使得计算量大大减小。参考链接 不同点：V2在每个DW卷积之前加入了一层PW的卷积，主要作用是用于提升特征的channel数。由于DW层无法提升feature map的通道数，于是先通过PW提升feature map的通道数，PW卷积的大小为：Mx1x1，卷积核的个数可以控制，也即为卷积后得到feature map的通道数。至于提升channel的具体原因如下： 当我们查看深层卷积层所有的d通道像素时，在这些值中编码的信息实际上位于某个流形中，这些流形结构可以嵌入到低维子空间中。ReLu在高层空间中的变换有助于增加网络的非线性。对于ReLU（Bx）激活后的非0部分，输入空间与输出空间之间的特征映射是线性变换。另一方面，当ReLU破坏通道时（relu小于0的部分），它会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。总而言之，以下两个特性表明感兴趣的流形区域位于较高维激活空间的低维子空间中： 如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。 只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。 因此我们需要先对channel通道进行升维。假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。线性可以防止非线性破坏太多的信息。 Linear Bottleneck：V2 去掉了第二个 PW 的激活函数。论文作者称其为 Linear Bottleneck。这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。由于第二个 PW 的主要功能就是降维，降维之后使用线性瓶颈层来获取低秩信息，防止非线性破坏太多信息。 倒置残差：V2的 shortcut 设计与ResNet相反，呈一个纺锥型，中间大两头小，因此称为倒置残差。使用倒置设计是由于其内存效率要高得多。网络将PW层得到的feature map先扩展6倍，然后通过DW卷积，与一个shortcut上来的feature map融合之后再输入PW卷积。 mobileNet的结构单元如下： 网络结构参数如下： 整体的结构如下：参考链接]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow 笔记（搭建网络-II）]]></title>
    <url>%2F2019%2F03%2F04%2FTensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-II%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇文章主要讲网络搭建过程中的代码以及注意要点。 添加网络层定义网络结构，然后将网络层添加到神经网络中。定义网络层的主要步骤有： 确定网络的参数：输入，输入的size，输出的size，激励函数 定义weight，biases 计算output 123456789def add_layer(input,in_size,out_size,activation_function = None): Weights = tf.Variable(tf.random.normal([in_size,out_size])) biases = tf.Variable(tf.zeros([1,out_size])+0.01) Wx_plus_b = tf.matmul(input,Weights)+biases if activation_function is None: output = Wx_plus_b else: output = activation_function(Wx_bias_b) return output 可以看出来，网络层神经元的个数即为输出的outsize的大小。 搭建神经网络以下为搭建一个三层神经网络，其中输入层为1个神经元，输出层为1个神经元，隐藏层为10个神经元。搭建网络是需要完成的事情为： 定义数据，网络层中的参数维度 定义传入的参数placeholder，loss，optimizer等 值得注意的是，数据的维度变化需要十分注意 1234567891011121314151617181920212223242526import tensorflow as tfimport numpy as np# create datax_data = np.linspace(-1,1,300)[:,np.newaxis]noise = np.random.rand(x_data.shape[0],x_data.shape[1])y_GT = np.square(x_data)+0.5+noise# placeholderxs = tf.placeholder(tf.float32,[None,1]) #表示样本数，和每个样本的维度为1ys = tf.placeholder(tf.float32,[None,1])# structurel1 = add_layer(ms,1,10,tf.nn.relu)output = add_layer(l2,10,1,None)# lossloss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),1))optimizer = tf.train.GrandientDescentOptimizer(0.1).minimize(loss)#traininit = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for step in range(1000): sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;) if step%20 == 0: print(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;) 代码详解如下： x_data = np.linspace(-1,1,300)[:,np.newaxis]：其中np.linspace(-1,1)生成-1，到1之间的300个数。[:,np.newaxis]指将生成的数据维度提升。原来是1x300，现在是300x1，由1为变为300维，每个数据占一个维度。 xs = tf.placeholder(tf.float32,[None,1]) #表示样本数，和每个样本的维度为1：其中[None,1]有一种含义为，当你不知道样本数的时候，抓住每个样本的维度即可。 tf.reduce_sum(tf.square(output-ys),1): 其中tf.reduce_sum()这个函数为求和函数，第一个参数是一个数组，第二个参数默认则为所有数之和。第二个参数为0，则为列之和（0），第二个参数为1则为行之和（1）。tf.reduce_mean()参数含义与求和函数一致。 在写网络结构的时候，用placeholder，暂时忘记掉真实的数据，先构建好框架后，然后传入参数。 结果可视化可视化模块一般使用matplotlib.plot as plt 来绘图。 matplotlib的层次结构：matplotlib的结构类似与一个树状结构。Figure : 为层次结构中的最外层，内部可包含多张plot图像。plot图层次结构可包含的对象例如刻度线，单独的线条，图例和文本框。几乎每个“元素”都是一个Python对象。具体代码实现如下：12345678910111213import matplotlib.pyplot as pltimport numpy as npx = np.linspace(-np.pi,np.pi,300)xsin = np.sin(x)xcos = np.cos(x)plt.subplot(221) # 表明共有2列，2行的图片要画，现在拿到第一个来画plt.plot(x,xsin) # 要画折线图，如果点很密集，就是曲线图plt.xlabel('x轴') # 所有属于这个子图的小对象，如颜色，图例，都可以修改plt.subplot(222) # 表明2列2行，现在要画第二个plt.plot(x,xcos)plt.subplot(223) # 表明2行2列，现在要画第三个plt.scatter(x,xsin) # 要画散点图plt.show() 如上，每次使用plt.subplot(xxx)交换控制的子图，非常好懂哈哈哈。 下面是搭建网络，绘制拟合图的完整代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltimport osos.environ['KMP_DUPLICATE_LIB_OK']='True'"""添加层需要考虑的因素有几个，首先输入的数据，输入的数据尺度，输出的尺度（神经元个数），激活函数"""def add_layer(input,in_size,out_size,activation_function = None): #定义权重 Weights = tf.Variable(tf.random.normal([in_size,out_size])) bias = tf.Variable(tf.zeros([1,out_size])+ 0.01) Wx_plus_b = tf.matmul(input,Weights) + bias if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs"""构建神经网络：1. 搭建一个输入层仅有一个神经元，隐藏层10个神经元，输出层1个神经元的网络2. 需要定义数据，网络层，输入输出，placeholder，loss ，optimizer"""# np.linspace(-1,1,10)[:,np.newaxis],引入新维度# create datax_data = np.linspace(-1,1,300)[:,np.newaxis]noise = np.random.rand(300,1)y_GT = np.square(x_data) + 0.5+noise# create networkxs = tf.placeholder(tf.float32,x_data.shape)ys = tf.placeholder(tf.float32,y_GT.shape)l1 = add_layer(xs,1,10,activation_function=tf.nn.relu)output = add_layer(l1,10,1,activation_function=None)# lossloss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),1))optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)#illustrationax = plt.subplot(111)plt.scatter(x_data,y_GT)plt.ion() # 动态画图，不停止plt.show()# traininit = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for step in range(500): sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;) if step%20 == 0: print(sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)) predict = sess.run(output,feed_dict=&#123;xs:x_data&#125;) # plt.plot(x_data,predict) try: ax.lines.remove(lines[0]) except Exception: pass # plot the prediction lines = plt.plot(x_data, predict, 'r-', lw=5) plt.pause(0.5) TensorBoard 可视化Tensorboard 作为tensorflow网络结果可视化的一个比较好的工具，他使用tf.name_scope(&quot;name&quot;):的方式对部分元件进行整体的命名。并且支持多层的嵌套。如下例子： 123with tf.name_scope("layer"): with tf.name_scope("Weight"): Weights = tf.Variable(tf.random.normal([300,1]),name = 'W') tensorboard工作的思路是将文件写入磁盘，然后由浏览器进行访问，写入磁盘的语句如下： 12sess = tf.Session()writer = tf.summary.FileWriter('./log',sess.graph) 最后在命令行中，进入文件目录输入指令： 1tensorboard --logdir = 'log/' 随后在浏览器中输入：0.0.0.0:6006即可预览。 tensorboard还可以监控单个变量的变化情况，使用histogram直方图来显示。tf.summary.histogram代码如下： 123with tf.name_scope("Weight"): Weights = tf.Variable(tf.random.normal([300,1]),name = 'W') tf.summary.histogram(name,Weight) tensorboard看一个一维的变量，如loss，使用tf.summary.scalar 123with tf.name_scope('loss'): loss = tf.reduce.mean(tf.reduce.sum(tf.square(y-p_pred),1),1) tf.summary.scalar('loss',loss) 最后需要对所有的summary进行融合： 1merged = tf.summary.merge_all() 接下来在训练的时候更新参数,然后使用writer.add_summary(result,step)来将summary写入文件中。 12345678init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for step in range(1000): sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;) if step%20 == 0: result = sess.run(merged,feed_dict=&#123;xs:x_data,ys:y_GT&#125;) writer.add_summary(result,step) 接着使用命令行运行即可.x]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNets 详解]]></title>
    <url>%2F2019%2F03%2F03%2FMobileNets-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[mobileNets为谷歌开发的，为移动或嵌入式端视觉应用开发的一个轻量级高效模型。 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applicationssubmit time: 2017arxiv link mobileNets的背景及作用背景：在很多CNN的是被问题中，总体趋势是使用更深层次更加复杂的模型来实现更高的精度。然后提高精度的代价往往是网络在尺度和速度的性能变差，对于一些要求时效且计算资源有限的任务这些网络难以完成。 mobileNets：本文介绍的moblieNets具有高效的网络结构和两个超参数，以便构建非常小的，快速度的模型，可以轻松匹配移动和嵌入式视觉应用的设计要求。 本文提出了一类网络结构，允许模型开发人员选择与其应用程序的资源限制（延迟，大小）相匹配的小型网络。MobileNets主要侧重于优化速度，但也能够产生小型网络，我们介绍了两个简单的全局超参数，可以在时间和准确性之间进行有效折中。 深度可分离卷积： 一个传统的大小为$M*N*D_k*D_k$的卷积核，对一个大小为$D_F*D_F$的features map进行卷积，他的计算量为：$N*M*D_k*D_k*D_F*D_F$.MobileNets基于深度可分离卷积构建，深度可分离卷积由两层构成：depthwise convolutions和pointwise convolutions，分别对将$M*N*D_k*D_k$的大小的卷积核进行深度（channel）和尺寸（$D_k$）上的分割：其中M为通道数，N为卷积核个数，$D_k$为卷积核大小。 depthwise convolution：将$M*D_k*D_k$的卷积核分解为$1*D_k*D_k$，一共M组卷积核（不使用N），即每个卷积核仅对一个通道进行处理。对于一个大小为$D_F*D_F$的features map他的计算量为：$M*D_k*D_k*D_F*D_F$. Pointwise convolution（1x1卷积）：即将$M*D_k*D_k$的卷积核分解为$M*1*1$大小的卷积核共有N个，用来创建depthwise层的线性叠加。该层的计算量为$N*M*D_F*D_F$. Deep-wise 分离卷积相比于传统卷积的计算量减少如下：$$\frac{M*D_k*D_k*D_F*D_F+N*M*D_F*D_F}{N*M*D_k*D_k*D_F*D_F} = \frac{1}{N} + \frac{1}{D_K^2}$$计算量得到了显著的下降，而模型准确率仅下降了一点点，MobileNets对两层卷积层都使用了BatchNormalization和ReLU非线性激活。 一个转换的例子如下： MobileNets 网络结构网络共28层，大大量重叠的deepwise结构组成，最后接一个argpooling送入全连接层进行softmax分类。网络中大部分参数及计算来自1*1的卷积层，以及最后的全连接层。网络很少使用BN以及数据增强技术，因为小网络不易发生过拟合现象。 超参 Width multiplier（更小的模型）我们使用一个参数$\alpha$，称为width multiplier。它的作用是在每层均匀地减负网络。对于一个给定的层和$\alpha$，输入通道的数量从M变成$\alpha M$，输出通道的数量从N变成$\alpha$N。深度可分离卷积的计算复杂度变为原来的$\alpha$倍。α在(0,1]之间，通常设为1，0.75，0.5和0.25。Width multiplier有减少计算复杂度和参数数量（大概α二次方）的作用。用于定义新的简化结构，但需要重新进行训练。计算复杂度如下：$$\alpha M*D_k*D_k*D_F*D_F+\alpha N* \alpha M*D_F*D_F$$ 超参 Resolution Multiplier （Reduced Representation）使用超参数$\rho$用于减小图片的尺度，$\rho$的范围在(0,1]之间，用于缩减图片的大小，计算复杂度如下：$$\alpha M*D_k*D_k* \rho D_F* \rho D_F+\alpha N* \alpha M*\rho D_F* \rho D_F$$ 通过调整$\alpha,\rho$来使得模型在资源使用和精确度上执行折中。 网络的损失函数网络损失函数较为简单，即为feature map接一个全连接层，然后连上softmax loss。$$Loss = \sum_I y_i \log p_i$$ 总结MobileNets 是一个目标识别网络，即用来判断一张图片的类别。它在原有CNN的基础上，将卷积层进行了deepWise 和pointWise上的分解，参数量大大减少，精度仅下降一点点。缩减结构的同时，使用两个超参数控制参数的大小以及图片的大小，在精度和资源上进行权衡。此外，MobileNets可以作为许多网络的特征提取部分，例如Faster RCNN的特征提取部分等等，精度在可以满足的情况下，大大降低了网络的参数量。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 笔记（基础部分-I）]]></title>
    <url>%2F2019%2F03%2F03%2FTensorFlow-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[TensorFlow是一个开源的软件包，用于各种感知以及语言理解的机器学习，深度学习任务。 简单例子：使用MSE loss去拟合一条二维的直线，优化方式选择SGD。步骤如下： 定义训练数据，以及GroundTruth 搭建tensorflow的结构，包括变量的定义(weight,bias)，损失函数的定义，优化器的定义 执行tensorflow，使用tf.Session()定义回话，用于执行tensorflow计算图。设置epoch的次数（执行次数） 1234567891011121314151617181920212223import tensorflow as tfimport numpy as np#create datax_data = np.random.rand(100) # 100个 0～1之间的数y_data = x_data*0.3 + 0.9# create tensorflow structureWeights = tf.Variable(tf.random.uniform([1],-1.0,1.0))Bias = tf.Variable(tf.zeros([1]))y = Weights*x_data + Biasloss = tf.reduce_mean(tf.square(y - y_data))optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss)# executeinit = tf.global_variables_initializer()sess = tf.Session()sess.run(init)for step in range(500): sess.run(train) if step%20 == 0: print(sess.run(Weights),sess.run(Bias)) 这里头可说的东西有很多，首先是：np.random.rand(100),即： numpy产生随机数的方式：为什么重要，因为很多神经网络中参数的初始化，都是使用numpy来完成的，以前没仔细记录导致一知半解，自己写不出来。详细链接 np.random.rand(4,2): 表示产生（0，1）之间的float随机数，维度为4x2. np.random.rand(4,2,3):维度为4x2x3. np.random.randn(4,2): 表示产生一组符合正态分布的数 N ( 0,1 )，维度是4x2. np.random.randint(low,high,size = (4,2)): 表示产生一组整数，维度为4x2，大小在[low,high)之间。 np.random.seed(1) np.random.rand(5):表示指定了seed，该seed下产生的随机数是相同的。 tensorflow中表示变量的函数：tf.Variable()tensorflow中所有的变量使用函数定义，tf.Variable 类用于操纵变量，该变量可以通过op运算来更改他的值。定义变量：weights = tf.Variable(&lt;initial-value&gt;,name = &lt;optional&gt;)变量的初始化：与其他语言不同，tensorflow在使用变量的时候需要先进行初始化操作。可以这么理解，tensorflow内部是以执行Graph的形式进行计算的，之前的所有操作，如定义变量，仅仅是构建Graph的结构，但是并没有真正的将值传入Graph节点中，因此需要tf.Session()来执行初始化操作，为变量节点赋值。初始化如下：init = tf.global_variables_initializer()sess = tf.Session()sess.run(init) tensorflow 产生随机数 tf.random.uniform([2,3],minval = -1,maxval = 1,seed = None)：表示产生均匀分布的随机数，大小在[minval,maxval]之间。 tf.random.normal([2,3],mean = 0,stddev = 1)： 表示产生正态分布的随机数，服从N（0，1）。 tf.truncated.normal([2,3],mean = 0,stddev = 1)：表示生成范围在[mean-2stddev,mean+2stddev]范围内的正态分布随机数。 tf.random.shuffle([1,2,3,4])：表示沿着第一维，对数组进行重新排列。 此外初始化为0: tf.zeros([2,3]) tensorflow 中的LossMSE Loss：(L2)mse = tf.reduce_mean(tf.square(y_pre,y))MAE Loss: (L1)mae = tf.losses.absolute_difference(y_pre,y)mae_loss = tf.reduce_sum(mae) 处理分类问题交叉熵Loss：softmax_sparse = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,logits = y_pred)loss = tf.reduce_mean(softmax_sparse)其中不要求y-true 是one-hot 格式。 优化器：tensorflow中的优化器共有其中，均在tf.train 这个类中，使用的时候看具体的应用。optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(optimizer) tf.Session() 会话控制：Session 用于执行计算图中的节点，因此获取一个值，或者是最小化loss等操作，都需要使用Session来激活部分计算图。使用如下：123with tf.Session() as sess: sess.run(init) sess.run(train) tf.constant() 常量：tensorflow 用 tf.constant() 来申请一个常量，常量指不能被修改的数。matrix1 = tf.constant([[1,2],[3,4]]) tf.placeholdertf.placeholder(tf.float32,[3,2]):表示数据类型为tf.float32，大小为3x2。使用placeholder的目的是： placeholder 可以作为一个参数，专门用来将数据传入函数中 由于tensorflow是计算图模型，如果使用变量传参数的话，计算图将会变得很大，不便与计算，因此使用placeholder来代替 123456import tensorflow as tfinput1 = tf.placeholder(tf.float32,[2,2])input2 = tf.placeholder(tf.float32,[2,2])ouput = tf.multiply(input1,input2)with tf.Session() as sess: print(sess.run(output,feed_dict=&#123;input1:[[1,2],[2,2]],input2:[[1,2],[3,4]]&#125;)) 激活函数1234567891011tf.nn.relu(features,name = None) # 下面均相同tf.nn.relu6tf.nn.crelutf.nn.elutf.nn.selutf.nn.softplustf.nn.softsigntf.nn.dropouttf.nn.bias_addtf.sigmoidtf.tanh]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ESRGAN 详解]]></title>
    <url>%2F2019%2F03%2F02%2FESRGAN-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ESRGAN 详解ESRGAN网络是在SRGAN的基础上，对对抗损失以及感知损失进一步的改善，引入residual-in residual Dense Block(残差密集块)来组建网络而取代了网络中的BN。并且借鉴了相对GAN的思想，让给判别器预测相对的真实性，而不是完全相同。ESRGAN网络的作者是香港中文大学的学生，他对学习的建议是多看论文多实验，自己push自己！显然能力越大舞台越大！ ESRGAN: Enhanced Super-Resolution Generative Adversarial Networkssubmit time:2018 ECCVarxiv link ESRGAN 的作用传统提升SR（super resolution）的方法是使用Peak Signal-to-Noise Ratio(PSNR)峰值信噪比，即最小化生成图片与GT之间的MSE loss，但是这种优化策略倾向于输出平滑的结果而没有足够多的具体细节。这篇文章在SRGAN的基础上进行改进，提升了图片超分辨率的精度，作者从三个方面提升修改模型： 引入密集残差块（RDDB）去除了BN，节省内存空间提升模型的结构，使之具有更大的容量和更易于训练。 辨别器使用相对平均GAN（RaGAN），即判断“是否一个图像相比于另一个更真实”而不是“是否一个图像是真或假”。这个改进有助于生成器恢复更真实的纹理细节。 SRGAN感知损失部分，使用激活函数之前的VGG features map，而不是SRGAN激活之后的feature map，调整后的感知损失提供了清晰的边缘和更具有视觉体验的结果 网络结构生成器部分：生成器结构上的改进： 去除所有的BN层 用残差基础块代替原始基础块 BN在训练期间需要计算整个训练集的均值和方差，当训练集和测试集差异很大的时候会引入伪影，造成图像的模糊，通过在残差块中去除BN层，有助于提高泛化能力，能够减少空间和计算复杂度。 生成器训练过程的tip：1）残差缩放，例如将残差乘以0和1之间的常数（图中$\beta$），然后将它们添加到主路径以防止不稳定。2）较小的初始化参数，当初始参数方差变小时，残差结构更容易训练。 判别器部分：（相对判别器）判别器部分使用相对判别，也即是说真实图像与生成图像哪个更加真实一些。如上图，真实判别器为$D(x_r) = \sigma (C(x))$,其中$\sigma$ 为sigmoid函数，$C(x)$为sigmoid转换前判别器的输出。相对判别器在则判断是的，真实图像是否比生成图像更加的真实：$$D_{ra}(x_r,x_f) = \sigma(C(x_r) - E[C(x_f)] )$$其中$E[C(x_f)]$为在mini-batch中所有的生成图片取均值。 损失函数生成器部分：生成器的loss由三部分组成： $$L_G = L_{percep}+ \lambda L_G^{Ra} + \eta L_1$$其中$L_{percep}$为vgg中激活函数之前的features map与GT的features map的MSE loss（同SRGAN），$L_{G}^{Ra}$损失为对抗损失（与判别器对称）：$$L_G^{Ra} = -E_{x_r}[log(1-D_{Ra}(x_r,x_f))] - E_{x_f}[log(D_{Ra}(x_f,x_r))]$$即生成器的目标是另判别器将生成图片判断成比原始图像真实。$L_1$ loss 表示恢复图像与真实图像之间的L1 距离：$$L_1 = E_{x_a} || G(x_i)-y||_1$$ 判别器部分：判别器loss与生成器对抗loss对称，如下：$$L_D^{Ra} = -E_{x_r}[log(D_{Ra}(x_r,x_f))] - E_{x_f}[log(1 - D_{Ra}(x_f,x_r))]$$判别器的目标是将原始图片判别成更加的真实。 网络特点 用密集残缺块来代替原有的基础块，去除了BN 对GAN进行修改，进而去判断相对真实感 对激活前的features map做MSE提升恢复精度 网络插值：为了去除PSNR导致的像素平滑，同时保证感知质量。可以通过训练一个PSNR 的生成器$G_{PSNR}$，然后基于GAN网络的$G_{GAN}$进行fine tune,然后利用插值模型得到一个插值网络。$$\theta_{G}^{INTERP} = (1-\alpha) \theta_G^{PSNR}+\alpha \theta_G^{GAN}$$因此可以通过调整$\alpha$的大小来调整网络输出PSNR指标与视觉效果。 总结网络在SRGAN的基础上进行了大量的改进，包括在训练方法上，loss的设计上等等，最终取得了较好的恢复结果。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微电阻成像]]></title>
    <url>%2F2019%2F03%2F02%2F%E5%BE%AE%E7%94%B5%E9%98%BB%E6%88%90%E5%83%8F%2F</url>
    <content type="text"><![CDATA[微电阻成像原理： 微电阻率扫描成像测井采用多个有序排列、间距几毫米的钮扣电极测量井壁地层电阻率，并形成分辨率很高的井壁图像，从而对地层进行细微分析的电阻率测井方法。它采用多个压向井壁的极板，每个极板上的多排钮扣状小电极向井壁地层发射电流，由于电极所接触的井壁岩石的结构、成分及所含流体的不同引起电流变化，电流的变化反映了正对电极处井壁地层电阻率的变化。经过适当的处理，可以描绘为彩色或灰度等级的井壁电阻率图像，对地层岩性、沉积特征、构造特征、裂缝及洞穴等进行分析。 微电阻图像： 将电阻率数据进行处理，然后进行颜色的映射，得到的结果如下：上图宽表示井口的周长，长表示测井的深度（图中仅为部分长度）。可以看出来，途中存在倾斜的黑色条道，只是由于探测的时候设备仅仅有六个探测口，然后每次探测完一个深度探测口发生旋转，继续进行探测。黑色条道即为探测器之间的距离。 任务： 根据已有的数据，恢复出黑色条道部分的数据。 workFlow 2019.3.5沟通需求之后发现暂时需要实现有数据部分的数据恢复工作，接下来用网络跑一下看看效果。如果效果好的话，改写到tensorflow的版本。 下图是使用ESRGAN恢复得到超分辨后的结果。右图是原图放大到像素级别的效果，左图是图片恢复后的效果图。 2019.3.3do something in this place 2019.3.2看了一些对微电阻成像图像的应用，发现人们会根据有数据部分的图像来推测没有数据的部分，通常使用曲线的先验来判断的，如下：也就是说我们可以对数据进行标注，然后加入一下曲线先验信息等，然后采用深度学习的方法来做。 专业人员可以从电阻率的分布曲线看出岩石的类型，如下图，因此可以认为电阻率在空间分布上是存在一定的规律的。是不是可以找一个指标来表示这种分布？]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux操作及远程服务器访问]]></title>
    <url>%2F2019%2F03%2F02%2Flinux%E6%93%8D%E4%BD%9C%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SRGAN 详解]]></title>
    <url>%2F2019%2F03%2F01%2FSRGAN-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[SRGANSRGAN是一个这篇文章将生成对抗学习用于基于单幅图像的高分辨重建，不同于传统的CNN的方法，SRGAN得到的超分辨率的图片放大四倍之后还是能够体现细节感。 Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Networksubmit time:2017arxiv link SRGAN的作用SRGAN目标从一个低分辨率的图片中生成它的高分辨率版本。 传统CNN方法：基于深度学习的高分辨率图像重建已经取得了很好的效果，其方法是通过一系列低分辨率图像和与之对应的高分辨率图像作为训练数据，学习一个从低分辨率图像到高分辨率图像的映射函数。但是当图像的放大倍数在4以上时，很容易使得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为传统的方法使用的代价函数一般是最小均方差（MSE），使得生成的图像有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。作者还做了实验，证明并不是信噪比越高超分辨率效果越好。本文的做法：应当使重建的高分辨率图像与真实的高分辨率图像无论是低层次的像素值上，还是高层次的抽象特征上，和整体概念和风格上，都应当接近。因此在loss部分，SRGAN加上了feature map部分的MSE loss。 网络结构 生成网络部分：SRResnet，由残差结构，BN，PReLU组成，用于实现高分辨率的生成。判别器部分：由大量卷积层，Leaky ReLU,BN等结构组成，用于判别图像的真实性。 损失函数SGGAN的损失函数由两部分组成：content loss，以及adversarial loss组成。content loss：传统算法使用的是还原图像与GT图像之间的MSE损失，作者为了避免放大后特征过于平滑，认为高层次（features map）也应当相似。因此定义了VGG feature map loss。其中$\phi_{i,j}$表示feature map的位置在j-th conv 与i-th Max pooling 中间的部分。即同时对GT与生成的图片提取feature map，然后最小化这两种features map的MSE loss。 adversarial loss：对抗网络部分的loss为判别器判别loss，即当生成器生成的图片，判别器认为为真实的图片时，该loss取得最小。 SRGAN输入输出以及亮点SRGAN的训练数据：GT：为原始高分辨率的图片train data：原始图片经过高斯滤波得到的图片输出：即为最终恢复高分辨率之后的图片 亮点： 训练了一个SRResnet，由Resnet生成的一张恢复高分辨率的图片，然后将这张图片与GT传入Vgg网络中，训练一个MSE loss 最小。 重新设计了Loss，将features map的MSE Loss，与对抗网络的Loss结合。 总结这篇文章可以比较好的恢复分辨率低的问题，结合了高层特征Loss以及对抗网络的loss共同作用，得到比较好的还原结果。 看这篇文章的本意是想要对电阻成像数据进行恢复，这么看来，恢复的前提需要GT，但是数据集中并不存在这部分数据，因此这种方法可能需要进行修改。我觉得一个思路可能可以行得通，首先对电阻成像数据进行切割，然后将切割后的小batch图像作为GT，进行训练，可能可行。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project two]]></title>
    <url>%2F2019%2F02%2F25%2Fproject-two%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>项目总结</category>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈看论文和记笔记]]></title>
    <url>%2F2019%2F02%2F23%2F%E8%B0%88%E7%9C%8B%E8%AE%BA%E6%96%87%E5%92%8C%E8%AE%B0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本篇纯属个人体会之谈。 如何看论文这几天看了些论文，遂总结一下看论文的方法。我尝试了很多方法之后觉得下面这种方式比较合适：找论文找论文一般的的途径就是找综述文章，找博客总结类的文章，里头一般就按时间顺序排好列出若干重要的论文，打好基础后专门去看与(🌧️这个表情还蛮可爱)问题相关的文章。看文章 下载文章后，网上找翻译，对照着翻译大致通读一遍文章 通读完文章之后，上网找对该文章总结的博客，越多越好 结合自己的认识，参考博客总结一下文章内容，尝试复述 如何总结文章上次看到一个博客里头关于文章的总结结构十分的好，值得借鉴一下： 这个网络是用来干什么用的，有什么好的特点, 网络的背景及作用 然后直接搬出代码，讲这个网络的网络结构，简直一目了然，网络结构 讲一下结构中特殊的部分，以及好处，网络的亮点 第三部分讲损失函数，这个也很精彩，因为一个网络知道他的网络结构和损失函数就了解的差不多了，损失函数 第四部分讲测试的输入输出，讲清楚就知道怎么用的，网络输入与输出 最后做了一下总结，清晰易懂 ，总结]]></content>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN系列论文]]></title>
    <url>%2F2019%2F02%2F23%2FGAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%2F</url>
    <content type="text"><![CDATA[GAN系列论文Generative Adversarial Networks(GAN) Generative Adversarial Networkssubmit time: 2014arxiv link 生成对抗网络中含有两个模型（均由多层感知机实现）： 生成模型G：用来将随机样本映射到真实数据分布 判别模型D用来估计样本来自真实样本的概率 G的训练目标是最大化D产生错误的概率，D训练的目标是最大化真实样本的判别概率。相当于一个极小化极大的双方博弈过程。以上是模型的结构图，生成器的输入一个随机分布的数据，判别器输入的是真实样本和生成的数据，做一个二分类，最后通过一个sigmoid函数输出样本的概率。 训练D来最大化分配正确标签的概率即$\log(D(x))$.我们同时训练G来最小化$\log(1−D(G(z)))$。换句话说，D和G的训练是关于值函数$V(G,D)$的极小化极大的二人博弈问题：$$\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x)]+E_{z∼pz(z)}[log(1−D(G(z)))].$$ $Pdata(x)$：真实数据的分布；$x$：真实数据；$P(Z)$：生成数据的分布；$Z$：生成的数据；$G(Z)$：生成器网络；$D(X)$：判别器网络。 GAN的训练过程首先对具体的问题定义出生成器和判别器（多层的感知机）。1. 训练判别器（discriminator）如上图，判别器的优化目标是上式两项期望和最大。输入为真实数据和生成的数据。由于log函数是一个增函数，他的形状如下：因此当判别器将真实数据判错时，第一项得到的D(x)的值将小于1，当判别器将生成数据判断成真实数据时，第二项的1 - D(G(x))将小于1。由上式可知由于错判将会导致上式的期望接近无穷小。因此最大化这个式子（等于0表示完美的判别），可以使得判别器尽可能对数据正确判别。1. 训练生成器（generator）生成器的目标是最小化上图中的式子。由于第二个式子在优化的时候能够提供很大的梯度，使得算法快速收敛，因此通常使用第二个式子作为生成器的目标函数。式子含义十分明显，就是使得G(x)生成的数据分布与真实数据分布无限接近，D(x) = 1时，函数取得最大值。整个训练过程如下图所示，判别器和生成器交替优化训练：全局最优解：不断迭代上式，上诉方程最终会收敛到一个全局最优解。首先固定G，优化D，得到D的全局最有解为：$$D(x) = \frac{P_{data}(x)}{P_{data}(x) + P_g(x)}$$上式可以通过对目标方程求导得到。将上式带入到目标方程里去最优化G的结果，最终我们将得到如下方程：即两个KL散度减去log(4)，由于KL散度的值大于等于0，当且仅当：$P_z(z) = P_{g}(x)$时，该方程取得最小值-log(4)。我们知道，当固定D去优化G时，优化的最优结果应为生成的数据分布与真实分布相同：$$P_z(z) = P_{g}(x)$$上式恰好等于D(x)最优条件下，G(x)的最优结果，因此通过迭代的方式去优化GAN的目标函数能够同时得到最优的生成模型和判别模型，并使得生成的数据与原始数据尽可能的相似。（具体的式子推导过程可参考论文）。因此判别器D(x)的全局最优解为：$$D(x) = \frac{1}{2}$$例子： Conditional GAN由于单纯的GAN的生成器太过自由了，对于较大的图片，较多的pixel的情形，基于简单 GAN 的方式就不太可控。于是Conditional Generative Adversarial Networks提出了条件型的生成对抗网络，通过给GAN中的G和D增加一些条件性的约束，来解决训练太自由的问题。 在生成模型（G）和判别模型（D）的建模中均引入了条件变量y，这里y可以是label，可以是tags，可以是来自不同模态是数据，甚至可以是一张图片。 $$\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].$$ 在生成器模型中，条件变量y实际上是作为一个额外的输入层（additional input layer），它与生成器的噪声输入p(z)组合形成了一个联合的隐层表达； 在判别器模型中，y与真实数据x共同作为输入，并输入到一个判别函数当中。 常见的输入结构如下： 模型的训练过程： 论文中作者使用的例子：在MNIST数据集的实验中，对于生成器模型，将label的one-hot编码与100维的均匀分布的噪声输入融合起来作为输入，输出是784维的生成数据，与数据集28*28的维度一致。对于判别器模型，作者使用了一个maxout的激活层连接输入数据（与生成器输入相同），随后将maxout与判别器相连。 pix2pix Image-to-Image Translation with Conditional Adversarial Networkssubmit time: 2016arxiv link pix2pix网络的主要作用及特点pix2pix是一个基于CGAN改造的一个做图像变换的网络，在CGAN的基础上修改了生成器G的网络结构，及判别器D网络的网络结构。同时引入一个生成图片与样本间的L1 loss增强生成图片的低频信息。 pix2pix 网络结构以下网络结构都是用了conv-BatchNorm-ReLu的单元结构。生成器G(X)的网络结构：生成器的网络结构是U-Net结构，即encoder-decoder加上skip layer的类型这种结构在输入与输出之间共享图片底层的信息，有利于图片细节的还原。具体每一层的尺寸看代码注释：1234567891011121314151617encoder_1: [batch, 256, 256, in_channels] =&gt; [batch, 128, 128, ngf]encoder_2: [batch, 128, 128, ngf] =&gt; [batch, 64, 64, ngf * 2]encoder_3: [batch, 64, 64, ngf * 2] =&gt; [batch, 32, 32, ngf * 4]encoder_4: [batch, 32, 32, ngf * 4] =&gt; [batch, 16, 16, ngf * 8]encoder_5: [batch, 16, 16, ngf * 8] =&gt; [batch, 8, 8, ngf * 8]encoder_6: [batch, 8, 8, ngf * 8] =&gt; [batch, 4, 4, ngf * 8]encoder_7: [batch, 4, 4, ngf * 8] =&gt; [batch, 2, 2, ngf * 8]encoder_8: [batch, 2, 2, ngf * 8] =&gt; [batch, 1, 1, ngf * 8]decoder_8: [batch, 1, 1, ngf * 8] =&gt; [batch, 2, 2, ngf * 8 * 2]decoder_7: [batch, 2, 2, ngf * 8 * 2] =&gt; [batch, 4, 4, ngf * 8 * 2]decoder_6: [batch, 4, 4, ngf * 8 * 2] =&gt; [batch, 8, 8, ngf * 8 * 2]decoder_5: [batch, 8, 8, ngf * 8 * 2] =&gt; [batch, 16, 16, ngf * 8 * 2]decoder_4: [batch, 16, 16, ngf * 8 * 2] =&gt; [batch, 32, 32, ngf * 4 * 2]decoder_3: [batch, 32, 32, ngf * 4 * 2] =&gt; [batch, 64, 64, ngf * 2 * 2]decoder_2: [batch, 64, 64, ngf * 2 * 2] =&gt; [batch, 128, 128, ngf * 2]decoder_1: [batch, 128, 128, ngf * 2] =&gt; [batch, 256, 256, generator_outputs_channels] 判别器的网络结构：判别器为卷积网络，结构如下：12345layer_1: [batch, 256, 256, in_channels * 2] =&gt; [batch, 128, 128, ndf]layer_2: [batch, 128, 128, ndf] =&gt; [batch, 64, 64, ndf * 2]layer_3: [batch, 64, 64, ndf * 2] =&gt; [batch, 32, 32, ndf * 4]layer_4: [batch, 32, 32, ndf * 4] =&gt; [batch, 31, 31, ndf * 8]layer_5: [batch, 31, 31, ndf * 8] =&gt; [batch, 30, 30, 1] 网络的总体架构如下： pix2pix的出彩的结构：选择PatchGAN进行训练： 为了能更好得对图像的局部做判断，作者提出patchGAN的结构，也就是说把图像等分成patch，分别判断每个Patch的真假，最后再取平均！PatchGAN可以看成另一种形式的纹理损失或样式损失。在具体实验时，70x70的尺寸比较合适。 损失函数加入L1 loss：众所周知，用L1和L2 loss重建的图像很模糊，也就是说L1和L2并不能很好的恢复图像的高频部分(图像中的边缘等)，但能较好地恢复图像的低频部分(图像中的色块)。 图片的高低频信息：（1）低频就是颜色缓慢变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，梯度较小的一块区域，这部分就是低频。（2）高频就是相邻区域之间灰度相差很大，这就是变化快，梯度变化明显，即边缘部分，即高频显示图像边缘。图像的细节处也就是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。 pix2pix的损失函数pix2pix在CGAN的基础上加上了生成图像与原始图像的L1 loss：$$L_{L1}(G)=E_{y∼p_{data(x,y)},z∼p_z(z)}[‖y−G(x,z)‖_1]$$加入L1 loss增强了生成器对低频部分的还原（颜色变化平缓的部分，色块等等）。因此最总的loss为： $$G^∗=\min_G \max_D L_{cGAN}(G,D)+\lambda L_{L1}(G)$$其中：$$\min_G \max_D L_{cGAN}(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].$$ 缺点由于网络引入L1 loss，同时它是学习一个输入图片到输出图片的位移映射，映射范围十分有限，因此当训练集中不存在输入图片类似的样式时，输出的结果将不可控。 pix2pix 总结pix2pix是cGAN网络出来之后，在图片变化上使用的第一个网络。网络的亮点在于生成器与判别器使用conv-BatchNorm-ReLu单元的U-Net结构，在目标函数上引入L1 loss，使得生成的图片更加的真实。网络训练方便，使用了SGD + adam共同训练，使用了BN，dropout等技术等等。最终结果图如下：]]></content>
      <categories>
        <category>项目总结</category>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project one]]></title>
    <url>%2F2019%2F02%2F22%2Fproject-one%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>项目总结</category>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语义分割简要总结]]></title>
    <url>%2F2019%2F02%2F22%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[语义分割简要总结CNN padding 的方式： valid padding：当卷积到边界时，最后边界位置不够卷积则直接舍弃。 SAME padding：当卷积到边界时，最后边界位置不够卷积则用0补充，保持图片尺寸大小不变。 视觉未来研究方向： 三维数据集 序列数据集 使用图卷积网络（GCN）对点云进行分割 上下文知识 实时分割 存储空间 序列数据的时间一致性 多视角整合 SegNetFCN之后，CNN网络在语义分割领域引起了人们极大的兴趣。SegNet在FCN的基础上引入了更多的shortcut，它不是直接对不同层的feature map进行融合，而是通过Max pooling的方式传到后面的层中，这种方式能够包含更多的信息。 Dilated Convolutions孔洞卷积在FCN中有两个关键，一个是pooling减小图像尺寸增大感受野，另一个是upsampling扩大图像尺寸。在先减小再增大尺寸的过程中，将会有一些信息损失掉，那么能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？答案就是dilated conv 空洞卷积。空洞卷积的一个最大的特点就是可以增大感受野，避免使用pooling。图中，对于一个7x7的图像patch（a图），只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7(a) 普通卷积，1-dilated convolution，卷积核的感受野为$3 \times 3 = 9$。(b) 扩张卷积，2-dilated convolution，卷积核的感受野为$7 \times 7 = 49$。(c) 扩张卷积，4-dilated convolution，卷积核的感受野为$15 \times 15 = 225$。但是由于dilated convolution 存在一些问题： kernel 并不连续，也就是并不是所有的 pixel 都用来计算了，因此这里将信息看做 checker-board 的方式会损失信息的连续性。（在还原的标注图片上就会出现一些不连续的小格） 对于一些尺寸比较小的物体分割效果差。 解决方案：通向标准化设计：Hybrid Dilated Convolution (HDC)，图森组的文章对其提出了较好的解决的方法。他们设计了一个称之为 HDC 的设计结构。 第一个特性是，叠加卷积的 dilation rate 不能有大于1的公约数。比如 [2, 4, 6] 则不是一个好的三层卷积，依然会出现 gridding effect。 第二个特性是，我们将 dilation rate 设计成 锯齿状结构，例如 [1, 2, 5, 1, 2, 5] 循环结构。 第三个特性是，我们需要满足这个式子：就可以保证对所有的pixel都能够卷积到，同时层次的锯齿结构对小物体也有很好的检测效果。DeepLab V1： DCNNs的成功得益于DCNNs定位图像变换（平移等）的内在不变性, 这一属性能加强它们学习数据的分层抽象能力。不变性非常适用于高级视觉任务（目标检测）。但不利于低级任务，如语义分割，哪些我们需要知道他们精确的位置信息而不是他们的抽象特征。 DCNN定位图像变换的内在不变性理解：即对图像进行pooling 降低分辨率提高感受野，尽管图像变得比较模糊，位置信息也不准确，但是不影响网络对物体的识别，但是对于位置信息比较关心的语义分割来说就是一大缺点。 DCNN在图像标注任务应用上的两大技术障碍: 信号的降采样，分辨率低： DCNN中多次的max-pooling及downsampling(striding)造成信号分辨率减小, 信息失真比较严重 空间不灵敏性： DCNN对空间信息不敏感，它可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓 孔洞卷积：对于信息降采样，信息丢失的问题，我们使用’atrous’孔洞卷积，减少pooling的使用，同时扩展感受野，以获得更多的上下文信息。其中（a）为stride为2的pooling，pooling之后四个神经元的感受野对应为7。（b）中为stride = 1的pooling，四个神经元的感受野为5，虽然保留了更多的信息，但是感受野降低了，信息更加的冗余。（c）中使用stride=1，hole = 2的卷积核，四个神经元的感受野仍然为7，同时保留了更多的信息（features map的分辨率较高）。 感受野的计算：感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。当已知上一层的感受野计算下一层的感受野时有：$$r = (m-1) stride+ksize$$其中m为上一层的感受野。空洞卷积的感受野计算：dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。 全连接的CRF（条件随机场）DCNN的预测图可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓，其内在的不变性限制了对位置精度的预测（平移不变性破坏了模型对位置信息的预测），本文使用了全连接的CRF作为后处理操作，通过耦合DCNN的识别能力进一步优化分割的边缘。DenseDRF：对于每一个位置i，如果有观测值$x_i$(该位置的颜色)，标签$y_i$(类别信息)，。以像素为节点，像素与像素之间的关系作为边，就可以构成一个条件随机场，通过观测$x_i$的值来推断对应的类别信息$y_i$。denseCRF的公式如下：由式子可以看出来，CRF预测像素类别和像素的颜色强度，像素位置有关系，模型包含耦合相邻节点的能量项，有利于对空间邻近像素进行相同标签的分配。 下图是dilate conv + CRF的组合效果。 Deeplab v2deeplab v2在v1的基础上进行升级，其提出的ASPP技术来更好地分割多尺度的物体。通过采用最新的ResNet 图像分类DCNN构建了DeepLab的残差网络变体，实现了更好的语义分割性能。deeplab v2的特点： 使用Atrous Convolution 代替原来上采样的方法，能有效地扩大卷积核的视野，增加更多的上下文信息而不增加参数的数量或计算量。 提出多孔空间金字塔池化(ASPP)，在多尺度上鲁棒地分割物体。ASPP使用多个采样率和有效视野的滤波器对features map进行多尺度信息提取。 第三，通过合并DCNN和概率图模型全连接CRF方法，增强物体边界的定位。 DCNN应用于语义图像分割中的三个挑战: 特征分辨率下降问题解决：该问题是由连续DCNN层中的最大池化和下采样(滑动步长)的重复组合引起的。为了克服这一障碍并有效地产生更密集的特征图，将最后的池化层替换为atrous convolution 层 多尺度下的物体的存在该问题由于物体的多尺度状态引起的，有些物体太小或者太大无法检测出来。处理这种情况的一个标准方法是向DCNN提供相同图像的重缩放版本，然后聚合特征或分数图，但开销很大。我们的方法：我们有效地使用具有不同采样率的多个并行的多孔卷积层来实现对特征图的采样，称之为“多孔 space pyramid pooling”(ASPP)技术。在多个尺度上捕获物体的上下文信息。 DCNN位移不变性导致对位置定位模糊：一种减轻此问题的方法是当计算最终的分割结果时使用跳跃层(skip-layers)从多个网络层提取特征。我们的方法是：通过全连接的条件随机场(CRF)来提高模型捕获精细细节的能力。 deeplap v2工作流程 将所有全连接的层转换为卷积层 通过多孔卷积层对conv5输出的features map进行多尺度的特征提取，提高特征分辨率以及感受野，然后送入softmax进行分类。此时产生的features map大小为原图的1/8 采用双线性插值对features map进行8倍上采样以达到原始图像分辨率 生成全连接的CRF的输入，优化分割结果 值得注意的是：特征图的训练和全连接CRF的训练是分开进行的，先用DCNN生成预测结果图，然后用全连接CRF进行分割结果的优化。上图是DCNN产生的预测图，然后通过1，2，10次的CRF迭代的结果。 deeplab v3V3在v2的基础上进行了结构上了一些改进，v3，v3+，Xecption这里实在不想在看了，以后有机会回来补充。先留一个flag。可能就是之后几天里某一天吧。state of art 似乎绕不过。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interview Summary]]></title>
    <url>%2F2019%2F02%2F21%2FInterview-Summary%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP动态规划问题]]></title>
    <url>%2F2019%2F02%2F21%2FDP%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[DP动态规划问题 动态规划方法常常应用于解决优化问题，通常分析一个问题是否可以用动态规划方法求解可以从以几个方面判断： 原问题可分，原问题的数据结构(array,tree,graph)可以进行划分。 原问题有最优子结构。 原问题的最优解将由一系列的子问题的解组合而成。 动态规划法的一般思路为，通过枚举所有可能的分类策略，来组合成最优解。关键步骤在于找到一个合适的递推公式，将原问题转化为一个多步决策的问题。 下面是重点介绍几个DP问题，以及他们的解题过程。 矩阵连乘问题： 问题描述：给定n个矩阵 $（A_1,A_2,A_3…..A_n）$，其中$A_i$与$A_{i+1}$是可乘的，i=1,2,…n-1。考察n个矩阵的连乘积 $A_1A_2A_3,….A_n$ 。由于矩阵乘法满足结合律，试提出矩阵连乘积最优计算次序，使得计算量最小。分析：确定矩阵相乘次序的问题等价于在原始序列上添加括号。通过改变不同位置上的矩阵的计算次序，能够减小矩阵乘法所需要的计算次数。经典的序列划分问题。现在来判断该问题是否可以用动态规划方法来求解： 原问题是否可分：假设找到一个位置k添加括号能够得到最优解，因此将原问题转化为（1，k）与（k+1，n）两个序列，子问题性质与原问题完全相同，因此问题可分。 问题的递推公式（最优子结构）： $$ OPT[1,n] = OPT[1,k]+OPT[k+1,n] + p_0p_kp_{n+1} $$ 由于子问题之间不存在相互关系，原问题的最优解由一系列子问题的最优解组成。 矩阵连乘问题求解：若使用递归的方法，对原问题进行枚举，枚举每一种加括号的方式，能够得到原问题的解，但是计算量巨大，对这道题来说，他的时间复杂度是：$2^{n-1}$算法框架如下：12345678910111213recursive_matrix_chain(i,j)&#123; if i == j then return 0 OPT(i,j) = INF for k=i to j-1: q = recursive_matrix_chain(i,k)+ recursive_matrix_chain(k+1,j)+ p[i]*p[k+1]*p[j+1] if q&lt;OPT(i,j): OPT(i,j) = q return OPT(i,j)&#125; memorizing technique：动态规划法的英文为dynamic programming，programming 这个词最早有tabular这个词演化而来，tabular意为表格，因此DP方法可以直观的理解为动态填表法。动态规划法的一个重要思想就是：对子问题的结果进行保存。算法框架如下：123456789101112131415memorize_matrix_chain(i,j)&#123; if OPT[i,j] != NULL: //如果子问题已经算过了，就可以不用算了 return OPT[i,j] if i == j: //递归法的出口 OPT[i,j] = 0 else: for k = i to j - 1: //对每一个子问题划分情况进行枚举 q = memorize_matrix_chain(i,k)+ memorize_matrix_chain(k+1,j) + p[i]*p[k+1]*p[j+1] if q &lt; OPT[i,j]: OPT[i,j] = q return OPT[i,j] &#125; 该方法的时间复杂度为： $T(n) = O(n^3)$ ，动态规划问题的时间复杂度计算方法为：子问题的个数子问题的时间，对于本题： $O(n^2)n = O(n^3) $一种更快的实现方法，从底往上计算省略递归步骤。 具体思路是：先将分割的长度由2到n进行遍历，每次拿出一个长度然后对其进行由i到j每个位置的划分，均求一个最大，对每次的结果进行保存，最后得出结果。123456789101112131415matrix_chain_multiplication()&#123; for i = 1 to n : OPT[i,i] = 0 for l = 2 to n : //子串的长度由2到n递增 for i = 1 to n - l + 1: //l长度下，对i所有可能位置进行遍历 j = i + l -1 // j移到子串的最后位置上 opt[i,j] = INF for k = i to j - 1: //对每一个位置均遍历一下括号的位置 q = opt[i,k]+opt[k+1,j]+p[i]*p[k+1]*p[j+1] if q &lt; opt[i,j]: opt[i,j] = q s[i,j] = k return opt[1,n]&#125; 0/1背包问题 给定一个集合其中有S个物品，每个物品i有一个重量 w_i 和一个价值 v_i ，每个物品只有一个，你有一个能装重量为W的背包。问怎么装使得所装物品的价值最大。 分析：我们将0/1背包问题转化成一个多步决策的问题，在第i步决定是否选择第i个物品。因此有一下的递推表达式：$$ opt({1,2,…n},W) = \max \begin{cases} opt({1,2,…n-1},W) &amp; opt({1,2,…n-1},W-w_n)+v_n \end{cases}$$算法框架如下：123456789Knapsack(n,w)&#123; for w = 1 to W: OPT[0,w] = 0 for i = 1 to n: //现在拿i个物品 for w = 1 to W: // 现在拿出w个空间来装 if w &gt; w[i]: //当前拿出的空间够装现在的货物 OPT[i,w] = max(opt[i-1][w],opt[i-1][w-w[i]]+v[i])&#125; 回退法判断物品是否被取走：12345678910void traceback()&#123; for i = n to 2: if(m[i][c] == m[i-1][c]): x[i] = 0 else: x[i] = 1 c -= w[i] x[1] = m[1][c]&gt;0? 1:0;&#125; 时间复杂度为 O(nW) 伪多项式时间。$ O(nW) = O(n*2^{logW})$ ，W为输入的长度，当W很大时，算法效率很低。需要注意的是，我们选择物品的顺序是从头到尾挑选，而不是在一个子集中随机挑选。 最小覆盖点问题： 问题描述：在一个图中找到最少的点，使其能够覆盖图中所有的边。 问题分析：这个问题可以用一个树的结构的分析。当选取当前的点作为最优结果中的一点时，从从改点的所有子节点作为新的子问题，否则选取所有的儿子节点，从其孙子节点作为子问题。 该问题的最优子结构为：$$ opt(root) = \min ( 1 + \sum_copt(c) , children + \sum_gopt(g) )$$算法框架如下：1234567vertex_cover(root)&#123; if(root == NULL): return 0 opt(root) = min(sum_of_child+opt(g),1+opt(c)) return opt(root) &#125; 动态规划问题的适用于求解那些子问题存在大量重复的问题，可以通过存储中间结果的方式大大缩小程序的复杂度。通常的求解方式有递归法，动态填表法。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语义分割系列 -- FCN详解]]></title>
    <url>%2F2019%2F02%2F20%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%B3%BB%E5%88%97-FCN%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[语义分割系列 – FCN详解FCN是深度学习用于语义分割领域的开山之作，他的主要核心贡献在于： 全卷积（convolutional）：采样端对端的卷积网络，将普通分类网络的全连接层换上对应的卷积层（FCN） 上采样(upsample)：即反卷积（deconvolution），恢复图片的位置信息等，反卷积层可以通过最小化误差学习得到。 跳跃连接(skip layer)：通过连接不同卷积层的输出到反卷积层，来改善上采样很粗糙的问题。 FCN：Fully Convolutional Networks for Semantic Segmentationsubmit time: 2015arxiv link FCN与CNN通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率），比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。如下：下图中的猫, 输入AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高。FCN相对用于图片分类领域的经典网络如Alexnet, VGG, Googlenet等只是在最后几层稍作了修改，替换，以让它们适用在了semantic segmentation上面。下图中可看出FCN相当于分类CNN网络在模型后端所有的变化。FCN全卷积：前端输入，一般CNN分类网络选择使用固定大小的image patch来作为输入，这个patch往往是从原图当中剪切出来的；而FCN网络则使用整张原图来作为输入，允许图片大小不固定。然后在模型的后端，CNN分类网络会使用FC层对最后的CNN层生成出的feature map进行处理，从而丢掉由前端CNN各层处理所一直保存着的图片上敏感区域的位置信息，进而只抽象表达出它的类别信息来，以交由后面的softmax等层来最终预测出它的类别概率分布；FCN则不同，它丢掉了CNN分类网络后端的FC层，进而保留了图片上的区域位置信息，又在其后加上了几层CNN来进一步分析处理，整合主干网络输出特征，最终它生成出有着C+1（C为目标类别数，+1是为了考虑进去图片背景）个channels的heat map（本质上可以理解为是cnn所产生的feature map）来。由于FCN网络前端CNN处理过程中会不断选择用Pool来整合、下采样特征，从而扩大后来层次的receptive fields，因此最终我们生成出来的heat map其大小肯定要小于原输入图片大小。实际上最终生成的feature map比原图片缩小s倍，s为图片中下采样层次stride的乘积即累积下采样步长。而我们Semantic segmentation的目标是要预测输入图片每个像素点的可能类别。因此我们要想办法将输出的heat map与input raw image关联起来。简单的话可以直接使用线性二次插值来解决。FCN中通过在网络最后加入步长为s的deconvolution层来使得最终的网络输出heat map具有与输入原图一样的大小。全连接层-&gt;卷积层 第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为k=7，padding = 0,stride = 1,共4096个卷积核，这样输出数据体就为[1x1x4096]了。 第二个全连接层，令其滤波器尺寸为K=1，共有4096个卷积核，这样输出数据体为[1x1x4096]。 对最后一个全连接层，令其K=1，共1000个卷积核，最终输出为[1x1x1000] 上采样：下图是一个反卷积的过程，首先在feature map上增加padding，padding的大小为Kernel size - 1，padding部分用0来填充。随后使用卷积核在对该feature 进行卷积操作。该图是一个strides(步长)为1的反卷积，即FULL卷积方式：full: 滑动步长为1，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：N1+N2-1 x N1+N2-1下图是步长为2的反卷积，可以使得图片变大，反卷积中步长指的是原图像素间填充0的行数。这时候原图中就会出现孔，可以这么理解，反卷积与卷积对应，当卷积stride为2的时候，表明下一次卷积将跨越两个像素。当反卷积stride为2时，意味着反卷积的步长为0.5，即需要走2步才能走到下一个像素位置。反卷积效果： 跳跃连接(skip layer)：由于直接从最后的feature map上采样到图片大小，精度上过于粗糙，这是因为当网络较深时可以学到比较深度的特征，同时过深的网络也会丢失空间位置信息。这意味着较浅层的输出具有更多位置信息。如果我们将两者结合起来，我们就提高结果。训练过程：第一阶段：用经典的分类网络进行初始化，最后两层参数不使用。从特征图（16*16*4096）预测分割小图（16*16*21），之后直接上采样为大图。反卷积（橙色）的步长为32，即特征图放大16倍，这个网络称为FCN-32s。升采样分为三次完成（橙色×3）。进一步融合了第3个pooling层的预测结果。 第三次反卷积步长为8，记为FCN-8s。 LOSSFCN的loss 为交叉墒loss，先接一个soft Max将网络的输出转化为概率。用概率计算交叉墒。tensorflow 中调用的函数为：12loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=tf.squeeze(annotation, squeeze_dims=[3]),name="entropy"))) CNN 网络优化通常使用的是SGD，随机梯度下降法来优化。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cross entropy 交叉熵以及softmax]]></title>
    <url>%2F2019%2F02%2F20%2Fcross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax%2F</url>
    <content type="text"><![CDATA[cross entropy 交叉熵以及softmax交叉熵常常用在CNN网络中，作为网络的loss，他描述的是模型数据分布与训练数据之间的相似程度。最小化交叉熵等价于模型产生数据与训练数据相似度越高。 信息量：用来衡量一件事情的不确定程度，一件事情发生概率越大，他的不确定性越小，信息量越少。信息量的计算公式为：$$I(x_0) = - \log(P(x_0))$$例如，当$p(x_0) = 0.1,I(x_0) = 3.32$，$p(x_0) = 0.999,I(x_0) = 0.0014$ 熵：用于衡量一个系统的混乱程度，代表一个系统信息量的总和。当一个系统信息量越大越不稳定。熵等于所有事件所带来的信息期望总和。$$H(x) = - \sum_{x\in X}p(x) \log p(x)$$交叉熵：交叉熵描述两个事件之间的相互关系：$$H(A,B) = -\sum_i P_{A}(x_i)log(P_{B}(x_i))$$ 如何计算两个分布之间的不同： KL散度KL散度，有时候也叫KL距离，一般被用于计算两个分布之间的不同，KL散度不具备有对称性。$$D_{KL}(A||B) = \sum_i P_A(x_i)\log(\frac{P_A(x_i)}{P_B(x_i)}) = \sum_{i}P_{A}(x_i)log(P_{A}(x_i ))- \sum_i P_{A}(x_i)log(P_{B}(x_i))$$由上式可以发现，KL散度 = - 熵 + 交叉熵，当熵固定不变时，认为交叉熵等价于KL散度。 机器学习中使用交叉熵代替KL散度：机器学习的过程中希望在训练数据上模型学到的分布 P(model) 和训练数据groundtruth的分布 P(real) 越接近越好，可以通过优化KL散度，使其KL散度最小来达到目的。由于训练数据groundtruth是固定的因此求解KL散度将会等价于求解交叉熵。因此最小化交叉熵将会得到一个比较好模型。 softmax：在神经网络分类任务来说，最后一层将会输出x的一维特征，每一个位置表示一个特征表示值。这个表示值越大认为这张图片是这个类别的概率越大。因此可以用特征表示值来判断类别。但是在实际运用中，特征表示值的用途不大, 我们更希望得到具有统计意义的概率。例如可以利用概率来优化KL散度，使得预测结果更加准确。softmax它将多个神经元的输出，映射到（0,1）区间内，表示类别的概率，从而进行多分类。softmax的公式如下：$$S_i = \frac{e^{V_i}}{\sum_j{e^{V_j}}}$$其中V表示神经网络输出的一维数组。 softmax在实际使用时需要注意数值溢出的问题。如上公式，在计算概率的时候存在指数运算，当V数值很大的时候将会发生溢出。因此需要对上式做一下处理，将指数部分同时减去指数中的最大值。$$D = max(V) \\S_i = \frac{e^{V_i - D}}{\sum_j{e^{V_j - D}}} = \frac{e^{V_i}}{\sum_j{e^{V_j}}} / \frac{D}{D}$$经过处理后，保证数值不会发生溢出现象。 神经网络中的应用大多数的CNN网络中，均适用softmax + cross entropy作为损失函数。首先是交叉熵LOSS：$$Loss = -\sum_i P_{groundtruth} \log P_{predict}$$其中$P_{groundtruth}$是真值的类别分布概率。在多分类问题中，一张图片只属于一个类别，因此$P_{groundtruth}$表示成one hot编码，即[0,0,…,1,0,0]这种形式。对于$P_{predict}$来说，神经网络输出的特征值经过softmax层，转换为概率的形式。因此Loss 最终会等于：$$-\log p_i$$i表示这个图片真实的类别。 交叉熵+ softmax反向求导：由上式可知，交叉熵的形式非常简单，其中$p_i$由softmax计算得到。带入softmax公式，得到交叉熵最后的形式为：$$L = - \log \frac{e^{V_{i}}}{\sum_j e^{V_{j}}}$$ 对交叉熵的求导：在进行BP方向传播的时候，更新参数的时候，误差需要由交叉熵提供，即$-\log p_i$，然后对每一个参数值通过链式法制都求一次偏导,例如对$W_{ij}$：$$\frac{\partial{L}}{\partial{W_{ij}}} = - \frac{1}{\frac{e^{a_i}}{\sum_k e^{a_k}}} \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}} \frac{\partial{a_j}}{\partial{W_{ij}}}$$对softmax进行求导如下：上式中间部分为对softmax求导，令$$ y_i = \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}$$对softmax求偏导数：$$\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}}$$当 i!=j 时：$$\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ 0 - e^{a_i}e^{a_j}}{\Sigma^2}=-\frac{e^{a_i}}{\Sigma}\frac{e^{a_j}}{\Sigma}=-y_iy_j$$当 i==j 时：$$\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ e^{a_i}\Sigma - e^{a_i}e^{a_j}}{\Sigma^2}=\frac{e^{a_i}}{\Sigma}\frac{\Sigma - e^{a_j}}{\Sigma}=y_i(1 - y_j)$$求导过程比较简单，算一下就知道了，不要害怕。得到误差对权重的偏导数就可以对该权重进行更新了，CNN网络通常使用的更新方式为SGD。 SGD 随机梯度下降法最优化算法的核心是从当前点走到下一个点，是的目标函数得到下降。即$x_0 -&gt; x_1$，最优化算法考虑两个问题，即从当前点，移动的方向和步长。可以写成下面形式：$$x_{k+1} = x_k + \eta P_k$$其中$P_k$是前进方向。令$P_k = -\nabla f_k$，即负梯度方向时，下降速度最快。这种方法在及其学习中称为梯度下降法。他有一个缺点，就是需要严格求解出整个数据集的梯度，才能走到下一步。而且十分容易陷入局部极小点,因此我们使用SGD来改善这一现象。SGD 算法的表达式和GD差不多:$$x_{t+1}=x_t+\eta_t g_t$$这里 $g_t$ 就是所谓的Stochastic Gradient，它满足 $E[g_t]=-\nabla f(x_t)$。它对导数的要求非常低，导数算起来非常快。由于数据样本中存在大量无用的冗余信息，因此使用随机梯度下降法可以得到近似的下降梯度，而仅仅话费少量的计算资源。softmax tensorflow 实现版本12345678910111213141516171819202122232425262728293031323334import tensorflow as tfimport numpy as np# downlown the datafrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/",one_hot=True)# input dataX = tf.placeholder(tf.float32,[None,784])Y = tf.placeholder(tf.float32,[None,10])# model variableW = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10]))# define modely_predict = tf.matmul(X,W) + bcross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=y_predict))optimizer = tf.train.GradientDescentOptimizer(0.5)train_step = optimizer.minimize(cross_entropy)sess = tf.InteractiveSession()global_initial = tf.global_variables_initializer()sess.run(global_initial)for i in range(1000): batch = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;X:batch[0],Y:batch[1]&#125;)correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(Y,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))print(sess.run(accuracy,feed_dict=&#123;X:mnist.test.images,Y:mnist.test.labels&#125;))print(sess.run(b))]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 题解(持续更新)]]></title>
    <url>%2F2019%2F02%2F20%2FLeetCode-%E9%A2%98%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本篇文章置顶，长期更新，用于记录日常刷题题解以及需要注意的tip。 2019年的关键词：思路要紧！ 28/5/2019 116.Populating Next Right Pointers in Each Node,117这一题看leetcode上的表示方式十分的唬人，实际上还算是比较简单。思路就是层次遍历，然后每次遍历用两个数来维护每一层的遍历次数。在元素进队列的时候进行左右的连接。（116的树为完全树，117的树不是完全树，同样的做法） 12345678910111213141516171819202122232425262728293031323334353637383940"""# Definition for a Node.class Node(object): def __init__(self, val, left, right, next): self.val = val self.left = left self.right = right self.next = next"""class Solution(object): def connect(self, root): """ :type root: Node :rtype: Node """ if root == None: return root que = [] que.append(root) count = 1 record = 0 while len(que) &gt; 0: node = que.pop(0) count -= 1 if node.left: que.append(node.left) record += 1 if len(que)&gt;1: que[-2].next = que[-1] if node.right: que.append(node.right) record += 1 if len(que)&gt;1: que[-2].next = que[-1] if count == 0: node.next = None count = record record = 0 return root 21/5/2019 103. Path Sum II思路：这一题可以沿着深度遍历的方向去做，然后在遍历的过程中，记录下路径。然后判断，当前path上的元素之和是否等于sum，并且当前节点是叶子结点。划重点：sum(path) + root.val 之和来判断，而不是把所有val都加到path上。 123456789101112131415161718192021222324252627282930313233# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def __init__(self): self.result = [] def find_path(self,root,sums,path): if root == None: return if sum(path) + root.val == sums and root.left == None and root.right == None: self.result.append((path+[root.val])[:]) return path.append(root.val) self.find_path(root.left,sums,path) self.find_path(root.right,sums,path) if path!=[]: path.pop() def pathSum(self, root, sum): """ :type root: TreeNode :type sum: int :rtype: List[List[int]] """ path = [] self.find_path(root,sum,path) return self.result 114.Flatten Binary Tree to Linked List思路：这一题太巧妙啦，要把所有节点压到右支上，这时候用的方法是先后续遍历，用一个变量记录上一个节点，然后作为当前节点的右节点，同时砍掉当前的左节点。 1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def flatten(self, root): """ :type root: TreeNode :rtype: None Do not return anything, modify root in-place instead. """ self.prev = None def dfs(root): if root == None: return None dfs(root.right) dfs(root.left) root.right = self.prev root.left = None self.prev = root dfs(root) 19/4/2019 107. Binary Tree Level Order Traversal II思路：哇，类似的专题好多啊，这一题要求按层次，从最后一层依次打印到第一层，与前面几题的区别在于，每次将层插入第一个位置。 12345678910111213141516171819202122232425class Solution(object): def levelOrderBottom(self, root): """ :type root: TreeNode :rtype: List[List[int]] """ res = [] line =[root] if root == None: return res num = 1 val = [] while len(line): node = line.pop(0) num-=1 val.append(node.val) if node.left: line.append(node.left) if node.right: line.append(node.right) if num == 0: res.insert(0,val[:]) val = [] num = len(line) return res 18/4/2019 102. Binary Tree Level Order Traversal思路：层次遍历一棵树，最近做的题都比较接地气啊，都是大一做的题，哈哈我感觉记得这么清楚全要谢谢林老师。这一题要求把每一行的的元素依次打印出来，每一行一个list。 用队列结构来处理这个问题。首先从根节点开始，依次进队列，每次循环头节点出队列，并将其子节点进队列。然后维护一个计数器，计数器初始化为每一行list长度，当这个变量变成0的时候说明这一行已经遍历完成了。重新开一个list。 1234567891011121314151617181920212223242526class Solution(object): def levelOrder(self, root): """ :type root: TreeNode :rtype: List[List[int]] """ res = [] if root == None: return res line = [] line.append(root) val = [] num = 1 while len(line): node = line.pop(0) val.append(node.val) num -= 1 if node.left != None: line.append(node.left) if node.right != None: line.append(node.right) if num == 0: res.append(val) val = [] num = len(line) return res 103. Binary Tree Zigzag Level Order Traversal思路：这一题沿着Z字形进行输出，只需要在上一题的基础上加一个记录层数的变量即可。 1234567891011121314151617181920212223242526272829303132class Solution(object): def zigzagLevelOrder(self, root): """ :type root: TreeNode :rtype: List[List[int]] """ res = [] if root == None: return res line = [] line.append(root) val = [] num = 1 level = 0 while len(line): node = line.pop(0) num -= 1 val.append(node.val) if node.left: line.append(node.left) if node.right: line.append(node.right) if num == 0: num = len(line) if level%2 == 1: val.reverse() res.append(val) else: res.append(val) val = [] level += 1 return res 15/4/2019 96. Unique Binary Search Trees思路：这一题说给一个数字，求出所有平衡二叉树的个数。根据平衡二叉树的性质可以知道，左子树小于根节点，右子树大于根节点。因此有这种关系： f(1) = f(0) x f(2), f(2)=f(1) x f(1), … f(n) = f(n-1)xf(0) 12345678class Solution(object): def numTrees(self,n): res = [0] *(n+1) res[1] = 1 for i in range(1,n+1): for j in range(j): res[i] += res[j]*res[i-j-1] return res 94. Binary Tree Inorder Traversal这一题要求按中序遍历的方式输出一颗二叉树。可用递归的方式解决。想起这道题，林老师上课的画面迎面而来，哈哈。 中序遍历思路为沿着树的枝往下走，当回溯时，第二次遇到这个节点的时候返回，此时记录下遍历的节点值。 1234567891011121314151617class Solution(object): def __init__(self): self.res = [] def dfs(self,root): if root == None: return self.dfs(root.left) self.res.append(root.val) self.dfs(root.right) def inorderTraversal(self, root): """ :type root: TreeNode :rtype: List[int] """ self.dfs(root) return self.res 101. Symmetric Tree思路：这一题判断树是否是镜像。用树的结构进行递归，每次递归判断是否为镜像，如果不是则返回False。每次进行递归的时候传入树的对称边。 12345678910111213141516171819class Solution(object): def dfs(self,left,right): if left == None or right == None: if left != right: return False else: return True if left.val != right.val: return False return self.dfs(left.left,right.right) and self.dfs(left.right,right.left) def isSymmetric(self, root): """ :type root: TreeNode :rtype: bool """ if root == None: return True return self.dfs(root.left,root.right) 25/3/2019 92. Reverse Linked List II分析：这一题需要定义头节点，关于元素的调换的问题，都需要定义头节点。然后记住tail，head，思路清晰一点，就很好做了。 12345678910111213141516171819202122232425262728293031323334# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def reverseBetween(self, head, m, n): """ :type head: ListNode :type m: int :type n: int :rtype: ListNode """ if m == n: return head dummy = ListNode(-1) dummy.next = head p = dummy newhead = p for i in range(m): newhead = p p = p.next tail = p q = p p = p.next for i in range(n-m): p_pre = p.next p.next = q q = p p = p_pre tail.next = p_pre newhead.next = q return dummy.next 93. Restore IP Addresses分析：这一题蛮有意思的我感觉。它的内循环是从1到3，即截取的字符长度，每个截取的长度都作为ip地址的一部分。每次截取子串的时候需要对他们进行合法性判断。 123456789101112131415161718class Solution(object): def __init__(self): self.res = [] def helper(self,s,ret,index,count): if count&gt;4: return if count == 4 and index == len(s): self.res.append(res[:-1]) for i in range(1,4): if i + index &gt; len(s): break temp = s[index,index+i] if (temp[0] == '0' and len(temp)&gt;1) and (len(temp) and int(temp)&gt;=256): continue helper(s,ret+temp+'.',index+i,count+1) def restoreIpAddresses(self,s): self.helper(s,'',0,0) return self.res 24/3/2019 91. Decode Ways分析：这一题是典型的动态规划题，主要就是想到状态转移方程该怎么写就行了。有几种情况要进行分析。首先当前位置上为0的时候，当前的字母需要与前一个字母组成一个合法数据才行。否则就是按照正常的方式单个字母，两个字母的方式。 123456789101112131415161718192021222324252627class Solution(object): def numDecodings(self, s): # 动态规划 """ :type s: str :rtype: int """ if len(s) == 0 or s[0] == '0': return 0 dp = [0]*len(s) dp[0] = 1 for i in range(1,len(s)): if s[i] == '0': # 必须与前一个组成一个二位数 if s[i-1] == '2' or s[i-1] == '1' : if i == 1: dp[i] = 1 else: dp[i] = dp[i-2] elif int(s[i-1:i+1])&lt;=26 and s[i-1]!='0': if i == 1: dp[i] = 2 else: dp[i] = dp[i-1]+dp[i-2] else: dp[i] = dp[i-1] return dp[len(s)-1] 23/3/2019 这两天的状态和前两天一样，没办法调整🤢 90. Subsets II这题用递归的方法做，我觉得在做题的时候应该要多总结思路，首先就要确定这一题是什么类型的题目。然后向方法，一定唔要无头苍蝇似的，面试题差不多就median了，加油咯⛽️。 12345678910111213141516171819class Solution(object): def dfs(self,nums,pos,temp,res): if sorted(temp) not in res: res.append(sorted(temp)) for i in range(pos,len(nums)): temp.append(nums[i]) self.dfs(nums,i+1,temp,res) temp.pop() def subsetsWithDup(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ res = [] if len(nums) == 0: return [] self.dfs(nums,0,[],res) return res 这一题有一个地方，需要注意一下，就是深浅拷贝的问题。（错过的问题） 12345678temp = [1,2,3]a = temp # 浅拷贝，a随着temp而变化a = temp[:] # 深拷贝，a与temp无关import copya = copy.deepcopy(temp) # 深拷贝## 排序问题a.sort() # 直接改变asorted(a) # 返回值为排序后的结果 89. Gray Code分析：这一题本来想要递归的方法来做，但是奈何，递归不满足格雷码依次变一位的原则。因此本题采用格雷码的公式求解。G(i) = i ^ (i/2) 12345678910class Solution(object): def grayCode(self, n): """ :type n: int :rtype: List[int] """ res = [] for i in range(1&lt;&lt;n): res.append(i^i&gt;&gt;1) return res 21/3/2019 100. Same Tree最近有点儿奇怪呀， 明天想着做的事情，都没能做起来。 分析： 这一题用递归调用的方式求解。 123456789101112131415161718192021# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def isSameTree(self, p, q): """ :type p: TreeNode :type q: TreeNode :rtype: bool """ if p == None: return q==None if q == None: return False if p.val != q.val: return False return self.isSameTree(p.right,q.right) and self.isSameTree(p.left,q.left) 18/3/2019 73. Set Matrix Zeroes 一直想刷题一直没刷，很惭愧。 分析： 这一题是找出行活列含1的数，然后将整行置0。对呀python的数组，可以整行整行的赋值： 1234matrix[key] = [0]*n # 对key这一行整行赋值#对列赋值,不可以整行for i in range(n): matrix[i][key] = 1 1234567891011121314151617181920212223242526class Solution(object): def setZeroes(self, matrix): """ :type matrix: List[List[int]] :rtype: None Do not return anything, modify matrix in-place instead. """ dict_x = &#123;&#125; dict_y = &#123;&#125; if len(matrix) == 0: return if len(matrix[0]) == 0: return m = len(matrix) n = len(matrix[0]) for i in range(m): for j in range(n): if matrix[i][j] == 0: if i not in dict_x: dict_x[i] = 1 if j not in dict_y: dict_y[j] = 1 for key in dict_x.keys(): matrix[key] = [0]*n for key in dict_y.keys(): for i in range(m): matrix[i][key] = 0 77. Combinations 分析：这一题目的就是用递归的方式来求解，需要记住的是上一次的递归起点。需要注意的一点是，当一个list要添加另一个list作为一项时，使用：list.append(list1[:]) 12345678910111213141516class Solution(object): def dfs(self,n,idx,k,res,cur): if k == 0: res.append(cur[:]) else: for i in range(idx,n): if k &gt; n-i: return [] cur.append(i+1) self.dfs(n,i+1,k-1,res,cur) cur.pop() def combine(self,n,k): res = [] cur = [] dfs(n,0,k,res,cur) return res 78. Subsets 分析：这一题的思路是，看到这种递归问题，想到需要用循环来做。需要所有长度的情况都考虑进去。需要把所有的长度都考虑进去。因此要维护一个长度，由于不重复，因此需要维护一个下标。 1234567891011121314151617181920class Solution(object): def dfs(self,nums,idx,ilen,res,cur): if ilen &gt; len(nums): return if len(cur) == ilen: res.append(cur[:]) for i in range(idx,len(nums)): cur.append(nums[i]) self.dfs(nums,i+1,ilen+1,res,cur) cur.pop() def subsets(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ res = [] cur = [] self.dfs(nums,0,0,res,cur) return res 80. Remove Duplicates from Sorted Array II这题从头扫描到尾巴，当情况符合的时候进行覆盖。le表示重复的个数，每一次覆盖条件满足都需要覆盖。 12345678910111213141516171819202122class Solution(object): def removeDuplicates(self, nums): """ :type nums: List[int] :rtype: int """ if len(nums) == 0: return 0 le = 0 pos = 0 for i in range(1,len(nums)): if nums[i-1] == nums[i]: le += 1 if le&lt;2: pos+=1 nums[pos] = nums[i] else: le = 0 pos+=1 nums[pos] = nums[i] # nums[pos] = nums[len(nums)-1] return pos+1 14/3/2019 分析： 犹豫要不要用python刷题，发现python实在是方便,这一题用stack的思路来做。首先用/把字符进行分割，然后用一个dict组织。 1234567891011121314151617181920class Solution(object): def simplifyPath(self, path): """ :type path: str :rtype: str """ str = path.split('/') res = [] for ch in str: if ch == '..': if len(res) != 0: res.pop() elif ch!='' and ch!='.': res.append(ch) ans = '/' for ch in res: ans += ch+'/' if len(ans) == 1: return ans return ans[:len(ans)-1] 11/3/2019 63. Unique Paths II 分析：用动态规划做，递推公式为：$path[i][j] = path[i-1][j]+path[i][j-1]$。需要先把第一行和第一列先填上1。 1234567891011121314151617181920212223class Solution &#123;public: int uniquePathsWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) &#123; if(obstacleGrid.size() == 0||obstacleGrid[0].size() == 0) return 0; if(obstacleGrid[0][0] == 1 ) return 0; int height = obstacleGrid.size(); int width = obstacleGrid[0].size(); vector&lt;vector&lt;double&gt;&gt; path(height,vector&lt;double&gt;(width,0)); for(int i = 0;i&lt;width&amp;&amp;obstacleGrid[0][i]!=1;i++)&#123; path[0][i] = 1; &#125; for(int i = 1;i&lt;height&amp;&amp;obstacleGrid[i][0]!=1;i++)&#123; path[i][0] = 1; &#125; for(int i = 1;i&lt;height;i++)&#123; for(int j = 1;j&lt;width;j++)&#123; if(obstacleGrid[i][j] == 1) continue; path[i][j] = path[i-1][j]+path[i][j-1]; &#125; &#125; return path[height-1][width-1]; &#125;&#125;; 64. Minimum Path Sum 分析：这一题和上一题差不多，唯一的区别在于这一题是找到最小的代价，因此去min就可以了。 1234567891011121314151617181920class Solution &#123;public: int minPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; if(grid.size() == 0 || grid[0].size() == 0) return 0; int height = grid.size(); int width = grid[0].size(); for(int i = 1;i&lt;width;i++)&#123; grid[0][i] += grid[0][i-1]; &#125; for(int j = 1;j&lt;height;j++)&#123; grid[j][0] += grid[j-1][0]; &#125; for(int i = 1 ;i&lt;height;i++)&#123; for(int j = 1;j&lt;width;j++)&#123; grid[i][j] += min(grid[i-1][j],grid[i][j-1]); &#125; &#125; return grid[height-1][width-1]; &#125;&#125;; 65. Valid Number 分析：字符串的转移这种问题很讨厌啊，情况太多了，总之思路就是从头到位扫一遍，判断很多边界情况。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Solution &#123;public: bool isNumber(string s) &#123; if( !s.empty() )&#123; s.erase(0,s.find_first_not_of(" ")); s.erase(s.find_last_not_of(" ") + 1); &#125; if(s.size() == 0) return false; if(s.size() == 1&amp;&amp;s[0] == '.') return false; unordered_map&lt;char,int&gt; amap; amap['-'] = 0; amap['+'] = 0; amap['.'] = 0; amap['e'] = 0; int i = 0; int flag = 0; while(i&lt;s.size())&#123; if('0'&lt;=s[i]&amp;&amp;s[i]&lt;='9')&#123; flag = 1; i++; continue; &#125; if(s[i] == '-'||s[i] == '+')&#123; if(amap['-'] + amap['+'] &gt; 0)&#123; if(i&gt;0&amp;&amp;s[i-1]=='e')&#123; i++; if(i&gt;=s.size()) return false; continue; &#125;else&#123; return false; &#125; &#125; else&#123; if(i!= 0&amp;&amp;s[i-1]!='e') return false; i++; if(i&gt;=s.size()) return false; continue; &#125; amap[s[i]]++; i++; if(i&gt;=s.size()) return false; continue; &#125; if(s[i] == '.')&#123; if(amap['.'] != 0) return false; if(amap['e']!=0) return false; if(i==0||('0'&lt;=s[i-1]&amp;&amp;s[i-1]&lt;='9'))&#123; i++; amap['.']++; continue; &#125; if(s[i-1]=='-'||s[i-1]=='+')&#123; i++; amap['.']++; continue; &#125; &#125; if(s[i] == 'e')&#123; if(amap['e']!=0) return false; if(i&gt;0&amp;&amp;('0'&lt;=s[i-1]&amp;&amp;s[i-1]&lt;='9'))&#123; i++; amap['e']++; if(i&gt;=s.size()) return false; continue; &#125; if(s[i-1]=='.'&amp;&amp;flag == 1)&#123; i++; amap['e']++; if(i&gt;=s.size()) return false; continue; &#125; &#125; return false; &#125; if(amap['.']||amap['-']||amap['+'])&#123; if(flag == 0) return false; &#125; return true; &#125;&#125;; 69. Sqrt(x) 分析：这一题用二分法做比较快。 123456789101112131415161718192021class Solution &#123;public: int mySqrt(int x) &#123; // int a = 0;// a = sqrt(x);// return a; int l = 1; int r = x; while(l&lt;=r)&#123; int m = l+(r-l)/2; if(m&gt;(x/m))&#123; r = m-1; &#125; else&#123; l = m+1; &#125; &#125; return l-1; &#125;&#125;; 10/3/2019 54. Spiral Matrix 分析：这一题用最简单的四个循环这种思路求救最合适！然后需要注意的是，在对边界进行缩减的时候，需要保证仍然满足begin&lt;end的条件。 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; res; if(matrix.size() == 0 || matrix[0].size() == 0) return res; int rowbegin = 0; int rowend = matrix.size()-1; int colbegin = 0; int colend = matrix[0].size()-1; while(rowbegin&lt;=rowend&amp;&amp;colbegin&lt;=colend)&#123; for(int i = colbegin;i&lt;=colend;i++)&#123; res.push_back(matrix[rowbegin][i]); &#125; rowbegin++; for(int i = rowbegin;i&lt;=rowend;i++)&#123; res.push_back(matrix[i][colend]); &#125; colend--; if(rowbegin&gt;rowend || colbegin&gt;colend) return res; for(int i = colend;i&gt;=colbegin;i--)&#123; res.push_back(matrix[rowend][i]); &#125; rowend--; if(rowbegin&gt;rowend || colbegin&gt;colend) return res; for(int i = rowend;i&gt;=rowbegin;i--)&#123; res.push_back(matrix[i][colbegin]); &#125; colbegin++; &#125; return res; &#125;&#125;; 55. Jump Game 分析：与某一题很类似，总之记住记住当前位置能达到的最远距离的方法来求解。 1234567891011121314151617class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() &lt;= 1)&#123; return true; &#125; int lastindex = 0; int cur = 0; while(lastindex&lt;nums.size())&#123; cur = max(lastindex+nums[lastindex],cur); if(cur&gt;=nums.size()-1) return true; if(cur==lastindex &amp;&amp; nums[lastindex] == 0) return false; lastindex++; &#125; return true; &#125;&#125;; 59. Spiral Matrix II 分析：这一题属于构造nxn的一个数组，可以按照读取的方式进行构造。 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; generateMatrix(int n) &#123; vector&lt;vector&lt;int&gt;&gt; matrix(n,vector&lt;int&gt;(n,0)); if(n==0) return matrix; int rowbegin = 0; int rowend = n-1; int colbegin = 0; int colend = n-1; int count = 1; while(rowbegin&lt;=rowend &amp;&amp; colbegin&lt;=colend)&#123; for(int i = colbegin;i&lt;=colend;i++)&#123; matrix[rowbegin][i] = count++; &#125; rowbegin++; for(int i = rowbegin;i&lt;=rowend;i++)&#123; matrix[i][colend] = count++; &#125; colend--; if(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend) return matrix; for(int i = colend;i&gt;=colbegin;i--)&#123; matrix[rowend][i] = count++; &#125; rowend--; if(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend)&#123; return matrix; &#125; for(int i = rowend;i&gt;=rowbegin;i--)&#123; matrix[i][colbegin] = count++; &#125; colbegin++; &#125; return matrix; &#125;&#125;; 60. Permutation Sequence 分析：递归全排列，当满足长度的个数到达k个时得到结果。 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int count = 0; string res = ""; string ans; vector&lt;int&gt; visit; void dfs(int n,int k)&#123; if(res.size() == n)&#123; count++; if(count == k)&#123; ans = res; return; &#125; &#125; if(count!=k)&#123; for(int i = 1;i&lt;=n;i++)&#123; if(visit[i]==1) continue; res += to_string(i); visit[i] = 1; dfs(n,k); res = res.substr(0,res.size()-1); visit[i] = 0; &#125; &#125; &#125; string getPermutation(int n, int k) &#123; visit = vector&lt;int&gt;(n+1,0); dfs(n,k); return ans; &#125;&#125;; 61. Rotate List 分析：这题需要处理掉循环插的情况，即取模即可。然后就是正常的链表。 123456789101112131415161718192021222324252627class Solution &#123;public: ListNode* rotateRight(ListNode* head, int k) &#123; if(k == 0||head == NULL) return head; int n = 0; auto p = head; while(p!=NULL)&#123; n++; p = p-&gt;next; &#125; k = k%n; if(k == 0) return head; p = head; while(n - k -1 &gt; 0)&#123; p = p-&gt;next; k++; &#125; auto q = p-&gt;next; auto ans = q; p-&gt;next = NULL; while(q-&gt;next!=NULL)&#123; q = q-&gt;next; &#125; q-&gt;next = head; return ans; &#125;&#125;; 70. Climbing Stairs 分析：动态规划法求解。 1234567891011121314class Solution &#123;public: int climbStairs(int n) &#123; if(n == 0) return 0; if(n == 1) return 1; vector&lt;int&gt; dp(n,0); dp[0] = 1; dp[1] = 2; for(int i = 2;i&lt;n;i++)&#123; dp[i] = dp[i-1]+dp[i-2]; &#125; return dp[n-1]; &#125;&#125;; 7/3/2019 不知道为什么漏了6号，我明明都有做🐸 51. N-Queens N皇后递归最经典的问题，我觉得我在求解递归的问题的时候思路不是很清晰，总是做的不好，有必要总结一下。 递归递归就是你需要确定一个循环机制，然后每次递归需要进行标记（不标记的话每次都执行一样的东西了），当然是根据条件进行标记的。因此对于递归的条件判断也需要十分注意，每次递归结束需要释放掉当前状况所添加的约束。 定义约束变量，比如visit矩阵用于判断是否遍历过 确定主循环，主循环指需要对所有的子问题进行完整解析 将当情况的约束加到visit上，进行递归 确定递归返回条件，比如temp.size()&gt;=n 结束递归将当前约束释放掉 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Solution &#123;public: //回溯法 vector&lt;vector&lt;string&gt;&gt; res; vector&lt;vector&lt;int&gt;&gt; visit; void dfs(vector&lt;string&gt; temp,int pos,int n)&#123; if(temp.size() == n)&#123; res.push_back(temp); return; &#125; if(pos&gt;=n) return; for(int i = 0;i&lt;n;i++)&#123; string s(n,'.'); if(pos == 0)&#123; s[i] = 'Q'; temp.push_back(s); visit[pos][i] = 1; dfs(temp,pos+1,n); temp.pop_back(); visit[pos][i] = 0; &#125; else if((i==0||visit[pos-1][i-1]!=1)&amp;&amp; (i+1==n||visit[pos-1][i+1]!=1))&#123; int flag = 0; for(int j = 0;j&lt;n;j++)&#123; if(visit[j][i] == 1) &#123;flag = 1;break;&#125; &#125; int tempi = i-1; int tempj = pos-1; while(tempj&gt;=0&amp;&amp;tempi&gt;=0)&#123; if(visit[tempj--][tempi--] == 1)&#123;flag = 1;break;&#125; &#125; tempi = i+1; tempj = pos+1; while(tempj&lt;n&amp;&amp;tempi&lt;n)&#123; if(visit[tempj++][tempi++] == 1) &#123;flag = 1;break;&#125; &#125; tempi = i+1; tempj = pos-1; while(tempj&gt;=00&amp;&amp;tempi&lt;n)&#123; if(visit[tempj--][tempi++] == 1) &#123;flag = 1;break;&#125; &#125; tempi = i-1; tempj = pos+1; while(tempj&lt;n&amp;&amp;tempi&gt;=0)&#123; if(visit[tempj++][tempi--] == 1) &#123;flag = 1;break;&#125; &#125; if(flag == 0)&#123; s[i] = 'Q'; temp.push_back(s); visit[pos][i] = 1; dfs(temp,pos+1,n); temp.pop_back(); visit[pos][i] = 0; &#125; &#125; else&#123; continue; &#125; &#125; &#125; vector&lt;vector&lt;string&gt;&gt; solveNQueens(int n) &#123; if(n&lt;=0) return res; visit = vector(n,vector&lt;int&gt;(n,0)); vector&lt;string&gt; temp; dfs(temp,0,n); return res; &#125;&#125;; 206. Reverse Linked List递归题 1234567891011121314151617181920212223class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head == NULL||head-&gt;next == NULL) return head; ListNode* p = head-&gt;next; ListNode* q = head; q-&gt;next = NULL; while(p)&#123; auto temp = p-&gt;next; p-&gt;next = q; q = p; p = temp; &#125; return q; //递归做法，先将所有的节点打散，然后从最后一个慢慢往前连接/* if(head==NULL||head-&gt;next == NULL) return head; auto last = head-&gt;next; head-&gt;next = NULL; ListNode* newhead = reverseList(last); last-&gt;next = head; return newhead;*/ &#125;&#125;; 226. Invert Binary Tree 分析：在每一次递归时进行左右交换。树的遍历方式算是递归的一种。 123456789101112class Solution &#123;public: TreeNode* invertTree(TreeNode* root) &#123; if(root == NULL) return NULL; auto p = root-&gt;left; root-&gt;left = root-&gt;right; root-&gt;right = p; invertTree(root-&gt;left); invertTree(root-&gt;right); return root; &#125;&#125;; 104. Maximum Depth of Binary Tree 分析：每一次进步一个深度，然后如果为零返回。 12345678910111213141516class Solution &#123;public: int maxn = 0; void dfs(TreeNode* root,int level)&#123; if(root == NULL) return; dfs(root-&gt;left,level+1); dfs(root-&gt;right,level+1); if(maxn&lt;level) maxn = level; &#125; int maxDepth(TreeNode* root) &#123; if(root == NULL) return 0; dfs(root,1); return maxn; &#125;&#125;; 5/3/2019 49. Group Anagrams 分析：这道题使用哈希表来解决，记录是否有相同的元素被访问过。 12345678910111213141516171819202122class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; vector&lt;vector&lt;string&gt;&gt; res; if(strs.size() == 0) return res; unordered_map&lt;string,int&gt; amap; for(int i = 0;i&lt;strs.size();i++)&#123; auto temp = strs[i]; sort(temp.begin(),temp.end()); if(amap.count(temp) == 0)&#123; amap[temp] = res.size(); vector&lt;string&gt; a; a.push_back(strs[i]); res.push_back(a); &#125; else&#123; res[amap[temp]].push_back(strs[i]); &#125; &#125; return res; &#125;&#125;; 82. Remove Duplicates from Sorted List II 分析：这一题的思路其实很简单，就是当你要删除一个数的时候，你应该保证目前的指针指向要删除的数的前一个,因此需要保证next和next之后的数都不为空。 123456789101112131415161718192021class Solution&#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; if(head == NULL) return head; ListNode* dummy = new ListNode(-1); dummy-&gt;next = head; auto p = dummy; while(p-&gt;next &amp;&amp; p-&gt;next-&gt;next)&#123; if(p-&gt;next-&gt;val == p-&gt;next-&gt;next-&gt;val)&#123; int same = p-&gt;next-&gt;val; while(p-&gt;next&amp;&amp;p-&gt;next-&gt;val == same)&#123; p-&gt;next = p-&gt;next-&gt;next; &#125; &#125; else&#123; p = p-&gt;next; &#125; &#125; return dummy-&gt;next; &#125;&#125; 83. Remove Duplicates from Sorted List 分析：这一题比较好做，唯一要注意的是不要判断p不为空。 1234567891011121314class Solution&#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; if(head == NULL) return head; auto p = head; while(p-&gt;next)&#123; if(p-&gt;next-&gt;val == p-&gt;val)&#123; p-&gt;next = p-&gt;next-&gt;next; &#125; else p = p-&gt;next; &#125; return head; &#125;&#125; 86. Partition List 分析：我发现我链表的题做得还行。这一题思路是先走到链表尾巴，然后遇到比目标大的数，就截取下来放到最后。 12345678910111213141516171819202122232425262728293031class Solution &#123;public: ListNode* partition(ListNode* head, int x) &#123; if(head == NULL) return head; ListNode* dummy = new ListNode(-1); dummy-&gt;next = head; auto p = dummy; auto q = head; int count = 0; while(p-&gt;next)&#123; p = p-&gt;next; count++; &#125; q = p; p = dummy; while(count)&#123; count--; if(p-&gt;next-&gt;val &lt; x)&#123; p = p-&gt;next; &#125; else&#123; q-&gt;next = p-&gt;next; p-&gt;next = p-&gt;next-&gt;next; q = q-&gt;next; &#125; &#125; q-&gt;next = NULL; return dummy-&gt;next; &#125;&#125;; 87. Scramble String 分析：这一题用递归的方法做，感觉所有用递归的方法其实都是最耗时的方法，更好的方法可能是动态规划方法。总之递归之后应该有一个动归才是。然后基本思路是做两次判断，第一次两个串切在同一个位置上，第二次在首尾位置上。 1234567891011121314151617181920212223242526class Solution &#123;public: bool isScramble(string s1, string s2) &#123; if(s1.size()==0||s2.size() == 0) return false; if(s1 == s2) return true; vector&lt;int&gt; letters(26); for(int i = 0;i&lt;s1.size();i++)&#123; letters[s1[i]-'a']++; letters[s2[i]-'a']--; &#125; for(int i = 0;i&lt;26;i++)&#123; if(letters[i]!=0) return false; &#125; for(int i = 1;i&lt;s1.size();i++)&#123; if(isScramble(s1.substr(0,i),s2.substr(0,i))&amp;&amp; isScramble(s1.substr(i),s2.substr(i))) return true; if(isScramble(s1.substr(0,i),s2.substr(s1.size()-i))&amp;&amp; isScramble(s1.substr(i),s2.substr(0,s1.size()-i))) return true; &#125; return false; &#125;&#125;; 4/3/2019 46. Permutations分析：这一题是典型的排列问题，用递归的方式完成，然后用一个数组来标记当前的位置是否被读取过。1234567891011121314151617181920212223242526class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; res; void dfs(vector&lt;int&gt; nums,vector&lt;int&gt; visit,vector&lt;int&gt; temp)&#123; if(temp.size() == nums.size())&#123; res.push_back(temp); return; &#125; for(int i = 0;i&lt;nums.size();i++)&#123; if(visit[i] == 0)&#123; visit[i] = 1; temp.push_back(nums[i]); dfs(nums,visit,temp); temp.pop_back(); visit[i] = 0; &#125; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return res; vector&lt;int&gt; visit(nums.size(),0); vector&lt;int&gt; temp; dfs(nums,visit,temp); return res; &#125;&#125;; 47. Permutations II分析：这一题与上一题的一个改善是，有重复的数，去重复的一个方法是对数组排序，如果当前的元素与上一个元素相同，并且上一个元素没有被访问过（意味着上一个元素曾经在这个位置上），直接跳过这个位置进入下一个位置。1234567891011121314151617181920212223242526272829class Solution &#123;public: // set&lt;vector&lt;int&gt;&gt; res; vector&lt;vector&lt;int&gt;&gt; res; void dfs(vector&lt;int&gt; nums,vector&lt;int&gt; visit,vector&lt;int&gt; temp)&#123; if(temp.size() == nums.size())&#123; res.push_back(temp); return; &#125; for(int i = 0;i&lt;nums.size();i++)&#123; if(visit[i] == 0)&#123; if(i&gt;0&amp;&amp;nums[i-1] == nums[i]&amp;&amp;visit[i-1] == 0) continue; temp.push_back(nums[i]); visit[i] = 1; dfs(nums,visit,temp); visit[i] = 0; temp.pop_back(); &#125; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return res; vector&lt;int&gt; visit(nums.size(),0); vector&lt;int&gt; temp; sort(nums.begin(),nums.end()); dfs(nums,visit,temp); return res; &#125;&#125;; 45. Jump Game II分析：这一题用动态规划或者greedy来做，具体看代码即可。dp中对i之前每个位置进行判断，时间复杂度为$O(n^2)$ , greedy中cur指当前能到最远位置，last指上一步能到最远位置。然后需要排除掉一步不走的情况。1234567891011121314151617181920212223242526272829303132class Solution &#123;public:/* int jump(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return 0; vector&lt;int&gt; dp(nums.size(),INT_MAX); dp[0] = 0; for(int i = 0;i&lt;nums.size() ;i++)&#123; for(int j = 0;j&lt;i;j++)&#123; if(nums[j]&gt;=i-j)&#123; dp[i] = min(dp[i],dp[j]+1); &#125; &#125; &#125; return dp[nums.size()-1]; &#125;*/ int jump(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return 0; int res = 0; int last = 0; int cur = 0; for(int i = 0;i&lt;nums.size()-1 ;i++)&#123; cur = max(cur,i+nums[i]); if(i == last)&#123; last = cur; res++; if(last&gt;=nums.size()-1) return res; &#125; &#125; return res; &#125;&#125;; 50. Pow(x, n)分析：由于指数乘法可以由比他小的指数乘起来得到，一次可以用分治法来做。12345678910111213141516class Solution &#123;public: double myPow(double x, int n1) &#123; if(n1 == 0) return 1.0; if(n1 == 1) return x; long long n = n1; if(n&lt;0)&#123; n = -n; x = 1.0/x; &#125; double res = myPow(x,n/2); if(n%2 == 0) return res*res; return res*res*x; &#125;&#125;; 3/3/2019 40. Combination Sum II分析：这一题用递归来求解，对于重复的问题，在执行一次递归之后，对重复的元素进行排除。12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; res; void dfs(vector&lt;int&gt; candidates,vector&lt;int&gt; temp,int target,int pos)&#123; if(target == 0)&#123; res.push_back(temp); return; &#125; for(int i = pos;i&lt;candidates.size()&amp;&amp;target&gt;=candidates[i];i++)&#123; temp.push_back(candidates[i]); dfs(candidates,temp,target-candidates[i],i+1); while(i+1&lt;candidates.size()&amp;&amp;candidates[i] == candidates[i+1]) i++; temp.pop_back(); &#125; &#125; vector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt;&amp; candidates, int target) &#123; if(candidates.size() == 0) return res; sort(candidates.begin(),candidates.end()); vector&lt;int&gt; temp; dfs(candidates,temp,target,0); return res; &#125;&#125;; 42. Trapping Rain Water分析：这一题之前做过，思路就是用两个数组，从左到右记录最大的val，从右到左记住最大的val，然后水坑的值就等于三个数组相减。12345678910111213141516171819202122class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; if(height.size() == 0) return 0; vector&lt;int&gt; left(height.size()); vector&lt;int&gt; right(height.size()); left[0] = height[0]; right[height.size()-1] = height[height.size()-1]; for(int i = 1;i&lt;height.size();i++)&#123; left[i] = max(left[i-1],height[i]); &#125; for(int i = height.size()-2;i&gt;=0;i--)&#123; right[i] = max(right[i+1],height[i]); &#125; int res = 0; for(int i = 0;i&lt;height.size();i++)&#123; int temp = min(left[i],right[i])-height[i]; if(temp&gt;0) res += temp; &#125; return res; &#125;&#125;; 44. Wildcard Matching分析：字符串匹配问题多可以用动态规划来求解，思考动态规划问题的时候不要想太多步。就想着当前这一步有多少种情况就可以了。同时需要注意边界问题。递推情况如下：当p[j] = &#39;*&#39;: s[i-1]和p[j-1]进行匹配，s[i]和p[j]进行匹配。此时考虑*表示1个字符。 s[i-1]已经和p[j]进行了匹配，s[i]也仍然和p[j]进行匹配。此时考虑*表示n个字符。 s[i]和p[j - 1]进行了匹配，此时考虑*表示0个字符。 当p[j] = &#39;?&#39;等：p[j-1]与s[i-1]进行匹配，p[j],s[i]匹配。 12345678910111213141516171819202122class Solution &#123;public: bool isMatch(string s, string p) &#123; int m = s.size(),n = p.size(); vector&lt;vector&lt;bool&gt;&gt; dp(m+1,vector&lt;bool&gt;(n+1,false)); dp[0][0] = true; for(int i = 1;i&lt;=n;i++)&#123; if(p[i-1] == '*') dp[0][i] = dp[0][i-1]; // s为空，p为连续* 号 &#125; for(int i = 1;i&lt;=m;i++)&#123; for(int j = 1;j&lt;=n;j++)&#123; if(p[j-1] == '*')&#123; dp[i][j] = dp[i-1][j]||dp[i][j-1]||dp[i-1][j-1]; &#125; else if(p[j-1] == '?'||p[j-1] == s[i-1])&#123; dp[i][j] = dp[i-1][j-1]; &#125; &#125; &#125; return dp[m][n]; &#125;&#125;; 67. Add Binary分析：做过类似的面试题，然后思路就是这样没错了。1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: string addBinary(string a, string b) &#123; int n = a.size()-1; int m = b.size()-1; int add = 0; string res = ""; while(n&gt;=0&amp;&amp;m&gt;=0)&#123; int le = a[n] - '0'; int ri = b[m] - '0'; if(le+ri+add&gt;=2)&#123; res = to_string(le+ri+add -2) + res; add = 1; &#125; else&#123; res = to_string(le+ri+add) + res; add = 0; &#125; n--; m--; &#125; res = (n&gt;=0? a.substr(0,n+1):b.substr(0,m+1)) + res; if(add == 0) return res; int left = n&gt;=0? n:m; while(left&gt;=0)&#123; if(res[left] == '0')&#123; res[left] = '1'; return res; &#125; else&#123; res[left] = '0'; &#125; left--; &#125; res = '1'+ res; return res; &#125;&#125;; 2/3/2019 32. Longest Valid Parentheses分析：这一题括号匹配，用栈的结构来解决，每次将括号的下标存入栈的结构中。1234567891011121314151617181920212223class Solution &#123;public: int longestValidParentheses(string s) &#123; if(s.size() == 0) return 0; int maxn = 0; stack&lt;int&gt; sta; sta.push(-1); for(int i = 0;i&lt;s.size();i++)&#123; if(s[i] == '(')&#123; sta.push(i); &#125; else&#123; sta.pop(); if(!sta.empty()) maxn = max(maxn,i-sta.top()); else&#123; sta.push(i); &#125; &#125; &#125; return maxn; &#125;&#125;; 34. Find First and Last Position of Element in Sorted Array这一题题目要求复杂度是O(log(n)) 很显然就是用二分法来做的，然后如果找到了target，就往target的两边去找相同的元素。12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; vector&lt;int&gt; res = &#123;-1,-1&#125;; if(nums.size() == 0) return res; int low = 0; int high = nums.size()-1; int mid; while(low&lt;=high)&#123; mid = (low+high)/2; if(nums[mid] == target) break; else if(nums[mid]&gt;target)&#123; high = mid-1; &#125; else&#123; low = mid+1; &#125; &#125; if(low&gt;high) return res; int i = 0; for(i = mid-1;i&gt;=0;i--)&#123; if(nums[i] != target) &#123;break;&#125; &#125; res[0] = i+1; for(i = mid + 1;i&lt;nums.size();i++)&#123; if(nums[i]!=target) &#123; break;&#125; &#125; res[1] = i-1; return res; &#125;&#125;; 36. Valid Sudoku分析：判断横排，竖排，里头九宫格即可。123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: bool isValidSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; if(board.size() == 0) return false; //横排 for(int i = 0;i&lt;9;i++)&#123; unordered_map&lt;char,int&gt; amap; for(int j = 0;j&lt;9;j++)&#123; if(amap.count(board[i][j]) != 0 &amp;&amp;board[i][j]!='.') return false; amap[board[i][j]] = 1; &#125; &#125; //竖排 for(int i = 0;i&lt;9;i++)&#123; unordered_map&lt;char,int&gt; amap; for(int j = 0;j&lt;9;j++)&#123; if(amap.count(board[j][i])!=0&amp;&amp;board[j][i]!='.') return false; amap[board[j][i]] = 1; &#125; &#125; //九宫格 for(int i = 0;i&lt;9;i += 3)&#123; for(int j = 0;j&lt;9;j+=3)&#123; unordered_map&lt;char,int&gt; amap; for(int h = i;h&lt;i+3;h++)&#123; for(int k = j;k&lt;j+3;k++)&#123; if(amap.count(board[h][k])!=0&amp;&amp;board[h][k]!='.') return false; amap[board[h][k]] = 1; &#125; &#125; &#125; &#125; return true; &#125;&#125;; 39. Combination Sum分析：经典的一道递归题，下次一定要会做才行，因为最基本的递归就长这个样子。123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; res; void digui(vector&lt;int&gt;&amp; candidates,int target,vector&lt;int&gt; temp,int pos)&#123; if(target == 0) res.push_back(temp); for(int i = pos;i&lt;candidates.size();i++)&#123; if(target&gt;=candidates[i])&#123; temp.push_back(candidates[i]); digui(candidates,target-candidates[i],temp,i); temp.pop_back(); &#125; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) &#123; if(candidates.size() == 0) return res; vector&lt;int&gt; temp; digui(candidates,target,temp,0); return res; &#125;&#125;; 1/3/2019 38. Count and Say分析：这一题是递归的题，出口是n = 0 或 1，然后用for循环判断当前生成的字符。123456789101112131415161718class Solution &#123;public: string countAndSay(int n) &#123; if(n &lt;= 0) return ""; if(n == 1) return "1"; string s = countAndSay(n-1); string newS = ""; for(int i = 0;i&lt;s.size();i++)&#123; int count = 1; while(i+1&lt;s.size()&amp;&amp;s[i] == s[i+1])&#123; count++; i++; &#125; newS += to_string(count) + s[i]; &#125; return newS; &#125;&#125;; 2/28/2019 30. Substring with Concatenation of All Words分析：控制一个words的所有字符长度的子串，然后在子串里面看是否满足条件。用hash_map做。 1234567891011121314151617181920212223242526class Solution &#123;public: vector&lt;int&gt; findSubstring(string s, vector&lt;string&gt;&amp; words) &#123; vector&lt;int&gt; res; if(s.empty()||words.size() == 0) return res; int m = words[0].size(); int n = words.size(); unordered_map&lt;string,int&gt; m1; for(int i = 0;i&lt;words.size();i++)&#123; ++m1[words[i]]; &#125; for(int i = 0;i&lt;=(int)s.size()-m*n;i++)&#123; cout&lt;&lt;s.size(); unordered_map&lt;string,int&gt; m2; int j = 0; for(;j&lt;words.size();j++)&#123; string t = s.substr(i+j*m,m); if(m1.find(t) == m1.end()) break; ++m2[t]; if(m2[t]&gt;m1[t]) break; &#125; if(j == words.size()) res.push_back(i); &#125; return res; &#125;&#125;; 2/26/2019 53. Maximum Subarray分析：这一题时简单的DP问题，用一个数存之前的序列和，当和小于0时则清零。1234567891011121314class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return 0; int maxn = INT_MIN; int ans = 0; for(int i = 0;i&lt;nums.size();i++)&#123; if(ans&lt;0) ans = 0; ans += nums[i]; maxn = max(maxn,ans); &#125; return maxn; &#125;&#125;; 15. 3Sum 分析：这一题要找出所有的相加为0的组合，可以定义三个变量，用来控制数组中相加的数字，一个数字控制外循环，里头两个数字当遇到与前一个相同时，需要跳过。 123456789101112131415161718192021222324252627class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(),nums.end()); vector&lt;vector&lt;int&gt;&gt; res; if(nums.size() == 0) return res; for(int i = 0;i&lt;nums.size();i++)&#123; int begin = i+1,end = nums.size()-1; if(i&gt;0&amp;&amp;nums[i-1]==nums[i]) continue; while(begin&lt;end)&#123; int result = nums[i]+nums[end]+nums[begin]; if(i!=end&amp;&amp; result == 0)&#123; vector&lt;int&gt; temp = &#123;nums[i],nums[begin],nums[end]&#125;; res.push_back(temp); end--; while(end&gt;=0&amp;&amp;nums[end+1] == nums[end]) end--; begin++; while(begin&lt;nums.size()&amp;&amp;nums[begin-1] == nums[begin]) begin++; &#125; else if(i==end||result&gt;0) end--; else begin++; &#125; &#125; return res; &#125;&#125;; 16. 3Sum Closest这一题是上一题的变形，省去了判断过滤重复的步骤，只要求一个绝对值最接近1就好。1234567891011121314151617181920212223242526class Solution &#123;public: int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) &#123; if(nums.size() == 0) return 0; int sum = INT_MAX; int ans; sort(nums.begin(),nums.end()); for(int i = 0;i&lt;nums.size();i++)&#123; int j = i+1,k = nums.size()-1; while(j&lt;k)&#123; int result = nums[i]+nums[j]+nums[k]; if(i!=k&amp;&amp;abs(result-target)&lt;=sum)&#123; sum = abs(result-target); ans = result; if(result&lt;target)j++; else if(result&gt;target) k--; else return result; &#125; else if(result&gt;target) k--; else j++; &#125; &#125; return ans; &#125;&#125;; 17. Letter Combinations of a Phone Number这一题比较简单，把存结果的数组当作栈来用就行了。12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;string&gt; letterCombinations(string digits) &#123; vector&lt;string&gt; res; if(digits.size() == 0) return res; vector&lt;vector&lt;char&gt;&gt; alphabet = &#123; &#123;&#125;, &#123;&#125;,&#123;'a','b','c'&#125;,&#123;'d','e','f'&#125;,&#123;'g','h','i'&#125;,&#123;'j','k','l'&#125;,&#123;'m','n','o'&#125;, &#123;'p','q','r','s'&#125;,&#123;'t','u','v'&#125;,&#123;'w','x','y','z'&#125; &#125;; vector&lt;char&gt; tem(alphabet[digits[0]-'0']); string a =""; for(int i = 0;i&lt;tem.size();i++)&#123; a += tem[i]; res.push_back(a); a = ""; &#125; for(int i = 1;i&lt;digits.size();i++)&#123; vector&lt;char&gt; te(alphabet[digits[i]-'0']); int resSize = res.size(); for(int j = 0;j&lt;resSize;j++)&#123; string ahead = res[0]; for(int k = 0;k&lt;te.size();k++)&#123; res.push_back(ahead+te[k]); &#125; res.erase(res.begin()); &#125; &#125; return res; &#125;&#125;; 18. 4Sum分析：这一题是前面三个数的加强版，注意一些重复的判断就行了。12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; fourSum(vector&lt;int&gt;&amp; nums, int target) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(nums.size() &lt; 4) return res; sort(nums.begin(),nums.end()); for(int i = 0;i&lt;nums.size();i++)&#123; if(i&gt;0&amp;&amp;nums[i] == nums[i-1]) continue; for(int j = i+1;j&lt;nums.size();j++)&#123; if(j&gt;i+1&amp;&amp;nums[j] == nums[j-1]) continue; int begin = j+1,end = nums.size()-1; while(begin&lt;end)&#123; int result = nums[i]+nums[j]+nums[begin]+nums[end]; if(result == target)&#123; res.push_back(&#123;nums[i],nums[j],nums[begin],nums[end]&#125;); begin++; end--; while(end&gt;begin&amp;&amp;nums[end] == nums[end+1]) end--; while(begin&lt;end&amp;&amp;nums[begin-1] == nums[begin]) begin++; &#125; else if(result &gt; target) end--; else begin++; &#125; &#125; &#125; return res; &#125;&#125;; 19. Remove Nth Node From End of List分析：这一题要求执行一趟，删除掉倒数第n个节点。可以用两个指针来完成，第一个指针领先第二个指针n的位置，当第一个指针到达终点时，第二个指针的位置就是倒数n的位置。然后需要注意删除第一个元素的情况。12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; if(head == NULL) return NULL; ListNode* pre = head; ListNode* last = head; ListNode* pos = head; while(n--)&#123; pos = pos-&gt;next; &#125; if(pos == NULL) return head-&gt;next; //当删除第一个元素时 while(pos!=NULL)&#123; pre = last; last = last-&gt;next; pos = pos-&gt;next; &#125; pre-&gt;next = last-&gt;next; return head; &#125;&#125;; 22. Generate Parentheses分析：这是一道很经典的递归的题目，我做出一道就有感觉了。就是说看递归一定是这一步做了某种选择，待会还要回来。而且要比较注重递归程序的出口。1234567891011121314151617class Solution &#123;public: int nn; vector&lt;string&gt; ans; void digui(string res,int left,int right)&#123; if(res.size() == 2*nn)&#123; ans.push_back(res);return;&#125; if(left&lt;nn) digui(res+"(",left+1,right); if(right&lt;nn&amp;&amp;right&lt;left) digui(res+")",left,right+1); &#125; vector&lt;string&gt; generateParenthesis(int n) &#123; if(n == 0) return ans; nn = n; digui("",0,0); return ans; &#125;&#125;; 24. Swap Nodes in Pairs调换两个数，需要三个指针，然后注意特殊情况只有一个数的时候的。直接放回head。123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* swapPairs(ListNode* head) &#123; if(head == NULL) return NULL; ListNode* pre = new ListNode(-1); ListNode* first = head; ListNode* second = head-&gt;next; pre-&gt;next = head; if(second == NULL) return head; head = second; while(second != NULL)&#123; pre-&gt;next = second; first-&gt;next = second-&gt;next; second-&gt;next = first; pre = first; first = first-&gt;next; if(first!=NULL) second = first-&gt;next; else return head; &#125; return head; &#125;&#125;; 29. Divide Two Integers分析：这一题由于有越界问题，可以用long long申请变量，保证不会溢出。12345678910111213141516171819class Solution &#123;public: int divide(int dividend, int divisors) &#123; long long divide = dividend; long long divisor = divisors; if(divisor == 0) return divide; int sign = 1; if(divisor&lt;0) sign = -1,divisor *= -1; if(divide&lt;0) sign *= -1,divide *= -1; long time = 0; while(divide&gt;=divisor)&#123; time++; divide -= divisor; &#125; if(time*sign&gt;INT_MAX) return INT_MAX; if(time*sign&lt;INT_MIN) return INT_MIN; return time*sign; &#125;&#125;; 4. median of two sorted array分析：这一题要找两个排序好的数组的中位数。 中位数有一个性质就是一定位于数列的中间位置，而且中位数左边的数都小于中位数，中位数右边的数都大于中位数 因此我们对数组位置进行分析时，需要保持中位数位置一定为数组长度的一半，又因为这道题对两个排序好的数组寻找中位数，因此可以分别对他们使用分治法求解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; //首先拿到数组的长度，并设置nums1的长度大于nums2 int m = nums1.size(); int n = nums2.size(); if(m&gt;n)&#123; auto temp = nums1; nums1 = nums2; nums2 = temp; swap(n,m); &#125;// n &gt; m int imin = 0,imax = m,half = (m+n+1)/2; //half保证了长度为数列的一半 //接下来在nums2数组中对中位数位置进行遍历 while(imin&lt;=imax)&#123; int i = (imax-imin)/2 + imin; // seperate nums1 int j = half - i; // j为num2的分割点，可以看出来j为一半的长度，不是下标 if(i&lt;m &amp;&amp; nums1[i]&lt;nums2[j-1]) // i is too small &#123; imin = i+1; &#125; else if(i&gt;0&amp;&amp;nums1[i-1]&gt;nums2[j])&#123; // i is to big imax = i-1; &#125; else&#123; // ferfect int max_left,min_right; if(i == 0)&#123; max_left = nums2[j-1]; &#125; else if(j == 0)&#123; max_left = nums1[i-1]; &#125; else&#123; max_left = max(nums2[j-1],nums1[i-1]); &#125; if((m+n)%2 == 1)&#123; return max_left; &#125; else&#123; if(i == m)&#123; min_right = nums2[j]; &#125; else if(j == n)&#123; min_right = nums1[i]; &#125; else&#123; min_right = min(nums1[i],nums2[j]); &#125; return (min_right+max_left)/2.0; &#125; &#125; &#125; return -1.0; &#125;&#125;; 26. Remove Duplicates from Sorted Array 分析：这一题思路比较简单，由于数组是排序过的，因此重复的数在相邻的位置上。所以做法就是用i遍历一边数组，用j保持数组不重复的长度，当出现不重复时j++，将不重复的数补充到j位置上。123456789101112131415161718class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0) return 0; int count = 0; int j = 0; for(int i = 1;i&lt;nums.size();i++)&#123; while(i&lt;nums.size()&amp;&amp;nums[j] == nums[i])&#123; i++; &#125; if(i&lt;nums.size()) &#123; j++;nums[j] = nums[i]; &#125; &#125; return j+1; &#125;&#125;; 837. New 21 Game 分析：先吐槽一下自己，最近刷题有点儿太慢了。这一题的题意是说，Alice每次都可以在1～W之间随机选择一个数，当Alice选择的数累加起来大于等于K的时候，Alice停止游戏。这时候这个累加和如果大于N那么Alice就输了，小于等于N Alice就赢了。题目叫我们算Alice赢得概率，就是累加和小于等于N的概率。 这一题可以用DP来求解,维护一个累加和窗。设dp[i]为当前累加和为i的时候的概率。要求i的概率有下面关系：dp[i] = 1/w * (dp[i-1]+dp[i-2]...dp[i-w])，即我可以先选择i-1，然后选1。由于可以选择的数只有W个，因此窗口宽度为W。对于累加和有下面的关系： i&lt;K : Wsum += dp[i] 表明当前的i可以作为下一次两步选择的第一步 i-W&gt;=0: Wsum -= dp[i-W] 表明对于下一个i来说，因为W的范围限定，取不到第dp[i-W]作为前两步选择的第一步，需要把概率减去，维护窗内概率。 N&gt;= i &gt;=K: res += dp[i]；结果为res,即这个时候分数在K与N之间。 1234567891011121314151617181920class Solution &#123;public: double new21Game(int N, int K, int W) &#123; if(K == 0) return 1; // 共有N+1个状态 vector&lt;double&gt; dp(N+1); double Wsum = 1.0; // 记录前W个数的概率 double res = 0.0; dp[0] =1; for(int i = 1;i&lt;=N;i++)&#123; dp[i] = Wsum/W; if(i&lt;K) Wsum+=dp[i]; // 当前的i可以作为下一次两步选择的第一步 else&#123; res += dp[i]; &#125; if(i-W&gt;=0) Wsum -= dp[i-W]; //对于下一个i来说，当前的i-W下一个无法取到 &#125; return res; &#125;&#125;; 481. Magical String 这一题的题意是说，1和2将会交替出现，最开始1先出现，然后去产生下面的数，最后会发现产生的数组和每一行数字的个数序列将会是同一个序列。最后统计一下序列中1的个数。数字的产生规则如下： 先产生1 1与2交替出现 当前字符串最末尾的数字控制添加入字符串的字符个数，如122，表示下一次将加入2个1，变成12211 前三个数比较特殊，直接生成122 123456789101112class Solution &#123;public: int magicalString(int n) &#123; if(n == 0) return 0; string s = "122"; int i = 2; while(s.size()&lt;n)&#123; s+= string(s[i++]-'0',s.back() == '1'? '2':'1'); &#125; return count(s.begin(),s.begin()+n,'1'); &#125;&#125;; 有几个新函数记录一下：12s = string(char_num,char); //产生char_num个charcount(s.begin(),s.begin()+n,&apos;1&apos;);//计算字符串s中含&apos;1&apos;的个数 2. Add Two Numbers这一题题意说的是用链表表示数字，表头为个位。然后将两个链表相加，计算他们的和，返回一个新的链表。这一题比较简单，要注意的有种情况： 链表相加完，有一个链表长度还有剩余 链表要记录进位，最后可能进位项还为1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode* head = new ListNode(-1); auto p = head; int step = 0; while(l1!=NULL&amp;&amp;l2!=NULL)&#123; int sum = l1-&gt;val + l2-&gt;val+step; if(sum&gt;=10)&#123; sum -= 10; step = 1; &#125; else&#123; step = 0; &#125; p-&gt;next = new ListNode(sum); p = p-&gt;next; l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; auto l = l1 != NULL ? l1 : l2; if(l!=NULL)&#123; while(l!=NULL)&#123; int sum = l-&gt;val +step; if(sum&gt;=10)&#123; sum -= 10; step = 1; &#125; else&#123; step = 0; &#125; p-&gt;next = new ListNode(sum); p = p-&gt;next; l = l-&gt;next; &#125; &#125; if(step==1)&#123; p-&gt;next = new ListNode(1); &#125; return head-&gt;next; &#125;&#125;; 数据大小及其表示的问题 整数int的上下界： 12最小的表示方式：-1&lt;&lt;31，INT_MIN最大的表示方式：1&lt;&lt;31 -1,INT_MAX 其他类型： 123unsigned int -&gt;UINT_MAXlong-&gt;LONG_MAXunsigned long-&gt;ULONG_MAX 无穷大的选择： 1const int INF = 0x7fffffff; 0x7fffffff 是32-bit int的最大值。 1const int INF = 0x3f3f3f3f 0x3f3f3f3f的十进制是1061109567，是10^9级别的（和一个数量级），而一般场合下的数据都是小于10^9的，可以用来表示无穷大。此外，0x3f3f3f3f * 2 =2122219134，这非常大但却没有超过32-bit int的表示范围，所以0x3f3f3f3f能够满足“无穷大加无穷大还是无穷大”的需求。如果我们想要将某个数组清零，我们通常会使用memset(a,0,sizeof(a))。但是当我们想将某个数组全部赋值为无穷大时，就不能使用memset函数而得自己写循环了，因为memset是按字节操作的。如果我们将无穷大设为0x3f3f3f3f，0x3f3f3f3f的每个字节都是0x3f！所以要把一段内存全部置为无穷大，我们只需要memset(a,0x3f,sizeof(a))。 123#include&lt;cstring&gt;memset(a,0,sizeof(a)); //给a数组置0memset(a，0x3f,sizeof(a));//给a数组赋值正无穷 表示一个很小的数：1const long double eps = 1e-8; 1e-8 是0.00000001，用来表示一个很小很小的数，通常可以用来判断两个数是否相同，即精度的差距。 2/22/1019 3. Longest Substring Without Repeating Characters分析：这一题题目非常好理解，找到字符串中的最长非重复子串。一看这一题的题目就感觉会有大量的元素比较，重复计算，因此可以用DP来做，用一个数组存储子问题的解。 维护一个数组res[j]，用来存储子问题的解，遍历原始数组，如果发现循环到的元素s[i]与res中最后一个位置所代表的元素不同，这res[j]++;如果发现相同这j++;res[j] = res[j-1]-1。具体写代码的时候里面有很多陷阱，看代码注释：12345678910111213141516171819202122232425262728class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; if(s.size() == 0) return 0; vector&lt;int&gt; res(s.size()); int j = 0; res[0] = 1; int flag = 0; for(int i = 1;i&lt;s.size();i++)&#123; for(int k = j;k&lt;i;k++)&#123; //判断当前循环元素与子串中是否有重复 if(s[k]==s[i])&#123; flag = 1; &#125; &#125; if(j&gt;=i) continue; //由于底下有i--的操作，需要保证j&lt;i if(flag == 0)&#123; // all different res[j]++; &#125; else&#123; //如果有重复 flag = 0; j++; //res表示的子串向前缩减 i--; //当前遍历到的元素需要保留 res[j] = res[j-1]-1&gt;0? res[j-1]-1 : 1; //保证res[j]最小为1 &#125; &#125; return *max_element(res.begin(),res.end()); &#125;&#125;; tip：关于vector找最大值最小值：12int maxValue = *max_element(s.begin(),s.end());int minValue = *min_element(s.begin(),s.end()); 5. Longest Palindromic Substring 分析：找到最长的回文子串，可以用一个窗口去扫描，窗口的长度有2到字符串长度。该做法的时间复杂度为$O(n^2)$。 1234567891011121314151617181920212223242526272829class Solution &#123;public: string longestPalindrome(string s) &#123; if(s.size() == 0) return ""; int pos = 0; int length = 1; for(int l = 2;l&lt;=s.size();l++)&#123; // 回文的长度 cout&lt;&lt;l&lt;&lt;" "; for(int i = 0;i&lt;s.size()-l+1;i++)&#123; int j = i+l-1; int temp = i; while(temp&lt;j)&#123; // 判断窗口内是否满足回文 if(s[temp]==s[j])&#123; temp++; j--; &#125; else&#123; break; &#125; &#125; if(temp&gt;=j)&#123; //说明满足回文 pos = i; length = l; &#125; &#125; &#125; return s.substr(pos,length); &#125;&#125;; 2/23/2019 6. ZigZag Conversion分析：这一题题意要求生成zigZag字形的序列，如图。可以用下标间关系求解，规定i为行数，j为要输出位置的下标，则该序列中下标间存在以下关系： V口向上： j += 2*（numRows-i-1） V口向下：j +=2i 第一行和最后一行处于V的交界位置，需要排除掉一种即可。 1234567891011121314151617181920class Solution &#123;public: string convert(string s, int numRows) &#123; if(s.size() == 0) return ""; if(numRows == 1) return s; string res = ""; for(int i = 0;i&lt;numRows;i++)&#123; int j = i; while(j&lt;s.size())&#123; res += s[j]; j += 2*(numRows-i-1); if(j&lt;s.size()&amp;&amp;i!=0&amp;&amp;i!=numRows-1)&#123; res += s[j]; &#125; j += 2*i; &#125; &#125; return res; &#125;&#125;; 8. String to Integer (atoi)分析：这一题做的我很狼狈，可以按从头到尾扫描的方式来做，我的做法太蠢了。特例很多。 从头到位扫描。 当判断一个string 转成int是否超过精度的时候，可以申请一个long long类型的变量，判断他是否大于边界值。 char 转int的方式： str[i] - &#39;0&#39;;即可。 我的做法：（不推荐，虽然挺快的）1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: int myAtoi(string str) &#123; if(str.size() == 0) return 0; string s = ""; for(int i = 0;i&lt;str.size();i++)&#123; if(s ==""&amp;&amp;str[i] == ' ') continue; if(s=="")&#123; if(isdigit(str[i])) s = str[i]; else if(str[i] =='-') s += '-'; else if(str[i] == '+') s += '+'; else return 0; &#125; else&#123; if(!isdigit(str[i])) break; s+=str[i]; &#125; &#125; if(s.size() == 0) return 0; if(s.size() == 1 &amp;&amp; s[0] == '-') return 0; int flag = 1; if((s[0]=='+'||s[0]=='-')&amp;&amp;!isdigit(s[1])) return 0; if(s[0] == '-')&#123; flag = -1; s = s.substr(1,s.size()-1); &#125; else if(s[0] == '+') &#123; s = s.substr(1,s.size()-1); &#125; if(s.size()&gt;1)&#123; while(s.size()&gt;1&amp;&amp;s[0]=='0')&#123; s = s.substr(1,s.size()-1); &#125; &#125; string min = "2147483648"; if(s.size()&gt;10) return flag == 1? INT_MAX:INT_MIN; if(s.size()&gt;=min.size()&amp;&amp;s&gt;=min) return flag == 1? INT_MAX:INT_MIN; else return stoi(s)*flag; &#125;&#125;; 比较合理的做法：12345678910111213int myAtoi(string str) &#123; if(str.size() == 0) return 0; long long base = 0; int sign = 1,i = 0; while(str[i] == ' ') i++; if(str[i] == '+') i++; else if(str[i] == '-') sign = -1,i++; while(i&lt;str.size()&amp;&amp;str[i]&gt;='0'&amp;&amp;str[i]&lt;='9')&#123; base = base*10 + str[i++]-'0'; if(base&gt;INT_MAX) return sign == 1?INT_MAX:INT_MIN; &#125; return base*sign;&#125; 35. Search Insert Position分析： 这一题可以用分治法来做，主要的点在于当要找的数不存在时，它如果比num[high]大，那么插入点为high（需要保证high&gt;=0），如果比high小，插入点为high+112345678910111213141516class Solution &#123;public: int searchInsert(vector&lt;int&gt;&amp; nums, int target) &#123; if(nums.size() == 0) return 0; int low = 0; int high = nums.size()-1; while(low&lt;=high)&#123; int mid = (high+low)/2; if(nums[mid] == target) return mid; else if(nums[mid]&gt;target) high = mid -1; else low = mid + 1; &#125; if(high&gt;=0&amp;&amp;nums[high]&gt;target) return high; else return high+1; &#125;&#125;; 24/2/2019 10. Regular Expression Matching这道题的题意是判断两个字符串是否能够匹配，由于*号可以替换多个字符，因此这一题有一个递归的过程，也就是说，替换的个数可能是1，2…等等。所以要用递归的方法求解。 当p[1] == &#39;*&#39;: 两种情况，*直接跳过；match一个字符； 当p[1]!=*: 则两个字符对应位置match 递归解法：12345678910111213class Solution &#123;public: bool isMatch(string s, string p) &#123; if(p.empty()) return s.empty(); if(p[1]=='*')&#123; return isMatch(s,p.substr(2))||(!s.empty()&amp;&amp;(s[0] == p[0]||p[0]=='.')&amp;&amp;isMatch(s.substr(1),p)); &#125; else return !s.empty()&amp;&amp;(s[0]==p[0]||p[0]=='.')&amp;&amp;isMatch(s.substr(1),p.substr(1)); &#125;&#125;; 动态规划法利用dp数组把所有的子情况都进行保存。有以下几种情形： dp[i][j]: s(0,i) ,p(0,j)是否match 当 p[j-1] != *: dp[i][j] == d[i-1][j-1]&amp;&amp;s[i-1] == p[j-1] 当p[j-1] == *： 两种：有替换或无替换：123dp[i][j] = dp[i-1][j] //in this case, a* counts as multiple a dp[i][j] = dp[i][j-1] // in this case, a* counts as single a dp[i][j] = dp[i][j-2] // in this case, a* counts as empty 动态规划：123456789101112131415161718192021class Solution &#123;public: bool isMatch(string s, string p) &#123; if(p.empty()) return s.empty(); int len1=s.size(),len2=p.size(); vector&lt;vector&lt;bool&gt;&gt; dp(len1+1,vector&lt;bool&gt;(len2+1,false)); dp[0][0]=true; for(int i=0;i&lt;=len1;i++) &#123; for(int j=1;j&lt;=len2;j++) &#123; if(p[j-1]=='*') dp[i][j] = dp[i][j-2] || ( i&gt;0 &amp;&amp; dp[i-1][j] &amp;&amp; (s[i-1]==p[j-2] || p[j-2]=='.') ); else dp[i][j] = i&gt;0 &amp;&amp; dp[i-1][j-1] &amp;&amp; (s[i-1]==p[j-1] || p[j-1]=='.'); &#125; &#125; return dp[len1][len2]; &#125; &#125;; 12. Integer to Roman 分析：这一题题意要求将普通数字表示称罗马数字，注意一一对应的关系即可。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123;public: string intToRoman(int num) &#123; string res = ""; while(num&gt;=1000)&#123; res += "M"; num -= 1000; &#125; if(num&gt;=900)&#123; res+= "CM"; num -= 900; &#125; else if(num&gt;=100)&#123; if(num&gt;=500) res+='D',num -= 500; else if(num&gt;=400) res += "CD",num -= 400; while(num&gt;=100)&#123; res +='C'; num-=100; &#125; &#125; if(num&gt;=90)&#123; res += "XC"; num -= 90; &#125; else if(num&gt;=10)&#123; if(num&gt;=50) res += 'L',num -= 50; else if(num&gt;=40)res+="XL",num -= 40; while(num&gt;=10)&#123; res +='X'; num -= 10; &#125; &#125; if(num&gt;=9)&#123; res += "IX"; num -= 9; &#125; else if(num&gt;=1)&#123; if(num&gt;=5) res += "V",num -= 5; else if(num&gt;=4)res +="IV",num-=4; while(num&gt;=1)&#123; res +='I'; num -= 1; &#125; &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络-- CNN]]></title>
    <url>%2F2019%2F02%2F19%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN%2F</url>
    <content type="text"><![CDATA[卷积神经网络 – CNNCNN最早由LeCun 在1998年《Gradient-based learning applied to document recognition》中提出，并提出了一个目标检测的模型：LeNet-5，随后在2012年ImageNet竞赛上，基于CNN网络的AlexNet取得了第一，且正确率超出第二近10%，取得了历史性的突破。CNN开始大放异彩，VGG Net，Google Net，ResNet等，都是基于CNN网络的一些杰出的工作。 CNN基本模块CNN由输入和输出层以及多个隐藏层组成，隐藏层可分为卷积层，池化层、RELU层和全连通层，如下图：输入层CNN的输入为原始图像，三维（RGB）或二维的向量。卷积层卷积层是CNN的核心，卷积层由一组可学习的滤波器（filter）或内核（kernels）组成，它们具有小的感受野，每个卷积核具有kernel size，padding，stride等参数。从图像的左上角依次做内积操作，提取出图片的高层次特征。pooling layer池化层对conv后输出的feature map进行下采样操作，这样的好处有降低参数的数量，防止过拟合等作用。relu激活函数在CNN中使用relu激活函数，在网络中引入了非线性。通过relu激活函数传递卷积运算的结果。因此，最终特征映射中的值不是简单的线性关系。全连接层全连接层的输入是一维向量，需要将pooling 层的输出向量flatten成一个一维的向量，然后输入到全连接层中，最后送到soft Max层进行类别的分类。 值得注意的是：在很多CNN网络结构中，pooling层的kernel = 2x2, stride = 2 ， padding = 0,经过这样的pooling后，输出图片缩小一半。 卷积层的kernel = 3x3, stride = 1， padding = 1。经过这样的卷积，输出大小与输入相同。 CNN的特点局部感知局部感知即卷积核的感受野，指的是卷积核所覆盖的像素面积，由于每个卷积核所覆盖的面积仅是很少的一部分，是局部特征，即为局部感知。CNN是一个从局部到整体的过程（局部到整体的实现是在全连通层）。下图是全连接层和卷积层的对比。 权重共享传统的神经网络的参数量巨大，例如对1000X1000像素的图片做一次全连接操作，需要（1000X1000）10的6次方个参数。而CNN除全连接层外，卷积层的参数完全取决于滤波器的设置大小，比如10x10的滤波器，仅有100个参数。整个图片共享一组滤波器的参数，参数数量少，计算简单。多卷积核一种卷积核代表的是一种特征，为获得更多不同的特征集合，允许有多个卷积核，卷积生成的feature map有几个channel就有几个卷积核。 dropout技术dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5），与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。dropout的实现：12345678910111213141516171819#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元#dropout函数的实现def dropout(x, level): if level &lt; 0. or level &gt;= 1:#level是概率值，必须在0~1之间 raise Exception('Dropout level must be in interval [0, 1[.') retain_prob = 1. - level #我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样 #硬币 正面的概率为p，n表示每个神经元试验的次数 #因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。 sample=np.random.binomial(n=1,p=retain_prob,size=x.shape)#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了 print sample x *=sample#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0 print x x /= retain_prob # 归一化 return x#对dropout的测试x=np.asarray([1,2,3,4,5,6,7,8,9,10],dtype=np.float32)dropout(x,0.4) dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。dropout能防止过拟合： 多样化学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。 阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不应该依赖于另外一个神经元。 CNN经典框架：LeNet：开始用于手写数字字体识别32*32，处理不了大型的图片，用于缺少计算机资源的时候。3个卷积层大小为5x5，2个pooling 层，大小为2x2。 输入层，尺寸大于任何一个字母，以保证每个字母都会出现在第七层单元的感受野的中心。 中间五层分别是：卷积层→降采样层→卷积层→降采样层→卷积层。 第一个卷积层使用了六种滤波器，因此具有六个通道的 feature maps 。 第二个卷积层上升到16个通道。每一个通道与前6个通道的关系都不一样，见上图，目的是破坏对称性，迫使每个通道学习不同的特征（理想情况是互补特征）。 在全连接层，特征进行内积和非线性激活。 最后是输出层，10种数字对应10个输出单元，分别计算输出向量和该分类参考向量的欧式距离。 loss 为 MSE loss，输出向量和分类参考向量最近则将其判为这一类。AlexNet：AlexNet在2012年imageNet比赛上大放异彩，引发了神经网络的高潮，AlexNet共有5个卷积，5个pool，loss为softMax loss。 该网络有以下的创新：A. ReLU之前使用的 tanh 和 sigmoid 激活函数都存在饱和区。改用无饱和的 ReLU ，收敛速度可以达到数倍于 tanh ！B. Training on Multiple GPUs2个 GPU 协同，最直接的作用是加快了训练速度。作者尝试将网络改为单GPU，同时保证参数数量不变，速度略逊于双 GPUs 。C. Overlapping Pooling实验证明，重叠池化可以更好地抑制过拟合，使准确率提高约0.4%和0.3%。D. Data Augmentation最简单的抑制过拟合技术，就是 label-preserving transformations 。简单来说，就是让图像进行各种不影响目标本质的变换，扩大数据量。 - 镜像对称变换； - 图像光照强度和色彩变换。 第二点具体而言： - 先提取 RGB 三通道分量； - 对每一个通道分别进行主成分分析，提取出主成分； - 然后再进行三通道的随机系数线性组合。 E. Dropout如果我们有多个不同的模型合作进行预测，那么泛化误差将会有效降低。问题是，训练多个模型的计算成本很高昂。Dropout 为我们提供了新思路：让这些模型分享相同的权重系数，但神经元的输出结果不尽相同。具体而言，是让 hidden neuron 的输出有50%的概率被置零。这样，每次反向传播时，参考的 loss 都是由不同模型计算得到的。总的来说，Dropout 技术打破了神经元之间的依赖性，强迫网络学习更鲁棒的神经元连接。我们只在全连接层使用，因为全连接层的连接非常多。在测试阶段不采用 Dropout 。Dropout 会延长收敛时间，但能有效抑制过拟合。 VGG Net：VGG相对Googlenet虽然精度略逊些，但其整体网络框架还是延续了Alexnet及更早的Lenet等的一贯思路，此外还更深入的探讨了ConvNet深度对模型性能可能的影响。由于其整个网络结构的简单、强大，VGG16/VGG19曾一度广泛被用作各种检测网络框架像Faster-RCNN/SSD等的主干特征提取网络，直到Resnet提出之后，它才渐渐完成了其历史使命，退居二线。VGGnet有许多中深度的版本，他们基本采用了3x3的Conv kernel，pad/stride为1，只是在其中的若干Conv层后会置MaxPool层来作特征的上采样以高度抽象特征，节省后续的计算。然后在每个网络的最后则是同其它分类网络一样的若干个FCs层及Softmax。其中VGG16与VGG19最为受人欢迎（最深）。 作者表明：两个级联的3x3 conv或三个级联的3x3 conv分别在理论上等价于一个5x5 conv及一个7x7 conv。不过它们所具的模型参数要大大小于后面两者的参数。同时作者实验表明更深（层数更多）而非更宽（conv channels更多）的网络有着自动规则自己参数的能力，因此有着更好的学习能力。VGG使用与AlexNet相同的SGD对网络进行训练。VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少），相比于AlexNet使用更小的卷积核级联，更深的网络。 GoogleNet：（inception）尽管VGG可以在ImageNet上表现很好，但是将其部署在一个适度大小的GPU上是困难的，因为需要VGG在内存和时间上的计算要求很高。由于卷积层的通道数过大，VGG并不高效。在此之前经典的CNN模型像LeNet/Alexnet/VGG等无不是一个模子即使用Conv/Pool/Normalization/Activation等层来不断累积而成。模型对数据集概率分布的表达能力则往往通过单纯增加模型的深度（层数）或宽度（层的channels数）来提高（当然这也亦是当下深度学习领域的共识）。但这样进行网络设计一般会等来巨量的计算开销，因为每一层channels数目的增加都会随着层深而指数级增加，这大大地限制了模型的实际应用。 GoogleNet则从提高精度以及减少计算量的角度出发，想通过一种spared layer architecture来实现较优的多维度特征表达（inception module），然后通过对这种结构进行叠加，中间不时再插入一些MaxPool层以减少参数数目（从而节省内存与计算开销），最终就形成了Inception v1分类模型。GoogleNet团队计算效率以及GPU对密集计算的优化等等，选择了密集计算子结构组合而成的稀疏模块来用于特征提取及表达，这就是用于构建Inception v1的Inception module如上图中a所示。其中1x1/3x3/5x5这三种Conv kernels的选择决定是基于方便，因为这几种kernels用的多，而且比较容易对齐,padding。但是a中的模型计算量太大，因此作者在每个子conv层里使用了1x1的conv来作上一层的输入feature maps的channels数缩减、归总。例如：假设输入时 256 个 feature map 进来，256 个 feature map 输出，假设 Inception 层只执行 3x3 的卷积，那么这就需要这行 (256x256) x (3x3) 次卷积左右（大约 589,000 次计算操作），此时每一个特征的channel为256。现在 Bottleneck layer 的思想是先来减少特征的通道数， 操作量(每次卷积核参数)是：256(channel)×64(个) × 1×1 = 16,000s -&gt; 与1x1的卷积层做一次卷积，通道数缩减为6464(channel)× 64(个) × 3×3 = 36,000s64× 256(个) × 1×1 = 16,000s上诉处理能够大大减小计算量。模型的最后会选通过一个7x7的AvgPool层来处理最终的feature maps，大大降低了参数量。然后再由FC层汇总生成1000个输出，进而由Softmax来得到1000类的概率分布。 ResNet：Resnet分类网络是当前应用最为广泛的CNN特征提取网络。它的提出于2015年。残差学习：若将输入设为X，将某一有参网络层设为H，那么以X为输入的此层的输出将为H(X)。一般的CNN网络如Alexnet/VGG直接通过训练学习出参数函数H的表达，即直接得到H(X)。而残差学习则是学习输入、输出之间的残差即H(X) - X。即学习得到 (H(X) - X) 。最终的网络输出为：残差+X，其中X直接由identity mapping得到，而H(X) - X则为有参网络层要学习的输入输出间残差，优化难度大大减小。identity mapping：我们在输入与输出之间建立了一条连接，成为identity map，主要作用是将X传递到输出中，当输出与输入的channel数不一致时，通过直接补0或者用1x1 conv来映射。在处理一些很复杂的数据集时，作者引入bottleneck结构，即下图的1x1 的conv，第一个conv用来降低通道数，最后一个conv用来恢复通道数，这样的操作是的中间的conv维度不受输入影响，降低运算量。 退化现象：退化现象产生的原因在于当模型的结构变得复杂时，随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。通过建立identity map可以将浅层的信息传入深层网络，可以很好的缓解退化现象。 inception V2/V3：inception V2/V3遵循上面的思路，进一步对inception v1结构中较大的卷积核进行分解。例如将5x5的卷积核分解成两个级联的3x3的卷积核，减少参数的同时，增加了网络的学习能力。更高效的下采样方式：由于对features map做pooling将会损失掉一部分的信息，为了减少这种信息的损失，在VGGnet中，通常的做法是pooling 的同时增大features map的channel的数量。googlenet中的做法是，分类对features map进行conv以及pooling，然后将最后得到的feature maps进行组合，得到最终的feature map。作者认为，inception v1 中的辅助分类器起到的作用是对网络底层的参数进行归一化的作用，因此inception v3 在inception v2的基础上在辅助分类器中使用BN对参数进行regularization。同时在最终的loss中增加了标签平滑，用label的先验避免过拟合发生。 inception v4inception v4使用tensorflow完成，涉及结构更加复杂，计算量也相比比较小。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习中常用的技术（面试考点）]]></title>
    <url>%2F2019%2F02%2F19%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%88%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深度学习中常用的技术（面试考点）（一）神经网络中，防止过拟合的方法有： early stop（及早停止），当在测试集上出现错误率上升时，及时停止。 data expanding (扩大训练数据) dropout 技术（随机丢弃） 加入正则项 BN（让激活函数的输入分布保持在一个稳定状态来尽可能避免它们陷入梯度饱和区。） dropout技术dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5），与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。dropout的实现：12345678910111213141516171819#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元#dropout函数的实现def dropout(x, level): if level &lt; 0. or level &gt;= 1:#level是概率值，必须在0~1之间 raise Exception('Dropout level must be in interval [0, 1[.') retain_prob = 1. - level #我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样 #硬币 正面的概率为p，n表示每个神经元试验的次数 #因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。 sample=np.random.binomial(n=1,p=retain_prob,size=x.shape)#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了 print sample x *=sample#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0 print x x /= retain_prob # 归一化 return x#对dropout的测试x=np.asarray([1,2,3,4,5,6,7,8,9,10],dtype=np.float32)dropout(x,0.4) dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。dropout能防止过拟合： 多尺度学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。 阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不依赖于另外一个神经元。 Batch Normalization 参考链接深层网络难以训练，由于底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；参数的变化导致每一层的输入分布会发生改变，进而上层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。Internal Covariate Shift： 在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。因此而带来的问题： 上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低 网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（可以使用线性整流函数ReLU因为它可以在一定程度上解决训练进入梯度饱和区的问题） 缓解Internal Covariate shiftICS产生的原因是由于参数更新带来的网络中每一层输入值分布的改变，并且随着网络层数的加深而变得更加严重，因此我们可以通过固定每一层网络输入值的分布来对减缓ICS问题。常用的方法如下：白化：使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1；而ZCA白化则保证了所有特征分布均值为0，方差相同；去除特征之间的相关性。但是由于白化操作计算成本高，且将会改变网络每一层参数的分布，使得网络底层学到的信息被丢弃batch normalization 单独对每个特征进行normalizaiton(每一层)，让每个特征都有均值为0，方差为1的分布，减少计算量。线性变换操作，让网络恢复本身的表达能力。BN插在在全连接层之后如下图：BN操作如下： 对输入取均值 对输入取方差 计算normalize后的输入（其中 $\epsilon$ 是为了防止方差为0产生无效计算） 反标准化进行学习 反标准化是为了让神经网络能够学习batch normalization的平移拉伸，让数据再能够尽可能恢复本身的表达能力就好，达到学习的目的。 BN作用： BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度 BN使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定。BN不会受到权重scale的影响，因此其能够使模型保持在一个稳定的训练状态；而没有加入BN的网络则在一开始就由于学习率过大导致训练失败BN的网络能够克服如此bad的权重初始化 BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题 BN具有一定的正则化效果：在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，在一定程度上对模型起到了正则化的效果。 正则项L1 正则项： L1是模型各个参数的绝对值之和,将它添加到损失函数上：$$\min \frac{1}{N}\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_1$$L2 正则项：是模型各个参数的平方和的开方值：$$\min \frac{1}{N} \sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_{2}^{2}$$添加L1和L2正则项之后的损失函数如下：如图可以看出，如果仅有损失函数的话，优化目标为损失函数最内圈的紫色的环。但是给loss function加上正则化项，能使得新得到的优化目标函数h = f+normal，需要在f和normal中做一个权衡（trade-off），即最优解应该使得正则项和模型损失函数之和最小。 可以看出来，L1正则项与loss更多的相交于坐标轴，因此L1更容易产生稀疏解。L2的解比较接近与坐标轴，L2范数能让解比较小（靠近0），但是比较平滑（不等于0）。 正则项降低过拟合程度： L1正则化：在loss function后边所加正则项为L1范数，加上L1范数容易得到稀疏解（0比较多），能够避免过拟合。有助于生成一个稀疏权重矩阵，进而可用于特征选择。 L2正则化：在loss function后边所加正则项为L2范数的平方，L2控制w的大小，则w的幅度较小且较均匀。一般认为参数值较小的模型比较简单，能适应不同的数据集，一定程度上避免了过拟合。（缺点是L2对离群点敏感，而且容易造成梯度爆炸） 在Faster RCNN中，边框回归通常情况下，使用平方误差最小，即L2loss，但是由于，L2 loss对离群点比较敏感，同时，当预测边框距离真值边框比较远的时候，容易出现梯度爆炸的问题，因此使用smooth L1替代L2 loss，smooth L1 相比于正常的L1它是可导的。且导数是一个常数。 如何处理数据特征缺失项： 如果数据集样本很多，可以删除掉缺失的特征的个别样本。 用平均值，中位数，众数进行替换补全。（人为的增加了噪声） 使用一些机器学习的算法对数据特征进行恢复，如EM算法等等，KNN算法 异常值的检测： 当数值在$(\mu -3\sigma,\mu+3\sigma)$之外时，属于异常数值。 使用K nearnest neighbour计算每一个点的K近邻，然后距离临近点距离最远，而且周围的邻居位置很稀疏的情况下，这个点很可能是异常点。 canny边缘检测介绍：canny边缘检测是一个基于图像梯度的边缘检测算法。由于图像边缘即图像中的高频部分，噪音也属于高频信息，因此首先需要对图像进行去噪（高斯滤波器），然后提取图片梯度，然后对提取的梯度做一些例如非极大值抑制等处理，总之canny算子没有考虑到图片全局的信息，仅仅使用了梯度来提取边缘。对于一些梯度不明显的边缘信息可能无法很好的提取。 max pooling 与 average pooling的应用有何不同： 使用pooling技术将小邻域内的特征点整合，同时保持某种不变性（旋转、平移、伸缩等）。average-pooling对领域内特征取平均值，结果融合了所有的特征。平均操作类似与平滑处理，能够保留图片的低频信息，即更多的保留图像的背景信息。因此更多用在最后的分类中。max-pooling对领域内的特征值取最大值，即能够极大的保留图片的边缘信息，纹理信息。一张图片的高频信息能够极大程度的表示一个物体，因此进行下采样特征缩减时更多用到max-pooling。 训练过程中学习率如何调整： 从大到小依次衰减 或者使用RMSprop更新法，在累计梯度的平方项上进行衰减。 CNN网络中全连接层的作用：全连接层将学到的“分布式特征表示”映射到样本标记空间（进行分类）。全连接层参数过多（一个大型的分类问题，参数量通常占到80%）不宜有太多层全连接层。是把卷积提取的特征看做多层感知机的输入节点，后面只需要接两层全连接理论上就可以拟合任意非线性函数， GAP（全局平均池化）：将每张feature的值全部加起来，取平均，每一个均值代表一个类别。比如有10个类，就在最后输出10个 feature map，每个feature map中的值加起来求平均值，这十个数字就是对应的概率或者叫置信度。然后把得到的这些平均值直接作为属于某个类别的 confidence value，再输入softmax中分类。用GAP代替全连接层可以大幅减小参数量，同时检测效果不会变差。 维度灾难：对于大多数数据，在一维空间或者说是低维空间都是很难完全分割的，但是在高维空间间往往可以找到一个超平面，将其完美分割。于是我们将维度提升，例如从2维到3维这样就可以区分开物体了。但是无限制的增大数据的纬度，会出现分类进度极速下降的问题。即分类器过拟合，出现维度灾难。 聚类方法：K-means 聚类 首先确定样本的类别数n，然后在样本上随机确定n个中心 然后计算每一个样本到样本中心的距离，将该样本划分到距离它最近的那一类中 对划分过的样本重新计算各类的类中心 重复上述步骤，直到类中新位置不发生明显变化为止 基于密度的聚类方法(DBSCAN) 首先确定半径r和minPoints. 从一个没有被访问过的任意数据点开始，以这个点为中心，r为半径的圆内包含的点的数量是否大于或等于minPoints，如果大于或等于minPoints则该点被标记为central point，反之则会被标记为noise point。 重复上面的步骤，如果一个noise point存在于某个central point为半径的圆内，则这个点被标记为边缘点，反之仍为noise point。重复上述步骤，直到所有的点都被访问过。 混合高斯模型（GMM）最大期望（EM）聚类： 选择簇的数量（与K-Means类似）并随机初始化每个簇的高斯分布参数（均值和方差）。 给定每个簇的高斯分布，计算每个数据点属于每个簇的概率。一个点越靠近高斯分布的中心就越可能属于该簇。 基于这些概率我们计算高斯分布参数使得数据点的概率最大化，可以使用数据点概率的加权来计算这些新的参数，权重就是数据点属于该簇的概率。 重复迭代2和3直到在迭代中的变化不大。 自顶向下的层次分类： 将所有样本视为一类，然后对样本进行m次二分实验，然后选择一种分类，分类后的两簇SSE（Sum of the Squared Error）之和最小。 选择最大SSE的簇，然后对他重复上述分类，直到分类到k个簇。 L1 loss 为什么会导致稀疏解：如下图，原函数设为L，它的极小点为绿色的点，不在原点。加上L2 loss之后L+L2的极小点为黄点。加上L1后L+L1的极小点为红点。 为什么L1 loss的最小点就是原点呢？要形成极小值点，以上图为例，x0 时导数&gt;0 (函数增)，x从左边趋近于0 时，C|x|的导数是-C，假设此时 L 的导数为 La ，必须有 La -C &lt;0，即C&gt;La，同理x从右边趋近于0时，必须有 Lb + C &gt; 0 ，即C&gt;-Lb，所以说C要大于L在0点附近的绝对值。即原点左右两边的导数正负不同，原点为一个极小点。 海量数据球中位数：使用堆的思想。查找中位数，也就是找出中间最大的数字，总共10G的数据，查找第5G大的数据，创建一个1G的大顶堆，遍历一遍这个10G的数据，找出前1G大的数据，在这个大顶堆中找出最小的值，这个最小的值就是这10G数据中第1G大的元素，然后利用这个元素在创建大顶堆，比这个元素小的才能进堆，那么就创建了从1G到2G的元素，这么一来，就找到了第2G大的元素，利用第2G大的元素就可以找到第5G大的元素，这么一来就可以找到中位数了。 pooling 层如何进行反向传播： max pooling层：对于max pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项的值都是0； mean pooling层：对于mean pooling，下一层的误差项的值会平均分配到上一层对应区块中的所有神经元。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Faster RCNN详解]]></title>
    <url>%2F2019%2F02%2F14%2FFaster-RCNN%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Faster RCNN详解Faster RCNN 是在Fast RCNN的基础上，进一步改进，解决select search 算法选择候选框速度太慢的问题。 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networkssubmit time: 2016arxiv link fast R-CNN和faster R-CNN之间的区别在于我们不使用特殊区域提议方法来创建region proposal。而是训练一个region proposal network（RPN），该网络将features map 作为输入并输出region proposals。然后将这些proposal输入Fast R-CNN中的RoI池化层。以下是fast RCNN与Faster RCNN的网络结构对比图。Faster RCNN 关键步骤： Conv layers。作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。 Region Proposal Networks。RPN网络用于生成region proposals。该层通过softmax判断anchors属于foreground或者background，再利用bounding box regression修正anchors获得精确的proposals。 Roi Pooling。该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。 Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。 Faster RCNN 网络是用于目标检测的一种比较流行的框架。它主要由以下四个部分组成 分别是conv layer 输入为原始图片，用于提取图片的feature map RPN网络，输入为features map，用于生成region proposal，该层为features map 上每个像素生成若干个anchors（9个），随后通过softmax 判断每个anchor是属于foreground（目标）或者background（背景），再利用bounding box regression修正anchors获得精确的proposal位置。 RoI pooling，该层输入为proposal位置信息和features map，通过proposal的位置信息在features map 上提取region features map候选区，然后通过pooling产生一个固定长度的特征，送入全连接层进行目标判别。 classification，利用proposal feature maps计算proposal的类别，同时再次进行一次bounding box regression，对proposal位置进行精修，随后将结果输出。 总结一套介绍网络框架的先后顺序的方法。 可以先大后小，按照先后顺序从前到后，按功能性介绍一件事情，每件事情的功能介绍的时候，说清楚输入，工作流程附带其具体功能，输出。 Faster RCNN 详细网络结构如图： 将一副任意大小PxQ的图像，首先缩放至固定大小MxN，然后将MxN图像送入网络；而卷积层 Conv layers中包含了13个conv层+13个relu层+4个pooling层；RPN网络首先经过3x3卷积，再分别生成foreground anchors与bounding box regression偏移量，然后计算出proposals；而Roi Pooling层则利用proposals以及feature maps，提取proposal feature送入后续全连接和softmax网络作classification。 conv layer Conv layers部分共有13个conv层，13个relu层，4个pooling层。 所有的conv层都是： kernel_size=3 ， pad=1 ，stride=1，因此conv层不改变原图大小 所有的pooling层都是： kernel_size=2 ，pad=0 ， stride=2，pooling 层将原图缩小为原来的一半 经过Conv layer后，一个MxN大小的矩阵将变为(M/16)x(N/16) Region Proposal Networks(RPN)Faster RCNN 层在fast RCNN 的基础上，对提取候选框进行优化。 RPN网络分为2条线，上面一条通过softmax分类anchors获得foreground和background（检测目标是foreground），下面一条用于计算anchors的bounding box regression偏移量，以获得精确的proposal。而最后的Proposal层则负责综合foreground anchors和bounding box regression偏移量获取proposals，同时剔除太小和超出边界的proposals。其实整个网络到了Proposal Layer这里，就完成了相当于目标定位的功能。 anchorsanchor为由一个中心点，周围生成了9个矩形，矩形长宽比由三个尺寸1:1,1:2;2:1三种，如下图，基本覆盖了各种尺寸和形状，引入检测中常用到的多尺度方法。Faster RCNN遍历Conv layers计算获得的feature maps，为feature map上每一个点都配备这9种anchors作为初始的检测框。这样做获得检测框很不准确，之后将会在RPN层，以及最后进行2次的bounding box regression修正检测框位置。如上图，对于每一个点的k个anchor来说，从conv layer提取出得特征具有256维，对于每一个anchor，需要分foreground与background，因此共有2k个score，对于每一个anchor共有$(x_1,y_1,x_2,y_2)$四个坐标值。因此共有4k个coordinates。在训练阶段，程序将会从这些anchor中挑选出一些合适的anchor进行训练。因此RPN最终就是在原图尺度上，对每一个像素设置9个尺度的候选anchor。然后用cnn去判断哪些Anchor是里面有目标的foreground anchor，哪些是没目标的backgroud。所以，仅仅是个二分类而已！那么Anchor一共有多少个？原图800x600，VGG下采样16倍，feature map每个点设置9个Anchor，所以：$$ceil(800/16) \times ceil(600/16) \times 9=50\times38 \times9=17100$$其中ceil()表示向上取整，是因为VGG输出的feature map size= 50*38。 softmax判定foreground与backgroundRPN网络中利用anchors和softmax初步提取出foreground anchors作为候选区域。features map 首先做一个1*1的卷积，这个卷积的作用是生成一个$W*H*(9*2)$大小的矩阵。该矩阵用于存储上面提到的foreground与background信息（2*k score）。将该特征后接softmax分类获得foreground anchors，也就相当于初步提取了检测目标候选区域box（一般认为目标在foreground anchors中）。前后两个reshape 操作目的为便于程序实现。clc layer输出预测区域共k个，每个有的2个参数，即预测为前景的概率和背景的概率，损失用softmax loss（cross entropy loss）。监督信息是Y=0,1，表示这个区域是否为groundtruth。确定groundtruth时，我们需要确定k个区域中的各个区域是不是有效的，是前景还是背景。K个区域分配标签规则： 与某个ground truth(GT)的IoU最大的区域的分配正标签 与任意GT的IoU大于0.7的区域分配正标签 与所有GT的IoU都小于0.3的区域分配负标签 bounding box regression原理对于窗口一般使用四维向量 (x, y, w, h) 表示，分别表示窗口的中心点坐标和宽高。对于图 11，红色的框A代表原始的Foreground Anchors，绿色的框G代表目标的GT，我们的目标是寻找一种关系，使得输入原始的anchor A经过映射得到一个跟真实窗口G更接近的回归窗口G’，即： 给定：$anchor A=(A_{x}, A_{y}, A_{w}, A_{h}) 和 GT=[G_{x}, G_{y}, G_{w}, G_{h}]$寻找一种变换F，使得：$F(A_{x}, A_{y}, A_{w}, A_{h})=(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})，$其中$(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})≈(G_{x}, G_{y}, G_{w}, G_{h})$那么经过何种变换F才能从图10中的anchor A变为G’呢？ 比较简单的思路就是先做平移，然后进行缩放，边框回归与RCNN中边框回归相同。bounding box 原理参考链接RPN中所涉及的边框回归首先经过一个1*1的卷积层，输出一个$W*H*(9*4)$的矩阵，用于存储box的坐标信息（4k coordinate） RPN值得注意的地方: - RPN在原图的尺度上选择anchor的大小- anchor的数目是feature map上每个像素选择9个长宽比不同的矩形- soft Max层用于判断anchor是否为前景（含有目标）- bounding box regression 预测的输出是anchor的偏移变换- proposal层，结合前景的anchor（背景anchor被忽略）与anchor偏移变换，对anchor位置进行调整，计算出proposal的精确位置。- bounding box 本质上是学习一个W权重矩阵，即那个1*1的网络的参数（输出为4K regreason,对应anchor的（x，y,w,h）四个偏移），利用W参数乘以 CNN pool5层输出的features map，通过最小二乘，得到anchor的偏移。- 为什么bounding box regression不直接预测坐标呢？ 因为坐标间的关系不是简单的一维关系，难以优化。当anchor 与 ground truth比较接近时，他们之间的位置关系（偏移）就可以用一维关系来近似。- proposal层输出的proposal坐标是在原图的尺度上的proposal坐标。#### proposal layerRPN 最后一层为proposal layer，用于前景anchors，以及anchor对应的边框回归微调参数$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$和im_info=[M, N, scale_factor]（传入Faster RCNN前首先reshape到固定MxN，im_info则保存了此次缩放的所有信息）来计算产生的proposal位置，此时输出的proposal坐标为原图尺度上的proposal坐标。Proposal Layer forward（caffe layer的前传函数）按照以下顺序依次处理：- 生成anchors：利用$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致）- 按照输入的foreground softmax scores由大到小排序anchors，提取前pre_nms_topN(e.g. 6000)个anchors，即提取修正位置后的foreground anchors。- 限定超出图像边界的foreground anchors为图像边界（防止后续roi pooling时proposal超出图像边界）- 剔除非常小（width&lt;threshold or height&lt;threshold）的foreground anchors- 进行nonmaximum suppression- 再次按照nms后的foreground softmax scores由大到小排序fg anchors，提取前post_nms_topN(e.g. 300)结果作为proposal = [x1, y1, x2, y2]输出。输出的proposal=[x1, y1, x2, y2]，由于在第三步中将anchors映射回原图判断是否超出边界，所以这里输出的proposal是对应MxN输入图像尺度的。RPN网络结构主要步骤如下：生成anchors -&gt; softmax分类器提取前景 anchors -&gt; bbox reg回归前景 anchors -&gt; Proposal Layer生成proposals#### RoI pooling layerRoI Pooling layer负责收集proposal，并计算出proposal feature maps，送入后续网络。Rol pooling层有2个输入：- 原始的feature maps- RPN输出的proposal boxes（大小各不相同）RoI Pooling layer forward过程：- 由于proposal是对应$ M\times N$ 尺度的，所以首先使用spatial_scale参数将其映射回 $(M/16)\times(N/16) $大小的feature map尺度；- 再将每个proposal对应的feature map区域水平分为 $\text{pooled_w}\times \text{pooled_h} $的网格；- 对网格的每一份都进行max pooling处理。经过上述处理后，即使大小不同的proposal输出结果都是 $\text{pooled_w}\times \text{pooled_h}$ 固定大小，实现了固定长度输出。#### ClassificationClassification部分利用已经获得的proposal feature maps，通过full connect层与softmax计算每个proposal具体属于那个类别（如人，车，电视等），输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置偏移量bbox_pred，用于回归更加精确的目标检测框。从PoI Pooling获取到7x7=49大小的proposal feature maps后，送入后续网络，可以看到做了如下2件事：- 通过全连接和softmax对proposals进行分类- 再次对proposals进行bounding box regression，获取更高精度的rect box#### Faster R-CNN训练Faster R-CNN的训练，是在已经训练好的model（如VGG_CNN_M_1024，VGG，ZF）的基础上继续进行训练。实际中训练过程分为6个步骤：- 在已经训练好的model上，训练RPN网络- 利用步骤1中训练好的RPN网络- 第一次训练Fast RCNN网络- 第二训练RPN网络- 再次利用步骤4中训练好的RPN网络- 第二次训练Fast RCNN网络可以看到训练过程类似于一种“迭代”的过程，不过只循环了2次。至于只循环了2次的原因是应为作者提到：”A similar alternating training can be run for more iterations, but we have observed negligible improvements”，即循环更多次没有提升了。#### RPN 训练与检测网络类似的是，依然使用Conv Layers提取feature maps。整个网络使用的Loss如下：$$L({p_i},{t_i})=\frac{1}{N_{cls}}\sum_{i} L_{cls}(p_i,p_i^*)+\lambda \frac{1}{N_{reg}}\sum_{i} p_i^* L_{reg} (t_i,t_i^*)$$上述公式中 i 表示anchors index，$ p_{i}$ 表示foreground softmax probability，$p_{i}^{*}$代表对应的GT predict概率（即当第i个anchor与GT间IoU&gt;0.7，认为是该anchor是foreground，$p_{i}^{*}=1$；反之IoU&lt;0.3时，认为是该anchor是background，$ p_{i}^{*}=0 $；至于那些0.3&lt;IoU&lt;0.7的anchor则不参与训练）；t代表predict bounding box，$ t^{*} $ 代表对应foreground anchor对应的GT box。可以看到，整个Loss分为2部分：- cls loss，即rpn_cls_loss层计算的softmax loss，用于分类anchors为forground与background的网络训练- reg loss，即rpn_loss_bbox层计算的soomth L1 loss，用于bounding box regression网络训练。注意在该loss中乘了 $p_{i}^{*}$ ，相当于只关心foreground anchors的回归（其实在回归中也完全没必要去关心background）。Smooth L1 loss 相比于L2 loss对离群点更加不敏感，更加鲁棒。当预测值与目标相差很大时，L2 loss的梯度是x-t，容易产生梯度爆炸，而L1的梯度为常数，使用L1 loss 可以防止梯度爆炸。 关于softMax loss 和 边框回归loss与fast RCNN 相同。链接]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fast RCNN详解]]></title>
    <url>%2F2019%2F02%2F14%2FFast-RCNN%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Fast RCNN详解SPP-Net改造了RCNN，使用SPP layer使得输入图片大小不受限制，同时使用region proposal映射的方式，大大加速了目标检测的速度，但是SPP-net训练需要花费很多时间，同时fine-tune不能越过SPP层，因为pyramid BP开销太大了（金字塔感受野比较大），只能fine-tune全连接层，tune不到卷积层，所以在一些较深的网络上准确率上不去。Fast RCNN 受到SPP-Net网络，在网络卷积层后加入ROI层（region of interesting）。此外，损失函数使用了多任务损失函数(multi-task loss)，将分类和边框回归两个loss统一到一个网络中一起训练。 Fast RCNNsubmit time: 2015arxiv link Fast RCNN网络结构如下：Fast RCNN关键步骤： select search 算法提取2k个region proposal 区域 将整张图片输入CNN网络中，提取出整张图片的特征 将2k个region proposal区域映射到feature maps上（RoI projection） 通过RoI pooling layer，将features map上的大小不一致的region proposal变成固定长度的特征向量。 将特征向量通过一系列FCs层分别输入softMax，以及bbox regression。利用Softmax Loss(探测分类概率) 和Smooth L1 Loss(探测边框回归)对分类概率和边框回归(Bounding box regression)联合训练。 ROI pooling layerRoI池化层使用最大池化将任何有效区域内的特征转化成一个小的带有固定空间范围HxW（比如7×7）的特征图，其中H和W是层的超参数，和任何特定的RoI无关。本文中，一个RoI是针对卷积特征图的一个矩形窗口。每个RoI定义成四元组（r, c, h, w），左上角为（r, c），高和宽是（h, w）。RoI最大池化将hxw的RoI窗口分成HxW的子窗口网格，每个子窗口大小大约是h/H x w/W。然后每个子窗口进行最大池化放入网格对应的单元。池化以标准最大池化的形式独立应用在每个特征图的channel上。RoI层是SPPnets中的空间金字塔层的一个特例，因为他是一个一层的金字塔结构。即将一个hw大小的框转化为HW大小的框，每个H*W的网格为h/H x w/W区域内最大的值(max-pooling)表示。 为目标检测任务做微调 分层采样得到SGD的mini-batch，首先采样N个images，然后每个image采样R/N个ROIs。来自同一个image的ROIs在前向后向传输时共享计算和内存，减小N 则能降低mini-batch的计算。这种分层采样的策略实际中不会减慢收敛速度。作者使用N=2, R=128， 并发现SGD迭代次数比R-CNN的还少。 联合优化softmax分类器和bbox regressor回归器 Multi-task Losssoftmax类别分类器R-CNN与SPPNet均使用SVM作为分类器，而Fast R-CNN使用softmax作为分类器，以下为真实类属u的log loss，即p的值越到loss越接近1。$$L_{cls}(p, u) = -logp_u$$ softmax函数可以将连续数值转换为相对概率：$$P_i= \frac{e^{V_i}}{\sum_i^C{e^{V_i}}}​$$实际应用中，使用 Softmax 需要注意数值溢出的问题。因为有指数运算，如果 V 数值很大，经过指数运算后的数值往往可能有溢出的可能。所以，需要对 V 进行一些数值处理：即 V 中的每个元素减去 V 中的最大值。$$\begin{align}D = \max(V) \nonumber\\P_i= \frac{e^{V_i-D}}{\sum_i^C{e^{V_i-D}}} \nonumber\end{align}$$由于log函数不会改变函数单调性，所以通常对softMax函数取一个 $-\log$，表示损失函数。 边框回归loss：边框回归使用$L_1$ loss，第二个loss $L_{loc}$是定义真值和预测值上，第一个是针对类u的真实标注约束框回归目标 $v=(v_x, v_y, v_w, v_h)$，第二个也是针对类u的预测值$t^u = (t^u_x, t^u_y, t^u_w, t^u_h)$。对于约束框回归，边框回归的loss为：$$L_{loc}(t^{u},v) = \sum_{ i \in {x,y,w,h}} smooth_{L_{1}}(t_i^u - u_i)$$其中： 联合loss：$$L(p,u,t^u,v) = L_{cls}(p,u)+\lambda[u\geq 1] L_{loc}(t^{u},v)$$ 其中中括号项代表这样一个函数：当u ≥ 1时，返回1，否则返回0。根据约定代表全部剩余一切的背景类标注成u=0。所以对于背景RoI而言，没有真是标注框信息，因而$L_{loc}$就忽略了。 Mini-Batch 采样微调阶段，每次SGD迭代所用的mini-batch从N=2个images中获取， 这N个images随机选择，mini-batch的大小为128，每个image中采样64个ROIs。其中25%的样本为正样本，也就是IOU大于0.5的，其他样本为负样本，同样使用了困难负样本挖掘的方法（hard negative mining），也就是负样本的IOU区间为[0.1，0.5），负样本的u=0，$[u\geq 1]$函数为艾弗森指示函数。 RoI 反向传播不同于SPPNet，ROI Pooling可以反向传播，以Max Pooling为例，根据链式法则，对于最大位置的神经元偏导数为1，对于其他神经元偏导数为0。ROI Pooling 不用于常规Pooling，因为很多的region proposal的感受野可能是相同的或者是重叠的，因此在一个Batch_Size内，我们需要对于这些重叠的神经元偏导数进行求和，因此反向传播公式如下：$$\frac{\partial L }{ \partial x_{i}} = \sum_r \sum_{j} [i = i^*(r,j)]\frac{\partial L }{\partial y_{rj}}$$ $i^*(r, j) = argmax (i)∈R(r,j)$，也就是在R(r, j)这个区域中做max pooling得到的结果 $[i = i * (r, j)]$ 是一个条件表达式，就是判断input的xi是否是max pooling的结果，如果不是，输出的梯度就不传到这个值上面,不提供loss r是RoI数量，j是在一个region中，与x对应的输出个数 $y_{rj}$是第j个跟x对应的输出 如下，RoI层反向传播例子：fast rcnn的网络结构如下：]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SPP-Net详解]]></title>
    <url>%2F2019%2F02%2F13%2FSPP-Net%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[SPP-Net详解在fast RCNN 之前，RCNN的进化中SPP Net的思想对其贡献很大，下面先介绍一下SPP Net。 SPP-Net Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognitionsubmit time: 2015arxiv link 空间金字塔池化spatial pyramid pooling，是一种词袋(Bag-of-Words, BoW)模型的扩展。池袋模型是计算机视觉领域最成功的方法之一。它将图像切分成粗糙到精细各种级别，然后整合其中的局部特征。SPP-net允许任意尺寸的输入，也允许图像可以有各种尺寸和缩放尺度。SPP使用了多级别的空间箱(bin)，而滑窗池化则只用了一个窗口尺寸。多级池化对于物体的变形十分鲁棒。RCNN的不足之处 1）输入图像需要crop成固定尺寸将导致失真：rcnn里将所有的region warp成固定尺寸，导致图片会出现不同程度的缺失和失真扭曲2）时间和空间成本高：对每个region proposals都需要过一遍AlexNet，且需要落盘到本地磁盘，存储量大3）检测速度慢：对每个regions proposals均需要分别提取特征，用VGG16一幅图片需要47s SPP-Net关键步骤： 通过select search算法提取出2k个proposal region 将整张图片输入CNN中提取特征，得到整张图片的feature maps 将选择性搜索得到的2k个proposal区域映射到feature maps上(RCNN需要对每一个proposal提取一次特征，SPP-net只需要提取一次) 对feature map上的候选框采用金字塔空间池化，提取出固定长度的特征向量，输入FC层(SPP-net不需要对图片进行crop等操作) 将proposals区域的特征向量输入SVM分类器中进行类别分类。 SPP-Net 解决了下面几个问题： 如何解决输入图片尺寸必须固定的要求？金字塔池化 如上图由features map上确定的region proposal大小不固定，将提取的region proposal分别经过三个卷积4*4，2*2，1*1，都将得到一个长度为21的向量(21是数据集类别数，可以通过调整卷积核大小来调整)，因此不需要对region proposal 进行尺寸调整。 如何解决只进行一次特征提取的要求? SPP-Net在原图上选择region proposals区域，随后对图片提取特征，得到整张图片的features map，然后通过映射将region proposals区域映射到features map上，得到region proposal区域的特征。因此仅仅需要对原图提取一次特征即可。 如何将region proposal映射到特征空间?SPP-Net在提取完整图像的feature map后，要将候选框的位置映射到feature map中得到对应特征。映射原则如下：假设(x,y)是原始图像上的坐标点，(x′,y′)是特征图上的坐标，S是CNN中所有的步长的乘积，那么左上角的点转换公式如下：$$x′=\frac{x}{S}+1$$右下角的点转换公式为：$$x′=\frac{x}{S}−1$$计算S有下面例子：论文中使用的ZF-5: S = 2*2*2*2 = 16Overleaf-5/7：S = 2*3*2 = 12 SPP-Net训练策略：理论上，无论输入什么尺寸的图像，都可以输入SPP-net中进行训练。但是实际上由于GPU实现中，更适合在固定尺寸的输入图像上，因此提出了一些训练策略。 Single-size training:使用固定的224x224的输入，是从原始图像中裁切得到的，目的是为了数据扩增；对于给定的输入尺寸，可以预先计算出空间金字塔池化需要的bin size，假如feature map是axa的大小，那么在SPP layer中，窗口尺寸$win=\frac{a}{n}$上取整，步长$stride=\frac{a}{n}$下取整。 Multi-size training：考虑两种输入，180x180和224x224，这里不再用裁切，而是直接进行缩放，比如把224x224的图像直接缩放为180x180，它们之间的区别只是分辨率不同。实现两个固定输入尺寸的网络，训练过程中先在1号网络上训练一个epoch，然后用它的权重去初始化2号网络，训练下一个epoch；如此转换训练。通过共享两种尺寸输入的网络参数，实现了不同输入尺寸的SPP-Net的训练。 原始图片中的ROI如何映射到到feature map感受野：卷积神经网络CNN中，某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。感受野的大小是由kernel size，stride，padding , outputsize 一起决定的。经过一层卷积后输出的features map大小计算： $$W_2 = （W_1- K + 2P）/S + 1$$（其中 $W_1$是输入卷积层的特征的尺寸，K是卷积核大小，P是填充padding，S是步长stride）上一层features map大小计算： $$W_1 = (W_2 - 1)*S -2P+K$$ 感受野的计算：感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。当已知上一层的感受野计算下一层的感受野时有：$$r = (m-1) stride+ksize$$其中m为上一层的感受野。空洞卷积的感受野计算：dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。感受野坐标映射： $$p_i = s_i \cdot p_{i+1} +( (k_i -1)/2 - padding)$$ SPP-Net中的坐标映射： SPP-Net 是把原始ROI的左上角和右下角 映射到 feature map上的两个对应点。 有了feature map上的两队角点就确定了 对应的 feature map 区域(下图中橙色)。变换公式见上。 总结 SPPNet在R-CNN的基础上提出了改进，通过候选区域和feature map的映射，配合SPP层的使用，从而达到了CNN层的共享计算，减少了运算时间，允许输入图片的大小不固定。Fast R-CNN受SPPNet的启发，进一步改进完网络。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RCNN详解]]></title>
    <url>%2F2019%2F02%2F11%2FRCNN%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[目标检测目标检测任务主要有两个不同的思路。一种思路是借鉴语义分割的做法，这方面的工作有YOLO和SSD另一种思路是把目标检测看作分类任务（bounding box中对象的类别）和回归任务（回归bounding box）的组合。主要的工作有R-CNN，SPP-Net，Fast R-CNN，Faster R-CNN。方法一速度快但精度稍差，方法二速度慢但精度高，是主流方法。 RCNNRCNN: Region-based Convolutional NetworkSubmitted on 2014 RCNN目标识别的主要任务为检测物体类别以及边框的大小以及位置。主要贡献： 根据Selective search 算法提取Region proposal。 将每个Region Proposal 缩放到统一大小后输入CNN，输出固定大小的特征。 将特征用SVM进行分类。 训练一个回归器，对边框（bounding box）进行微调。 边框的选择：原始产生边框的方法为通过滑窗的方式产生region proposal，作者做过实验，原话如下： 我们也考虑了采用滑动窗口方法。然而，在我们的网络中，具有五个卷积层的单元在输入图像中具有非常大的接收场（195×195像素）和步进（32×32像素），这使得在滑动窗口内的精确定位成为开放的技术挑战。 selective search 算法 使用一种过分割手段，将图像分割成小区域 (2k~3k 个) 查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置 输出所有曾经存在过的区域，所谓候选区域 selective search 合并规则：颜色相近(颜色直方图)；纹理相近(梯度直方图)；合并后总面积小的；合并后总面积在其BBOX中所占比例大的(保证合并后形状规则) 多样化与后处理为尽可能不遗漏候选区域，上述操作在多个颜色空间中同时进行（RGB,HSV,Lab等）。在一个颜色空间中，使用上述四条规则的不同组合进行合并。所有颜色空间与所有规则的全部结果，在去除重复后，都作为候选区域输出。 RCNN卷积：将生成的region proposal 减去像素平均值后，使用各向异性的缩放方式（直接缩放），将图片缩放到227*227大小，随后对每个proposal 提取特征，对每个proposal经过五层卷积层以及两层全连接层，在cf7层得到提取出的4096维特征。提取特征使用了pre-training的AlexNet网络，作者原文如下： 检测面临的第二个挑战是带标记的数据很少，目前可用的数量不足以训练大型CNN … 本文的第二个主要贡献是识别网络在大型辅助数据集(ILSVRC)上进行监督预训练，然后对小数据集(PASCAL)进行指定域的微调，这是在数据稀缺时训练高容量CNN模型的有效方法。 即提取特征需要训练一个大型的CNN识别网络，作者使用了hinton在2012年image net上做识别的AlexNet，此网络提取的特征为4096维，之后送入一个4096-&gt;1000的全连接(fc)层进行1000个类别的分类，学习率0.01。针对特定的小数据集对该识别网络进行微调。同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。 学习率0.001，网络各层参数不变。每一个batch包含32个正样本（属于20类）和96个背景（背景多于正样本是因为实际图片中背景部分就是比样本要多）。网络结构如下： 目标类别与分类器作者在cf7层提取出特征后，未直接通过最后一层softMax层进行分类，而是将cf7层提取出的特征用于训练SVM分类器。原因在于： svm训练和cnn训练过程的正负样本定义方式不同，softmax得到的结果比svm精度低。 cnn在训练的时候，对训练数据做了比较宽松的标注（例如bounding box只包含物体的一部分，我们也把它标注为正样本），采用这个方法的主要原因在于CNN容易过拟合，要扩大正样本的样本量，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松(IOU只要大于0.5的region proposal都被标注为正样本) svm分类器原理是最小距离最大化，样本的定义越严格分类效果越好，所以对于训练样本数据的IOU要求比较严格（大于0.7为正样本） SVM训练对每一个类别训练一个二分类器，我们用IoU重叠阈值来解决正负样本的问题，在0.3阈值以下的区域被定义为负样本，0.3-0.7阈值的样本被忽略，0.7-1.0的样本被定义为正样本。（重叠阈值0.3是通过在验证集上尝试了0,0.1,…,0.5的不同阈值选择出来的。选择这个阈值是很重要，将很大程度上影响最后的结果。）正样本被简单地定义为每个类的检测框真值。我们提取了特征并应用了训练标签，就可以对每一个类别训练一个线性SVM，当我们用CNN提取2000个候选框，可以得到2000 * 4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096 * N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，就可以得到结果。 边框回归学习一个线性回归器，用于bounding box的边框回归，输入为Alexnet pool5的输出。bbox回归认为候选区域和ground-truth之间是线性关系(因为在最后从SVM内确定出来的区域比较接近ground-truth,这里近似认为可以线性关系)。训练回归器的输入为N对值，${(P^i, G^i)}_{i=1,2,…,N}$，分别为候选区域的框坐标和真实的框坐标。这里选用的Proposal必须和Ground Truth的IoU大于0.6才算是正样本(避免一些远离groundtruth的边框参与计算)，通过学习四个变换函数，得到变换后的边框坐标。对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。所谓脊回归，就是对于一个线性模型，在原来的损失函数加入参数的l2范数的惩罚项。当使用最小二乘法计算线性回归模型参数的时候，如果数据集合矩阵（也叫做设计矩阵(design matrix)）XX，存在多重共线性，那么最小二乘法对输入变量中的噪声非常的敏感，其解会极为不稳定。为了解决这个问题，就有了这一节脊回归（Ridge Regression ）。脊回归当矩阵存在多重共线性的时候（数学上称为病态矩阵），最小二乘法求得的参数W在数值上会非常的大，输入变量X有一个微小的变动，其反应在输出结果上也会变得非常大，因而结果对输入变量噪声非常敏感。 如果能限制参数W的增长，使W不会变得特别大，那么模型对输入W中噪声的敏感度就会降低。这就是脊回归和套索回归（Ridge Regression and Lasso Regrission）的基本思想。为了限制模型参数W的数值大小，就在模型原来的目标函数上加上一个惩罚项，这个过程叫做正则化（Regularization）。 如果惩罚项是参数的$l_2$范数，就是脊回归(Ridge Regression) 如果惩罚项是参数的$l_1$范数，就是套索回归（Lasso Regrission） 正则化同时也是防止过拟合有效的手段 非极大值抑制（NMS）：RCNN 网络会对一个目标标定了多个标定框，使用极大值抑制算法滤掉多余的标定框。NMS算法搜索局部的极大值，并且抑制那些分数低的窗口。首先对RCNN产生的边框分类概率从大到小排序，将最大概率边框设置为保留边框，并选择与该边框重合IoU大于某一个阈值的所有边框，将他们过滤，接下来从剩下的边框中重复上述步骤，直到所有边框都被处理过。 RCNN网络结构图：]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAC 私人订制]]></title>
    <url>%2F2019%2F02%2F07%2FMAC-%E7%A7%81%E4%BA%BA%E8%AE%A2%E5%88%B6%2F</url>
    <content type="text"><![CDATA[配置gitMac上安装Xcode命令行工具，命令行工具包是一个小型独立包,可供下载独立于Xcode的和允许您执行命令行开发OS X:1xcode-select --install 设置用户名，邮箱：12git config --global user.name &quot;wenhui-zhou&quot;git config --global user.email &quot;765647930@qq.com&quot; 创建ssh-key：1ssh-keygen 在当前目录下找到/.ssh/id_rsa.pub，将其中的内容配置到GitHub账号中的ssh中完成配置。验证：1ssh -T git@github.com 若输出一下内容则说明配置成功。 Hi WenHui-Zhou! You’ve successfully authenticated, but GitHub does not provide shell access. 网络端口80端口：http端口，用于网页访问443端口：https访问端口，用于https的网页访问http与https是两种不同的协议，https协议安全xing Mac 系统环境配置Mac系统的环境变量，加载顺序为： /etc/profile /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc /etc/profile和/etc/paths是系统级别的，系统启动就会加载，后面几个是当前用户级的环境变量。后面3个按照从前往后的顺序读取，如果~/.bash_profile文件存在，则后面的几个文件就会被忽略不读了，如果~/.bash_profile文件不存在，才会以此类推读取后面的文件。~/.bashrc没有上述规则，它是bash shell打开的时候载入的。 windows上hexo博客迁移到Mac上的方法 安装node.js 安装git 安装hexo（使用npm安装） 新建博客文件夹，依次hexo init,sudo npm install 将原来文件夹中的文件替换Mac文件夹中的文件 博客恢复使用 安装anaconda后设置iterm的默认python版本打开iterm环境配置文件：vim ~/.zshrc在文件末尾添加指令：123456789101112131415161718192021#### Mac选择大段文字的方法由于使用触控板，抛弃了鼠标，但是选择大段文字则成了一个问题，还好有解决方案：选择段落：鼠标在段落内点击三下即选中选择大段篇幅：按住shift，鼠标在起始位置点击一下，在末尾点击一下即选中。#### 电池使用次数mac居然有点电池的充放电次数一说，以后使用电脑尽量插着插头。人事有代谢给我一个启发就是，万事万物都有尽头的一天，比如一个茶杯，身体，细胞等等，每天都在消耗，只是没人给你列一个上限而已。#### MAC 开启本地服务器MAC 开启本地的服务器，可以通过http的方式传递文件，具体做法如下：1. 打开终端，移动到需要分享文件的文件夹下；2. 在终端中输入：`python -m http.server 80`，开启web服务；3. 查询本机ip（百度输入本机IP即可），随后访问 `http://ip` 即可。4. 该方法下载文件夹：```shellwget -r -np -nH -R index.html http://include/file -r : 遍历所有子目录 -np : 不到上一层子目录去 -nH : 不要将文件保存到主机名文件夹 -R index.html : 不下载 index.html 文件]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>tip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-递归]]></title>
    <url>%2F2019%2F01%2F30%2F%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[递归递归(recursion)，是指函数的定义中使用函数自身的方法。用于表示用相似的方法重复事物的过程。 问题描述：从 1~n 这 n 个整数中随机选取任意多个，输出所有可能的选择方案。 输出格式：输入一个整数n。 输出格式：输出所有的方案。 数据范围：1 $\leq n \leq15$ 输入样例：13 输出样例：12345678322 311 31 21 2 3 方案一：主循环确定方案的长度，循环里头进一个dfs()，来控制填入的数。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;int a[20];//记录序列int vis[20]; //记录是否访问过void dfs(int pos,int tar,int start)&#123; if(pos == tar+1)&#123; for(int i = 1;i&lt;=tar;i++)&#123; cout&lt;&lt;a[i]&lt;&lt;" "; &#125; cout&lt;&lt;endl; return; &#125; for(int i = start;i&lt;=n;i++)&#123; if(!vis[i])&#123; vis[i] = true; a[pos] = i; dfs(pos+1,tar,i+1); vis[i] = false; &#125; &#125;&#125;int main()&#123; cout &lt;&lt; endl; cin &gt;&gt; n; for(int i = 1;i&lt;= n;i++)&#123; dfs(1,i,1); &#125;&#125; 二进制优化：用二进制表示选了哪些书，用来代替之前使用的a[20]数组。| 或操作将i位置置为1（选中）： state |= 1&lt;&lt;(i-1)^ 异或操作将i位置还原为0（未选）： state ^= 1&lt;&lt;(i-1) 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;bool vis[20];void dfs(int pos,int tar,int start,int state)&#123; if(pos == tar+1)&#123; for(i = 1;i&lt;=n;i++)&#123; if((state&gt;&gt;i)&amp;1) cout &lt;&lt; i&lt;&lt;&quot; &quot;; &#125; cout &lt;&lt;endl; return; &#125; for(int i = start;i&lt;=n;i++)&#123; if(!vis[i])&#123; vis[i] = true; state |= 1&lt;&lt;(i-1); dfs(pos+1,tar,i+1,state); state ^= 1&lt;&lt;(i-1); vis[i] = false; &#125; &#125;&#125;int main()&#123; cout&lt;&lt;endl; cin &gt;&gt; n; for(int i =1;i&lt;= n;i++)&#123; dfs(1,i,start = 1, 0); &#125; return 0;&#125; 状态压缩递归：用一个$2^n$的数的各个位上取0或取1来表示选中或未选中。 000 ： \n001 ： 1010 ： 2011 ： 3…… 123456789101112131415#include &lt;iostream&gt;using namespace std;int main()&#123; int n; cout &lt;&lt;endl; cin&gt;&gt; n; for(int state = 1;state&lt; 1&lt;&lt;n;state++)&#123; for(int j = 0;j&lt;n;j++)&#123; if(state&gt;&gt;j&amp;1) cout&lt;&lt;j+1&lt;&lt;&quot; &quot;; &#125; cout &lt;&lt;endl; &#125; return 0;&#125; 状态压缩的递归：1234567891011121314151617181920212223#include &lt;iostream&gt;using namespace std;int n;//u表示当前枚举到的数，state表示二进制的表示，记录哪些数字被选过void dfs(int u,int state)&#123; if(u == n)&#123; for(int i = 0;i&lt;=n;i++)&#123; if(state &gt;&gt; i &amp;1)&#123; cout&lt;&lt;i+1&lt;&lt;&quot; &quot;; &#125; &#125; cout&lt;&lt;endl; return; &#125; dfs(u+1,state); // 不用u这个数 dfs(u+1,state|(1&lt;&lt;u)); //用u这个数&#125;int main()&#123; cin &gt;&gt;n; dfs(0,0); return 0;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循环神经网络RNN,LSTM]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-LSTM%2F</url>
    <content type="text"><![CDATA[RNNRNN适用背景当一段序列是连续的，且序列长度不一（音频序列），难以直接差分成一个个独立的样本来训练DNN/CNN，传统的神经网络无法用前面的场景来影响后面的预测。此时，可以使用RNN来解决这个问题。 循环神经网络内部具有循环边，允许信息持续存在。前一个节点传递消息给他的后继者。结构如下图：正是借助于这个链式的信息传导结构，RNN在处理序列相关的数据时，具有先天的优势。 RNN的缺点在需要利用的历史信息离当前节点较近时，RNN能够利用该信息去进一步学习。但是当需要的背景信息离当前的节点距离较远时，RNN无法学到这些信息，即RNN无法处理这种需要长连接的信息。 LSTM NetWork长短式记忆模型是一种特殊的RNN模型，能够解决长依赖无法学习的问题。所有循环神经网络均具有相同的模块链，在标准的RNN中，该重复的模块链是一个简单的tanh层。LSTM中的重复模块则由四个部分组成。 LSTM背后的思想LSTM关键是细胞的状态，表示细胞状态的这条水平线从图中顶部穿过。细胞在链上运行，其下有一些小的线性操作作用在它的上面。LSTM模型中具有很多门（gate）结构。他有一个sigmoid神经节点和一个点乘运算组成。sigmoid输出0到1之间的数字，表明这个组件可以有多少信息可以通过。LSTM中有三个门，用于控制细胞的状态。 一步步拆解LSTMLSTM第一步为决定从输入中丢弃什么信息，这一步称为遗忘门，遗忘门的输入为$h_{t-1}$（前一个细胞的输出）与$X_t$（当前细胞输入），通过一个sigmoid，输出0-1之间的数，添加到上一个细胞的状态$C_{t-1}$中。下一步决定细胞需要的存储信息。该部分由两步构成。sigmoid层决定了哪些值需要更新，接下来一个tanh层创建候选向量$C_t$，该向量将会被加入到细胞状态中。更新上一个状态值$C_{t-1}$，生成$C_{t}$最后决定我们要输出什么，此输出将局域我们的细胞状态，首先先运行一个sigmoid层，他决定我们要输出的细胞状态的哪些部分。随后将单元格通过tanh（将值规范化到-1到1之间），并乘以sigmoid 输出，得到最后的$h_t$部分。 总结 为什么具有记忆功能：由于存在递归结构，上一时刻的隐层的状态参与到了这个时刻的计算过程中，即每一步的选择和决策参考了上一次的状态。 为什么LSTM的记忆时间长（解决长连接问题）：由于传统的RNN在训练过程中引入一个激活函数，经过多步推导之后，这个乘子连乘，当参数发生轻微变化时，梯度将发生距离的波动，甚至将导致梯度消失问题。为了解决这个问题，特意设计了一个CEC常数误差流，即激活函数是线性的，将上一个节点的output由连乘改为连加。$|f_{ij}(x) W_{ij}| = 1,W_{ij}$是上一个状态与下一个状态的权值连接。误差没有衰减，使得序列很长之前带来的影响仍然能够保持到最后。LSTM在原来RNN的基础上是一个叫做CEC的部件，这个部件保证了误差将以常数的形式流动。同时添加输入门和输出门，使得模型变成非线性的。]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目总结]]></title>
    <url>%2F2019%2F01%2F25%2F%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[sketch2Cloth虚拟试衣总结虚拟试衣允许用户定制衣服的纹理，颜色。能够改善生成图像的真实感。虚拟试衣项目分成训练数据的处理以及GAN图片生成。 Human-parsing：输入一张人像图片，使用DeepLab+SSL框架对人体图像不同部位进行解析标记。从而根据不同分类的标记信息可以将图片分割成人体皮肤部分，服饰部分，首饰部分等等。根据不同的标注信息，仅保留含有人体皮肤，脑袋的图片；以及保留仅含有服饰的图片。随后对含有服饰的图片提取边缘信息，得到服饰的边缘纹理。最终将人体皮肤信息与服饰边缘信息相结合，得到最终的图片和标记，完成数据的预处理。这样处理的好处是，保留了绝大部分人体皮肤，头发等信息，利用GAN进行服饰样式生成时，仅需要生成服饰的颜色，纹理信息，尽可能保证图片的真实感。 DeepLab v2 将多孔卷积应用到密集预测任务上，有效扩大感受野。 采用多看空金字塔模型，使用不同采样率多尺度获取图像上下文信息。 将DCNN与完全连接条件场（CRFS）结合，增强物体边界定位。 SSL：引入自监督结构敏感学习方法进行训练，将人体姿态引入解析结果中，提升实验性能。 边缘检测 canny 算子：通过计算像素梯度幅值，方向，确定图片的边缘信息。使用费最大值抑制使得边缘更加清晰。比较看重像素的梯度变化，不看重整体的空间信息。 edge detection using structure forest：使用随机森林算法学习一个隐状态，将图形映射成边缘。 HED：整体嵌套边缘检测，将多次度的Edge进行融合，得到整体信息对边缘信息的反映。HED有vgg改造而来，可提取图片特征信息，多次度同和，反映了空间特征。 pix2pix在CGAN的基础上加上L1约束，作为图片的生成器。 GAN 生成对抗网络，同时训练一个生成器和判别器。优化生成器使其生成的东西更接近原始样本，优化判别器，使其能够更好地判断样本的真假。JS散度：度量两个概率分布的相似度，但是当两个分布距离很远时，将会导致梯度消失。因此引入wasserstein（earth-mover距离）：能够在联合分布的下，样本间的距离，当两个分布距离很远时，也可以提供梯度。 CGAN条件生成网络，GAN生成数据太过于自由，数据不可控。因此条件生成对抗网络，在生成器与判别器作用是加入一个条件概率，使得结果更符合实际条件。 pix2pix：在CGAN的基础上加入L1约束（模糊图片），使得生成图像更接近真实图。自动学习损失函数。使用U-net,使得上层图像获取更多的底层图像信息。 海量地震数据三维可视化 地震数据segy文件解析：segy文件为GB级别的数据，对多种格式的解析，里头包含了五种不同的数据存储格式，需要对地震数据进行解析以及筛选合适的数据这些操作。 地震数据预处理：使用SVD分解技术，留下数据中分量比较中的那部分数据 数据分块读取：按切片载入内存，设计颜色传递函数，使用shader将绘制部分迁移到GPU上执行。使用shader进行绘制。Shader上分为上色，]]></content>
      <categories>
        <category>项目总结</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AutoMatic Image Colorization 整理]]></title>
    <url>%2F2019%2F01%2F23%2FAutoMatic-Image-Colorization-%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[《Let there be Color: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simutaneous Classification》 是由三位知名的日本学者，发表在2016年的SIGGRAPH上，该模型实现的图片颜色恢复效果十分的好。原文地址：Let there be Color:项目地址：Automatic Image Colorization 摘要本文利用CNN提取图片全局先验信息(global priors)和局部图片特征信息(local image features)，并对特征进行融合，端对端(end to end)的对灰度图片进行自动上色。 图片语义信息：&emsp;视觉层： 即底层颜色，纹理，形状等等。&emsp;对象层： 属性特征，如某一对象某一时刻的状态&emsp;概念层： 最接近人类理解，如室内，室外，沙子，海水等 全局特征将反映：概念层信息，如室内室外，白天黑夜等等局部特征信息反映：局部材质，物体的位置信息等 色彩空间作者采用Lab颜色空间，L表示亮度，a，b表示颜色光谱绿-红和蓝-黄。Lab编码中有一个灰度层，颜色层变为两个，因此只需要预测两个通道。由图可以看出人们对亮度信息比较敏感。人眼中有94%的细胞由于探测亮度，6%的细胞用于探测颜色。因此我们将图片保存成灰度图即保留了图片大部分的信息，又节省空间。 网络结构网络结构大体由两部分组成。第一部分： low-level features 低特征提取，mid-level features 中特征提取，fusion layer 融合层，colorization network上色层组成。第二部分： low-level features 低特征提取，全局特征提取两部分组成。网络的输入为灰度图，第一部分输入是原图，由于第一部分只有卷积操作，因此对图片尺寸没有要求。第二部分输入是经过resize成224224大小的图片。包含全链接层，对输入大小有限制。*预测流程：将图片输入，经过低特征，中特征和全局特征的提取，一起来预测两个色彩图层即a和b，然后通过上采样，恢复到原图大小，与灰度图层L融合一起组成lab图片。 第一部分第一部分包含上色层，可以对图片进行上色，但是由于未加入全局的语义信息，所以效果不好。可以这样认为，根据全局特征得到的图片语义信息（室内或室外），利用全局语义信息进一步决定对图片的上色方案。 第二部分网络第二部分是一个标准的卷积神经网络，全局特征提取层输出是一个1*1*256的一个张量，通过融合层将语义信息加入第一部分网络中。整个网络的损失函数为：$$L(y^{color},y^{class}) = ||y^{color} - y^{color,*}||^2_{FRO} - \alpha (y_{l^{class}}^{color} - \log(\sum^{N}_{i = 0} exp(y_i^{class})))$$ 前半部分是一个预测颜色和真实颜色间的一个MSE Loss，后半部分是预测一个分类交叉熵loss。由于分类loss不影响上色，将$\alpha$设置为0，仅适用上色部分的loss。 融合层$$y_{u,v}^{fusion} = \sigma (b + W [y^{global},y^{mid}_{u,v}]^T)$$ 其中$y^{global}$是一个1*1*256的张量，b是一个$\frac{H}{8}*\frac{H}{8}*256$的一个长方体，将y与b头尾拼在一起，构成一个$\frac{H}{8}* \frac{H}{8}*512$的张量。 风格迁移将第二部分的输入换成一张其他风格的图片，图片类型要求相同，最终形成的图片的风格将发生改变。 网络特点 网络输入为多分辨率图片 网络中无池化层 上采样过程采用最近邻算法 所有的上色模型无法解决毛衣的上色问题，因为毛衣颜色不存在先验，是不确定的。如天空，海洋的颜色则是确定的。 PREFERENCE preference1]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型性能评估指标概要]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E6%A6%82%E8%A6%81%2F</url>
    <content type="text"><![CDATA[模型性能评价指标能够对模型预测结果性能好坏进行评价。以下列举了常用的模型评价指标。 AUC评价指标AUC（area under thr curve）指标常用来评估二分类模型的性能，指的是ROC曲线与x轴围成的面积。AUC不依赖于判决阀值。判别矩阵如下: 类型 正样本 负样本 预测为正 TP(真正例) FP(假正例) 预测为负 FN(假负例) TN(真负例) 随着阈值t的取值不同，有：真正率（正例预测为真/所有正样本）：$$TPR = \frac{TP}{TP+FN}$$假正率（负例预测为假/所有负样本）：$$FPR = \frac{FP}{FP+TN}$$因此TPR与FPR是关于t的一个函数： AUC即为如下曲线下的面积：$$AUC = \int_{t = 0}^{1} y(t) dx(t)$$AUC实际表现为把正样本排在负样本前面的概率。同时AUC对政府样本的比例不敏感。AUC越大表明模型区分正例和负例的能力越强，AUC常常依赖于具体的任务。 精确率：$$Pricision = \frac{TP}{TP+FP}$$精确度pricision指的是我判断为真的里头，确实为真的概率。 召回率：$$Recall = \frac{TP}{TP+FN}$$召回率recall指的是我判断是真的里头，确实为真的占样本所有为真的概率。 F1 score:$$\frac{1}{F_{1}} = \frac{1}{Precision}+\frac{1}{Recall}$$F1是precision和recall的调和均值， F1 score作为正负样本不均衡的评价方式.参考链接 mAP:mAP指mean average precision，即各个类别AP的平均值。 AP：指precision与recall曲线的下面部分。 对于IoU = 0.5:0.05:0.95分别计算mAP，随后平均得到最后的mAP：指的是将IoU从0.5一直递增到0.95，然后每一个IoU均计算一个AP值，然后对所有的AP值取平均，得到最终的mAP。 BenchMark，SOTA 与Baseline一个算法的benchmark指的是，它的性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏。state-of-the-art（SOTA）：能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。 baseline：表示比这个算法性能还差的基本上不能接受的，除非方法上有革命性的创新点，而且还有巨大的改进空间和超越benchmark的潜力，只是因为是发展初期而性能有限。所以baseline有一个自带的含义就是“性能起点”。 总结一下就是：benchmark是属于较好的水准，baseline则代表了及格线。]]></content>
      <categories>
        <category>模型评价</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[human head detect summary]]></title>
    <url>%2F2019%2F01%2F23%2Fhuman%20head%20detect%20summary%2F</url>
    <content type="text"><![CDATA[welcome to my blog,enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>比赛</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 刷题常用数据及函数的语法记录]]></title>
    <url>%2F2019%2F01%2F21%2FC-%E5%88%B7%E9%A2%98%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[字符串操作： int to string： &emsp;string a = to_string(int) string to int：&emsp; int a = stoi(string) char to int： &emsp; int a = char_b - 48 字符串中查找字符： 123456string a = "abcd";string b = "ab";int start = 0;int pos = a.find(b,start); // start可省略，默认从0开始//如果查找不存在返回string::nposif(a.find(b) == string::npos) cout&lt;&lt;"dont exist"; 截取子串： &emsp; string a = astring.substr(startpos,length) vector操作： vector 删除： vector_a.erase(iter_pos),vector_a.erase(iter_begin(),iter_end()) vector排序：匿名函数的形式 nums.sort(nums.begin(),nums.end(),[](int a,int b){return a&gt;b;}) unordered_map操作: unordered_map实现使用了哈希表，可以在$O(1)$时间复杂度访问到对应元素，缺点为要花费较高的空间复杂度。 map实现使用的对应结构为红黑树（类似平衡树），查找元素使用的复杂度为$O(\log n)$。 unordered_map声明： &emsp;unordered_map&lt;char,int&gt; map; unordered_map插入键值对： &emsp;map[&#39;a&#39;] = 1;,map.insert(make_pair(&#39;a&#39;,1)); unordered_map查找元素： &emsp; if(map.find(&#39;B&#39;) == map.end()){dont exist}， &emsp; if(map.count(&#39;B&#39;) == 0){dont exist} unordered_map移除元素： &emsp;map.erase(map.begin()), &emsp;map.erase(map.begin(),map.end()), &emsp;map.erase(&#39;A&#39;) 中值的取法： 防止整数溢出：int mid = left + (right-left)/2; 大数组开成全局变量： int weight[N][M]; 原因是计算机会将把虚拟内存空间分配给程序。虚拟内存空间分为栈空间和堆空间。所有开在函数内部的变量会开在栈里，所有开在静态变量，全局变量会开在堆里。C++默认栈空间大小为4M，所以一般将大数组开到全局变量中去。 异或的作用（^）： 用异或实现配偶：0^1=1，1^1=0 lowbit运算：给一个n快速找到二进制中最低的一个1，lowbit(100100) = 100 -&gt;树状数组的基本操作。 123int lowbit(int n)&#123; return (~n + 1) &amp; n; // return (-n)^n; 补码就是负数&#125; 位运算与底层的电路实现有关，无论什么操作都只用O(1)时间。 STL中的全排列操作：12while(next_permutation(A.begin(),A.end()))&#123; ... &#125; //从小到大产生排列组合，当排列组合全部产生结束时返回falseprev_permutation(A.begin(),A.end()); // 从大到小生成排列数，直接改变vector里头的值 sprintf() C 库函数 int sprintf(char str, const char format, …) 发送格式化输出到 str 所指向的字符串 12sprintf(str, &quot;Pi 的值 = %f&quot;, M_PI); // str = &quot;Pi 的值 = 3.141593&quot;sprintf(str,&quot;%02d:%02d&quot;,h,m); // %02d 指的是整数h的宽度为2，如果不够的话前面补0.(3-&gt;03) set用法： set是一个内部元素唯一的集合，定义：set&lt;vector&lt;int&gt;&gt; res;1234for(auto iter = res.begin();iter!=res.end();iter++) ...res.clear(); //删除所有的元素res.empty(); //判断是否为空集合res.rbegin() == res.end(); vector的用法： 初始化：vector&lt;int&gt; vec(size,0); 添加元素：vec.push_back(val);vec.insert(vec.begin(),val); 删除元素：vec.pop_back();vec.erase(vec.begin()) `vec.erase(vec.begin(), vec.begin()+3);` 查找：find(vec.begin(),vec.end(),val) != vec.end() 排序: 123456sort(vec.begin(),vec.end()); bool myfun(int a,int b)&#123;return a&lt;b; // 生序&#125;sort(vec.begin(),vec.end(),myfun); sort(vec.begin(),vec.end(),[](int a,int b)&#123;return a&lt;b;&#125;) lambda 表达式：1auto func = [c](int a,int b) &#123; return a &lt; b; &#125;; 其中c为表达式外边的变量，a,b为传入表达式的变量。 string 中find函数int pos = str.find(char,int begin = 0,int end = str.size()) //if(pos == string::npos) cant find it else return the index of char string 中的substrstring str = s.substr(begin,num)//表示从begin开始，共num个数 string str = s.substr(begin)//表示从begin开始到最后]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 建站]]></title>
    <url>%2F2019%2F01%2F19%2FGithub-%E5%BB%BA%E7%AB%99%2F</url>
    <content type="text"><![CDATA[github上搭建一个博客网站（windows） 1. 前期准备 node.js: 2009年由Ryan推出的，基于javascript（负责解释并执行代码）与google 浏览器V8引擎（c++编写的一个超快的解释器）的一个后端服务器应用程序。旨在增大服务器并发连接的数量（非阻塞，时间驱动I/O）。 git:开源分布式版本控制系统。见链接 hexo:一个快速简洁的博客框架。见链接，hexo支持makdown，是一个生成静态网页，并将网页上传到服务器上的工具。 2. Github上创建一个registry Github上新建项目，项目必须要遵守格式：账户名.github.io，同时勾选Initialize this repository with a README。（eg：WenHuiZhou.github.io） 3. 下载安装node.js，以及git4. 安装hexo 命令行内输入指令：npm install -g hexo-cli&emsp;&emsp;npm (node package manager)：运行在node.js上的一个使用javascript写的类库管理器，npm内置于node.js中，作为node.js的包管理器。可以使用npm来查找安装一些库(nmp install jquery.js)。&emsp;&emsp;有时使用npm进行下载文件时经常出现网络上的问题，此时可以对npm换源。npm config set registry https://registry.npm.taobao.org 创建文件夹，作为hexo博客文件存储文件夹，输入指令。 123hexo init&lt;blog&gt;cd &lt;blog&gt;npm install 完成创建后hexo将生成如下文件： 正常使用中修改最多的文件夹为_config.yml，其中包括博客的基础配置以及模板信息。source为写文章所需的目录，如果要针对下载的模板修改，那么需要修改themes模板目录。 启动hexo：hexo g：hexo生成网页（generate），hexo s：hexo启动服务器server。 5 . hexo 连接 github 打开git bash，进入blog文件夹 配置用户名，以及邮箱输入：git config --global user.name WenHuiZhougit config --global user.email myemail 每次使用git进行commit时都需要用到用户名和邮箱记录。用于指定push到的github。 6. SSH密钥登陆： 利用密钥生成器制作一对密钥——一只公钥和一只私钥。将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。 生成密钥对：ssh -keygen -t rsa -C &quot;myemail.com&quot;，将生成id_rsa 和 id_rsa.pub两个文件。 添加密钥对到ssh-agent：eval &quot;$(ssh-agent -s)&quot; 添加生成的SSH key到ssh-agent：ssh-add ~/.ssh/id_rsa 7 .设置github的ssh密匙 打开github setting，将添加ssh key，将id_rsa.pub内容复制进去即可。 在git bash上输入ssh -T git@github.com 此时返回 hi WenHuiZhou表明配置成功。 8 . 配置_config.yml文件 在_config.yml文件最后添加：deploy: type:git repository:git@github.com:WenHui-Zhou/WenHuiZhou.github.io.git branch: master repository地址可以从github上download那得到。 9. 在hexo上写博客 hexo new post &quot;blog name&quot;，hexo将会在source文件夹中生成.md文件，编辑.md文件写博客。 hexo s: 进入本地博客地址观察效果 hexo d -g: 将博客上传至github上 输入github上的访问地址：https://wenhui-zhou.github.io/即可博客网站。 10. 总结 使用hexo和github搭建了一个博客 使用hexo模板 maupassant对博客进行美化，见链接 该模板还需要做大量的个人定制工作，这是接下来要做的。 PREFERENCE reference1 reference2]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>netStation</tag>
      </tags>
  </entry>
</search>
