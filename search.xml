<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>常见的目标检测网络</title>
      <link href="/2020/05/27/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/05/27/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>总结常见的目标检测网络，持续更新，文章要写很长。</p><p>@<a href="常用的目标检测网络">TOC</a></p><a id="more"></a><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>目标检测任务可以理解为目标的识别和定位，识别指的是判断物体的类别，定位指的是确定物体的位置。</p><p>目前的目标检测模型分为两类，一类是two-stage，这一类的典型代表是RCNN，Fast-RCNN，Faster-RCNN家族。他们的特点是检测精度高，识别错误率低，但是速度较慢，不能满足实时场景的需求。另一类是one-stage，他们典型的网络有yolo，SSD，yolo2并且准确率能够和two-stage基本持平。</p><h3 id="RCNN-2014"><a href="#RCNN-2014" class="headerlink" title="RCNN(2014)"></a>RCNN(2014)</h3><p>RCNN详解：<a href="https://perper.site/2019/02/11/RCNN详解/" target="_blank" rel="noopener">https://perper.site/2019/02/11/RCNN%E8%AF%A6%E8%A7%A3/</a></p><p><strong>大致流程：</strong></p><ul><li>首先通过select search算法选择出图像中可能出现目标的box，最终得到2000个框<ul><li>将图像过分割出2k-3k个框</li><li>对框进行合并（颜色相近，梯度相近等）</li><li>输出曾经有出现过的框</li></ul></li><li>将输出的候选框依次输入到卷积网络中进行网络训练</li><li>将cf7层得到4096维特征输出到SVM中，训练N个SVM二分类器，对每个框进行二分类</li><li>边框回归：边框回归主要学习四个参数分别是x，y的偏移和w，h的缩放。通过优化二模和参数二次项，得到四个变换的参数，然后将参数乘以相应的边得到最终的边框位置（位移和缩放）</li></ul><p>RCNN的流程如下图：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200528011717296.png" alt="image-20200528011717296" style="zoom:50%;"></p><p>该网络的主要缺陷在于：</p><ul><li>候选框由select search算法产生，需要花费很长时间</li><li>对2k个候选框，均需要从头做卷积，存在很多的冗余计算</li><li>模型确定的情况只能接受固定大小的输入</li><li>网络训练过程分段，过程繁琐</li></ul><h3 id="Fast-RCNN-2015"><a href="#Fast-RCNN-2015" class="headerlink" title="Fast-RCNN(2015)"></a>Fast-RCNN(2015)</h3><p>Fast-RCNN详解：<a href="https://perper.site/2019/02/14/Fast-RCNN详解/" target="_blank" rel="noopener">https://perper.site/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/</a></p><p><strong>大致流程：</strong></p><ul><li>select search 算法提取2k个候选框</li><li>将图片整体输入卷积网络中，得到整个图片的feature map</li><li>通过RoI projection（通过感受野的映射公式）将2k个region proposal 映射到feature map</li><li>通过RoI pooling变成一样大，然后经过全连接层等接入softmax分类，已经bbox边框回归</li></ul><p><strong>RoI pooling</strong></p><p>RoI pooling将传入不同大小的region proposal划分层h x w个网格，对每个网格做max pooling，因此得到的输出大小是一致的。</p><p>RoI pooling反向传播过程中，原则是，max value那个位置梯度为1，其他位置为0。由于不同的region可能存在重叠的部分，因此重叠部分的梯度是每个region 梯度的求和。</p><p><strong>Loss</strong></p><p>分类部分，Fast RCNN使用的是softmax + 交叉熵：</p><p>softmax：<br>$$<br>P_{i}=\frac{e^{V_{i}}}{\sum_{i}^{C} e^{V_{i}}}<br>$$<br>交叉熵：<br>$$<br>L = -\sum(plog(p))<br>$$</p><p>边框回归使用smooth L1 loss代替原来的L2loss：<br>$$<br>\operatorname{smooth}_{L_{1}}(x)=\left{\begin{array}{lr}0.5 x^{2} &amp; \text { if }|x|&lt;1 \ |x|-0.5 &amp; \text { otherwise }\end{array}\right.<br>$$<br><strong>网络流程：</strong></p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200528111556483.png" alt="image-20200528111556483" style="zoom:50%;"></p><p><strong>缺点：</strong></p><ul><li>select search 算法提取候选框效率太低了（CPU上），每张图耗时3s</li></ul><h3 id="Faster-RCNN-2016"><a href="#Faster-RCNN-2016" class="headerlink" title="Faster RCNN(2016)"></a>Faster RCNN(2016)</h3><p>Faster RCNN详解：<a href="https://perper.site/2019/02/14/Faster-RCNN详解/" target="_blank" rel="noopener">https://perper.site/2019/02/14/Faster-RCNN%E8%AF%A6%E8%A7%A3/</a></p><p><strong>大致流程：</strong></p><ul><li>将图片输入到卷积网络中，生成feature map</li><li>将feature map输入RPN层（region proposal network）中，输出proposal region</li><li>提取出proposal region内的feature map 输入到RoI pooling层，输出固定维度的向量</li><li>对该向量进行softmax分类以及边框回归</li></ul><p><strong>RPN层</strong></p><p>RPN即region proposal network，输入feature map，输出为候选框的位置。RPN网络有两个分支。一个分支是softmax进行前后景的分类。另一支是边框回归（同RCNN），修正region proposal的位置。</p><p><strong>前后景分类</strong></p><p>在feature map的每一个像素点上，生成9个长宽比不同的anchor作为初始的anchor，然后第一个分支用softmax对每一个边框判断是前景还是背景。对于GT来说，前背景anchor标签分配的规则是：</p><ul><li>与某个GT的IoU最大的为前景</li><li>与任意GT IoU大于0.7为前景</li><li>与任意GT的IoU小于0.3为负类</li></ul><p>Faster RCNN在速度上提升很多，但是每秒仅能处理5张图片，因此one stage算法脱颖而出。</p><h3 id="Yolo-V1"><a href="#Yolo-V1" class="headerlink" title="Yolo V1"></a>Yolo V1</h3>]]></content>
      
      
      <categories>
          
          <category> 深度学习总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见数据结构</title>
      <link href="/2020/05/26/%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/2020/05/26/%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<ul><li>array</li><li>链表</li><li>hash map</li><li>set</li><li>红黑树</li></ul><h3 id="array"><a href="#array" class="headerlink" title="array"></a>array</h3><p>数组又叫顺序表，在内存中存储空间是连续的，允许用户对其进行插入，删除，访问和替换等等。Python中的列表是由对其它对象的引用组成的连续数组。</p><p>append复杂度为O(1)，insert复杂度为O(n)，sort复杂度：O(nlogn)。</p><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>链表数据存储空间未必是连续的，在插入或删除的时候，只需要改变指针的指向，其他都是不变的。链表的空间不需要提前分配，链表只能顺序访问，无法实现随机访问。</p><h3 id="hash-map"><a href="#hash-map" class="headerlink" title="hash map"></a>hash map</h3><p>哈希表的关键思路在于建立存储对象和地址之间的联系，这个联系即哈希函数。通过哈希函数算出对象的地址。dict类似对key进行了hash,然后再对hash生成一个红黑树进行查找，其查找复杂其实是O(logn)，O(1)是理想情况。</p><p>建立hash map的过程哈希值可能存在冲突，可用的解决方案是：链式地址法，开放定址法，线行探查法，平方探查法等。</p><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set本质上是一颗红黑树</p><h3 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h3><p>红黑树是一棵自平衡二叉查找树，<strong>二叉查找树</strong>满足左子树节点小于根节点，右子树节点大于根节点。</p><p><strong>红黑树的定义和性质：</strong></p><ul><li>红黑树每个节点要么是红色，要么是黑色</li><li>根节点是黑色</li><li>子节点是黑色</li><li>红色节点两个子节点都是黑色的</li><li>如果一个节点存在一个子黑节点，那么一定会有两个黑色子节点</li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>序列化RNN系列</title>
      <link href="/2020/05/21/%E5%BA%8F%E5%88%97%E5%8C%96RNN%E7%B3%BB%E5%88%97/"/>
      <url>/2020/05/21/%E5%BA%8F%E5%88%97%E5%8C%96RNN%E7%B3%BB%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h3 id="为什么需要RNN"><a href="#为什么需要RNN" class="headerlink" title="为什么需要RNN"></a>为什么需要RNN</h3><p>当我们遇到一些数据是序列的，长度不定的，数据的先后，顺序，是存在相互影响的语义的。对于这类问题，因此就出现了RNN这种结构，能够能够的提取序列数据的特征。</p><h3 id="RNN结构"><a href="#RNN结构" class="headerlink" title="RNN结构"></a>RNN结构</h3><p><img src="/images/nlp/image-20200521141220698.png" alt="image-20200521141220698" style="zoom:50%;"></p><p>最简单的RNN的结构如上所示，左边是一个RNN单元，右边是将这个单元展示后得到的网络。最早的激活函数使用tanh，该网络的特殊之处在于，下一个阶段网络的输入由上一阶段的输出以及x共同组成，用公式表示如下：<br>$$<br>\begin{array}{l}O_{t}=g\left(V \cdot S_{t}\right) \ S_{t}=f\left(U \cdot X_{t}+W \cdot S_{t-1}\right)\end{array}<br>$$</p><h3 id="RNN的优点"><a href="#RNN的优点" class="headerlink" title="RNN的优点"></a>RNN的优点</h3><ol><li>RNN可以记录时间序列上的信息，对于序列数据，前后语义有着相互联系的场景比较适用。</li><li>RNN可以处理文本，语音这些数据，数据的输出长度可以是不定的。</li></ol><h3 id="RNN的缺点"><a href="#RNN的缺点" class="headerlink" title="RNN的缺点"></a>RNN的缺点</h3><ol><li><p>梯度消失和梯度爆炸问题，当对RNN进行梯度求导的时候，得到的表达式是参数的一个连乘形式，任意时刻对$W_s$求偏导如下：<br>$$<br>\frac{\partial L_{t}}{\partial W_{x}}=\sum_{k=0}^{t} \frac{\partial L_{t}}{\partial O_{t}} \frac{\partial O_{t}}{\partial S_{t}}\left(\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}\right) \frac{\partial S_{k}}{\partial W_{x}}<br>$$<br>随着网络加深，连乘项越来越多，将S用tanh激活函数带入，下面表达式可变为：<br>$$<br>\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}= \prod_{j=k+1}^{t} \tanh ^{\prime} W_{s}<br>$$<br>即一个参数累乘的形式，当网络足够深的时候，如果参数小于一，则会出现梯度消失的问题，如果参数大于1，多次连乘的结果将导致梯度爆炸。</p></li><li><p>RNN网络难以训练，并且如果使用的是tanh或者relu激活函数，它无法处理非常长的序列。</p></li></ol><p>通过上面可以发现，只要解决了掉偏导公式中参数连乘的哪一项就可以解决梯度问题，LSTM就是按照这个思路，将这一项变成0或者1。</p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>LSTM即long short Term memory，LSTM的结构比普通的RNN要复杂一些，由三个门结构组成，分别是遗忘门，输入门，输出门：</p><p><img src="/images/nlp/image-20200521155345276.png" alt="image-20200521155345276" style="zoom:50%;"></p><p>首先是<strong>遗忘门</strong>，对输入的数据做一些选择性的遗忘，控制是否遗忘由sigmoid决定。其次是<strong>输入门</strong>，利用sigmoid对输入数据进行取舍，tanh对输入数据赋予权重。<strong>输出门</strong>：利用sigmoid对输入进行取舍，然后用tanh对数据进行加权，得到下一个输入。</p><p>（通过sigmoid后的特征，最后通过一个乘法加入到网络中）</p><h3 id="为什么LSTM能够解决梯度消失问题"><a href="#为什么LSTM能够解决梯度消失问题" class="headerlink" title="为什么LSTM能够解决梯度消失问题"></a>为什么LSTM能够解决梯度消失问题</h3><p>接在RNN的后面分析，LSTM梯度求导过程每一项中也存在一个累乘项，但是LSTM这个累乘项在LSTM中为0或者为1，因此有效避免了累乘导致的梯度消失问题。</p><p>传统RNN梯度计算如下：<br>$$<br>\frac{\partial L_{3}}{\partial W_{s}}=\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial S_{2}} \frac{\partial S_{2}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial S_{2}} \frac{\partial S_{2}}{\partial S_{1}} \frac{\partial S_{1}}{\partial W_{s}}<br>$$<br>LSTM中有表达式：<br>$$<br>\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}=\prod_{j=k+1}^{t} \tanh ^{\prime} \sigma\left(W_{f} X_{t}+b_{f}\right) \approx 0 | 1<br>$$<br>因此LSTM:<br>$$<br>\frac{\partial L_{3}}{\partial W_{s}}=\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{2}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{1}}{\partial W_{s}}<br>$$<br>梯度中不存在累乘项，因此可以克服梯度消失和梯度爆炸的问题。</p><h3 id="LSTM具有记忆功能"><a href="#LSTM具有记忆功能" class="headerlink" title="LSTM具有记忆功能"></a>LSTM具有记忆功能</h3><p>由于LSTM每次计算都有参考到上一时刻的LSTM状态，每一步决策均使用到了上一次的中间结果，因此具有记忆功能。</p><h3 id="LSTM具记忆时间长"><a href="#LSTM具记忆时间长" class="headerlink" title="LSTM具记忆时间长"></a>LSTM具记忆时间长</h3><p>由于LSTM将连乘项转化为1或者0，因此有效解决了梯度爆炸和梯度消失的问题，可以保存距离当前位置比较远的位置的信息，因此LSTM具有记忆时间长的功能。</p><h3 id="LSTM存在的问题"><a href="#LSTM存在的问题" class="headerlink" title="LSTM存在的问题"></a>LSTM存在的问题</h3><p>无法并行运算，LSTM计算效率太低。</p>]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2D animation,SVG文件</title>
      <link href="/2020/05/13/2D-animation-SVG%E6%96%87%E4%BB%B6/"/>
      <url>/2020/05/13/2D-animation-SVG%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要为了了解动画的原理，始末，已经一些常用的技术路线，为之后可能遇到的工作做准备。</p><a id="more"></a><h3 id="动画是什么"><a href="#动画是什么" class="headerlink" title="动画是什么"></a>动画是什么</h3><p>计算机动画即利用计算机绘制技术，绘制图画，为了制造连续的假象，将画面显示在计算机上，然后很块的用另一个相似但有一些移动的画面替代，制造平滑移动的假象。</p><p>由于人脑和眼存在<strong>视觉停留</strong>的现象，眼和脑会将看到的画面存储几分之一秒，然后将场景切换的跳跃平滑掉。因此制作动画的一个基本最低切换帧率为12帧，在这个帧率是人们比较能够接受的帧率。通常电影为24帧，当帧率提升到60帧以上时，为人眼处理图像的极限，画面真实感将不再提升。</p><h3 id="SVG"><a href="#SVG" class="headerlink" title="SVG"></a>SVG</h3><p>SVG是一种基于XML的标记语言，是由万维网联盟开发的开放标准，用于描述二维的矢量图形。是一个基于文本的开放web标准，可以与CSS，DOM，HTML在统一标准下使用。SVG是可伸缩的矢量图像，本质上是一段文本，可以被编辑，检索，压缩，编辑和创建的。</p><p>通过上面的介绍，容易发现SVG和万维网联盟的其他标准类似，是一种专门为了互联网而生的一种产物。</p><p>SVG文件大小比较小，可用代码进行绘图，支持web协议，可在网页中打开。</p><h3 id="pose-animator"><a href="#pose-animator" class="headerlink" title="pose-animator"></a>pose-animator</h3><p>由模型得到的点位信息的结构如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200514223027223.png" alt="image-20200514223027223" style="zoom:50%;"></p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200514223058374.png" alt="image-20200514223058374" style="zoom:50%;"></p><p>修改代码，将pose的keypoint信息通过json传入，得到相同的结果：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200518161834873.png" alt="image-20200518161834873" style="zoom:40%;"></p><h3 id="Paper-js"><a href="#Paper-js" class="headerlink" title="Paper.js"></a>Paper.js</h3><p>Paper.js在处理path的时候，将整个curve分成多个segment，每个segment由handleOut，handleIn，以及一个点组成，由三个点绘制出一条curve。</p><p>贝塞尔曲线下链接：<a href="https://www.jianshu.com/p/8f82db9556d2" target="_blank" rel="noopener">https://www.jianshu.com/p/8f82db9556d2</a></p><h3 id="绘制动画的基本思路"><a href="#绘制动画的基本思路" class="headerlink" title="绘制动画的基本思路"></a>绘制动画的基本思路</h3><p>pose-animator的总体思路是首先利用PoseNet和faceMesh得到人体和面部的关键点信息。动画部分，使用Paper.js控制SVG图像，首先给出了一个通用的骨骼结构(skeleton.svg)，通过skeleton.js获取关节点的位置以及关节点之间可能存在的骨骼信息：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200522163733751.png" alt="image-20200522163733751" style="zoom:50%;"></p><p>然后利用已有的svg动画图像如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200522164204453.png" alt="image-20200522164204453" style="zoom:50%;"></p><p>最后遍历skeleton.svg中path中的segment第三个point与图二中所有的bone计算距离，去寻找最接近的bone，计算距离如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> getClosestPointOnSegment(p0, p1, p) &#123;</span><br><span class="line">    <span class="keyword">let</span> d = p1.subtract(p0);</span><br><span class="line">    <span class="keyword">let</span> c = p.subtract(p0).dot(d) / (d.dot(d));</span><br><span class="line">    <span class="keyword">if</span> (c &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> p1.clone();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (c &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> p0.clone();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> p0.add(d.multiply(c));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上诉函数将返回一个最接近point的点坐标，然后计算distance，作为判断图二最近的segment的标准，随后计算一个weight，以及根据handleIn，handleOut去计算动画的一些形变</p><p>形变代码：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (s.handleIn) &#123;</span><br><span class="line">                <span class="keyword">let</span> pHandleIn = s.handleIn.add(s.point);</span><br><span class="line">                segment.handleIn = <span class="keyword">this</span>.getSkinning(pHandleIn, collinear ? weightsP : <span class="keyword">this</span>.getWeights(pHandleIn, bones)); <span class="comment">//skinning指的是肉</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (s.handleOut) &#123;</span><br><span class="line">                <span class="keyword">let</span> pHandleOut = s.handleOut.add(s.point);</span><br><span class="line">                segment.handleOut = <span class="keyword">this</span>.getSkinning(pHandleOut, collinear ? weightsP : <span class="keyword">this</span>.getWeights(pHandleOut, bones));</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><h3 id="添加自己的动画结果"><a href="#添加自己的动画结果" class="headerlink" title="添加自己的动画结果"></a>添加自己的动画结果</h3><p>首先需要绘制一张svg图像，节点的名称与已有的一致，然后传入图片，检测出关键点，然后就可以显示了。</p>]]></content>
      
      
      <categories>
          
          <category> 动画 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RDSNet总结文档</title>
      <link href="/2020/05/12/RDSNet%E6%80%BB%E7%BB%93%E6%96%87%E6%A1%A3/"/>
      <url>/2020/05/12/RDSNet%E6%80%BB%E7%BB%93%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>约束项以及约束的含义</title>
      <link href="/2020/05/11/%E7%BA%A6%E6%9D%9F%E9%A1%B9%E4%BB%A5%E5%8F%8A%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%90%AB%E4%B9%89/"/>
      <url>/2020/05/11/%E7%BA%A6%E6%9D%9F%E9%A1%B9%E4%BB%A5%E5%8F%8A%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%90%AB%E4%B9%89/</url>
      
        <content type="html"><![CDATA[<p>我们在训练神经网络的时候，总是希望网络能够有很强的抗干扰能力，对参数，对数据波动不敏感。因此我们需要引入约束项，规范参数的分布。</p><a id="more"></a><h3 id="扰动敏感"><a href="#扰动敏感" class="headerlink" title="扰动敏感"></a>扰动敏感</h3><p>很多时候我们希望得到一个稳健的模型，稳健的含义<strong>一是对参数扰动稳定性强</strong>，即当模型参数变为$f_w + \Delta x$</p><p><strong>二是对输入的稳定性强。</strong>即当x变成$x+\Delta x$作为输入的时候，网络结果不该发生比较大的变化。</p><h3 id="Lipschitz约束"><a href="#Lipschitz约束" class="headerlink" title="Lipschitz约束"></a>Lipschitz约束</h3><p>当我们希望网络足够稳定，当$||x_1 - x_2||$ 很小时，我们希望$\left|f_{w}\left(x_{1}\right)-f_{w}\left(x_{2}\right)\right|$ 也尽可能小，尽可能谁也说不准，于是Lipschitz提出了一个具体的约束，即存在某个常数C（仅仅与参数有关），<br>$$<br>\left|f_{w}\left(x_{1}\right)-f_{w}\left(x_{2}\right)\right| \leq C(w) \cdot\left|x_{1}-x_{2}\right|<br>$$<br>上诉便是L约束，我们希望C越小越好。</p><p>进一步简化公式，可以将公式转化为如下：<br>$$<br>\left|W\left(x_{1}-x_{2}\right)\right| \leq C\left|x_{1}-x_{2}\right|<br>$$</p><h3 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h3><p>我们可以将上诉的参数C转换为矩阵范数问题，矩阵范数相当于向量的模长。定义矩阵的范式来表示常量C，进而实现L约束。</p><h3 id="F范数"><a href="#F范数" class="headerlink" title="F范数"></a>F范数</h3><p>F范数指的是将矩阵视为一个向量，求解向量的欧式模长：<br>$$<br>|W|_{F}=\sqrt{\sum_{i, j} w_{i j}^{2}}<br>$$<br>通过柯西不等式可以得到F范数是W的一个上界，当我们不要求高的精度的情况下，选择F模是一个比较好的选择（计算量比较小）。</p><h3 id="L2-范数"><a href="#L2-范数" class="headerlink" title="L2 范数"></a>L2 范数</h3><p>L2范数指的是参数的平方和：<br>$$<br>\lambda\left(\sum_{i, j} w_{i j}^{2}\right)<br>$$<br>L2正则项能够很好的满足L约束，从而降低模型对输入扰动的敏感性，将L2正则项加入loss中。</p><p>L2范数将参数控制在比较小的水平，使得网络能够快速收敛，L2参数不会变为0，将选择比较多的特征，同时避免网络的过拟合。</p><h3 id="L1-范数"><a href="#L1-范数" class="headerlink" title="L1 范数"></a>L1 范数</h3><p>L1范数指的是参数的和：<br>$$<br>\sum_{i, j} ||w_{i j}||<br>$$<br>优化L1的目标将导致参数趋于0，使得参数变得稀疏化，使得模型自动选择特征，降低网络的复杂度。</p><p>正则化操作可见：<a href="https://perper.site/2019/07/24/normalization/" target="_blank" rel="noopener">https://perper.site/2019/07/24/normalization/</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>优化器总结</title>
      <link href="/2020/05/04/%E4%BC%98%E5%8C%96%E5%99%A8%E6%80%BB%E7%BB%93/"/>
      <url>/2020/05/04/%E4%BC%98%E5%8C%96%E5%99%A8%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>本文总结了常用的优化器，以及优化器的优缺点等。</p><a id="more"></a><h3 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h3><p>批量梯度下降，每次更新整个数据集计算一次梯度，确定是每次迭代比较耗时，遇到比较大的数据集则比较棘手。BGD容易陷入局部极小值点。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J(\theta)<br>$$</p><h3 id="Stochastic-gradient-Descent"><a href="#Stochastic-gradient-Descent" class="headerlink" title="Stochastic gradient Descent"></a>Stochastic gradient Descent</h3><p>随机梯度下降，每次更新时根据单个样本对梯度进行更新。SGD的优点是计算较快，缺点是会造成loss的剧烈震荡。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i)} ; y^{(i)}\right)<br>$$<br>SGD剧烈震荡可能会使得最后loss降到一个比较小的局部极小值点上。</p><h3 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h3><p>MBGD 小批样本的梯度下降，每次经过n个样本后才更新模型参数。这样的好处是可以降低参数更新时的方差，使得收敛更加稳定，另一方面可以利用矩阵计算来计算计算的速度。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i: i+n)} ; y^{(i: i+n)}\right)<br>$$</p><h3 id="普通梯度下降方法总结"><a href="#普通梯度下降方法总结" class="headerlink" title="普通梯度下降方法总结"></a>普通梯度下降方法总结</h3><ul><li>对于SGD方法来说，算法不能够保证很好的收敛性，如果learning rate选择太小，收敛速度比较慢，如果learning rate 选择过大则loss过分震荡无法收敛。</li><li><p>学习率的一种策略是逐步的降低learning rate的大小，如果数据是稀疏的，我们希望对出现频率低的特征进行大一点的更新。</p></li><li><p>此外对于非凸函数，当梯度下降时，loss陷入鞍点时，所有维度的梯度都为0，导致SGD方法无法更新参数。</p></li></ul><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>针对上面SGD容易陷入局部位置，可以利用前一次梯度更新的方向，作为一个动量，使当前loss脱离当前的位置。</p><p>加入前一次更新的动量，可以使得loss在梯度方向不变的方向上更新速度加快，在梯度方向变化的方向上，使更新速度变慢，可以起到收敛并减小震荡的作用。</p><p>缺点是动量完全取决于上一次的梯度方向，先验知识不足。<br>$$<br>\begin{array}{l}v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta} J(\theta) \ \theta=\theta-v_{t}\end{array}<br>$$</p><h3 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h3><p>NAG在momentum的基础上，对网络下一步更新方向进行微调：<br>$$<br>\begin{array}{l}v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta} J\left(\theta-\gamma v_{t-1}\right) \ \theta=\theta-v_{t}\end{array}<br>$$<br>利用动量调整网络下一步迭代的方向。</p><p> NAG 会先在前一步的累积梯度上有一个大的跳跃，然后衡量一下梯度做一下修正，这种预期的更新可以避免我们走的太快。</p><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>Adagrad在上面的基础上，改进了学习率，由于上诉的学习率无法自己调整，因此Adagrad通过累计梯度的方式，学习模型的学习率。<br>$$<br>\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot \nabla_{\theta} J\left(\theta_{i}\right)<br>$$<br>其中 $G_t$ 是个对角矩阵， (i,i) 元素就是 t 时刻参数 $θ_i$ 的梯度平方和。</p><p>我们累计每一次梯度的平方，接着让学习率除以它的开方。这个的作用是为了改变不同参数的学习率。假如一个参数的梯度一直很大，那么通过这个约束，它改变的就越少。假如一个参数的梯度一直很小，那么通过这个约束它，它变化的也就越快。</p><p>缺点是，随着梯度的累积，权重步长难免变得很小。</p><h3 id="adadelta"><a href="#adadelta" class="headerlink" title="adadelta"></a>adadelta</h3><p>adadelta使用梯度的均方根（先平方，在求平均，最后开方）作为分母，替代了所有t时刻的梯度平方，仅仅需要保留上一次的均方根和这一次的梯度值，减小了算法占用的空间。</p><p>相比于adagrad，分母使用了梯度平方的衰减平均值，公式如下：<br>$$<br>\Delta \theta_{t}=-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}+\epsilon}}g_{t}<br>$$<br>其中：<br>$$<br>g_{t}=\nabla_{\theta} J\left(\theta\right)<br>$$<br>E的计算仅仅与上一次的E与这次的梯度有关：<br>$$<br>E\left[g^{2}\right]_{t}=\gamma E\left[g^{2}\right]_{t-1}+(1-\gamma) g_{t}^{2}<br>$$<br>更新公式为：<br>$$<br>\theta_t =\theta_{t-1} + \Delta \theta_{t-1}<br>$$<br>学习率初值为：RMS[Δθ]</p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>这个方法与adadelta类似，是hinton在课上提出来的，建议将E的超参数设置为0.9：<br>$$<br>\begin{array}{l}E\left[g^{2}\right]_{t}=0.9 E\left[g^{2}\right]_{t-1}+0.1 g_{t}^{2} \ \theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}+\epsilon}} g_{t}\end{array}<br>$$</p><h3 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h3><p>adam设计了一种新的参数自适应学习的方法，存储了梯度的平方等衰减值，更新公式如下：<br>$$<br>\begin{array}{l}m_{t}=\beta_{1} m_{t-1}+\left(1-\beta_{1}\right) g_{t} \ v_{t}=\beta_{2} v_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2}\end{array}<br>$$<br>其中m，v初始化为0，初始化为0矫正检查之后即为：<br>$$<br>\begin{array}{l}\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}} \ \hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}}\end{array}<br>$$<br>迭代公式如下：<br>$$<br>\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{v}_{t}}+\epsilon} \hat{m}_{t}<br>$$<br>即adam同时结合了momentum和adadelta的特点，对梯度和累积梯度做一个叠加。</p><p>参数设置为β1 ＝ 0.9，β2 ＝ 0.999，ϵ ＝ 10e−8。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BGD方法是最基础的梯度下降方法，每次遍历整个数据集</p><p>SGD方法对单个样本计算梯度，速度快，但是容易陷入鞍点</p><p>MBGD方法采用小样本更新梯度，loss震荡比较平缓</p><p>Momentum方法采用前一个梯度方向作为动量，使得梯度快速下降，能够脱离鞍点</p><p>NAG在动量的基础上，加上对梯度方向上的调整</p><p>adagrad方法通过累积梯度平方对学习率进行调整</p><p>adadelta方法通过计算每一时刻梯度的平方和的根，通过动量的方式调整平方根，从而调整梯度</p><p>RMSprop在adadelta的基础上，设定了动量的参数，是adadelta的一种</p><p>adam使用一种结合动量和动态调节学习率的方法</p><p>如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam（动态调节loss）</p><p>Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum</p><p>随着梯度变的稀疏，Adam 比 RMSprop 效果会好。</p><p>整体来讲，Adam 是最好的选择。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习知识点总结1</title>
      <link href="/2020/05/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
      <url>/2020/05/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="梯度消失与梯度爆炸问题"><a href="#梯度消失与梯度爆炸问题" class="headerlink" title="梯度消失与梯度爆炸问题"></a>梯度消失与梯度爆炸问题</h3><p>训练神经网络时，神经网络各层的参数逐层累乘，因此在训练一个深度网络的时候，每层的参数累乘结果大于1，累乘n次之后则会出现梯度爆炸，反之小于1则出现梯度消失问题。</p><h3 id="神经网络的初始化"><a href="#神经网络的初始化" class="headerlink" title="神经网络的初始化"></a>神经网络的初始化</h3><p>为了缓解梯度消失和梯度爆炸问题，我们想到的一个办法是在参数初始化的时候，使用ReLU激活函数，同时给出参数的方差对参数进行归一化，方差通常为：<br>$$<br>\operatorname{np} . \operatorname{sqrt}\left(\frac{2}{n^{[l-1]}}\right)<br>$$<br>这种方法不能解决梯度消失或爆炸的问题，但是通过这种方式初始化得到的参数，数值比较小，比较接近1，因此在一定程度上缓解了梯度消失或爆炸的问题，可以加快网络的收敛。</p><h3 id="各种优化器总结"><a href="#各种优化器总结" class="headerlink" title="各种优化器总结"></a>各种优化器总结</h3><p><a href="https://perper.site/2020/05/04/优化器总结/" target="_blank" rel="noopener">https://perper.site/2020/05/04/%E4%BC%98%E5%8C%96%E5%99%A8%E6%80%BB%E7%BB%93/</a></p><h3 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch normalization"></a>batch normalization</h3><p>BN技术使得网络对超参数的选择不那么敏感，超参数的取值不会很大程度影响网络的性能。</p><p>covariate shift问题，即浅层网络参数的变化，会一直影响到深层网络的参数变化，使得每一层的参数分布发生变化，这种变化传递到深层网络的时候将会出现比较大的偏差，使得网络每次迭代的时候都需要去学习这种分布，因此希望通过BN将每层的分布归一化之后，加速网络的训练，泛化能力。</p><p>BN技术指的是使得BN那一层的参数，归一化到指定的mean和variance上。通常现将参数归一化后，然后输入激活函数中。原因是参数经过类似sigmoid这种激活函数，函数值之间的差异变得很小，归一化的作用不如直接进行归一化来得明显，同时可以保证进入sigmoid的时候，参数克服偏移，处在一个比较合适的位置上。</p><p>如下图计算出每一层输出z的平均值和方差，归一化参数，在实际运用中，BN通常与mini batch一起使用，利用一个batch的样本计算均值以及标准差。因此为了使得计算出的均值和方差足够代表整个数据集，我们的batch的大小需要尽量的大。</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200506202238045.png" alt="image-20200506202238045" style="zoom:50%;"></p><p><strong>优点</strong></p><ul><li>BN解决了网络训练过程中，每层参数分布变化的情况，参数发生整体偏移将导致网络训练缓慢，落入饱和区，不利于网络的训练，BN后，参数取值比较小且集中，可以使用更大的学习率</li><li>BN能够有效防止梯度消失，BN能够使得参数保持在一个合适的区间（尤其sigmoid，tanh）</li><li>对参数的初始化具有更强的鲁棒性</li><li>防止过拟合，由于每次用batch的均值和方差代替整个数据集的均值方差，因此无形给网络训练加入了噪音，能够提升网络的泛化能力，防止过拟合。</li></ul><p>由于我们对参数进行BatchNorm操作，将参数分布整体平移到N(0,1)之间，削弱了网络激活函数的非线性部分的作用，因此在进行BN之后，同时学习两个变量，对参数整体进行一个scale 和 shit。</p><p><a href="https://perper.site/2019/07/24/normalization/" target="_blank" rel="noopener">https://perper.site/2019/07/24/normalization/</a></p><h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><p>softmax对应的是hardmax，hardmax表示会将向量表示成one-hot形式，而softmax则比较柔和一点，输出是在0-1之间的概率值，softmax的公式为：<br>$$<br>S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}<br>$$<br>通常会将softmax作为交叉熵的输入，公式如下：<br>$$<br>\text {Loss}=-\sum_{i} t_{i} \ln y_{i}<br>$$<br>其中t为真值，即为1，y即为softmax，对softmax求导的时候，是否需要对分子求导，需要分情况讨论，详情请见：</p><p><a href="https://perper.site/2019/02/20/cross-entropy-交叉熵以及softmax/" target="_blank" rel="noopener">https://perper.site/2019/02/20/cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax/</a></p><h3 id="为什么使用卷积网络"><a href="#为什么使用卷积网络" class="headerlink" title="为什么使用卷积网络"></a>为什么使用卷积网络</h3><p>卷积核参数相比全连接层参数指数级下降，卷积核仅有很少的参数，便于训练，卷积核参数少但是能够提取数据的特征，原因如下：</p><ul><li>卷积权重共享， 即特征的移动不变性，一张图片不同位置的类似特征，可以通过同一个卷积核来提取不影响网络对特征的学习。</li><li>稀疏连接，图像的局部特征仅仅依赖于周围的像素特征，因此卷积核不需要太大就可以学到数据所表示的特征。</li></ul><h3 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h3><p>有些网络非常深，非常大，训练的时候存在梯度消失和梯度爆炸的问题。因此提出<strong>跳跃结构</strong>，最早在resNet这篇文章中提出。即将一层的特征，直接输出到其后的某一层作为输入，因此网络仅仅需要学习一个残差。引入残差也将不同尺度的特征进行了融合。</p><h3 id="1x1卷积的作用"><a href="#1x1卷积的作用" class="headerlink" title="1x1卷积的作用"></a>1x1卷积的作用</h3><ul><li>1x1卷积最直接的作用是，遍历图像的每一个像素，做一些乘积，累加的操作</li><li>用于压缩向量的通道数，减小网络的计算</li><li>给网络添加一个非线性变换</li></ul><h3 id="inception结构"><a href="#inception结构" class="headerlink" title="inception结构"></a>inception结构</h3><p>构建网络的时候，我们需要决定使用多大的卷积核，通常可以选择的有3x3,5x5,7x7等等，inception结构就是代替你来决定，选择出一种最佳的卷积核大小的方案。</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200517165426861.png" alt="image-20200517165426861" style="zoom:50%;"></p><p>第二层的特征，由许多不同大小的卷积核共同生成。inception的一个问题是网络的计算量相比使用单一的卷积核来的大。</p><h3 id="使用迁移学习"><a href="#使用迁移学习" class="headerlink" title="使用迁移学习"></a>使用迁移学习</h3><p>我们在训练一个网络模型的时候，通常需要重头开始训练整个模型。我们可以使用迁移学习的方法，将一些大型的公共数据集的知识迁移到自己的网络上。具体的做法是将网络的分类softmax层修改了，freeze住其他的层，或者使用别人训练好的backbone，对网络进行微调。</p><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>数据增强的方式其实是对数据的一种扩充，对于绝大多数任务来说，数据量越大，网络的效果越好，例如一些镜像，拉伸，随机crop，颜色通道的变换，对比度，透明度的变换，都是数据增强中比较常用的方式。</p><h3 id="增强网络性能"><a href="#增强网络性能" class="headerlink" title="增强网络性能"></a>增强网络性能</h3><ul><li>模型集成，同时使用多个独立的模型，得出检测的结果，最后对结果取平均</li><li>利用别人已经开源的网络结构，而不是自己重新搭建一个</li><li>使用别人的预训练模型</li><li>设计合适的手工工程，特征工程（例如人工设计的某个公式，指标等等）</li></ul><h3 id="yolo-v1的设计"><a href="#yolo-v1的设计" class="headerlink" title="yolo v1的设计"></a>yolo v1的设计</h3><p>yolo v1将图片划分为nxn个网格大小，每一个网格对应长度为m的一个标注[是否有图，x,y,h,w,class1,class2….]，对class的选择取决于对象的中点落在哪个网格区域内。</p><p>因此网络的输入是一张图片，经过各种卷积操作，输出是nxnxm的向量。</p><p>此外，yolo确定x,y,h,w的方式是和外包围的网格进行比较的，外包围网格第左上角是（0，0），右下角是（1，1）。因此x,y,h,w都是相对值。</p><h3 id="交并比IoU"><a href="#交并比IoU" class="headerlink" title="交并比IoU"></a>交并比IoU</h3><p>当候选框与GT框的相交面积比上他们面积的交集的比值，在大多数的情况下，这个值大于0.5则这个框为正类，否则这个框为负类。</p><h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>非极大值抑制的作用是确保每个对象只检测一次，具体的做法是，同一个目标可能会被多个候选框选中，我们需要在这些候选框中找出最合适作为下一步检测的框。在所有的候选框中找出置信度最高的，然后将其他边框都忽略，这就是非极大值抑制。</p><h3 id="anchor-box"><a href="#anchor-box" class="headerlink" title="anchor box"></a>anchor box</h3><p>有些时候，同一个网格中可能有多个目标，这时候一个网格位置需要检测多个目标，我们的做法是使用anchor box，即为每一个网格生成k个候选目标框，k个候选框的大小，长宽比均不同，这些框可以应付不同的目标出现在同一个网格内，然后网络最终的输出是将k个候选框关联起来，共同输出。</p><p>通常anchor box的数量会选择8个，长宽比为2：1等。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cpp常见的考点</title>
      <link href="/2020/04/14/cpp%E5%B8%B8%E8%A7%81%E7%9A%84%E8%80%83%E7%82%B9/"/>
      <url>/2020/04/14/cpp%E5%B8%B8%E8%A7%81%E7%9A%84%E8%80%83%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>不定时总结cpp可能问到的考点。</p><a id="more"></a><ul><li>全局变量自动初始化，局部变量系统不会对其初始化</li><li>static变量，指在程序生命周期内保持局部（全局）变量的存在，仅仅初始化一次。当static修饰类数据成员的时候，会导致该类成员数据被所有的类所共享。</li><li>extern变量，extern 是用来在另一个文件中声明一个全局变量或函数。</li></ul><h4 id="指针和引用的区别"><a href="#指针和引用的区别" class="headerlink" title="指针和引用的区别"></a>指针和引用的区别</h4><ul><li>引用是变量的别名，内部实现是只读指针</li><li>指针可以是空指针，但是引用必须指向一块合法的内存</li><li>引用一旦被初始化之后，就无法指向另一个对象</li><li>引用必须在创建的时候进行初始化，指针则无所谓</li></ul><p>####函数重载（静态多态）</p><p>指的是类中函数有着同样的函数名，但是函数的<strong>参数列表以及实现不同</strong>。</p><h4 id="多态（动态多态）"><a href="#多态（动态多态）" class="headerlink" title="多态（动态多态）"></a>多态（动态多态）</h4><p>多态指的是调用多态成员时，会根据调用函数对象的不同，来执行不同的函数。如果使用普通函数，一个父类指针，指向子类对象。调用的函数仍然是父类函数。需要对这些函数声明virtual变量，使得父类指针能够正常的调用。</p><p>使用virtual定义函数，即为后期绑定，在函数执行的时候，才根据函数的主体来决定函数执行的定义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Shape &#123;</span><br><span class="line">   protected:</span><br><span class="line">      int width, height;</span><br><span class="line">   public:</span><br><span class="line">      Shape( int a=<span class="number">0</span>, int b=<span class="number">0</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         width = a;</span><br><span class="line">         height = b;</span><br><span class="line">      &#125;</span><br><span class="line">      virtual int area()</span><br><span class="line">      &#123;</span><br><span class="line">         cout &lt;&lt; <span class="string">"Parent class area :"</span> &lt;&lt;endl;</span><br><span class="line">         <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>对于这一类有虚函数的类来说，我们需要给父类加上虚析构函数，他的作用是在你删除父对象指针的时候，函数会调用子类的析构函数，对析构对象内存进行回收。</strong></p><h4 id="虚继承"><a href="#虚继承" class="headerlink" title="虚继承"></a>虚继承</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>:</span><span class="keyword">virtual</span> <span class="keyword">public</span> A&#123;...&#125;</span><br></pre></td></tr></table></figure><p>虚继承解决多重继承问题中，父类二义性，冗余的问题。（菱形继承）</p><h3 id="内存泄漏，内存溢出"><a href="#内存泄漏，内存溢出" class="headerlink" title="内存泄漏，内存溢出"></a>内存泄漏，内存溢出</h3><p><strong>内存泄露</strong>：本意是申请的内存空间没有被正确释放，导致后续程序里这块内存被永远占用（不可达），而且指向这块内存空间的指针不再存在时，这块内存也就永远不可达了，内存空间一直被占用。</p><p><strong>内存溢出：</strong>内存越界，调用栈溢出等，栈内存不足的一种表现。</p><h4 id="接口（纯虚函数）"><a href="#接口（纯虚函数）" class="headerlink" title="接口（纯虚函数）"></a>接口（纯虚函数）</h4><p>即在类的成员函数中，有一些函数是纯虚函数，没有函数的实现，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">getArea</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>当子类在继承的时候，需要实现该函数。</p><h4 id="C-动态内存"><a href="#C-动态内存" class="headerlink" title="C++动态内存"></a>C++动态内存</h4><p><strong>栈内存：</strong>用于存储函数声明的变量，以及存储代码等，由系统自动分配</p><p><strong>堆内存：</strong>在程序执行过程中，申请的内存空间，通常由程序员分配和回收（new，delete）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span>* pvalue  = <span class="literal">NULL</span>;   <span class="comment">// 初始化为 null 的指针</span></span><br><span class="line">pvalue  = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">20</span>]; <span class="comment">// 为变量请求内存</span></span><br></pre></td></tr></table></figure><h4 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h4><p>设计模式是一套被反复使用多数人知晓，经过分类的代码设计经验总结。</p><h4 id="STL库"><a href="#STL库" class="headerlink" title="STL库"></a>STL库</h4><p>STL主要包括容器和算法，容器分为序列式容器和关联式容器</p><p>序列式容器不一定有序，但是可以被排序，如：vector，list，deque等</p><p>关联式容器，内部是一颗平衡二叉树，如set，map等等</p><p>迭代器提供了一种方法，使我们能够从头到尾遍历整个容器。</p><h4 id="const"><a href="#const" class="headerlink" title="const"></a>const</h4><p>const修饰成员变量，该变量不能被修改，const 函数只能访问const成员函数，不能修改数据成员。</p><p>const在定义指针时的限制范围：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">char greeting[] = 'hello';</span><br><span class="line"><span class="keyword">char</span>* p1 = greeting; <span class="comment">// 指针，指针变量都可以改变</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* p2= greeting; <span class="comment">//指针是变量，指针所指的内容是const</span></span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> p3 = greeting; <span class="comment">// 指针时const</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> p4 = greeting; <span class="comment">// 指针以及所指的内容均是const</span></span><br></pre></td></tr></table></figure><h4 id="static变量"><a href="#static变量" class="headerlink" title="static变量"></a>static变量</h4><p>函数的static变量在执行此函数时进行初始化，类的static变量在类实例化之前初始化，分配内存。</p><ul><li>修饰普通变量：修改变量的存储区和声明周期，使变量存储在静态区，在main函数之前初始化</li><li>修饰成员变量：所有对象共用一个成员实例，实例在对象生成之前就分类空间了</li><li>修饰成员函数：static成员函数只能访问const变量，即对对象不做任何修改</li></ul><h4 id="this指针"><a href="#this指针" class="headerlink" title="this指针"></a>this指针</h4><ul><li>this指针是隐含于每一个非静态成员函数中的特殊指针，他指向调用该成员函数的那个对象</li><li>this指针是const类型，可以代表当前的对象实例</li></ul><h4 id="inline内联函数"><a href="#inline内联函数" class="headerlink" title="inline内联函数"></a>inline内联函数</h4><ul><li><p>内联函数直接在调用位置将代码展开，省去调用函数的开销，因此内联函数需要形式简单，不应该有for一类的操作。</p></li><li><p>程序员无法确定函数是否真正内联，只能建议编译器内联，最后内联与否还是要编译器来决定。</p></li><li><p>inline可以修饰虚函数，但是只有在编译器知道调用对象是属于哪个类的时候，才可能发生。</p></li></ul><h4 id="struct和class"><a href="#struct和class" class="headerlink" title="struct和class"></a>struct和class</h4><p>struct和class本质的区别在于class数据成员时private，struct数据成员时public的。</p><h4 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h4><p>对数据进行隐藏，同时提供数据访问接口。</p><h4 id="堆和栈的生命周期"><a href="#堆和栈的生命周期" class="headerlink" title="堆和栈的生命周期"></a>堆和栈的生命周期</h4><p>栈：由操作系统自动分配释放 ，存放函数的参数值，局部变量等。其操作方式类似于数据结构中的栈</p><p>堆： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收，分配方式类似于链表（new，delete操作）</p><h4 id="内存泄漏，指针越界"><a href="#内存泄漏，指针越界" class="headerlink" title="内存泄漏，指针越界"></a>内存泄漏，指针越界</h4><p>动态内存分配时，空间在使用完之后未释放，一直占据着内存，称为内存泄漏。在new一块内存之后，需要用delete释放。</p><p>对指针赋值时，要注意指针赋值时的越界问题。</p><p>为了防止指针出现内存泄漏问题，可以将资源拷贝到auto_ptr,shared_ptr中，用这类资源管理器来管理资源。</p><p>成对的出现new和delete。</p><h4 id="CPP代码执行的过程"><a href="#CPP代码执行的过程" class="headerlink" title="CPP代码执行的过程"></a>CPP代码执行的过程</h4><p><strong>预处理：</strong> 条件编译，宏替换等等</p><p><strong>编译：</strong> 将处理后的语言转化成汇编语言</p><p><strong>汇编：</strong> 将汇编语言转化为目标代码</p><p><strong>链接：</strong> 链接目标代码，生成可执行文件</p><h4 id="CPP创建类的时候，自动生成的代码"><a href="#CPP创建类的时候，自动生成的代码" class="headerlink" title="CPP创建类的时候，自动生成的代码"></a>CPP创建类的时候，自动生成的代码</h4><p>构造函数，析构函数，拷贝析构函数，赋值函数</p><h4 id="智能指针"><a href="#智能指针" class="headerlink" title="智能指针"></a>智能指针</h4><p>包括<code>shared_ptr</code>，<code>unique_ptr</code>,<code>weak_ptr</code>，<code>auto_ptr</code>。share_ptr指多个智能指针共享一个对象。unique_ptr独享一个对象，weak_ptr允许共享，但是不拥有对象。</p><h3 id="Linux常见的指令"><a href="#Linux常见的指令" class="headerlink" title="Linux常见的指令"></a>Linux常见的指令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps # 查看当前用户的进程</span><br><span class="line">ps aux  # aux 选项查看进程的 CPU 或内存使用量</span><br></pre></td></tr></table></figure><h3 id="Linux-的grep用法"><a href="#Linux-的grep用法" class="headerlink" title="Linux 的grep用法"></a>Linux 的grep用法</h3><p>grep 指令用于查找内容包含指定的范本样式的文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep test *file  # 查找file后缀的文件中，含有test的文件的那一行</span><br></pre></td></tr></table></figure><h3 id="Linux的find指令"><a href="#Linux的find指令" class="headerlink" title="Linux的find指令"></a>Linux的find指令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find . -name &quot;*jpg&quot; # 找出当前路径，以及当前路径的子目录下所有图片</span><br><span class="line">find . -type f # 将目前目录其其下子目录中所有一般文件列出</span><br></pre></td></tr></table></figure><h3 id="new-delete-malloc-free的区别"><a href="#new-delete-malloc-free的区别" class="headerlink" title="new,delete,malloc,free的区别"></a>new,delete,malloc,free的区别</h3><p>new，delete能够调用对象的构造函数或是析构函数，new，delete是C++的运算符不是库函数。</p><p>malloc，free是C++的库函数，用于申请和释放内存，仅使用于内部数据类型变量，无法调用对象的构造或析构函数。</p><p>delete：只调用一次析构函数</p><p>delete[]：会调用每一个对象的析构函数</p><h3 id="构造函数，析构函数的调用顺序"><a href="#构造函数，析构函数的调用顺序" class="headerlink" title="构造函数，析构函数的调用顺序"></a>构造函数，析构函数的调用顺序</h3><p>定义一个对象时先调用基类的构造函数、然后调用派生类的构造函数</p><p>析构的时候恰好相反：先调用派生类的析构函数、然后调用基类的析构函数。</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>给某个目标起别名，相当于直接对对象进行操作</p><h3 id="重载和重写"><a href="#重载和重写" class="headerlink" title="重载和重写"></a>重载和重写</h3><p>重载是参数表不同，重写是子类覆盖了父类的方法</p>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>resume summary（1）</title>
      <link href="/2020/03/25/problem-summary/"/>
      <url>/2020/03/25/problem-summary/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RDSNet</title>
      <link href="/2020/03/18/RDSNet/"/>
      <url>/2020/03/18/RDSNet/</url>
      
        <content type="html"><![CDATA[<p>RDSNet的一个亮点在于同一个网络同时学习目标检测和目标分割，这两个任务相互促进提升模型精度。RDSNet提出了双流结构，分别取学习目标尺度和像素尺度上的物体。同时两条流上的信息相互融合，相互促进各自的训练。object level为pixel level提供了实例信息，为pixel提供一些分割上的先验。pixel level为object level重新定义边框的定位，提升精度。</p><p>在这个结构中，来自两个流的信息是交替融合，即对象层的信息引入实例意识和翻译差异到像素级，像素级的信息-在对象级别细化对象的定位精度作为回报</p><a id="more"></a><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>目标识别</strong>上，找出一个tight bounding box是非常具有挑战的，即要么无法全部选中目标，要么bounding 太大选中过多。</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200318110910599.png" alt="image-20200318110910599" style="zoom:40%;"></p><p>一个主要的原因是我们在做边框回归的时候，由于逐点回归并不能直接感知整个对象，因此将这个问题转化为pixel wise更加合理，即根绝mask的大小，找到一个最小的包围盒。</p><p><strong>实例分割</strong>的目的是进一步预测除类别外的每个对象的每像素二值掩码。核心思想是：实例分割时，像素类别是具有实例感知的。如在MASK-RCNN中，mask是根据网络提取出来的单独的proposal来生成的，因此具有整个对象的感知。但是这种方法必须依赖于目标检测的结果。</p><p>通过上面的分析，这里两种任务时能够相互促进的，因此作者提出了RDSNet，一种互惠的目标检测方法和实例分割网络（RDSNet）来利用这两项任务之间的关系。</p><p>RDSNet利用双流结构，即对象流和像素流，同时这两条流的信息相互融合，具体来说，对象流集中在对象级别特征是一个回归的检测器，而像素流关注像素级特征，结构沿用FCN的结构，以保证高分辨率输出。</p><p>为了利用来自对象流的对象级提示，提出了<strong>一个相关模块和一个裁剪模块</strong>，该模块将实例感知和翻译方差特性引入到像素流，并产生实例感知的分割掩码。然后，提出了一种基于掩模的边界求精模块，以减小定位误差像素流，即基于实例掩码生成更精确的边界框。</p><p>RDSNet充分考虑了目标检测和实例分割任务之间的相互关系.与以往的方法相比，它有以下三个优点：1）由RDSNet生成的掩码对不同尺度的对象具有一致的高分辨率；2）由于具有巧妙的裁剪模块，掩码对检测结果的依赖性较小；3）更准确和更准确；更紧密的包围盒是用一种新的像素级公式得到的对象包围盒位置。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200318114954524.png" alt="image-20200318114954524" style="zoom:50%;"></p><h4 id="双流结构"><a href="#双流结构" class="headerlink" title="双流结构"></a>双流结构</h4><p>RDSNet的核心是双流结构，即对象流和像素流。这两条流共用相同的FPN（Lin等人.2017a）主干，然后为每个相应的任务分离。这种平行结构支持对象级和像素级信息的分离以及不同任务的可变分辨率。</p><p><strong>对象流</strong>。对象流侧重于对象级信息，包括对象类别，位置等。可有各种回归的检测器充当（Liu等）。此外，我们还添加了一个与分类和回归分支并行的新分支，以提取每个锚点（或位置）的对象特征。这条流负责产生检测结果，稍后将由像素级信息进一步提取信息（见SEC.3.3）。</p><p><strong>像素流</strong>。像素流的重点是像素级信息，并遵循FCN（2015）的高分辨率输出设计。具体来说，每像素特征是在这个流中提取的，并且用于通过使用对象级信息生成实例掩码（参见SEC.3.2）。</p><p><strong>对象感知：相关性模块</strong></p><p>主要思路是将实例信息融合到像素上来，以便做分割处理：<br>$$<br>M_{o}=\operatorname{softmax}\left(\Psi(U) \star \phi\left(v_{o}\right)\right)<br>$$<br>其中 $v_0$ 表示从obejct stream上的特征，U表示来着像素流的特征，将两个特征映射之后，做一个卷积操作，然后在M0上计算一个pixelwise的交叉熵损失，作为最后loss的一部分。</p><p>其中U的维度为1xdxhxw，v的维度为2xdx1x1，其中2表示当前像素是属于前景还是背景。因此U与v做完卷积之后，得到的维度是2x1xwxh，即每一个位置上有两个值，表示前景和背景的概率。每一个anchor对应一个v，与U做完卷积之后计算softmax得到一个二值图。因此可以发现，网络检测出多少anchor，最终segmentation的时候，就会输出多少张二值图，理论上每一个二值图表示一个对象。</p><p>2xkxdx1x1 representation即表示anchor对象的深层含义。</p><p><strong>翻译改变到翻译不变</strong></p><p>由于上诉相关模块对每一个object生成的mask覆盖了整个图像，由于卷积操作产生了大量的噪声。我们使用一个裁剪模块来克服这个问题。可以利用物体的边框进行裁剪，边框以外的像素设置成背景，但是这种做法又会受到检测结果的影响，因此我们选择裁剪进过扩展后的边框，保证mask对box的依赖比较小。同时扩展后的边框引入了更多的背景，使得背景也容易被区分出来。需要注意的是，我们引入背景的时候也需要保持正负样本的平衡（1:1），可以使用背景像素的OHEM算法。</p><h4 id="由mask得到精确边框"><a href="#由mask得到精确边框" class="headerlink" title="由mask得到精确边框"></a>由mask得到精确边框</h4><p>利用从对象流和像素流中获得的边界框和实例掩码，得到每个对象的更精确的边界框。虽然回归边界框可能包含定位错误，但我们认为它们在一定程度上仍然为对象边界位置提供了合理的先验。因此，我们的提法联合擦除检测和分割结果。</p><h3 id="网络损失函数"><a href="#网络损失函数" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>最终的loss：<br>$$<br>L=L_{c l s}+\lambda_{r} L_{r e g}+\lambda_{m} L_{m a s k}<br>$$<br>即分类损失，边框回归损失，相关模块产生的mask损失。</p><h3 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h3><p><strong>数据的组织形式</strong></p><p>GT中segmentation部分采用coco的标注格式，即ploygon多边形的轮廓坐标[x1,y1,x2,y2,x3,y3…]。</p><p>box部分则表明GT中的目标所在的外包围盒。</p><p><strong>dataset部分：</strong> 数据输出为[img, gt_bboxes, gt_labels, gt_masks]</p><p>代码结构：</p><ul><li>backbone: usually an FCN network to extract feature maps, e.g., ResNet, MobileNet.</li><li>neck: the component between backbones and heads, e.g., FPN, PAFPN.</li><li>head: the component for specific tasks, e.g., bbox prediction and mask prediction.</li><li>roi extractor: the part for extracting RoI features from feature maps, e.g., RoI Align.</li></ul><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>IoU：即预测的mask与GT的重叠程度<br>$$<br>I O U(A, B)=\frac{|A \cap B|}{|A \cup B|}<br>$$<br>dice：与IoU相似，也是用来评价与GT的重叠程度：<br>$$<br>\operatorname{dice}(A, B)=\frac{2|A \cap B|}{|A|+|B|}<br>$$<br>相同的结果比值上，dice的值要比IoU稍微大一点。</p><p>COCO数据集的验证方式得到的结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603</span><br><span class="line">Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.499</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000</span><br></pre></td></tr></table></figure><p>其中IoU表示阈值，用于区分正负样本，然后计算precision和recall，得到的结果如上。</p><p>下面是各个模型的指标，可以作为一个baseline，可以说明效果不错。</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200320153558364.png" alt="image-20200320153558364" style="zoom:50%;"></p><p>但是这个结果仅仅只是检测的结果，过于segmentation部分的结果并没有。</p><p>这个需要我自己去写一个。</p><p>对于segmentation的指标有：</p><p><strong>pa：</strong> 是标记正确的像素占总像素的比例</p><p><strong>mpa：</strong>每个类别被正确分类像素的比例，之后求所有类的平均</p><p><strong>mIU：</strong>在每个类上求IoU，再求平均</p><p><strong>fwIU：</strong>根据每个类出现的频率为其设置权重，再算IoU</p><p><strong>FCN模型的检测结果如下，可以做为一个baseline</strong></p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200320152311238.png" alt="image-20200320152311238" style="zoom:50%;"></p><p>验证集574张图片，能够检测出人的图像有：384张</p><p>验证后指标分别如下：</p><p>pa: 0.9326967388628634</p><p>person pa: 0.948784433562702; ski pa 0.7863983575482737</p><p>person mIU: 0.8811813306596593; ski mIU 0.47062399967040647</p><p><strong>人体倒立的效果不好：</strong></p><p>目前有的数据增强操作有：resize：[(1333, 640), (1333, 800)]，randomFilp（左右翻转），Normalize，Pad</p><p>增加上下翻转的操作，同时翻转mask和box。</p><p><strong>检测人体的一些参数：</strong></p><p>置信度threshold=0.3</p><p>4.5最新的segmentation结果：</p><ul><li><p>增加了人的上下翻转</p></li><li><p>改变了mask和人的面积的占比的阈值</p></li><li><p>使用了RDSNet原始的预训练模型</p></li><li>先过滤掉skis的GT，用原始的模型跑了一版只有人的mask，然后再训练所有的数据</li></ul><p>nums of all images:574 detect img: 574<br>pa: 0.9354692319143859<br>person pa: 0.952586679919327; ski pa 0.795659633538158<br>person mIU: 0.8703372762800548; ski mIU 0.4621799597472673</p><p>赅睦v3结果：</p><p>nums of all images:574 detect img: 315 </p><p>pa: 0.9402883800000756        person pa: 0.9549458484555311;     </p><p>ski pa    0.8145014928441581 person mIU: 0.8682211200110778</p><p>ski mIU 0.4661748785006413</p><p>4.3最新segmentation结果：</p><p>nums of all images:574 detect img: 233</p><p>pa: 0.9369132159512628</p><p>person pa: 0.9535568322424365;      ski pa 0.7994298667822376</p><p>person mIU: 0.8703037390529358;   ski mIU 0.4607294905584023</p><p>513张检测出来</p><p>pa: 0.931</p><p>person pa: 0.948; ski pa 0.786</p><p>person mIU: 0.881; ski mIU 0.450</p><p>最新的，雪板缺失的结果：</p><p>nums of all images:574 detect img: 492<br>pa: 0.9325332039535604<br>person pa: 0.952345728818519;        ski pa 0.774363662229735<br>person mIU: 0.8692397985003847;   ski mIU 0.46683807840731795</p><h4 id="本周的工作"><a href="#本周的工作" class="headerlink" title="本周的工作"></a>本周的工作</h4><ol><li>对视频进行mask抠像</li><li>将标注数据转化成80分类的数据格式，共8k张</li><li>训练了一版没有加入coco数据集80分类的结果</li><li>将coco加入数据集，重新训练新一版的结果</li></ol><p>0413：将划水数据加入数据集中得到的结果，感觉还有提升空间，可以继续训练</p><p>nums of all images:574 detect img: 496<br>pa: 0.9343723520825538<br>person pa: 0.9539596612578186; ski pa 0.7762043705731111<br>person mIU: 0.8691335572039341; ski mIU 0.4734166211250842<br>122.55705881118774</p><p>0415：80分类的跳水 + 滑雪数据：</p><p>nums of all images:574 detect img: 500<br>pa: 0.9338427680139673<br>person pa: 0.9529509669453708; ski pa 0.7774459065324504<br>person mIU: 0.8697633935721094; ski mIU 0.4716099906503192<br>123.1501772403717</p><table><thead><tr><th></th><th>总数</th><th>det_img</th><th>pa</th><th>person pa</th><th>person miu</th><th>ski pa</th><th>ski miu</th><th>备注</th></tr></thead><tbody><tr><td>0420_epoch16</td><td>574</td><td>279</td><td>0.95</td><td>0.97</td><td>0.88</td><td>0.84</td><td>0.50</td><td>加入coco数据</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h3 id="修改的点"><a href="#修改的点" class="headerlink" title="修改的点"></a>修改的点</h3><ol><li>数据增强：加入forst，上下翻转，brightness（defocus）</li><li>FL with distance aware</li></ol><h3 id="A-distance-aware-cross-entropy-loss"><a href="#A-distance-aware-cross-entropy-loss" class="headerlink" title="A distance-aware cross entropy loss"></a><strong>A distance-aware cross entropy loss</strong></h3><p>即： Class Weight based Dual Focal Loss</p><p> although FL proved to be better than CE and WCE to address both class imbalance and class weakness, it increases the weight factor on ‘positive hard’ classes {𝑃𝑖 ̂: 𝑃𝑖 = 1, 𝑃𝑖 ̂ ≪ 1}) only and remains blind to the ‘negative easy’</p><h3 id="剪视频"><a href="#剪视频" class="headerlink" title="剪视频"></a>剪视频</h3><p>滑雪视频：bFF_20191214095649.mp4</p><p>跳水场景</p><p>V1:</p><p>nums of all images:372 detect img: 109<br>pa: 0.8202673860246401<br>person pa: 0.8604234773163142; ski pa 0.4365939611642742<br>person mIU: 0.834689556354205; ski mIU 0.32204986948916425<br>57.603790283203125</p><p>v2：无</p><p>v3：</p><p>nums of all images:372 detect img: 234<br>pa: 0.8635791399587737<br>person pa: nan; ski pa 0.52861091026923<br>person mIU: 0.8660126998199129; ski mIU 0.37964839550921387<br>64.33940291404724</p><p>v4：（0413.epoch_47）</p><p>nums of all images:372 detect img: 240<br>pa: 0.8728082198181446<br>person pa: 0.9037850500010524; ski pa 0.5343325737147256<br>person mIU: 0.8766753717860475; ski mIU 0.3892417225535218<br>67.59345650672913</p><p>V5:(epoch_16)</p><p>nums of all images:372 detect img: 74<br>pa: 0.9405744365529746<br>person pa: 0.9630469046257544; ski pa nan<br>person mIU: 0.9072004643371733; ski mIU 0.0<br>62.072516441345215</p><ol><li>将部分跳水数据转成2分类，80分类验证集</li><li>对历史模型重新测试在跳水上的效果</li><li>绘制mask可视化视频（跳水和滑雪融合）</li><li>训练加入coco的RDSNet，验证最新结果</li></ol><h3 id="RDSNet的loss修改"><a href="#RDSNet的loss修改" class="headerlink" title="RDSNet的loss修改"></a>RDSNet的loss修改</h3><p>RDSNet目标检测上使用的loss是focal loss，在mask 分割上使用的loss是cross entropy loss。</p><p>mask分割的内部实现：</p><p><strong>mmdet/models/mask_heads/rdsnet_mask_head.py：213行</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(Pdb) pred_mask.shape</span><br><span class="line">torch.Size([<span class="number">34</span>, <span class="number">2</span>, <span class="number">248</span>, <span class="number">160</span>])</span><br><span class="line">(Pdb) gt_mask.shape</span><br><span class="line">torch.Size([<span class="number">34</span>, <span class="number">248</span>, <span class="number">160</span>])</span><br><span class="line">最终通过下面函数进行计算：</span><br><span class="line">input = log_softmax(input, <span class="number">1</span>)</span><br><span class="line">ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)</span><br></pre></td></tr></table></figure><p>V6 (epoch_37 0427)</p><p>滑雪：</p><p>nums of all images:574 detect img: 395<br>pa: 0.9525877472767361<br>person pa: 0.9645798724157836; ski pa 0.8437678375390546<br>person mIU: 0.8893634429910271; ski mIU 0.4647400425444946<br>110.54691290855408</p><p>跳水：</p><p>nums of all images:372 detect img: 143<br>pa: 0.9387247103765048<br>person pa: 0.9542593861783638; ski pa 0.7321668474084746<br>person mIU: 0.909753853880885; ski mIU 0.44296937228518907<br>61.86693835258484</p><p><strong>dual focal loss训练5个epoch后的结构：</strong></p><p>跳水：</p><p>nums of all images:372 detect img: 195<br>pa: 0.942374395615374<br>person pa: 0.9584690806034492; ski pa 0.7241165337826362<br>person mIU: 0.8722316754876035; ski mIU 0.47293200705732463<br>64.31871056556702</p><p>滑雪：</p><p>nums of all images:574 detect img: 433<br>pa: 0.9660662841297223<br>person pa: 0.9734102175290501; ski pa 0.865497049546744<br>person mIU: 0.8444838659179477; ski mIU 0.41508230594421563<br>108.87461352348328</p><p><strong>dual focal loss without coco</strong></p><p>跳水：</p><p>nums of all images:574 detect img: 478<br>pa: 0.9443598058031467<br>person pa: 0.9577760462895214; ski pa 0.8324571806551673<br>person mIU: 0.8813928476174313; ski mIU 0.46156182496159115<br>116.63049459457397</p><p>滑雪：</p><p>nums of all images:372 detect img: 186<br>pa: 0.8752277721197145<br>person pa: 0.897262192400029; ski pa 0.6044119935949241<br>person mIU: 0.8711407606062432; ski mIU 0.38455484339814283<br>63.10305881500244</p><p>训练80epoch的结果：</p><p>滑雪：</p><p>nums of all images:574 detect img: 480<br>pa: 0.9448030285036926<br>person pa: 0.9590008038256677; ski pa 0.8280578495166153<br>person mIU: 0.8797742794543877; ski mIU 0.4640084072051552<br>117.41836833953857</p><p>跳水：</p><p>nums of all images:372 detect img: 188<br>pa: 0.8714032581962176<br>person pa: 0.8949121343976324; ski pa 0.5869715304627966<br>person mIU: 0.8689041863792644; ski mIU 0.3728823778076807</p><ol><li>测试加入coco数据下，dual focal loss的效果，训练了5个epoch</li><li>将coco数据集移除，训练dual focal loss 的RDSNet</li><li>阅读segmentation部分的loss，RDSNet原始版本使用的是交叉熵loss</li><li>后续版本希望修改这部分loss为dual focal loss</li></ol><p><strong>2分类dual loss：</strong></p><p>滑雪：</p><p>nums of all images:574 detect img: 468<br>pa: 0.9398213765874458<br>person pa: 0.9551532269115653; ski pa 0.8188987123099618<br>person mIU: 0.8766970201077243; ski mIU 0.47674212496400986</p><p>跳水：</p><p>nums of all images:372 detect img: 275<br>pa: 0.9482054503366465<br>person pa: 0.9598653406334634; ski pa 0.7852411728484762<br>person mIU: 0.9124365370322647; ski mIU 0.4102839323682259</p><p><strong>2 分类v96 0503</strong></p><p>滑雪：</p><p>nums of all images:574 detect img: 475<br>pa: 0.939923169980097<br>person pa: 0.9567105804281405; ski pa 0.8082511329118433<br>person mIU: 0.8767730148660953; ski mIU 0.47880553997407566</p><p>跳水：</p><p>nums of all images:372 detect img: 291<br>pa: 0.9476719604689137<br>person pa: 0.96116073149258; ski pa 0.7693642239056024<br>person mIU: 0.9126262313523922; ski mIU 0.4118130800852414</p><p>加入随机对比度增强：（0503）</p><p>skiing：</p><p>nums of all images:574 detect img: 507<br>pa: 0.9365616582224128<br>person pa: 0.9557731597670968; ski pa 0.7875246119333108<br>person mIU: 0.8698177517484026; ski mIU 0.47908820398245655</p><p>跳水：</p><p>nums of all images:372 detect img: 304<br>pa: 0.9476233052691827<br>person pa: 0.9630547323478765; ski pa 0.7644954664819416<br>person mIU: 0.9158077226970566; ski mIU 0.44526721531789315</p><ol><li>训练二分类的dual focal loss</li><li>数据增强部分加入随机对比度增强，测试得到结果如下：</li><li>颜色通道变换，透明度，颜色空间变换等，模型还在训练</li></ol><ol><li>讨论下一步的改进方向</li></ol><ol><li>RDSNet/configs/rdsnet/ 中修改config，（35行左右）</li></ol><p>原来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss_cls=dict(</span><br><span class="line">            type=<span class="string">'FocalLoss'</span>,</span><br><span class="line">            use_sigmoid=<span class="keyword">True</span>,</span><br><span class="line">            gamma=<span class="number">2.0</span>,</span><br><span class="line">            alpha=<span class="number">0.25</span>,</span><br><span class="line">            loss_weight=<span class="number">1.0</span>),</span><br></pre></td></tr></table></figure><p>修改成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_cls=dict(</span><br><span class="line">            type=<span class="string">'DualFocalLoss'</span>,),</span><br></pre></td></tr></table></figure><ol start="2"><li>RDSNet/mmdet/models/losses/ 中替换<code>__init__.py</code>，添加<code>dual_focal_loss.py</code></li></ol><ol><li>0506加入颜色空间变换，量度变换，随机crop之后结果不好：</li></ol><p>nums of all images:574 detect img: 434<br>pa: 0.9284912894101659<br>person pa: 0.9347836581387167; ski pa 0.8339256079243513<br>person mIU: 0.8582783158839123; ski mIU 0.4214144635187835</p><p>nums of all images:372 detect img: 201<br>pa: 0.9282038176537211<br>person pa: 0.9157486699556354; ski pa 0.9054421235666925</p><p>person mIU: 0.8589043912125288; ski mIU 0.22410981963307305</p><ol start="2"><li>协助解决新模型无法加载问题</li><li>绘制，分析数据mask，box检测的结果</li></ol><p>ski检测不出来的情况有：</p><ul><li><p>反光严重，雪板和背景相互融合</p></li><li><p>ski仅仅露出一个侧边，雪板形状细长</p></li><li>图片像素模糊</li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LR 推导</title>
      <link href="/2020/03/14/LR-%E6%8E%A8%E5%AF%BC/"/>
      <url>/2020/03/14/LR-%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p>逻辑斯蒂回归是一种二分类模型，使用sigmoid函数判别函数，下面将详细讲一下逻辑回归的原理。</p><a id="more"></a><h3 id="逻辑回归函数"><a href="#逻辑回归函数" class="headerlink" title="逻辑回归函数"></a>逻辑回归函数</h3><ul><li>逻辑回归需要满足伯努利二次分布，即$h(\theta)$ 为正样本的概率，那么$1-h(\theta)$ 为负样本的概率。</li><li>样本分布相互独立，即求所有样本出现的概率可以通过连乘的形式得到。</li></ul><p><strong>sigmoid函数</strong><br>$$<br>h(\theta) = \frac{e^{wx}}{1+e^{wx}}<br>$$<br><strong>逻辑回归的损失函数：</strong></p><p>在一个二分类的数据中，一个事件发生的概率为：<br>$$<br>P(y | \boldsymbol{x})=\left{\begin{aligned} p, y &amp;=1 \ 1-p, y &amp;=0 \end{aligned}\right.<br>$$<br>为了方便计算将上式写成：<br>$$<br>P\left(y_{i} | \boldsymbol{x}_{i}\right)=p^{y_{i}}(1-p)^{1-y_{i}}<br>$$<br>当我们采集到一组数据，由于数据分布是相互独立的，因此联合的概率可以写成：<br>$$<br>\begin{aligned} P_{\breve{E}} &amp;=P\left(y_{1} | \boldsymbol{x}_{1}\right) P\left(y_{2} | \boldsymbol{x}_{2}\right) P\left(y_{3} | \boldsymbol{x}_{3}\right) \dots P\left(y_{N} | \boldsymbol{x}_{N}\right) \ &amp;=\prod_{n=1}^{N} p^{y_{n}}(1-p)^{1-y_{n}} \end{aligned}<br>$$<br>为了简化上面的式子，而不失去函数单调性，我们对函数取对数，得到：<br>$$<br>\begin{aligned} F(\boldsymbol{w})=\ln \left(P_{\breve{\mathbf{E}} \mathbf{h}}\right) &amp;=\ln \left(\prod_{n=1}^{N} p^{y_{n}}(1-p)^{1-y_{n}}\right) \ &amp;=\sum_{n=1}^{N} \ln \left(p^{y_{n}}(1-p)^{1-y_{n}}\right) \ &amp;=\sum_{n=1}^{N}\left(y_{n} \ln (p)+\left(1-y_{n}\right) \ln (1-p)\right) \end{aligned}<br>$$<br>其中p为sigmoid函数，可以发现上面实质加上负号就变成了交叉熵。</p><p><strong>逻辑回归函数的求导</strong></p><p>对于sigmoid函数，我们的求导如下：<br>$$<br>\begin{aligned} p^{\prime}=f^{\prime}(\boldsymbol{w}) &amp;=\left(\frac{1}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}\right)^{\prime} \ &amp;=-\frac{1}{\left(1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}\right)^{2}} \cdot\left(1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}\right)^{\prime} \ &amp;=-\frac{1}{\left(1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}\right)^{2}} \cdot e^{-\boldsymbol{w}^{T} \boldsymbol{x}} \cdot\left(-\boldsymbol{w}^{T} \boldsymbol{x}\right)^{\prime} \ &amp;=-\frac{1}{\left(1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}\right)^{2}} \cdot e^{-\boldsymbol{w}^{T} \boldsymbol{x}} \cdot(-\boldsymbol{x}) \ &amp;=\frac{e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}{\left(1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}\right)^{2}} \cdot \boldsymbol{x} \ &amp;=\frac{1}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}} \cdot \frac{e^{-\boldsymbol{w}^{T} \boldsymbol{x}}}{1+e^{-\boldsymbol{w}^{T} \boldsymbol{x}}} \cdot \boldsymbol{x} \ &amp;=p(1-p) \boldsymbol{x} \end{aligned}<br>$$<br>接下来对逻辑回归函数进行求导(求函数的最大似然)：<br>$$<br>\begin{aligned} \nabla F(\boldsymbol{w}) &amp;=\nabla\left(\sum_{n=1}^{N}\left(y_{n} \ln (p)+\left(1-y_{n}\right) \ln (1-p)\right)\right) \ &amp;=\sum\left(y_{n} \ln ^{\prime}(p)+\left(1-y_{n}\right) \ln ^{\prime}(1-p)\right) \ &amp;=\sum\left(\left(y_{n} \frac{1}{p} p^{\prime}\right)+\left(1-y_{n}\right) \frac{1}{1-p}(1-p)^{\prime}\right) \ &amp;=\sum_{n=1}\left(y_{n}(1-p) \boldsymbol{x}_{n}-\left(1-y_{n}\right) p \boldsymbol{x}_{n}\right) \ &amp;=\sum_{n=1}^{N}\left(y_{n}-p\right) \boldsymbol{x}_{n} \end{aligned}<br>$$<br><strong>SGD</strong></p><p>对参数进行更新，得到：<br>$$<br>\boldsymbol{w}_{t+1}=\boldsymbol{w}_{t}+\eta \nabla F(\boldsymbol{w})<br>$$</p><p>$$<br>\boldsymbol{w}_{t+1}= \boldsymbol{w}_{t} + \eta \sum_{n=1}^{N}\left(y_{n}-p\right) \boldsymbol{x}_{n}<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>TrackIn:BERT five-classification on MSMARCO.md</title>
      <link href="/2020/03/12/TrackIn-BERT/"/>
      <url>/2020/03/12/TrackIn-BERT/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要构建一个BERT的五分类模型，然后研究使用TrackIn来确定样本在模型训练中，对模型inference的影响。</p><a id="more"></a><h3 id="MS-MARCO"><a href="#MS-MARCO" class="headerlink" title="MS MARCO"></a>MS MARCO</h3><p>MS MARCO是微软发布的一个NLP问答数据集，里头含有100000个真实的在bing上提出的问题，以及问题的答案，可作为QnA问题的数据集，此后还陆续提出了多种问题的数据集。</p><p>格式的介绍在这里：<a href="https://microsoft.github.io/MSMARCO-Passage-Ranking/" target="_blank" rel="noopener">https://microsoft.github.io/MSMARCO-Passage-Ranking/</a></p><p>MARCO数据集中，比较重要的文件有：</p><ul><li><p><strong>triples.train.small.tsv</strong>，他的文件格式为:&lt;query,doc1,doc2&gt;，第一个doc1是positive，第二个doc2是negative。</p></li><li><p><strong>top1000.dev.tsv：</strong>&lt;query_id ,doc_id,query,doc&gt;，即query和doc对</p></li><li><strong>qrels.dev.small.tsv</strong>：&lt;query_id,0,doc_id,1&gt;，用来判断query和doc是否是相互关联的。</li></ul><p>triples.train.small.tsv中query是重复的。</p><h3 id="STSB数据集"><a href="#STSB数据集" class="headerlink" title="STSB数据集"></a>STSB数据集</h3><p>用1到5的分数来表征两个句子的语义相似性，本质上是一个回归问题，但依然可以用分类的方法做，因此可以归类为句子对的文本五分类任务。</p><p>数据集的格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indexgenrefilenameyearold_indexsource1source2sentence1sentence2score</span><br></pre></td></tr></table></figure><p>其中我们用到的数据是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sentence1sentence2score</span><br><span class="line">A plane is taking off.An air plane is taking off.5.000</span><br></pre></td></tr></table></figure><p>数据首先经过wordembedding，每个词变成长度为768的向量，每个句子通过pad_sequence变成长度为512，因此输出为【512 x 768】随后将【512 x 768】加上position embedding输入BERT模型中。</p><h3 id="dataloader部分"><a href="#dataloader部分" class="headerlink" title="dataloader部分"></a>dataloader部分</h3><p>使用一个数据存储数据，格式为&lt;query,doc,label&gt;,然后将数组存储为dataloader。其中label = 0 表示负类，label = 1 表示你正类。</p><p>其具体的实现过程如下：</p><p>首先将数据query与doc分别经过tokenizer分词化，然后组成一个输入:</p><p>[CLS] + tokens_query + [SEP] + tokens_doc + [SEP]</p><p>随后将分词转换为vocab中的word id，构建一个segments_tensor，长度与输入长度相同，其中query部分为0，doc部分为1。如果我们希望返回一个batch，需要将所有的tensor通过前面填充0 的方式，将tensor维度变成一直（pad_sequence）,同时构建一个mask，mask的维度与batch的维度相同，其中用零填充的部分为0，不是0填充的部分为1。</p><p>最终dataloader将返回：</p><p>&lt;tokens_tensors, masks_tensors,segments_tensors,  labels_ids&gt; </p><p>tensor的维度为：tokens_tensor为：32x128</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>模型使用<code>transformers.BertForSequenceClassification</code></p><p>该模型的网络结构如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200314021335605.png" alt="image-20200314021335605" style="zoom:50%;"></p><p>即BERT的基础上加上一层全连接层，全链接层输入为768，输出为label class的个数，最后通过一个交叉熵得出最后的loss。</p><h3 id="STSB评价指标"><a href="#STSB评价指标" class="headerlink" title="STSB评价指标"></a>STSB评价指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pearson_and_spearman</span><span class="params">(preds, labels)</span>:</span></span><br><span class="line">        pearson_corr = pearsonr(preds, labels)[<span class="number">0</span>]</span><br><span class="line">        spearman_corr = spearmanr(preds, labels)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">"pearson"</span>: pearson_corr,</span><br><span class="line">            <span class="string">"spearmanr"</span>: spearman_corr,</span><br><span class="line">            <span class="string">"corr"</span>: (pearson_corr + spearman_corr) / <span class="number">2</span>,</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p><strong>pearson:</strong>是衡量向量相似度的一种方法。输出范围为-1到+1, 0代表无相关性，负值为负相关，正值为正相关。<br>$$<br>\rho(X, Y)=\frac{E\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sigma_{X} \sigma_{Y}}=\frac{E\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sqrt{\sum_{i=1}^{n}\left(X_{i}-\mu_{X}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(Y_{i}-\mu_{Y}\right)^{2}}}<br>$$<br>相关系数 0.8-1.0 极强相关</p><p>0.6-0.8 强相关</p><p>0.4-0.6 中等程度相关</p><p>0.2-0.4 弱相关</p><p>0.0-0.2 极弱相关或无相关</p><p><strong>spearmanr</strong>：斯皮尔曼相关系数表明X(独立变量)和Y(依赖变量)的相关方向：<br>$$<br>\rho=\frac{\sum_{i}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sqrt{\sum_{i}\left(x_{i}-\bar{x}\right)^{2} \sum_{i}\left(y_{i}-\bar{y}\right)^{2}}}<br>$$</p><h3 id="trackIn-理解"><a href="#trackIn-理解" class="headerlink" title="trackIn 理解"></a>trackIn 理解</h3><p>TrackIn核心的观点在于model经过当前样本训练迭代后，更新参数得到的新模型在验证集上loss与未更新前下降的数值之差。</p><p><strong>样本影响力</strong>的定义如下（z为指定的样本，z’为验证集）：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image001.png" alt="img" style="zoom:50%;"></p><p>理想状态：即在某次迭代，能够指定一个训练样本。</p><p>在理想状态下，所有训练数据对验证集样本的影响如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image002.png" alt="img" style="zoom:50%;"></p><p><strong>上述公式，默认条件是每次迭代仅在一个训练样本上进行训练。</strong></p><p>作者使用一阶近似来估计迭代t中，测试示例的损失变化：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image003.png" alt="img" style="zoom:50%;"></p><p>其中梯度的计算是在验证集数据上的。</p><p>SGD梯度下降法计算参数迭代如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image004.png" alt="img" style="zoom:50%;"></p><p>将两个公式结合，忽略高阶项得到：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image005.png" alt="img" style="zoom:50%;"></p><p>因此我们固定一个样本z，可以算出利用z的所有迭代次数的影响力之和：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image006.png" alt="img" style="zoom:50%;"></p><p>当我们训练数据不是一个样本，而是一个batch的时候：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image007.png" alt="img" style="zoom:50%;"></p><p>作者在实际的应用中，在每次迭代仅使用单个样本，保存学习率不变，模型每次在训练集上训练一次后保存一个检查点checkpoint，因此两个checkpoint之间样本仅训练过一次。作者利用检查点的参数，作为近似参数向量：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/clip_image008.png" alt="img" style="zoom:50%;"></p><p>上式的含义是模型参数wt 到wt+1之间，样本z对验证集的影响。通过对这个影响是positive或negative的判断，得到样本对模型的影响力，一个应用就是用来判断是否存在样本误标注的问题。</p><p>作者论文中给出一个NLP例子是文本分类问题，证明这种方法也是可以用在NLP中的。 </p><h3 id="trackIn的一点尝试"><a href="#trackIn的一点尝试" class="headerlink" title="trackIn的一点尝试"></a>trackIn的一点尝试</h3><ol><li><p>使用STS-B数据集：五分类数据集，数据示例如下：</p><p> sentence1 sentence2 similar_score（0-4）<br> A plane is taking off.    An air plane is taking off.    4<br> A man is playing a large flute.    A man is playing a flute.    3<br> A man is smoking.    A man is skating.    0</p></li><li><p>使用huggingface中的BertForSequenceClassification类，调整网络的输出为五分类，该网络的结构为：<br> Bert + dropout + linear（768x5）+ corssentropy</p></li><li><p>原始版本训练10个epoch后，得到了检测的指标指标：<br> corr = 0.8668199467352331<br> pearson = 0.8680211975793752<br> spearmanr = 0.865618695891091<br> 这个成绩在glue排行版上top20左右，top10以上基本你上90分。</p></li><li><p>fix BERT部分参数，仅训练linear层，10个epoch之后的指标为：<br> corr = 0.46851795469199176<br> pearson = 0.4883897702565989<br> spearmanr = 0.44864613912738466</p></li><li><p>由于Bert后的分类结构过于简单，因此在原始网络后面添加linear层。fix bert部分，训练得到结果：<br> Bert + linear（768x100） + linear(100x5) + crossentropy<br> corr = 0.4874025699052884<br> pearson = 0.48976918410773407<br> spearmanr = 0.4850359557028428</p></li><li><p>bert + linear(768,300) + linear(300,50) + linear(50,5):<br> corr = 0.4901503255725512<br> pearson = 0.49249477605462705<br> spearmanr = 0.48780587509047535</p></li><li><p>Bert + linear(768,300) + linear(300,100) + linear(100,50) + linear(50,5) </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">corr = 0.5010257366795687</span><br><span class="line">pearson = 0.5034574745457592</span><br><span class="line">spearmanr = 0.49859399881337824</span><br></pre></td></tr></table></figure></li><li><p>训练bert最后一层以及linear层得到的结果：<br>bert + linear(768,300) + linear(300,100) + linear(100,50) + linear(50,5)</p><p> corr = 0.7648302644703243<br> pearson = 0.7663893373697331<br> spearmanr = 0.7632711915709155</p></li></ol><p>pearson:输出范围为-1到+1, 0代表无相关性，负值为负相关，正值为正相关。<br>相关系数 0.8-1.0 极强相关<br>0.6-0.8 强相关<br>0.4-0.6 中等程度相关<br>0.2-0.4 弱相关<br>0.0-0.2 极弱相关或无相关</p><h3 id="分析trackIn函数"><a href="#分析trackIn函数" class="headerlink" title="分析trackIn函数"></a>分析trackIn函数</h3><p>$$<br>\operatorname{TrackIn}\left(z, z^{\prime}\right)=\sum_{t: z_{t}=z} \eta_{t} \nabla \ell\left(w_{t}, z^{\prime}\right) \cdot \nabla \ell\left(w_{t}, z\right)<br>$$</p><p>如上，作者经过一些推导之后得到TrackIn的表达式，表达式表明，在第t步迭代的时候，训练样本z 对 待测试样本$z^`$ 的影响的计算方法是： 待测样本在$w_t$上的梯度与训练样本在$w_t$上的梯度的乘积。</p><p>这时候有一个问题，就是$w_t$是一个矩阵，而TrackIn是loss的差，是一个标量，我的想法是矩阵对应位置相乘后相加，得到最后的结果。可以把t次数调大一点，使得效果能够明显一点。</p><p>因此思路如下：</p><ol><li>将训练样本和测试样本输入网络，然后将Bert最后一层以及classifier层的梯度拿出来</li><li>计算梯度相乘，然后求和得到trackIn的值</li><li>记录一个表，表中的内容是target example 和 对应的一些列 train example，然后每个train example有一个trackIn的值。</li></ol><p>因此要做的事情是：</p><ol><li>重新设计数据集，dataset，dataloader</li><li>对训练数据和测试数据迭代t次网络，然后将每次的梯度记到txt中</li><li>写一个矩阵相乘的代码，得到trackIn的值</li></ol><p>明天做！</p><p>测试数据：</p><p>aa: A plane is taking off.    An air plane is taking off.    5.000  </p><p>trackIn训练数据（假样本对数据的影响）：</p><p>b1: A plane is taking off.    A man wearing a hard hat is dancing.    5.000   :11326.170552326665</p><p>b2: A plane is taking off.    The plane is about to take off.     5.0 done         :11326.172044273939</p><p>b3: A plane is taking off.    Spaceship is about to take off.     3.0 done         :11326.17223393679</p><p>提取出20%的样本，其中最后一层输出的25维vector相似的向量，发现没有明显的规律。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Bert，XLNet，UNILM，RoBERTa以及QA</title>
      <link href="/2020/03/10/Bert%EF%BC%8CXLNet%EF%BC%8CUNILM%EF%BC%8CRoBERTa%E4%BB%A5%E5%8F%8AQA/"/>
      <url>/2020/03/10/Bert%EF%BC%8CXLNet%EF%BC%8CUNILM%EF%BC%8CRoBERTa%E4%BB%A5%E5%8F%8AQA/</url>
      
        <content type="html"><![CDATA[<p>trackIn是一种模型解释的方法，可用于评价每一个样本对模型的贡献度，通常可用于找出训练样本中，标注错误的样本。</p><p>本篇post以Bert QA问题为切入，研究一下这个问题。</p><a id="more"></a><h3 id="QA问答系统"><a href="#QA问答系统" class="headerlink" title="QA问答系统"></a>QA问答系统</h3><p>问答系统的类型有许多种，目前研究比较多的<strong>抽取式QA</strong>，目前认同度最大的数据集是SQuAD。抽取式QA的pipeline是，给定一篇文章，与这个文章对应着一些问题，抽取式QA从文章中选择出正确的答案，<strong>通常是确定答案的起始以及终止位置</strong>，基本框架如下：</p><p><img src="/images/nlp/image-20200311010615222.png" alt="image-20200311010615222" style="zoom:50%;"></p><p>即【问题，文章】-&gt; 【抽取式QA】 -&gt;【答案的收尾位置】</p><p>Embedder：对词进行embedding</p><p>Encoder：分别对问题和文章用LSTM进行建模。</p><p>Interaction Layer：各种Attention机制花式结合问题和文章，对问题和文章进行交互，在原文上得到query-aware的文章表示。（差别主要在这一部分）</p><p>Answer Layer：用query-aware的文章表示来预测答案，一般是用两个网络分别预测答案起止位置，或者直接对文章进行答案标注。</p><p>一些比较有名的模型：<strong>Match-LSTM</strong>，<strong>BiDAF</strong>，<strong>FastQAExt</strong> ，<strong>R-NET</strong> 。</p><p>本文从huggingface提供的bert-Squad pretrain model入手，可选择的模型有：BERT/RoBERTa/XLNet/XLM </p><h3 id="SQuAD"><a href="#SQuAD" class="headerlink" title="SQuAD"></a>SQuAD</h3><p><img src="/images/nlp/image-20200311010632954.png" alt="image-20200311010632954" style="zoom:50%;"></p><p>（图片引用：<a href="https://www.cnblogs.com/xuehuiping/p/12262700.html）" target="_blank" rel="noopener">https://www.cnblogs.com/xuehuiping/p/12262700.html）</a></p><p><strong>SQuAD的指标</strong></p><p><strong>EM：</strong>exact match，即预测结果完全匹配占所有结果的百分比</p><p><strong>F1：</strong> F1的选取是question预测结果与所有GT的最大F1，最终的F1为所有question的平均。<br>$$<br>F_1 = 2 <em> \frac{precision</em>recall}{precision + recall}<br>$$</p><h3 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h3><p>transformer结构如下所示，是一个由encoder和decoder组成的模块，其中encoder和decoder的数量为Nx个。</p><p><img src="/images/nlp/image-20200311155847088.png" alt="image-20200311155847088" style="zoom:50%;"></p><p>一个transformer有6个encoder，decoder组成，如下：</p><p><img src="/images/nlp/image-20200311160905424.png" alt="image-20200311160905424" style="zoom:50%;"></p><h3 id="NLP回归模型"><a href="#NLP回归模型" class="headerlink" title="NLP回归模型"></a>NLP回归模型</h3><p>经典的NLP问题通常为<strong>自回归语言模型</strong>：单方向预测，只能根据上文预测下文，或下文预测上文。经典的网络有GPT，ELMO。另一种为<strong>自编码语言模型：</strong>通过在输入的X中随机mask掉一些词，通过上下文的单词来预测这些被mask掉的词。这也有一个缺点，就是在输入侧引入了【mask】，导致预训练阶段和fintune阶段不一致的问题，这种类型的网络有Bert以及Bert类似的网络。</p><h3 id="Bert"><a href="#Bert" class="headerlink" title="Bert"></a>Bert</h3><p><img src="/images/nlp/image-20200311165643576.png" alt="image-20200311165643576" style="zoom:80%;"></p><p>bert结构如上，采用的是MASK双向的语言模型，规则是随机选择15%的词，在这15%的词中间，只有80%真正被替换成[mask]标记，10%被随机替换成另外一个单词，10%不做改动。</p><p><strong>Bert的缺点：</strong>它在预训练中使用了<code>[MASK]</code>，但是这种人为的符号在finetune的时候在实际数据中时没有的，导致了预训练 — finetune的不一致。<code>[MASK]</code>的另一个缺点是它假设所预测的(mask掉的)token是相互独立的，给出的是未掩码的tokens。</p><h3 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h3><p>XLNet基于以上两点，目前是使用自回归语言模型从左到右的方法，并且在引入MASK还要上下文的语义，学习双向的上下文信息。</p><p>在预训练阶段，引入Permutation Language Model的训练目标，直接的想法就是对句子进行排列组合，然后选择部分的组合输入到模型中，这样任意位置上的词就能看到它的上下文了。</p><p><img src="/images/nlp/image-20200311121638110.png" alt="image-20200311121638110" style="zoom:50%;"></p><p>直观上来说，，他的做法是当前预测到T位置，从句子中随机选择T-1个数，放到T的前面，作为预测T位置元素来使用，其他词通过掩码隐藏掉。</p><p><strong>双流自注意力机制：</strong>1）内容流自注意力，其实就是标准的Transformer的计算过程；2）Query流自注意力，例如预测x3的值，query流直接忽略掉x3输入了，只保留这个位置信息，用参数w来代表位置的embedding编码。</p><p><img src="/images/nlp/image-20200311201431222.png" alt="image-20200311201431222" style="zoom:50%;"></p><p>attention mask的含义如上右边，输入还是1，2，3，4，mask表中，每一列存在的值表示能看到的位置，其中内容流能看到自身信息，但是查询流看不到自身的信息。</p><h3 id="UNILM"><a href="#UNILM" class="headerlink" title="UNILM"></a>UNILM</h3><p>由于mask的训练方式对生成式的任务效果不好，对理解式的任务有着较好的性能，因此UNILM希望从训练方式上做创新，得到一个能够处理生成任务和理解任务的模型。</p><p>UNILM的预训练基于三个目标：单向LM（左到右和右到左），双向LM，sequence2sequence LM。</p><p>该模型采用一个共享参数的Transformer网络的同时还使用了特定的self-attention masks用以控制预测时候所用到的上下文信息。模型结构如下:</p><p><img src="/images/nlp/image-20200311214538762.png" alt="image-20200311214538762" style="zoom:50%;"></p><p>作者通过自动self-attention masks掩码的方式，来选择输入token的上下文，然后在训练阶段，每个batch训练的时间分别为1/3。</p><h3 id="RoBERTa"><a href="#RoBERTa" class="headerlink" title="RoBERTa"></a>RoBERTa</h3><p>1）动态Masking，相比于静态，动态Masking是每次输入到序列的Masking都不一样；</p><p>2）移除next predict loss，相比于BERT，采用了连续的full-sentences和doc-sentences作为输入（长度最多为512）；</p><p>3）更大batch size，batch size更大，training step减少，实验效果相当或者更好些；</p><p>4）text encoding，基于bytes的编码可以有效防止unknown问题。另外，预训练数据集从16G增加到了160G，训练轮数比BERT有所增加。</p><h3 id="GLUE"><a href="#GLUE" class="headerlink" title="GLUE"></a>GLUE</h3><p>通常来说，NLP可以分为自然语言理解（NLU）和自然语言生成（NLG）。在NLU方面，我们拿时下最流行的<a href="https://gluebenchmark.com/tasks" target="_blank" rel="noopener">GLUE</a>(General Language Understanding Evaluation)排行榜举例，其上集合了九项NLU的任务，分别是</p><ul><li><a href="https://nyu-mll.github.io/CoLA/" target="_blank" rel="noopener">CoLA</a>(The Corpus of Linguistic Acceptability):纽约大学发布的有关语法的数据集，该任务主要是对一个给定句子，判定其是否语法正确，因此CoLA属于单个句子的文本二分类任务；</li><li><a href="https://nlp.stanford.edu/sentiment/index.html" target="_blank" rel="noopener">SST</a>(The Stanford Sentiment Treebank)，是斯坦福大学发布的一个情感分析数据集，主要针对电影评论来做情感分类，因此SST属于单个句子的文本分类任务（其中SST-2是二分类，SST-5是五分类，SST-5的情感极性区分的更细致）；</li><li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52398" target="_blank" rel="noopener">MRPC</a>(Microsoft Research Paraphrase Corpus)，由微软发布，判断两个给定句子，是否具有相同的语义，属于句子对的文本二分类任务；</li><li><a href="http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark" target="_blank" rel="noopener">STS-B</a>(Semantic Textual Similarity Benchmark)，主要是来自于历年<a href="https://en.wikipedia.org/wiki/SemEval" target="_blank" rel="noopener">SemEval</a>中的一个任务（同时该数据集也包含在了<a href="https://github.com/facebookresearch/SentEval" target="_blank" rel="noopener">SentEval</a>），具体来说是用1到5的分数来表征两个句子的语义相似性，本质上是一个回归问题，但依然可以用分类的方法做，因此可以归类为句子对的文本五分类任务；</li><li><a href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs" target="_blank" rel="noopener">QQP</a>(Quora Question Pairs)，是由Quora发布的两个句子是否语义一致的数据集，属于句子对的文本二分类任务；</li><li><a href="http://www.nyu.edu/projects/bowman/multinli/" target="_blank" rel="noopener">MNLI</a>(Multi-Genre Natural Language Inference)，同样由纽约大学发布，是一个文本蕴含的任务，在给定前提（Premise）下，需要判断假设（Hypothesis）是否成立，其中因为MNLI主打卖点是集合了许多不同领域风格的文本，因此又分为matched和mismatched两个版本的MNLI数据集，前者指训练集和测试集的数据来源一致，而后者指来源不一致。该任务属于句子对的文本三分类问题。</li><li><a href="https://arxiv.org/abs/1606.05250" target="_blank" rel="noopener">QNLI</a>（Question Natural Language Inference)，其前身是SQuAD 1.0数据集，给定一个问句，需要判断给定文本中是否包含该问句的正确答案。属于句子对的文本二分类任务；</li><li><a href="https://aclweb.org/aclwiki/Recognizing_Textual_Entailment" target="_blank" rel="noopener">RTE</a>(Recognizing Textual Entailment)，和MNLI类似，也是一个文本蕴含任务，不同的是MNLI是三分类，RTE只需要判断两个句子是否能够推断或对齐，属于句子对的文本二分类任务；</li><li><a href="https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html" target="_blank" rel="noopener">WNLI</a>(Winograd Natural Language Inference)，也是一个文本蕴含任务，不过似乎GLUE上这个数据集还有些问题；</li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>天池安全AI挑战赛细枝末节</title>
      <link href="/2020/03/10/%E5%A4%A9%E6%B1%A0%E5%AE%89%E5%85%A8AI%E6%8C%91%E6%88%98%E8%B5%9B%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/"/>
      <url>/2020/03/10/%E5%A4%A9%E6%B1%A0%E5%AE%89%E5%85%A8AI%E6%8C%91%E6%88%98%E8%B5%9B%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>精彩视频剪辑的细枝末节</title>
      <link href="/2020/03/08/%E7%B2%BE%E5%BD%A9%E8%A7%86%E9%A2%91%E5%89%AA%E8%BE%91%E7%9A%84%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/"/>
      <url>/2020/03/08/%E7%B2%BE%E5%BD%A9%E8%A7%86%E9%A2%91%E5%89%AA%E8%BE%91%E7%9A%84%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>openpose细枝末节</title>
      <link href="/2020/03/07/openpose%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/"/>
      <url>/2020/03/07/openpose%E7%BB%86%E6%9E%9D%E6%9C%AB%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 面试准备 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>支持向量机-SVM</title>
      <link href="/2020/02/26/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM/"/>
      <url>/2020/02/26/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM/</url>
      
        <content type="html"><![CDATA[<p>SVM原理的简要梳理，包括了hard-svm，soft-svm，拉格朗日，对偶等知识点。</p><a id="more"></a><h3 id="VC维"><a href="#VC维" class="headerlink" title="VC维"></a>VC维</h3><p>VC维指的是在线性分类模型中，最多可以划分的簇的个数，例如2D平面中VC维为3.</p><p>对于非线性的模型来说，VC维是无限大的。通常来说，VC维越大分类器的分类性能越灵活。</p><h3 id="硬间隔SVM"><a href="#硬间隔SVM" class="headerlink" title="硬间隔SVM"></a>硬间隔SVM</h3><p>在对数据进行分两类的时候，尽可能找一条最粗的分界线，即margin最大，这条线恰好能够对数据进行分割。在分界线边上的点即为支撑向量。</p><p>平面中任意一点到分界面的距离为：<br>$$<br>d(\mathbf{x})=\frac{|\mathbf{x} \cdot \mathbf{w}+b|}{\sqrt{|\mathbf{w}|_{2}^{2}}}=\frac{|\mathbf{x} \cdot \mathbf{w}+b|}{\sqrt{\sum_{i=1}^{d} w_{i}^{2}}}<br>$$<br>我们找到所有样本点距离分界面最近的距离，作为当前样本的margin：</p><p><img src="/images/nlp/image-20200226224459260.png" alt="image-20200226224459260" style="zoom:50%;"><br>$$<br>\operatorname{margin} \equiv \underset{\mathbf{x} \in D}{\arg \min } d(\mathbf{x})=\underset{\mathbf{x} \in D}{\arg \min } \frac{|\mathbf{x} \cdot \mathbf{w}+b|}{\sqrt{\sum_{i=1}^{d} w_{i}^{2}}}<br>$$<br>为了使margin最大，达到最鲁棒的效果，调整w，b使：<br>$$<br>\underset{\mathbf{w}, b}{\operatorname{argmax}} \arg \min _{\mathbf{x} \in D} \frac{\left|b+\mathbf{x}_{i} \cdot \mathbf{w}\right|}{\sqrt{\sum_{i=1}^{d} w_{i}^{2}}}\\<br>\text { subject to } \forall \mathbf{x}_{i} \in D: y_{i}\left(\mathbf{x}_{i} \cdot \mathbf{w}+b\right) \geq 0<br>$$<br>即最大化最小间距，上式成立必须满足一个条件，即所有的点都必须在正确的分类。</p><p>由于$|xw + b|$的取值不会影响函数优化的结果，因此我们将它设为1，方便计算，即可得到：<br>$$<br>\begin{array}{l}{\underset{\mathbf{w}, b}{\operatorname{argmin}} \sum_{i=1}^{d} w_{i}^{2}} \ {\text { subject to } \forall \mathbf{x}_{i} \in D: y_{i}\left(\mathbf{x}_{i} \cdot \mathbf{w}+b\right) \geq 1}\end{array}<br>$$<br>上式即为硬间距SVM的表达式，通过计算出其中的w得到分界线的位置。</p><h3 id="soft-SVM"><a href="#soft-SVM" class="headerlink" title="soft-SVM"></a>soft-SVM</h3><p>在有些数据中，大部分数据都是可分的，但是可能存在一些噪点，使得数据整体不可分。因此我们需要加上一些tradesoff来解决这个问题，修改后的函数如下：</p><p><img src="/images/nlp/image-20200226232159974.png" alt="image-20200226232159974" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200226232318315.png" alt="image-20200226232318315" style="zoom:50%;"></p><p>每一个样本点对应一个tradesoff，通过最小化tradesoff的方式，使误分样本尽量少，同时鲁棒性好</p><h3 id="hinge-loss"><a href="#hinge-loss" class="headerlink" title="hinge loss"></a>hinge loss</h3><p>hinge loss是一个可导的函数，可视为是0-1loss的上界。</p><p><img src="/images/nlp/image-20200226233815693.png" alt="image-20200226233815693" style="zoom:50%;"></p><h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><h4 id="拉格朗日乘子"><a href="#拉格朗日乘子" class="headerlink" title="拉格朗日乘子"></a>拉格朗日乘子</h4><p>拉格朗提乘子满足下面的变换关系：</p><p><img src="/images/nlp/image-20200227001235311.png" alt="image-20200227001235311" style="zoom:50%;"></p><p>KKT条件：</p><p><img src="/images/nlp/image-20200227001334193.png" alt="image-20200227001334193" style="zoom:50%;"></p><p>用拉格朗日乘子求解SVM问题：</p><p><img src="/images/nlp/image-20200227001418834.png" alt="image-20200227001418834" style="zoom:50%;"></p><p>将偏导结果带回上式，得到对偶问题：</p><p><img src="/images/nlp/image-20200227001548912.png" alt="image-20200227001548912" style="zoom:50%;"></p><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>由于有些数据是非线性，不可分的。在低维空间中无法分隔开，因此需要使用核函数，对数据进行升维，使得数据可分。</p><p>核函数的表达式如下：<br>$$<br>K\left(x_{i}, x_{j}\right)=\phi\left(x_{i}\right) \cdot \phi\left(x_{j}\right)<br>$$<br>因此可以整体替换掉点乘项，使用核函数对数据进行升维。因为函数仅仅需要点乘的结果，我们不需要直接写出从低维到高维的映射函数。</p><p><img src="/images/nlp/image-20200227003536399.png" alt="image-20200227003536399" style="zoom:50%;"></p><p>常见的核函数如下：</p><p><img src="/images/nlp/image-20200227003606023.png" alt="image-20200227003606023" style="zoom:50%;"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上便是SVM的主要内容，下次回忆SVM算法的时候，可以从点到直线的距离开始，然后入手，将hard，soft，maxmin，拉格朗日，对偶，KTT，偏导那些东西全部过一遍便可。</p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>聚类</title>
      <link href="/2020/02/19/%E8%81%9A%E7%B1%BB/"/>
      <url>/2020/02/19/%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>物以类聚，人以群分。</p><a id="more"></a><h3 id="聚类简述"><a href="#聚类简述" class="headerlink" title="聚类简述"></a>聚类简述</h3><p>将数据分成多个类别，在同一个类别内对象之间就有较高的相似性，不同类对象之间的差异性则较大。对一批没有标注数据的样本，相似的归为一类，不相似的归为其他类，称为聚类分析，聚类的质量拒绝于度量标准的选择。</p><h3 id="聚类方法分类"><a href="#聚类方法分类" class="headerlink" title="聚类方法分类"></a>聚类方法分类</h3><ul><li>聚类类型<ul><li>统计聚类方法：基于全局数据的聚类，即从全体 样本中通过距离比较，获得聚类中心（马氏距离）</li><li>概念聚类方法：将数据按按一定的方式和准则进 行分组，得到的分组代表着不同的概念。</li><li>按度量方法分类：距离（k-means），密度，连通性（谱聚类）</li></ul></li></ul><h3 id="距离与相似度度量"><a href="#距离与相似度度量" class="headerlink" title="距离与相似度度量"></a>距离与相似度度量</h3><p><img src="/images/nlp/image-20200219191644847.png" alt="image-20200219191644847" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200219191715323.png" alt="image-20200219191715323" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200219191752693.png" alt="image-20200219191752693" style="zoom:40%;"></p><h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>给定一个包含n个无类别标签的数据集，假定这些样本符合一个形式已知，但是参数位置的函数：<br>$$<br>p(\mathbf{x} | \boldsymbol{\theta})=\sum_{j=1}^{c} p\left(\mathbf{x} | \omega_{j}, \boldsymbol{\theta}_{j}\right) P\left(\omega_{j}\right)<br>$$<br>采用最大似然方法对参数$\theta$ 进行估计。</p><p>最大似然估计的方式是首先对函数取对数，随后计算对$\theta$的梯度，令梯度等于零，求解其中待估计的参数$\theta$。</p><p><img src="/images/nlp/image-20200221005723555.png" alt="image-20200221005723555" style="zoom:40%;"></p><h3 id="K-均值聚类"><a href="#K-均值聚类" class="headerlink" title="K-均值聚类"></a>K-均值聚类</h3><p><img src="/images/nlp/image-20200221015505581.png" alt="image-20200221015505581" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200221015600990.png" alt="image-20200221015600990" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200221015922143.png" alt="image-20200221015922143" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200221022258398.png" alt="image-20200221022258398" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200221022334981.png" alt="image-20200221022334981" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>神经网络</title>
      <link href="/2020/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>神经网络是一个并行的分布式处理结构，由处理单元及其链接的无向通道组成。</p><a id="more"></a><h3 id="人工神经元"><a href="#人工神经元" class="headerlink" title="人工神经元"></a>人工神经元</h3><p>人工神经元接受一个输入，经过激活函数，得到一个输出。</p><p><img src="/images/nlp/image-20200217190314746.png" alt="image-20200217190314746" style="zoom:40%;"></p><p><strong>激活函数</strong></p><p><img src="/images/nlp/image-20200217195205430.png" alt="image-20200217195205430" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217195431829.png" alt="image-20200217195431829" style="zoom:40%;"></p><h3 id="单层感知器"><a href="#单层感知器" class="headerlink" title="单层感知器"></a>单层感知器</h3><p><img src="/images/nlp/image-20200217200553358.png" alt="image-20200217200553358" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217200623566.png" alt="image-20200217200623566" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217210505691.png" alt="image-20200217210505691" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217214410100.png" alt="image-20200217214410100" style="zoom:40%;"></p><h3 id="多层感知器"><a href="#多层感知器" class="headerlink" title="多层感知器"></a>多层感知器</h3><p><img src="/images/nlp/image-20200217224218769.png" alt="image-20200217224218769" style="zoom:40%;"></p><p><strong>误差反向传播算法BP</strong></p><p>利用输出后的误差来估计输出层的前一层的误差，再用这个误差去估计更前一层的误差，从而获得各层的误差估计。</p><p><img src="/images/nlp/image-20200217225713435.png" alt="image-20200217225713435" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217231110300.png" alt="image-20200217231110300" style="zoom:40%;"></p><p>反向传播如下：</p><p><img src="/images/nlp/image-20200217231224975.png" alt="image-20200217231224975" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217233040444.png" alt="image-20200217233040444" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217233643956.png" alt="image-20200217233643956" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217233705608.png" alt="image-20200217233705608" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217234019319.png" alt="image-20200217234019319" style="zoom:40%;"></p><p><strong>人工神经网络到深度网络的演化</strong></p><p><img src="/images/nlp/image-20200218121400892.png" alt="image-20200218121400892" style="zoom:40%;"></p><p>网络发展的趋势是参数越来越多，网络越来越深。</p><p><img src="/images/nlp/image-20200218122631866.png" alt="image-20200218122631866" style="zoom:40%;"></p><h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p><img src="/images/nlp/image-20200218123425909.png" alt="image-20200218123425909" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218123610159.png" alt="image-20200218123610159" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218123655620.png" alt="image-20200218123655620" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218123747946.png" alt="image-20200218123747946" style="zoom:40%;"></p><p>对于自然图像而言，我们希望从图像底层开始进行学习，而非利用人为设计的特征，如果直接将图像作为输入，采用全连接的方式，将造成巨大的计算量，因此我们提出卷积神经网络：</p><ul><li>局部连接：每次计算仅考虑卷积核大小的区域<ul><li>对图像而言，局部领域内的像素联系比较紧密，距离较远的像素相关性则比较弱</li><li>卷积核对局部信息进行感知，在高层则将局部信息综合起来得到全局信息</li></ul></li><li>权值共享：克服参数过多问题<ul><li>利用一个参数待学习的卷积核（3x3），对图像进行卷积过滤，每个卷积核可视为学习一种参数</li></ul></li></ul><p><img src="/images/nlp/image-20200218125212298.png" alt="image-20200218125212298" style="zoom:40%;"></p><p>采用卷积得到的结果得到的仍然是一个较高维度的结果，在如此高维的特征下设计分类器容易产生过拟合，并且计算量较大。</p><p>因此一个方法就是对不同位置上的特征进行聚合：</p><p><img src="/images/nlp/image-20200218125659834.png" alt="image-20200218125659834" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218133024988.png" alt="image-20200218133024988" style="zoom:40%;"></p><h3 id="自编码器（autoencoder）"><a href="#自编码器（autoencoder）" class="headerlink" title="自编码器（autoencoder）"></a>自编码器（autoencoder）</h3><p><img src="/images/nlp/image-20200218133233532.png" alt="image-20200218133233532" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218134846541.png" alt="image-20200218134846541" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218135048551.png" alt="image-20200218135048551" style="zoom:40%;"></p><h3 id="RNN网络"><a href="#RNN网络" class="headerlink" title="RNN网络"></a>RNN网络</h3><p><img src="/images/nlp/image-20200218140718801.png" alt="image-20200218140718801" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218140918045.png" alt="image-20200218140918045" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200218141105912.png" alt="image-20200218141105912" style="zoom:40%;"></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>线性判别函数</title>
      <link href="/2020/02/16/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0/"/>
      <url>/2020/02/16/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p><strong>线性判别函数</strong>：用于分类的判别函数的参数形式已知，通过从样本来估计判别函数的参数。</p><a id="more"></a><h3 id="模式分类的途径"><a href="#模式分类的途径" class="headerlink" title="模式分类的途径"></a>模式分类的途径</h3><ul><li>估计类条件概率密度函数，然后通过贝叶斯得到后验概率，用于决策</li><li>直接估计后验概率：k-近邻分类器等</li><li>使用判别函数，直接决策</li></ul><h3 id="线性判别函数与决策面"><a href="#线性判别函数与决策面" class="headerlink" title="线性判别函数与决策面"></a>线性判别函数与决策面</h3><p><img src="/images/nlp/image-20200216222218691.png" alt="image-20200216222218691" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200216222522730.png" alt="image-20200216222522730" style="zoom:40%;"></p><p><strong>多类情况-判别器</strong></p><ul><li>one-vs-all：构造C的二分类器，逐一比较</li><li>one-vs-one：两两配对，构造c/2个二分类器</li></ul><p><strong>增广性</strong></p><p>对线性判别函数采用其次增广表示，使得决策平面过原点，具有一些很好地分类性质。</p><p><img src="/images/nlp/image-20200216230032056.png" alt="image-20200216230032056" style="zoom:40%;"></p><h3 id="感知准则函数"><a href="#感知准则函数" class="headerlink" title="感知准则函数"></a>感知准则函数</h3><p><img src="/images/nlp/image-20200216230427121.png" alt="image-20200216230427121" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200216231014083.png" alt="image-20200216231014083" style="zoom:40%;"></p><p>越靠近区域中间的解向量，越能对新的样本正确分类，可以对解区进行限制：</p><p><img src="/images/nlp/image-20200216233948027.png" alt="image-20200216233948027" style="zoom:40%;"></p><p>感知器准则：最小化错分样本</p><p><img src="/images/nlp/image-20200216234659412.png" alt="image-20200216234659412" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200216234827162.png" alt="image-20200216234827162" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200216235836881.png" alt="image-20200216235836881" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217000045647.png" alt="image-20200217000045647" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217000108761.png" alt="image-20200217000108761" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217000130566.png" alt="image-20200217000130566" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217000842488.png" alt="image-20200217000842488" style="zoom:40%;"></p><p><img src="/images/nlp/image-20200217000608368.png" alt="image-20200217000608368" style="zoom:40%;"></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Learn To Rank</title>
      <link href="/2020/02/14/Learn-To-Rank/"/>
      <url>/2020/02/14/Learn-To-Rank/</url>
      
        <content type="html"><![CDATA[<p>Learn To Rank是一种学习方法，通过训练模型来解决排序的问题，在信息检索，NLP，Data Mining领域有着很多的应用。</p><a id="more"></a><h3 id="排序问题"><a href="#排序问题" class="headerlink" title="排序问题"></a>排序问题</h3><p>在信息检索中，给定一个query，搜索引擎会召回（<strong>粗筛选</strong>）一系列相关的Documents（term匹配，keyword匹配，semantic匹配），之后对这些Documents排序，最后输出Top N的Documents。</p><p>排序问题即使用一个模型 f(q,d)来对该query下的documents进行排序，这个模型可以是人工设定一些参数的模型，也可以是用<strong>机器学习算法自动训练出来的模型</strong>。在Web Search领域，因为在Web Search 中，有很多信息可以用来<strong>确定query-doc pair的相关性</strong>，而另一方面，由于大量的搜索日志的存在，可以将<strong>用户的点击行为日志作为training data</strong>，使得通过机器学习自动得到排序模型成为可能。</p><p><strong>排序问题的核心在于找出query和doc之间的相关性，对相关性进行排序。</strong></p><p>learn to rank 是监督学习，分为train和test两个阶段：</p><p><img src="/images/nlp/image-20200214232441639.png" alt="image-20200214232441639"></p><h3 id="training-data-set-的生成"><a href="#training-data-set-的生成" class="headerlink" title="training data set 的生成"></a>training data set 的生成</h3><p>由于learning to rank是监督学习，因此对每一条记录都需要label。通常feature vector容易获取，而label实际上反映了query-doc pair的真实相关程度。通常有两种label的获取方式：</p><ul><li>人工标注，即对抽样出来作为training data的query-doc pair人为地进行相关程度的判断和标注，一般标注的相关程度分为5档：perfect，excellent，good，fair，bad。<ul><li>例如，query=“Microsoft”。document为Microsoft的官网是perfect；介绍Microsoft的wikipedia则是excellent；一篇将Microsoft作为其主要话题的网页则是good；一篇只是提到了Microsoft这个词的网页则是fair，而一篇跟Microsoft毫不相关的网页则是bad。人工标注的方法可以通过多人同时进行，最后以类似投票表决的方式决定一个query-doc pair的相关程度，这样可以相对减少各个人的观点不同带来的误差。</li></ul></li><li>通过搜索日志获取。搜索日志记录了人们在实际生活中的搜索行为和相应的点击行为，点击行为隐含了query-doc pair的相关性，所以可以被用来作为query-doc pair的相关程度的判断。一种最简单的方法就是利用同一个query下，不同doc的点击数的多少来作为它们相关程度的大小。</li></ul><p>通过搜索日志的方式获取的方法存在一些偏差，即用户偏向于点击位置靠前的doc，即便这个doc并不相关或者相关性不高。因此有一些tricky和general的方法用来处理这种“position bias”的偏差：</p><ol><li>当位置靠后的doc的点击数都比位置靠前的doc的点击数要高了，那么靠后的doc的相关性肯定要比靠前的doc的相关性大。</li><li>Joachims等人则提出了一系列去除bias的方法，例如 Click &gt; Skip Above, Last Click &gt; Skip Above, Click &gt; Earlier Click, Click &gt; Skip Previous, Click &gt; No Click Next等。</li><li>一个doc的点击数比另一个doc的点击数多，并不一定说明前者比后者更相关。但即使前者比后者位置靠前，两者的点击数相差5-10倍，这时候我们还是愿意相信前者更加相关。</li><li>click model，根据用户的点击信息对用户真正看到的doc进行“筛选”，进而能更准确地看出用户到底看到了哪些doc，没有看到哪些doc，更准确反应点击数/展示数（即展现CTR）来确定各个doc的相关性大小。</li></ol><h3 id="feature-的生成"><a href="#feature-的生成" class="headerlink" title="feature 的生成"></a>feature 的生成</h3><p>一般Learning to Rank的模型的feature分为两大类：relevance 和 importance（hotness），即query-doc pair 的相关性feature，和doc本身的热门程度的feature。两者中具有代表性的分别是 BM25 和 PageRank。</p><h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>比较模型的输出结果，和真实结果（ground truth）之间的差异大小。用于Information Retrieval的排序衡量指标通常有：NDCG，MAP等。</p><p><strong>NDCG</strong></p><p>NDCG表示了从第1位doc到第k位doc的“归一化累积折扣信息增益值”，主要思想是相关性高且等级高的结果，值应该比较高。</p><ul><li>高关联度的结果比一般关联度的结果更影响最终的指标得分</li><li>有高关联度的结果出现在更靠前的位置的时候，指标会越高</li></ul><p><strong>CG：累计增益cumulative gain</strong></p><p>只考虑到了相关性的关联程度，没有考虑到位置的因素，是一个搜素结果相关性分数的总和。<br>$$<br>\mathrm{CG}_{\mathrm{p}}=\sum_{i=1}^{p} r e l_{i}<br>$$<br>rel表示i的相关性。</p><p><strong>折损累计增益（DCG）</strong>：</p><p>即对每一个CG的结果，除以一个折算值，目的是为了排名越靠前的结果影响力越大：<br>$$<br>\mathrm{DCG}_{\mathrm{p}}=\sum_{i=1}^{p} \frac{r e l_{i}}{\log _{2}(i+1)}=r e l_{1}+\sum_{i=2}^{p} \frac{r e l_{i}}{\log _{2}(i+1)}<br>$$<br><strong>归一化折损累计增益（NDCG）</strong></p><p>归一化之后的折损累积增益，由于搜索的词不同，因此返回的检索数量是不同的，DCG是一个累加值，因此没法针对两个不同的结果进行比较，需要求一个归一化之后的结果：<br>$$<br>\mathrm{nDCG}_{\mathrm{p}}=\frac{D C G_{p}}{I D C G_{p}}<br>$$<br>其中IDCG是理想情况下最大的DCG：<br>$$<br>\mathrm{IDCG}_{\mathrm{p}}=\sum_{i=1}^{|R E L|} \frac{2^{r e l_{i}}-1}{\log _{2}(i+1)}<br>$$<br>即从大到小，取前p个结果组成的集合。</p><p><strong>MAP</strong></p><p>对每个相关文档检索出准确率平均值的算术平均值。首先对每一个query计算一个AP：<br>$$<br>A P=\frac{\sum_{j=1}^{n_{i}} P(j) \cdot y_{i, j}}{\sum_{j=1}^{n_{i}} y_{i, j}}<br>$$<br>$y_{ij}$即每个doc的label（1和0），而每个query-doc pair的P值代表了到$d_{ij}$这个doc所在的位置为止的precision：<br>$$<br>P(j)=\frac{\sum_{k: \pi_{i}(k) \leq \pi_{i}(j)} y_{i, k}}{\pi_{i}(j)}<br>$$<br>其中pi表示排序中的位置。</p><h3 id="Formulation"><a href="#Formulation" class="headerlink" title="Formulation"></a>Formulation</h3><p>通过建立一个损失函数，即经验风险函数，通过最小化这个函数来达到模型训练的目的：<br>$$<br>\hat{R}(F)=\frac{1}{m} \sum_{i=1}^{m} L\left(F\left(\mathbf{x}_{i}\right), \mathbf{y}_{i}\right)<br>$$<br>由于上式优化函数不连续，因此我们寻求一个替代函数，通过优化次优函数得到次优解，替代方案有许多种，可以选择的方法有：</p><p><strong>pointwise loss</strong></p><p>平方误差：<br>$$<br>L^{\prime}(F(\mathbf{x}), \mathbf{y})=\sum_{i=1}^{n}\left(f\left(x_{i}\right)-y_{i}\right)^{2}<br>$$<br><strong>pairwise loss</strong></p><p>例如hinge loss，exponential loss，logistic loss等<br>$$<br>L^{\prime}(F(\mathbf{x}), \mathbf{y})=\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \phi\left(\operatorname{sign}\left(y_{i}-y_{j}\right), f\left(x_{i}\right)-f\left(x_{j}\right)\right)<br>$$<br><strong>listwise loss</strong><br>$$<br>L^{\prime}(F(\mathbf{x}), \mathbf{y})=\exp (-N D C G)<br>$$</p><h3 id="Learn-To-Rank"><a href="#Learn-To-Rank" class="headerlink" title="Learn To Rank"></a>Learn To Rank</h3><p><strong>pointwise：</strong>输入数据为单个doc以及query</p><p><strong>pairwise：</strong>输入数据为同一个query对应的两个doc，以及query</p><p><strong>listwise：</strong>输入数据为同一个query对应的若干doc，以及query</p><p>pointwise和pairwise方法将排序问题转化为classification，regression，ordinal classification等问题。而listwise方法则将一个ranking list作为一个instance来进行训练，其实会考虑每个query下所有doc之间的顺序关系。</p><p>这三种类型的Learning to Rank方法的具体算法一般有：</p><p>1) <strong>Pointwise</strong>: Subset Ranking, McRank, Prank, OC SVM</p><p>2) <strong>Pairwise</strong>: Ranking SVM, RankBoost, RankNet, GBRank, IR SVM, Lambda Rank, LambdaMart</p><p>3) <strong>Listwise</strong>: ListNet, ListMLE, AdaRank, SVM MAP, Soft Rank</p><p><strong>inference</strong></p><p>本文为学习笔记，参考如下网页：<a href="https://www.cnblogs.com/bentuwuying/p/6681943.html" target="_blank" rel="noopener">https://www.cnblogs.com/bentuwuying/p/6681943.html</a></p>]]></content>
      
      
      <categories>
          
          <category> webSearch </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</title>
      <link href="/2020/02/05/OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/"/>
      <url>/2020/02/05/OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是2017年发表在CVPR上，作者开源了代码openpose，openpose代码完整，在推动人体识别，起到了巨大的作用。</p><a id="more"></a><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>人体姿态估计</strong>是理解视频图像的一个核心问题，一种比较简单的方法是two-step的框架，首先检测出图像中的人，然后解决人体姿态估计的问题。这种方法的问题在于，算法执行时间与图片中的人数呈正比，同时若第一步未检出行人，将会出现比较严重的漏检。</p><p>这篇文章提出一种<strong>bottom-up approach</strong>，这种方法检测出人体的部分，然后parsing成人体姿态的结果。这种方法执行时间与人数无关。</p><h3 id="architecture-网络框架"><a href="#architecture-网络框架" class="headerlink" title="architecture 网络框架"></a>architecture 网络框架</h3><p><img src="/images/nlp/image-20200205200758114.png" alt="image-20200205200758114" style="zoom:50%;"></p><ul><li>首先通过baseline10层的VGG-19网络，生成feature map</li><li>将feature map 分为两路，通过多层的CNN生成：<ul><li><strong>a set of Part Confidence Maps</strong> 身体部位的置信度</li><li><strong>a set of Part Affinity Fields (PAFs)</strong> 部位亲和场</li></ul></li><li><strong>Part Confidence Maps</strong>: a set of 2D confidence maps <strong>S</strong> for body part locations. Each joint location has a map.也就是说，每一个节点都对应了一张map，如果有25个节点的时候，就会有25张map。</li><li><strong>Part Affinity Fields (PAFs)</strong>: a set of 2D vector fields <strong>L</strong> which encodes the degree of association between parts.  生成parts之间的单位向量场。</li><li>Finally, the <strong>Confidence Maps</strong> and <strong>Part Affinity Fields</strong> are processed by a greedy algorithm to obtain the poses for each person in the image 联合置信图以及亲合场得出图像中每一个人的pose</li></ul><h3 id="confidence-maps"><a href="#confidence-maps" class="headerlink" title="confidence maps"></a>confidence maps</h3><p>置信图指的是一张2D表示的置信度图，可以定位到图像中关节点的像素上。</p><p>令$J$作为人体的的关节点总数，confidence map如下：<br>$$<br>\text { the set } S=\left(S_{1}, S_{2}, \ldots, S_{J}\right) \text { where } S_{j} \in R^{w \times h}, j \in 1 \ldots J<br>$$<br>总的来说，每一张map都对应一个节点，并且与输入的图片有着相同的size。</p><h3 id="Part-Affinity-Fields（PAFs）"><a href="#Part-Affinity-Fields（PAFs）" class="headerlink" title="Part Affinity Fields（PAFs）"></a>Part Affinity Fields（PAFs）</h3><p>PAF指的是流向量场，流向量场用来编码第一部分成对的关节点对，例如nose，neck，elbow等等：<br>$$<br>\text { the set } L=\left(L_{1}, L_{2}, \ldots, L_{C}\right) \text { where } L_{c} \in R^{w \times h \times 2}, c \in 1 \ldots C<br>$$<br>如果一个点在他的body part上（腿），那么这个点的值是一个2D单位向量，从起点joint指向终点的joint。</p><p><img src="/images/nlp/image-20200206214339000.png" alt="image-20200206214339000" style="zoom:40%;"></p><p>如上所述，整个流程分成两个步骤，第一个阶段生成PAF流向量场，第二个向量生成关节点密度场。</p><h3 id="Multi-Person-Parsing-using-PAFs"><a href="#Multi-Person-Parsing-using-PAFs" class="headerlink" title="Multi-Person Parsing using PAFs"></a>Multi-Person Parsing using PAFs</h3><p>从图像中找出人体姿态的步骤如下：</p><ul><li><strong>Step 1</strong>: Find <strong>all joints</strong> locations using the <strong>confidence maps</strong>.</li><li><strong>Step 2</strong>: Find which joints go together to <strong>form limbs (body parts)</strong> using the <strong>part affinity fields</strong> and joints in step 1.</li><li><strong>Step 3</strong>: <strong>Associate limbs that belong to the same person</strong> and get the final list of human poses.</li></ul><h3 id="如何生成人体limb"><a href="#如何生成人体limb" class="headerlink" title="如何生成人体limb"></a>如何生成人体limb</h3><ul><li>首先将生成的PAFs放大到输入的尺寸，</li><li>对于每一个limb类型，例如对wrist_elbow：<ul><li>从深度图中拿到所有的wrist和elbow的关节点的位置</li><li>对每一个起点peak和终点peak：<ul><li>用终点减去起点，然后归一化之后得到单位方向向量</li><li>每一对起点和终点之间的点，计算他们的PAFs的值</li><li>通过这中间所有点的PAFs值得平均值，计算当前limb connection的score</li><li>添加一个score来惩罚long distance：<code>min(0.5*paf_height/limb_dist - 1,0)</code></li><li>添加当前的limb连接到limb connecton candidate中</li></ul></li><li>对limb connection candidate进行排序</li><li>对于每一个候选连接，如果source和destination未被选中，则添加这个connection到最终的list当中</li></ul></li></ul><h3 id="pytorch-implementaton"><a href="#pytorch-implementaton" class="headerlink" title="pytorch implementaton"></a>pytorch implementaton</h3><p>giithub链接：https:/github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation</p><h3 id="preference"><a href="#preference" class="headerlink" title="preference"></a>preference</h3><ul><li><a href="https://blog.csdn.net/qq_14845119/article/details/98192997" target="_blank" rel="noopener">https:/towardsdatascience.com/cvpr-2017-openpose-realtime-multi-person-2d-pose-estimation-using-part-affinity-fields-f2ce18d720e8</a></li><li><a href="https://blog.csdn.net/qq_14845119/article/details/98192997" target="_blank" rel="noopener">https://blog.csdn.net/qq_14845119/article/details/98192997</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯法(4)</title>
      <link href="/2020/01/30/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95-4/"/>
      <url>/2020/01/30/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95-4/</url>
      
        <content type="html"><![CDATA[<p>《统计学习方法》第4章 朴素贝叶斯法</p><p>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法，对于给定的数据集，首先基于特征条件独立假设学习输入、输出的联合概率分布。对于给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。<br>$$<br>P\left(\omega_{i} | \mathbf{x}\right)=\frac{p\left(\mathbf{x} | \omega_{i}\right) P\left(\omega_{i}\right)}{p(\mathbf{x})}=\frac{p\left(\mathbf{x} | \omega_{i}\right) P\left(\omega_{i}\right)}{\sum_{i=1}^{c} p\left(\mathbf{x} | \omega_{j}\right) P\left(\omega_{j}\right)}<br>$$<br>将后验问题转化为先验的形式。</p><a id="more"></a><h3 id="贝叶斯用于模式分类"><a href="#贝叶斯用于模式分类" class="headerlink" title="贝叶斯用于模式分类"></a>贝叶斯用于模式分类</h3><p><img src="/images/nlp/image-20200130155020167.png" alt="image-20200130155020167" style="zoom:50%;"></p><p><strong>通过上述分类器设计的方法，拼凑出贝叶斯公式的右半部分，贝叶斯决策的关键在于得到一个准确的类先验概率</strong>。</p><h3 id="类先验的概率密度估计"><a href="#类先验的概率密度估计" class="headerlink" title="类先验的概率密度估计"></a>类先验的概率密度估计</h3><p>概率密度估计也是一个非常重要的研究方向，通常有三种方法：</p><ul><li>参数法：假定类先验的概率密度已知，如高斯分布</li><li>非参数法：parzen窗，k-nn等</li><li>半参数法：混合高斯分布（GM），期望最大化（EM）</li></ul><p><strong>高斯分布的一些知识点</strong></p><p>一维高斯分布：<br>$$<br>p(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right]<br>$$<br>混合高斯分布如下：</p><p><img src="/images/nlp/image-20200130161716499.png" alt="image-20200130161716499" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200130162547374.png" alt="image-20200130162547374" style="zoom:50%;"></p><p>当数据分布符合高斯分布的时候，可以认为概率密度函数符合高斯分布：</p><p><img src="/images/nlp/image-20200130163925001.png" alt="image-20200130163925001" style="zoom:50%;"></p><p>从而得到类的后验概率的估计。</p><h3 id="离散变量贝叶斯决策"><a href="#离散变量贝叶斯决策" class="headerlink" title="离散变量贝叶斯决策"></a>离散变量贝叶斯决策</h3><p>此类问题例如问卷调查，医疗诊断等问题。</p><p><strong>独立二值特征</strong></p><p><img src="/images/nlp/image-20200131200632117.png" alt="image-20200131200632117" style="zoom:50%;"></p><p>二值特征的特点是两个特征之间相互独立，因此概率值为相乘：<br>$$<br>p^{x_i}_i(1-q_i)^{1-x_i}<br>$$<br><strong>复合模式分类</strong></p><p><img src="/images/nlp/image-20200131203920471.png" alt="image-20200131203920471" style="zoom:50%;"></p><h3 id="最大似然和贝叶斯参数估计"><a href="#最大似然和贝叶斯参数估计" class="headerlink" title="最大似然和贝叶斯参数估计"></a>最大似然和贝叶斯参数估计</h3><p><strong>参数估计</strong></p><p>给定分类器结构和函数形式，从而训练样本估计参数。使用最大似然（maximum likehood），贝叶斯估计（bayesian estimation）来估计模型的参数。</p><p><strong>最大似然估计</strong></p><p>最大似然估计的前提是默认知道了模型的形式。</p><p><img src="/images/nlp/image-20200131205146516.png" alt="image-20200131205146516" style="zoom:50%;"></p><p>最大似然估计的原理如上，样本间分布相互独立，概率密度的格式为：$p(x|w_i,\theta_i)$，通过估计参数$\theta$得出最后的结果，原理如下：</p><p><img src="/images/nlp/image-20200131212844576.png" alt="image-20200131212844576" style="zoom:50%;"></p><p>最大似然公式，通过最大求导令导数为零的方式来计算模型参数如下。</p><p><img src="/images/nlp/image-20200131215730451.png" alt="image-20200131215730451" style="zoom:50%;"></p><p>举个例子，概率密度函数形式为高斯混合函数：</p><p><img src="/images/nlp/image-20200131220410254.png" alt="image-20200131220410254" style="zoom:50%;"></p><p>通过求导数为0的方式，计算出模型的关键参数为 $\mu$ 以及 $\sum$ ，计算过程如下：</p><p><img src="/images/nlp/image-20200131222132022.png" alt="image-20200131222132022" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200131222144463.png" alt="image-20200131222144463" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200201151054278.png" alt="image-20200201151054278" style="zoom:60%;"></p><p><strong>贝叶斯参数估计</strong></p><p><img src="/images/nlp/image-20200131234433018.png" alt="image-20200131234433018" style="zoom:50%;"></p><p>主要原理是假设已经知道先验，用贝叶斯公式去估计模型的参数的后验分布，通常对于一些服从高斯分布的数据适用。</p><p><img src="/images/nlp/image-20200131234727931.png" alt="image-20200131234727931" style="zoom:50%;"></p><p>贝叶斯估计的步骤以及需要的条件。</p><p><img src="/images/nlp/image-20200201151321933.png" alt="image-20200201151321933" style="zoom:60%;"></p><p><strong>最大似然估计和贝叶斯估计的区别</strong></p><blockquote><p>最大似然估计和贝叶斯估计最大区别便在于估计的参数不同，最大似然估计要估计的参数θ被当作是固定形式的一个未知变量，然后我们结合真实数据通过最大化似然函数来求解这个固定形式的未知变量！</p></blockquote><blockquote><p>贝叶斯估计则是将参数视为是有某种已知先验分布的随机变量，意思便是这个参数他不是一个固定的未知数，而是符合一定先验分布如：随机变量θ符合正态分布等！那么在贝叶斯估计中除了类条件概率密度p(x|w)符合一定的先验分布，参数θ也符合一定的先验分布。我们通过贝叶斯规则将参数的先验分布转化成后验分布进行求解！</p></blockquote><h3 id="期望最大法EM"><a href="#期望最大法EM" class="headerlink" title="期望最大法EM"></a>期望最大法EM</h3><p><img src="/images/nlp/image-20200201153104416.png" alt="image-20200201153104416" style="zoom:50%;"></p><p>数据存在好数据以及bad数据，通过以及的参数，以及好的数据，共同来对缺失数据求期望。</p><p><img src="/images/nlp/image-20200201153235737.png" alt="image-20200201153235737" style="zoom:50%;"></p><p>步骤如上，首先计算预测函数的期望E。M步计算期望函数的最大化结果，直到模型性能提升程度小于阈值。</p><p>EM算法在高斯模型上的使用步骤：</p><p><img src="/images/nlp/image-20200201154032629.png" alt="image-20200201154032629" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200201154122745.png" alt="image-20200201154122745" style="zoom:50%;"></p><h3 id="隐形马尔科夫模型"><a href="#隐形马尔科夫模型" class="headerlink" title="隐形马尔科夫模型"></a>隐形马尔科夫模型</h3><p>硬性马尔科夫模型是统计模型，用来描述一个含有未知参数的马尔科夫过程，其难点是从观测到的结果或参数中获得该过程的隐含参数，下面举个例子来说明：</p><p><img src="/images/nlp/image-20200201163743843.png" alt="image-20200201163743843" style="zoom:50%;"></p><p>我们有以上三种骰子，假设我们开始掷骰子，随机挑选骰子后记录得到的数字，最后得到的结果为一串3数字序列：1 6 3 5 2 7 3 5 2 4</p><p>这串数字叫做<strong>可见状态链</strong>，此外还有一个<strong>隐含的状态链</strong>，即选择骰子的序号：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8。</p><p>马尔科夫链其实指的是这个隐含状态链，每个状态之间存在一个<strong>转换概率</strong>，例如D6后面下一个状态的概率都是1/3，其实我们也可以人为的设置骰子之间的转换概率。此外还有一个<strong>输出概率</strong>的概念，即在隐含状态和可见状态之间的输出概率。即D6骰子输出一个数字的概率是1/6，这个输出概率我们也是可以设置的。</p><p><img src="/images/nlp/image-20200201164743562.png" alt="image-20200201164743562" style="zoom:50%;"></p><p>通常我们在应用hhm的时候，这些状态信息是存在缺失的，因此hhm模型相关的算法主要分为三类：</p><ul><li><strong>知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道每次掷出来的都是哪种骰子（隐含状态链）</strong><ul><li>这个问题在语音识别领域称为解码问题，一种解法是求最大似然状态路径，即求一串骰子序列，该序列输出该观测结果的概率最大</li><li>第二种解法是求每次掷骰子是哪种骰子的概率。</li></ul></li><li><strong>知道骰子有几种（隐含状态数量），每种骰子是什么 （转换概率），根据掷骰子掷出的结果（可见状态链），我想知道掷出这个结果的概率。</strong> <ul><li>即根据模型去求解当前输出结果的概率大小，判断模型是否和数据相互匹配</li></ul></li><li><strong>知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），观测到很多次掷骰子的结果 （可见状态链 ），我想反推出每种骰子是什么（转换概率）</strong><ul><li>这是个很常见的问题，根据可观测到的大量的可见状态链，去反推hhm模型中的参数，极可能是骰子的转换概率等</li></ul></li></ul><p><strong>破解骰子序列问题</strong></p><p><strong>求解最大似然路径问题：</strong>已知到骰子的结果序列，但是不知道用了哪种骰子，最简单的方法就是穷举从中选择最大概率序列。另一种选择方法为：<strong>viterbi algorithm</strong></p><p><strong>viterbi algorithm</strong></p><p>每次计算产生结果的骰子的序号时，选择最大概率的骰子作为当前位置上的骰子。我们发现，我们要求最大概率骰子序列时要做这么几件事情。首先，不管序列多长，要从序列长度为1算起，算序列长度为1时取到每个骰子的最大概率。然后，逐渐增加长度，每增加一次长度，重新算一遍在这个长度下最后一个位置取到每个骰子的最大概率。因为上一个长度下的取到每个骰子的最大概率都算过了，重新计算的话其实不难。当我们算到最后一位时，就知道最后一位是哪个骰子的概率最大了。然后，我们要把对应这个最大概率的序列从后往前推出来。<strong>只有算到最后，计算出最大的序列概率之后，才能确定序列上骰子是哪个。</strong></p><p><strong>谁动了骰子的问题</strong></p><p>当出现一段序列，你怀疑骰子被别人动过手脚，因此我们需要计算一下有问题骰子出现这段序列的概率是多少，正常的骰子出现这段序列的概率是多少。计算这段序列的概率就是所有结果的加和。计算这个问题的方法叫做<strong>forward algorithm</strong></p><p><strong>forward algorithm</strong></p><p>前向算法的计算方法为计算可能产生这个序列的所有的骰子的概率之和。例如这个三个骰子的情况，所有的概率之和计算如下：</p><p><img src="/images/nlp/image-20200202144838271.png" alt="image-20200202144838271" style="zoom:50%;"></p><p><strong>hhm总结</strong></p><p>以上两种方法，viterbi 以及forward算法一种计算序列上的最短路径，一种是计算产生所有的结果可能的骰子序列概率的加和算法。</p><h3 id="非参数方法"><a href="#非参数方法" class="headerlink" title="非参数方法"></a>非参数方法</h3><p><img src="/images/nlp/image-20200202150246277.png" alt="image-20200202150246277" style="zoom:50%;"></p><p>常用的密度估计算法如下：</p><p><img src="/images/nlp/image-20200202150336756.png" alt="image-20200202150336756" style="zoom:50%;"></p><p><strong>parzen window</strong></p><p><img src="/images/nlp/image-20200202151729629.png" alt="image-20200202151729629" style="zoom:50%;"></p><p>如上式，利用parzen window计算样本的概率密度分布，其中$h_n$为超参数。</p><p><img src="/images/nlp/image-20200202152404784.png" alt="image-20200202152404784" style="zoom:50%;"></p><p><strong>k近邻估计</strong></p><p><img src="/images/nlp/image-20200202152640531.png" alt="image-20200202152640531" style="zoom:50%;"></p><p>当收敛条件满足时，趋近于贝叶斯错误率。当k的个数为1时：</p><p><img src="/images/nlp//image-20200202152902374.png" alt="image-20200202152902374" style="zoom:50%;"></p><p><img src="/images/nlp/image-20200202153225602.png" alt="image-20200202153225602" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>k近邻法(3)</title>
      <link href="/2020/01/29/k%E8%BF%91%E9%82%BB%E6%B3%95-3/"/>
      <url>/2020/01/29/k%E8%BF%91%E9%82%BB%E6%B3%95-3/</url>
      
        <content type="html"><![CDATA[<p>《统计学习方法》第三章 k近邻法</p><a id="more"></a><h3 id="k近邻模型"><a href="#k近邻模型" class="headerlink" title="k近邻模型"></a>k近邻模型</h3><p>k近邻算法是一类基本的分类回归方法，假定给定一个训练数据集，其中实例类别已定，对新的实例，根据其k个最近邻的训练实例的类别通过多数表决等方式进行预测。其中k值得选择，距离度量以及分类决策规则是k近邻法的三个基本要素：</p><ul><li><p>优点</p><ul><li>精度高</li><li>对异常值不敏感</li><li>无数据输入假定</li></ul></li><li><p>缺点</p><ul><li>计算复杂度高</li><li>空间复杂度高</li></ul></li><li><p>适用数据范围</p><ul><li>数值型和标称型</li></ul></li></ul><p><strong>工作原理</strong></p><p>存在一个数据集，且数据集中样本与标签存在一一对应的关系，输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签作为新数据的分类类别。</p><p><strong>距离量度</strong></p><p>我们在确定两个向量是否属于同一类别的时候，我们需要利用一个距离量度来决定该实例的类别，距离定义方式有以下几种：</p><p>$L_p$距离：<br>$$<br>L_{p}\left(x_{i}, x_{j}\right)=\left(\sum_{l=1}^{n}\left|x_{i}^{(l)}-x_{j}^{(l)}\right|^{p}\right)^{\frac{1}{p}}<br>$$<br>欧氏距离，L1以及L无穷距离：<br>$$<br>\begin{aligned} L_{2}\left(x_{i}, x_{j}\right) &amp;=\left(\sum_{l=1}^{n}\left|x_{i}^{(l)}-x_{j}^{(l)}\right|^{2}\right)^{\frac{1}{2}} \ L_{1}\left(x_{i}, x_{j}\right) &amp;=\sum_{l=1}^{n}\left|x_{i}^{(l)}-x_{j}^{(l)}\right| \ L_{\infty}\left(x_{i}, x_{j}\right) &amp;=\max _{l}\left|x_{i}^{(l)}-x_{j}^{(l)}\right| \end{aligned}<br>$$<br><strong>k值选择</strong></p><ul><li><p>如果选择较小的K值</p><ul><li>学 习”的近似误差（approximation error)会减小，但 “学习”的估计误差（estimation error) 会增大</li><li>噪声敏感</li><li>K值的减小就意味着整体模型变得复杂，容易发生过 拟合</li></ul></li><li><p>如果选择较大的K值</p><ul><li>减少学习的估计误差，但缺点是学习的近似误差会增大.</li><li>K值的增大 就意味着整体的模型变得简单.</li></ul></li></ul><h3 id="KD-tree"><a href="#KD-tree" class="headerlink" title="KD tree"></a>KD tree</h3><p>实现k近邻法时，主要考虑的问题是如何对训练数据进行快速k近邻搜索，为了提高这种搜索的效率，可以考虑使用特殊的结构存储训练数据，以减少计算距离的次数，一个常用的存储结构就是kd tree。</p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>感知机(2)</title>
      <link href="/2020/01/29/%E6%84%9F%E7%9F%A5%E6%9C%BA-2/"/>
      <url>/2020/01/29/%E6%84%9F%E7%9F%A5%E6%9C%BA-2/</url>
      
        <content type="html"><![CDATA[<p>《统计学习方法》第二章《感知机》</p><a id="more"></a><h3 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h3><p>感知机是一个二分类线性分类模型，输入为实例特征向量，输出为1或-1。感知器对应输出空间中将实例划分为正负两类。</p><ul><li>输入为实例的特征向量，输出为实例的类别，取+1和-1；</li><li>感知机对应于输入空间中将实例划分为正负两类的分离超平面，属于判别模型；</li><li>导入基于误分类的损失函数；</li><li>利用梯度下降法对损失函数进行极小化；</li><li>感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式；</li></ul><p>感知机函数如下：<br>$$<br>f(x)=\operatorname{sign}(w \cdot x+b)<br>$$<br>其中w为模型参数，b为偏置。</p><p><img src="../images/nlp/image-20200129004532357.png" alt="image-20200129004532357" style="zoom:50%;"></p><h3 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h3><p>通过定义一个损失函数，来达到感知机的学习的目的。我们选择误分点到分界点的距离作为损失函数，误分点到超平面的距离为：<br>$$<br>\frac{1}{|w|}\left|w \cdot x_{0}+b\right|<br>$$<br>误分点的性质为：<br>$$<br>-y_{i}\left(w \cdot x_{i}+b\right)&gt;0<br>$$<br>因此损失函数为所有误分点的距离集合：<br>$$<br>-\frac{1}{|w|} \sum_{x_{i} \in \mathcal{M}} y_{i}\left(w \cdot x_{i}+b\right)<br>$$<br>其中前面的系数可以忽略。</p><h3 id="感知机的学习算法"><a href="#感知机的学习算法" class="headerlink" title="感知机的学习算法"></a>感知机的学习算法</h3><p>通过随机梯度下降法，分别对w和b进行求导，得到下一步参数的更新：<br>$$<br>\nabla_{w} L(w, b)=-\sum_{x_{i} \in M} y_{i} x_{i} \quad \nabla_{b} L(w, b)=-\sum_{x_{i}, m} y_{i}<br>$$</p><p>$$<br>w \leftarrow w+\eta y_{i} x_{i} \quad b \leftarrow b+\eta y_{i}<br>$$</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>还有一些算法优化的可行性验证这里就忽略了。</p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>统计学习方法概述</title>
      <link href="/2020/01/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0/"/>
      <url>/2020/01/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p>第一章 《统计学习方法概论》</p><p>这一部分介绍了统计学习的一些基本概念，基本问题，基本方法等，作为统计学习的一个引入。</p><p>写《统计学习方法》这个系列博客的目的在于在找工作前，对机器学习方法重新温顾一下，在肺炎国难当前，争分夺秒，把这本书看完！</p><p>这本书在网上有着广泛的讨论，笔记，代码一应俱全，因此这个系列将会参考这些资料：</p><ul><li><a href="https://github.com/SmirkCao/Lihang" target="_blank" rel="noopener">https://github.com/SmirkCao/Lihang</a> （笔记）</li><li><a href="https://www.jiqizhixin.com/articles/2019-11-11-15" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2019-11-11-15</a> （课件）</li><li><a href="https://github.com/fengdu78/lihang-code" target="_blank" rel="noopener">https://github.com/fengdu78/lihang-code</a> （代码）</li></ul><a id="more"></a><h3 id="部分符号"><a href="#部分符号" class="headerlink" title="部分符号"></a>部分符号</h3><p>$H$: 希尔伯特空间</p><ul><li>希尔伯特空间 = 无限维+度量+线性+范数+内积 = 无限维 + 欧几里得空间</li></ul><h3 id="统计学习"><a href="#统计学习" class="headerlink" title="统计学习"></a>统计学习</h3><p><strong>特点</strong></p><p>基于数据构建概率统计模型，并运用该模型进行预测与分析的一门学科。是基于数据驱动的。</p><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p><strong>基本概念</strong></p><p><strong>输入空间、特征空间、输出空间</strong></p><p>输入空间指输入的数据的集合；特征空间指所有特征向量所存在的空间；输出空间指输出的集合所在的空间。</p><p><strong>联合概率分布</strong></p><p>监督学习假设输入与输出遵循联合概率分布$P(X,Y)$函数。</p><p><strong>假设空间</strong></p><p>监督学习的目的在于学习一个由输入到输出的一个映射。映射就是有模型来表示的。假设空间就是所有的映射的集合，我们的目的就是找到最好的一个映射。</p><p><strong>问题的形式化</strong></p><p>通过成对的数据样本，学习一个函数映射，即条件概率分布（决策函数）$P(Y|X)$，该函数描述了输入与输出随机变量之间的映射关系。</p><h3 id="统计学习三要素"><a href="#统计学习三要素" class="headerlink" title="统计学习三要素"></a>统计学习三要素</h3><p>方法 = 模型 + 策略 + 算法</p><p><strong>模型</strong></p><p>在监督学习中，<strong>模型就是所要学习的条件概率分布或决策函数</strong>，模型的假设空间包含所有可能的条件概率函数。</p><p><strong>策略</strong></p><p>引入损失函数来度量模型的性能好坏，预测效果越好的模型损失函数的值越小。</p><p>损失函数的期望：<br>$$<br>R_{\mathrm{exp}}(f)=E_{P}[L(Y, f(X))]=\int_{x \times y} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{d} y<br>$$<br>上式是模型$f(x)$关于联合分布$P(X,Y)$的平均意义下的损失，因此我们要最小化损失函数意味着要得到联合概率分布。得到联合概率分布即可得到条件概率，就无需预测了。因此我们希望找到一个近似函数，来解决这个问题：<br>$$<br>R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)<br>$$<br>称为风险函数或期望损失。</p><p><strong>经验风险最小化与结构风险最小化</strong></p><p>经验风险指在训练集上的损失的平均值，经验风险最小化模型：<br>$$<br>\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)<br>$$<br>当样本容量很小的时候，模型优化经验风险最小化会导致模型的<strong>过拟合</strong>发生。</p><p><strong>结构风险最小化</strong> structure risk minimization，为防止过拟合提出的策略，等价于正则化（regularization），加入正则化项regularizer，或罚项 penalty term：<br>$$<br>R_{\operatorname{srm}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)<br>$$<br><strong>算法</strong></p><p>算法指模型训练过程中的优化策略。如果最优化问题有显式的解析式，那么这个最优化问题就比较简单，但是通常解析解不存在，这就需要用数值计算的方法去求解。统计学习方法可以利用已有的最优化算法进行模型的优化。</p><h3 id="模型评估与模型选择"><a href="#模型评估与模型选择" class="headerlink" title="模型评估与模型选择"></a>模型评估与模型选择</h3><p>当我们一味追求训练数据上的拟合能力的时候，往往将导致模型发生过拟合。<img src="/images/nlp/image-20200126191036412.png" alt="image-20200126191036412" style="zoom:50%;"></p><p>因此在选择模型的时候，需要在模型的复杂度与预测的误差上做出最优的选择。</p><h3 id="正则化与交叉验证"><a href="#正则化与交叉验证" class="headerlink" title="正则化与交叉验证"></a>正则化与交叉验证</h3><p>模型选择的典型方法是正则化，正则化是结构化方向最小化策略的实现，模型越复杂正则化值就会越大：<br>$$<br>L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}|w|^{2}<br>$$<br><strong>交叉验证</strong></p><p>交叉验证的思想是将数据进行切分，分成训练集，测试集以及验证集等，例如留一验证法等。</p><h3 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h3><p>泛化能力指模型对未知数据的预测结果，可以通过比较两个函数的泛化误差的上界来比较两种方法的好坏。</p><h3 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h3><p>生成模型表示了给定输入X产生Y的生成关系，判别模型给定X，输出X的类别。</p><h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>分类问题即对输入进行分类，分类的评价指标是准确率和召回率。</p><ul><li>TP  true positive</li><li>FN  false negative</li><li>FP  false positive</li><li>TN  true negative</li></ul><p>$$<br>P = \frac{TP}{TP+FP}<br>$$</p><p>$$<br>R = \frac{TP}{TP + FN}<br>$$</p><p>F1 值：<br>$$<br>F_1 = \frac{2TP}{2TP + FP + FN}<br>$$</p><h3 id="标注问题"><a href="#标注问题" class="headerlink" title="标注问题"></a>标注问题</h3><p>输入：观测序列</p><p>输出：标记序列或状态序列</p><p>如对一个长句子的标注。</p><h3 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h3><p>回归问题数据是连续的，同时常常使用著名的最小二乘法来求解。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本章概要的介绍了一下统计学习的各个方法，如果深入到深入学习来说，可以看出来有很多东西没有涉及到，但是对于机器学习基础来说，足够了。</p>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cs224N word vector I</title>
      <link href="/2020/01/09/cs224N-word-vector-I/"/>
      <url>/2020/01/09/cs224N-word-vector-I/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是CS224N winter2019的第一次课的内容，主要针对词的表示，词向量生成的一些方法，从最早到最新，列举了这些算法以及应用。</p><a id="more"></a><h3 id="NLP任务的特殊性"><a href="#NLP任务的特殊性" class="headerlink" title="NLP任务的特殊性"></a>NLP任务的特殊性</h3><p>说道NLP任务的特殊性，其实是针对图像任务来说的。对于图像任务来说，我们所看到的场景通常直接反映了图像中所包含的内涵，同时图像上像素点通常是连续的，对于一个可微分系统求最优化的过程（深度学习的内涵就是构建一个可微分的系统），是天然切合的。</p><p>我们知道NLP最小的单元是词，由众多的词组成句子，形成语义。<strong>对于一个词来说，它在形状上不表示任何的含义，而是指代一种抽象的含义</strong>，因此在理解词含义的时候，我们需要结合上下文，结合语境，诸如LSTM，transformer这种能够获得较长上下文信息的结果在NLP中起到巨大的作用。此外，还存在着大量的一词多义的情形，因此具体的语境，上下文对理解NLP任务显得至关重要。</p><p>另一个显著的不同在于图像色彩在变化上是连续的，而NLP任务中，每个词之间是离散的，不存在连续的关系。因此我们需要对每次词进行适当的编码，转化成连续的词向量的形式。通过这种方式最优化我们的模型，得到NLP任务的解。</p><h3 id="word-vector"><a href="#word-vector" class="headerlink" title="word vector"></a>word vector</h3><p>如何用向量表示词，一个重要的指标是词向量能够反映词之间的相似性和相异性。例如苹果和巧克力，应当比苹果和梨之间的距离要大。下面是自己中词的表示方式：</p><ul><li><strong>同义词的字典：</strong>一个比较直观的解决方法是建立一个同义词的字典，将所有的同义词归类，用字典的方式来表示词，但是这种方式有缺点，我们无法涵盖所有的单词的含义，需要人去维护字典。</li><li><strong>one-hot方式：</strong>采用onehot方式，奖励一个大小为vocab size的向量，在该词的位置为1，其他为0。这种方式的缺点是，需要维护一个巨大的矩阵，同时每个 词之间都是独立的，无法表示不同词的相似性。</li><li><strong>一个词的含义由它周围的词决定：</strong>即一个词的含义应该与他的上下文（fix-window）所决定的。这种利用周围的词来表示当前的词的方式称为词嵌入word-embedding，它实际上是一种分布。</li></ul><p><img src="/images/nlp//image-20200112210153920.png" alt="image-20200112210153920" style="zoom:40%;"></p><h3 id="word-vector-1"><a href="#word-vector-1" class="headerlink" title="word vector"></a>word vector</h3><p>2013年由Mikolov提出，提出利用周围周围的词来预测当前的词：</p><ul><li>一个很大的语料库</li><li>每一个词表示表示成 一个词向量</li><li>遍历句子中的每一个词c</li><li>利用每一个c周围的词（fix-window），来计算c的相似性</li><li>通过迭代，最大化预测c的概率</li></ul><p><img src="/images/nlp//image-20200112214809724.png" alt="image-20200112214809724" style="zoom:50%;"></p><p>构造损失函数如下：</p><p><img src="/images/nlp//image-20200112215013622.png" alt="image-20200112215013622" style="zoom:40%;"></p><p>利用贝叶斯公式，利用前后m个位置的词来预测当前位置词的概率。构造一个负log似然函数，即交叉熵函数，通过最小化交叉熵损失，预测正确的概率最大。</p><p>其中每个词概率的计算p：</p><p><img src="/images/nlp//image-20200112215844822.png" alt="image-20200112215844822" style="zoom:40%;"></p><p>因此对于每一个词来说，同时有两个向量来表示：</p><p><img src="/images/nlp//image-20200112224851890.png" alt="image-20200112224851890" style="zoom:40%;"></p><p>在词的含义由周围词决定的思想下，有着两种模型的变种，一种是CBOW，另一种是skip-gram。</p><h3 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h3><p>Continuous Bag of Words Model,连续的词包模型，将句子挖空，利用其它词来预测当前的词。每个词学习两个向量：</p><ul><li>v：when the word is in the context</li><li>u：when the word is in the center</li></ul><p><img src="/images/nlp//image-20200112230514347.png" alt="image-20200112230514347" style="zoom:50%;"></p><p>如上，我们输入一个长度为字典词数长度的词（可以使onehot形式），然后学习一个从输入到隐变量的一个映射，然后在学一个隐变量到输出的映射。输入时句子中出了挖空的那个单词。最后通过softmax变成概率之后，最优化交叉熵损失，得到最优的结果。</p><h3 id="skip-gram-model"><a href="#skip-gram-model" class="headerlink" title="skip gram model"></a>skip gram model</h3><p>这个模型的思路和CBOW相反，利用一个单词去预测其他周围位置的单词，网路结构如下：</p><p><img src="/images/nlp//image-20200112231300222.png" alt="image-20200112231300222" style="zoom:50%;"></p><p>输入为一个词的onehot，学习两个映射过程，最终得到其周围fix-window内的其他词的预测结果，其过程与CBOW类似。</p><p>上述的两个模型中，均是三层结构，隐藏层维度为我们希望的词向量的长度，从输入到隐藏层之间的映射参数即为词典长度x词向量长度的一个矩阵，即我们所要的wordvec。</p><h3 id="negative-sampling"><a href="#negative-sampling" class="headerlink" title="negative sampling"></a>negative sampling</h3><p>在训练神经网络时，每当接受一个训练样本，然后调整所有神经单元权重参数，来使神经网络预测更加准确。换句话说，每个训练样本都将会调整所有神经网络中的参数。<br> 我们词汇表的大小决定了我们skip-gram 神经网络将会有一个非常大的权重参数，并且所有的权重参数会随着数十亿训练样本不断调整。</p><p>negative sampling  每次让一个训练样本仅仅更新一小部分的权重参数，从而降低梯度下降过程中的计算量。<br> 如果 vocabulary 大小为1万时， 当输入样本 ( “fox”, “quick”) 到神经网络时， “ fox” 经过 one-hot 编码，在输出层我们期望对应 “quick” 单词的那个神经元结点输出 1，其余 9999 个都应该输出 0。在这里，这9999个我们期望输出为0的神经元结点所对应的单词我们为 negative word.   negative sampling 的想法也很直接 ，将随机选择一小部分的 negative words，比如选 10个 negative words 来更新对应的权重参数。（选择onehot中为0的一部分数参与模型的更新。）</p><p>在论文中作者指出指出对于小规模数据集，建议选择 5-20 个 negative words，对于大规模数据集选择 2-5个 negative words.</p><p>如果使用了 negative sampling 仅仅去更新positive word- “quick” 和选择的其他 10 个negative words 的结点对应的权重，共计 11 个输出神经元，相当于每次只更新 300 x 11 = 3300 个权重参数。对于 3百万 的权重来说，相当于只计算了千分之一的权重，这样计算效率就大幅度提高。</p><p><strong>如何选择负样本</strong></p><p>一个词是否会被选择为负样本与其出现的频率有关，出现的频次越高，越容易被当成负样本：</p><p><img src="/images/nlp//image-20200112233855262.png" alt="image-20200112233855262" style="zoom:50%;"></p><p>经过实验，当这个数为3/4的时候，模型表现最好。</p><h3 id="hierarchical-softmax"><a href="#hierarchical-softmax" class="headerlink" title="hierarchical softmax"></a>hierarchical softmax</h3><p>层次softmax是另一种优化模型计算的方法，他的思路借鉴了huffman树的思想，出现越是频繁的树，他出现的位置越浅。哈夫曼树每一个叶子节点表示一个类别，每个非叶子节点需要做一次二分类，走左边后走右边的概率用逻辑回归来表示：</p><p><img src="/images/nlp//image-20200113002246268.png" alt="image-20200113002246268" style="zoom:50%;"></p><p>如何降低复杂度呢，当k为词个数时,h为维度，可以将复杂度降到 $O(hlog_2(k))$。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上便是wordvec的表示方法，即解决了NLP的一个最基本，最重要的问题，词的表示。我们利用CBOW，skip-gram等模型，在优化模型的过程中，得到了词到向量的一个映射关系，这个关系就是wordvec的一个映射矩阵，有了这个矩阵我们就可以将词转化成向量。此时向量是根据其前后的单词而产生的，因此此位置的单词是根据前后的词而产生。下面一篇post将介绍wordvec更深层的东西，wordsence。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>2019！2020！</title>
      <link href="/2020/01/01/2019%EF%BC%812020%EF%BC%81/"/>
      <url>/2020/01/01/2019%EF%BC%812020%EF%BC%81/</url>
      
        <content type="html"><![CDATA[<p>2019年的最后几天，我在想给这一年打上一个什么样的标签，让我十几二十年后还能想起来这一年。确实是，我记不清过去的二十几年，唯一的感触剩下时间匆匆。</p><p>2019年1月份，和xu在北大三教的咖啡厅搭了这个网站，与此同时进行的还有刷算法题，准备着一些东西。再往前推几天，我匆匆完成了研一上最后的考试，连夜收拾行李进城。和yingying在雁栖湖有很多美好的回忆，可惜那些事情发生在2018年了，2018年对我来说是煎熬的一年，有一种引力阻止我思考里头究竟发生了什么事情。不过最令我开心的是在2018年结束的时候，我收获了很多宝贵的友谊。</p><p>所以我想，我不能在失去2019年了。</p><p>让我努力回忆几件事情，把一年的生活串起来。</p><p><strong>第一件事情</strong>，2019年新年在2月5号，过完春节我提前了两周时间回到雁栖湖。北京大雪后不久，校园里寂静的景象让我震惊，整个雁栖湖被雪裹住，我拖着行李箱，踏出一条雪路。接下来一个月我把时间安排的满满当当，这段时间，自我怀疑、喝鸡汤、再次怀疑循环往复。这段经历给我的启发很多，我愿意把它写出来：</p><ul><li>制定一个目标每时每刻努力着，这个过程是非常充实且令人满足的。结果反而是其次</li><li>目标明确的好处是知道自己要干什么，坏处是焦虑越来越严重</li></ul><p><strong>第二件事，</strong>我开始慢慢窥探自己的性格。事情讲起来很琐碎，我意识到自己在很多不确定的事情面前，显得唯唯诺诺，不敢承担责任。和老板聊到这件事情让我感触颇深，也对老板充满了感激。我在此总结一下导师给我的帮助：一个人自信与否在于他看待问题的角度，林彪认为一场战役七层胜算则可以打，粟裕有四层胜算便胸有成竹，侃侃而谈。</p><p>所以我大可不必这样的担心，也由此我摆脱了大部分的焦虑。后来才意识到，突破自己是困难的，很大一部分原因是无法找到问题的关键。此刻我很需要这样的信心，我也感到自己有了长足的进步。给人以正能量，给人以信心！</p><p>另一方面是自我意识的觉醒，顺从应当是我从小到大的习惯，当我发现我讨厌这样的自己，我会刻意去做一些改变，我会愿意决定一些事情，事先想好事情的应对方案。在这件事情上我还不够好。</p><p><strong>第三件事，</strong>生活需要理想，信仰。如果物质追求成为生活的目标时，生活是沉重且乏味的。而后读了《乔布斯传》，发现在物质之上，有着一群人，在追逐着梦想，渴望改变世界，追求着精神上更美好的东西。这对我的冲击是巨大的，我被这些浅显的道理击中，在回头看时，发现这些东西对我是多么的重要。想起来一次去参观腾讯，晚上8点和朋友坐班车回来，看到眼前拥堵的公路，熙熙攘攘的车子仿佛看到了日后无数个上下班的日日夜夜 ，备受打击。但是回头一想，你每天为着心中的理想奋斗，这是多么振奋人心的事情啊！</p><p>嗯，人生是伟大的理想，是诗和远方。</p><p><strong>最后</strong>，以上三件事情能够大致的勾勒出2019的轮廓，也许到我人生快结束的时候，也会有三件事情，勾勒我的一生。毕竟和时间比起来我们都太渺小。2019年很多时候在忙碌，但是真正对我有推动作用的事情却很少，最后还希望记录一些感悟：</p><ul><li>没有一个夜晚允许我们有一点软弱</li><li>永远不要掉队</li><li>人生应当有更高的追求和理想</li><li>相信积累的力量</li><li>阅读能够拯救我的内心，让我体会到真正的快乐</li><li>清醒的认识自己</li><li>展现积极的一面，永远是自己给别人信心</li></ul><p><strong>最后的最后，2020，happy new year!</strong></p><p><strong>2019/12/31</strong></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GPT</title>
      <link href="/2019/12/29/GPT/"/>
      <url>/2019/12/29/GPT/</url>
      
        <content type="html"><![CDATA[<p>GPT在bert出现之前就与我们见面了，它利用了transformer的结构，在众多的任务中，取得了比较好的成绩。GPT的核心思想是 <strong>通过无标签的文本去训练生成语言模型</strong>，根据具体的NLP任务，利用新的数据进行finetune（和bert简直一模一样）。</p><a id="more"></a><h3 id="模型的结构"><a href="#模型的结构" class="headerlink" title="模型的结构"></a>模型的结构</h3><p>模型的结构是使用了多层的单向transformer结构，如下图：</p><p><img src="/images/nlp/v2-fb7be8467a0231607f3f2e4ace92534e_hd.jpg" alt="img"></p><p>GPT即gerneral pre-training 通用预训练语言模型，是一种利用transformer作为特征抽取器，基于语言模型进行训练的预训练语言模型。因此GPT有两个重点，一个是语言模型，另一个是transformer。</p><p><strong>语言模型</strong></p><p>一个语言模型通常可以理解成一句话出现的概率 p(W) 的计算。语言模型利用语料进行训练，训练的目的就是：<strong>计算某个句子出现的概率。</strong>一个句子的概率的计算方式如下：</p><p>对于一个有T个词按顺序构成的句子，P(W)实际上求解的是字符串的<strong>联合概率</strong>，利用贝叶斯公式，链式分解如下：<br>$$<br>\begin{aligned}<br>P\left(W_{1}^{T}\right) &amp;=P\left(\mathrm{w}_{1}, w_{2}, \ldots, w_{T}\right) \\<br>&amp;=P\left(w_{1}\right) P\left(w_{2} | w_{1}\right) P\left(w_{3} | w_{1}, w_{2}\right) \ldots P\left(w_{T} | w_{1}, w_{2}, \ldots w_{T-1}\right)<br>\end{aligned}<br>$$<br>从上面可以看出来，一个统计语言模型可以表示成给定前面的词，求后面的一个词出现的条件概率。当我们在求P(w)的时候，我们就已经建立了一个模型，这里的诸多条件概率就是模型的参数。GPT预训练过程就是利用语料，构造训练数据，利用上述语言模型，不断预测，学习参数的过程。</p><p><strong>GPT结构</strong></p><p>GPT的结构由12个transformer组成，和bert的一个最大的不同在于，他的transformer是单向的，输入为文本token和position信息结合一起后embedding。输入经过12个transformer结果处理之后，到输出层，经过一个lienar层之后，使用softmax进行初始化，随后使得似然最大化（交叉熵的负数最大），得到最后的结果：<br>$$<br>P\left(y | x^{1}, \ldots, x^{m}\right)=\operatorname{softmax}\left(h_{l}^{m} W_{y}\right)<br>$$<br>其中$h_l^m$表示12个transformer输出的结果，W表示linear层的参数，最大化似然，即得到最终的结果：<br>$$<br>L_{2}(\mathcal{C})=\sum_{(x, y)} \log P\left(y | x^{1}, \ldots, x^{m}\right)<br>$$<br><strong>如何使用GPT</strong></p><p>GPT训练过程分为两步，第一步在一个非常大的数据集上进行数据的无监督训练，第二阶段，我们在一个很小的数据集上对模型进行finetune，使用有监督的方法解决特定方向的问题。通过大量的实验，作者发现，只要经过很小的fintune就可以应用到很多不同的任务上。</p><p>第一步使用无监督的方式学习语言本身存在的相关性，训练方式是单向的，模型从左到有，利用已经出现的词，来预测下一个位置上的词。和bert不同，bert使用mask技术，能够学到语言中双向的特征。</p><p>之所以使用unsupervised learning的原因是，标注大量的数据的成本是很高的，同时人工标注的难度也很大。使用无监督的方式可以学到数据之间的相关性。</p><p><strong>GPT和下游任务的结合</strong></p><p><img src="/images/nlp/gpt.jpg" alt="img"></p><p>使用GPT作为pretraining模型，第一步将数据转化成序列结构，如上图输入的组合方式，然后通过修改输出部分的结构，达到网络在多个特定任务上的应用：</p><ul><li>For text classification, we can directly fine-tune the model.</li><li>For textual entailment, we concatenate the premise and hypothesis token sequences, with a delimiter token in between.</li><li>For similarity tasks, since there is no inherent ordering of the two sentences being compared, the input sequence is modified to contain both possible sentence orderings. Each input sequence is processed independently to produce two sequence representations, which are finally added element-wise before being fed into the linear output layer.</li><li>For question answering and commonsense reasoning, we are given a context document zz, a question qq, and a set of possible answers akak. We concatenate the document context and question with each possible answer as [start;z;q;delim;ak;extract]. Each of these sequences are processed independently and then normalized via a softmax layer to produce an output distribution over possible answers.</li></ul><p>上面主要介绍的是输入的组合方式。</p><p><img src="/images/nlp/difference.jpg" alt=""></p><p><strong>bert下游任务</strong></p><p><img src="/images/nlp/fine-tuning.jpg" alt=""></p><h3 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h3><p>GPT-2 是GPT-1的升级版本，它在文本生成上有着惊艳的表现，其<strong>生成的文本在上下文连贯性和情感表达上</strong>都超过了人们对目前阶段语言模型的预期。</p><p>GPT-2有着海量的训练数据，GPT-2结构采用了只有解码器的transformer架构，接下来我们将一起探索GPT-2的应用以及在生成任务中的奥秘。</p><p>语言模型的作用是根据已有的句子的一部分来预测下一个单词是什么。GPT-2使用transformer解码器模块构建，而bert则是通过transformer编码器模块构建，他们之间一个关键的不同在于GPT-2一次只输出一个单词，新的单词产生之后就被添加到单词序列中，作为下一个单词预测的输入。这种机制叫做自回归（auto-regression），诸如TransformerXL和XLNet都是用了自回归，XLNet同时还找到了一种能够同时兼顾前后的上下文信息的方法。</p><p>GPT-2对transformer模块进行了改造，仅仅选择了Decoder的部分：</p><p><img src="/images/nlp/640-1577377624300.webp" alt=""></p><p>即只允许看到当前预测位置左边的单词，transformer结构只允许片段的长度为512，而这种结构可以支持最长1024个单词序列。</p><p><strong>GPT-2的工作流程</strong></p><p>训练一个GPT-2模型，最简单的方法就是让他随机工作。我们随机选择一个单词作为起始单词让它根据我们提供得词生成一段样本（即生成交互式条件样本）。</p><p>此时模型的输入只有一个词，然后经过若干层的transformer，得到一个向量输出。然后将这个向量与词汇表中的每一个单词计算一个概率，我们选择概率最高的一个单词作为下一个单词。GPT-2的词汇表中有50000个单词。</p><p>有时选择top1的方法会出现问题，有时模型可能会陷入一直推荐同一个词的循环中，因此我们在选择下一个词的时候，通常我们从topk个词中按概率随机选择一个（torch.distribution.categorical.Categorical）。</p><p>接下来我们将新增的单词添加在序列的尾部，作为预测下一个单词的输入，GPT-2网络的参数保留了对第一个单词的解释，然后根据这些信息来生成第二个单词。在向后生成的过程中，GPT-2已生成的单词将不会被改变。</p><h3 id="深入GPT-2内部"><a href="#深入GPT-2内部" class="headerlink" title="深入GPT-2内部"></a>深入GPT-2内部</h3><p><strong>输入编码</strong></p><p>GPT-2输入从词嵌入矩阵中查找单词对应的嵌入向量word embedding，该矩阵也是模型训练的一部分：</p><p><img src="/images/nlp/640-1577377615340.webp" alt=""></p><p>模型的大小和词向量的长度有关，词向量长度最小为768。此外我们还需要对输入序列的每一个位置都对应一个位置编码，这些编码矩阵也是训练参数的一部分：</p><p><img src="/images/nlp/640.webp" alt=""></p><p>因此在准备输入数据的时候，我们随机找到一个起始单词，然后根据起始单词，去vocab中转化成词向量，然后加上第一个位置上的位置编码：</p><p><img src="/images/nlp/640-1577377765194.webp" alt=""></p><p>随后序列进入transformer中，transformer中的自注意力机制将每个词与序列中的相关性学习到，体现了transformer超强的特征提取能力。</p><p>对于自注意力机制来说，存在三个矩阵，Key，Query，Value，首先将这三个矩阵与输入相乘，然后得到K，Q，V，可以认为接下来就是找到相互匹配的K，Q（query和key的匹配对），即softmax的值最高，然后乘以V，得到当前词对序列中其他词的相关性的大小：</p><p><img src="/images/nlp/640-1577378601211.webp" alt="img"></p><p><strong>模型输出</strong></p><p>当最后一个transformer输出向量之后，这个向量本质上就会预测词的词向量。我们将这个词向量乘上词嵌入矩阵，得到一个长度为词汇表长度的向量。这个向量每一个位置就表示当前预测位置上的词对词汇表中该位置词的相似概率。</p><p><img src="/images/nlp/640-1577378813143.webp" alt="img"></p><p>然后我们现在top-k（40）个概率，然后从topk中，按照概率大小，选择出一个单词作为当前预测的单词。</p><p><img src="/images/nlp/640-1577378918869.webp" alt="img"></p><p>重复上述的过程，直到生成1024个词，遇到终止符。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>finetune-诗句生成</title>
      <link href="/2019/12/29/finetune-%E8%AF%97%E5%8F%A5%E7%94%9F%E6%88%90/"/>
      <url>/2019/12/29/finetune-%E8%AF%97%E5%8F%A5%E7%94%9F%E6%88%90/</url>
      
        <content type="html"><![CDATA[<p>原先的诗句生成模型仅仅利用了bert language model，而没有去利用诗句语料进行finetune，尽管language model生成的结果已经令人比较满意了。但是我们想知道在特定的数据集上进行finetune的话，结果是否能得到提升，于是这篇post主要完成这个工作：continue training。</p><a id="more"></a><h3 id="pytorch-多卡分布式训练"><a href="#pytorch-多卡分布式训练" class="headerlink" title="pytorch 多卡分布式训练"></a>pytorch 多卡分布式训练</h3><p>关于分布式训练，通常可以使用<strong>DataLoader</strong>，这个wrapper可以方便使用多张卡，而进程只有一个，唯一的问题是这个方法只能满足一台计算机上GPU的通信，对需要使用多个机器，多个GPU的任务无能为力。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net = nn.DataParallel(net)</span><br></pre></td></tr></table></figure><p>以上代码将整个网络分布到多个GPU上。pytorch定义的网络模型参数默认放在GPU 0上，所以dataparallel的时候，实质上是把训练参数从gpu靠背到其他的gpu上同时训练。此时dataloader加载数据的时候，batch_size需要设置成原来batch的n倍，n为gpu的数量。</p><p>如果我们要使用多个机器上的GPU，pytorch依然提供了办法：</p><ul><li><code>torch.utils.parallel.DistributedDataParallel</code>方法：与dataloader类似，用来实现多机多卡分布训练，他可实现在不同机器的多个模型拷贝之间的平均梯度</li><li><code>torch.utils.data.distributed.DistributedSampler</code> 方法：在多机多卡的情况下，每个卡读取的数据显然是不同的，dataparallel的做法是直接将batch切分到不同的卡上。对于多机来说，直接进行数据传输将会耗费很多时间，于是使用distributedSampler，确保每一个dataloader只会load到整个数据集的一个特定子集，避免不同进程之间数据重复</li></ul><p><strong>使用方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataloader,Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.distributed <span class="keyword">import</span> DistributedSampler</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel</span><br><span class="line"></span><br><span class="line">dataset = your_dataset()</span><br><span class="line">datasample =DistributedSampler(dataset,num_replicas=world_size,rank = rank)</span><br><span class="line">dataloader = Dataloader(dataset,batch_size=batch_size_per_gpu,sampler = datasampler)</span><br><span class="line">model = your_model()</span><br><span class="line">model = DistributedDataParallel(model,device_ids = [local_rank],output_device=local_rank)</span><br></pre></td></tr></table></figure><p>在设置dataloader的batch-size的时候，只需要设置单卡的batch-size即可。world_size指进程总数，就是卡的数量，rank是进程编号，local_rank指本地序号。要想使用DistributedDataParallel就需要先完成多进程的初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.distributed.init_process_group()</span><br></pre></td></tr></table></figure><p><img src="/images/nlp/image-20191224122842203.png" alt=""></p><p><img src="/images/nlp/image-20191224122817322.png" alt="image-20191224122817322"></p><p><img src="/images/nlp/image-20191224123807016.png" alt="image-20191224123807016"></p><p><img src="/images/nlp/image-20191224123750444.png" alt="image-20191224123750444"></p><p><img src="/images/nlp/image-20191224124839172.png" alt="image-20191224124839172"></p><p><strong>梯度积累</strong></p><p>梯度累加的步骤如下：</p><ol><li>获取loss，输入图像和标签，通过infer计算得到预测值，计算损失函数</li><li><code>loss.backward()</code> 反向传播，计算当前梯度</li><li>多次循环1-2，不清空梯度，使梯度累加在已有的梯度上</li><li>梯度累加了一定的次数以后，先<code>optimizer.step()</code>根据累计的梯度更新网络参数，然后通过<code>optimizer.zero_grad()</code> 清空过往的梯度，为下一波梯度累加做准备</li></ol><p>梯度累加总结来说就是每次获取一个batch吼不清空梯度，而是累加到一定程度的时候去清空梯度，变相的相当于扩大了batchsize，同时可以避免计算多个损失函数时，存储多个计算图。</p><p><strong>pytorch采样器（dataloader）</strong></p><p>pytorch在加载数据的时候提供了一个sampler模块，这个模块用来对数据进行采样，常用的采样器有<code>RandomSampler</code>，当dataloader中shuffle的参数为true的时候，系统会自动调用这个采样器。dataloader默认使用的采样器为sequentialSampler，即按顺序来进行采样。sampler组织好数据的下标后，在dataloader中将数据取出来。</p><p><strong>pytorch and apex</strong></p><p>pytorch在分布式训练上存在着一些问题：</p><ul><li>混合精度训练难以收敛：pytorch可以方面得将模型转换成fp16，但是训练batchnorm层的时候，又需要转成f32，导致了混合精度，难以优化的问题。</li><li>bn同步的问题，bn同步能够极大的加快模型的收敛，精度也会有所提升，原生的方法一直未能较好地解决</li></ul><p>apex是NVIDIA维护的一个支持</p><p><strong>bert优化器</strong></p><p>bert常使用的优化器有BertAdam，AdamW，FusedAdam（和BertAdam类似，当用到apex时配套当做优化器使用）。Bert的优化器和传统的Adam优化器有什么不同呢，主要的不同有以下两点：</p><ul><li>bertAdam/AdamW 能够固定权重衰减，可用于微调模型</li><li>bertAdam/AdamW 不会对偏差bias进行补偿</li></ul><p><strong>bert loss function</strong></p><p>bert损失函数主要由两部分组成，第一部分来自Mask-LM的单词级别分类任务，另一部分是句子级别的分类任务。通过联合学习，使bert学习到语言中token级别，以及句子级别的语义信息，具体的损失函数如下：</p><p>第一部分的损失函数是mask部分的词的一个多分类问题，词典的大小为分类的大小。第二部分的损失函数是是否是下一句的二分类问题，两个分类函数结合作为最后的loss.</p><p><strong>bert激活函数：gelu</strong></p><p>gelu：高斯误差线性单元，是一种高性能的神经网络激活函数，GELU的非线性变换是一种符合预期的随机正则变换方式：</p><p><img src="/images/nlp/image-20191224220030781.png" alt="image-20191224220030781"></p><p><strong>总结</strong></p><p>总结一下上面的工作，我基本上了解了生成诗句的一套流程，对bert的结构也有了比较多的了解。总体来说，代码比较容易看懂，这比起C++的代码，简直轻松很多。</p><p>还可以梳理一下bert的脉络，研究一下whole word marking的实现方法。明后两天把这个事情做完。其他在按计划慢慢推进！</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>bert的一些思考</title>
      <link href="/2019/12/19/bert%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
      <url>/2019/12/19/bert%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>观其大致，能够比较好的融会贯通，理解整个任务。这是这篇post的主要目的。</p><a id="more"></a><p>Bert的应用模式</p><p>bert在应用到具体的任务上时，通常采用两阶段策略：</p><ul><li>第一阶段利用通用语言模型任务，采用自监督的学习方法，选择某个具体的特征抽取器，来学习预训练模型</li><li>第二个阶段，根据手头具体的监督学习任务，采取特征集成或finetune的应用模型，</li></ul><p>总之，加载预训练模型，然后为不同的任务定制第二阶段的定制网络</p><p><strong>特征集成任务</strong></p><p>ELMO方法是典型的特征集成方式，把当前要判断的输入句子，走一遍ELMO预训练好的的双层双向LSTM网络，然后把每个输入单词对应位置的高层LSTM激活embedding（或者输入单词对应位置的若干层embedding进行加权求和），作为下游任务单词对应的输入。</p><p>这是一种典型的应用预训练模型的方法，更侧重于单词的上下文特征表达方面。</p><p><strong>finetune模式</strong></p><p>GPT和bert采用finetune应用模式，在获得了预训练模型以及对应的网络结构（Transformer）后，第二个阶段仍然采用与预训练过程相同的网络结构，拿出手头任务的部分训练数据，直接在这个网络上进行模型训练，以针对性地修正预训练阶段获得的网络参数，一般这个阶段被称为Fine-tuning。</p><p><strong>搜索引擎的未来就是QA和阅读理解</strong>：搜索引擎通过理解文本，对于用户提出的问题直接给出答案。</p><p><strong>Bert生成式任务</strong></p><p>例如将bert用在生成式摘要任务中。从技术角度上来讲，生成式任务符合典型的encoder-decoder框架。encoder部分好解决，只需要用预训练好的Bert模型初始化encoder部分的transformer即可。另一方面是decoder端。大量的实验证明直接将bert的预训练参数用来初始化decoder的部分效果都不好。主要原因是bert预训练的时候使用的是双向的语言模型，而一般的decoder任务是从左到右依次生成的，无法利用bert在预训练阶段学到的上下文信息。这也是bert在做生成类任务时遇到的最大问题。</p><p><strong>如何用bert</strong></p><p>简而言之，使用bert的核心在于使用transformer作为特征提取器，用bert预训练模型初始化transformer参数，然后再用当前的任务去finetune。</p>]]></content>
      
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 重点回顾</title>
      <link href="/2019/12/09/pytorch-%E9%87%8D%E7%82%B9%E5%9B%9E%E9%A1%BE/"/>
      <url>/2019/12/09/pytorch-%E9%87%8D%E7%82%B9%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>pytorch 在日常实践中的一些常用的函数，工作流。</p><a id="more"></a><h3 id="pytorch-简介"><a href="#pytorch-简介" class="headerlink" title="pytorch 简介"></a>pytorch 简介</h3><p>pytorch是一个基于torch的python开源库。前身torch是一个有大量机器学习算法支持的科学计算框架，以及与numpy类似的张量操作库。通过pytorch的反向求导技术，可以实现动态的修改神经网络，实现速度快是一大特点。</p><p>缺点是全面性不如TensorFlow，移动端的部署性能有待提升。</p><h3 id="张量tensors"><a href="#张量tensors" class="headerlink" title="张量tensors"></a>张量tensors</h3><p>张量在神经网络中大量的应用，支持pytorch的反向求导，可以和numpy库互换，GPU计算，是pytorch中的<strong>砖块</strong>的角色。</p><p><strong>创建张量</strong></p><p>在深度学习中，<code>torch.float</code>类型使用比较多，常见的，当我们使用tensor申请参数的时候，常用的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 申请一个未初始化的矩阵</span></span><br><span class="line">x = torch.empty(<span class="number">3</span>,<span class="number">3</span>) <span class="comment"># 大小为3x3的一个矩阵，数字可以无限加，每一个数值表示一个矩阵</span></span><br><span class="line"><span class="comment"># 随机初始化，感觉这个会用的比较多一点</span></span><br><span class="line">x = torch.rand(<span class="number">24</span>,<span class="number">24</span>,<span class="number">3</span>，dtype = torch.float) <span class="comment"># 大小为24x24x3，dtype = float</span></span><br><span class="line">x = torch.zeros(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>) <span class="comment">#维度为3x3x3</span></span><br><span class="line"><span class="comment"># 直接使用数据来构造</span></span><br><span class="line">x = torch.tensor([<span class="number">5.1</span>,<span class="number">1</span>]) </span><br><span class="line"><span class="comment"># 使用已经存在的数据来构造</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>,<span class="number">4</span>,dtype=  torch.double)</span><br><span class="line">x = torch.randn_like(x,dtype = torch.float) <span class="comment"># 维度与之前的x相同</span></span><br><span class="line">x.size() <span class="comment"># 返回一个tuple，表示tensor的维度</span></span><br></pre></td></tr></table></figure><p><strong>张量操作</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加法</span></span><br><span class="line">z =  x + y</span><br><span class="line"><span class="comment">#减法</span></span><br><span class="line">z = x - y</span><br><span class="line"><span class="comment"># 获得float的输出（而不是tensor）</span></span><br><span class="line">x.item()</span><br><span class="line"><span class="comment"># 改变tensor的形状</span></span><br><span class="line">x.view(<span class="number">16</span>) <span class="comment"># 变成1*16的向量</span></span><br><span class="line">x.view(<span class="number">-1</span>,<span class="number">4</span>)<span class="comment"># 4x4的向量</span></span><br><span class="line">x.view(<span class="number">-1</span>,<span class="number">2</span>,<span class="number">2</span>)<span class="comment"># 2x2x2的向量</span></span><br><span class="line"><span class="comment"># tensor支持所有的numpy切片操作</span></span><br><span class="line">x[:<span class="number">10</span>]</span><br><span class="line"><span class="comment"># cat拼接向量</span></span><br><span class="line">torch.cat((x,y),dim = <span class="number">0</span>) <span class="comment"># y轴方向</span></span><br><span class="line">torch.cat((x,y),dim = <span class="number">1</span>) <span class="comment"># x轴方向</span></span><br><span class="line"><span class="comment"># chunk，向量拆分</span></span><br><span class="line">x.chunk(chunks = <span class="number">3</span>,dim = <span class="number">0</span>) <span class="comment"># y方向，等分成三份，第三份可能会少一点</span></span><br><span class="line">x.chunk(chunks = <span class="number">3</span>,dim = <span class="number">1</span>) <span class="comment"># x方向</span></span><br><span class="line"><span class="comment"># 截断</span></span><br><span class="line">x.clamp(<span class="number">0.3</span>,<span class="number">0.7</span>) <span class="comment"># 数值限制在这个范围</span></span><br><span class="line">x.sort(dim = <span class="number">0</span>) <span class="comment"># 沿着x方向排序，返回下标</span></span><br><span class="line">x.flatten() <span class="comment"># 将向量展成一列</span></span><br><span class="line"><span class="comment"># 选择前topK</span></span><br><span class="line">x.topk(<span class="number">2</span>,dim=<span class="number">0</span>) <span class="comment"># 返回 值以及下标</span></span><br><span class="line">x.numel()<span class="comment">#返回所有元素</span></span><br><span class="line">torch.stack((x,y), dim = <span class="number">0</span>/<span class="number">1</span>) <span class="comment"># 保留维度，然后将向量组合在一起</span></span><br><span class="line">x.permute(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>) <span class="comment"># 调整每一维度向量的先后</span></span><br><span class="line">x.squeeze(dim = <span class="number">1</span>) <span class="comment"># 维度为1的坍缩</span></span><br><span class="line">x.unsqueeze(dim = <span class="number">0</span>) <span class="comment"># 增加一个维度为1的</span></span><br><span class="line">x.cuda() <span class="comment"># 放回在GPU上的拷贝</span></span><br><span class="line">torch.where(x&gt;<span class="number">0</span>,x,y) <span class="comment"># x&gt;0 返回x，否则返回y</span></span><br><span class="line">x.round() <span class="comment"># 取整</span></span><br><span class="line">x.contiguous() <span class="comment"># 转成连续存储模式 </span></span><br><span class="line">x.numpy() <span class="comment"># 返回numpy格式</span></span><br><span class="line">x = torch.from_numpy(a) <span class="comment"># numpy转成tensor</span></span><br></pre></td></tr></table></figure><h3 id="pytorch自动微分"><a href="#pytorch自动微分" class="headerlink" title="pytorch自动微分"></a>pytorch自动微分</h3><p>autograd包是pytorch所有神经网络的核心，autograd为tensor上所有的操作提供自动微分。当我们在定义一个tensor的时候，将<code>requires_grad</code>设置成true，pytorch将会开始跟踪该tensor的所有操作。<code>backward()</code>将会自动计算所有的梯度。</p><p>要停止计算梯度可以使用detach()，或者使用<code>with torch.no_grad()</code>包起来。每个张量都有一个grad_fn的属性，这个属性保存着一个Function的引用，保存计算过程的完整信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad = <span class="keyword">True</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">x = tensor([[1,1],</span></span><br><span class="line"><span class="string">             [1,1]],requires_grad = True)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">y = tensor([[3,3],[3,3]],grad_fn = &lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h3><p>神经网络可以通过torch.nn来构建。一个nn.Module包含层以及一个正向传播的方法,<code>forward()</code>。一个典型的神经网络训练过程包括以下几点：</p><ol><li>定义一个包含可训练参数的神经网络</li><li>迭代整个输入</li><li>通过神经网络处理输入</li><li>计算loss</li><li>反向传播梯度到神经网络的参数</li><li>更新网络的参数，使用一些优化器等</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">      super(net,self).__init__()</span><br><span class="line">      <span class="comment"># 定义一些层</span></span><br><span class="line">      .</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">      <span class="comment"># x 为输入，下面是定义网络正向传播的过程</span></span><br><span class="line">      .</span><br><span class="line">nets = net()</span><br><span class="line">print(nets) <span class="comment"># 输出net的结构信息</span></span><br><span class="line">net.parameters() <span class="comment"># 得到net中的所有的参数</span></span><br><span class="line"></span><br><span class="line">net.zero_grad() <span class="comment"># 将所有参数梯度缓存置零</span></span><br><span class="line"></span><br><span class="line">output = nets(input)</span><br><span class="line">target = torch.rand(<span class="number">10</span>)</span><br><span class="line">target = target.view(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">criterion = nn.MSELoss() <span class="comment"># 定义loss</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数更新规则</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">optimizer = optim.SGD(net.parameters(),lr = <span class="number">0.01</span>)</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = nets(input)</span><br><span class="line">loss = criterion(output,target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p><strong>处理数据</strong></p><ul><li>处理图像时，我们可以使用pillow，opencv这些库</li><li>处理语音时，我们可以使用scipy，librosa</li><li>处理文本，可以使用python的基础数据加载模块，或者使用NTLK，SpaCy这些库</li></ul><p><strong>GPU数据处理</strong></p><p>如何将数据转移到GPU上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda:0,1,2,3'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">net.to(device)</span><br><span class="line"><span class="comment"># 输入，输出也有传输到gpu上</span></span><br><span class="line">inputs,labels = inputs.to(device),labels.to(devices)</span><br></pre></td></tr></table></figure><p>pytorch默认使用一个GPU，我们可以通过<code>DataParallel()</code>来设定模型在GPU上跑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">model = DataParallel(model)</span><br></pre></td></tr></table></figure><p>尽管我们的模型只获得一个输入，执行一个线性操作，然后输出。数据并行操作自动拆分了你的数据，将任务单发到多个GPU上。当每一个模型都完成自己的任务，DataParallel收集这些结果，然后返回到输出中。（代码形式是线性的，但是程序执行的时候是并行的）</p><p>代码见github链接。</p><p><strong>数据类</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">own_dataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data)</span>:</span></span><br><span class="line">    self.data = data</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.data[index]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(self.data)</span><br><span class="line">data_loader = DataLoader(own_dataset,batch_size = <span class="number">4</span>,num_works = <span class="number">2</span>,shuffle = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>继承Dataset需要实现其中的<code>__getitem__()</code>，<code>__len__()</code>方法。</p><p>继而实现dataLoader类，作为一个迭代器，每次向model中喂数据，batch_size这些参数都在这里设置。</p><p>如何将自己的数据转化成DataLoader的类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line">x = torch.rand(<span class="number">10</span>,<span class="number">10</span>)</span><br><span class="line">y = torch.rand(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 转换成dataset</span></span><br><span class="line">datas = Data.TensorDataset(x ,y)</span><br><span class="line">lloader = DataLoader(datas,batch_size=<span class="number">4</span>,shuffle=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">for</span> data_x,data_y <span class="keyword">in</span> lloader:</span><br><span class="line">    print(data_x,data_y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><strong>python</strong></p><h3 id="pytorch-迁移学习"><a href="#pytorch-迁移学习" class="headerlink" title="pytorch 迁移学习"></a>pytorch 迁移学习</h3><p>事实上，很少人从头开始训练一个完整的网络。通常的做法是在一个很大的数据集上进行预训练，得到网络的初始化参数，或者固定这些参数，去优化下游任务。</p><p><strong>保存、加载模型</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save 参数</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'my_resnet.pth'</span>)</span><br><span class="line">resnet = ResNet()</span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'my_resnet.pth'</span>))</span><br><span class="line"><span class="comment"># save 模型结构</span></span><br><span class="line">torch.save(model,<span class="string">'my_resnet.pth'</span>)</span><br><span class="line">resnet = torch.load(<span class="string">'my_resnet.pth'</span>)</span><br><span class="line"><span class="comment"># 保存checkpoint</span></span><br><span class="line">torch.save(&#123;</span><br><span class="line">  <span class="string">'epoch'</span>:epoch,</span><br><span class="line">  <span class="string">'model_state_dict'</span>:model.state_dict(),</span><br><span class="line">  <span class="string">'optimizer_state_dict'</span>:optimizer.state_dict(),</span><br><span class="line">  <span class="string">'loss'</span>:loss,</span><br><span class="line">  .</span><br><span class="line">&#125;, PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataParallel模型的保存使用：</span></span><br><span class="line">torch.save(model.module.state_dict(),PATH)</span><br></pre></td></tr></table></figure><p><strong>加载部分预训练参数</strong></p><p>有些场景我们基于一个基础网络做的，因此我们需要为主干网络进行初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pretrain = model_zoo.load_url(model_urls[<span class="string">'resnet152'</span>])</span><br><span class="line">model_dict = model.state_dict()</span><br><span class="line">pretrain = &#123;k:v <span class="keyword">for</span> k,v <span class="keyword">in</span> pretrain.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125;</span><br><span class="line">model_dict.update(pretrain)</span><br><span class="line">model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure><h3 id="当一个batch中，句子不等长的时候"><a href="#当一个batch中，句子不等长的时候" class="headerlink" title="当一个batch中，句子不等长的时候"></a>当一个batch中，句子不等长的时候</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.utils.rnn <span class="keyword">as</span> rnn_utils</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line">train  = [tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]),tensor([<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]),tensor([<span class="number">6</span>,<span class="number">6</span>])]</span><br><span class="line"><span class="comment"># 将train 变量的长度补全后面补上0，使得其长度一致</span></span><br><span class="line">x = rnn_utils.pad_sequence(train, batch_first=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 由于直接用上面的变长变量，会增加很多工作，因此我们需要pack，将向量的长度减小</span></span><br><span class="line"><span class="comment"># 其中第二个参数为每一个序列，实际的长度</span></span><br><span class="line"><span class="comment"># 返回值为：data=tensor([1., 3., 6., 1., 3., 6., 1., 3., 1., 3., 1., 3., 1., 1.]),</span></span><br><span class="line"><span class="comment">#          batch_sizes=tensor([3, 3, 2, 2, 2, 1, 1]))</span></span><br><span class="line">x = rnn_utils.pack_padded_sequence(x,[<span class="number">7</span>,<span class="number">5</span>,<span class="number">2</span>],batch_first = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面函数为上面函数的逆函数，恢复填充0之后的tensor</span></span><br><span class="line">x = rnn_utils.pad_packed_sequence(x,batch_first = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><strong>pytorch库的大致功能</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 包含的大量的网络层nn.Linear() 等等</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader <span class="comment"># 包含了数据读取的方式</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment"># 包含了激活函数等</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim <span class="comment"># 包含了优化器</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.utils.rnn <span class="keyword">as</span> rnn <span class="comment"># rnn中的一些方法</span></span><br></pre></td></tr></table></figure><h3 id="机器翻译模型"><a href="#机器翻译模型" class="headerlink" title="机器翻译模型"></a>机器翻译模型</h3><p>将词转化成可以输入网络的格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="comment"># 首先经过一系列的分词，去除不正确的词</span></span><br><span class="line"><span class="comment"># 建立词向量表，用随机值初始化</span></span><br><span class="line">embed = nn.embedding(n_vocabulary,embedding_size) <span class="comment">#字典的字数，每个词向量的长度</span></span><br><span class="line"><span class="comment"># embedding是一个二维的矩阵，y轴方向为每个单词，x轴为词向量的具体表示</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word2vec</span><span class="params">(input_seq)</span>:</span></span><br><span class="line">  <span class="comment"># input_seq是一个batch，含有多个句子，但是句子的长度不一致，</span></span><br><span class="line">  <span class="comment"># 因此需要将句子的长度补充到一致的水平</span></span><br><span class="line">  <span class="comment"># 可以使用nn.utils.rnn.pad_sequence(x,batch_first = True)</span></span><br><span class="line">  words = nn.utils.rnn.pad_sequence(x,batch_first = <span class="keyword">True</span>)</span><br><span class="line">  <span class="comment"># 输入的数据每次喂给模型的为batch中句子的第n列词，因此需要把维度改为seq*batch</span></span><br><span class="line">  words = word.T</span><br><span class="line">  embed_word = embed(words) <span class="comment"># 将词替换成词向量</span></span><br><span class="line">  <span class="comment"># 下一步送入模型之前，对填充变量进行压缩</span></span><br><span class="line">  x = rnn_utils.pack_padded_sequence(x,lengths = [<span class="number">7</span>,<span class="number">5</span>,<span class="number">2</span>],batch_first = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>上述过程就得到了输入数据的格式。通常机器翻译模型由encoder和decoder的机构组成。</p><p><img src="/images/nlp/seq1.png" style="zoom:50%;"></p><p>Encoder将句子编码成一个语义向量，decoder一个一个产生目标单词，根据之前的单词，产生之后的单词：</p><p><img src="/images/nlp/seq2.png" style="zoom:50%;"></p><p>具体如何选择encoder和decoder有非常多的选择（LSTM，GRU）等等。</p><p><strong>下面实现encoder部分:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 搭建encoder模型</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">encoder的输入input_seq大小为【最大句子长度*batch-size】</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderRNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,hidden_size,embedding,n_layers=<span class="number">1</span>,dropout=<span class="number">0</span>)</span>:</span></span><br><span class="line">        super(EncoderRNN,self).__init__()</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.embedding = embedding</span><br><span class="line">        self.gru = nn.GRU(hidden_size,hidden_size,n_layers,droput=(<span class="number">0</span> <span class="keyword">if</span></span><br><span class="line">                          n_layers==<span class="number">1</span> <span class="keyword">else</span> dropout),bidirectional=<span class="keyword">True</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input_seq,input_lengths,hidden=None)</span>:</span></span><br><span class="line">        embedded = self.embedding(input_seq) <span class="comment"># 转化成词向量</span></span><br><span class="line">        packed = nn.utils.rnn.pack_paded_sequence(embedding,input_lengths)<span class="comment"># 压缩</span></span><br><span class="line">        <span class="comment"># 整体的一个output，和最后一层的hidden输出</span></span><br><span class="line">        outputs,hidden = self.gru(packed,hidden)</span><br><span class="line">        <span class="comment"># 将tensor填充到维度一致，还返回一个每个句子的长度</span></span><br><span class="line">        outputs,_ = nn.utils.rnn.pad_packed_sequence(outputs) </span><br><span class="line">        <span class="comment"># 将正反两向的值相加</span></span><br><span class="line">        outputs = outputs[:,:,:self.hidden_size] + output[:,:,:self.hidden_size] </span><br><span class="line">        <span class="keyword">return</span> outputs,hidden</span><br></pre></td></tr></table></figure><p><strong>GRU的使用</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gru = torch.nn.GRU(input_size,hidden_size,n_layers)</span><br><span class="line"><span class="comment"># 这里的input_size就是词向量的维度，hidden_size就是RNN隐藏层的维度，这两个一般相同就可以</span></span><br><span class="line"><span class="comment"># n_layers是GRU的层数</span></span><br><span class="line"><span class="comment"># GRU实现自身迭代，不需要时间步数</span></span><br><span class="line"><span class="comment"># GRU的输入是经过pack后的向量</span></span><br><span class="line"><span class="comment"># GRU的输出有两个，分别为整体的输出和最后一层的hidden</span></span><br></pre></td></tr></table></figure><p>注意力机制的应用：</p><p><img src="/images/nlp/seq3.png" style="zoom:67%;"></p><p>上面$h_s$表示GRU向上的所有输出，用来分类。$h_t$表示GRU向右的输出，是隐藏状态值。</p><p>由上面分析，最终权重将会有三种计算方式：</p><ul><li><p>第一个是直接将输出和隐藏状态的输出相乘，linear层的输出作为权重。</p></li><li><p>第二种方式是加入一个linear层，输入为output。linear的输出再乘以hidden。</p></li><li>第三种首先hidden转化为output的shape，然后将hidden和output串在一起，经过一个linear层，之后用tanh激活函数，最后用hidden_shape的value乘以tanh的输出，得到最后权重</li></ul><p>但是这个还没完，最后还要经过一个softmax，才能得到最终的权重，然后乘以output，作为decoder的输入。</p><p><strong>下面是attention第三种公式的实现部分</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">atten</span><span class="params">(nn.Moudle)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,hidden_size)</span>:</span></span><br><span class="line">        super(atten,self).__init__()</span><br><span class="line">        self.fc = linear(hidden_size*<span class="number">2</span>,hidden_size)</span><br><span class="line">        self.v = nn.Parameter(torch.FloatTensor(hidden_size))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,hidden,encoder_output)</span>:</span></span><br><span class="line">        x = torch.cat((hidden.expand(encoder_output.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">-1</span>),</span><br><span class="line">                       encoder_output),<span class="number">2</span>)</span><br><span class="line">        x = self.fc(x) <span class="comment"># shape = [hidden_size,hidden]</span></span><br><span class="line">        x = F.tanh(x)</span><br><span class="line">        x = torch.sum(self.v * x,dim = <span class="number">2</span>)</span><br><span class="line">        x = F.softmax(x.T,dim = <span class="number">1</span>).unsqueze(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>最后的输出转置之后，经过一个softmax转换成概率之后，输出。</p><p>decoder接受encoder部分的hidden-state，即句子的深层特征。然后输入全是<code>&lt;SOS&gt;</code>，即句子的结束符。所以首先decoder需要进行word2vec，然后接受encoder的中间层的输出，最后得到decoder的output（可能会有全连接层），然后输出结果和target计算一个loss。</p><p>下面实现以下decoder的部分，包括输入的形成以及decoder最后的输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># decoder 部分</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,embedding,hidden_size,n_layers = <span class="number">1</span>,dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(decoder,self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size <span class="comment"># encoder,decoder都会用到</span></span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义decoder的层</span></span><br><span class="line">        self.embedding = embedding</span><br><span class="line">        self.embedding_dropout = nn.Dropout(dropout)</span><br><span class="line">        self.gru = nn.GRU(hidden_size,hidden_size,n_layers,dropout)</span><br><span class="line">        self.fc1 = nn.Linear(hidden_size*<span class="number">2</span>,hidden_size)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_size,hidden_size)</span><br><span class="line">        self.attn = atten(hidden_size)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,inputs,last_hidden,encoder_output)</span>:</span></span><br><span class="line">        embedd = self.embedding(inputs)</span><br><span class="line">        embedd = self.embedding_dropout(embedd)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 进入GRU网络</span></span><br><span class="line">        rnn_output,hidden = self.gru(embedd,last_hidden)</span><br><span class="line">        <span class="comment"># 然后rnn_output作为是一个输出结合连个输出的attention，去做分类的工作</span></span><br><span class="line">        attention = self.attn(rnn_output,encoder_output)</span><br><span class="line">        x = torch.cat((rnn_output,attention),<span class="number">1</span>)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = torch.tanh(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = F.softmax(x,dim = <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output,hidden <span class="comment"># 返回输出和最终隐藏状态（每一个词的长度都是词向量的长度）</span></span><br></pre></td></tr></table></figure><p>下面调用encoder和decoder，使得整个网络连贯起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">encoder_outputs, encoder_hidden = encoder(input_variable, lengths)</span><br><span class="line">attens = atten(encoder_hidden,encoder_output)</span><br><span class="line">encoder_outputs = encoder_outputs*attens</span><br><span class="line">decoder_output,decoder_hidden = decoder(inputs,encoder_outputs,encoder_hidden)</span><br></pre></td></tr></table></figure><p><strong>定义损失函数：</strong></p><p>由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地考虑张量的所有元素。我们定义<code>maskNLLLoss</code>可以根据解码器的输出张量、 描述目标张量填充的<code>binary mask</code>张量来计算损失。该损失函数计算与<code>mask tensor</code>中的1对应的元素的平均负对数似然。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maskNLLLoss</span><span class="params">(inp, target, mask)</span>:</span></span><br><span class="line">    nTotal = mask.sum()</span><br><span class="line">    crossEntropy = -torch.log(torch.gather(inp, <span class="number">1</span>, target.view(<span class="number">-1</span>, <span class="number">1</span>)).squeeze(<span class="number">1</span>))</span><br><span class="line">    loss = crossEntropy.masked_select(mask).mean()</span><br><span class="line">    loss = loss.to(device)</span><br><span class="line">    <span class="keyword">return</span> loss, nTotal.item()</span><br></pre></td></tr></table></figure><p>本文github地址：<a href="https://github.com/WenHui-Zhou/NLP_pratice/blob/master/pytorh_review.ipynb" target="_blank" rel="noopener">https://github.com/WenHui-Zhou/NLP_pratice/blob/master/pytorh_review.ipynb</a></p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><ul><li><a href="https://www.cnblogs.com/duye/p/10590146.html" target="_blank" rel="noopener">https://www.cnblogs.com/duye/p/10590146.html</a></li><li><a href="https://plmsmile.github.io/2017/10/12/Attention-based-NMT/" target="_blank" rel="noopener">https://plmsmile.github.io/2017/10/12/Attention-based-NMT/</a></li><li><a href="http://www.nlpuser.com/pytorch/2018/11/04/Attention-In-TextClassification/" target="_blank" rel="noopener">http://www.nlpuser.com/pytorch/2018/11/04/Attention-In-TextClassification/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP实践 基于注意力机制的文本匹配</title>
      <link href="/2019/12/05/NLP%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"/>
      <url>/2019/12/05/NLP%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/</url>
      
        <content type="html"><![CDATA[<p>文本匹配是一个宽泛的任务，只要是研究两端样本之间的关系，都可以将这个问题看成文本匹配的问题。常见的任务场景有：</p><ul><li>相似度计算，复述识别</li><li>问答系统</li><li>对话系统</li><li>自然语言推理、文本蕴含识别</li><li>信息检索中的匹配</li><li>机器阅读理解</li></ul><a id="more"></a><h3 id="通用baseline"><a href="#通用baseline" class="headerlink" title="通用baseline"></a>通用baseline</h3><p>对于这种匹配问题，直接上一个SiameseCNN模型，即孪生模型将textA，textB输入两个模型中，如果是计算两个文本的相似性，可以直接采用cosine，L1距离，欧式距离等得到两个文本之间的相似性。</p><p><img src="../images/nlp/text11.png" style="zoom:53%;"></p><p>匹配问题可能还会涉及到问答关系，文本蕴含关系等等，因此我们可以通过两个子模型生成了textA，textB的向量来构造出更加适合的feature，如A-B，A*B等等。然后用额外的模型（如MLP）来学习文本之间的映射关系。</p><p><strong>孪生模型</strong></p><p>孪生模型的含义指的是神经网络连体，通过权值共享的方式，组成一个完整的网络：</p><p><img src="../images/nlp/text12.jpg" style="zoom:50%;"></p><p>Network1与Network2有着相同的网络和相同的权重。他的作用是衡量两个输入的相似性。具体的应用有QA问答系统，手写体识别等等。</p><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>相似度计算<ul><li>判断两个文本是否表达相同的含义，构成复述关系</li><li>有些数据集给出相似度等级，有些数据集则给出0/1标签</li></ul></li><li>问答匹配<ul><li>问答问题可以视为是一个分类问题，但是通常情况下，但是实际场景是从若干候选中找出正确的答案，相关数据集是通过一个匹配正例和若干负例组成的，往往建模成rank问题</li><li>学习方法上，不仅可以使用分类方法来做（pointwise-learning），还可以使用pairwise-learning（同问题的一对正负样本作为一对正负样本），listwise-learning（同问题的全部样本序列作为一个样本）。</li></ul></li><li>对话匹配<ul><li>对话系统是问答系统的升级，主要的不同有：对话匹配引入了历史轮，因此回答需要参考历史</li><li>对话匹配的回复空间比问答系统要大很多，甚至存在一些万能回复。</li></ul></li><li>自然语言推理、文本蕴含识别<ul><li>如果一直句子A，能够推导出句子B为正，则A蕴含B，若推导出B为假，则说明，A与B相互矛盾，如无法推导出B为真为假那么A与B独立。</li><li>可以将这个问题看成是一个3-way classification的问题</li></ul></li><li>信息检索匹配<ul><li>query-title匹配、query-document匹配等信息检索场景下的文本匹配问题。不过，信息检索场景下，一般先通过检索方法召回相关项，再对相关项进行rerank。对这类问题来说，<strong>更重要的是ranking</strong>，而不是非黑即白或单纯的selection</li></ul></li><li>机器阅读理解<ul><li>在文本中找到答案片段</li></ul></li></ul><h3 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h3><p>基于表示的文本匹配方法（simaese结构）与基于交互的匹配方法（花式attention交互）纷争数年，最终文本匹配问题还是被BERT方法给终结了。</p><p><strong>基于表示的孪生结构</strong></p><p>这种结构有两个改进方向，一种是使用更加强大的encoder，第二种为使用更加花哨的相似度计算函数。基于这两个方向的工作也很多</p><p><strong>基于交互attention结构</strong></p><p>首先通过attention为代表的结构来对两段文本进行不同粒度（词，短语级别）的交互，然后将各个粒度的匹配结果通过一种结构聚合起来，作为一个超级特征向量得到最终的匹配关系。</p><p>然后这种结构往往在某个场景中有很好的性能，换一个场景性能可能就会变差（因为设计出来的结构迎合了某个特定数据集的数据分布）。</p><h3 id="attention机制"><a href="#attention机制" class="headerlink" title="attention机制"></a>attention机制</h3><p>attention是一个用于提升RNN在encoder-decoder中性能的机制，在机器翻译，语音识别，图像标注中得到广泛的应用。attention为句子中的每个词赋予了不同权重，使得神经网络学习变得更加的灵活（soft），同时可以反应在翻译，识别过程中的一种对齐关系。</p><p><strong>attention帮助模型对输入的x的每个部分赋予不同的权重，抽取出更加关键的信息，使得模型做出更加准确的判断，同时不会产生过大的计算和存储的开销。</strong></p><p>attention模型以经典的Bahdanau attention 为例：</p><p><img src="../images/nlp/attention1.jpg" style="zoom:87%;"></p><p>经典的attention结构主要由三个部分：</p><ul><li>source function：度量环境向量与当前输入向量的相似性，找到当前环境下应该focus那些信息</li></ul><p>$$<br>\begin{equation}<br>e_{i j}=a\left(c, y_{i}\right)=v_{a}^{T} \tanh \left(W_{a} <em> c+U_{a} </em> y_{i}\right)<br>\end{equation}<br>$$</p><ul><li>alignment function：计算attention weight，通常使用softmax进行归一化</li></ul><p>$$<br>\begin{equation}<br>\alpha_{i j}=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1}^{T_{x}} \exp \left(e_{i k}\right)}<br>\end{equation}<br>$$</p><ul><li>generate context vector function: 利用attention weight对输出赋予新的权重。</li></ul><p>$$<br>\begin{equation}<br>z_{i}=\sum_{i} \alpha_{i j} * y_{i}<br>\end{equation}<br>$$</p><p>attention机制通常和seq2seq一起介绍：</p><p><img src="../images/nlp/attention2.jpg" style="zoom:87%;"></p><p>脱离seq2seq结构，使用下面的方式计算attention：</p><p><img src="../images/nlp/attention3.jpg" style="zoom:67%;"></p><p>首先计算key和query的相似性，得出权重。然后通过sotfmax进行归一化得到结构之后与value相乘，得到最后的attention value。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>数据集：<a href="https://nlp.stanford.edu/projets/snli/" target="_blank" rel="noopener">https://nlp.stanford.edu/projets/snli/</a></p><p>SNLI1.0包含570，000的人工手写英文句子对。<br>针对 <code>推理前提</code>(premise)与<code>推理假设</code>(hypothesis)之间是否存在逻辑关系，人工标注了以下三种标签：</p><ul><li><a href="https://en.wikipedia.org/wiki/Entailment_(linguistics" target="_blank" rel="noopener"><strong>entailment</strong></a>) 蕴含、推理 p⇒h</li><li><a href="https://en.wikipedia.org/wiki/Contradiction" target="_blank" rel="noopener"><strong>contradiction</strong></a> 矛盾、对立 p⊥h</li><li><strong>neutral</strong> 中立、无关 p⇎h</li></ul><p>明天要做的事：</p><ol><li>把数据集的文件整理好</li><li>然后把网络结构搭建起来</li><li>整理一下思路</li><li>跑代码，完成蕴含关系的实验</li><li>把照片找出来</li></ol><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><a href="https://www.jiqizhixin.com/articles/2019-10-18-14" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2019-10-18-14</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP实践 文本分类任务</title>
      <link href="/2019/12/02/NLP%E5%AE%9E%E8%B7%B5-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
      <url>/2019/12/02/NLP%E5%AE%9E%E8%B7%B5-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p>文本分类是NLP中的一个很经典的问题，通过这个问题可以熟悉NLP在处理这类问题的一个大致的思路，达到快速入门的目的。</p><a id="more"></a><blockquote><p>nlp中token，tokenize，tokenizer</p><p>token：令牌，表示关键字，变量名，标点，括号等标记符号</p><p>tokenize：令牌化，解析标记，将一个句子中关键字等令牌解析出来</p><p>tokenizer：令牌解析器，具有解析的功能的类</p></blockquote><h3 id="任务简介"><a href="#任务简介" class="headerlink" title="任务简介"></a>任务简介</h3><p>文本分类的数据集，数据格式如下：<br>$$<br>X = {(x^1 , y^1 ),(x^2,y^2) · · · , (x^N , y^N )}<br>$$<br>其中$ x_i $表示一组文本，$ y_i $可以为一组标签如词性，也可以是一个标签，即文本的类别。本文的最终目标就是希望达到：<br>$$<br>f(x_i) \to y_i<br>$$<br>下面来深入解决这个问题。 </p><h3 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h3><p>在机器学习算法中，样本实例一般是以连续变量或离散变量的形式存在的。因此我们在分类之前，需要将文字转化为特征向量。</p><p><strong>词袋模型</strong></p><p>一种简单的方法就是认为文本是由字，词组成的无序，多重集合，不考虑语法和词序。这就是在自然语言处理中常用的词袋模型。磁带模型可以看车以词为基本单位的向量空间模型。</p><p><strong>N元特征</strong></p><p>在实际场景中词序是十分重要的，可能影响句子含义的表达。因此我们需要在特征中保留单词的词序。 </p><p>N 元特征(N-gram 特征),顾名思义,就是由 N 个字或词组成的字符串,单元可以 是字或词。这里N是大于等于1的任意整数。如果N 为2,就叫做二元特征,如果N为 3,就叫做三元特征以此类推。</p><p>以中文句子“机器学习算法”为例,以字为基本单位的二元特征集合为:{机器,器 学,学习,习算,算法}。集合中每一项都是由二个相邻的字组成的的子串,长度为 2。</p><p> 有了 N 元特征集合,就可以利用词袋模型将文本表示为向量形式。随着 N 的增加, 可以抽取的特征就会越多,特征空间也会呈指数增加。这些高阶的特征出现的频率也会相对较低,对分类不但没有太多帮助,还会直接影响着后续处理的效率与复杂度。<strong>因此在一般的文本分类任务中,N 取 3 就足够了,并且同时也使用一元和二元特征,防止出现过拟合。</strong></p><h3 id="特征分类"><a href="#特征分类" class="headerlink" title="特征分类"></a>特征分类</h3><p>经过特征的抽取之后，一个模型就可以认为是k维特征空间上的一个点，需接下来就要寻找一些超平面来对空间进行划分，也就是对文本进行分类。</p><p><strong>二分类问题</strong></p><p>$$ \hat y =sign((f(z))) = sign(\theta^Tz+\theta_0) $$</p><p>sign为符号函数，取判别函数f(z)的正负号，为方便，简写判别函数为 </p><p>$$ f(z) ＝ \theta^Tz+\theta_0 = \sum_{i=1}^{k}\theta_iz_i + \theta_0 = \sum_{i=0}^{k} = \hat \theta^T \hat z $$ </p><p>其中$z_0=1$,$\hat\theta,\hat z$分别称为增广权重向量和增光特征向量。 $$ \hat z = \left( \begin{array} {ccc} 1  z_1 . . z_k \end{array} \right) = \left( \begin{array}{ccc} 1   z   \<br>\end{array} \right) $$</p><p>$$ \hat \theta = \left( \begin{array} {ccc} \theta_0  \theta_1 . . \theta_k \end{array} \right) = \left( \begin{array}{ccc} \theta_0   \theta   \<br>\end{array} \right) $$</p><p>后面的分类器描述中,我们都采用简化的表示方法,并直接用 $θ , z$ 来表示增广权重向量和增广特征向量</p><p><strong>多分类问题</strong></p><p> 对于 C 类分类问题,需要定义 C 个判别函数。但是这种表示一般适用于类别 y 为离散变量的情况。在自然语言处理的很多学习任务,类别 y 可以是更复杂的结构,比如多标签、层次化以及结构化等形式。为了更好的描述这些情况，可采用如下形式： $$ \hat y = \mathop{argmax}_yf(\phi(x,y),\theta)$$ 这里$\phi(x,y)$是包含了样本x和类别y混合信息的特征向量，$\theta=[\theta_1;\theta_2…;\theta_C]$，$\phi(x,y)$ 为特征表示，$f(\phi,\theta)$为模型，一般在文本分类中为线性模型（由于我们可以构建足够复杂的特征表示，在高维空间中总是线性可分的），argmax 为解码过程，即寻求y解的过程，对于分类问题，看得分取高分即可。机器学习要学的参数是$\theta$。<a href="https://perper.site/2019/12/02/NLP%E5%AE%9E%E8%B7%B5-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" target="_blank" rel="noopener"></a></p><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>数据集：<a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews" target="_blank" rel="noopener">https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews</a></p><p>数据集由train.tsv和test.tsv组成，tsv即数列的分隔符是tab，数据的格式如下：</p><p><img src="/images/nlp/text1.png" style="zoom:45%;"></p><p>每一行由短语id，句子id，句子，类型四列组成。句子类型分为五类：</p><ul><li>0 - negative</li><li>1 - somewhat negative</li><li>2 - neutral</li><li>3 - somewhat positive</li><li>4 - positive</li></ul><p><strong>数据处理</strong></p><p><code>nltk</code>：一个专门处理英文文本的库</p><p><code>beautifulsoup</code>：构建，解析分析树</p><p>nlp数据预处理的流程：</p><ul><li>bs4等工具去除标签，或手工的方式，去除数据中不需要的内容</li><li>拼写错误检查，通常使用 pyenchant工具包</li><li>词干提取（stemming），词形还原（lemmatization），这两种方法都是要找到词的原始形式。即对于一些复数，过去式等英文的还原。stemming方法更加激进一些，还原后的词不一定是原词的词干，通常使用nltk工具包</li></ul><p>下面是具体的实现，在拿到原始的数据之后，我们需要对数据进行一些处理，处理的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面这个函数用来去除html标签</span></span><br><span class="line"><span class="comment"># 去除非文本内容</span></span><br><span class="line"><span class="comment"># tokenize句子，即分词</span></span><br><span class="line"><span class="comment"># lemmatize句子，即词性还原</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_sentences</span><span class="params">(df)</span>:</span></span><br><span class="line">    reviews = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> tqdm(df[<span class="string">'Phrase'</span>]):</span><br><span class="line">        review_text = BeautifulSoup(sent).get_text() <span class="comment"># 去除html</span></span><br><span class="line">        review_text = re.sub(<span class="string">'[^a-zA-Z]'</span>,<span class="string">' '</span>,review_text) <span class="comment"># 去除非文本部分</span></span><br><span class="line">        <span class="comment"># tokenize the sentences</span></span><br><span class="line">        words = word_tokenize(review_text.lower()) <span class="comment"># 令牌化</span></span><br><span class="line">        lemma_words = [lemmatizer.lemmatize(i) <span class="keyword">for</span> i <span class="keyword">in</span> words] <span class="comment"># 词形恢复</span></span><br><span class="line">        reviews.append(lemma_words)</span><br><span class="line">    <span class="keyword">return</span> reviews</span><br><span class="line"><span class="comment"># clear the data</span></span><br><span class="line">train_sentences = clean_sentences(train)</span><br><span class="line">test_sentences = clean_sentences(test)</span><br><span class="line">print(len(train_sentences))</span><br><span class="line">print(len(test_sentences))</span><br></pre></td></tr></table></figure><p>上述代码对这个数据集进行统一的处理，将文本中的html部分去掉，非文字部分去掉。将单词还原到原始的拼写方式上，最终将得到一个每个句子都转变为一行单词组成的list中。</p><p>标注数据为5个类别，通过keras.utils中的to_categorical方法将target转变为one-hot的形式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将标注转变为one-hot格式</span></span><br><span class="line">target = train.Sentiment.values</span><br><span class="line">y_target = to_categorical(target)</span><br><span class="line">num_classes = y_target.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>使用sklearn对训练集进行划分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split the data into train and val</span></span><br><span class="line">x_train,x_val,y_train,y_val = train_test_split(train_sentences,y_target,test_size = <span class="number">0.2</span>,stratify=y_target)</span><br></pre></td></tr></table></figure><p>划分完训练集和测试集只有，训练集中不同单词的个数可能减少了，我们希望得到一个当前训练集的一个词汇全集，并且记录一下最长的句子的长度。得到词汇全集是为了之后做token以及句子的序列化将会使用到。记录句子的最大长度是为了对句子长度进行对齐的时候们将会使用到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去除重复出现的词，unique_words里头是一个单词的全集</span></span><br><span class="line">unique_words = set()</span><br><span class="line">len_max = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> tqdm(x_train):</span><br><span class="line">    unique_words.update(sent)</span><br><span class="line">    <span class="keyword">if</span>(len_max &lt; len(sent)):</span><br><span class="line">        len_max = len(sent)</span><br><span class="line">print(len(list(unique_words)))</span><br><span class="line">print(len_max)</span><br></pre></td></tr></table></figure><p>下面利用keras的方法，对句子进行重新的token，这里的目的和最开始做token的目的不同，这里是为了得到句子的序列表示，得到序列表示以及词汇表之后，就可以使用embedding层，对句子进行word2vec变换了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对句子再次进行tokenizer操作</span></span><br><span class="line">tokenizer = Tokenizer(num_words = len(list(unique_words)))</span><br><span class="line">tokenizer.fit_on_texts(list(x_train)) <span class="comment"># 用数据初始化tokenizer</span></span><br><span class="line"><span class="comment"># tokenizer.word_count 返回一个字典，字典的key为词，val为出现的个数</span></span><br><span class="line"><span class="comment"># tokenizer.word_index 对词集合中每一个词编号,key为词，val为编号</span></span><br><span class="line"><span class="comment"># 将句子中的词替换成词的编号</span></span><br><span class="line">x_train = tokenizer.texts_to_sequences(x_train)</span><br><span class="line">x_val = tokenizer.texts_to_sequences(x_val)</span><br><span class="line">x_test = tokenizer.texts_to_sequences(test_sentences)</span><br><span class="line"><span class="comment"># 由于每个句子的长度不一样长，因此需要对齐，通过pad在短的句子开头补上0</span></span><br><span class="line">x_train = sequence.pad_sequences(x_train,maxlen=len_max)</span><br><span class="line">x_val = sequence.pad_sequences(x_val,maxlen=len_max)</span><br><span class="line">x_test = sequence.pad_sequences(x_test,maxlen=len_max)</span><br></pre></td></tr></table></figure><p>最终得到长度一致的一个句子序列化结果，上述代码即完成了所有的数据处理的操作。</p><h3 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置early stop</span></span><br><span class="line">early_stopping = EarlyStopping(min_delta=<span class="number">0.001</span>,mode =<span class="string">'max'</span>,monitor=<span class="string">'val_acc'</span>,patience = <span class="number">2</span>)</span><br><span class="line">callback = [early_stopping]</span><br><span class="line"><span class="comment"># keras搭建模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># embedding(input_dim(词汇表长度),output_dim(输出的vector的长度)，input_length(输入句子的长度))</span></span><br><span class="line"><span class="comment"># 等于输入了词汇表，句子的sequences，然后去学习word2vec的参数，得到表示句子的vector，长度通常设置成128或300</span></span><br><span class="line">model.add(Embedding(len(list(unique_words)),<span class="number">300</span>,input_length=len_max))<span class="comment"># embedding 起到word2vec的作用</span></span><br><span class="line"><span class="comment"># LSTM return_sequences=true表示输出全序列的输出，False只输出最后一个LSTM的输出</span></span><br><span class="line">model.add(LSTM(<span class="number">128</span>,dropout=<span class="number">0.5</span>,recurrent_dropout=<span class="number">0.5</span>,return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(LSTM(<span class="number">64</span>,dropout=<span class="number">0.5</span>,recurrent_dropout=<span class="number">0.5</span>,return_sequences=<span class="keyword">False</span>))</span><br><span class="line">model.add(Dense(<span class="number">100</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(num_classes,activation = <span class="string">'softmax'</span>))</span><br><span class="line">model.compile(loss = <span class="string">'categorical_crossentropy'</span>,optimizer=Adam(lr = <span class="number">0.005</span>),metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>模型结果如下：</p><p><img src="/images/nlp/text2.png" style="zoom:43%;"></p><p>embedding 层用于skip-gram方法得到词向量，最后一层softmax，使用交叉熵计算误差。</p><p>下面开始模型的训练过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 往模型中加入数据</span></span><br><span class="line">history = model.fit(x_train,y_train,validation_data,(x_val,y_val),epochs=<span class="number">6</span>,batch_size = <span class="number">256</span>,verbose=<span class="number">1</span>,callbacks=callback)</span><br></pre></td></tr></table></figure><p>包含了验证集的验证：</p><p><img src="/images/nlp/text3.png" style="zoom:50%;"></p><p>绘制训练结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">epoch_count = range(<span class="number">1</span>,len(history.history[<span class="string">'loss'</span>]) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epoch_count,history.history[<span class="string">'loss'</span>],<span class="string">'r--'</span>)</span><br><span class="line">plt.plot(epoch_count,history.history[<span class="string">'val_loss'</span>],<span class="string">'b--'</span>)</span><br><span class="line">plt.legend([<span class="string">'Training loss'</span>,<span class="string">'validation loss'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>生成测试集的预测结果，代码结束：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># submission</span></span><br><span class="line">y_pred = model.predict_classes(x_test)</span><br><span class="line">sub_file = pd.read_csv(os.path.join(root,<span class="string">'sampleSubmission.csv'</span>),sep=<span class="string">','</span>)</span><br><span class="line">sub_file.Sentiment = y_pred</span><br><span class="line">sub_file.to_csv(<span class="string">'submission.csv'</span>,index = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>看完代码最后来总结一些模型的结构：</p><p><img src="/images/nlp/text2.png" style="zoom:43%;"></p><p>通过数据的预处理部分，将文本中句子整理成一个【句子个数，句子最大长度】的一个矩阵，每一个位置上为一个单词。如果句子长度不够长的话，就在句子的前面用0来填充。</p><p>随后将每个句子，每个词进行word2vec，即embedding处理。<code>keras.layers.embedding</code>层完成词嵌入的工作。本质是一个全连接层，embedding是一个【总词汇数量，每个词编码长度】的一个权重矩阵，每一行表示一个词的向量，embeding层训练好词向量之后，将这些词向量赋予给句子中的词</p><p><img src="/images/nlp/text4.png" style="zoom:50%;"></p><p>每一个句子将得到一个【句子最大长度，词向量长度】的矩阵。</p><p><strong>RNN</strong></p><p>LSTM类似于cv领域的CNN，值得好好琢磨一下（虽然现在transform更加的流行）</p><p>传统的RNN如下：</p><p><img src="/images/nlp/text5.jpg" style="zoom:70%;"></p><p>可以看出隐层间的信息传递，$\hat{h}$与h以及x有关，每一个RNN输出的y仅与$\hat{h}$有关，通过softmax进行分类，通过训练网络得出W的参数。RNN与DNN相同，当网络比较深的时候，同样面临梯度消失的问题，当两个词相距比较远的时候，前一个词难以影响到后面的词（但是有时候这种长连接的词能够决定句子的含义）。</p><p><strong>LSTM</strong></p><p><img src="/images/nlp/text6.jpg" alt=""></p><p>LSTM包含三个数据的输入，C的输入为简单的相乘与相加，因此能够保留较长序列的信息。LSTM之间传递的h信息，有一份来自前一层的信息以及当前LSTM的输入信息。LSTM中间分层三个部分，分别为遗忘门，记忆门，选择输出门。</p><p><strong>GRU</strong></p><p>Gate Recurrent Unit是循环神经网络的一种，和LSTM相似，用来解决长期记忆和反向传播中梯度等问题而提出来的。GRU和LSTM的表现类似，但是GRU的计算复杂度比较小。</p><p><img src="/images/nlp/text7.png" style="zoom:25%;"></p><p>即：</p><p><img src="/images/nlp/text8.jpg" style="zoom:55%;"></p><p><img src="/images/nlp/text10.jpg" style="zoom:45%;"></p><p><img src="/images/nlp/text9.jpg" style="zoom:55%;"></p><p>GRU用一个1-z的方式，用同一个门代替了遗忘门和记忆门的工作，在使用的时候，GRU参数较小，能够使得算法复杂度下降。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>nlp和cv问题在处理上比起来，一个很大的不同在于数据预处理部分有比较多的工作需要完成。这些工作包括了文本数据的清洗，单词的划分tokenize，对每个句子生成word2vec，然后下面才搭建模型，和cv部分就比较类似了。</p><p>我觉得从上面的代码里头可以总结从一份代码，这份代码专门处理文本数据的预处理问题。</p><p>本文的代码地址：<a href="https://github.com/WenHui-Zhou/NLP_pratice/tree/master/text_classification" target="_blank" rel="noopener">https://github.com/WenHui-Zhou/NLP_pratice/tree/master/text_classification</a></p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><a href="https://www.kaggle.com/chiranjeevbit/movie-review-prediction" target="_blank" rel="noopener">https://www.kaggle.com/chiranjeevbit/movie-review-prediction</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>图像的去噪</title>
      <link href="/2019/12/02/%E5%9B%BE%E5%83%8F%E7%9A%84%E5%8E%BB%E5%99%AA/"/>
      <url>/2019/12/02/%E5%9B%BE%E5%83%8F%E7%9A%84%E5%8E%BB%E5%99%AA/</url>
      
        <content type="html"><![CDATA[<p>噪声在图像上通常表现为引起较强视觉效果的孤立像素点或像素块。通常噪声信号与要研究的对象不相关，以无用的信息的形式出现，下面的任务就是将噪声部分消去，使其对图像的影响最小。</p><a id="more"></a><h3 id="噪声概述"><a href="#噪声概述" class="headerlink" title="噪声概述"></a>噪声概述</h3><p><strong>噪声的来源</strong></p><p>（1）图像获取过程中</p><p>两种常用类型的图像传感器CCD和CMOS采集图像过程中，由于<strong>受传感器材料属性、工作环境、电子元器件和电路结构</strong>等影响，会引入各种噪声，如<strong>电阻引起的热噪声</strong>、场效应管的<strong>沟道热噪声、光子噪声、暗电流噪声、光响应非均匀性噪声</strong>。</p><p>（2）图像信号传输过程中</p><p>由于传输介质和记录设备等的不完善，<strong>数字图像在其传输记录过程中往往会受到多种噪声的污染</strong>。另外，在图像处理的某些环节当输入的对象并不如预想时也会在结果图像中引入噪声。</p><p><strong>噪声类型</strong></p><p>图像中常见的噪声基本上有四种：</p><ul><li>高斯噪声</li><li>泊松噪声</li><li>乘性噪声</li><li>椒盐噪声（真没写错）</li></ul><p>噪声的图像由原图，一直到椒盐噪声，从上到下：</p><p><img src="../images/3D/noise1.jpeg" style="zoom:60%;"></p><p><img src="../images/3D/noise2.jpeg" style="zoom:60%;"></p><p><img src="../images/3D/noise3.jpeg" style="zoom:60%;"></p><p><img src="../images/3D/noise4.jpeg" style="zoom:60%;"></p><p><img src="../images/3D/noise5.jpeg" style="zoom:60%;"></p><h3 id="传统去噪方法"><a href="#传统去噪方法" class="headerlink" title="传统去噪方法"></a>传统去噪方法</h3><p>传统的去噪算法分为<strong>空间域法</strong>和<strong>变换域法</strong>：</p><ul><li><p><strong>空间域去噪方法的思想就是在原图像上对图像灰度值进行处理</strong>，通常采取“平均”或“平滑”的方法，将突变的噪声分量分散到周围像素中去，使图像变得较为平滑，降低噪声的影响。常用的空间域去噪方法有：均值去噪法，中值去噪法，高斯去噪法、维纳滤波去噪法等。</p></li><li><p><strong>变换域去噪方法的思想是将原图像进行相关的变换</strong>，将图像信息变换到变换域中,再通过一定的方法来对图像信息进行处理，之后再通过反变换恢复图像信息，以达到图像去噪的目的。常用的变换域去噪方法有：傅里叶变换去噪方法，小波变换去噪方法等。</p></li></ul><p><strong>常用去噪算法</strong></p><ul><li>均值滤波去噪</li><li>中值滤波去噪</li><li>高斯滤波去噪</li><li>傅里叶变换去噪</li></ul><p>下面介绍深度学习在图像去噪上的一篇最新的论文：Noise2Noise: Learning Image Restoration without Clean Data ICML 2018</p><h3 id="Noise2Noise-Learning-Image-Restoration-without-Clean-Data"><a href="#Noise2Noise-Learning-Image-Restoration-without-Clean-Data" class="headerlink" title="Noise2Noise: Learning Image Restoration without Clean Data"></a>Noise2Noise: Learning Image Restoration without Clean Data</h3><p><strong>概述</strong></p><p>这篇文章的主要亮点在于训练网络的时候不需要提供清晰的图像，。作者将另一个不清晰的图像作为GT进行网络的训练，最终也能够得到较好的结果。</p><p><strong>理论依据</strong></p><p>先看一种简单的情况，假设我们对某个物理量（如房间的温度）多次测量，得到一系列不可靠的测量值（y1,y2,…)一种估计真实值的通用方法是找到一个数z，使其与这些测量值有最小的平均偏差，即优化下面损失函数：<br>$$<br>argminz𝔼y{L(z,y)}\arg\min_z \mathbb{E}_y{L(z,y)}<br>$$<br>对于L2 损失$L(z,y)=(z-y)^2$ ，该损失函数的最优解在测量值的算数平均值(期望)处取到：<br>$$<br>z=\mathbb{E}_y{y}<br>$$<br>对于L1,损失$L(z,y)=|z-y|$，该损失函数的最优解在测量值的中值处取到：<br>$$<br>z=median{y}<br>$$<br>对于L0损失 ,$L(z,y)=|z-y|_0$ ，该损失函数的最优解近似在测量值的众数处取到：<br>$$<br>z=mode{y}<br>$$<br>从统计学角度，这些通用的损失函数都可以解释为似然函数的负对数，而对这些损失函数的优化过程可以看做为最大似然估计。<br>训练神经网络回归器是这种点估计过程的推广。已知一系列输入-目标对$(x_i,y_i)$，典型的网络训练形式是优化下列目标函数：<br>$$<br>\arg\min_\theta\mathbb{E}_{(x,y)}{L(f_θ(x),y)}<br>$$<br>通过调节参数theta，使得x与y之间的误差最小。事实上，使用上面的Loss，结果和GT不是一一对应的关系，而是一个多值映射的关系，网络学习到所有的输出结果的平均值。</p><p>这意味着对于L2 loss来说，我们在目标图像上加上一个均值为0的随机噪声，例如高斯噪声，泊松噪声等，根据上面的方程，在目标上加上一个均值为0的噪声对方程的结果没有影响（均值为0的噪声期望为0），因此：<strong>可以通过含有噪声的图像最为训练数据，GT为在目标上加上均值为0而生成的噪声数据，这样训练的结果和直接使用干净的GT的结果理论上来说是相同的，实验结果表情，精度仅仅相差了一点点</strong>。</p><p><strong>应用场景</strong></p><p>看这个文章的时候我一直很疑惑，实验假定了存在一个含有随机噪声的图像，以及一张和它对应的，在干净的图像上加上均值为0的某个噪声分布的图像作为label，在这个基础上进行训练，得到的训练结果和clear图像的训练结果十分相似。疑惑的点在于，我认为这种假设现实生活中是难以满足的，事实上，作者在做实验的时候，也是在GT上加了均值为0的噪声来做实验的。</p><p>但是也有一些人说这个方法可能可以用在一些特定的领域，例如医疗MRT图像，难以获得清晰的图像版本，但是可以通过多次观测得到多个含噪声的医疗MRT图像，利用这些成对的含噪声的图像进行去噪处理。但是从实验角度出发，噪声的分布并不满足均值为0，因为效果可能还是不好。</p><p><strong>实验</strong></p><p>作者分别做了Guassian Noise，possion noise，monte Carlo rendering，MRT图像上的实验。实验结果表明，在加上均值为0的噪声后，同样能够得到去噪后的结果。</p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><ul><li>传统去噪算法： <a href="https://www.voidking.com/dev-gp-image-denoise/" target="_blank" rel="noopener">https://www.voidking.com/dev-gp-image-denoise/</a></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP模型finetune:GPT到Bert（三）</title>
      <link href="/2019/12/01/NLP%E6%A8%A1%E5%9E%8Bfinetune-GPT%E5%88%B0Bert%EF%BC%88%E4%B8%89%EF%BC%89/"/>
      <url>/2019/12/01/NLP%E6%A8%A1%E5%9E%8Bfinetune-GPT%E5%88%B0Bert%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>NLP模型的预训练方式有ELMO的方式，基于特征的融合，通过学习句子的上下文语境来判断句子中多义词的含义，解决多义词歧义的问题，从而提升模型的性能。</p><p>另一种更类似于图像领域的预训练方式为fine tuning模式，该模式有一个代表，即GPT网络。</p><a id="more"></a><h3 id="word-embedding-to-GPT"><a href="#word-embedding-to-GPT" class="headerlink" title="word embedding to GPT"></a>word embedding to GPT</h3><p>GPT的网络结果如下：</p><p><img src="/images/nlp/gpt1.jpg" style="zoom:80%;"></p><p>GPT是Generative Pre-Training的简称，模型分为两个部分，第一个阶段利用语言模型进行预训练，第二个阶段利用fine tune解决下游的任务。上图的预训练过程与ELMO类似，也是分为两个阶段，下面回顾一下ELMO：</p><p><img src="/images/nlp/gpt2.jpg" style="zoom:80%;"></p><p>ELMO利用语言模型得到一个不可区分多义词的word embedding，然后通过下游任务来微调这个word embedding使得其适应具体的语境。</p><p>GPT与ELMO的区别有两个：</p><ul><li>GPT使用transformer结果替代ELMO中的LSTM</li><li>GPT采用单向的语言模型，GPT仅利用到语言的上文信息，而ELMO则是双向模型（可以算一个 缺点）</li></ul><h3 id="使用GPT预训练参数"><a href="#使用GPT预训练参数" class="headerlink" title="使用GPT预训练参数"></a>使用GPT预训练参数</h3><p>GPT利用语言模型就是预训练之后，对不同的下游任务，设计网络结构，这个结构朝GPT看齐。这样在下游任务中，利用GPT的参数去初始化下游模型，然后根据具体数据来对网络 进行 fine tune，这个过程和cv领域的预训练模型一模一样。</p><p>接下来的 问题就转变为，如果将一个下有任务改造成类似GPT的 结构。</p><p>对于常见的任务，GPT的改造 如下：</p><p><img src="/images/nlp/gpt4.jpg" style="zoom:87%;"></p><p>对于GPT来说，一个值得改进的地方是他使用的单向的语言模型，因此在这之后，Bert就填补了这个遗憾。</p><h3 id="Bert"><a href="#Bert" class="headerlink" title="Bert"></a>Bert</h3><p><img src="/images/nlp/bert1.jpg" style="zoom:80%;"></p><p>bert借鉴了GPT中使用的transformer以及ELMO中使用的双向语言模型。使用过程同样分为两步，第一步训练双向语言模型进行参数的预训练。第二步根据具体的下游任务，改造为bert结构。</p><p>Bert的演化过程如下：</p><p><img src="/images/nlp/bert2.jpg" style="zoom:80%;"></p><p>transformer在做双向的时候，采用的是CBOW的方法，即将当前要预测的词扣掉，利用这个词的上下文来预测，具体做法 如下：</p><p>Masked双向语言模型：随机选择语料中15%的单词，把它抠掉，也就是用[Mask]掩码代替原始单词，然后要求模型去正确预测被抠掉的单词。但是这里有个问题：训练过程大量看到[mask]标记，但是真正后面用的时候是不会有这个标记的，这会引导模型认为输出是针对[mask]这个标记的，但是实际使用又见不到这个标记，这自然会有问题。为了避免这个问题，Bert改造了一下，15%的被上天选中要执行[mask]替身这项光荣任务的单词中，只有80%真正被替换成[mask]标记，10%被狸猫换太子随机替换成另外一个单词，10%情况这个单词还待在原地不做改动。这就是Masked双向语音模型的具体做法。</p><p>Bert在NLP的各大任务中均大方异彩，出现了一统江湖的趋势，成为NLP领域内的一个标杆工作。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP之transformer（二）</title>
      <link href="/2019/11/29/NLP%E4%B9%8Btransformer%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>/2019/11/29/NLP%E4%B9%8Btransformer%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>NLP任务的输入往往是一句话或者是一篇文章，他有几个特点：</p><ul><li>输入是一个一维<strong>线性序列</strong></li><li>输入是<strong>不定长的</strong></li><li>输入单词的<strong>相对位置</strong>非常的重要</li><li>句子中的<strong>长特征</strong>对理解句子非常的重要（距离很远的词）</li></ul><p><strong>一个合格的特征抽取器应当很好的适配领域问题的特点，能够充分抽取数据中的特征。</strong></p><a id="more"></a><h3 id="NLP领域主要任务"><a href="#NLP领域主要任务" class="headerlink" title="NLP领域主要任务"></a>NLP领域主要任务</h3><p>该部分在上一篇文章中有简要提到，下面详细记录一下这些任务主要解决的问题：</p><ul><li>序列标注：这是NLP典型的任务，包括中文分词，词性标注，命名实体识别等等。<ul><li>特点：模型根据上下文给每个单词分配一个类别</li></ul></li><li>分类任务：常见有的文本分类和情感计算<ul><li>特点：不论文章多长，总体给出一个分类类别</li></ul></li><li>句子关系判断：问答系统，语义改写，自然语言推理<ul><li>特点：给出两个句子，判断这两个句子是否具有某种语义关系</li></ul></li><li>生成式任务：机器翻译，文本摘要，写诗造句，看图说话<ul><li>特点：输入文本后，需要自主生成另一段文字</li></ul></li></ul><p>从模型的角度来看，模型的特征抽取能力是至关重要的，下面开始详细介绍NLP的三个抽取器。</p><h3 id="久经沙场RNN"><a href="#久经沙场RNN" class="headerlink" title="久经沙场RNN"></a>久经沙场RNN</h3><p>RNN引入NLP之后，一直是一个明星模型，在各种模型中被广泛的应用。它采用线性序列结构不断从前往后收集输入信息。但是这种结构在反向传播过程中存在优化的困难。因为反向传播路径过长，导致严重的梯度消失或爆炸问题。于是很快建LSTM引入RNN作为标准模型中。</p><p><img src="/images/nlp/lstm.png" style="zoom:40%;"></p><p>下面是非常典型的使用RNN来解决NLP任务的基本框架：</p><p><img src="/images/nlp/rnn_frame.png" style="zoom:47%;"></p><p>RNN本身结构就是个可以接纳不定长输入的由前向后进行信息线性传导的网络结构，而在LSTM引入三个门后，对于捕获长距离特征也是非常有效的。所以RNN特别适合NLP这种线形序列应用场景，这是RNN在NLP界如此流行的根本原因。</p><p>但是对于RNN来说，来自一些新型的特征提取器的挑战，以及RNN并行能力差的问题，导致了它很可能被替代。</p><p><strong>RNN并性能力差的原因</strong>：RNNT时刻有两个输入，一个输入为当前的文本，另一个输入为T-1时刻隐藏层的输出S(T-1)，这是最能体现RNN的一点，RNN的历史信息就是通过这个传输渠道向后传的。因此T时刻计算依赖于T-1时刻的结果，因此网络必须按照时序的顺序一个一个往后走。</p><p>而CNN与transformers不存在这种问题，他们是天生的并行计算结构。</p><p>RNN在并行化上也做了一些工作，通常的做法有打断隐层的连接，或者打断部分的连接，层间并行。</p><h3 id="改造CNN"><a href="#改造CNN" class="headerlink" title="改造CNN"></a>改造CNN</h3><p>2014年CNN最早被引入NLP中：</p><p><img src="/images/nlp/kim_cnn.png" style="zoom:50%;"></p><p>每一行为一个单词的数值编码，卷积层将数值编码分割，在编码维度上移动，得到卷积后的特征，但仅仅在句子分类的任务上性能不错。</p><p>但是单个卷积层难以捕获远距离的特征，因此解决的方案<strong>有把卷积层做深；使用dilated 孔洞卷积。</strong>CNN能够捕获向量的位置信息，但是pooling结构通过会破坏掉这种顺序，因此通常使用全连接层替换掉pooling结构。</p><p>目前使用的比较多的CNN如下：</p><p><img src="/images/nlp/cnn.png" style="zoom:50%;"></p><p>上图是现代CNN的主体结构，通常由1-D的卷积层来叠加深度，使用skip-connection来辅助优化，也可以使用dilated等手段。CNN在nlp中的引入，能够保持数据间的时序信息，要设法将CNN的深度做起来。</p><h3 id="transformer结构"><a href="#transformer结构" class="headerlink" title="transformer结构"></a>transformer结构</h3><p>Transformer模型有很多好处，它改进了RNN最被人诟病的训练慢的缺点，利用self-attention机制实现快速并行。且Transformer可以增加到非常深的深度，充分发掘DNN模型的特性。下面具体的讲解一下transformer的机制。</p><p>下面通过引入一个NLP中经典问题的方式来解释这个结构：</p><blockquote><p>我们打算将英语翻译为西班牙语：</p><p><em>X = [‘Hello’, ‘,’, ‘how’, ‘are’, ‘you’, ‘?’] (Input sequence)</em><br><em>Y = [‘Hola’, ‘,’, ‘como’, ‘estas’, ‘?’] (Target sequence)</em></p></blockquote><p>transformer中encoder部分负责提取句子信息，decoder部分负责将encoder的输出与target相结合，得到接近target的翻译结果。</p><h3 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h3><p>transformer结构是一个由encoder，decoder，ski-connection，layerNorm，FF共同作用的一个结构，在数据特征提取上有着明显的优势。</p><p><img src="/images/nlp/transformer1.png" style="zoom:40%;"></p><p>编码和解码的部分分别都由六个编码器组件组合而成：</p><p><img src="/images/nlp/transformer2.png" style="zoom:30%;"></p><p>将encoder与decoder模块展开来看：</p><p><img src="/images/nlp/transformer4.png" style="zoom:43%;"></p><p>encoder部分由一个自注意力层和一个前向网络构成，其中自注意力层关注句子中的每一个单词对当前编码单词的关系。</p><p>decoder部分由三层构成，其中中间那一层，用来关注句子中的相关部分（和seq2seq类似）。</p><h3 id="decoder模块"><a href="#decoder模块" class="headerlink" title="decoder模块"></a>decoder模块</h3><p>decoder模块是对nlp数据提取特征的模块，将每一个编码器单元展开如下：</p><p><img src="/images/nlp/transformer3.png" style="zoom:50%;"></p><p><strong>数据流动</strong></p><ul><li>将单词转化成词向量（词向量的长度固定，BERT中为512），输入的维度：<strong>句子长度*词向量长度</strong></li><li>生成一个<strong>句子长度*词向量长度</strong>的位置编码信息，添加到输入中</li><li>输入数据经过N个encoder单元，生成<strong>句子长度*词向量长度</strong>大小的向量</li></ul><p>第一步对句子进行分词，将单词转化为词向量：</p><p><img src="/images/nlp/transformer5.png" style="zoom:53%;"></p><p>当我们训练一个batch的数据的时候，我们需要对一些较短的句子进行补充，通过在句首添加padding的方式，将句子长度对齐。</p><blockquote><p>[“<pad>”, “<pad>”, “<pad>”, “Hello”, “, “, “how”, “are”, “you”, “?”] →</pad></pad></pad></p><p>[5, 5, 5, 34, 90, 15, 684, 55, 193]</p></blockquote><p>第二步，对位置信息进行编码，然后将位置信息加入到输入当中，对位置信息进行编码采用以下的公式：</p><p><img src="/images/nlp/transformer6.png" style="zoom:73%;"></p><p>其中i表示y方向即每一个单词，j表示在词向量的长度（emb-dim）上的位置，因此最终得到下面的结果：</p><p><img src="/images/nlp/transformer7.png" style="zoom:45%;"></p><p>将输入与上面的位置编码相加，得到最终的输入数据。</p><p><strong>encoder block</strong></p><p>接下来进入encoder内部，编码器内部采用一层的自注意力层以及一个前向的全连接层。将数据输入编码器，首先遇到的是 <strong>multi-head attention</strong>结构。</p><p><strong>multi-head attention</strong>结构共同训练h次注意力层，这种做法能够扩展专注于不同位置的能力，同时给出了注意力层的多个表示子空间。</p><p>对于每一个head来说，我们训练三个向量，Q，K，V，与输入embedding向量相乘得到中间结果，用于最后计算每一个词最终的得分：</p><p><img src="/images/nlp/transformer8.png" style="zoom:70%;"></p><p>将上面的运算合并为矩阵运算，则算法如下：</p><p><img src="/images/nlp/transformer9.png" style="zoom:67%;"></p><p>利用上面的结果计算每个单词的得分：<br>$$<br>\begin{equation}<br>\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V<br>\end{equation}<br>$$<br><img src="/images/nlp/transformer10.png" style="zoom:67%;"></p><p>对于multi-head来说，我们将X输入h个head中，将会得到h个句子不同词之间的得分Z:</p><p><img src="/images/nlp/transformer11.png" style="zoom:67%;"></p><p>对于一个句子来说，我们只希望得到一组表示词语间的相互关系，于是我们将Z拼接起来，通过训练一个权重$W^0$使得最终得到一个 <strong>句子长度*词向量长度</strong>。</p><p><img src="/images/nlp/transformer12.png" style="zoom:60%;"></p><p>通过融合注意力机制的多头的结果，每个词与句子的其他成分之间的关系得到了充分的挖掘：</p><p><img src="/images/nlp/transformer13.png" style="zoom:70%;"></p><p>当我们计算出句子单词之间的注意力分布，下一步为添加残差后归一化：</p><p><img src="/images/nlp/transformer14.png" style="zoom:67%;"></p><p>完成残差之后是一个正向的全连接层（Free Forward），即一个两层的全连接层，第一层的激活函数为ReLU，第二层的激活函数为线性激活函数：<br>$$<br>\begin{equation}<br>\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}<br>\end{equation}<br>$$<br>其中W1位第一层，W2为第二层，max函数表示ReLU激活函数，b2为线性激活函数的偏移。最终的输出添加残差，归一化之后得到一个decoder的输出，随后将这个输出输入下一个decoder模块中，直到所有的模块都完成输出，将输出传至decoder模块。</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder部分网络结构相比较于decoder部分，多出了一个encoder to decoder的模块，这个模块的的输入来自于decoder的输出：</p><p><img src="/images/nlp/transformer4.png" style="zoom:43%;"></p><p>encoder和decoder中信息传播如下：</p><p><img src="/images/nlp/transformer15.png" style="zoom:43%;"></p><p>每一个decoder模块都将接受encoder的输出。Decoder的一个单元具体结构如下：</p><p><img src="/images/nlp/transformer16.png" style="zoom:43%;"></p><p><strong>数据流动</strong></p><ul><li>首先将target进行分词，编码成词向量，维度为 <strong>target句子长度*词向量长度</strong></li><li>将第一步得到的数据输入N个Decoder模块中，在每次迭代过程中，接收decoder的输出作为一个额外的输入，最终得到的输出维度为 <strong>target句子长度*词向量的长度</strong></li><li>将decoder得到的输出，输入到一个全连接层，并且每一层做一个逐行的softmax，最终得到的输出是翻译的结果，即维度为<strong>句子长度*每个单词的长度</strong></li></ul><p><strong>输入</strong></p><p>由于input的句子长度和target的句子的长度不一致，因此首先对target句子分词后，进行偏移：</p><blockquote><p><em>[“Hola”, “, “, “como”, “estás”, “?”]→[“”, “Hola”, “, “, “como”, “estás”, “?”]</em></p></blockquote><p><strong>train vs test</strong></p><p>train阶段和test阶段对于decoder部分来说有一个重要的差别：</p><ul><li>在test阶段，我们不知道groundTruth，因此我们将会根据之前给出的单词来预测当前位置的单词，即无法使用当前位置之后的单词的信息。</li><li>在train阶段，我们知道GT，我们会直接告诉模型我们的target是什么，然后根据和test一样的顺序进行预测，但是这将会出现一个问题，<strong>模型可能根据target句子本身的位置关系来预测target，也就是使用了target的信息</strong>，这是不允许的，因为在实际情况中我们不可能提前知道target，因此这样的训练是不充分的。</li></ul><p>因此我们在Decoder的训练阶段必须消除target提供当前词之后的词所提供的信息。例如下面例子，当要预测estás的时候，我们就只能使用绿色部分所使用的信息，而红色部分的信息不能使用：</p><p><img src="/images/nlp/transformer17.png" style="zoom:63%;"></p><p>为了解决上面这个问题，我们提出了mask multi-head attention，即对output的数据进行处理。</p><p><strong>mask multi-head attention</strong></p><p>首先通过与encoder相同的操作，即multi-head attention得到一个 <strong>target句子长度*词向量</strong>的一个输出矩阵，<strong>然后进行mask操作，即将矩阵右上角的数值置为负无穷。</strong></p><p>原始multi head结果：</p><p><img src="/images/nlp/transformer18.png" style="zoom:73%;"></p><p>mask后的结果：</p><p><img src="/images/nlp/transformer19.png" style="zoom:73%;"></p><p>这就意味着当前单词的预测无法使用其后出现的单词信息。</p><p><strong>Encoder to decoder</strong></p><p>将上述的输出添加输入以及归一化之后，输入到下一层encoder to decoder，这一部分接受的输入由两部分组成，第一部分就是decoder的第一阶段的输出，另一个部分就是encoder最终的输出。</p><p>与decoder同样的操作，我们训练三个向量，Q，K，V，与输入embedding向量相乘得到中间结果，用于最后计算每一个词最终的得分，唯一的不同在于这三个向量使用的训练数据不同，如下图：</p><p><img src="/images/nlp/transformer20.png" style="zoom:73%;"></p><p><strong>即Q向量由decoder第一阶段的数据来训练，K，V由encoder最后输出的数据来训练。</strong></p><p>同样的利用与encoder相同的attention公式计算每一个词与句子中其他的成分的关系：<br>$$<br>\begin{equation}\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\end{equation}<br>$$<br>接下来与encoder相同，训练h个head，然后组合在一起通过一个$W^0$矩阵进行组成得到输出，最后传入decoder模块的第三阶段，即全连接层进行前向的传播。</p><p><strong>linear and softmax</strong></p><p>重复上面decoder的基础模块N次，最后得到的输出的维度为 <strong>target句子长度*词向量长度</strong>，然后将这个向量输入一个linear全连接层中，全连接层输出的维度为翻译后句子的真实长度，其实际含义在对每一个词赋予一个权重：<br>$$<br>\begin{equation}<br>x W_{1}<br>\end{equation}<br>$$<br>最后，将上面的输出输入到softmax当中，计算出当前位置上，所有可能出现的翻译的结果的概率，然后根据最大的概率得到模型预测的翻译的结果：</p><p><img src="/images/nlp/transformer21.png" style="zoom:83%;"></p><p>根据第一行的结果，我们可以判断，ss对应的翻译是hello。</p><p>最后放一张encoder和decoder的合照，以便于回顾transformer的各种细节：</p><p><img src="/images/nlp/transformer22.png" style="zoom:43%;"></p><p>最最最后小彩蛋：</p><p><img src="/images/nlp/transformer23.png" style="zoom:43%;"></p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><ul><li><a href="https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f" target="_blank" rel="noopener">https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f</a></li><li><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">https://jalammar.github.io/illustrated-transformer/</a></li><li><a href="https://zhuanlan.zhihu.com/p/54356280" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/54356280</a></li><li><a href="https://zhuanlan.zhihu.com/p/54743941" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/54743941</a></li><li><a href="https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3" target="_blank" rel="noopener">https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP之Word2Vec（一）</title>
      <link href="/2019/11/29/NLP%E4%B9%8BWord2Vec%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/11/29/NLP%E4%B9%8BWord2Vec%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>NLP领域有着四个比较大的方向：</p><ul><li>文本分类</li><li>序列标注</li><li>文本匹配</li><li>文本生成</li></ul><p>在NLP里头，最细粒度的就是 <strong>词语</strong>，由词语组成句子，由句子组成文章继而表达一些语言层面上的含义。因此本文从NLP的根源问题 <strong>词语表达</strong> 开始讲起，即word2vec，NLP领域重要的预训练方法。</p><a id="more"></a><h3 id="word2vec考古史"><a href="#word2vec考古史" class="headerlink" title="word2vec考古史"></a>word2vec考古史</h3><p>Word2vec最早出现是以一个副产品的身份出现的。它是在实现语言模型过程中出现的<strong>一个惊喜的意外</strong>。简而言之，就是在做实现语言模型的过程中，我们得到了词语的数值表达，这也就是word2vec的精髓。</p><p><strong>词语是人类对语言在符号上的抽象总结，通过word2vec，将符号语言转化为数值表达，方便计算机寻找语言背后的抽象逻辑。</strong></p><p><strong>语言模型</strong></p><p>生成word2vec的语言模型是个什么东西呢？如下图：</p><p><img src="/images/nlp/language_model.png" style="zoom:50%;"></p><p>语言模型就是量化的衡量哪一个句子更像是人说的，核心函数p的思想是说，通过一系列的前导词，预测出后面跟着哪一个词的概率最大。</p><p><strong>数据的输入问题</strong>，第一步是将每个词用一个向量来唯一表示（<strong>one-hot</strong>），然后才可能对这个向量进行编码，得到具有语言意义的一个向量（<strong>word2vec</strong>）。</p><p><strong>one-hot</strong>的实现过程为建立一个长度为V的表，假设这个V表示世界上所有词语的词语。当我们对出现的一个词语进行编码的时候，只需要将这个词语出现的位置置为1，其他为0，即得到了这个<strong>词语的唯一表达（one-hot形式）。</strong></p><p><strong>语言网络的设计</strong>，加入你设计出了如下的结构：</p><p><img src="/images/nlp/nnlm.png" style="zoom:50%;"></p><p>这就是大名鼎鼎的神经网络语言模型，由Bengio 2003发表在JMLR上，2013年深度学习升温后，才慢慢进入了神坛。</p><p>他的核心思想即是最大似然估计的思想：<br>$$<br>\begin{equation}<br>\left.P\left(W_{t}=\operatorname{‘Bert’} | W_{1}, W_{2}, \ldots W_{(} t-1\right) ; \theta\right)<br>\end{equation}<br>$$<br>即如果当前位置出现了’Bert‘，要求网络预测前t-1的参数，使得当前出现Bert的概率最大。网络的输入，我们最初说使用one-hot的形式，但是为了另其具有语言的含义，我们在将词语输入网络之前，使用矩阵Q进行语义上的转换。从而得到词语的word embedding表达。</p><p>矩阵Q就是所谓的word2vec的转换矩阵，它包含V行，每一行表示一个单词的vector值，有一点值得注意的是，Q矩阵一开始是用随机值进行初始化的，矩阵Q参与网络的训练，当网络训练好之后，矩阵Q就被正确赋值了。</p><p>word2vec有两种训练方式：</p><ul><li>CBOW：从一个句子中将一个词抠掉，用这个词的上下文去预测这个词。</li><li>skip-gram：用一个词去预测这个词的上下文。</li></ul><h3 id="ELMO克服word2vec的多义词缺陷"><a href="#ELMO克服word2vec的多义词缺陷" class="headerlink" title="ELMO克服word2vec的多义词缺陷"></a>ELMO克服word2vec的多义词缺陷</h3><p>word2vec对下游的nlp任务有一些帮助，但是帮助却不是那么大。一个比较严重的问题在于<strong>多义词的问题</strong>，例如bank这个单词，可以指银行也可以指河床，但是在矩阵Q中，这个单词只有一种特征的编码。</p><p>如何解决这个问题呢，ELMO模型提出了一种想法，<strong>利用上下文场景来确定多义词的语义。</strong></p><p><strong>ELMO的本质思想是：</strong>事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分。在下游任务中，实际使用Word Embedding的时候，单词已经具备了特定的上下文，这个时候<strong>可以根据上下文单词的语义去调整单词的Word Embedding表示</strong>，经过调整后的Word Embedding更能表达在这个上下文中的具体含义，即确定了多义词的具体语义。</p><p><img src="/images/nlp/elmo.png" style="zoom:50%;"></p><p>ELMO采用典型的两阶段：</p><ul><li>第一个阶段利用语言模型进行word embedding的预训练</li><li>第二个阶段是提取对应单词网络各层的word embedding作为新特征，补充到下游任务中</li></ul><p>上图是第一阶段的预训练过程，网络结构采用双层的word embedding作为新特征补充到任务中。网络结构采用双层的LSTM，左端正向表示正向的编码器。右边逆向，表示逆向的编码器。从两个方向来预测扣掉的那一个词。</p><p>使用这个网路，每次输入一个句子网络将会输出三个向量，分别是 <strong>单词特征，句法特征，语义特征。</strong></p><p>这三个特征如何使用呢，在下游的任务中，我们给每一个vector一个权重，然后将三个特征相加，整合成一个特征输入下游的任务中。这个权重需要通过网络的学习得到。EMLO效果相比较于传统的word2vec性能上得到了比较明显的提升。</p><p><img src="/images/nlp/elmo_use.png" style="zoom:50%;"></p><p>ELMO有什么缺点呢：</p><ul><li>LSTM抽取特征的能力远弱于transformer</li><li>拼接方式双向融合特征，融合能力偏弱</li></ul><p>接下来，我将在另外的文章中介绍transformer。</p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><a href="https://zhuanlan.zhihu.com/p/49271699" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/49271699</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(九)杂项讨论</title>
      <link href="/2019/11/26/effective-cpp-%E4%B9%9D-%E6%9D%82%E9%A1%B9%E8%AE%A8%E8%AE%BA/"/>
      <url>/2019/11/26/effective-cpp-%E4%B9%9D-%E6%9D%82%E9%A1%B9%E8%AE%A8%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p>2019/11/26 effective cpp 第九章 杂项讨论</p><p>这是这本书的最后一章，今晚应该就能够阅读完！在开始阅读之前，我想感慨一下，最后的几章难度太大，一知半解的看下来，我想原因是相关张章节的实践不多导致的，因此日后有需要要回来重新阅读它们，时间很快大概花了一个月的空闲时间来阅读这本书，收获满满！</p><p>这一章主要说了三个问题：编译器的警告要重视；C++标准库的一个总览；boost一个泛用性C++库的总览。</p><ul><li>53 条款：不要轻视编译器的警告</li><li>54 条款：让自己熟悉包括TR1在内的标准程序库</li><li>55 条款：让自己熟悉Boost</li></ul><a id="more"></a><h3 id="53-条款：不要轻视编译器的警告"><a href="#53-条款：不要轻视编译器的警告" class="headerlink" title="53 条款：不要轻视编译器的警告"></a>53 条款：不要轻视编译器的警告</h3><p>编译器作者在触发一个warning的时候，他比你更加明白将来会发生什么严重的错误，因此我们需要在对待编译器警告的时候更加的小心。</p><p>当出现一个编译器warning的时候，我们应该需要知道它的意图以及真正的意义。</p><p><strong>总结</strong></p><ul><li>严肃对待编译器发出的警告，争取无警告荣誉</li><li>不要过度依赖编译器的报警功能，因为不同的编译器对待事情的反应是不同的</li></ul><h3 id="54-条款：让自己熟悉包括TR1在内的标准程序库"><a href="#54-条款：让自己熟悉包括TR1在内的标准程序库" class="headerlink" title="54 条款：让自己熟悉包括TR1在内的标准程序库"></a>54 条款：让自己熟悉包括TR1在内的标准程序库</h3><p>C++standard定义了C++语言及其标准程序库的规范，里头包含以下：</p><ul><li>STL 标准模板库</li><li>Iostream</li><li>国际化支持</li><li>数值处理</li><li>C89标准程序库</li><li>异常阶层体系</li></ul><p>此外C++的新特性被记录在TR1的文档内，在下一次更新将会加入到标准库中。</p><p><strong>总结</strong></p><ul><li>C++标准库的主要机能由STL，iostreams，locates组成。并包含C99标准程序库。</li><li>TR1添加了智能指针，一般化函数指针，hash-based容器，正则表达式以及另外10个组件的支持</li><li>TR1自身只是一份规范。</li></ul><h3 id="55-条款：让自己熟悉Boost"><a href="#55-条款：让自己熟悉Boost" class="headerlink" title="55 条款：让自己熟悉Boost"></a>55 条款：让自己熟悉Boost</h3><p>如果你在找一个高质量，源码开放，平台独立，编译器独立的程序库，那么Boost是一个很好地选择。他的网址是：<a href="">http://boost.org</a>。</p><p><strong>总结</strong></p><ul><li>Boost是一个社群，也是一个网站，致力于免费，源码开放，同僚复审的C++程序库开发。Boost在C++标准化过程中扮演深居影响力的角色。</li><li>Boost提供许多TR1组件实现品，以及其他许多程序库。</li></ul><p>最后告诫一下自己，熟悉STL，在开始用C++写一个东西之前，应当要过一遍这9篇博客！</p>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(八)定制new和delete</title>
      <link href="/2019/11/25/effective-cpp-%E5%85%AB-%E5%AE%9A%E5%88%B6new%E5%92%8Cdelete/"/>
      <url>/2019/11/25/effective-cpp-%E5%85%AB-%E5%AE%9A%E5%88%B6new%E5%92%8Cdelete/</url>
      
        <content type="html"><![CDATA[<p>2019/11/25 effective cpp 第8章 定制new和delete</p><p>C++在内存管理，垃圾回收机制上常常受到人们的讨论。下面这一章将讨论C++的内存管理例程。</p><ul><li>49 条款：了解new-handler的行为</li><li>50 条款：了解new和delete的合理替换时机</li><li>51 条款：编写new和delete时需固守常规</li><li>52 条款：写了placement new也要写placement delete</li></ul><a id="more"></a><h3 id="49-条款：了解new-handler的行为"><a href="#49-条款：了解new-handler的行为" class="headerlink" title="49 条款：了解new-handler的行为"></a>49 条款：了解new-handler的行为</h3><p>当operator new无法满足某一内存分配的需求时，它将会抛出异常。当operator new发生异常，它会先调用一个客户指定的错误处理函数，即new-handler函数。为了指定这个用以处理内存不足的函数，客户必须调用set_new_handler，那是声明与<code>&lt;new&gt;</code>的一个标准程序库函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*new_handler)</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">new_handler <span class="title">set_new_handler</span><span class="params">(new_handler p)</span> <span class="title">throw</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面可以看出来new_handler是一个typedef。定义出一个指向函数的指针，该函数没有返回任何东西，set_new_handler则是接受一个指针，返回一个指针，并且不允许抛出任何的异常。</p><p>Set_new_handler的使用方式如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">outOfMem</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"unable doing something"</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">abort</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::set_new_handler(outOfMem);</span><br><span class="line">  <span class="keyword">int</span>* pBig = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">12323232333333</span>];</span><br><span class="line">  <span class="comment">// 当new无法分配这么多空间的时候，将会去调用outOfMem报错。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在实现new-handler的时候，有几点注意：</p><ul><li><strong>让更多的内存可被使用</strong>，一个做法是程序开始执行的时候就分配了一大块内存，当调用handler的时候，释放给程序使用</li><li><strong>安装另一个new-handler</strong>，如果目前这个new-handler无法处理这个异常，它可以通过调用其他的handler来分配内存。</li><li><p><strong>卸除new-handler</strong>，就是讲null指针传给set_new_handler，一旦没有安装任何new-handler，operator new会在内存分配不成功时抛出异常。</p></li><li><p><strong>跑出bad_alloc异常，</strong>这样的异常不会被operator new捕获，因此会被传播到内存索求处。</p></li><li><strong>不返回</strong>，通常调用abort，exit来中断程序。</li></ul><p><strong>总结</strong></p><ul><li>set_new_handler允许客户指定一个函数，在内存分配无法获得满足时被调用</li><li>Nothrow new是一个颇为局限的工具，因为它只适用于内存分配，后续的构造函数调用还是可能抛出异常。</li></ul><h3 id="50-条款：了解new和delete的合理替换时机"><a href="#50-条款：了解new和delete的合理替换时机" class="headerlink" title="50 条款：了解new和delete的合理替换时机"></a>50 条款：了解new和delete的合理替换时机</h3><p>通常我们选择替换new和delete会出于几个原因：</p><ul><li>用于检测运用上的错误</li><li>为了强化效能</li><li>为了收集使用上的统计数据</li></ul><p>此外，在了解何时可在 <strong>全局性</strong>或 <strong>class专属的</strong>基础上合理替换缺省的new和delete：</p><ul><li>为了检测运用上的错误</li><li>为了手机动态分配内存之使用统计信息</li><li>为了增加分配和归还的速度</li><li>为了降低缺省内存管理器带来的空间额外开销</li><li>为了弥补缺省分配器中的非最佳齐位</li><li>为了将相关对象成簇集中</li><li>为了获得非传统的行为</li></ul><p><strong>总结</strong></p><p>有许多理由需要写个自定义的new和delete，包括改善效能，对heap运用错误进行调试，收集heap使用信息。</p><h3 id="51-条款：编写new和delete时需固守常规"><a href="#51-条款：编写new和delete时需固守常规" class="headerlink" title="51 条款：编写new和delete时需固守常规"></a>51 条款：编写new和delete时需固守常规</h3><p>让我们从实现operator new开始，实现一致性operator new必须返回正确的值，内存不足的时候必须调用new-handling函数，必须有对付零内存需求的准备，还需避免不慎掩盖正常形式的new。</p><p>operator new其实比较单纯，如果能够申请到空间，就返回正确的值，如果申请不到空间就返回一个bad-alloc。但是他也有不单纯的一面，因为operator不止一次的申请内存，如果new-handling有能力做一些操作释放内存出来，因此只有在new-handling返回null的时候才会抛出错误。</p><p>如果你打算控制operator new[]的行为，你唯一要做的事情就是分配一块未加工的内存。因为你无法知道array中将会保存什么东西。</p><p>对于operator delete来说，我们要确保的是 <strong>删除null指针永远安全</strong>。</p><p><strong>总结</strong></p><ul><li>operator new应该内含一个无穷循环，并在其中尝试分配内存，如果它无法满足内存的需求，就调用new-handler。它应该也有能力处理0byte申请。class 专属版本则应该处理 <strong>比正确大小更大的错误。</strong></li><li>operator delete应该受到null指针时不做任何事，class专属版本则还应该处理 <strong>比正确大小更大的申请。</strong></li></ul><h3 id="52-条款：写了placement-new也要写placement-delete"><a href="#52-条款：写了placement-new也要写placement-delete" class="headerlink" title="52 条款：写了placement new也要写placement delete"></a>52 条款：写了placement new也要写placement delete</h3><p>placement new和placement delete应当也成对的出现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">widget* pw = <span class="keyword">new</span> widget;</span><br></pre></td></tr></table></figure><p>当我们通过上面的代码的时候，实际上做了两件事情，第一件是new，第二件是调用了widget的default构造函数。如果在第二种情况下发生了异常，new成功执行。这种情况下我们要去释放new所申请的空间，但是我们手上并没有申请得到的指针，因此释放内存的重任就交给了C++。</p><p>如果当前面对的是拥有正常签名的new和delete函数，那么系统在运行期间就会主动去调用相应的delete函数。</p><p>但是如果我们使用的new是我们修改过的，带有附加参数的new，这时候我们需要制定一个与之对应的delete函数。</p><p>此外，由于成员函数名称将会覆盖其外围作用域的相同名称，你必须小心避免掉这种覆盖。一个简单的做法就是建立一个base class，内含所有正常形式的new和delete，凡是想以自定形式扩充标准形式的客户，可利用继承机制及using声明式来取得标准形式。</p><p><strong>总结</strong></p><ul><li>当你写一个placement operator new。请确定也写出对应了placement operator delete函数，如果没有这样做的话，你的程序可能会发生隐微而断续的内存泄漏。</li><li>当你声明placement new和placement delete，请确定不要无意识地掩盖了他们的正常版本。</li></ul><p>一知半解。。。</p>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(七) 模板与范型编程</title>
      <link href="/2019/11/19/effective-cpp-%E4%B8%83-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E8%8C%83%E5%9E%8B%E7%BC%96%E7%A8%8B/"/>
      <url>/2019/11/19/effective-cpp-%E4%B8%83-%E6%A8%A1%E6%9D%BF%E4%B8%8E%E8%8C%83%E5%9E%8B%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>2019/11/19 effective cpp 第七章 模板与范型编程</p><p>C++ template最初是为了让我们建立类型安全的容器，如vector，list，map等等，后来随着越来越多的人用上模板之后，人们发现，template这种代码与其处理对象类型分离，彼此独立的风格很好，于是人们道出了模板元编程，template的作用越来越大。</p><p>本章主要解决在使用template上遇到的一些可以避免，优化的问题。</p><ul><li>41 条款：了解隐式接口和编译期多态</li><li>42 条款：了解typename的双重含义</li><li>43 条款：学习处理模板化基类内的名称</li><li>44 条款：将与参数无关的代码抽离template</li><li>45 条款：运用成员函数模板接受所有兼容类型</li><li>46 条款：需要类型转换时请为模板定义非成员函数</li><li>47 条款：请使用traits classes表现类型信息</li><li>48 条款：认识template元编程</li></ul><!--moew--><h3 id="41-条款：了解隐式接口和编译期多态"><a href="#41-条款：了解隐式接口和编译期多态" class="headerlink" title="41 条款：了解隐式接口和编译期多态"></a>41 条款：了解隐式接口和编译期多态</h3><p>面向对象编程总是以显式的接口和运行期多态来解决问题，它具有两个特点：</p><ul><li>必须在子类总的各种方法，且他的代码在源码中是明确可见的。</li><li>由于widget的某些成员函数是virtual，w对于那些函数的调用将表现出运行期间的多态，根据运行期间w的动态类型来决定调用哪一个函数。</li></ul><p>在template的泛型编程中，我们将函数转变为函数模板：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doProcessing</span><span class="params">(T&amp; w)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (w.size() &gt; <span class="number">10</span> &amp;&amp; w!= someWidget)&#123;</span><br><span class="line">    <span class="function">T <span class="title">temp</span><span class="params">(w)</span></span>;</span><br><span class="line">    temp.normalize();</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码，我们可以认为T这种类型应该具有size(),normalize()这些函数，允许进行大小的比较。但是实际上，对于模板类来说，他不一定必须要具备这些，这就是和显示接口的一个重大的不同。</p><p><strong>对于显式接口来说</strong>，<strong>他由函数的签名式构成，即包含函数的名称，参数类型，返回类型。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">widget</span>&#123;</span></span><br><span class="line">  widget();</span><br><span class="line">  <span class="keyword">virtual</span> ~widget();</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">normalize</span><span class="params">()</span></span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>对于隐式接口来说，他并不是基于函数签名式，而是由有效表达式组成的，如上的第一份代码。</strong></p><p>由于操作符允许重载，因此在实现上述接口的时候，类型T不必要满足支持size成员函数，operation成员函数等。对于size()可由他的父类来提供。对于operator&gt;来说，只要存在一个隐式转换就能够进行类型的转换，将操作符两边的对象转换为同一种对象即可。</p><p><strong>总结</strong></p><ul><li>classes和templates都支持接口和多态</li><li>对class而言，接口式显式的，以函数签名为中心，多态则是通过virtual函数发生于运行期。</li><li>对template参数而言，接口式隐式的，基于有效表达式。多态则是通过template具现化和函数重载解析与编译期的。</li></ul><h3 id="42-条款：了解typename的双重含义"><a href="#42-条款：了解typename的双重含义" class="headerlink" title="42 条款：了解typename的双重含义"></a>42 条款：了解typename的双重含义</h3><p><strong>在template的声明式中，class和typename没有不同。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt; <span class="title">class</span> <span class="title">widget</span>;</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="class"><span class="keyword">class</span> <span class="title">widget</span>;</span></span><br></pre></td></tr></table></figure><p>当我们在声明参数的时候，上面的两种表达方式完全相同。</p><p>在template中，我们存在着两种类型的变量。</p><p><strong>从属名称：</strong>template内部出现名称依赖于某个template参数。如果存在嵌套的话，则称为嵌套从属名称，如C::iterator，类型C的从属名称。</p><p><strong>非从属名称：</strong>对于类似于int那种名称，不依赖于template。</p><p>对于从属名称来说，typename有时候表示为一种类型，而有时候则是一个成员白能量，例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> C&amp; container)</span></span>&#123;</span><br><span class="line">  C::const_iterator*x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>当上式C::const_iterator表示一个变量的时候，上面变成一个乘法的表达式，如果他是一个类型的话，那就表示声明了一个local的指针。</strong></p><p>C++是如何区分这种情况的呢，<strong>C++在默认的情况下，处理从属关系的时候优先认为这是一个变量，而不是一个类型，除非你告诉编译器。</strong></p><p>显式告诉编译器这是个类型的方式是通过typename来实现的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> C&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> C&amp; container)</span></span>&#123;</span><br><span class="line">  <span class="keyword">typename</span> C::<span class="function">cosnt_iterator <span class="title">iter</span><span class="params">(container.begin())</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>typename只被用来确定嵌套从属类型的名称，在其他地方不要去使用它。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> C&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">const</span> C&amp; container,         <span class="comment">// 一定不要使用typename</span></span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">typename</span> C::iterator iter)</span></span>;  <span class="comment">// 一定要使用typename</span></span><br></pre></td></tr></table></figure><p>此外，在typename在一个特殊的例子中是不允许使用的，就是 <strong>base class list 以及mem init list即父类列表，以及成员初始化的初始化列表中不允许使用。</strong></p><p>当我们在使用嵌套类型的时候，有时候类型名非常的长，我们希望通过typedef来给他重命名，可以将typedef typename一起连用：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">typename</span> <span class="built_in">std</span>::iterator_traits&lt;iterT&gt;::value_type value_type;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>声明template参数时，前缀关键字class和typename可互换。</li><li>请使用关键字typename标识嵌套从属类型的名称，但不得在base class lists或mem init list以他作为base class修饰符。</li></ul><h3 id="43-条款：学习处理模板化基类内的名称"><a href="#43-条款：学习处理模板化基类内的名称" class="headerlink" title="43 条款：学习处理模板化基类内的名称"></a>43 条款：学习处理模板化基类内的名称</h3><p>template的继承和显式的继承有些不同之处：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> company&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loggin</span>:</span><span class="keyword">public</span> MsgSender&lt;company&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendClearMSG</span><span class="params">(<span class="keyword">const</span> MsgSender&lt;Company&gt;)</span></span>&#123;</span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">      sendClear(info);  <span class="comment">// 调用父类中的sendClear函数</span></span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码如果实在class的继承中，一定是成立的，但是template继承中则会出错，因为在继承<code>MsgSender&lt;company&gt;</code>的时候，编译器并不知道这是个什么样的class，也就自然不知道这个class中是否有一个sendClear函数了，因此上面的调用将会出错。</p><p>解决方法：</p><ol><li><strong>在base class函数调用动作之前加上this-&gt;</strong></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> company&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loggin</span>:</span><span class="keyword">public</span> MsgSender&lt;company&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendClearMSG</span><span class="params">(<span class="keyword">const</span> MsgSender&lt;Company&gt;)</span></span>&#123;</span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">      <span class="keyword">this</span>-&gt;sendClear(info);  <span class="comment">// 调用父类中的sendClear函数</span></span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>使用using声明式，是的父类的方法能够在子类中可见</strong></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> company&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loggin</span>:</span><span class="keyword">public</span> MsgSender&lt;company&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendClearMSG</span><span class="params">(<span class="keyword">const</span> MsgSender&lt;Company&gt;)</span></span>&#123;</span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">      <span class="keyword">using</span> MsgSender&lt;company&gt;::sendClear;</span><br><span class="line">      sendClear(info);  <span class="comment">// 调用父类中的sendClear函数</span></span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>明确指出函数在base class内</strong></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> company&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loggin</span>:</span><span class="keyword">public</span> MsgSender&lt;company&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sendClearMSG</span><span class="params">(<span class="keyword">const</span> MsgSender&lt;Company&gt;)</span></span>&#123;</span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">      MsgSender::sendClear(info);  <span class="comment">// 调用父类中的sendClear函数</span></span><br><span class="line">      <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在template继承的时候，子类对父类的方法一无所知，因此我们需要通过this，或者明确指出父类方法的方式得到函数的声明。</p><p><strong>总结</strong></p><ul><li>可在derived class templates内通过<code>this-&gt;</code>指涉base class template内的成员名称，或由一个明白写出的base class资格的修饰符，使用using 或直接由类调用。</li></ul><h3 id="44-条款：将与参数无关的代码抽离template"><a href="#44-条款：将与参数无关的代码抽离template" class="headerlink" title="44 条款：将与参数无关的代码抽离template"></a>44 条款：将与参数无关的代码抽离template</h3><p>template是一个节约时间与避免代码重复的一个方法。但是有时候我们可能会导致代码膨胀。</p><p>一些指针，vector，list等等，位于父类函数中，将会造成代码的膨胀。</p><p><strong>总结</strong></p><ul><li>template生成多个class和多个参数，所以任何template代码都不该与某个造成膨胀的template参数产生相依的关系。</li><li>因非类型末班参数而造成的代码膨胀，往往可以消除，做法是用函数参数或class成员变量替代template参数</li><li>因类型参数而造成的代码膨胀往往可以降低，做法是让带有完全相同的二进制表述的具现类型共享实现码。</li></ul><h3 id="45-条款：运用成员函数模板接受所有兼容类型"><a href="#45-条款：运用成员函数模板接受所有兼容类型" class="headerlink" title="45 条款：运用成员函数模板接受所有兼容类型"></a>45 条款：运用成员函数模板接受所有兼容类型</h3><p>智能指针是行为上像是一个指针的对象，它提供了指针的所有机能，在STL容器中，我们总是使用智能指针。此外指针的另一很好的优点在于支持<strong>隐式转换</strong>，即子类指针可以隐式的转换为父类指针。但是这种关系在template类模板中是不存在的。</p><p><strong>用具有base-derived关系的对象去具现化某个template的时候，产生出来的的具现体并不具有base-derived的关系。</strong></p><p>一个可行的方法就是实现一个template构造函数，即构造模板：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SmartPtr</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">    SmartPtr(<span class="keyword">const</span> SmartPtr&lt;U&gt;&amp; other);  <span class="comment">// 将一个具现化的u转型为t</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这一构造函数根据对象u创建对象t，而u和t的类型是同一个template的不同具现体，我们称这个函数为泛化copy构造函数。需要注意的是，<strong>上面的前提是说，一个U可以被转型为T。</strong></p><p>我们同样可以在构造函数中完成我们想要达到的转化：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SmartPtr</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> U&gt;</span><br><span class="line">    SmartPtr(<span class="keyword">const</span> SmartPtr&lt;U&gt;&amp; other)</span><br><span class="line">      :heldPtr(other.get())&#123;...&#125;  <span class="comment">//  使用u的指针去初始化t变量的指针</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    T* heldPtr;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>同样的，上述的做法是在 <strong>U指针可以隐式转换为T*的基础上才成立的。</strong></p><p>泛化copy构造函数与普通的copy构造函数之间不存在冲突，因此具现化后的类，依旧会为这个类实现一个copy构造函数。</p><p><strong>总结</strong></p><ul><li>请使用member function templates成员函数模板，生成可接受所有兼容类型的函数。（即上面的u-&gt;t）。</li><li>如果你声明member templates用于泛化copy构造或泛化assignment操作，你还是需要声明正常的copy构造函数和copy assignment操作符，因为编译器默认生成的函数不会因为生成泛化copy构造函数受到影响。</li></ul><h3 id="46-条款：需要类型转换时请为模板定义非成员函数"><a href="#46-条款：需要类型转换时请为模板定义非成员函数" class="headerlink" title="46 条款：需要类型转换时请为模板定义非成员函数"></a>46 条款：需要类型转换时请为模板定义非成员函数</h3><p>当我们在使用template来定义非成员函数，同时这个成员函数的参数需要隐式的转换的话，我们可能会遇到问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">const</span> Rational&lt;T&gt; <span class="keyword">operator</span>* (<span class="keyword">const</span> Rational&lt;T&gt;&amp; lhs,<span class="keyword">const</span> Rational&lt;T&gt;&amp; rhs)</span><br><span class="line">&#123;...&#125;</span><br></pre></td></tr></table></figure><p>当我们调用上面代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rational&lt;<span class="keyword">int</span>&gt; result = onehalf*<span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>将会出现编译错误，因为template类型<code>Rational&lt;T&gt;</code>在具现化的时候需要确定T的类型，当遇到2的时候，C++无法推断出T为int，因此无法通过编译。</p><p>此路不通，我们曲线救国，通过将<code>Rational&lt;T&gt;</code>申请为class Rational的friend函数的方式来实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">   <span class="keyword">friend</span> Rational <span class="keyword">operator</span>*(<span class="keyword">const</span> rational&amp; lhs,<span class="keyword">const</span>&amp; rhs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过友元的方式来制定一个具体的函数，从而避免template进行参数的推导。</p><p>但是上面方法同样会引发一个问题，就是我们通过友元的方式，使得我们可以通过友元来确定函数，但是仅仅是个声明，没有函数的实现，一个最直接的方法就是我们直接将函数的本体定义在Rational乘法里头。</p><p><strong>总结</strong></p><ul><li>当我们需要编写一个class template，而他所提供的与此template相关的函数支持所有参数隐式类型转换时，请将那些函数定义为class template内部的friend函数。</li></ul><h3 id="47-条款：请使用traits-classes表现类型信息"><a href="#47-条款：请使用traits-classes表现类型信息" class="headerlink" title="47 条款：请使用traits classes表现类型信息"></a>47 条款：请使用traits classes表现类型信息</h3><p>在一些状况下，我们需要知道一个类的某些信息。<strong>traits构件</strong>就是做这件事情的，他是一种技术，也是C++程序员所遵守的一种协议。我们将trait放入一个template中去：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> TT&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">iterator_traits</span>;</span></span><br></pre></td></tr></table></figure><p>接下来我们确认一个traits中应该包含哪些信息：</p><ul><li>确认若干你希望将来可取得的类型的相关信息，例如对于迭代器，我们希望将来可取的他的分类。</li><li>为该信息选择一个名称</li><li>提供一个template与一组特化版本，内含你希望看到的相关信息</li></ul><p>接下来是如何使用traits：</p><ul><li>建立一个重载函数或函数模板，彼此的差异在于各自的trait参数；</li><li>建立一个控制函数或函数模板，用于调用上述的函数，并传递trait信息。</li></ul><p><strong>总结</strong></p><ul><li>traits class使得类型相关信息在编译期可用，它以template和templates特化完成实现。</li><li>整合重载技术后，trait class有可能在编译期对类型执行if … else 操作。</li></ul><h3 id="48-条款：认识template元编程"><a href="#48-条款：认识template元编程" class="headerlink" title="48 条款：认识template元编程"></a>48 条款：认识template元编程</h3><p>template metaprogramming元编程是编写template-based c++程序并执行与编译期的过程。</p><p><strong>总结</strong></p><ul><li>元编程可将工作由运行期移往编译期，因而得以实现早期错误侦测和更高的执行效率</li><li>TMP可被用来生成 <strong>基于政策选择组合</strong>的客户定制代码，也可用来避免生成对某些特殊类型并不适合的代码。</li></ul><p>it is a little difficult for me,but never mind !</p>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(六) 继承与面向对象设计</title>
      <link href="/2019/11/16/effective-cpp-%E5%85%AD-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/"/>
      <url>/2019/11/16/effective-cpp-%E5%85%AD-%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p>2019/11/16 effective cpp 第六章 继承与面向对象设计</p><p>面向对象编程成为一个风靡一时的重要特性，关于C++在面向对象上的一些特性，将在本章进行详细的介绍。</p><ul><li>32 条款：确定你的public继承塑膜出is-a关系</li><li>33 条款：避免遮掩继承而来的名称</li><li>34 条款：区分接口继承和实现继承</li><li>35 条款：考虑virtual函数与外的其他选择</li><li>36 条款：绝不重新定义继承而来的non-virtual函数</li><li>37 条款：绝不重新定义继承而来的缺省参数值</li><li>38 条款：通过符合塑模出has-a或“根据某物实现出”</li><li>39 条款：明智而审慎地使用private继承</li><li>40 条款：明智而审慎地使用多重继承</li></ul><a id="more"></a><h3 id="32-条款：确定你的public继承塑膜出is-a关系"><a href="#32-条款：确定你的public继承塑膜出is-a关系" class="headerlink" title="32 条款：确定你的public继承塑膜出is-a关系"></a>32 条款：确定你的public继承塑膜出is-a关系</h3><p>作者通过一个例子表明立场，说明一个<strong>戒慎恐惧</strong>的东西，将会使人们记得异常牢固。接下来他说我们应该用同样的心态记住下面的话：</p><p><strong>public继承意味着是一种is-a关系</strong>，即子类通过public的方式继承父类，那么子类在任何场合都可以直接转变为父类。</p><p>即D以public的方式继承自B，意味着B比D表现出更一般化的概念，D比B则表现出更加的特殊化。B可以使用的地方D一定可以使用，D可以使用的地方B不一定可以使用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span>...&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">student</span>:</span><span class="keyword">public</span> Person&#123;...&#125;;</span><br></pre></td></tr></table></figure><p>上诉的代码表明是一个学生一定是一个人。任何函数希望得到一个person参数的时候，通常也愿意接受一个student对象。即给父类参数传递一个子类对象作为参数，是符合继承的观点，合法的。</p><p><strong>总结</strong></p><ul><li>public继承意味着“is-a”的关系。适用于base classes身上的每一件事情一定也适用于derived class 身上，因为每一个derived classes 对象也都是一个base classes对象。</li></ul><h3 id="33-条款：避免遮掩继承而来的名称"><a href="#33-条款：避免遮掩继承而来的名称" class="headerlink" title="33 条款：避免遮掩继承而来的名称"></a>33 条款：避免遮掩继承而来的名称</h3><p>这个内容与作用域相关，指的是在不同的作用域之中，变量的遮掩。编译器从local领域从发，向外一步步直到找到变量。</p><p>当我们在谈论继承的时候，当位于一个derived class成员函数的内指涉base class内的某物，编译器可以找出所指涉的东西，因为derived classes继承了声明与base class内的所有东西。<strong>子类的作用域嵌套在base class作用域内，子类对象可以调用父类的成员。</strong></p><p>例如下面例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">base</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf2</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">boid <span class="title">mf4</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上述例子中混合了public，private名称，以及一组成员变量和成员函数名称，包含了pure virtual，virtual，non-virtual三种，假设mf4函数实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Derived::mf4()&#123;</span><br><span class="line">  ...</span><br><span class="line">    mf2();</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 当编译器遇到mf2的时候，必须估算他所指涉的东西，编译器的做法是查找各个作用域，看看有没有mf2的声明式，首先是local，然后是外围作用域，base的作用域，最外层的global作用域。</p><p>下面我们考虑一个重载带来的问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">base</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf2</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">(<span class="keyword">double</span>)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们重载了mf1和mf3函数，base class中的mf1和mf3都被子类的函数所代替，但是此时对于父类中的重载函数将会发生错误：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Derived d;</span><br><span class="line">d.mf1(); <span class="comment">//正常调用</span></span><br><span class="line">d.mf1(x); <span class="comment">// 含参数的那个函数也被mf1函数所覆盖，因此调用出现问题</span></span><br><span class="line">d.mf3(); <span class="comment">// 正常调用</span></span><br><span class="line">d.mf3(x); <span class="comment">// 出错</span></span><br></pre></td></tr></table></figure><p>为了解决上面出现的遮掩行为造成的错误，我们可以使用using声明式来达到目的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span><span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="keyword">using</span> Base::mf1;</span><br><span class="line">  <span class="keyword">using</span> Base::mf3;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">mf3</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用using机制使得继承可以得到完美的实现。子类中调用d.mf3(x)将会到父类中寻找d.mf3(x)函数进行调用。</p><p><strong>这意味着你继承base class并加上重载函数，而你又希望重新定义或覆盖其中的一部分，那么你必须为那些原本会遮掩的每个名称引入一个using声明式，否则某些你希望的名称将会被遮掩。</strong></p><p>另一种情况是，当我们只希望继承父类重载的多个函数中的一个函数的时候，我们使用转交函数的方式，在子类函数中调用父类的函数，使其成为inline：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span><span class="keyword">private</span> Base&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">mf1</span><span class="params">()</span></span>&#123;  <span class="comment">// 转交函数，只实现了一个版本，有参数的那个版本在子类中未继承</span></span><br><span class="line">      Base::mf1();  <span class="comment">// 使其成为inline</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>子类内的名称会遮掩base classes内的名称，在public继承下从来没有人希望如此</li><li>为了让遮掩的名称重见天日，可以使用using 声明式或转交函数。</li></ul><h3 id="34-条款：区分接口继承和实现继承"><a href="#34-条款：区分接口继承和实现继承" class="headerlink" title="34 条款：区分接口继承和实现继承"></a>34 条款：区分接口继承和实现继承</h3><p>在类的继承中，可以通过三种方式进行继承：</p><ul><li>继承一个接口（pure virtual）</li><li>继承接口以及接口的部分实现，子类选择覆盖这些实现（impure virtual）</li><li>继承接口以及接口的部分实现，子类不覆盖这些实现（non-virtual）</li></ul><p><strong>成员函数的接口总是会被继承</strong></p><p>pure virtual函数最突出的特性，他们必须被任何继承了他们的具象class重新声明，而且他们在抽象class中通常没有定义。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>声明一个pure virtual函数的目的是为了让derived classes只继承函数接口。</strong></p><p>对于shape::draw函数来说，这样是十分合理的，因为每个shape对象都应该有一个draw函数，同时由于shape子类形状各异，因此父类无法提供一个缺省（通用的）实现方式。</p><p>但是令人意外的是：<strong>我们可以为纯虚pure virtual函数提供一份实现代码，但是调用他的唯一途径就是明确指出class的名称。</strong>但是pure virtual依然无法创建对象。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">shape* ps = <span class="keyword">new</span> shape;</span><br><span class="line">shape* ps1 = <span class="keyword">new</span> Rectangle;</span><br><span class="line">ps1-&gt;draw();  <span class="comment">// Rectangle的draw函数</span></span><br><span class="line">ps1-&gt;shape::draw(); <span class="comment">// 调用了父类的draw函数</span></span><br></pre></td></tr></table></figure><p><strong>声明非纯impure virtual函数的目的，就是让derived classes继承该函数的接口和缺省实现。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">error</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; msg)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码表示每个class都必须支持一个“当遇到错误时可调用”的函数，但每个class可自由处理错误。如果不愿意自己处理错误的话，也可以使用父类的缺省实现。</p><p>但是这就会出现一个问题，当我们继承了一个韩非纯函数的父类的时候，我们可能会忘记实现自己的版本，此时编译器就会为了安排默认的版本，而引发错误，下面这种做法就是为了解决这个问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Airplane</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(cosnt sAirport&amp; destination)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">protected</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">defaultFly</span><span class="params">(cosnt Ariport&amp; destination)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> Airplane::defaultFly(<span class="keyword">const</span> Airport&amp; destination)&#123;</span><br><span class="line">  <span class="comment">//fly函数中的实现部分改到这里来写</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述操作将fly函数又impure设置成pure函数，意味着子类必须有自己实现的版本，在缺省的实现部分转移到defaultFly当中去，如果子类不实现fly函数则会报错，如果希望用缺省方式的话，则调用defaultFly函数。</p><p>但是上面这种做法将会导致代码的重复这种情况。</p><p>另一种做法是将默认的实现部分转移到纯虚函数的实现中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Airplane</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(cosnt Airport&amp; destination)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> Airplane::fly(cosnt Airport&amp; destination)&#123;</span><br><span class="line">  <span class="comment">//缺省行为，将飞机飞至指定的目的地</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelA</span>:</span><span class="keyword">public</span> Airplane&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">fly</span><span class="params">(<span class="keyword">const</span> Airport&amp; destination)</span></span>&#123;</span><br><span class="line">      Airplane::fly(destination); <span class="comment">// 使用缺省的方式实现</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;；</span><br><span class="line"><span class="comment">// 如果你要自己实现fly这个函数的话，可以自己写相应的方法</span></span><br></pre></td></tr></table></figure><p>这种方式避免了再去定义一个defaultFly函数。现在的fly函数被切割成两个部分，其声明部分表现的是接口，其定义部分表现出缺省行为。</p><p><strong>声明non-virtual函数的目的就是为了令derived classes继承函数的接口及一份强制性的实现。</strong></p><p>由于non-virtual函数代表的意义是不变性凌驾于特异性之上，我们绝对不要在子类中重新定义父类中的non-virtual函数。</p><p><strong>总结</strong></p><ul><li>接口继承和实现继承不同。在public继承之下，derived classes总是继承base class的接口。</li><li>pure virtual函数只具体指定接口继承。</li><li>非纯的函数具体制定接口继承及缺省实现继承。</li><li>non-virtual函数具体指定接口继承以及强制性实现继承。</li></ul><h3 id="35-条款：考虑virtual函数与外的其他选择"><a href="#35-条款：考虑virtual函数与外的其他选择" class="headerlink" title="35 条款：考虑virtual函数与外的其他选择"></a>35 条款：考虑virtual函数与外的其他选择</h3><p>我们可以使用一些其他的方式来代替virtual的使用</p><p><strong>template method模式</strong></p><p>这种模式为将虚函数修改为public的non-virtual函数，然后其具体的实现通过定义一个private的virtual函数来实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GameCharacter</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">healthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">      ... <span class="comment">// 调用前准备</span></span><br><span class="line">      <span class="keyword">int</span> retval = dohealthValue();</span><br><span class="line">      ... <span class="comment">// 调用后处理</span></span><br><span class="line">      <span class="keyword">return</span> retval;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">dohealthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p> 上面的设计令用户通过public non-virtual成员函数佳节调用private virtual函数的模式（NVI non-virtual interface），把non-virtual函数作为一个外覆器，在调用前后都可以进行一些处理，这是这种方法的一个优点，但是缺点是我们需要定义很多private virtual函数。</p><p><strong>籍由Function Pointers实现strategy模式</strong></p><p>利用传入一个函数指针的方式，进行实际的操作。</p><p>函数指针的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">defaultHealth</span><span class="params">(<span class="keyword">const</span> GameCharacter&amp; gc)</span></span>;</span><br><span class="line"><span class="comment">//函数指针如下</span></span><br><span class="line">return_types (*func_pointer)( data_types arg1, data_types arg2, ..);</span><br><span class="line"><span class="keyword">int</span> (*defaultHealth)(<span class="keyword">const</span> GameCharacter&amp;);</span><br><span class="line"><span class="comment">//使用上面的定义之后，就可以用指针defaultHealth来调用函数了</span></span><br></pre></td></tr></table></figure><p>上述这种方法提供了某种弹性，在调用不同的类型的时候，传入不同计算方法的函数的指针，得到不同的计算方式。当我们使用了类外的方法的时候，我们可能会陷入一个陷阱中，就是这个函数只能访问类的public部分，如果我们想进一步的话，就只能降低函数的封装级别了。</p><p><strong>籍由tr1::function完成strategy模式</strong></p><p><strong>C++ Technical Report 1 （TR1</strong>）是ISO/IEC TR 19768, C++ Library Extensions（函式库扩充）的一般名称。TR1是一份文件，内容提出了对C++标准函式库的追加项目。这些追加项目包括了正则表达式、智能指针、哈希表、随机数生成器等。</p><p><strong>function 是一种通用、多态的函数封装</strong>。<strong>std::function 的实例可以对任何可以调用的目标进行存储、复制、和调用操作，这些目标包括函数、lambda 表达式、绑定表达式、以及其它函数对象等</strong>。（c++11起的版本可用）<br>　　function（和bind一样）可以实现类似函数指针的功能，却比函数指针更加灵活（体现在占位符上面），尤其是在很多成员调用同一个函数（仅仅是参数类型不同）的时候比较方便。</p><p><strong>C++中的函数签名(function signature)</strong>：包含了一个函数的信息，包括函数名、参数类型、参数个数、顺序以及它所在的类和命名空间。</p><p>function对象只要签名式满足要求，那么这个对象就可以存储任何可调用物。下面我们使用function来替代上面的函数指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GameCharacter</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> <span class="built_in">std</span>::str1::function&lt;<span class="keyword">int</span> (<span class="keyword">const</span> GameCharacter&amp;)&gt; healthCalFunc;</span><br><span class="line">    explicit GameCharacter(HealthCalcFunc hcf = defaultHealthCalc):healthFunc(hfc)&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">healthValue</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> healthFunc(*<span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    HealthCalcFunc healthFunc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由上面代码可以看出来，我们只要传入一下接受一个const reference参数的任意函数都可以，我们可以使用函数，函数对象，成员函数等等。</p><p><strong>古典的strategy模式</strong></p><p>传统的strategy做法将一个健康的计算函数做成一个分离的继承体系中的virtual成员函数。</p><p><strong>替代方案</strong></p><p>本条条款的核心就是可以通过一下几种方式来找到virtual的替代方案：</p><ul><li>使用non-virtual interface手法，那是template method设计模式的一种特殊形式，它以public non-virtual成员函数包裹较低访问性的virtual函数。</li><li>将virtual函数替换为函数指针成员变量，这是strategy设计模式的一种分解形式。</li><li>以tr1::function成员变量替换virtual函数，因而允许使用任何可调用物来搭配一个兼容于需求的签名式。</li><li>将继承体系内的virtual函数替换为另一个继承体系内的virtual函数，这是strategy设计模式的传统实现方法。</li></ul><p><strong>总结</strong></p><ul><li><p>virtual 函数的替代方案包含NVI，以及strategy设计模式的多种形式，NVI手法是一个特殊形式的template method模式。</p></li><li><p>将机能从成员函数一道class外部函数，带来一个缺点，非成员函数无法访问class的non-public成员。</p></li><li>tr1::function对象行为就像一般函数指针，这样的对象可接纳与给定目标签名式兼容的所有可调物。</li></ul><h3 id="36-条款：绝不重新定义继承而来的non-virtual函数"><a href="#36-条款：绝不重新定义继承而来的non-virtual函数" class="headerlink" title="36 条款：绝不重新定义继承而来的non-virtual函数"></a>36 条款：绝不重新定义继承而来的non-virtual函数</h3><p>在一个类中，我们定义了non-virtual函数，意味着我们遵循设计原则，认为这个函数的不变性要大于特异性，因此我们不可以在子类中对这个函数进行覆盖。否则，将同一个元素赋值给父类和子类，将导致不同的行为，这是我们不希望看到的。</p><p><strong>总结</strong></p><ul><li>绝对不要重新定义继承而来的non-virtual函数</li></ul><h3 id="37-条款：绝不重新定义继承而来的缺省参数值"><a href="#37-条款：绝不重新定义继承而来的缺省参数值" class="headerlink" title="37 条款：绝不重新定义继承而来的缺省参数值"></a>37 条款：绝不重新定义继承而来的缺省参数值</h3><p>当我们继承一个父类的时候，如果父类中的virtual函数带有缺省值，我们选择不去重写这个缺省值。原因是：</p><p><strong>virtual函数系动态绑定，而缺省参数值确实静态绑定。</strong>因此缺省的参数值在定义的时候就会被确定，缺省值就是定义这个函数的类给赋予的。如下面代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> shapecolor&#123;red,green,blue&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = red)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> Shape&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = green)</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">void</span> rectangle::draw(Shape::shapecolor color) <span class="keyword">const</span> &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"---"</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; color;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"---"</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Shape *ps = <span class="keyword">new</span> rectangle();</span><br><span class="line">rectangle* rec = <span class="keyword">new</span> rectangle();</span><br><span class="line">ps-&gt;draw();  <span class="comment">// 使用静态绑定的shape中的缺省值</span></span><br><span class="line">rec-&gt;draw(); <span class="comment">// 使用静态绑定的rectangle中的缺省值</span></span><br></pre></td></tr></table></figure><p>上述代码就可以看出矛盾，同一个对象却有不同的表现，导致缺省值的不同。上述代码的一个解决方案就是使用NVI方式，用non-virtual去调用virtual函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> shapecolor&#123;red,green,blue&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">draw</span><span class="params">(shapecolor color = red)</span></span>&#123;</span><br><span class="line">        doDraw(color);  </span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">doDraw</span><span class="params">(shapecolor color)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">doDraw</span><span class="params">(shapecolor color)</span> <span class="keyword">const</span></span>;  <span class="comment">// 这里不需要指定缺省的参数值</span></span><br><span class="line">&#125;；</span><br></pre></td></tr></table></figure><p>由于non-virtual函数是不会被子类覆盖。这个设计保证了参数值一定是一致的。</p><p><strong>总结</strong></p><ul><li>绝对不要重新定义一个继承而来的缺省参数值，因为缺省参数值都是静态绑定的，而virtual函数（你唯一需要覆盖的东西）是动态绑定的。</li></ul><p>###38 条款：通过符合塑模出has-a或“根据某物实现出”</p><p>has-a表现出来的是一种复合关系（composition），当某种类型的对象内含它种类型的对象，便是这种关系。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    Address ad; <span class="comment">// 其他类型的生成对象</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">  PhoneNumber num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除此之外，还有另一种关系，成为 <strong>is-implemented-in-terms-of</strong> 关系，例如我们实现一个set，直觉上我们可以继承标准库中的set，但是为了资源等考虑，我们打算另辟蹊径。我们可能就会考虑到list的实现，但是我们不能直接继承list，因为list与set不是is-a的关系。但是我们可以在函数中多次使用list结构来构造一个set，<strong>这就是根据某物实现出</strong>的这种关系。</p><p><strong>总结</strong></p><ul><li>复合的意义和public继承完全不同</li><li>在应用域，复合意味着is-a关系。在实现域，复合意味着根据某物来实现。</li></ul><h3 id="39-条款：明智而审慎地使用private继承"><a href="#39-条款：明智而审慎地使用private继承" class="headerlink" title="39 条款：明智而审慎地使用private继承"></a>39 条款：明智而审慎地使用private继承</h3><p>private继承不是一个is-a继承，而是一种子类实现需要使用父类的某些函数性质的 “implemented-in-terms-of”的关系。</p><p>对于private的选择，我们通常会考虑：<strong>当一个意欲成为derived class者想要访问一个意欲成为base class者的protected成分，或者成为重新定义一个或多个virtual函数。</strong>如果满足这个条件的话，我们会考虑使用private继承，但是很多情况下，我们使用复合，将private继承的类作为一个成员变量的方式，能够提供能多的灵活性。</p><p><strong>即：我们可以使用复合的方式来代替private的继承，保证更大的灵活性。</strong></p><p>但是如果我们追求一种更加激进的空间优化，我们会选择使用private继承来代替复合。</p><p>如果我们使用的类满足不带数据成员，没有virtual等条件，满足空白基类最优化EBO的情况下，我们应该优先考虑private继承，但是这种情况基本很少见。</p><p><strong>总结</strong></p><ul><li>private继承意味着 <strong>根据某物实现出</strong>的关系，它通常比复合的级别要低，当时当子类需要访问protected base class的成员，或需要重新定义继承而来的cirtual函数时，是合理的。</li><li>和复合不同，private继承可以造成empty base最优化，这对于严格要求“对象尺寸最小化”的程序开发者而言是很重要的。</li></ul><h3 id="40-条款：明智而审慎地使用多重继承"><a href="#40-条款：明智而审慎地使用多重继承" class="headerlink" title="40 条款：明智而审慎地使用多重继承"></a>40 条款：明智而审慎地使用多重继承</h3><p>当我们设计到多重继承的时候，在子类的使用上将会面临起义的一个问题，共同父类中相同的函数，必须通过类名的方式进行调用。</p><p>对于钻石形的继承关系，我们使用virtual来继承，使得每一个子类都有一份供自己使用的父类成员变量。但是使用virtual将会导致C++编译器在处理这类继承时，生成体积较大的对象，访问速度也比较慢，virtual继承付出的代价更加的明显，规则复杂不够直观。</p><p><strong>忠告</strong></p><ul><li><p>非必须使用virtual bases的时候不要使用它，大部分情况使用non-virtual继承</p></li><li><p>如果必须使用virtual base继承，那么尽量避免在其中放置数据，使得类小一点，以及不会出现难以察觉的赋值问题。</p></li></ul><p>但是有些时候，双重继承也有其合理的用途，保留使用多重继承的看法。如果能用单一继承代替多重继承的话，单一继承是一个非常好的选择。</p><p><strong>总结</strong></p><ul><li>多重继承比单一继承复杂，他可能导致起义性，以及对virtual继承的需要</li><li>virtual继承会增加大小，速度，初始化复杂度等成本，如果virtual base classes不带任何的数据，将会是多重继承最具有使用价值的情况。</li><li>多重继承的确有正当用途，其中一个情节涉及public继承某个interface class和private继承某个协助实现的class的两相组合。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(五) 实现</title>
      <link href="/2019/11/10/effective-cpp-%E4%BA%94-%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/11/10/effective-cpp-%E4%BA%94-%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>2019/11/10，effective cpp第五章 实现</p><p>cpp在实现上存在着很多高效率，代码优化的细节。</p><ul><li>26 条款：经可能延后变量定义式的出现时间</li><li>27 条款：尽量少做转型动作</li><li>28 条款：避免返回handles指向对象内部成分</li><li>29 条款：为异常安全而努力是值得的</li><li>30 条款：透彻了解inlining 的里里外外</li><li>31 条款：将文件间的编译依存关系降至最低</li></ul><a id="more"></a><h3 id="26-条款：经可能延后变量定义式的出现时间"><a href="#26-条款：经可能延后变量定义式的出现时间" class="headerlink" title="26 条款：经可能延后变量定义式的出现时间"></a>26 条款：经可能延后变量定义式的出现时间</h3><p>我们定义一个变量需要承担它的构造成本以及析构成本，如果我们在程序中，由于一些判断条件未能使用到这些变量，那么将造成大量的时间浪费，于是我们应当尽量的延后变量的定义。</p><p>第二个优化的地方在于在定义变量的时候，通过调用构造函数来初始化变量，而不是通过赋值的方式。（通过赋值的方式将会浪费一次系统默认的赋值时间）</p><p>第三个优化的地方，如果我们需要在一个循环中使用变量的话，<strong>我们应该在循环的内部定义变量</strong>，除非析构与构造的成本比较高，且你的代码对效率高度敏感。</p><p><strong>总结</strong></p><ul><li>尽可能延后变量定义式的出现，这样做可以增加程序的清晰度，并改善程序的效率。</li></ul><h3 id="27-条款：尽量少做转型动作"><a href="#27-条款：尽量少做转型动作" class="headerlink" title="27 条款：尽量少做转型动作"></a>27 条款：尽量少做转型动作</h3><p>首先是结论：<strong>优良的C++代码很少使用转型</strong></p><p>C++的设计目标之一就是保证类型错误绝不可能发生，尽量保证任何转型动作尽可能少的发生。转型动作破坏了类型系统，导致一些很隐晦的错误。C++提供的转型变换如下：</p><ul><li><p><code>const_cast&lt;T&gt; (expression)</code>，通常用于对象的常量性移除，将常量去除</p></li><li><p><code>dynamic_cast&lt;T&gt;(expression)</code>，主要用于执行“安全向下转型”，用来决定某对象是否归属继承体系中的某个类型。可能耗费比较大的运行成本。</p></li><li><code>reinterpret_cast&lt;T&gt;(expression)</code>，执行低级转型，例如将point to int 转成int。</li><li><code>static_cast&lt;T&gt;(expression)</code>，用来强迫执行隐式转型，将int转成double等等。</li></ul><p>旧式的转型：</p><ul><li><code>(T)expression</code></li><li><code>T(expression)</code></li></ul><p>旧式的两种写法功能相同，建议使新式的转型方法，因为他们在代码上容易辨认，且各个转型动作目标比较窄，容易排查错误,例如只有const_cast方法才能实现对象的常量移除。</p><p>关于<code>dynamic_cast</code>方法，例如我有有些时候，希望在子类函数调用的时候先调用父类的函数，会写出下面的代码（错误的）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">special</span>:</span> <span class="keyword">public</span> window&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">onResize</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">static_cast</span>&lt;window&gt;(*<span class="keyword">this</span>).onResize();</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上诉代码将this转为window的指针，但是他调用的并不是当前对象上的函数，<strong>转型动作将产生一个this对象的base class的成分的一个副本</strong>。因此window上的onsize操作只是在一个副本上执行操作的，并不会改变this对象的内容。解决的方法是直接调用父类的onsize方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">special</span>:</span> <span class="keyword">public</span> window&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">onResize</span><span class="params">()</span></span>&#123;</span><br><span class="line">    window::onResize();</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>dynamic_cast</code>的场景通常说，我们手上只有一个base class的指针，但是想希望通过它来执行子类的一些操作：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;tr1::<span class="built_in">shared_ptr</span>&lt;window&gt;&gt; vpw;</span><br><span class="line">vpw winptr;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">for</span>(vpw::iterator iter=winptr.begin();iter!=winptr.end();++iter)&#123;</span><br><span class="line">    <span class="keyword">if</span>(special* psw=<span class="keyword">dynamic_cast</span>&lt;special*&gt;(iter-&gt;get()))</span><br><span class="line">      psw-&gt;blink();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>上面代码效率比较低，而且令人担心，因此最后直接用子类的容器存储指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;tr1::<span class="built_in">shared_ptr</span>&lt;special&gt;&gt; vpsw;</span><br><span class="line">vpsw winptr;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span>(vpsw::iterator iter = winptr.begin();iter!=winptr.end();++iter)&#123;</span><br><span class="line">  (*iter)-&gt;blink();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是上面的代码童谣失去了指向所有可能子类的可能，<strong>一个可行的解决方案就是为在base class提供一个缺省实现的blink函数声明。或者是直接用上述方式写出子类</strong></p><p>不论是哪一种写法：使用类型安全容器，或将virtual函数往继承体系上方移动，都是一个替代dynamic_cast 的可行方案。</p><p>绝对需要避免的一种写法是连串使用多个dynamic_cast，这种代码将又大又慢，同时十分的不安全。</p><p><strong>总结</strong></p><ul><li>如果可以，尽可能避免转型，特别在注重效率的代码中避免使用<code>dynamic_cast</code></li><li>如果转型是必要的，试着将它隐藏呀某个函数背后，供客户调用</li><li>宁可使用C++新式的转型，因为容易辨认，同时便于排查错误。</li></ul><h3 id="28-条款：避免返回handles指向对象内部成分"><a href="#28-条款：避免返回handles指向对象内部成分" class="headerlink" title="28 条款：避免返回handles指向对象内部成分"></a>28 条款：避免返回handles指向对象内部成分</h3><p><strong>handles指的是诸如reference，指针，迭代器这种用来取得某个对象的变量，我们应当避免直接返回指向对象内部数据或函数的handle出现。</strong></p><p>如下，我们打算实现一个矩阵类：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">point</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    point(<span class="keyword">int</span> x,<span class="keyword">int</span> y);</span><br><span class="line">  ...</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setX</span><span class="params">(<span class="keyword">int</span> val)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setY</span><span class="params">(<span class="keyword">int</span> val)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//定义角</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RectData</span>&#123;</span></span><br><span class="line">  point ulhc;</span><br><span class="line">  point lrhc;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//定义矩阵</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rectangle</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    tr1::<span class="built_in">shared_ptr</span>&lt;RectData&gt; pData;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">point&amp; <span class="title">upper</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> pData-&gt;ulhc;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>upper函数取得矩阵左上角的点，返回一个引用，这个引用指向了矩阵内部的点，就会引发一个矛盾，我们使用一个const函数，但是返回的值是private数据，且可以被修改。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> Rectangle <span class="title">rec</span><span class="params">(coord1,coord2)</span></span>;</span><br><span class="line">rec.upper().setX(<span class="number">50</span>); <span class="comment">//被修改</span></span><br></pre></td></tr></table></figure><p>从从上面我们可以得出两条结论，</p><ul><li>第一条，成员变量的封装性只能等于返回其reference的级别，即引用的级别决定了封装性。</li><li>第二条，如果const成员函数传出一个reference，后者所指的数据与对象自身有关联，而他又被存储与对象之外，那么这个函数的调用者可以修改那笔数据。</li></ul><p>一个好的解决办法就是在函数调用的时候，将返回值的内容设置成const：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> Point&amp; <span class="title">upperLeft</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> pData-&gt;ulhc;&#125;</span><br></pre></td></tr></table></figure><p>但是即使如此，如果直接返回代表对象内部数据的handle的话，有可能这个handle的生存周期比对象本身的生存周期要长，那么将导致空悬指针的发生（dangling handles）。</p><p>因此：<strong>尽量避免将对象内部的handles传出去。</strong></p><p><strong>总结</strong></p><ul><li>避免返回handles指向对象内部，遵守这个条款可以增加封装性，使得const更加像一个const，并避免虚调handles的发生。</li></ul><h3 id="29-条款：为异常安全而努力是值得的"><a href="#29-条款：为异常安全而努力是值得的" class="headerlink" title="29 条款：为异常安全而努力是值得的"></a>29 条款：为异常安全而努力是值得的</h3><p>对于一个异常安全性的函数来说，他通常有两个条件：</p><ul><li><strong>不泄漏任何资源</strong></li><li><strong>不允许数据败坏</strong>：即出现类似空指针，指向已经销毁的对象这种情况</li></ul><p>第一种情况可以通过资源管理类来完美的解决，下面专门来解决第二种情况</p><p><strong>异常安全函数</strong>提供以下三种程度的保证：</p><ul><li><strong>基本承诺：</strong>如果异常被抛出，程序内的任何事物仍然保持在有效状态下</li><li><strong>强烈承诺：</strong>如果异常被抛出，程序状态不改变，如果函数成功就完全成功，如果函数失败，就恢复到调用函数之前的状态。</li><li><strong>不抛掷保证：</strong>承诺不抛出异常，他们总能完成承诺的功能，例如一些内置类型等。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">doSomething</span><span class="params">()</span> <span class="title">throw</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p>上面的函数带有指定的空白异常，也就是说上述函数抛出异常的话，将会产生很严重的后果，但是该函数并不能提供任何异常安全的保证，异常安全的保护正完全由实现来决定。</p><p>对于异常安全来说，保证不抛出异常基本难以实现。基本上能够实现强烈承诺或基本承诺就可以满足需求了。</p><p>实现强烈承诺，即出现异常情况对象的状态不发生改变，有一个策略称为：<strong>copy and swap</strong>，即为打算修改的对象提供一份副本，并在那个副本上做一切必要的修改，如果出现异常，则原对象未发生改变，如果正常则将副本和原对象进行交换。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> pretty::changeBackground(istream&amp; imgSrc)&#123;</span><br><span class="line">  <span class="keyword">using</span> <span class="built_in">std</span>::swap;</span><br><span class="line">  <span class="function">Lock <span class="title">ml</span><span class="params">(&amp;mutex)</span></span>;    <span class="comment">// 获得mutex的副本</span></span><br><span class="line">  tr1::<span class="built_in">shared_ptr</span>&lt;PMImpl&gt; pNew(<span class="keyword">new</span> PMImpl(*pImpl)); </span><br><span class="line">  pNew-&gt;bgImage.reset(<span class="keyword">new</span> Image(imgSrc));</span><br><span class="line">  ++pNew-&gt;imageChanges;</span><br><span class="line">  swap(pImpl,pNew);  <span class="comment">// 释放mutex</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面可以看出来，对函数的异常保证将花费大量的资源，因此如果强烈保证不能满足的情况下，你就应该转向基本满足的情况。</p><p>对于一个对象来说，它的异常保证的级别取决于最差的一个异常保证函数。</p><p><strong>总结</strong></p><ul><li>异常安全函数即使发生异常也不会泄露资源或允许任何数据结构败坏，这样的函数区分为三种可能的保证：基本型，强烈型，不抛异常型</li><li>强烈保证往往能够以copy and swap实现出来</li><li>函数提供的异常安全保证，通常最高值等于其所调用的各个函数的异常安全保证种最弱的</li></ul><h3 id="30-条款：透彻了解inlining-的里里外外"><a href="#30-条款：透彻了解inlining-的里里外外" class="headerlink" title="30 条款：透彻了解inlining 的里里外外"></a>30 条款：透彻了解inlining 的里里外外</h3><p>inline函数，使用起来像函数，调用他们又不用蒙受额外的函数调用所导致的开销，编译器的最优化机制通常被设计成用来浓缩那些<strong>不含函数调用</strong>的代码，因此inline函数也会得到编译器在当前语境下的最优化处理。</p><p>但是过度使用inline同样会导致很多问题，首先是使得程序的目标码过大，导致一些效率上的损失。</p><p><strong>总之，如果inline函数的本体很小，编译器对函数本体所产出的代码可能比函数调用所产出的代码要小，这种情况将函数inlining确实可以导致较小的目标码和较高的指令高速缓存装置的击中率。</strong></p><p><strong>inline函数的做法</strong>：隐喻的做法是将函数定义在class内，自动就完成了inline的操作。明确声明的做法则是在函数前面加上inline关键字。</p><p><strong>inline函数通常一定被放置于头文件内，因为大多数的生成环境在编译过程中进行inline，需要知道函数本体长什么样子。</strong></p><p>模版类templates也通常被置于头文件内，因为它一旦被使用，编译器为了将它具体化，需要知道它长什么样子。但是templates与inline没有直接的联系，如果你觉得该templates内的函数都比较简单，可以进行inline的话，才会去定义为inline。</p><p><strong>inline是一个申请，编译器可以拒绝</strong></p><p>也就是说，一个函数最终实现方式是否是inline，取决于编译器是否同意该函数满足inline的条件。</p><p>例如大部分过于复杂（含循环，递归等）的函数，virtual声明的函数，通常都会被定义为outline函数。</p><p>有些编译器有意愿inlining某个函数，但是也可能为函数生成一个函数本体。<strong>例如程序要取得某个inline函数的地址，编译器通常必须为此函数生成一个outline函数本体。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;...&#125; <span class="comment">//假设编译器有意愿inline对f的调用</span></span><br><span class="line"><span class="keyword">void</span> (*f)()  = f;</span><br><span class="line">f(); <span class="comment">// 调用inline</span></span><br><span class="line">pf(); <span class="comment">// 调用outline的本体</span></span><br></pre></td></tr></table></figure><p>有时候，编译器会为析构函数和构造函数生成一个函数的副本，这样他们就可以获得指针指向那些需要指针的函数，但是这样一来，导致了析构函数和构造函数的赋值过程。</p><p>实际上析构函数，构造函数往往是inline糟糕的候选人，因为C++在创建对象的时候，将构造对象，析构对象，异常处理等一些操作隐藏在析构函数和构造函数内部，因此函数内部存在着很多的对象。但是对这些对象的副本往往会造成很大的资源消耗。</p><p><strong>因此，是否将构造函数和析构函数inline化，是一个慎重的考虑。</strong></p><p><strong>inline函数修改后必须重新编译</strong></p><p>此外，inline函数还存在一个问题。当我们对inline函数进行修改的时候，原来函数的本体因为已经编译进程序的内部了，无法通过函数的链接步骤实现修改，而是需要对整个程序进行重新编译。</p><p><strong>总结</strong></p><ul><li>将大多数inlining限制在小型、被频繁调用的函数身上，这可使得日后的调试过程和二进制升级更加容易，也可使潜在的代码膨胀问题最小化，使得程序速度提升最大化。</li><li>不要滥用inline，不用只因为function templates出现在头文件中就将他们声明为inline，因为很多时候，这些函数不符合inline标准，编译器还是会为他们生成outline版本</li></ul><h3 id="31-条款：将文件间的编译依存关系降至最低"><a href="#31-条款：将文件间的编译依存关系降至最低" class="headerlink" title="31 条款：将文件间的编译依存关系降至最低"></a>31 条款：将文件间的编译依存关系降至最低</h3><p>文件之间的依存关系越是复杂将会导致函数之间的耦合度越高，对修改代码带来不便。</p><p>例如你仅仅对class进行轻微的修改，但是这将导致所有用到这个文件的程序都需要进行重新编译，这一连串的编译依存关系将导致难以形容的灾难。</p><p>例如下面的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"data.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"address.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Person(<span class="keyword">const</span> <span class="built_in">string</span>&amp; name,<span class="keyword">const</span> Date&amp; birthday);</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">birthday</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> thename;</span><br><span class="line">    Data theData;</span><br><span class="line">    address add;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面的类别的私有变量中，string，Data需要用到其他的头文件来创建（实现细则），这些头文件任意一个被修改后都将导致Person class重新编译。</p><p>针对这种形式，我们可以这样做：</p><p><strong>把person分割为两个classes，一个只提供接口，另一个负责实现该接口。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Date</span>;</span>   <span class="comment">// 类的前置声明</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Address</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Person(<span class="keyword">const</span> <span class="built_in">string</span>&amp; name,<span class="keyword">const</span> Date&amp; birthday);</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">birthday</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    str1::<span class="built_in">shared_ptr</span>&lt;PersonImpl&gt; pImpl;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类PersonImpl为person类的实现，这样的话，修改Data类就不需要对Person函数进行重新编译，将person与其他类进行分离。</p><p>这个分离的关键在于：<strong>使用声明的依存性</strong>来代替<strong>定义的依存性</strong>，尽量让头文件自我满足，万一无法做到，那么让它和其他文件内的声明式相依（而不是定义式）。</p><p>下面一些准则都是这个原则下完成的：</p><ul><li>如果使用object references 或objects pointers可以完成任务，就不要使用object，即使用声明式来代替定义式。</li><li><p>尽量以class声明式代替class定义式。</p></li><li><p><strong>为声明式和定义式提供不同的头文件</strong>，为一个文件提供函数的声明，而不是而代替提供class的定义式，这样可将文件见的编译依存关系去掉。因此我们需要定义两个文件，一个是声明式，另一个是定义式。</p></li></ul><p>上面这个实现使得代码编，让Person变成一个handle class。</p><p><strong>抽象基类</strong></p><p>通过制作抽象类的方式，也可以实现这种操作。通过定义抽象类函数接口，创建不同类型的的派生类对象。</p><p>handle classes 和interface class解除了接口和实现之间的耦合关系，从而减低了文件间的编译依存关系。但是也在某种程度上使得每个对象超额付出若干的时间以及空间的成本。</p><p><strong>总结</strong></p><ul><li>支持<strong>编译依存最小化</strong>的一般构想是：相依与声明式，不要相依于定义式，基于此的构想的两个手段是 handle classes，interface classes。</li><li>程序库头文件应该以完全且仅有的声明式的形式存在，这种做法不论是否涉及templates都适用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(四) 设计与声明</title>
      <link href="/2019/11/09/effective-cpp-%E5%9B%9B-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/"/>
      <url>/2019/11/09/effective-cpp-%E5%9B%9B-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%A3%B0%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<p>2019/11/09 effective cpp 第四章</p><p>良好的cpp接口的设计以及声明是可以令软件作出其最正确的事，包括正确，高效性、封装性、维护性、延展性、以及协议一致性。</p><ul><li>18 条款：让接口容易被正确使用，不易被误用</li><li>19 条款：设计class犹如设计type</li><li>20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value</li><li>21 条款：必须放回对象时，别妄想返回其reference</li><li>22 条款：将成员变量声明为private</li><li>23 条款：宁以non-member、non-friend替换member函数</li><li>24 条款：若所有参数皆需类型转换，请为此采用non-member函数</li><li>25 条款：考虑写出一个不抛异常的swap函数</li></ul><a id="more"></a><h3 id="18-条款：让接口容易被正确使用，不易被误用"><a href="#18-条款：让接口容易被正确使用，不易被误用" class="headerlink" title="18 条款：让接口容易被正确使用，不易被误用"></a>18 条款：让接口容易被正确使用，不易被误用</h3><p>接口开发的目标在于：<strong>让接口容易被正确使用，不易被误用</strong></p><p>但是由于有时候会遇到用户传入的参数和接口能够接受的参数不同，可能会导致错误，这个时候最后通过 <strong>类型系统的方式来预防</strong>，通过导入新的类别来限制数据类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Date</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    Date(<span class="keyword">const</span> Month&amp; m,<span class="keyword">const</span> Day&amp; d,<span class="keyword">const</span> Year&amp; y)&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">Date <span class="title">d</span><span class="params">(Month(<span class="number">3</span>),Day(<span class="number">30</span>),year(<span class="number">1995</span>))</span></span>;</span><br></pre></td></tr></table></figure><p>对数据的限制部分在每一个数据类型的函数内部。明智地选择合适的新类型，能够有效的防止接口被误用。</p><p>另一个预防客户错误的方式是限制类型内可做什么事情，不能做什么事情，常见的限制加上const，阻止用户自定义类型错误。</p><p>另一个准则为除非有好的理由，否则应该尽量令你的types的行为和内置的type的行为一致。例如STL中的所有类均有一个size方法，表示长度。</p><p>如果在接口内部有资源的申请，申请的资源必须在最后得到销毁。因此最好的方法就是将函数的返回值设置为shared_ptr：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1:：<span class="built_in">shared_ptr</span>&lt;invest&gt; create();</span><br></pre></td></tr></table></figure><p>此外，shared_ptr还允许绑定一个对象释放函数，当对象释放的时候，shared_ptr调用这个函数来释放对象。定义方式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;invest&gt; pInt(ptr,deleteMethod);</span><br></pre></td></tr></table></figure><p><code>str1::shared_ptr</code>会自动调用每个使用它的指针专属的删除器，避免跨DLL文件delete导致运行期的错误。<strong>shared_ptr会调用指针的专属删除器</strong>。</p><p>shared_ptr在效率和空间上是用指针的两倍大，使用辅助动态内存，比原始指针要大。</p><p><strong>总结</strong></p><ul><li>设计不容易出错的接口</li><li>保证接口之间的一致性</li><li>阻止误用，建立新类型的方式限制类型上的操作，消除客户资源管理的任务</li><li>Tr1::shared_ptr支持定制删除器，防范DLL问题</li></ul><h3 id="19-条款：设计class犹如设计type"><a href="#19-条款：设计class犹如设计type" class="headerlink" title="19 条款：设计class犹如设计type"></a>19 条款：设计class犹如设计type</h3><p>当你定义了一个新的class，也就定义了一个type，设计好的type有自然的语法和直观的语义，有一下的设计规范：</p><ul><li>新type的对象应该如何创建和销毁</li><li>对象初始化和对象的赋值该有什么样的差别</li><li>新type对象如果被传值（passed by value）该在copy函数中写实现方法</li><li>对type的合法值进行约束</li><li>新的type是否需要配合继承图系</li><li>新type需要什么样的类型转换</li><li>什么样的操作符和函数对新type是合理的</li><li>什么样的标准函数需要驳回</li><li>谁该去用新type成员</li><li>什么是新type的未声明接口</li><li>type的一般化程度</li><li>你真的需要一个新type吗</li></ul><p><strong>总结</strong></p><p>设计一个class的时候，需要充分考虑上面的问题，具体所指可以参考书本84页。</p><h3 id="20-条款：宁以-pass-by-reference-to-const-替换-pass-by-value"><a href="#20-条款：宁以-pass-by-reference-to-const-替换-pass-by-value" class="headerlink" title="20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value"></a>20 条款：宁以 pass-by-reference-to-const 替换 pass-by-value</h3><p>C++默认以传值的方式给函数传递参数，这一过程函数参数的初值都是调用对象的构造函数来实现，当离开这个函数的时候，通过析构函数来回收这些资源，因此传值的方式将会耗费大量的资源和时间。</p><p>一个很好的优化方法就是使用const 引用的方式，这种方式没有任何的构造函数被调用。之所以使用const，是为了保证传入的参数对象不会被改变。</p><p>此外如果直接传值，对于参数类型为父类的情况，传入子类对象，会造成子类特化功能被切割，参数的行为与父类相同，但是如果使用传引用的方式，这种现象不会发生。</p><p>说到这里，我们会好奇，引用到底是个什么东西呢，其实际上运用是通过指针的方式来实现的，传递引用等同于传递指针，<strong>对于内置类型来说，传值方式会比传指针的方式更加高效。</strong> 对于int，float这些类型，直接通过传值的方式更加的高效。</p><p><strong>总结</strong></p><ul><li>尽量以传const引用的方式替换传值的方式，前者通常比较高效，避免对象切割问题</li><li>对于内置类型以及STL迭代器，函数对象来说，直接传值比较高效</li></ul><h3 id="21-条款：必须放回对象时，别妄想返回其reference"><a href="#21-条款：必须放回对象时，别妄想返回其reference" class="headerlink" title="21 条款：必须放回对象时，别妄想返回其reference"></a>21 条款：必须放回对象时，别妄想返回其reference</h3><p>当我们尝试消灭所有的传值行为的时候，我们可能会对函数的返回值下手，这种做法是不可取的。</p><p>所谓的引用，即表明它所指代的对象一定要存在，在函数中我们有两种方式创建对象：</p><p><strong>创建对象在stack内存上</strong></p><p>stack内存存放函数的参数，局部变量值，由编译器自动释放：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration&amp; <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  <span class="function">Ration <span class="title">result</span><span class="params">(lhs.n*rhs.n)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上买代码返回了一个局部变量的引用，但是由于出了这个函数，局部变量就会被销毁，因此这个reference将毫无意义。</p><p><strong>创建对象在heap内存上</strong></p><p>用户自己分配，自己销毁的资源都会分配在heap内存上，有new-delete对来管理。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration&amp; <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  Ration* result = <span class="keyword">new</span> Ration(lhs.n*rhs.n);</span><br><span class="line">  <span class="keyword">return</span> *result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面返回的引用是有意义的，但是当我们使用完这个 内存之后，由谁去销毁呢，在一些很复杂的操作里面，程序员往往无法保证资源的完全回收。</p><p><strong>使用static变量</strong></p><p>在函数内部定义static变量，该变量的生命周期是整个程序的生命周期，static变量，全局变量他们的值都是存放在同一块区域，由程序结束后统一回收。</p><p>但这又引发了另一个问题，你想要比较两个数相乘后与另外两个数相乘的大小，但是结果存放在static当中，程序只会保存一份static的结果，因此永远无法比较。</p><p>因此，<strong>如果函数要求返回一个对象，那么我们就承担返回值所产生的构造和析构成本</strong>，不要试图去放回引用。</p><p><strong>总结</strong></p><p>不要返回一个指针或引用指向一个local对象，或指向heap-allocated对象，或指向static对象，而是直接返回该对象（传值）。</p><h3 id="22-条款：将成员变量声明为private"><a href="#22-条款：将成员变量声明为private" class="headerlink" title="22 条款：将成员变量声明为private"></a>22 条款：将成员变量声明为private</h3><p>为保证成员便来那个的约束性，对用户隐藏变量，使得类中的约束条件总会收到维护。如果将一个变量声明为public，破坏了封装性，在我们修改该变量的时候，我们无法预知这个变量所涉及的一切，可能会对程序造成极大的破坏。因此保护类的封装性。protected类型与public相似，其实只有来那个两种访问权限：<strong>private（提供封装）和其他（不提供封装）</strong></p><p><strong>总结</strong></p><ul><li>切记将成员变量声明为private，这可赋予客户访问数据一致性，细微划分访问控制，允许约束条件获得保护，并 提供class作者充分的实现弹性。</li></ul><h3 id="23-条款：宁以non-member、non-friend替换member函数"><a href="#23-条款：宁以non-member、non-friend替换member函数" class="headerlink" title="23 条款：宁以non-member、non-friend替换member函数"></a>23 条款：宁以non-member、non-friend替换member函数</h3><p>这个条款的核心在于：<strong>越少的操作直接接触到数据，对类的封装性，代码的维护越好</strong>。因此如果一些操作可以由非成员函数来完成的话，就不要去写那个成员函数的版本。</p><p>越少的函数接触到数据，我们在改变数据的时候，就可以有越大的灵活度修改这个数据。</p><p>有几种方式可以去实现非类内函数来完成这个操作：</p><ul><li>例如我们指提供了一个完成基础操作的类，我们可以选择另一个类中的函数，传入这个对象，来实现你想要的操作，而不用为基础类添加成员</li><li>C++的一个常用的做法是，将non-member函数与类写在同一个命名空间中，命名空间可以跨越多个源码文件。将所有便利函数放在多个头文件内，但同属于一个命名空间，以为着用户可以轻松扩展这一组便利函数</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//头文件webbrowser.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowserStuff&#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">webbrowser</span>&#123;</span>...&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//头文件webbrowserbook.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowserbook&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 头文件webbrowsercookies.h</span></span><br><span class="line"><span class="keyword">namespace</span> webbrowsercookies&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过include需要的头文件的方式来管理标准程序库，使得那一小部分系统形成编译相依的关系。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//web.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> wweb&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">web</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="built_in">string</span> <span class="title">get_name</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name;</span><br><span class="line">        &#125;</span><br><span class="line">        web(<span class="built_in">string</span> n):name(n)&#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say_hi</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="built_in">string</span> name;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//web.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"web.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span>::wweb;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> web::say_hi() &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"hihi"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>宁可用non-member函数替代member函数，这可增加类的封装性，包裹性，机能扩充性。</li><li>non-member的函数通常与class定义在同一个命名空间内</li></ul><h3 id="24-条款：若所有参数皆需类型转换，请为此采用non-member函数"><a href="#24-条款：若所有参数皆需类型转换，请为此采用non-member函数" class="headerlink" title="24 条款：若所有参数皆需类型转换，请为此采用non-member函数"></a>24 条款：若所有参数皆需类型转换，请为此采用non-member函数</h3><p>当我们传入参数都需要进行类型转换的时候，如果将类函数写成如下情况：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ration</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">    <span class="keyword">const</span> Ration <span class="keyword">operator</span>* (<span class="keyword">const</span> Ration&amp; rhs) <span class="keyword">const</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Ration <span class="title">oneE</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">Ration result = oneE*<span class="number">2</span>; <span class="comment">// C++将2转换成Ration类型</span></span><br><span class="line">Ration result = <span class="number">2</span>*oneE; <span class="comment">// 编译错误，因为this不可以作为类型转换的变量</span></span><br></pre></td></tr></table></figure><p>只有当参数可位列于参数列中内，这个参数才允许隐式转换，因此一个比较好的方法就是非类内函数去实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Ration <span class="keyword">operator</span>*(<span class="keyword">const</span> Ration&amp; lhs,<span class="keyword">const</span> Ration&amp; rhs)&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>能够避免使用友元的情况就一定要避免使用它。</p><p><strong>总结</strong></p><p>如果需要为某个函数的所有参数进行类型的转换，那么这个函数必须是个non-member。</p><h3 id="25-条款：考虑写出一个不抛异常的swap函数"><a href="#25-条款：考虑写出一个不抛异常的swap函数" class="headerlink" title="25 条款：考虑写出一个不抛异常的swap函数"></a>25 条款：考虑写出一个不抛异常的swap函数</h3><p>swap函数的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">namspace <span class="built_in">std</span>&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a,T&amp; b)</span></span>&#123;</span><br><span class="line">    <span class="function">T <span class="title">temp</span><span class="params">(a)</span></span>;</span><br><span class="line">    a = b;</span><br><span class="line">    b = temp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只要支持copying，swap就会完成交换。但是上面这种方法需要不断的构造，析构。于是我们选择特性化swap，<strong>通过置换指针的方式就可以达到置换的效果</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(Widget&amp; other)</span></span>&#123;</span><br><span class="line">      <span class="keyword">using</span> <span class="built_in">std</span>::swap;  <span class="comment">//令std内的swap函数可见</span></span><br><span class="line">      swap(pInt,other.pInt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">namespace</span> <span class="built_in">std</span>&#123;</span><br><span class="line">  <span class="keyword">template</span>&lt;&gt;  <span class="comment">//告诉编译器，这是个全特化的版本</span></span><br><span class="line">  <span class="keyword">void</span> swap&lt;Widget&gt;(Widget&amp; a,Widget&amp; b)</span><br><span class="line">  &#123;</span><br><span class="line">    a.swap(b);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此优化copy：</p><ul><li>提供一个public swap成员函数，让它高效置换你的类型的两个对象值，且不能抛出异常。（置换基本类型）。</li><li>在class或template所在命名空间中提供一个non-member swap函数，并令他调用上述的swap成员函数。</li><li>如果你正编写一个class，为你的class特化std::swap，并调用你的swap。</li></ul><p><strong>总结</strong></p><ul><li><p>当std::swap对你的类型效率不高的时候，提供一个swap成员函数，并确保不抛出异常</p></li><li><p>提供一个member swap函数，也应该提供一个non-member swap用来调用前者，对于classes也请特化std::swap。</p></li><li>调用 swap时应该针对std::swap使用using声明式，然后调用swap并且不带任何命名空间资格修饰。</li><li>为“用户定义类型”进行std::template全特化是好的但是千万不要尝试在std内部加上对std而言全新的东西。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>EncNet结合上下文的语义分割</title>
      <link href="/2019/11/06/EncNet%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
      <url>/2019/11/06/EncNet%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</url>
      
        <content type="html"><![CDATA[<p>《Context Encoding for Semantic Segmentation》是发表在2018年cvpr上的文章，文章的主要insight在于将图像中的内容信息加入到语义分割的网络中，通过一个context encoding module突出图像类别，对分类类别进行简化，降低分割的难度，提升分割的精度。</p><a id="more"></a><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>目前的分割网络主要的关注点在于pixel-level predict，即对每个像素进行类别的分类。从2016年提出的FCN分割网络开始，图像分割实现了一个端到端的分割，当时由于CNN-pooling的网络设计，使得FCN网络对数据的丢失严重。为了解决这个问题，人们提出了dilated conv以及特征金字塔等（deeplab）结构来解决这个问题，即扩大feature map的感受野的同时，保证feature map的分辨率，保留大部分的数据。</p><p>EncNet另辟蹊径，认为通过图像中给出的类别信息能够对分割种类进行缩小，找到一个比较小的子集，在该类别的子集上进行语义的分割，简化分割问题。本文给出了两个主要的贡献：</p><ol><li>本文提出了一个context encoding mudule模块，以及一个SE-Loss，一个简单的单元来利用全局的场景内容信息学到不同channel的权重，以及学到场景中所包含的类别。</li><li>EncNet，作者的第二个贡献就是提出了EncNet这个网络，能勾在许多公开的语义分割的数据集上取得state of the art的效果。</li></ol><p>下面来看一下作者具体是怎么实现的：</p><p><img src="/images/3D/encnet.png" style="zoom:40%;"></p><h3 id="Context-Encoding-Module"><a href="#Context-Encoding-Module" class="headerlink" title="Context Encoding Module"></a>Context Encoding Module</h3><p><strong>context Enocding</strong></p><p>作者通过使用一系列的卷积层（空洞卷积）去学习一个内在的语义字典的表示，将这个字典作为编码语义，为了方便使用上下文，去学习预测了一组缩放因子用于突出和类别相关的特征图。</p><p>将feature map的大小reshape成二维（WxH）x C，去学习codebook $D = {d_1,d_2,…d_k}$ ,以及一组和视觉中心平滑因子$S = {s_1,s_2,…s_k}$,编码层输出残差编码，通过soft-assignment进行聚合，$e_k = \sum_{i=1}^{N}e_{ik}$，其中$e_{ik}$ 如下：<br>$$<br>\begin{equation}<br>e_{i k}=\frac{\exp \left(-s_{k}\left|r_{i k}\right|^{2}\right)}{\sum_{j=1}^{K} \exp \left(-s_{j}\left|r_{i j}\right|^{2}\right)} r_{i k}<br>\end{equation}<br>$$<br>其中$r_{ik} = x_i - d_k$作为残差加入计算，其中$e = \sum_{k=1}^{K}\phi(e_k)$，对所有的ek进行batch normalization得到e，作为编码层的输出。</p><p><strong>feature attention</strong></p><p>通过编码层输出的e，来学习一组缩放因子，用于强调和抑制一些不同的类别。缩放因子通过全连接层进行学习，最得到一组缩放因子如下：<br>$$<br>\gamma = \sigma(We)<br>$$<br>其中w为全连接层的参数，$\sigma$为sigmoid函数，最终将得到的缩放因子与输入的深度图进行相乘得到最终权重改变后的feature map。</p><p><strong>Semantic Encoding Loss</strong></p><p>作者为了能够更好的理解图片与类别之间的关系，从图像中直接预测出图像中所包含的类别，将编码层的输出传入另一个全连接层中，GT为图片中已有的类别，通过最小化SE-Loss，即二次的交叉熵loss，判断60个类，存在或不存在的方式，来建立图像全局信息与类别之间的映射关系。最终对图像中的类别进行一个削减。</p><h3 id="Context-Encoding-Network"><a href="#Context-Encoding-Network" class="headerlink" title="Context Encoding Network"></a>Context Encoding Network</h3><p>EncNet网络的backbone使用的是resnet，同时使用了之前证明有效的dilated conv，在深度图的state3，和4阶段使用了空洞卷积：</p><p><img src="/images/3D/dilated.png" style="zoom:50%;"></p><p>在stage3位置上同样适用了SE-loss，作为一个额外的正则化的操作，encnet在FCN的基础上进行一些小的改动，通过增加一些轻微的计算量就可以达到一个很好的效果。</p><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>pixAcc：像素类别预测正确的像素除以所有像素的比例。</p><p>mIoU：每一类预测结果与GT的结果的IoU的平均值。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>看完整篇文章，这篇文章最大的亮点就是认为<strong>飞机不会出现在房间里</strong>，利用图像的feature map，与类别GT，建立一个映射，从而在做最终的逐像素的语义分割的问题时，没必要在所有的类别上做，而是直接在根据图像feature map上映射得到的类别上做，降低了语义分割的难度。</p><p>对图像整个内容信息的提取上，主要由两部分构成，一部分对不同的channel学习一个重要性权重，另一个直接通过图像内容学习一个图像中含有的类别。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之评分预测（三）</title>
      <link href="/2019/11/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89/"/>
      <url>/2019/11/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>评分问题，根据已有的评分，或者用户、物品的评分规则对物品进行评分的预测。</p><a id="more"></a><p><strong>离线实验方法</strong></p><p>评分的预测基本上都是通过离线实验进行研究的。研究者通过将数据分成训练集和测试集的方式，根据训练好的兴趣模型，对测试集进行评分。一般使用的度量方法为RMSE：<br>$$<br>\operatorname{RMSE}=\frac{\sqrt{\sum_{(u, i) \in T}\left(r_{u i}-\hat{r}_{u i}\right)^{2}}}{|\mathrm{Test}|}<br>$$</p><h3 id="评分预测算法"><a href="#评分预测算法" class="headerlink" title="评分预测算法"></a>评分预测算法</h3><h3 id="平均值"><a href="#平均值" class="headerlink" title="平均值"></a>平均值</h3><p>通过计算训练集中的全局平均值，作为测试集中的评分。</p><p><strong>用户评分平均值</strong></p><p>用户的评分平均值为用户历史评分的平均值，作为他之后评分的一个值。</p><p><strong>物品评分平均值</strong></p><p>对物品的所有评分计算平均值，作为它在训练集中的所有评分的平均值。</p><p><strong>用户分类对物品分类的平均值</strong></p><p>同类的用户对同类的物品的评分的平均值作为物品的评分。</p><p><strong>用户和物品的平均分</strong></p><p>将用户和物品按照评分从高到低分成平均分成N类。</p><p><strong>用户活跃度和物品流行度</strong></p><p>用户活跃度和物品的流程度从大到小平均分成N类。</p><h3 id="基于领域的方法"><a href="#基于领域的方法" class="headerlink" title="基于领域的方法"></a>基于领域的方法</h3><p>基于领域的方法认为一个用户对一个物品的评分需要参考和着高哟高糊兴趣相似的用户对该物品的评分。<br>$$<br>\hat{r}_{u i}=\bar{r}_{u}+\frac{\sum_{v \in S(u, K) \cap N(i)} w_{u v}\left(r_{v i}-\bar{r}_{v}\right)}{\sum_{v \in S(u, K) \cap N(i)}\left|w_{u v}\right|}<br>$$<br>其中w为用户之间的相似度，可以通过皮尔逊系数来计算：<br>$$<br>w_{u v}=\frac{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right) \cdot\left(r_{v i}-\bar{r}_{v}\right)}{\sqrt{\sum_{i \in I}\left(r_{u i}-\bar{r}_{u}\right)^{2} \sum_{i \in I}\left(r_{v i}-\bar{r}_{v}\right)^{2}}}<br>$$<br>基于五瓶的领域算法在预测用户对物品的评价的时候，会参考用户对相似物品评价的评分：<br>$$<br>\hat{r}_{u i}=\bar{r}_{i}+\frac{\sum_{j \in S(u, K) \cap N(u)} w_{i j}\left(r_{u j}-\bar{r}_{i}\right)}{\sum_{j \in S(i, F) \cap W(u)}\left|w_{i j}\right|}<br>$$<br>其中w为普通的优先相似度、皮尔逊系数，修正的余弦相似度三种之一，具体那种效果好，需要看具体的实验。</p><h3 id="隐语义模型与矩阵分解模型"><a href="#隐语义模型与矩阵分解模型" class="headerlink" title="隐语义模型与矩阵分解模型"></a>隐语义模型与矩阵分解模型</h3><p>评分系统可以写成一个评分矩阵R，其中每一个位置就是用户对物品的一个评分。传统的方法通过降维的方式对评分矩阵进行填充。</p><p><strong>传统的SVD分解</strong></p><p>一个直观的想法就是，补全之后的矩阵对不全之前的矩阵扰动最小，补全后的特征值和补全之前的特征值相互差异不大。</p><p>一开始可以使用全局平均值对矩阵进行填充，然后进行矩阵的SVD分解，然后选择其中特征向量topN保留，得到一个降维之后的评分矩阵。</p><p>SVD分解有一个问题，就是它本上是十分稀疏的，95%都是空的，但是通过这种方式进行填充之后变得非常的大，计算复杂度很高，难以实际应用。</p><p><strong>simon Funk SVD</strong></p><p>simon对传统的SVD进行改造，直接将评分矩阵分解成两个低维度的矩阵相乘：<br>$$<br>\hat{r}_{u i}=\sum_{f} p_{u f} q_{i f}<br>$$<br>于是通过最小化RMSE误差，加上参数的正则化项，从而得到：<br>$$<br>C(p, q)=\sum_{(u, i) \in \mathrm{Train}}\left(r_{u i}-\sum_{f=1}^{F} p_{u f} q_{i f}\right)^{2}+\lambda\left(\left|p_{u}\right|^{2}+\left|q_{i}\right|^{2}\right)<br>$$<br>通过随机梯度下降法，去学习p，q矩阵，最终得到评分表中的缺失的评分。</p><p><strong>加入偏执的LFM</strong></p><p>在上一个方法的基础上，有人提出了许多改进的方法，提出了很多偏执，对算法进行修正：<br>$$<br>\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}<br>$$<br>u为评分的全局平均数，b为用户喜好的偏执（用户评分随意或者很苛刻的情况），后一个b为物品品质的偏执（评分都很高，或都很低的情况）。</p><p><strong>加入时间信息</strong></p><p>基于领域的融合时间的模型，考虑用户评分年时间对推荐结果的影响：<br>$$<br>\begin{equation}<br>\hat{r}_{u i t}=\frac{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right) r_{u j}}{\sum_{j \in N(u) \cap S(i, K)} f\left(w_{i j}, \Delta t\right)}<br>\end{equation}<br>$$</p><p>$$<br>\begin{equation}<br>\begin{array}{c}{f\left(w_{i j}, \Delta t\right)=\sigma\left(\delta \cdot w_{i j} \cdot \exp \left(\frac{-|\Delta t|}{\beta}\right)+\gamma\right)} \ {\sigma(x)=\frac{1}{1+\exp (-x)}}\end{array}<br>\end{equation}<br>$$</p><p>随着$\Delta t$d的变大，影响力就会变小。</p><p><strong>模型的融合</strong></p><p>模型融合基本上分成两种方式：</p><ul><li>模型级联融合，上一个模型的输出最为下一个模型的输入，每个模型在上一个模型的基础上进行学习。</li><li>模型加权融合，用K个模型去预测最终的结果，首先将训练集A分成A1，A2，然后在A1上训练K个模型，利用A2训练集，去学习每个模型的权重。然后在B上进行最终的评分预测，这样的好处就是防止模型过拟合。</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><strong>时间上上下文信息</strong></p><p>用户的兴趣以及推荐的物品与时间的关系十分的相关，必要将时间加入到推荐算法当中去。例如在协同过滤的基础上加上时间衰减函数，如判断两个物体的相似性：<br>$$<br>\begin{equation}<br>\operatorname{sim}(i, j)=\frac{\sum_{u \in N(0) \cap N(i)} f\left(\left|t_{u i}-t_{u |}\right|\right)}{\sqrt{|N(i)||N(j)|}}<br>\end{equation}<br>$$<br>其中时间衰减函数如下：<br>$$<br>\begin{equation}<br>f\left(\left|t_{u i}-t_{u j}\right|\right)=\frac{1}{1+\alpha\left|t_{u i}-t_{u j}\right|}<br>\end{equation}<br>$$<br>当两个商品购买的时间相差比较远的话，时间衰减函数那一项就会比较小。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(三) 资源管理</title>
      <link href="/2019/11/05/effective-cpp-%E4%B8%89-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"/>
      <url>/2019/11/05/effective-cpp-%E4%B8%89-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>2019/11/05 effective cpp 第三章</p><p>CPP程序运行中，将会动态申请内存、文件描述器、互斥锁等一些重要的资源，必须及时归还系统。</p><ul><li>13 条款：以对象管理资源</li><li>14 条款：</li></ul><a id="more"></a><h3 id="13-条款：以对象管理资源"><a href="#13-条款：以对象管理资源" class="headerlink" title="13 条款：以对象管理资源"></a>13 条款：以对象管理资源</h3><p>若一个基类通过一个工厂函数，得到若干个子类的地址指针，在使用完这些子类之后，需要将他们回收，下面写一个回收的函数对他们进行回收：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123;</span><br><span class="line">  Invest* ptr = create();</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">delete</span> ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的代码可以完美的运行，但是在一些特定的情况下，如果程序在delete之前中途退出了，这将导致分配的资源无法得到释放。一个比较可靠的做法是：</p><p><strong>把资源放进对象内，当需要销毁资源的时候，使用C++的析构函数自动调用机制，确保资源的释放。</strong></p><p><strong>auto_ptr</strong></p><p>许多资源被动态分配到heap内，被用于函数内。它们应该在控制流离开那个函数的时候被释放，auto_ptr智能指针就是为此设计的一个<strong>类指针对象</strong>，由析构函数对其所指对象调用delete。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">auto_ptr</span>&lt;invest&gt; Ptr(create());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的做法体现了两条回收资源的设计：</p><ul><li><strong>获得资源后，立即放入管理对象内：</strong>资源对象创建的最佳时期就是资源获取的时机。最好的方式是获取资源的同一个语句内使用它初始化某个管理对象</li><li><strong>管理对象运用析构函数确保资源被释放：</strong>不论控制流如何离开区块，一旦对象被销毁，析构函数自动销毁所获得的资源。</li></ul><p>auto_ptr对象离开它的有效范围之后，就将自动销毁分配的资源。但是有一个缺陷，它不允许多个auto_ptr指向同一块区域，这样会造成一个对象被多次的删除。为了防止这个问题，auto_ptr中有一个特性，如果通过拷贝函数复制他们，之前的指针将会变成null，复制后的指针得到资源的唯一拥有权。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">auto_ptr</span>&lt;invest&gt; ptr1(create());</span><br><span class="line"><span class="built_in">auto_ptr</span>&lt;invest&gt; ptr2(ptr1);  <span class="comment">// 此时ptr1变成null</span></span><br></pre></td></tr></table></figure><p>auto_ptr的替代方案使用<code>tr1::shared_ptr</code>，这个对象类将持续追踪共有多少指针指向某个资源，但是在环形引用时无法打破。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>&#123; </span><br><span class="line"> tr1::<span class="built_in">shared_ptr</span>&lt;invest&gt; ptr(create());</span><br><span class="line"> tr1::<span class="built_in">shared_ptr</span>&lt;invest&gt; ptr1(ptr); <span class="comment">// ptr，ptr1指向同一个对象</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述例子告诉我们，当我们手动释放资源的时候，容易发生错误，罐装式的资源管理类如auto_ptr, shared_ptr可以比较好的准守这条规则。</p><p><strong>总结</strong></p><ul><li>防止资源浪费，使用RAII对象，在他们的构造函数中获得资源，在析构函数中释放资源。</li><li>使用RAII中的tr1::shared_ptr，auto_ptr是两个比较好的选择，shared_ptr具有比较正常的copy。</li></ul><h3 id="14-条款：在资源管理类中小心copying行为"><a href="#14-条款：在资源管理类中小心copying行为" class="headerlink" title="14 条款：在资源管理类中小心copying行为"></a>14 条款：在资源管理类中小心copying行为</h3><p>通常使用auto_ptr,shared_ptr作为资源管理类，但是有些资源并非在heap-based，不实用使用上述的两种资源管理类，因此需要建立自己的资源管理类。</p><p>自己定义的资源管理类通常在构造函数的部分申请得到资源，在析构函数中释放资源，这种类型的资源包括了互斥锁。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lock</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>：</span><br><span class="line">    explicit Lock(Mutex* pm):mutexPtr(pm)&#123;  // 在初始化资源类的时候，初始化资源</span><br><span class="line">      lock(mutexPtr);</span><br><span class="line">  &#125;</span><br><span class="line">  ~Lock()&#123;unlock(mutexPtr);&#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">   Mutex* mutexPtr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样的，对于资源管理类来说，如果对象被复制，我们需要处理对象的复制问题。可以让它继承UnCopyable对象，禁止对象的复制。或者使用shared_ptr的方法，<strong>使用引用计数法</strong>，使用shared_ptr来定义指针。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shared_ptr</span>&lt;Mutex&gt; mutexPtr;</span><br></pre></td></tr></table></figure><p>这时候就可以不用定义虚析构函数了，当指针被回收的时候，资源就会被回收。</p><p><strong>转移底层的资源拥有权</strong></p><p>使用类似于auto_ptr的做法，copy的时候，保证资源的唯一性。</p><p><strong>总结</strong></p><ul><li>复制RAII对象（资源管理对象）需要一并复制它所管理的资源，资源的copying行为决定了RAII对象的copying行为。</li><li>普遍常见的RAII copying行为通常为：抑制copying，使用引用计数法，转移底层资源的拥有权。</li></ul><h3 id="15-条款：在资源管理类中提供对原始资源的访问"><a href="#15-条款：在资源管理类中提供对原始资源的访问" class="headerlink" title="15 条款：在资源管理类中提供对原始资源的访问"></a>15 条款：在资源管理类中提供对原始资源的访问</h3><p>资源管理类通常是我们设计来保证资源的正常申请和销毁的，但是有些情况是，我们调用一些函数的时候需要直接访问内部的资源（例如一些指针类）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Invest&gt; pInt(create()); <span class="comment">// pInt是一个资源类对象</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">daysHeld</span><span class="params">(<span class="keyword">const</span> Invest* pi)</span></span>; <span class="comment">// pi是一个invest* 对象</span></span><br></pre></td></tr></table></figure><p>当我们要调用daysHeld()函数的时候，传入的参数如果为pInt的话会发生错误，因为pInt是一个资源类对象，因此我们需要从这个资源类对象中取出其中的指针资源。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">daysHeld(pInt.get());</span><br></pre></td></tr></table></figure><p>shared_ptr,auto_ptr继承了原是指针中的<code>-&gt;,*</code>操作，并且可以通过get函数得到资源的直接访问。</p><p>当我们选择自己实现资源管理类的时候，我们也需要实现一个get函数，实现显示的函数变换。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Font</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    explicit Font(Fhandle fh):f(fh)&#123;&#125;</span><br><span class="line">    ~Font()&#123;release(fh);&#125;</span><br><span class="line">    <span class="function">FHandle <span class="title">get</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> fh;&#125; <span class="comment">// 实现直接获取资源的函数</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    FHandle fh;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过实现<code>operator FHandle() const {return fh;}</code>函数可以实现隐式的变换，但是这样容易造成错误的发生，因此建议使用显式的变换（get的方式）。</p><p><strong>总结</strong></p><ul><li>API中往往要求访问原始资源，所以每一个RAII类中应该要实现一个直接获取志愿的方法（get方法）。</li><li>对原始资源的访问可能是显式变换或者隐式的变换，一般而言显式变换比较安全。</li></ul><h3 id="16-条款：成对使用new和delete时要采取相同形式"><a href="#16-条款：成对使用new和delete时要采取相同形式" class="headerlink" title="16 条款：成对使用new和delete时要采取相同形式"></a>16 条款：成对使用new和delete时要采取相同形式</h3><p>new在被使用的时候，可以申请单个内存（<code>new int</code>）或多个内存（<code>new int[10]</code>），delete再回收内存的时候，也有回收单一内存和连续内存的区别，需要注意的是，new和delete行为必须一致（单一内存和多内存的一致。）</p><p><strong>总结</strong></p><ul><li>new中使用[]必须在delete中也使用[]（连续内存），new中不使用[]，delete中也不能使用[]（单一）。</li></ul><p>下面补充一下CPP中new和delete的用法：</p><p><strong>new的使用</strong></p><p>new负责C++中的动态内存分配，动态内存位于heap上。在不使用这段内存的时候，程序需要负责将这段内存回收掉。</p><p>new指令初始化内存，返回内存分配的初始地址：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pointer-variable = <span class="keyword">new</span> data-type;</span><br><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>;</span><br></pre></td></tr></table></figure><p>可以<strong>使用括号的方式初始化对象</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">10</span>);</span><br></pre></td></tr></table></figure><p><strong>使用中括号[]的方式分配一整块内存空间：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br></pre></td></tr></table></figure><p>传统的申请内存的方式为<code>int a[10];</code> 这个空间由编译器申请，在使用结束之后也由编译器进行回收。但是自己申请的内存会一直存在，直到自己delete处理掉。</p><p><strong>delete的使用</strong></p><p>使用delete对new申请的数组进行清空：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> p; <span class="comment">// 删除单个元素</span></span><br><span class="line"><span class="keyword">delete</span>[] p; <span class="comment">// 删除整段空间</span></span><br></pre></td></tr></table></figure><h3 id="17-条款：以独立语句将newed对象置入智能指针"><a href="#17-条款：以独立语句将newed对象置入智能指针" class="headerlink" title="17 条款：以独立语句将newed对象置入智能指针"></a>17 条款：以独立语句将newed对象置入智能指针</h3><p>可以使用智能指针的方式来管理new申请的内存：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Widget&gt; pw(<span class="keyword">new</span> Widget);</span><br></pre></td></tr></table></figure><p>存在一种情况，当我们使用资源管理类来管理内存的时候，可能会出现内存泄漏。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">process(str1::<span class="built_in">shared_ptr</span>&lt;Wdiget&gt;(<span class="keyword">new</span> Widget),priority());</span><br></pre></td></tr></table></figure><p>上面代码可能的执行顺序是(顺序不一定)：</p><ol><li>new widget</li><li>priority</li><li>Shared_ptr构造函数</li></ol><p>如果第二步抛出异常，那么造成内存泄漏，因此：<strong>newed对象应当写一个单独的语句</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str1::<span class="built_in">shared_ptr</span>&lt;Widget&gt; pw(<span class="keyword">new</span> Widget);</span><br><span class="line">process(pw,priority());</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>以单独的语句将newed对象存储在智能指针内，确保资源不会泄露。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之用户标签数据(二)</title>
      <link href="/2019/11/05/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE-%E4%BA%8C/"/>
      <url>/2019/11/05/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<p>推荐系统的目的是链接用户的兴趣和物品，通常的连接方式可以通过：</p><ol><li>推荐与用户喜欢的物品相似的物品</li><li>推荐与用户兴趣相似的人所喜欢的物品</li><li>给用户推荐那些他喜欢的特征，例如利用用户标签</li></ol><p><strong>标签是一种无层次化结构的，用来描述信息的关键词，它可以用来描述物体的语义。</strong></p><a id="more"></a><h3 id="标签系统中推荐问题"><a href="#标签系统中推荐问题" class="headerlink" title="标签系统中推荐问题"></a>标签系统中推荐问题</h3><p><strong>用户为什么进行标注</strong></p><p>用户通常会给予社会维度、功能维度、传达信息的维度上对物品进行标注。</p><p><strong>用户如何打标签</strong></p><p>用户打标注的标签同样符合一个长尾分布，一些不流行的标签呈现一个长尾。</p><p><strong>用户打什么样的标签</strong></p><ul><li>表明物品是什么</li><li>物品的种类</li><li>用户的观点</li><li>谁拥有用户</li><li>用户相关的标签</li><li>用户的任务</li><li>类型</li><li>时间，人物，地点，语言，奖项</li></ul><h3 id="基于标签的推荐系统"><a href="#基于标签的推荐系统" class="headerlink" title="基于标签的推荐系统"></a>基于标签的推荐系统</h3><p><strong>数据的设计</strong></p><p>一个用户标签的行为的数据集一般由一个三元组的集合表示：(u,i,b)表示用户u给物品i打上了标签b。将数据随机分成10份，分割的键值是用户和物品，其中9份作为训练集，1份作为测试集。</p><p><strong>实验指标</strong></p><p>准确率、召回率、覆盖率、余弦相似度、新颖性（平均热门度）</p><p><strong>一个简单的算法</strong></p><p>利用用户标签进行个性化的推荐，一个直接的想法：</p><ol><li>统计每个用户最常用的标签</li><li>对每个标签，统计被打过这个标签次数最多的物品</li><li>对每个用户找到他最常用的标签，然后给他推荐具有这些标签的最热门的物品</li></ol><p>因此可以归纳出兴趣公式：<br>$$<br>p(u, i)=\sum_{b} n_{u, b} n_{b, i}<br>$$<br>$n_{u,b}$表示用户u打过标签b的次数，$n_{b,i}$ 表示物品i被打过b标签的次数。</p><p><strong>算法的改进：TF-IDF</strong></p><p>对于热门标签，它在许多物品上都有出现过，因此上述的公式对热门标签对应的热门物品给了过大的权重，系统将会倾向于推荐热门的物品，因此将降低推荐结果的新颖性，因此对<strong>热门标签</strong>进行惩罚：<br>$$<br>p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} n_{b, i}<br>$$<br>此外对<strong>热门物品</strong>进行惩罚：<br>$$<br>p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} \frac{n_{b, i}}{\log \left(1+n_{i}^{(u)}\right)}<br>$$<br><strong>数据稀疏性</strong></p><p>对于一些新用户或新物品，用户集合中的标签数量很小，可以我们可以将与已有标签相似的标签加入到用户标签中。</p><p>可以利用基于领域的方法，当两个标签同时出现在许多物品的标签集合中时，我们就可以认为这两个标签具有较大的相似度，可以使用余弦相似性进行计算，计算的方式时两个标签的交集除以他们的各自的平方开根号。<br>$$<br>\operatorname{sim}\left(b, b^{\prime}\right)=\frac{\sum_{i \in N(b) \cap V(b)} n_{b i} n_{b ; i}}{\sqrt{\sum_{i \in N(b)} n_{b, i}^{2} \sum_{i \in N(b)} n_{b^{\prime}, i}^{2}}}<br>$$<br><strong>标签清理</strong></p><p>有许多标签仅仅反应了用户的心情（例如不好笑），不能作为用户的兴趣，我们需要对这类标签进行过滤。去除一些停止词，同义词，等等方式去除不良标签。</p><h3 id="给用户推荐标签"><a href="#给用户推荐标签" class="headerlink" title="给用户推荐标签"></a>给用户推荐标签</h3><p>给用户推荐标签指给出一些选项供用户选择，这样的好处有：</p><ul><li>方便用户输入标签</li><li>提高标签的质量</li></ul><p><strong>如何给用户推荐标签</strong></p><ul><li>给用户推荐系统中推荐最热门的标签</li><li>给用户推荐物品i上最热门的标签</li><li>给用户推荐他常用的标签</li><li><strong>结合上述两种方法的加权结果</strong>（用得最多）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp (二) 构造、析构、赋值运算</title>
      <link href="/2019/11/02/effective-cpp-%E4%BA%8C-%E6%9E%84%E9%80%A0%E3%80%81%E6%9E%90%E6%9E%84%E3%80%81%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/"/>
      <url>/2019/11/02/effective-cpp-%E4%BA%8C-%E6%9E%84%E9%80%A0%E3%80%81%E6%9E%90%E6%9E%84%E3%80%81%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<p>2019/11/02，effective cpp 第二章</p><ul><li>05条款：了解C++默默编写并调用哪些函数</li><li>06条款：若不想使用编译器自动生成的函数，就该明确拒绝</li><li>07 条款：为多态基类声明virtual 析构函数</li><li>08 条款：别让异常逃离析构函数（不传播）</li><li>09 条款：绝不在构造和析构过程中调用virtual函数</li><li>10 条款：令operator= 返回一个reference to *this</li><li>11 条款：在operator=中处理自我赋值</li><li>12 条款：复制对象时勿忘其每一个成分</li></ul><a id="more"></a><h3 id="05-条款：了解C-默默编写并调用哪些函数"><a href="#05-条款：了解C-默默编写并调用哪些函数" class="headerlink" title="05 条款：了解C++默默编写并调用哪些函数"></a>05 条款：了解C++默默编写并调用哪些函数</h3><p>在一个类中，当你自己没声明，C++编译器将会替你生成的函数有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">entry</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  entry()&#123;...&#125; <span class="comment">//默认构造函数</span></span><br><span class="line">  ~entry(<span class="keyword">const</span> entry&amp; rth)&#123;...&#125; <span class="comment">// copy 构造函数</span></span><br><span class="line">  ~entry()&#123;...&#125; <span class="comment">// 析构函数</span></span><br><span class="line">  entry&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> entry&amp; rhs)&#123;...&#125; <span class="comment">//等号运算符重载</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的四个函数，分别负责对象的创建和销毁工作。其中default和析构函数用于防止一些幕后的代码，如调用父类的构造函数等。</p><p>copy构造函数和等号函数，起到的作用是将对象内每一个元素拷贝到目标对象上。</p><p>存在一个例外，如果成员变量不可以改变值的时候，例如成员变量含引用的时候（string&amp; name;）,含有const成员的时候，由于这些类型初始化之后，不允许改变它的值，因此系统不会为这些类生成copy构造函数以及重载等号初始化。</p><p><strong>总结</strong></p><p>编译器可以暗自生成构造函数，析构函数，copy构造函数，copy assignment操作符。一些含reference，const成员的函数，将不会产生copy，等号重载这两个函数。</p><h3 id="06-条款：若不想使用编译器自动生成的函数，就该明确拒绝"><a href="#06-条款：若不想使用编译器自动生成的函数，就该明确拒绝" class="headerlink" title="06 条款：若不想使用编译器自动生成的函数，就该明确拒绝"></a>06 条款：若不想使用编译器自动生成的函数，就该明确拒绝</h3><p>某些情况你不希望对象具有copy，等号这些操作，你就该明确拒绝。<strong>可以将copy，copy assignment申明成private，并且故意不去实现他们</strong>（只有声明没有实现），这样就能有效的阻止人们调用它，同时当类的friend函数调用的时候，将返回连接错误。</p><p>此外，还可以继承一个不可拷贝的对象，如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">homeforsale</span>:</span><span class="keyword">private</span> Uncopyable&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中Uncopyable的copy和copy assignment函数声明为private，而且未提供实现，这样可以将赋值的错误转移至编译期间。</p><p><strong>总结</strong></p><p>为了阻止编译器自动添加一些函数，可将相应的成员函数声明为private并且不写实现过程。使用Uncopyable这样的base class也是一种方法。</p><h3 id="07-条款：为多态基类声明virtual-析构函数"><a href="#07-条款：为多态基类声明virtual-析构函数" class="headerlink" title="07 条款：为多态基类声明virtual 析构函数"></a>07 条款：为多态基类声明virtual 析构函数</h3><p>例如一个基类实现了计时的功能，然后它派生出去的许多类，分别代表了不同特点的时钟。因此可以设计<strong>factory工厂方法</strong>，返回指针指向一个父类的计时对象，父类对象根据子类的指针类型得到一个子类的指针对象。</p><p>当我们通过上述的方法，生成了很多basic class指针（指向派生类），当我们希望回收内存的时候，使用delete方法释放内存，这时候C++只会调用basic class的non-virtual的析构函数。因此只对属于basic class部分的成员内存进行了释放，子类的内存无法得到释放。</p><p>解决上面的问题就是<strong>将basic class的析构函数定义为virtual</strong>，这样在释放指针所指空间的内存的时候，就可以就调用相应的子类的析构函数，销毁整个对象。</p><p>通常基类都会定义virtual的函数，供不同的子类指针调用，通常这类函数都需要有一个virtual的析构函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">entry</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">virtual</span> ~entry();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不含virtual的类基本上也不会加virtual的析构函数，因为加上virtual之后函数器对象需要加上徐函数的指针表，对象的大小会增加。</p><p>也不要在程序中继承一些带有non-virtual析构函数的class，因此如何你打算回收这个对象的时候，往往没办法完全回收内存。</p><p>倘若你想要将基类设计成一个抽象类，即不能实例化的一class，你可以选择将析构函数做成一个纯虚的析构函数，并且提供一份空的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AWOV</span>&#123;</span></span><br><span class="line">  <span class="keyword">virtual</span> ~AWOV() = <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">AWOV::AWOV()&#123;&#125; <span class="comment">// 提供一份空的实现</span></span><br></pre></td></tr></table></figure><p>当执行析构的时候，最深层的派生class的析构函数最先被调用，因此调用到AWOV这个类的析构函数。</p><p><strong>总结</strong></p><ul><li>含多态性质的base class应该声明一个virtual析构函数，如果class 带有任何virtual函数，他就应该拥有一个virtual析构函数。</li><li>classes的设计目的如果不是作为base classes使用，或不是为了具备多态性，就不该声明virtual</li></ul><h3 id="08-条款：别让异常逃离析构函数（不传播）"><a href="#08-条款：别让异常逃离析构函数（不传播）" class="headerlink" title="08 条款：别让异常逃离析构函数（不传播）"></a>08 条款：别让异常逃离析构函数（不传播）</h3><p>C++你并不能禁止析构函数吐出异常，因为例如在程序销毁的时候，析构函数将会销毁其构建的所有对象，当重复的对象在销毁的时候抛出异常，那么所有的这些对象在销毁的时候，都将会抛出异常，而多于一个异常被抛出的情况，将会导致不明确的行为。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DBConn</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  ~DBConn()&#123;</span><br><span class="line">    db.close(); <span class="comment">// 在DBConn的析构函数中，将会调用db.close()，然而db.close可能会发生异常，导致不明确的事情</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>C++不喜欢析构函数吐出异常，这将导致函数的提前结束或出现不明确的行为</strong></p><p>因此，如果在析构函数中出现异常，函数应该选择吞下这个异常，而不是抛出异常。如果必须对这个异常进行处理的话，应该提供一个普通函数来处理这个异常，而不是在析构函数中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">DBConn::DBConn&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">try</span>&#123;bd.close();&#125;</span><br><span class="line">  <span class="keyword">catch</span>&#123;...&#125;&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">abort</span>(); <span class="comment">// 终止程序,主动对异常进行捕获，而不是抛出</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者在一个普通函数中进行异常的捕获</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>&#123;</span><br><span class="line">  db.close();</span><br><span class="line">  closed = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">~DBConn()&#123;</span><br><span class="line">  <span class="keyword">if</span>(!closed)&#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      db.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span>(...)&#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>析构函数绝对不要吐出异常，如果一个被析构函数调用的函数可能抛出异常，那么析构函数应该去捕获异常，（try，catch）然后吞下它们或结束程序。</li><li>如果客户需要对某个函数在运行期间抛出的异常做出反应，那么class应该提供一个普通函数执行该操作。</li></ul><h3 id="09-条款：绝不在构造和析构过程中调用virtual函数"><a href="#09-条款：绝不在构造和析构过程中调用virtual函数" class="headerlink" title="09 条款：绝不在构造和析构过程中调用virtual函数"></a>09 条款：绝不在构造和析构过程中调用virtual函数</h3><p>在构造或析构函数中，如果在函数中调用虚函数，在子类的构造函数往回回溯的时候。这时候在父类中执行构造函数，构造函数内部的虚函数调用的是base class的版本，而不是子类的版本。</p><p><strong>在derived class对象的base class构造期间，对象的类型是base class，而不是derived class版本。</strong>如果使用了运行期类型信息，那么这时候也是base class的类型信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">transaction</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    transaction()&#123;</span><br><span class="line">      logtransaction(); <span class="comment">// 构造函数中的virtual函数只会使用base class（本类）的版本</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">logtransaction</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><p>在构造和析构期间不用调用virtual函数，因为这类调用从不下降至derived class（即这个版本的virtual函数不是你想要的那个。）</p><h3 id="10-条款：令operator-返回一个reference-to-this"><a href="#10-条款：令operator-返回一个reference-to-this" class="headerlink" title="10 条款：令operator= 返回一个reference to *this"></a>10 条款：令operator= 返回一个reference to *this</h3><p>关于重载等号=赋值运算符，由于赋值运算符可以连续赋值，形如：x=y=z=15，因此赋值运算符必须返回一个reference指向操作符的左侧实参，这是你为class需要遵循的协议：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    widget&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> *<span class="keyword">this</span>;       <span class="comment">// this调用=运算符，rhs为参数，返回this等于返回左边元素的引用</span></span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// 上述协议同样适用于+=，以及参数是其他类型的情况</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述写法只是一个协议，在CPP所有内置类型以及标准程序库中提供的类型都将共同准守。</p><p><strong>总结</strong></p><p>令赋值操作返回一个<code>reference to *this</code>的引用。</p><h3 id="11-条款：在operator-中处理自我赋值"><a href="#11-条款：在operator-中处理自我赋值" class="headerlink" title="11 条款：在operator=中处理自我赋值"></a>11 条款：在operator=中处理自我赋值</h3><p>自我赋值指的是自己给自己赋值的情况，这种情况通常出现在引用后指针的自我赋值上。例如一个类用来保存一个指针指向一块动态分配的位图：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bitmap</span>&#123;</span>...&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">widget</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">  Bitmap* pb;</span><br><span class="line">  widget&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">    <span class="keyword">delete</span> pb;    <span class="comment">// 这种方式可能造成不安全，当pb和rhs.pb指向同一块地址的时候，两个指针的对象会被删除</span></span><br><span class="line">    pb = <span class="keyword">new</span> Bitmap(*rhs.pb);</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述的危险可以使用验证是否相同的方式来化解：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">widget&amp; widget::<span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">  <span class="keyword">if</span>(*<span class="keyword">this</span> == &amp;rhs) <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">     <span class="keyword">delete</span> pb; </span><br><span class="line">    pb = <span class="keyword">new</span> Bitmap(*rhs.pb);</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//但是每次都要进行判断，效率不是很高，下面通过调换赋值的顺序，达到同样的效果</span></span><br><span class="line">widget&amp; widget::<span class="keyword">operator</span>=(<span class="keyword">const</span> widget&amp; rhs)&#123;</span><br><span class="line">  Bitmap* pOrig = pb;</span><br><span class="line">  pb = <span class="keyword">new</span> Bitmap(*rhs.pb);  <span class="comment">// 令pb指向一块新的pb的副本地址</span></span><br><span class="line">  <span class="keyword">delete</span> pOrig;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>确保当对象自我赋值的时候，operator=有良好的行为，利用来源对象和目标对象的地址，语句的顺序等等，避免将自身对象删除。</li><li>确保当函数操作一个以上对象的时候，它的行为是正确的。</li></ul><h3 id="12-条款：复制对象时勿忘其每一个成分"><a href="#12-条款：复制对象时勿忘其每一个成分" class="headerlink" title="12 条款：复制对象时勿忘其每一个成分"></a>12 条款：复制对象时勿忘其每一个成分</h3><p>当我们为一个类写copy构造函数和copy assignment构造函数的时候，编译器则会有一个报复行为，就是当你的类中新添了成员变量的时候，而未修改copy构造函数为这个值赋值的时候，编译器也不会报错：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    Customer(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">    Customer&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;</span><br><span class="line">Customer::Customer(<span class="keyword">const</span> Customer&amp; rhs):name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  name = rhs.name;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码可以正常的执行，但是当加入一个<code>int age;</code>的成员变量的时候，如果你忘记修改了上面的copy，assignment函数，编译器也不会提醒你，因此：</p><p><strong>如果你为class添加了一个成员变量，你必须同时修改copy和assignment，否则编译器也不会提醒你。</strong></p><p>当你为一个子类函数重写copy和assignment函数的时候，这种事情仍然会发生：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span>:</span> <span class="keyword">public</span> Person&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    Customer(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">    Customer&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs);</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;</span><br><span class="line">Customer::Customer(<span class="keyword">const</span> Customer&amp; rhs):name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  name = rhs.name;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Customer继承自Person对象，现实Customer的copy的时候没有对Person对象传递参数，那么编译器将会调用default构造函数，Person的数据并不会被拷贝到新的对象中，因此：</p><p><strong>我们在重写子类的copy函数的时候，需要调用base class 的copy函数。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Customer&amp; Customer(const Customer&amp; rhs):Person(rhs),name(rhs.name)&#123;</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">&#125;</span><br><span class="line">Customer&amp; Customer::<span class="keyword">operator</span>=(<span class="keyword">const</span> Customer&amp; rhs)&#123;</span><br><span class="line">  Person::<span class="keyword">operator</span>=(rhs);</span><br><span class="line">  <span class="keyword">do</span> something <span class="keyword">else</span>;</span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此当你编写一个copying函数，请确保（1）复制多有的local变量。（2）调用所有base classes内的适当copying函数。</p><p><strong>总结</strong></p><ul><li>copying函数应当确保复制对象内的所有成员变量，以及所有base class成分</li><li>不要尝试以某个copying函数实现另一个copying函数，可以将相同代码的部分单独提取出来，放到init函数中。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统之协同过滤（一）</title>
      <link href="/2019/11/02/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/11/02/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>基于领域的算法是推荐系统中最为基本的算法，这篇post主要针对其中重要的两类算法：基于用户的协同过滤，基于产品的协同过滤进行介绍。</p><a id="more"></a><h3 id="长尾效应"><a href="#长尾效应" class="headerlink" title="长尾效应"></a>长尾效应</h3><p>在需求曲线中，少量的需求会形成一条长长的尾巴，将所有非流行的需要累加起来，将会形成一个比流行市场还要庞大的市场。</p><p>长尾效应最直接的原因就是强调用户的个性化，将市场需求细分，这些小的需求市场的累积效应将形成巨大的理论。</p><p>推荐系统的一个迫切需求在于，存在信息过载以及用户需求不明显的问题，因此需要将用户感兴趣，或有潜在兴趣的商品推荐给用户。</p><h3 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h3><p>在介绍协同过滤之前，我们粗略设计一下算法的流程。</p><ul><li>将用户数据均匀成M（m = 8）份，挑选其中一份作为测试集。重复进行M次实验。（交叉验证，防止过拟合）</li><li>在训练集上训练用户兴趣模型，在测试集上进行预测，统计评测指标。</li><li>将M次实验结果的平均值作为最后的测评指标。</li></ul><h3 id="测评指标"><a href="#测评指标" class="headerlink" title="测评指标"></a>测评指标</h3><ul><li>召回率：recall = (用户感兴趣 与 推荐商品交集) / （推荐商品的总数）</li><li>准确率：precision = (用户感兴趣 与 推荐商品交集) / （用户感兴趣物品集合）</li><li>覆盖率：coverage = （推荐商品） / （总商品）</li><li>平均流行度：每个物品流行度的对数值（流行度满足长尾，取对数更加的稳定）</li><li>新颖度：新颖度可由流行度度量，负相关。</li></ul><h3 id="基于用户的协同过滤算法"><a href="#基于用户的协同过滤算法" class="headerlink" title="基于用户的协同过滤算法"></a>基于用户的协同过滤算法</h3><p>基于用户的协同过滤算法是推荐算法中最古老的算法，在1992年被提出（很年轻的领域）。主要包括两个部分：</p><ul><li>找到和目标用户兴趣相似的用户集合</li><li>找到这个集合中用户喜欢的，但目标用户中没有产生过行为的，推荐给目标用户</li></ul><p><strong>找出目标用户兴趣群</strong></p><p>如何判断两个用户的相似性，可以使用用户感兴趣物体N(u)的相似性来代替用户的相似性，使用Jaccard相似度，计算u，v用户的相似度：<br>$$<br>w_{u v}=\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}<br>$$<br>或者使用余弦相似度计算：<br>$$<br>w_{u v}=\frac{|N(u) \cap N(v)|}{\sqrt{|N(u)||N(v)|}}<br>$$<br>在具体的计算时，我们只关注两个用户之间存在交集的那部分商品：</p><ul><li><p>首先建立一个<strong>商品为表头的链表，链表上的节点是对该商品发生过行为的用户。</strong></p></li><li><p>随后建立一个<strong>用户与用户之间的相似矩阵</strong>，如果这两个用户出现在同一个链表中k次，则用户之间的数组值为k。相似矩阵作为余弦相似度的分子，总数作为分母，计算得到用户之间的相似度。</p></li><li>给目标用户提供与他相似度topK用户喜欢的产品。</li></ul><p><strong>用户相似性的改进：</strong></p><p>对于一些热门的产品，大家可能都会去购买，比如面包大家都会买，但是购买用户之间的相似性就天差地别了，换句话说，<strong>冷门商品更能说明用户兴趣</strong>，因此需要对热门商品进行惩罚：<br>$$<br>w_{u v}=\frac{\sum_{i \in N(u) \cap N(v)} \frac{1}{\log (1+|N(i)|)}}{\sqrt{|N(u)||N(v)|}}<br>$$<br>分子是u，v用户共同感兴趣的物品i，N(i)表示对i发生过行为的所有人的集合，i越热门惩罚越大。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>effective cpp(一) 让自己习惯cpp</title>
      <link href="/2019/10/31/effective-cpp-%EF%BC%88%E4%B8%80%EF%BC%89-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFcpp/"/>
      <url>/2019/10/31/effective-cpp-%EF%BC%88%E4%B8%80%EF%BC%89-%E8%AE%A9%E8%87%AA%E5%B7%B1%E4%B9%A0%E6%83%AFcpp/</url>
      
        <content type="html"><![CDATA[<p>2019/10/31，effective cpp第一章：</p><ul><li>01条款：视c++为一个语言联邦</li><li>02条款：尽量以const, enum,inline替换 #define</li><li>03条款：尽可能使用 const</li><li>04条款：确定对象被使用前已被初始化</li></ul><a id="more"></a><h3 id="01-条款：视c-为一个语言联邦"><a href="#01-条款：视c-为一个语言联邦" class="headerlink" title="01 条款：视c++为一个语言联邦"></a>01 条款：视c++为一个语言联邦</h3><p>c++最初从c语言发展而来，最初的名称是c with classes，同时这们语言接受了很多的不同的观点，特性，和编程的设计。使得cpp有着巨大的弹性和威力，因此在cpp不同的语言领域内，将有不同的最优用法。</p><p>cpp有着四个主要的次语言：</p><ul><li>C语言，cpp很多编程上的特性继承至C语言</li><li>面向对象的C++：很多关于类的操作在这一部分引入</li><li>template C++：C++的范型编程，<strong>唯template适用</strong></li><li>STL：标准模板库，里头有着大量的容器，迭代器等</li></ul><p><strong>总结</strong></p><p>C++由上面四种次语言组成，不存在一组高效编程的守则，而是视适用的次语言而定。</p><h3 id="02-条款：-尽量以const-enum-inline替换-define"><a href="#02-条款：-尽量以const-enum-inline替换-define" class="headerlink" title="02 条款： 尽量以const, enum,inline替换 #define"></a>02 条款： 尽量以const, enum,inline替换 #define</h3><p>将cpp程序转化成机器能够看懂的语言，需要经过预处理，编译，汇编，链接这些步骤。<strong>#define</strong>在预处理阶段就会被处理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define RATIO 1.25</span><br></pre></td></tr></table></figure><p>在编译器处理源代码阶段，define定义的符号将会被移走，因此RATIO可能根本就没进入<strong>符号表。</strong>当出现错误的时候，根据报错信息将很难定位错误，因此最好将define进行替换，也就是<strong>编译器替换预处理器。</strong></p><p><strong>符号表</strong></p><p>符号表在程序的编译阶段，将函数以及变量名地址记录起来，在链接阶段，根据符号表中记录的内容，去链接程序。</p><p><strong>用const替换define</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> ratio = <span class="number">1.25</span>;</span><br></pre></td></tr></table></figure><p>由于常量的定义经常在头文件之中，因此定义常量指针的时候，通常也将指针定义成const。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> author = <span class="string">"names"</span>;</span><br></pre></td></tr></table></figure><p>当我们需要创建一个类的常量的时候，需要在声明的时候，加一个static，使得这个常量只有一份实体，而且将这个常量的定义域限制在类内。</p><p>最后可以使用enum来代替define：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span>&#123;num1 = <span class="number">1</span>,num2 = <span class="number">2</span>&#125;;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; num1 &lt;&lt; num2;</span><br></pre></td></tr></table></figure><p>enum将数字符号化，也无法取到enum的地址。</p><p>此外，使用宏定义的另外一部分作用是定义一个简单的函数，避免函数调用带来的麻烦，同时不必要制定变量的类型（需要是同一个类别的），在宏定义的时候，注意为我每一个变量添加一个括号。</p><p>但是我们完全没必要去定义define，而是使用inline去替代：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">callwith</span><span class="params">(<span class="keyword">const</span> T&amp; a ,<span class="keyword">const</span> T&amp; b)</span></span>&#123;</span><br><span class="line">  f(a&gt;b ? a:b); <span class="comment">// 谁大调用谁</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>对于单纯的变量，使用const，enum替换define</li><li>对于宏定义的函数，改成template + inline的形式</li></ul><h3 id="条款-03：尽可能使用-const"><a href="#条款-03：尽可能使用-const" class="headerlink" title="条款 03：尽可能使用 const"></a>条款 03：尽可能使用 const</h3><p>const的原则，<strong>你在可以使用它的时候就使用它</strong>，</p><p>const 是一个语义的束缚，说明内容不可修改，因此只要有这样的一种约束在，就应该声明出来，获得编译器的协助。</p><p>const声明指针的时候有以下几种方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> greeting[] = <span class="string">"hello"</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* p = greeting; <span class="comment">// 指针所指内容为const</span></span><br><span class="line"><span class="keyword">char</span> <span class="keyword">const</span>* p = greeting; <span class="comment">// const在*左边，与上相同</span></span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> p = greeting; <span class="comment">// 指针为const，内容可变</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> p = greeting; <span class="comment">//指针，内容都不变</span></span><br></pre></td></tr></table></figure><p><strong>令函数的返回值为一个常量值，往往可以降低造成意外的风险</strong></p><p>函数的返回值，正常不应该作为一个变量来被其他赋值，因为这个不符合逻辑，如果可以被直接赋值的话，函数就没什么用了。因此对于大多数函数的返回值来说，可以加上const。</p><p><strong>const成员函数</strong></p><p>const成员函数指的是在一个类里头，这个函数用const进行了标注，表明这个函数是只读的不可以在函数内部对数据成员进行修改，格式如下,const在函数的最后：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position) <span class="keyword">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tex[position];</span><br><span class="line">  &#125;;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将函数定义成const，可以容易得知这个函数无法修改对象的值；同时使得操作const对象成为可能。</p><p><strong>真实程序中，const对象大多用于传参数，passed-by-pointer-to-const；passed-by-reference-to-const</strong>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">point</span><span class="params">(cosnt TextBlock&amp; ctb)</span></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; ctb[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在一些类中，const标注的函数其内部不允许对成员数据进行修改，但是也存在例外，<strong>mutable</strong>变量定义的变量将改变一些值的const属性，允许在const函数中修改：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">block</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">mutable</span> <span class="keyword">int</span> len;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">length</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> block::length() <span class="keyword">const</span></span><br><span class="line">&#123;</span><br><span class="line">  len = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">return</span> len; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>const和non-const函数允许函数进行重载，</strong>但是在使用的时候应该避免写两个函数，而是在non-const函数中，通过类型的转换来调用const类型的函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">block</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position) <span class="keyword">const</span>&#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">char</span>&amp; <span class="keyword">operator</span>[](<span class="keyword">int</span> position)&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">const_cast</span>&lt;<span class="keyword">char</span>&amp;&gt;(<span class="keyword">static_cast</span>&lt;cosnt block&amp;&gt;)(*<span class="keyword">this</span>)[position];</span><br><span class="line">    <span class="comment">// const_cast 去掉const</span></span><br><span class="line">    <span class="comment">// static_cast 将this转换为const类型，调用上一个函数</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结</strong></p><ul><li>const可以施加于任何作用域内的对象，函数参数，返回值，成员函数。</li><li>在能够使用const的时候尽量使用const，利用编译器规则为你排除错误。</li><li>编译器强制实行bitwise constness，编写程序的时候应该遵守逻辑上的const（避免const函数，有些指针是const，但是其内部的值可以修改）。</li><li>const和非const函数有本质上的相似的话，应该使用non-const的版本去调用，避免代码重复。</li></ul><h3 id="条款-04：确定对象被使用前已被初始化"><a href="#条款-04：确定对象被使用前已被初始化" class="headerlink" title="条款 04：确定对象被使用前已被初始化"></a>条款 04：确定对象被使用前已被初始化</h3><p>由于cpp是一个语言联邦，因此它并不保证所有的对象都会被初始化。因此：<strong>在使用对象之前先将对象进行初始化。</strong></p><p>特别值得注意的是，在对成员函数进行初始化时，在构造函数本体内进行的的并非初始化，而是赋值操作。<strong>cpp规定，对象的成员变量的初始化动作发生在进入构造函数本体之前。</strong>因此将成员初始化写在初始化成员列表中，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AB</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> aa;</span><br><span class="line">    <span class="keyword">int</span> bb;</span><br><span class="line">    AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b);</span><br><span class="line">&#125;</span><br><span class="line">AB::AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b)&#123;  <span class="comment">// 这种方式时赋值，初始化之后又做一遍赋值，效率很低</span></span><br><span class="line">  aa = a;</span><br><span class="line">  bb = b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 修改版本如下：</span></span><br><span class="line">AB::AB(<span class="keyword">int</span> a,<span class="keyword">int</span> b):aa(a),bb(b)  <span class="comment">// 构造初始化表，效率比较高</span></span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外，对于不同单元内定义的static变量，他们的初始化次序是不确定的。static对象，他们的寿命从构造出来一直到函数的结束。定义在函数内部的称为local static，定义在其他地方位置的称为non-local static，由于定义在不同编译单元的non-local-static中初始化的顺序不同，如果另一个初始化单元，用到了一个未被初始化的static的话，可能会发生很不好的事情，因此：<strong>将每个non-local-static对象搬到自己的专属函数内，这些函数返回一个reference对象，然后指针直接调用这些函数。</strong>这样你在调用这个函数之前，这个变量将会被初始化。</p><p><strong>总结</strong></p><ul><li>为内置的对象进行初始化，cpp不会保证初始化</li><li>构造函数最好使用成员初始化列表的方式进行初始化，成员的次序应该于定义的顺序相同</li><li>为了免除<strong>跨编译单元初始化次序问题</strong>，最好将non-local-static变量变为local static，定义在函数内部，函数返回一个该对象的引用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> effective cpp </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastFCN: 大工不巧</title>
      <link href="/2019/10/31/FastFCN-%E5%A4%A7%E5%B7%A5%E4%B8%8D%E5%B7%A7/"/>
      <url>/2019/10/31/FastFCN-%E5%A4%A7%E5%B7%A5%E4%B8%8D%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<p>FastFCN是自动化所2019年cvpr上的一个工作，提出JPU模块，代替dilated conv，在保证网络精度的前提下，大大降低网络的计算复杂度，是的FPS得到提升。</p><p>这些年来计算机视觉得到广泛的发展，网络结构也越来越复杂，这篇文章做了一些下修改，可以说耳目一新，结构十分简单，结果十分有效。</p><a id="more"></a><h3 id="语义分割常用的提取feature-map"><a href="#语义分割常用的提取feature-map" class="headerlink" title="语义分割常用的提取feature map"></a>语义分割常用的提取feature map</h3><p><img src="/images/3D/fcn_struct.png" style="zoom:80%;"></p><p><strong>a）FCN结构：</strong>通过一个全卷积的网络，直接得到图像分割后的结果。缺点是图像中的特征丢失。</p><p><strong>b）encoder-decoder结构：</strong>encoder结构得到高层次的特征，decoder阶段通过结合多层次的特征来得到一个多尺度融合的feature map，缺点是仍然存在数据的丢失（pooling 结构）</p><p><strong>c） DilatedFCN：</strong>利用空洞卷积替换pooling层，扩大feature map感受野的同时，没有降低feature map的分辨率。但是这种结构导致了很大的计算量。</p><p>###JPU结构</p><p>作者提出JPU（joint pyramid upsampling）结构，替换DilateFCN中的空洞卷积结构，能够大大的减少内存以及时间上的消耗。</p><p><img src="/images/jpu.png" alt="image-20191101134143826" style="zoom:60%;"></p><p>###FastFCN结构 </p><p><img src="/images/fastfcn.png" alt="image-20191101134311586" style="zoom:50%;"></p><p>FastFCN的backbone采用的是原始的FCN的结构，将FCN的最后三层输入JPU模块中进行训练，最终在许多任务上都得到一个性能一致，但速度得到提升的网络。</p><p><strong>mIoU：</strong>对每一类计算真实标签和预测标签的交并比，然后对所有类别求一个平均得到最后的结果。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这篇文章对FCN的网络中的dilated conv进行了一个很小的修改，达到一个比较合理的结果，文章非常的简单，不过可能是因为过于简单的原因，文中也有许多可有可无的内容，总之，对于做工程来说，得到一个FPS比较快的网络还是比较好的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于职业生涯规划以及时间安排的一些思考</title>
      <link href="/2019/10/30/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
      <url>/2019/10/30/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92%E4%BB%A5%E5%8F%8A%E6%97%B6%E9%97%B4%E5%AE%89%E6%8E%92%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 职业规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译器gcc，g++，clang，cmake，make介绍</title>
      <link href="/2019/10/27/%E7%BC%96%E8%AF%91%E5%99%A8gcc%EF%BC%8Cg-%EF%BC%8Cclang%EF%BC%8Ccmake%EF%BC%8Cmake%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/10/27/%E7%BC%96%E8%AF%91%E5%99%A8gcc%EF%BC%8Cg-%EF%BC%8Cclang%EF%BC%8Ccmake%EF%BC%8Cmake%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要介绍在mac上使用CLion编写cpp代码的时候，cpp编译以及链接的一些知识。</p><a id="more"></a><h3 id="cpp程序编译执行过程"><a href="#cpp程序编译执行过程" class="headerlink" title="cpp程序编译执行过程"></a>cpp程序编译执行过程</h3><ul><li><strong>编译</strong>：将源代码翻译成机器语言，生成目标文件<ul><li>预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。</li><li>编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。</li><li>汇编：将汇编代码翻译成目标机器代码.o文件。</li></ul></li><li><strong>链接</strong>：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。</li></ul><h3 id="cpp使用的编译器gcc，g-，clang"><a href="#cpp使用的编译器gcc，g-，clang" class="headerlink" title="cpp使用的编译器gcc，g++，clang"></a><strong>cpp使用的编译器gcc，g++，clang</strong></h3><ul><li><strong>gcc</strong>: 最开始的时候是 GNU C Compiler, 如你所知，就是一个c编译器。但是后来因为这个项目里边集成了更多其他不同语言的编译器，GCC就代表 the GNU Compiler Collection，所以表示一堆编译器的合集。</li><li><strong>g++</strong>：是GCC的c++编译器。</li><li><strong>clang</strong>：是mac上另起炉灶写的一个C语言、C++、Objective-C、Objective-C++语言的<strong>轻量级编译器</strong>。源代码发布于BSD协议下。Clang将支持其普通lambda表达式、返回类型的简化处理以及更好的处理constexpr关键字。</li></ul><p><strong>clang和gcc相比比gcc编译速度更快一些，而且错误提示更人性化。</strong></p><h3 id="make，cmake"><a href="#make，cmake" class="headerlink" title="make，cmake"></a>make，cmake</h3><p>光有gcc还不够，如果这时候我们开发的工程使用的文件很多，那就需要一个一个去编译，工作量很大。一些大型的IDE如VS studio，CLion使用clang编译器，使用cmake链接工具，对源码进行编译。</p><p><strong>make</strong></p><p>make类似于一个目录，是一个文件编译的批处理工具，本身没有编译的功能。make的作用就是告诉编译器，各种各样的编译规则，先做什么后做什么，这些规则写在makefile文件中。</p><p>make用于构建项目，其中一条很重要的规则就是依赖关系，当某些文件发生改变，直接或间接依赖这些文件的目标就要进行重新的构建。make用来构建管理文件，不一定用于编译。</p><p><strong>cmake</strong></p><p>构建一个项目需要了解构建的规则，并写出makefile文件，但是编译构建本身是个复杂过程，不同的项目构建规则会有所不同，要自己写出一个makefile文件比较困难。</p><p>cmake工具是根据平台（跨平台）和配置自动生成项目的makefile文件，然后给make使用。</p><p>cmake根据CMakeLists.txt文件（组态档）去生成makefile。在不使用CLion等这类IDE的情况下，这个CMakeLists.txt需要自己来写，下面是一个CMakeLists.txt：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.8</span>)</span><br><span class="line"><span class="keyword">project</span>(First_Code)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">11</span>)</span><br><span class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "-std=c++0x $&#123;CMAKE_CXX_FLAGS&#125; -g -ftest-coverage -fprofile-arcs")</span></span><br><span class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11")</span></span><br><span class="line"><span class="keyword">set</span>(SOURCE_FILES main.cpp <span class="keyword">test</span>.cpp assignment.cpp)</span><br><span class="line"><span class="keyword">add_executable</span>(First_Code <span class="variable">$&#123;SOURCE_FILES&#125;</span>)</span><br></pre></td></tr></table></figure><p>但是不用担心，CMakeLists.txt IDE也会负责生成。</p><h3 id="C-11"><a href="#C-11" class="headerlink" title="C++11"></a>C++11</h3><p>  C++11，（即ISO/IEC 14882:2011），是目前的C++编程语言的最新正式标准。它取代了第二版标准(第一版公开于1998年，第二版于2003年更新，分别通称C++98以及C++03，两者差异很小)。新的标准包含核心语言的新机能，而且扩展C++标准程序库。C++11新标准由C++标准委员会于2011年8月12日公布，并于2011年9月出版。此次标准为C++98发布后13年来第一次重大修正。</p><p><strong>gcc4.7以及之后，全面支持c++11。</strong></p><h3 id="MAC更换CLion编译器"><a href="#MAC更换CLion编译器" class="headerlink" title="MAC更换CLion编译器"></a>MAC更换CLion编译器</h3><p>在terminal输入<code>gcc -v</code>发现出来的是APPLE的clang编译器，由于更习惯使用GUN的gcc编译器，因此打算安装一个，同时保留原有的clang。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew search gcc // 查看有哪些gcc</span><br><span class="line">brew install gcc //安装最新版本的gcc，目前电脑上用的是gcc9.2</span><br></pre></td></tr></table></figure><p>上诉过程安装完成之后，gcc的位置在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/Cellar/gcc/9.2.0_1/bin</span><br></pre></td></tr></table></figure><p>将这个路径加入到CLion所使用的编译器上，同时修改cmake参数(preference 中修改)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D CMAKE_CXX_COMPILER=/usr/local/bin/g++-9</span><br></pre></td></tr></table></figure><h3 id="CLion-中新建项目的目录结构"><a href="#CLion-中新建项目的目录结构" class="headerlink" title="CLion 中新建项目的目录结构"></a>CLion 中新建项目的目录结构</h3><p>CLion是通过cmake来构建文件的，手动在CLion中生成cpp文件，系统件制动修改cmakeLists.txt</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp STL方法介绍</title>
      <link href="/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>这篇post主要目的是对cpp提供的Standard Template Library标准模板库中一些重要的方法进行学习，记录，以便今后学习。</p><a id="more"></a><h3 id="STL概述"><a href="#STL概述" class="headerlink" title="STL概述"></a>STL概述</h3><p>在开始STL之前，像大家介绍一下一个全能的头文件：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br></pre></td></tr></table></figure><p>这个头文件include了在STL中所有的头文件，方便我们使用而不用去担心这些方法所在的库。</p><p>STL库中有四类重要的部分：</p><ul><li>Algorithm：该部分提供的算法定义在容器上，用于操作容器上的元素。</li><li>containers：定义了一些常用的容器，如vector，map等等</li><li>functor：算子，是个函数，用于定制化STL函数，如sort，传入functor定制排序方式</li><li>iterator：迭代器，用于遍历整个序列</li></ul><h3 id="algorithm"><a href="#algorithm" class="headerlink" title="algorithm"></a>algorithm</h3><p><strong>sort(begin_adress,end_adress,compare)</strong></p><p>排序算法是定义在所有容器上的一个排序函数，其内部实现是快排，时间复杂度是$O(nlogn)$.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">9</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>&#125;;</span><br><span class="line">sort(arr,arr+<span class="number">10</span>); <span class="comment">//升序排序</span></span><br><span class="line">sort(arr,arr+<span class="number">10</span>,greater&lt;<span class="keyword">int</span>&gt;()); <span class="comment">// 降序排序</span></span><br><span class="line"><span class="comment">// 特殊数组的排序</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">interval</span>&#123;</span></span><br><span class="line">  <span class="keyword">int</span> val1;</span><br><span class="line">  <span class="keyword">int</span> val2;</span><br><span class="line">&#125;;</span><br><span class="line">interval arr[] = &#123;&#123;<span class="number">2</span>,<span class="number">2</span>&#125;,&#123;<span class="number">4</span>,<span class="number">3</span>&#125;,&#123;<span class="number">3</span>,<span class="number">4</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;&#125;</span><br><span class="line"><span class="keyword">bool</span> compareInterval(interval v1,interval v2)&#123;</span><br><span class="line">  <span class="keyword">return</span> v1.val1 &lt; v2.val2; <span class="comment">// 如果第一个数小的话，先排序</span></span><br><span class="line">&#125;</span><br><span class="line">sort(arr,arr+<span class="number">10</span>,compareInterval); <span class="comment">// 得到按第一个元素排序的数组</span></span><br></pre></td></tr></table></figure><p><strong>bool binary_search(start_adress,end_adress,value_find)</strong></p><p>二分搜索查找value_find这个元素，该数组已经被排序过了，复杂度为$O(logn)$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">if</span>(binary_search(arr,arr+<span class="number">10</span>,<span class="number">2</span>))&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"get it "</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>bool all_of(begin_adress,end_adress,lambda_func)</strong></p><p>该函数判断是否arr中的所有元素都满足lambda中的规则</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">STL_allof</span><span class="params">(<span class="keyword">int</span>*a)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> lens = <span class="keyword">sizeof</span>(a)/ <span class="keyword">sizeof</span>(a[<span class="number">0</span>]);</span><br><span class="line">    all_of(a,a+lens,[](<span class="keyword">int</span> x)&#123;<span class="keyword">return</span> x &gt;= <span class="number">0</span>;&#125;) ? <span class="built_in">cout</span>&lt;&lt;<span class="string">"all are positive"</span> : <span class="built_in">cout</span>&lt;&lt;<span class="string">"no all positive"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>bool any_of(begin_adress,end_adress,lambda_func)</strong></p><p>只要有一个满足要求的，就返回true</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">any_of(arr_begin,arr_end,[](<span class="keyword">int</span> x)&#123; <span class="keyword">return</span> x == <span class="number">0</span>;&#125;) <span class="comment">//返回bool</span></span><br></pre></td></tr></table></figure><p><strong>bool none_of(begin_adress,end_adress,lambda_func)</strong></p><p>所有都不满足情况的时候，返回true</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">none_of(arr_begin,arr_end,[](<span class="keyword">int</span> x)&#123; <span class="keyword">return</span> x == <span class="number">0</span>;&#125;) <span class="comment">//返回bool</span></span><br></pre></td></tr></table></figure><p><strong>copy_n(arr1,size,arr2)</strong></p><p>将arr1中的前size个元素拷贝到arr2中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[<span class="number">10</span>] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> arr2[<span class="number">10</span>];</span><br><span class="line">copy_n(arr,<span class="number">10</span>,arr2);</span><br></pre></td></tr></table></figure><h3 id="containers"><a href="#containers" class="headerlink" title="containers"></a>containers</h3><p><strong>序列容器</strong></p><h4 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h4><p>向量是一个动态数组，数组的大小随着元素的个数而变化，内存空间是连续分布的，因此可以使用迭代器。向vector末尾插入元素要花费的时间是不确定的，因为有时候vector可能会扩容，此外插入和删除要花线性的时间。</p><p><strong>iterators</strong></p><p>vector是在内存上连续的一段存储空间，因此允许使用迭代器，vector的迭代器有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.begin(); <span class="comment">// 指向第一个元素</span></span><br><span class="line">vec.end(); <span class="comment">// 指向最后一个元素</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i = vec.begin();i!=vec.end();i++)&#123;...&#125;</span><br><span class="line">vec.rbegin(); <span class="comment">//指向最后一个，反向迭代</span></span><br><span class="line">vec.rend();  <span class="comment">// 指向第一个，作为后向的终点</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i = vec.rbegin();i!=vec.end();i++)&#123;...&#125;</span><br><span class="line"><span class="comment">// 此外上诉两种指针都有一个c（const）的版本，如vec.rbegin()</span></span><br><span class="line"><span class="comment">//这个版本返回的迭代器是const类型的，不可改变迭代器所指向元素的值</span></span><br></pre></td></tr></table></figure><p><strong>capacity</strong></p><p>vector是一个可变长度的向量，当vector在添加元素的时候，会选择增长向量的容量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.size(); <span class="comment">//实际长度</span></span><br><span class="line">vec.capacity(); <span class="comment">//已经分配的长度</span></span><br><span class="line">vec.max_size(); <span class="comment">// 可分配的最大长度</span></span><br><span class="line">vec.empty(); <span class="comment">// 判断是否为空</span></span><br><span class="line">vec.shrink_to_fit(); <span class="comment">// 将容量减小到容器的容量大小</span></span><br></pre></td></tr></table></figure><p><strong>访问元素</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">vec[<span class="number">1</span>];</span><br><span class="line">vec.front();</span><br><span class="line">vec.back();</span><br><span class="line">vec.at(pos);</span><br><span class="line">vec.data(); <span class="comment">// 返回指针指向第一个地址</span></span><br></pre></td></tr></table></figure><p><strong>修改元素</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.assign(val,time); <span class="comment">//vec赋值，time个val的值</span></span><br><span class="line">vec.push_back(val);</span><br><span class="line">vec.pop_back(val);</span><br><span class="line">vec.insert(insert_adress,val);</span><br><span class="line">vec.erase(adress);</span><br><span class="line">vec.clear(); <span class="comment">// 清空</span></span><br><span class="line">vec.emplace(adress,val); <span class="comment">// 插入元素，并且避免不必要的复制</span></span><br><span class="line">vec.emplace_back(val); <span class="comment">// 末尾插入</span></span><br><span class="line">vec.swap(vec2); <span class="comment">// 交换vec和vec1的元素</span></span><br></pre></td></tr></table></figure><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list是由<strong>双向链表</strong>实现的数据结构，它在空间中不连续，元素的访问速度不如vector，但是对元素的删除，插入操作十分的快速。</p><p>他的很多函数与vector类似，下面列举一下特殊的一下操作：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; ll = &#123;<span class="number">1</span>,<span class="number">7</span>,<span class="number">3</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">9</span>&#125;;</span><br><span class="line">ll.sort();</span><br><span class="line">ll.reverse();</span><br><span class="line">ll.push_front();</span><br><span class="line">ll.erase(adress) <span class="keyword">or</span> ll.erase(begin,end);</span><br><span class="line">ll.remove(val); <span class="comment">//删掉val</span></span><br><span class="line">ll.unique(); <span class="comment">// 删除重复元素</span></span><br><span class="line">ll.splice(l1.begin(),l2); <span class="comment">// 链表的拼接</span></span><br><span class="line">ll.merge(<span class="number">12</span>); <span class="comment">// 两个排序后的链表融合</span></span><br></pre></td></tr></table></figure><p><strong>deque</strong></p><p>双向队列，可以两头操作，效率比vector高，但是不一定保证地址是连续的。</p><p>deque和vector的操作基本一致，唯一的不同在于deque允许头插。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">deque</span>&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push_front(val);</span><br><span class="line">que.pop_front(val);</span><br></pre></td></tr></table></figure><p><strong>froward_list</strong></p><p>单向链表，与list类似，但只支持一个方向，同时所占用的存储空间更小。基本操作和list类似。</p><p><strong>queue</strong></p><p>单向队列，基本方法如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push(val); <span class="comment">// 插到队列尾巴</span></span><br><span class="line">que.pop();  <span class="comment">// 删除队列头部元素</span></span><br><span class="line"><span class="built_in">queue</span>.empty();</span><br><span class="line"><span class="built_in">queue</span>.size();</span><br></pre></td></tr></table></figure><p><strong>priority queue</strong></p><p>优先队列中，队头的元素是最大的，但是队列的排列顺序不是按照顺序排序的。优先队列使用起来应该很方便，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;<span class="keyword">int</span>&gt; que;</span><br><span class="line">que.push(val);</span><br><span class="line">que.push(val);</span><br><span class="line">que.pop();</span><br><span class="line">que.top();</span><br></pre></td></tr></table></figure><p>优先队列是一种最大堆的结构。也可以用优先队列构建最小堆。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;<span class="keyword">int</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;,greater&lt;<span class="keyword">int</span>&gt;&gt; gg;</span><br></pre></td></tr></table></figure><p><strong>stack</strong></p><p>栈是先进先出的一个结构，只有一端开放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stack.empty();</span><br><span class="line">stack.push(val);</span><br><span class="line">stack.pop();</span><br><span class="line">stack.top();</span><br></pre></td></tr></table></figure><p><strong>关联容器</strong></p><p><strong>set</strong></p><p>集合容器，他要求内部元素没有重复的，他的常用的方法有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; gg;</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>,greater&lt;<span class="keyword">int</span>&gt;&gt; gg; <span class="comment">//从大到小</span></span><br><span class="line">begin();</span><br><span class="line">end();</span><br><span class="line">empty();</span><br><span class="line">gg.insert(val); <span class="comment">// set中的元素都是有序的</span></span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; gg = &#123;vec.begin(),vec.end()&#125;;</span><br><span class="line">gg.lower_bound(val); <span class="comment">//. 返回低于或等于val</span></span><br><span class="line">gg.upper_bound(val); <span class="comment">// 返回高于或等于val的第一个迭代器位置</span></span><br></pre></td></tr></table></figure><p><strong>multiset</strong></p><p>这个容器类似于set，但是和set有一个不同之处在于multiset可以允许重复。</p><p><strong>map</strong></p><p>字典，键值对。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">amap.insert(pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;(<span class="number">1</span>,<span class="number">21</span>));</span><br><span class="line">amap.insert(pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;(<span class="number">2</span>,<span class="number">23</span>));</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; amap[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">auto</span> ptr = amap.begin();</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;first&lt;&lt; <span class="string">" "</span>&lt;&lt; ptr-&gt;second;</span><br><span class="line">amap.erase(amap.begin());</span><br><span class="line">amap.erase(<span class="number">4</span>);<span class="comment">//key</span></span><br></pre></td></tr></table></figure><p><strong>multimap</strong></p><p>操作基本与map相同，不相同的是，multimap允许有相同的key。</p><p><strong>unordered_set</strong></p><p>背后使用hash表来存储，key没有顺序：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unordered_set</span>&lt;<span class="built_in">string</span>&gt; stringset;</span><br><span class="line">stringset.insert(<span class="string">"code"</span>);</span><br><span class="line">stringset.find(key); <span class="comment">//返回一个迭代器的位置</span></span><br></pre></td></tr></table></figure><p><strong>unordered_multiset</strong></p><p>与unordered_set相似，但是允许元素重复。</p><p><strong>unordered_map</strong></p><p>与map相似，但是其中的元素key的顺序不是按顺序的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">double</span>&gt; umap;</span><br><span class="line">umap['id'] = 11;</span><br><span class="line">umap.insert(make_pair(<span class="string">"e"</span>,<span class="number">2.33</span>));</span><br><span class="line">umap.find(key);</span><br></pre></td></tr></table></figure><p><strong>unordered_multimap</strong></p><p>与unordered_map相类似，但是允许有key的重复。</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp语法快速回顾</title>
      <link href="/2019/10/25/cpp%E8%AF%AD%E6%B3%95%E5%BF%AB%E9%80%9F%E5%9B%9E%E9%A1%BE/"/>
      <url>/2019/10/25/cpp%E8%AF%AD%E6%B3%95%E5%BF%AB%E9%80%9F%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>cpp的一些基本的语法的回顾，主要是一些比较小规模的语法特性的记录。</p><p>​    <a id="more"></a></p><p><strong>第一个可执行的cpp代码</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"hello world"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp程序编译执行过程</strong></p><ul><li>编译：将源代码翻译成机器语言，生成目标文件<ul><li>预处理：拷贝#include 文件代码，#define 宏定义的替换 ，处理条件编译指令 （#ifndef #ifdef #endif）等，输出.i文件。</li><li>编译优化：进行cpp词法语法分析，确定所有指令是否符合规则，后翻译成汇编代码文件.s。</li><li>汇编：将汇编代码翻译成目标机器代码.o文件。</li></ul></li><li>链接：由于目标文件调用了其他源文件，因此这一步需要将有关的源文件链接起来，生成.exe。</li></ul><p><strong>#define宏定义</strong></p><p>宏定义用一个字符串代替一串字符串，在cpp编译的预处理阶段，将字符串的位置替换成原来的长字符串，这种设计方式的好处是1）修改代码方面。2）对一些很短的代码，如果写成一个函数，将花费大量的系统调用时间，因此宏定义可以提升代码效率，但是目标代码空间就会变大。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> pi 3.14 <span class="comment">//对象宏，定义变量</span></span></span><br><span class="line"><span class="comment">// 函数宏，这种方式直接将字符串展开，需要注意代码运算优先级的问题</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MIN(A,B) ((A) &lt; (B) ?(A):(B))</span></span><br></pre></td></tr></table></figure><p><strong>条件编译</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> NULL</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> NULL 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p><strong>#与##运算符</strong></p><p><strong>#</strong>起到将指令变成字符串的作用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MACRO(x) #x</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;MACRO(HOW ARE)&lt;&lt;<span class="built_in">endl</span>; <span class="comment">// "HOW ARE"</span></span><br></pre></td></tr></table></figure><p><strong>##</strong>起到链接前后内容的作用，将参数连在一起。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACFUNS(x,y) x##y</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;ACFUNS(<span class="string">"aa"</span>,<span class="string">"bb"</span>)&lt;&lt;<span class="built_in">endl</span>; <span class="comment">// aabb</span></span><br></pre></td></tr></table></figure><p><strong>typedef申明</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">short</span> <span class="keyword">int</span> <span class="keyword">wchar_t</span>;</span><br></pre></td></tr></table></figure><p>使用wchar_t来表示short int 这种类型，起了一个新名字。</p><p><strong>enum枚举类</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> color&#123;red,blue,black&#125; c; <span class="comment">//值为0，1，2</span></span><br><span class="line">c = blue; <span class="comment">//等于为c赋值为1</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; c; <span class="comment">// 1</span></span><br></pre></td></tr></table></figure><p><strong>声明与定义</strong></p><p>cpp语言支持分离时编译，允许将程序分割成多个模块，声明与定义分离（.h / .cpp）,静态库(lib)包含声明以及方法，动态库(.lib,dll)仅包含声明，dll中为方法。</p><p>声明的作用是在编译器链接代码的阶段，告诉程序该变量的存在。可以在多个文件中，多次声明，使用关键字：</p><p><code>extern int a;</code>声明了一个变量a。定义的过程只能有一次。</p><p><code>extern</code>关键字常用在多个文件同时使用同一个变量或者函数的时候。</p><p><strong>变量的初始值</strong></p><p>当一个变量是全局变量，系统会默认初始值为0。当变量是局部变量，系统不会赋初始值。</p><p><strong>定义常量</strong></p><p>常量不可以修改它的值，两种方式定义常量：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> WIDTH 10</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> HEIGHT = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p><strong>修饰符类型</strong></p><p>修饰符用于改变基本数据类型char，int，double的含义。可以使用的修饰符有： <code>signed,unsigned,long short</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>* <span class="keyword">restrict</span> restar = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(<span class="number">10</span> * <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">制定只有restar这个指针可以指向这一块内存，其他指针都不能访问</span><br></pre></td></tr></table></figure><p><strong>存储类</strong></p><p>auto 关键字声明变量根据初始化值自动推断<strong>变量</strong>的类型，声明函数返回的<strong>占位符</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> f = <span class="number">3.14</span>;</span><br><span class="line"><span class="keyword">auto</span> s = <span class="string">"hello"</span>;</span><br></pre></td></tr></table></figure><p><strong>static</strong>告诉编译器在程序声明周期内保持局部变量的存在，在编译阶段进行赋值，其他阶段不会进行初始化操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> i = <span class="number">5</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;i&lt;&lt;<span class="string">'\n'</span>;</span><br><span class="line">    i--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">        func();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出为5，4，3，2，1.... 其中static i只会被初始化一次</span></span><br></pre></td></tr></table></figure><p><strong>thread_local</strong>关键字声明的变量仅仅可以在其上创建的线程上访问，仅仅可以用来声明变量。</p><p><code>thread_local int x;</code></p><p><strong>位运算符</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">00111100</span></span><br><span class="line">B = <span class="number">00001101</span></span><br><span class="line">A&amp;B = <span class="number">00001100</span></span><br><span class="line">A|B = <span class="number">00111101</span></span><br><span class="line">A^B = <span class="number">00110001</span></span><br><span class="line">~A = <span class="number">11000011</span></span><br><span class="line">A &lt;&lt;= <span class="number">1</span>; <span class="comment">//A = 01111000</span></span><br><span class="line">A &gt;&gt;= <span class="number">1</span>; <span class="comment">//A = 00011110</span></span><br><span class="line"><span class="keyword">sizeof</span>(A); <span class="comment">//返回A的大小</span></span><br><span class="line">b = &amp;A; <span class="comment">// 取地址</span></span><br><span class="line">c = *b; <span class="comment">// 取出b中的值</span></span><br></pre></td></tr></table></figure><p><strong>函数定义</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a &gt; b)&#123;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//传参数方式可以分为传值，传指针，传地址三种</span></span><br></pre></td></tr></table></figure><p><strong>lambda表达式</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[capture](parameter)-&gt; <span class="keyword">return</span>-type&#123;body&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> s = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">auto</span> funa = [s](<span class="keyword">int</span> a,<span class="keyword">int</span> b)-&gt; <span class="keyword">int</span>&#123;<span class="keyword">return</span> a+b+s;&#125;;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; funa(<span class="number">1</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure><p><strong>数学运算</strong></p><p>数学运算的方法在<cmath>头文件中。</cmath></p><p><strong>随机数</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">j = rand()</span><br></pre></td></tr></table></figure><p><strong>数组</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>] = &#123;<span class="number">10</span>,<span class="number">10</span>,<span class="number">1</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br></pre></td></tr></table></figure><p><strong>字符串</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//c风格字符串</span></span><br><span class="line"><span class="keyword">char</span> gre[] = &#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>&#125;;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;gre;</span><br><span class="line"><span class="built_in">strcpy</span>(str1,str2); <span class="comment">// str2给str1赋值</span></span><br><span class="line"><span class="built_in">strcat</span>(str1,str2); <span class="comment">// str1+str2</span></span><br><span class="line"><span class="built_in">strcmp</span>(s1,s2);<span class="comment">//比较s1，s2</span></span><br><span class="line"><span class="built_in">strchr</span>(s1,ch); <span class="comment">// 返回指针，指针位置为ch第一次出现的位置</span></span><br><span class="line"><span class="built_in">strstr</span>(s1,s2);<span class="comment">// 放回指针，指向第一次出现s2的位置</span></span><br></pre></td></tr></table></figure><p><strong>string 字符串操作</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> a = <span class="string">"hello"</span>;</span><br><span class="line"><span class="built_in">string</span> b = <span class="string">"el"</span>;</span><br><span class="line">a.find_first_of(b); <span class="comment">// 等于a.find(b);</span></span><br><span class="line">a.find_last_of(b);</span><br><span class="line">s.size();</span><br><span class="line"><span class="keyword">if</span>(a.find(b) == <span class="built_in">string</span>::npos)&#123;</span><br><span class="line">    <span class="keyword">return</span> “dont exists”;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>指针</strong></p><p>cpp中每个变量都有一个内存位置，这个内存位置可以通过<code>&amp;</code> 取址符来得到，他表示内存中的一个地址。</p><p>指针是一个变量，它的值就是地址。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *ip;</span><br><span class="line"><span class="keyword">int</span> var = <span class="number">10</span>;</span><br><span class="line">ip = &amp;var;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; *ip; <span class="comment">//取去ip中的值</span></span><br><span class="line"><span class="keyword">int</span> *ptr[<span class="number">10</span>]; <span class="comment">//指针数组，数组中存指针</span></span><br><span class="line"><span class="comment">//指针可以允许加减，数组和指针很类似，一个定义在数组开头的指针用法和数组相同</span></span><br><span class="line"><span class="keyword">int</span> var[<span class="number">5</span>] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line"><span class="keyword">int</span> *ip = var;</span><br><span class="line">ip++;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ip[<span class="number">1</span>];</span><br></pre></td></tr></table></figure><p><strong>引用</strong></p><p>引用变量是为变量起了一个别名，引用在创建的时候必须初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>&amp; r = a;</span><br><span class="line"><span class="comment">//传参数的时候可以使用引用，不用传值，快。</span></span><br><span class="line"><span class="comment">// 函数返回类型为引用类型的时候，操作和其他类型的一样，返回一个引用，就可以对这个引用进行赋值的过一些操作了。</span></span><br></pre></td></tr></table></figure><p><strong>结构体</strong></p><p>cpp中定义数据类型使用结构体</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Book</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Book</span> <span class="title">b1</span>;</span></span><br><span class="line"><span class="comment">//使用typedef定义别名</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Book</span>&#123;</span></span><br><span class="line">      <span class="keyword">int</span> count;</span><br><span class="line">      <span class="built_in">string</span> name;</span><br><span class="line">&#125;Book;</span><br><span class="line">Book b1,b2;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; b1.name;</span><br><span class="line"><span class="comment">//指针调用</span></span><br><span class="line">Book *ptr = &amp;b1;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;name;</span><br></pre></td></tr></table></figure><p><strong>类</strong></p><p>类是cpp的核心，通常被用与用户定制自己的数据以及方法</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">      <span class="keyword">int</span> width;</span><br><span class="line">      <span class="keyword">int</span> height;</span><br><span class="line">      Box(); <span class="comment">//构造函数，函数进行定义，初始化的入口</span></span><br><span class="line">      <span class="function"><span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> width*height;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;;</span><br><span class="line">Box b1; <span class="comment">//定义了一个Box的类型变量</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt; b1.width;</span><br><span class="line">Box* ptr = &amp;b1;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; ptr-&gt;get_area();</span><br></pre></td></tr></table></figure><p><strong>拷贝构造函数</strong></p><p>利用已经存在的类对象，对新类进行初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Box b2 = b1;</span><br></pre></td></tr></table></figure><p><strong>友元函数</strong></p><p>友元函数设计的思路是说，一个非A类内的函数，希望获得完整的A类内成员的访问权限，这时候需要在A类对该函数进行一下注册，用friend最为前缀（适用于多人协作的项目）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line">  <span class="keyword">int</span> val;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">int</span> mon;</span><br><span class="line">  <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">detial</span><span class="params">(A a1)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">(A a1)</span></span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; a1.val; <span class="comment">//允许访问私有变量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>this 指针</strong></p><p>成员函数均有一个隐含的this指针参数，用于指向对象。</p><p><strong>类内静态成员变量，静态函数</strong></p><p>类中允许定义static变量，该变量在所有类的对象中是共享的，该变量属于类，不属于对象，不可以在类的构造函数中初始化static变量，而是通过<code>A::变量 =  init</code>的方式进行初始化。</p><p>static声明的函数，与任何对象都没有关系，该函数与类同在，只能访问静态成员变量，与其他静态成员函数。</p><p><strong>继承</strong></p><p>我理解继承是这种大型工程中非常有灵性的一种设计，通过底层写一些通用的模版类，底下的继承类就有很好的一致性，以及少写了很多重复性的工作，此外通过子类中定制自己的成员，呈现一种放散式的结构。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">book</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> page = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">string</span> name = <span class="string">"island"</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span>&lt;&lt; <span class="keyword">this</span>.page &lt;&lt; <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">finance</span>:</span> <span class="keyword">public</span> book&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> profit = <span class="number">0</span>;</span><br><span class="line">    finance(<span class="keyword">int</span> pro);</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">detail</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line">finance::finance(<span class="keyword">int</span> pro):book()&#123;</span><br><span class="line">  <span class="keyword">this</span>.profit = pro;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> finance::detail()&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span>.page &lt;&lt; <span class="keyword">this</span>.name &lt;&lt; <span class="keyword">this</span>.pro;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体来说，<strong>继承不会继承积累的构造函数，友元函数，重载运算符。</strong>从设计的角度上看，友元这一类函数会破坏类的封装性，子类不接受友元是很正确的决定，而构造函数有专门的作用，因此，不继承构造函数也是可以理解的。</p><p><strong>基类构造函数</strong></p><p>所谓的基类构造函数，构造的时候，需要对父类进行初始化，很容易理解。初始化的方式就是通过构造函数表来初始化，在构造函数定义的时候使用，成员变量也允许那时候初始化。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">finance::finance(<span class="keyword">int</span> profit,<span class="keyword">int</span> page,<span class="built_in">string</span> name):Book(page,name),profit(profit)&#123;&#125;</span><br></pre></td></tr></table></figure><p><strong>重载运算符</strong></p><p>我认为这一步的设计思路是是我们设计的类和基础类型的变量能够使用一些类似于<strong>+，-，x，/</strong>这种方便的操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">   Box <span class="keyword">operator</span>+(Box b)&#123;</span><br><span class="line">     Box box;</span><br><span class="line">     box.width = <span class="keyword">this</span>.width + b.width;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">Box b1,b2;</span><br><span class="line">b = b1 + b2;</span><br></pre></td></tr></table></figure><p><strong>重载函数</strong></p><p>重载函数指的是同一个函数，但是随着输入的参数不同，调用的具体函数也是不同的。这样的设计思路在于，是一个函数用起来更加灵活，例如对于不同级别的类别都需要登入操作，但是入口不同。就可以利用重载的思路来实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">log</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> user = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> vip = <span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(<span class="keyword">int</span> user)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(<span class="keyword">int</span> user,<span class="keyword">int</span> vip)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>多态</strong></p><p>多态的设计思路，有这样一种情况，当子类与父类中同时有某个方法。我们可以用父类的指针来存放所有的子类的地址。但是每个子类调用一个工友的方法，各自应该有各自的方案。例如大家办护照都去公安局，但是每个人有不同的办理方案，这种情况就是多态。</p><p>要实现多态的话，在需要实现多态的函数前加上<strong>virtual</strong>关键字，告诉编译器，在编译的时候不要链接该函数，而是得到调用函数的时候，看变量的类型来确定用什么函数。这个叫<strong>做动态链接</strong>。</p><p>静态链接则是写死了，每次用父类的对象调用的都是父类的方法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> height = <span class="number">0</span>;</span><br><span class="line">    shape(<span class="keyword">int</span> w,<span class="keyword">int</span> h):width(w),height(h);</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"shape"</span> ；</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">triangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    triangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"triangle area"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">      <span class="keyword">return</span> a*b / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>:</span><span class="keyword">public</span> shape&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    rectangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="built_in">cout</span> &lt;&lt; <span class="string">"rectangle area"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">      <span class="keyword">return</span> a*b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">shape* sh;</span><br><span class="line"><span class="function">rectangle <span class="title">rec</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="function">triangle <span class="title">tri</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="comment">// 正方形面积</span></span><br><span class="line">sh = &amp;rec;</span><br><span class="line">sh-&gt;area();</span><br><span class="line"><span class="comment">// 三角形面积</span></span><br><span class="line">sh = $tri;</span><br><span class="line">sh-&gt;area();</span><br></pre></td></tr></table></figure><p><strong>虚基类virtual</strong></p><p>虚基类提出的设计思路是说，如果一个类同时继承两个类，而这两个类又同时继承自同一个父类，因此在子类这就会出现最高父类的两个拷贝。因此多继承很多时候会产生很多二义性的问题，因此在设计函数的时候要尽可能避免。出现这种情况可以用virtual进行虚继承。<code>class B : virtual public A{...}</code>。</p><p><strong>抽象类</strong></p><p>设计抽象类的设计思想是说，面向对象的系统可能会使用一个抽象基类为所有的外部应用程序提供一个适当的、通用的、标准化的接口。因此会在基类设计一个<strong>virtual</strong>抽象类，规定一下子类的接口参数的格式。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">shape</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">    <span class="keyword">int</span> weight;</span><br><span class="line">    shape(<span class="keyword">int</span> a,<span class="keyword">int</span> b):width(a),weight(b)&#123;&#125;</span><br><span class="line">  <span class="comment">// 提供纯虚函数接口，子类必须覆盖</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">rectangle</span>&#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    rectangle(<span class="keyword">int</span> a,<span class="keyword">int</span> b):shape(a,b)&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">get_area</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.width*<span class="keyword">this</span>.weight;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>文件的读写</strong></p><p>文件的读写定义在两个库函数中，<strong>ifstream,ofstream</strong>，写入过程使用&lt;&lt;，读出过程使用&gt;&gt;。</p><p><strong>异常处理</strong></p><p>cpp中提供了<code>try,catch,throw</code>用来保护代码，抛出错误。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="comment">//保护代码</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(ExceptionName e1)&#123;</span><br><span class="line">  <span class="comment">//catch 内容</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(ExceptionName e2)&#123;</span><br><span class="line">  <span class="comment">// something</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//catch 模块</span></span><br><span class="line"><span class="keyword">if</span>(error)&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="string">"error message"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp动态内存</strong></p><p>栈：在函数内部声明的所有变量都将用栈来存储</p><p>堆：这部分内存程序未使用，在程序运行时可动态分配内存。</p><p>cpp允许使用<strong>new</strong>给变量分配堆内内存，返回动态内存的起始位置，同时可以使用<strong>delete</strong>将这部分内存删除。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span>* ptr = <span class="keyword">new</span> <span class="keyword">double</span>;</span><br><span class="line">*ptr = <span class="number">12.32</span>;</span><br><span class="line"><span class="comment">//数组申请空间</span></span><br><span class="line"><span class="keyword">int</span> * ptr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line"><span class="comment">//释放</span></span><br><span class="line"><span class="keyword">delete</span>[] ptr;</span><br><span class="line"><span class="comment">// 二维数组</span></span><br><span class="line"><span class="keyword">int</span> ** ptr = <span class="keyword">new</span> <span class="keyword">int</span> *[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">  ptr[i] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">Box* ptr = <span class="keyword">new</span> Box[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">delete</span> [] ptr;</span><br></pre></td></tr></table></figure><p><strong>命名空间</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> first_space&#123;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">     ...</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">first_space::func();</span><br></pre></td></tr></table></figure><p><strong>cpp模板</strong></p><p>模板指<strong>函数模板</strong>和<strong>类模板</strong>，是一种参数化类型机制，在泛型编程（泛型允许程序员使用<strong>未指定</strong>类型的变量，在<strong>实例化</strong>时作为参数指明这些类型）中十分的重要。常用的cpp模版例如<strong>vector</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//函数模板</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="comment">// 用T表示一种类型的变量</span></span><br><span class="line"><span class="function">T <span class="title">Max_val</span><span class="params">(T a,T b)</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a &gt; b ? a:b;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line">Max_val(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">Max_val(<span class="number">1.2</span>,<span class="number">3.4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//类模板</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">stack</span>&#123;</span></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;T&gt; elems;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(T <span class="keyword">const</span>&amp; val)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">stack</span>&lt;T&gt;:</span>:push(T <span class="keyword">const</span>&amp; val)&#123;</span><br><span class="line">  elems.push(val);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; int_stack;</span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="built_in">string</span>&gt; str_stack;</span><br></pre></td></tr></table></figure><p><strong>const&amp;</strong></p><p>在一些库函数，模板类的函数中进场发现这种传参数，传指数的方法,这种方法用引用减少数值传递过程中需要消耗的时间。返回值是const&amp;是个引用，如果是const的话，程序还需要另外开辟空间。同时这样使用可以函数返回值还可以作为左值，因此建议今后写代码带上引用。</p><p><strong>void*</strong></p><p><code>void *</code>是一种指针类型，常用在<code>函数参数、函数返回值</code>中需要兼容不同指针类型的地方。它类似于指针类型中的原始基类，所有的指针可以对它赋值，它也可以转化为任何指针类型，但是是否合理需要看函数的原始定义。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* c;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> * ptr = &amp;a;</span><br><span class="line">c = ptr;</span><br><span class="line"><span class="keyword">int</span> * d = (<span class="keyword">int</span> *) c;</span><br></pre></td></tr></table></figure><p><strong>cpp多进程/线程</strong></p><ul><li>进程：程序需要并发执行</li><li>线程：一个进程中含多个线程，线程负责同一段程序中的并发</li></ul><p>使用 POSIX 编写多线程 C++ 程序。POSIX支持linux上的并行：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">// 线程的运行函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">say_hello</span><span class="params">(<span class="keyword">void</span>* args)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Hello Runoob！"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 定义线程的 id 变量，多个变量使用数组</span></span><br><span class="line">    <span class="keyword">pthread_t</span> tids[NUM_THREADS];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//参数依次是：创建的线程id，线程参数，调用的函数，传入的函数参数</span></span><br><span class="line">        <span class="keyword">int</span> ret = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, say_hello, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (ret != <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">           <span class="built_in">cout</span> &lt;&lt; <span class="string">"pthread_create error: error_code="</span> &lt;&lt; ret &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等各个线程退出后，进程才结束，否则进程强制结束了，线程可能还没反应过来；</span></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>cpp中的STL（standard template library）</strong></p><p>STL库中包含了许多模板类，实现了很多容器，算法以及迭代器等等。</p><ul><li>算法algorithm：这些算法类大多是作用在容器上</li><li>容器：如vector，map，set等等</li><li>迭代器</li><li>Functors：算子，类似于sort的时候用算法自定义排序的方式，作为参数传入</li></ul><p>为STL专门开一个post，日常使用和刷题都会比较经常使用：<a href="https://perper.site/2019/10/27/cpp-STL%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">链接</a></p><p><strong>cpp标准库</strong></p><p>这个库是继承自C语言的，包括标准函数库和标准对象库。</p><p><strong>#include</strong></p><p>cpp中include一个头文件在编译阶段等同于件这个头文件中的代码展开，因此cpp中发生相互引用时将会报错，当你在不确定是否存在相互引用的时候，建议加上include保护：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> FOLDER_METHOD_H_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FOLDER_METHOD_H_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>Google 开源风格指南中建议的include顺序：</p><p> <code>dir/foo.cc</code> 或 <code>dir/foo_test.cc</code> 的主要作用是实现或测试 <code>dir2/foo2.h</code> 的功能, <code>foo.cc</code> 中包含头文件的次序如下:</p><blockquote><ol><li><code>dir2/foo2.h</code> (优先位置, 详情如下)</li><li>C 系统文件</li><li>C++ 系统文件</li><li>其他库的 <code>.h</code> 文件</li><li>本项目内 <code>.h</code> 文件</li></ol></blockquote><p>这种优先的顺序排序保证当 <code>dir2/foo2.h</code> 遗漏某些必要的库时， <code>dir/foo.cc</code> 或 <code>dir/foo_test.cc</code> 的构建会立刻中止。因此这一条规则保证维护这些文件的人们首先看到构建中止的消息而不是维护其他包的人们。</p><p>.cpp中要包含include自己的h文件，在程序编译阶段include尽量都写在头文件中，源文件就可以很少的引用头文件。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>重新回顾了一下cpp的一些语法重点，发现这本语言相比较于其他语言来说，有很大的自由度，自由发挥的地方非常的多。同时有为写一些大工程而设计上的思路。总体来说，比较感兴趣，由于使用CLion来作为编辑器，通过一种更加原生的方式写代码，编译代码，感觉要比直接用VS studio要有深刻的理解。</p><p>这一页博客要常常回来回顾回顾！</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepLab 总结</title>
      <link href="/2019/10/22/DeepLab-%E6%80%BB%E7%BB%93/"/>
      <url>/2019/10/22/DeepLab-%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 项目总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp工程文件的总结</title>
      <link href="/2019/10/21/cpp%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/2019/10/21/cpp%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>cpp学习的第一轮，首先从以前的盲区开始杀进去，解决的第一个问题是</p><blockquote><p>人们说cpp工程文件，说的都是什么。</p></blockquote><a id="more"></a><p>打开vs，创建一个控制台的应用。（CLion用cmakeList链接文件，感觉可以学习一下）这时候会产生很多中间系统文件以及文件夹。</p>]]></content>
      
      
      
        <tags>
            
            <tag> learning cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读：基于RealSense和模型库的人体建模方法</title>
      <link href="/2019/10/18/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8ERealSense%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BA%93%E7%9A%84%E4%BA%BA%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/"/>
      <url>/2019/10/18/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8ERealSense%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BA%93%E7%9A%84%E4%BA%BA%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>这篇论文是张远师兄的毕业论文，主要的思路是通过深度模型预测类别，进而补全模型深度信息，然后通过学习模型参数，最终实现对人体的建模以及测量。</p><a id="more"></a><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>人体建模经历了 1. 基于回归分析的人体建模 2. 基于三维扫描人体建模 3. 基于数据库人体建模。人体建模的精度越来越高，对场景的约束越来越低。</p><p>本文通过基于RGBD信息与模型数据库的人体建模技术，提升人体建模的精度。主要的工作有：</p><ol><li><p>提出一种基于RGB数据的<strong>人体深度类别</strong>预测方法</p></li><li><p>提出一种基于深度类别信息的人体<strong>深度数据补全</strong>与优化方法</p></li><li>提出一种<strong>基于RGBD数据</strong>和<strong>模型参数</strong>的人体建模方法</li></ol><h3 id="基于RGB预测人体深度类别"><a href="#基于RGB预测人体深度类别" class="headerlink" title="基于RGB预测人体深度类别"></a>基于RGB预测人体深度类别</h3><p>基于RGB数据来预测人体的深度信息，本文提出了两阶段的网络结构，用于RGB图像中的人体深度类别预测。该部分主要分为两部分：</p><ul><li>预测图像中的人体分割</li><li><p>预测人体分割对应的深度信息</p><p>针对人体不变的局部特征和多变的全局特征，作者采用多尺度信息融合的方式提取特征，采用跳跃层结构，使用Stacked hourglass network作为基本网络，使用交叉熵作为损失函数，分别应用与人体部件分割以及深度类别的预测上。</p></li></ul><p>针对这两个问题，作者使用Varol et al.(CVPR 2017) 提到的方法对人体进行分割以及预测人体的深度类别信息。该网络深度信息预测结果不好，作者通过扩充网络，将网络修改成二阶段的网络，获取原始数据多尺度的结果之后得到一个较好的恢复结果。</p><p><img src="/images/3D/deep_predict.png" style="zoom:50%;"></p><p>左图第二行是分割信息，有图中间一列是Varol的结果，最后一列是本文结果。</p><h3 id="基于深度类别信息的人体深度数据补全与优化"><a href="#基于深度类别信息的人体深度数据补全与优化" class="headerlink" title="基于深度类别信息的人体深度数据补全与优化"></a>基于深度类别信息的人体深度数据补全与优化</h3><p>对RGB图像进行标定，作者使用realsense内部的标定算法实现标定。接下来对深度数据进行恢复，主要有两种方案，一种是基于滤波器的方法，另一种则是基于图像修复重建的方案。第一种方案难以修复比较大的空洞，第二种方案引入图像修复技术，通常会假设人体深度数据与RGB数据呈现局部线性关系，作者认为由于人的衣服颜色相同，因此不适用于这两种方案。</p><p>作者使用快速行进法（Telea 2004）(FMM)进行空洞的补全，该方法的思路是从已知的像素点和位置的像素点的边界开始计算，逐渐扩展到所有位置的像素点，求解出深度图。作者首先对其RGBD图像之后，对目标图像I上的任意一点深度，采用对周边点的一阶泰勒展开来得到。使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：<br>$$<br>I(p)=I(q)+\nabla I_{p}(q)(p-q)<br>$$<br>使用RGB图像上的梯度来替换深度图对应位置上的梯度，最终得到目标图像上的深度计算公式：<br>$$<br>I(p)=\frac{\sum w(p, q)\left[I(q)+s \cdot \nabla C_{p}(q)(p-q)\right]}{\sum w(p, q)}<br>$$<br>通过快速行进法，使用RGB梯度代替目标图像的梯度的方式，作者命名为GradientFMM，梯度的快速行进法。</p><p>在图像滤波上，作者使用了<strong>引导滤波</strong>的方法，对整张深度图像进行滤波。</p><h3 id="基于RGBD数据和模型参数的人体建模与测量"><a href="#基于RGBD数据和模型参数的人体建模与测量" class="headerlink" title="基于RGBD数据和模型参数的人体建模与测量"></a>基于RGBD数据和模型参数的人体建模与测量</h3><p>作者基于数据库学习出一种人体模型的参数表示方式，能够很好的表示出人体姿势的变化，从而使一个标准的人体形变后和点云数据相互拟合。随后建立一个融合点云数据和人体参数的能量优化模型，得到配准的人体三维模型。</p><p>能量函数（Bouaziz et al 2014）提出一种 能量函数泛式来解决配准问题，他包含数据匹配和参数先验能量。<br>$$<br>E = E_{match} + E_{prior}<br>$$<br>作者研究，对于刚体形变或非刚体形变本质上都是期望最大化算法。EM算法本上是一个非凸优化问题。因此上诉配准问题不一定能收敛到最优解。</p><p>作者使用SCAPE数据集，里头包含1517个男性和1531个女性在不同姿势下的模型，对于每一个人人体模型，都包含12500个顶点和25000个三角面片。对于人体的三维变形，本质上就是对人体网格的三角面片进行变形。 作者通过计算标准模型到每一块面片的参数变换的Q，R，S矩阵，得到整个数据集所有的变换矩阵。因此可以通过不用的姿势，体型参数，可以得到一组Q，R，S然后从标准的模型中，得到目标的模型。</p><p>随后利用能量函数（数据匹配能量以及人体先验能量函数）来无限的拟合人体参数模型和采集到的深度数据之间的距离，得到一个较为真实的人体模型。项目到此结束。</p><h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>做鱼类RGBD数据的三维重建工作，我觉得我的工作可能集中在深度数据的恢复，水下场景的去噪算法，光线折射的还原，空洞的补全这些部分上。对于最后和标准的三维模型去拟合这一部分的工作我可能没办法完成了。</p><p>然后使用到cpp，绘制部分的工作可以用恢复了一部分的深度数据来完成。</p><p>那么近期的工作就十分的清楚了，关注人体的恢复实验，找到一些深度学习的算法，恢复出人体，然后针对鱼进行优化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 3D重建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何读论文</title>
      <link href="/2019/10/16/%E5%A6%82%E4%BD%95%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
      <url>/2019/10/16/%E5%A6%82%E4%BD%95%E8%AF%BB%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<p>对于近期在读论文上效率比较低，读完收获比较小的问题，我从知乎上找到了一些比较好的读论文，做笔记的方法，在这里记录一下。</p><a id="more"></a><h2 id="读论文"><a href="#读论文" class="headerlink" title="读论文"></a>读论文</h2><h3 id="筛选论文，确定是否值得读"><a href="#筛选论文，确定是否值得读" class="headerlink" title="筛选论文，确定是否值得读"></a>筛选论文，确定是否值得读</h3><blockquote><p>feel free to stop reading the article at any point</p></blockquote><ol><li>拿到一篇论文先看<strong>论文题目，keywords</strong>，若你不感兴趣，you stop</li><li>阅读 <strong>abstract</strong>，你可以快速地了解整篇文章。</li><li><p>阅读 <strong>conclusion</strong>，从结论中你可以看出来这篇文章是否和你研究的问题相关。</p></li><li><p>阅读 论文 <strong>图片，表格，标题</strong>，从这些地方你可以花很少的时间，搞清楚作者是如何做这项工作的</p></li></ol><p>到这里，如果你认为这篇文章还可以继续的话，你就可以接着往下进行了。</p><h3 id="精度论文"><a href="#精度论文" class="headerlink" title="精度论文"></a>精度论文</h3><ol><li>阅读 <strong>introduction</strong>，该部分你将读到整个文章的背景，以及作者做这篇文章的主要目的。</li><li>文章的最重要的核心是 <strong>the result and the discussion</strong>，你应该在这上面花主要的时间，如果你觉得差不多了，你就可以停止了。</li><li>但是你如果觉得这篇文章和你的工作的相关性比较大的话，那你就应该dig extremely into the <strong>experience section</strong>。在这一部分你就可以清楚的知道作者是如何做这件事的。</li><li>当你阅读完这篇论文的时候，适当的做些笔记，这些笔记将会在你未来的研究中为你省下很多的时间。</li></ol><h3 id="读论文的一些tips"><a href="#读论文的一些tips" class="headerlink" title="读论文的一些tips"></a>读论文的一些tips</h3><ol><li>参考文献中信息很多，可以花时间找一些参考文献中的文章是否和你当前的问题相关，减少调研的工作量。</li><li>关注近五年的文献。</li><li>关注核心期刊、会议以及一些学科大牛。</li></ol><h3 id="如何记笔记"><a href="#如何记笔记" class="headerlink" title="如何记笔记"></a>如何记笔记</h3><p>记笔记在阅读完论文后，进行简要的记录：</p><ol><li>论文出处</li><li>论文背景</li><li>论文工作</li><li>论文创新</li><li>不足以及研究方向</li><li>自己的想法</li></ol><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p> <a href="https://www.zhihu.com/question/304334959/answer/553782865" target="_blank" rel="noopener">https://www.zhihu.com/question/304334959/answer/553782865</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>resume detail 2019/10/15</title>
      <link href="/2019/10/15/resume-detail/"/>
      <url>/2019/10/15/resume-detail/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 项目总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepMVS:Learning Multi-view Stereopsis</title>
      <link href="/2019/10/14/DeepMVS-Learning-Multi-view-Stereopsis/"/>
      <url>/2019/10/14/DeepMVS-Learning-Multi-view-Stereopsis/</url>
      
        <content type="html"><![CDATA[<p>该篇论文通过一系列的图像，生成这些图像所对应的深度信息。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 3D重建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>State of Art on 3D Reconstruction with RGB-D Cameras 三维重建综述</title>
      <link href="/2019/10/10/State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/"/>
      <url>/2019/10/10/State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras-%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p>这篇论文是发表在欧洲计算机图形学协会2018上的一篇综述文章，下面将精读这篇论文，对其中的重点内容进行记录。</p><a id="more"></a><h3 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h3><p>近些年来，基于结构光（structure light）和TOF（time of flight）方法的深度相机得到了大规模的商用，很多基于RGB-D数据的三维重建算法达到了很好的重建效果。一些具有创新性的方法得到了发展、一些基于RGB-D用于还原3D结构的方法、一些基于RGB-D研究物体其他属性的方法（材料，反射模型）也相继被提出。</p><h4 id="RGB-D-cameras-and-their-characteristics"><a href="#RGB-D-cameras-and-their-characteristics" class="headerlink" title="RGB-D cameras and their characteristics"></a>RGB-D cameras and their characteristics</h4><p>目前，深度距离检测上存在两种方法，一种为三角测距（triangulation），另一种为TOF（time of flight），三角测距可以是被动式（立体视觉），也可以是主动式（结构光）。stereo vision方法计算两张不同角度的照片的差异，而结构光同样是发射红外线，通过分析红外线的扭曲程度三角测量的方式得到深度信息。TOF方法则是通过发射红外光，通过测量接收到反射光的时间来判断物体的深度信息。</p><h4 id="static-Scene-Reconstruction（静态场景重建）"><a href="#static-Scene-Reconstruction（静态场景重建）" class="headerlink" title="static Scene Reconstruction（静态场景重建）"></a>static Scene Reconstruction（静态场景重建）</h4><p> 在线的静态场景重建直接相关的技术有SLAM（simultaneous Localization and Mapping），这个技术主要的关注点在于在未知环境中机器人的导航，主要针对离散稀疏的点云建模。另一方面，静态稠密点云的重建也引起很大的关注。</p><p>在线重建的发展使得一些如kinect Fusion算法，possion surface reconstruction（柏松重建算法）的研究成为一个热门的方向。</p><h4 id="静态场景重建的基础pipeline"><a href="#静态场景重建的基础pipeline" class="headerlink" title="静态场景重建的基础pipeline"></a>静态场景重建的基础pipeline</h4><p>第一步：深度图的预处理，噪声的消除，外部（outlier）信息的移除这些处理方法会首先对RGB-D数据进行处理。</p><p>第二步：从输入的深度图序列中提取出额外的信息，存储起来。</p><p>第三步：相机位姿的估计以及转换矩阵T的估计</p><p>第四步：深度图的融合，将所有计算出的点融合到模型M中。</p><h4 id="深度图的预处理"><a href="#深度图的预处理" class="headerlink" title="深度图的预处理"></a>深度图的预处理</h4><p>深度图中噪声的长生由多种因素影响，常用的方法有使用双边滤波的方式（bilateral filter）来过滤噪声，此外对于一些特定的模型，姿态估计等等方法也会被使用。</p><h4 id="camera-pose-Estimate"><a href="#camera-pose-Estimate" class="headerlink" title="camera pose Estimate"></a>camera pose Estimate</h4><p>对每一张RGB-D图像，计算6-DOF pose T。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>3D重建论文阅读</title>
      <link href="/2019/10/08/3D%E9%87%8D%E5%BB%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2019/10/08/3D%E9%87%8D%E5%BB%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>本篇博客的主要目的是为了记录所读的有关于三维重建的文章，对每篇文章的insight进行简要的总结。</p><a id="more"></a><h3 id="State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras"><a href="#State-of-Art-on-3D-Reconstruction-with-RGB-D-Cameras" class="headerlink" title="State of Art on 3D Reconstruction with RGB-D Cameras"></a>State of Art on 3D Reconstruction with RGB-D Cameras</h3><p>该论文是发表在eurographics 欧洲计算机图形学协会2018上，对当前的RGB-D图像三维重建进行了一个综述整理。</p><p>这是明天的任务。</p><hr><h3 id="Underwater-3-D-Scene-Reconstruction-Using-Kinect-v2-Based-on-Physical-Models-for-Refraction-and-Time-of-Flight-Correction"><a href="#Underwater-3-D-Scene-Reconstruction-Using-Kinect-v2-Based-on-Physical-Models-for-Refraction-and-Time-of-Flight-Correction" class="headerlink" title="Underwater 3-D Scene Reconstruction Using Kinect v2 Based on Physical Models for Refraction and Time of Flight Correction"></a>Underwater 3-D Scene Reconstruction Using Kinect v2 Based on Physical Models for Refraction and Time of Flight Correction</h3><p>该论文被2017年IEEE access收录，论文主要的思路是搭建一个防水装置，将kinect v2放入水中，利用kinect v2来采集RGB图像以及深度图像。然后通过<strong>水下数据采集，相机矫正，噪声过滤，TOF矫正，反射矫正</strong>等步骤恢复深度数据，最后通过kinect Fusion等到三维重建后的效果。</p><ul><li><p>数据获取采集部分采用加入防水外壳的kinect v2。</p></li><li><p>水下滤波部分，在kinect fusion算法中，针对空气中的滤波采用bilinear filter，水下环境复杂，作者采用5 x 5的median中值滤波。</p></li><li>kinect TOF矫正，由于在水下红外线的传播速度与空气中传播的速度不同，因此需要对检测到的深度信息进行矫正。水中传播的距离需要根据水中的红外线传播的速度进行修正。</li><li>水下折射矫正，kinect v2捕捉到的图像、深度信息在水下存在一定程度上的偏移，因此需要进行水下的折射矫正。</li></ul><p>在三维恢复性能比较方面，作者采用物体的三维模型或者激光采集到的三维数据作为ground truth进行对比，得出性能的优劣。</p><p>2019/10/8</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>3D重建综述</title>
      <link href="/2019/09/26/3D%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/"/>
      <url>/2019/09/26/3D%E9%87%8D%E5%BB%BA%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p> 双目重建问题是一个计算机视觉领域一个比较经典的问题。通过两个固定、水平放置的相机，对同一个物体各个角度采集照片，利用成像原理预测物体的深度信息，进行三维场景的重建。</p><a id="more"></a><p><strong>亚像素：</strong>面阵摄像机的成像面以像素为最小单位，像素间距为5.2微米。在宏观上可以认为像素是连续的，但是在微观上，5.2微米之间的部分我们称为亚像素，可以利用软件恢复出来。</p><p><strong>6 DOF：</strong>六自由度，指的是刚体在三维空间中运动的自由度，特别是指刚体可以在前后、上下、左右三个相互垂直的坐标轴上平移，也可以在三个垂直的坐标轴上旋转。</p><p><strong>数据集benchmark：</strong>立体视觉是计算机视觉中最为重要的方向之一，在视差检测方面<strong><a href="http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo" target="_blank" rel="noopener">KITTI</a></strong>、 <strong><a href="http://vision.middlebury.edu/stereo/" target="_blank" rel="noopener">MiddleBury</a></strong> 提供的数据集常被作为Benchmark。</p><h3 id="Image-based-3D-Object-Reconstruction-State-of-the-Art-and-Trends-in-the-Deep-Learning-Era"><a href="#Image-based-3D-Object-Reconstruction-State-of-the-Art-and-Trends-in-the-Deep-Learning-Era" class="headerlink" title="Image-based  3D Object Reconstruction:State-of-the-Art and Trends in the Deep Learning Era"></a>Image-based  3D Object Reconstruction:State-of-the-Art and Trends in the Deep Learning Era</h3><p>3D重建问题研究上的pipeline如下：</p><p>物体【generic objects 】-&gt;数据【single images,multiple RGB】-&gt;研究方法【shape representations，network architecture，training mechanism】</p><p>此外对一些特殊的物体，例如人体、人脸等问题，也有着很多的三维重建的工作。</p><h4 id="问题的定义"><a href="#问题的定义" class="headerlink" title="问题的定义"></a>问题的定义</h4><p>数据输入为一系列的RGB图片，输出为物体的三维重建的结果。三维重建网络的含义在于学习一个预测器，通过这个预测器学习到物体的三维表达，然后与GT之间计算一个最小的重建误差。</p><p>数据的输入形式有<strong>单张图片，多张图片，视频流。</strong>此外可以添加一些额外的预测信息，例如图像的轮廓，分割的结果以及语义标签进行共同预测。</p><h4 id="encoding-state"><a href="#encoding-state" class="headerlink" title="encoding state"></a>encoding state</h4><p>该部分用于提取图片中的深层次的特征将输入I映射到一个潜在的空间中。<br>$$<br>x = h(I)<br>$$<br>对于映射函数h有以下的要求：</p><ul><li>在I空间中相似的两个物体，在x空间中仍然十分的接近。</li><li>在x空间中小小的扰动（perturbation）可以反应到I空间中的扰动。</li><li>映射函数不受相机参数、位姿的影响。</li><li>3D模型和2D图像可以映射到x空间中的同一个点，这样的目的可以消除模型的二义性。</li></ul><p>隐空间有多种类型，离散、连续、层级以及开放（disentangled）的空间。</p><p><strong>离散的隐空间</strong> </p><p>最高由Wu等将一个3D的encoding 网络引入三维重建中用于映射一个3D的体素空间。此后标准的vanilla结构的网络，以及他的变种被引入三维重建中，其他工作如pooling layer，RELU，residual networks（resnet）等也被引入三维重建中。</p><p><strong>连续的隐空间</strong></p><p>一些网络如VAE（variational Autoencoders）或者他的变种，他们的隐空间均设计成连续的。该类型网络将数据映射到高斯分布的一个空间中。利用高斯分布生成一个连续的3D表达。</p><p><strong>层级隐空间（hierarchical latent spaces）</strong> </p><p>一些工作将输入映射到层级空间中，利用特征各个尺度维度的信息，能够很好的完成任务。</p><p><strong>解构的表示空间（disentangled representation）</strong></p><p>影响图像中物体的成像因素有很多，例如相机的位姿、光照条件等等。通过不同的网络的结构，来解析表示这些部分。</p><h4 id="体素解析（volumetric-decoding）"><a href="#体素解析（volumetric-decoding）" class="headerlink" title="体素解析（volumetric decoding）"></a>体素解析（volumetric decoding）</h4><p>体素网格用来表示离散空间中3D物体的3D形状。目标是重建3D体素网格使得它能够与真实的3D物体相近。这样做的一个优点是，很多2D的网络结构可以很轻易的转化成3D的结构。</p><p><strong>二次网格：</strong> 若当前的网格属于物体则为1，否则为0</p><p><strong>概率网格：</strong> 每一个像素表示一个该像素属于物体的概率</p><p><strong>SDF体素到物体表面的距离：</strong> 体素表示该位置到物体表面距离的数值，正数表示内部负数表示外部。</p><p><strong>截断距离：</strong>定义一个截断规则，将SDF距离进行截断。</p><p>上诉四种表示方式中概率网格的表示方式最适合深度学习系统。</p><h4 id="低分辨率的3D体素重建"><a href="#低分辨率的3D体素重建" class="headerlink" title="低分辨率的3D体素重建"></a>低分辨率的3D体素重建</h4><p>在得到隐空间中的特征表达之后，需要通过一个decoder结构，恢复出物体的三维结构。常用的结构为up-convolutional network，与encoder形成一个镜像映射。使用一些3D卷积结构，从一系列图片中得到物体的三维体素表达。</p><p>之后补上：由于对这个领域实在不熟悉，需要先看几篇论文熟悉一下，才能明白作者行文过程所做的分类的含义，以免现在一知半解浪费时间，耽误好文章。</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Stanford cs231A</title>
      <link href="/2019/09/19/Stanford-cs231A/"/>
      <url>/2019/09/19/Stanford-cs231A/</url>
      
        <content type="html"><![CDATA[<p>Stanford cs231A与cs231N是分别从传统方法和深度学习方法介绍计算机视觉的一些技术与应用。这本课程适合作为计算机视觉的入门课程，分别从目标的几何学和语义学上两个角度对图像进行分析。</p><a id="more"></a><h2 id="slide-10-Active-stereo-amp-Volumetric-stereo"><a href="#slide-10-Active-stereo-amp-Volumetric-stereo" class="headerlink" title="slide 10: Active stereo &amp; Volumetric stereo"></a>slide 10: Active stereo &amp; Volumetric stereo</h2><p> <img src="/images/3D/act.png" style="zoom:43%;"></p><p>使用一个光源发射器来代替相机，能够解决两张图片之间的关联问题。</p><p>通常可以使用激光，从上到下扫描这个物体的表面，可以获得一个非常精确的三维结构信息。</p><h3 id="traditional-stereo"><a href="#traditional-stereo" class="headerlink" title="traditional stereo"></a>traditional stereo</h3><p>传统的三维成像的方法：</p><p><img src="/images/3D/tra.png" style="zoom:33%;"></p><p><img src="/images/3D/tra1.png" style="zoom:33%;"></p><p><strong>volumetric stereo</strong></p><p><img src="/images/3D/vol.png" style="zoom:33%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture10_volumetric_stereo.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/26</p><h2 id="silde-9-Detectors-and-descriptors"><a href="#silde-9-Detectors-and-descriptors" class="headerlink" title="silde 9: Detectors and descriptors"></a>silde 9: Detectors and descriptors</h2><p><strong>Detectors:</strong></p><p><strong>边缘:</strong> 图片中深度不连续，表面朝向不连续，反射、光照不连续的位置。</p><p>可以使用传统的canny算法进行边缘的检测，通常图片可以进行平滑或求导处理。</p><p><strong>角点corner/blob光斑识别：</strong>角点通常较为突出，且具有重复性，局部性。可以使用harris角点检测算法来检测。</p><p>光斑可以使用拉普拉斯或高斯来检测：</p><p><img src="/images/3D/blob.png" style="zoom:33%;"></p><p>常用的检测器SIFT：</p><p><img src="/images/3D/sift.png" style="zoom:33%;"></p><p>HOG:</p><p><img src="/images/3D/hog.png" style="zoom:33%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture9_detector_descriptors.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/25</p><h2 id="slide-8-Fitting-and-Matching"><a href="#slide-8-Fitting-and-Matching" class="headerlink" title="slide 8: Fitting and Matching"></a>slide 8: Fitting and Matching</h2><p><strong>问题定义：</strong></p><p>特征点匹配问题存在着许多难以解决的问题：</p><ul><li>nosiy</li><li>outliers（外点）</li><li>missing data</li><li>intra-class variantion</li></ul><h4 id="拟合方法"><a href="#拟合方法" class="headerlink" title="拟合方法"></a>拟合方法</h4><p><strong>least square methods：</strong></p><p><img src="/images/3D/lse.png" style="zoom:33%;"></p><p>最小二乘法用来拟合数据，可以一定程度上对较小的噪声鲁棒，但是对于较大的噪声处理效果不好。</p><p><strong>RANSAC：</strong></p><p>通常样本中包含正确数据(inliers，可以被模型描述的数据)，也包含异常数据(outliers，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。</p><p>RANSAC为Random Sample Consensus的缩写，它是根据一组包含异常数据的样本数据集，计算出数据的数学模型参数，得到有效样本数据的算法。它于1981年由Fischler和Bolles最先提出 。</p><p>RANSAC算法的输入是一组观测数据（往往含有较大的噪声或无效点），一个用于解释观测数据的参数化模型以及一些可信的参数。RANSAC通过反复选择数据中的一组随机子集来达成目标。 被选取的子集被假设为局内点，并用下述方法进行验证：</p><ul><li>随机选择一组样本子集，并假设所选择的子集都为局内点</li><li>寻找一个模型适应于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。</li><li>用1中得到的模型去测试所有的其它数据，若某个点适用于估计的模型，认为它也是局内点inlier</li><li>如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。</li><li>用所有假设的局内点去重新估计模型（譬如使用最小二乘法）</li><li>最后，通过估计局内点与模型的错误率来评估模型。</li><li>上述过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为比现有的模型更好而被选用。</li></ul><p><strong>霍夫变换：</strong></p><p>霍夫变换(Hough Transform)是图像处理中的一种<strong>特征提取技术</strong>，它通过一种投票算法检测具有特定形状的物体。该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。</p><p>起初的方法要求知道物体边界线的解析方程，但不需要有关区域位置的先验知识。这种方法的一个突出优点是分割结果的Robustness , 对数据的不完全或噪声不是非常敏感。</p><p>例如使用霍夫变换来找出图像中的直线（某些特定的形状），将原图中的每个点所在直线的参数空间画出来。当在参数空间中重叠最大的那个参数证明是所有数据都经过该参数的直线，因此可以认为参数所表示的直线为图中的直线。</p><p><img src="/images/3D/hough.png" style="zoom:33%;"></p><p>图中每一个点都将对应到一条参数空间上的曲线，找到参数重叠最大的一个参数，即是大多数数据经过的直线的参数。</p><p>解释链接：<a href="https://zhuanlan.zhihu.com/p/47649796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47649796</a></p><p>使用hough算法变换之后，能够更好的进行图片之间的匹配。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture8_fitting_matching.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/25</p><h2 id="slide-7-Multi-view-geometry"><a href="#slide-7-Multi-view-geometry" class="headerlink" title="slide 7: Multi-view geometry"></a>slide 7: Multi-view geometry</h2><p><strong>问题描述：</strong></p><p>从m张照片中的n个点中，去估计、还原出m个仿射矩阵，以及n个3D的点。</p><p><img src="/images/3D/sfm1.png" style="zoom:37%;"></p><p>三维空间中的点和图像二维上的点存在一个仿射关系：</p><p><img src="/images/3D/fang.png" style="zoom:40%;"></p><p>将三维空间中的点，通过这种映射关系映射到二维平面上。</p><h4 id="factorization-method-因式分解方法"><a href="#factorization-method-因式分解方法" class="headerlink" title="factorization  method(因式分解方法)"></a>factorization  method(因式分解方法)</h4><p><strong>centering the data:</strong></p><p>提出去图像点之间的质心：<br>$$<br>\hat{\mathbf{x}}_{i j}=\mathbf{x}_{i j}-\frac{1}{n} \sum_{k=1}^{n} \mathbf{x}_{i k}<br>$$<br>将仿射变换代人上式，得到三维空间中的质心位置：</p><p><img src="/images/3D/sfm2.png" style="zoom:37%;"></p><p>经过数据的centering之后，每张图片的质心都将会映射到3D点云的质心上，将这个质心视为世界坐标系原点，进一步简化公式：</p><p><img src="/images/3D/sfm3.png" style="zoom:40%;"></p><p>构造一个m x n的矩阵，表示不同视点拍摄的n个点的位置信息，如下：</p><p><img src="/images/3D/sfm4.png" style="zoom:43%;"></p><p>对D矩阵进行SVD分解，选取前三大的奇异值构成一个新的矩阵（当rank=3时能够最小化F模使得其更加接近D矩阵）。</p><p><img src="/images/3D/sfm5.png" style="zoom:40%;"></p><p>利用MS恢复出三维像素点云信息。</p><p>该方法的确定是难以解决视觉上的歧义、结构的相似性问题。</p><h2 id="slide-6-Stereo-立体-Systems-Multi-view-geometry"><a href="#slide-6-Stereo-立体-Systems-Multi-view-geometry" class="headerlink" title="slide 6: Stereo(立体) Systems Multi-view geometry"></a>slide 6: Stereo(立体) Systems Multi-view geometry</h2><p>接上一章，使用多视角的几何方法需要找到两个图像之间的关联点，得出他们的焦点即物体实际的位置，即得到了物体的三维点云表达。</p><p>通常的做法是将图像内物体的位置调整成水平平行的方式，关键点匹配效果好。</p><p><img src="/images/3D/para.png" style="zoom:50%;"></p><p>当特征点在同一个水平位置时更容易计算深度：</p><p><img src="/images/3D/depth.png" style="zoom:40%;"></p><h4 id="method"><a href="#method" class="headerlink" title="method"></a>method</h4><p><strong>window base correlation: </strong></p><p><img src="/images/3D/win1.png" style="zoom:40%;"></p><p>上诉方法对图片光线不敏感，匹配效果不好，改进方案如下：</p><p><img src="/images/3D/win2.png" style="zoom:40%;"></p><p>匹配问题存在很多难点，常常导致匹配错误：</p><p><img src="/images/3D/win3.png" style="zoom:40%;"></p><p>使用下述方法可以提升精度：</p><p><img src="/images/3D/win4.png" style="zoom:40%;"></p><h3 id="SFM-structure-from-motion-problem"><a href="#SFM-structure-from-motion-problem" class="headerlink" title="SFM: structure from motion problem"></a>SFM: structure from motion problem</h3><p>SFM方法通过相机的移动来确定目标和几何关系，是三维重建的一种常见方法，使用RGB图像即可对图像进行恢复。</p><p><img src="/images/3D/sfm.png" style="zoom:40%;"></p><p>SFM算法流程：</p><ul><li>特征点提取(SIFT) 特征点匹配</li><li>基础矩阵估计F（5/8点法）</li><li>本质矩阵估计E</li><li>本质矩阵分解为R和T（SVD分解）</li><li>三维点云计算（三角形法）</li><li>重投影（将三维点云重新投影到平面的方法，用于计算误差）</li><li>重构的细化与优化</li></ul><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture6_stereo_systems.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/24</p><h2 id="slide-5-Epipolar-Geometry-对极几何"><a href="#slide-5-Epipolar-Geometry-对极几何" class="headerlink" title="slide 5: Epipolar Geometry (对极几何)"></a>slide 5: Epipolar Geometry (对极几何)</h2><p>  从单张图片中重建出物体的三维结构，存在着巨大的困难。需要对物体的位置，姿态进行定位，需要从场景中的线、无穷远点判断场景的结构以及相机内参K。此外还需要一些其他先验，例如点、平面等的对应关系。由于视点的空间感很弱，因此画面存在歧义，重建难度大。</p><p><img src="/images/3D/difficult.png" style="zoom:80%;"></p><h4 id="三角测量"><a href="#三角测量" class="headerlink" title="三角测量"></a>三角测量</h4><p>通过两个视点来观察整个场景：</p><p><img src="/images/3D/triangle.png" style="zoom:80%;"></p><p>使用上诉的三角测距方法，其中两个相机的内参K已知：</p><p><img src="/images/3D/minu.png" style="zoom:80%;"></p><p>通过找到两个图片的关联点，最小化距离。</p><h4 id="Multi-stereo-view-geometry-多视角几何"><a href="#Multi-stereo-view-geometry-多视角几何" class="headerlink" title="Multi(stereo)-view geometry (多视角几何)"></a>Multi(stereo)-view geometry (多视角几何)</h4><p><strong>camera geometry：</strong>找到两张图像中的对应点，找出相机的内参矩阵，位置，以及位姿。</p><p><strong>scene geometry：</strong> 从二维图像中恢复出三维场景的结果。</p><p><img src="/images/3D/example.png" style="zoom:80%;"></p><p><strong>给出A图片中的一个点，如何从另一张图片中找出其对应点？</strong></p><p>计算两张图像中，关联点的关联关系：</p><p><img src="/images/3D/epi1.png" style="zoom:70%;"></p><p>对于相机来说，我们通过调节相机参数使得两个视角的K均为单位矩阵简化函数的运算。</p><p><img src="/images/3D/epi2.png" style="zoom:80%;"></p><p>如上图，找到一个向量垂直于对极几何平面，得到上诉等式。</p><p>对上式进行变换：</p><p><img src="/images/3D/epi3.png" style="zoom:67%;"></p><p>进一步对上式进行分析，得到F变量：</p><p><img src="/images/3D/epi4.png" style="zoom:80%;"></p><p>已知F变量可以从一张图片中得到另一张图片的对应点,F变换包含了对极几何的两个视点以及相机内参的信息。此外F还反映了在视点下场景的变换关系：</p><p><img src="/images/3D/epi5.png" style="zoom:80%;"></p><h4 id="F变换的估计"><a href="#F变换的估计" class="headerlink" title="F变换的估计"></a>F变换的估计</h4><p>得到两张图片的F变换矩阵可以得到两张图像的关联点，于是有很多算法为估计F而提出：<strong>the eight-point algorithm</strong>八点法，通过选择图上的8个关联点，联立方程$P^{T}Fp’ = 0$,得到最终的结果。此外可以选择过完备的关联点对，联立方程通过SVD分解最小化误差的方式估计F。以及<strong>正则化八点法</strong>等等。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture5_epipolar_geometry.pdf" target="_blank" rel="noopener">silde</a></p><p>2019/9/23</p><h2 id="slide-4-Single-View-Metrology"><a href="#slide-4-Single-View-Metrology" class="headerlink" title="slide 4: Single View Metrology"></a>slide 4: Single View Metrology</h2><h4 id="2D环境下的变换"><a href="#2D环境下的变换" class="headerlink" title="2D环境下的变换"></a>2D环境下的变换</h4><p><strong>等距变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{ll}{\mathrm{R}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{e}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br>该变换对原始图片进行旋转和平移，不改变物体的相对位置和大小。</p><p><strong>相似变换：</strong><br>$$<br>\left[\begin{array}{l}{x^{\prime}} \ {y^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{S R} &amp; {t} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]=H_{s}\left[\begin{array}{l}{x} \ {y} \ {1}\end{array}\right]<br>$$<br>对原始物体进行旋转、平移、缩放等操作，改变了物体的大小。</p><p><strong>仿射变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {0} &amp; {1}\end{array}\right]\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{a}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br>该变换在一个方向上对图像进行拉伸。</p><p><strong>投影变换：</strong><br>$$<br>\left[\begin{array}{c}{\mathrm{x}^{\prime}} \ {\mathrm{y}^{\prime}} \ {1}\end{array}\right]=\left[\begin{array}{cc}{\mathrm{A}} &amp; {\mathrm{t}} \ {\mathrm{V}} &amp; {\mathrm{b}}\end{array}\right]\left[\begin{array}{c}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]=\mathrm{H}_{\mathrm{p}}\left[\begin{array}{l}{\mathrm{x}} \ {\mathrm{y}} \ {1}\end{array}\right]<br>$$<br><strong>交叉比例：</strong></p><p><img src="/images/3D/ratio.png" style="zoom:40%;"></p><h4 id="灭点和线"><a href="#灭点和线" class="headerlink" title="灭点和线"></a>灭点和线</h4><p>平面中的直线方程可以用矩阵来表示，两条直线叉乘得到垂直于该平面的垂线。</p><p><img src="/images/3D/intersect.png" style="zoom:80%;"></p><p>对于两条平行线，在齐次空间中，他们存在一个焦点（灭点）。该灭点位于垂直于两条线的一个方向向量上。</p><p><img src="/images/3D/ideal.png" style="zoom:80%;"></p><p>空间中的点或线都会在一个无限远的平面上汇聚于一个灭点：</p><p><img src="/images/3D/point.png" style="zoom:80%;"></p><p>图像中两条线相交于一个灭点，直线与夹角间存在下面的计算关系：</p><p><img src="/images/3D/vanish.png" style="zoom:80%;"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture4_single_view_metrology.pdf" target="_blank" rel="noopener">silde</a></p><p>2019/9/23</p><h4 id="从单张图片中估计物体的几何结构"><a href="#从单张图片中估计物体的几何结构" class="headerlink" title="从单张图片中估计物体的几何结构"></a>从单张图片中估计物体的几何结构</h4><p> 根据上一页的ppt可以看出来，当夹脚为0的时候，K变量中有5个自由度，需要通过三个角度来计算相机的内参k：</p><p><img src="/images/3D/inside.png" style="zoom:80%;"></p><h4 id="extension"><a href="#extension" class="headerlink" title="extension"></a>extension</h4><p>计算出k之后，可以根据k去恢复相机坐标系中的场景朝向：</p><p><img src="/images/3D/recover.png" style="zoom:80%;"></p><p><img src="/images/3D/result.png" style="zoom:80%;"></p><h2 id="slide-3-camera-calibertion"><a href="#slide-3-camera-calibertion" class="headerlink" title="slide 3: camera calibertion"></a>slide 3: camera calibertion</h2><p>相机的标定是十分重要的一个步骤，从图片中预测出相机的位姿和焦距等。</p><p>下面是坐标映射方程：<br>$$<br>\mathrm{P}^{\prime}=\mathrm{M} \mathrm{P}_{\mathrm{w}}=\mathrm{K}[\mathrm{R} \quad \mathrm{T}] \mathrm{P}_{\mathrm{w}}<br>$$<br>相机标定的目的是从图像中估计出相机的内参和外参。</p><p><strong>相机标定的目标为：</strong>已知物体在实际环境中的坐标，物体在图像中的坐标，预测映射矩阵M。映射矩阵M由相机的外参，内参矩阵，共有11个未知量。因此需要11个方程，6个correspondences可以解决这个问题。实际场景中，我们可以加入更多的约束，使得结果更加的robots。<br>$$<br>p_{i}=\left[\begin{array}{c}{u_{i}} \ {v_{i}}\end{array}\right]=\left[\begin{array}{c}{\frac{\mathbf{m}_{1} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}} \ {\frac{\mathbf{m}_{2} \mathrm{P}_{\mathrm{i}}}{\mathbf{m}_{3} \mathrm{P}_{\mathrm{i}}}}\end{array}\right]=M P_{i}<br>$$<br>常用标定板进行相机的标定，用相机各个角度多次拍摄同一块标定板，然后将图片以及标定板间距输入程序中，即可算出相机的内参K（焦距，物距，倾斜度等等）。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture3_camera_calibration.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/09/20</p><h2 id="slide-2-camera-models"><a href="#slide-2-camera-models" class="headerlink" title="slide 2: camera models"></a>slide 2: camera models</h2><p>这一课主要对相机的历史，成像原理进行介绍。</p><p>1452年leonardo发现了暗箱开始，一直到1822年第一张相片问世，1908年出现彩色的相机，直到现在相机的性能有了巨大的提升。</p><h4 id="小孔成像-pinhole-camera"><a href="#小孔成像-pinhole-camera" class="headerlink" title="小孔成像 pinhole camera"></a>小孔成像 pinhole camera</h4><p><img src="/images/3D/pinhole.png" style="zoom:80%;"></p><p>小孔成像原理如上，利用光线直线传播性质，通过相似三角形的比例关系得到成像的尺寸位置。成像的比例关系为物距和焦距的比例。</p><p><strong>小孔的大小越大成像越模糊，因为光线存在部分的重叠。当小孔变小之后光线之间分离，得到清晰的成效效果。</strong></p><p>使用凹透镜来实现光线的聚焦，在成像位置实现模糊和聚焦的区域。凹透镜同样使得相机拍摄的场景发生扭曲。</p><h4 id="坐标系统"><a href="#坐标系统" class="headerlink" title="坐标系统"></a>坐标系统</h4><p>将场景转换到坐标系统上，在视网膜上，设置一个坐标原点添加坐标偏移，其中k，l表示一个缩放单位，即焦距长度转换为焦距需要一个变换：</p><p><img src="/images/3D/converting.png" style="zoom:80%;"></p><p>三维到二维的转换如下：<br>$$<br>P=(x, y, z) \rightarrow P^{\prime}=\left(\alpha \frac{x}{z}+c_{x}, \beta \frac{y}{z}+c_{y}\right)<br>$$</p><h4 id="齐次坐标系（homogeneous-coordinates）"><a href="#齐次坐标系（homogeneous-coordinates）" class="headerlink" title="齐次坐标系（homogeneous coordinates）"></a>齐次坐标系（homogeneous coordinates）</h4><p>在传统的笛卡尔坐标系统中，两条平行线是永远不会相交的，但是在透视坐标系中，在无穷远处所有的平行线都会汇聚到一个点，这个点常常被称为灭点。</p><p>齐次坐标系常常用N+1个数字来表示N维坐标。用w表示与透视距离有关的系数，两个系统相互转换的关系如下：</p><p><img src="/images/3D/coordinate-transfer.png" style="zoom:80%;"></p><p>进一步提取出一个相机内部参数矩阵，完成这种转变。</p><p><img src="/images/3D/matrix.png" style="zoom:80%;"></p><p>相机位置发生偏移时，通过调节camera matrix可以得到精确的坐标位置：<br>$$<br>P^{\prime}=\left[\begin{array}{cccc}{\alpha} &amp; {-\alpha \cot \theta} &amp; {c_{x}} &amp; {0} \ {0} &amp; {\frac{\beta}{\sin \theta}} &amp; {c_{y}} &amp; {0} \ {0} &amp; {0} &amp; {1} &amp; {0}\end{array}\right]\left[\begin{array}{c}{x} \ {y} \ {z} \ {1}\end{array}\right]<br>$$<br>将一个眼前的物体拍摄到相机中，然后构建他的世界坐标系坐标，步骤如下：</p><ul><li>首先通过小孔成像的映射关系将实际物体的坐标映射到相机坐标中，需要提前获取的位置信息有物体的实际坐标，相机的内参即焦距、物距、倾斜角度。</li><li>得到物体的相机坐标之后将这个坐标转换到世界坐标系中，即进行旋转、平移变换。</li></ul><p><img src="/images/3D/world.png"></p><p><strong>图像坐标—投射变换—&gt;摄像机坐标—刚体变换—&gt; 世界坐标</strong></p><p>对于整个变换矩阵M，他还有着一些性质，可以直接判断相机是否有歪斜、单元横纵比等。</p><p><img src="/images/3D/theo.png"></p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture2_camera_models.pdf" target="_blank" rel="noopener">Slide</a></p><p>2019/9/20</p><h2 id="slide-1-introduction"><a href="#slide-1-introduction" class="headerlink" title="slide 1: introduction"></a>slide 1: introduction</h2><p>第一节课对计算机视觉两个关键技术进行一个的简要的回顾，这也是这门课之后的大纲内容。</p><h4 id="Geometry"><a href="#Geometry" class="headerlink" title="Geometry"></a>Geometry</h4><p>物体的几何学，需要从2D的图像中抽取出3D的信息，重点内容包含相机的标定，相机参数的估计（姿态和焦距）。单图片视角的重建，多图片视角的重建。对极几何等数学映射，结构光以及volumetric stereo（3D物体的体积估计）。</p><h4 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h4><p>语义分割对图像的理解，包括目标的分类、标定。这里头也面临很多困难，例如视角的不同，尺度的差异，关照的不同，形变，遮挡等等。</p><p><a href="http://web.stanford.edu/class/cs231a/lectures/lecture1_intro.pdf" target="_blank" rel="noopener">slide</a></p><p>2019/9/19</p>]]></content>
      
      
      <categories>
          
          <category> 3D重建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>some tip about resume</title>
      <link href="/2019/09/18/some-tip-about-resume/"/>
      <url>/2019/09/18/some-tip-about-resume/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>linux 环境安装</title>
      <link href="/2019/09/06/linux-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2019/09/06/linux-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>linux 环境下的python3.6安装，以及Linux系统的一些设置。</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>今天进行了linux环境的配置，感觉十分的尽兴，安装过程十分的舒适，一些配置环节比较知道来龙去脉，配置起来很过隐。感触是对linux环境比较熟悉，对这一块的帮助是很大的，其次是也知道了其他人做法其中的道理。</p><h3 id="python3-6的安装"><a href="#python3-6的安装" class="headerlink" title="python3.6的安装"></a>python3.6的安装</h3><p>linux系统默认的python版本有两个，分别是python2.7和python3.5，这次想安装一个比较常用的python3.6。现实条件是我只是一个用户权限的使用者，因此很多sodu操作无法执行。下面基础部分我跳过，重点放在linux环境的配置上。</p><p>去官网下载python3.6.tgz安装包，然后安装的时候因为没有root权限（正常安装python3.6，安装文件会放在/usr/bin,/local/bin这些地方），我在目录下新建了一个python3.6目录用来存放安装文件。安装过程：<a href="https://my.oschina.net/moonrain/blog/739612，其中`./configure`" target="_blank" rel="noopener">https://my.oschina.net/moonrain/blog/739612，其中`./configure`</a> 修改为<code>./configure --prefix=./python36</code>。</p><p>因为默认的python的版本是2.7,这时候需要修改成python3.6，（其实比较明智的做法是用virtualenv创建一个以pyhton3.6版本的环境就可以了。）首先在<code>.bashrc</code>中添加python3.6中bin的路径：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=&apos;./python/bin:$PATH&apos;</span><br></pre></td></tr></table></figure><p>然后创建别名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias python=./python3.6/bin/python3.6</span><br></pre></td></tr></table></figure><p>最后source ./bashrc修改完成。</p><p>然后还差一点，pip指向的是系统的python2.7，pip3指向的是python3.6，我尝试过修改别名，发现不起效果，最后发现原来系统配置的时候都会source 一下系统的bash，将pip修改为原来的。没办法着时候转向virtualenv。</p><h3 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h3><p>用了好久了virtualenv之后，现在才意识到这个环境包的好用之处，相比annaconda简洁多了，推荐指数max。安装过程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install virtualenv</span><br></pre></td></tr></table></figure><p>virtualenv中默认使用的python是当前python指向的python版本，当然也可以自己设置成自己指定python的版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv -p ./python3.6/bin/python3 zhou_env</span><br></pre></td></tr></table></figure><p>激活virtualenv：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source zhou_env/bin/activate</span><br></pre></td></tr></table></figure><p>下面就可以正常的在python3.6的环境中使用pip了，嗑盐了。</p><p>退出虚拟环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure><p>下面贴一个关于linux文件夹先后顺序的链接：</p><p><a href="https://perper.site/2019/04/24/linux配置环境/" target="_blank" rel="noopener">https://perper.site/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/</a></p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Image Super-Resolution Using Very Deep Residual Channel Attention Networks(RCAN)</title>
      <link href="/2019/09/05/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-RCAN/"/>
      <url>/2019/09/05/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-RCAN/</url>
      
        <content type="html"><![CDATA[<p>RCAN这篇文章是2018年发表在ECCV上的一篇poster，作者<a href="http://yulunzhang.com/" target="_blank" rel="noopener">Yunlun Zhang</a>也是该领域的一个大牛。在文中作者对比了各项性能指标，均达到了state of the art的效果。在目前超分辨率领域越做越细的前提下，以提升指标性能为目的的文章越来越不好发表了。下面介绍一下文章的思路、highlight希望能够有点启发。</p><p>arxiv： <a href="https://arxiv.org/pdf/1807.02758.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.02758.pdf</a></p><p>github：<a href="https://github.com/yulunzhang/RCAN" target="_blank" rel="noopener">https://github.com/yulunzhang/RCAN</a></p><a id="more"></a><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在超分辨率领域中，深度的卷积模型十分的重要，但是训练起来十分的困难；低频的输入或特征中有着很丰富的信息，但是这些信息在网络中被同等的对待，阻碍了卷积网络表达特征的能力。</p><p>为了解决上述问题，作者提出一个残差通道注意力网络（RCAN），通过提出<strong>RIR（residual in residual）</strong>模块来构建深度的网络，RIR中包含着许多的RG（residual group），RG中包含着许多的residual block，以及许多长连接跳跃（LSC）。RIR允许低频信息通过多个跳跃直接传播，使得网络集中学习图像中的高频部分。作者提出<strong>CA（channel attention）</strong> 通道注意力机制，通过考虑通道间的相互依赖性，来重新调整通道特征。</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>作者在这部分内容中列举了很多网络，目的是说明深度的网络在超分辨率问题上是有效果的。作者提出的RIR结构，提升网络的深度。对于低频信息的相互依赖性问题，作者提出了CA方法来调整通道的特征。</p><h3 id="Residual-Channel-Attention-Network（RCAN）"><a href="#Residual-Channel-Attention-Network（RCAN）" class="headerlink" title="Residual Channel Attention Network（RCAN）"></a>Residual Channel Attention Network（RCAN）</h3><p>RCAN的网络结构如下图所示：</p><p><img src="/images/SR/rcan-net.png" alt=""></p><p>RCAN网络结构由四部分组成，第一部分是卷积浅层特征提取模块，第二部分是RIR深层特征提取模块，第三部分是上采样模块，第四部分是重建模块，网络最后的卷积层具有三个通道，表示输出的颜色。 </p><p>RCAN网络损失函数采用L1损失：<br>$$<br>L(\Theta)=\frac{1}{N} \sum_{i=1}^{N}\left|H_{R C A N}\left(I_{L R}^{i}\right)-I_{H R}^{i}\right|_{1}<br>$$</p><h3 id="Residual-in-Residual-RIR"><a href="#Residual-in-Residual-RIR" class="headerlink" title="Residual in Residual (RIR)"></a>Residual in Residual (RIR)</h3><p>RIR结构中包含着若干个（10）residual groups（RG）结构以及long skip connection。每一个RG中包含着如果个（20）residual channel attention block（RCAB）模块，内部含有许多短的连接。</p><p>RIR结构通过堆叠残差块，利用skip connection这种结构来克服网络难以训练的问题。</p><h3 id="channel-attention（CA）"><a href="#channel-attention（CA）" class="headerlink" title="channel attention（CA）"></a>channel attention（CA）</h3><p><img src="/images/SR/ca.png" alt=""></p><p>输入是一个 H×W×C（64） 的特征，我们先进行一个空间的全局平均池化得到一个 1×1×C 的通道描述。接着，再经过一个下采样层和一个上采样层得到每一个通道的权重系数，将权重系数和原来的特征相乘即可得到缩放后的新特征，整个过程实际上就是对不同通道的特征重新进行了加权分配。</p><p>其中，下采样和上采样层都利用 1×1 的卷积来实现，下采样层的通道数减少 r 倍，激活函数为 Relu，上采样层的激活函数为 Sigmoid。在论文中，作者采用的通道数 C=64，r = 16。</p><h3 id="Residual-channel-attention-Block（RCAB）"><a href="#Residual-channel-attention-Block（RCAB）" class="headerlink" title="Residual channel attention Block（RCAB）"></a>Residual channel attention Block（RCAB）</h3><p><img src="/images/SR/rcab.png" alt=""></p><p>输入一个特征 input，我们首先进行一个卷积-Relu-卷积操作得到 f，然后 f 再经过一个 CA 模块进行重新缩放得到 x，最后将 x 和 input 相加得到输出特征。其中，卷积操作都采用 3×3 的卷积核。</p><h3 id="实现的细节"><a href="#实现的细节" class="headerlink" title="实现的细节"></a>实现的细节</h3><p>RIR中RG个数：10；RG中RCAB的个数：20，conv的大小：3 x 3，channel：64</p><p>通道下采样的scale：16，C/16 = 4。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超分辨率论文摘要阅读</title>
      <link href="/2019/09/03/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81%E9%98%85%E8%AF%BB/"/>
      <url>/2019/09/03/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>这篇博客的主要目的为了记录阅读的超分辨率论文的摘要部分，了解超分辨率领域的研究前沿进度。</p><a id="more"></a><h3 id="值得注意的网页"><a href="#值得注意的网页" class="headerlink" title="值得注意的网页"></a>值得注意的网页</h3><ol><li>github上关于超分辨率领域的SOAT论文的整理：<a href="https://github.com/YapengTian/Single-Image-Super-Resolution" target="_blank" rel="noopener">https://github.com/YapengTian/Single-Image-Super-Resolution</a></li><li>知乎上关于超分辨率一些大牛的主页： <a href="https://www.zhihu.com/search?type=content&amp;q=超分辨率" target="_blank" rel="noopener">https://www.zhihu.com/search?type=content&amp;q=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87</a></li></ol><h3 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h3><h4 id="Xuaner-Zhang-Qifeng-Chen-Ren-Ng-and-Vladlen-Koltun-Zoom-to-Learn-Learn-to-Zoom-CVPR-2019-Paper"><a href="#Xuaner-Zhang-Qifeng-Chen-Ren-Ng-and-Vladlen-Koltun-Zoom-to-Learn-Learn-to-Zoom-CVPR-2019-Paper" class="headerlink" title="Xuaner Zhang, Qifeng Chen, Ren Ng, and Vladlen Koltun. Zoom to Learn, Learn to Zoom, CVPR 2019. [Paper]"></a>Xuaner Zhang, Qifeng Chen, Ren Ng, and Vladlen Koltun. Zoom to Learn, Learn to Zoom, CVPR 2019. <a href="http://vladlen.info/papers/zoom.pdf" target="_blank" rel="noopener">[Paper]</a></h4><p>作者将超分辨率方法应用在数字变焦中，他认为真实的图片能够比生成的图片更能保留数据的细节，网络的性能也将更好。那些在制作的数据集上训练的模型，通常在实际场景下性能不好，因此本文使用单反去直接制作数据集。高分辨率使用长焦距拍摄，低分辨率使用短焦距拍摄。</p><p>由于使用单反采集的数据高低配置无法完全对齐，因此作者提出了CoBi loss function，完美的解决了这个问题。这就是本文的主要insight。</p><h3 id="Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks"><a href="#Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks" class="headerlink" title="Image Super-Resolution Using Very Deep Residual Channel Attention Networks"></a>Image Super-Resolution Using Very Deep Residual Channel Attention Networks</h3>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 超分辨率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电阻率成像数据分析</title>
      <link href="/2019/08/30/%E7%94%B5%E9%98%BB%E7%8E%87%E6%88%90%E5%83%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2019/08/30/%E7%94%B5%E9%98%BB%E7%8E%87%E6%88%90%E5%83%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><strong>电阻率成像(ERI)</strong> 是一种地球物理技术，用于通过在表面或在一个或多个钻孔中的电极进行的电阻率测量来对底层亚表面结构进行成像。</p><a id="more"></a><h3 id="电阻率数据的采集"><a href="#电阻率数据的采集" class="headerlink" title="电阻率数据的采集"></a>电阻率数据的采集</h3><p>方位电阻率成像测井是在双侧向测井基础上发展起来的，在主电极或屏蔽电极中部沿圆周剖分成12个长方形小电极（见图），每个电极的定向方位成30°辐射，12个方位电极电位彼此相等。</p><p><img src="../images/SR/bettery.png" alt=""></p><p>电流的大小反映了该方向内地层电阻率的变化。测量每个方位电极的供电电流和环状监督电极M 3 （M 4 ）相对铠装电缆钢丝外皮的电位，可计算该方向地层的视电阻率。</p><p> 地层中不同的岩石（泥岩、砂岩、石灰岩）、流体其电阻率是不同的，通过测量<strong>井壁</strong> 各点的电阻率值，然后将电阻率值的相对高低用灰度或色度图表示出来。井壁可以表示成一张黑白/彩色图像。</p><p>颜色映射如下：</p><p><img src="../images/SR/color-map.png" width="400" align="middle"> </p><p> 得到的电阻率成像图像如下：</p><p><img src="../images/SR/162.jpg" alt="162"></p><h3 id="电阻率数据的分析"><a href="#电阻率数据的分析" class="headerlink" title="电阻率数据的分析"></a>电阻率数据的分析</h3><p>微电极测井使用的电极紧贴井壁，电阻数据是测井井周一圈的数据，因此同一个水平面上数据的空间位置十分的接近。数据在空间关系上有一定的相关性。</p><p><img src="../images/SR/fmi1.jpg" alt=""></p><p><img src="../images/SR/fmi.png" alt=""></p><p>上图中的绿线是地层的分层线。对电阻率的分析过程是将电阻率数据传入一个专业软件中，将会自动生成一些简单的分层线，然后采用人工标注的方式，对电阻率数据标注进行完善。最终得到完善的电阻率标注图。</p><p>对超分辨率问题来说，有什么内在的约束？</p><p>得到新数据时，需要明白测量的精度（2.5mm），井口的大小这些数据。</p><p>反演的概念：通过一些观察到的局部信息，反推相关过程发生的原因以及机制。根据结果或信息反推事件发生的过程称为反演，而对事件发生过程的预测则称为正演。例如根据地表上探测到的部分数据，来推测地表以下的地质结构。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并查集，python示例</title>
      <link href="/2019/08/27/%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%8Cpython%E7%A4%BA%E4%BE%8B/"/>
      <url>/2019/08/27/%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%8Cpython%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>并查集是一种数据结构，在合并不相交的集合，用来判断一个图中是否有环这种问题时，具有很高的性能。</p><a id="more"></a><h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><p>并查集的主要操作就是为一个集合中的元素找到一个代表（根节点）。并查集的基本操作是合并两个集合，当拿到两个节点，第一步需要找到各自节点的根，然后选择一个节点作为新的代表，那么就完成了两个集合的合并。</p><h3 id="并查集实现"><a href="#并查集实现" class="headerlink" title="并查集实现"></a>并查集实现</h3><p>并查集可以使用一个数组来表示，数组表示图上的节点，下标表示节点的编号，数组的值表示该下标的父节点是哪一个。例如A[0] = 1 表示节点0的父节点是节点1.</p><p>并查集的实现过程主要分为两步，一步是实现节点的根的查找，另一步是实现两个集合的合并，这里包含了节点的路径压缩。</p><p>下面实现find_root算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">joint = <span class="number">10</span></span><br><span class="line">parent = [<span class="number">-1</span>]*<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_root</span><span class="params">(parent,x)</span>:</span></span><br><span class="line">  x_root = x</span><br><span class="line">  <span class="keyword">while</span> parent[x_root] != <span class="number">-1</span>:</span><br><span class="line">    x_root = parent[x_root]</span><br><span class="line">  <span class="keyword">return</span> x_root</span><br></pre></td></tr></table></figure><p>上面代码说明当x不是根节点时，循环继续往上找，当x时根节点时则返回。</p><p>下面是union的算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union_joint</span><span class="params">(parent,x,y)</span>:</span></span><br><span class="line">  x = find_root(parent,x)</span><br><span class="line">  y = find_root(parent,y)</span><br><span class="line">  <span class="keyword">if</span> x == y:</span><br><span class="line">    print(<span class="string">'circle'</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    parent[x] = y</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>上诉代码如果返回的结果是0的话则说明存在一个环，否则不存在环。</p><p>存在一种极端的情况，即每次union合成的集合它形成了一个很长的链，每次寻找一个节点的根需要遍历一下整个节点，复杂度太高，下面在union中引入路径压缩的思想，即引入另一个数组rank，表明当前节点的位置，当进行union的时候，rank小的数连接到rank大的树底下，当两个rank相同的时候，可以随意连接，但是连接之后作为父节点的rank需要加1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rank = [<span class="number">0</span>]*joint</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(parent,x,y,rank)</span>:</span></span><br><span class="line">  x = find_root(parent,x)</span><br><span class="line">  y = find_root(parent,y)</span><br><span class="line">  <span class="keyword">if</span> x == y:</span><br><span class="line">    print(<span class="string">'circle'</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> rank[x] &gt; rank[y]:</span><br><span class="line">      parent[y] = x</span><br><span class="line">    <span class="keyword">elif</span> rank[x] &lt; rank[y]:</span><br><span class="line">      parent[x] = y</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      parent[x] = y</span><br><span class="line">      rank[y] += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>在判断一个图是否存在环的时候，依次遍历图的所有边，如果union返回的结果是0的话，表明有环。</p><p>下面是一道lettcode的题目，思路就是用并查集来求解：</p><p><a href="https://leetcode.com/problems/friend-circles/" target="_blank" rel="noopener">547.Friend Circles</a></p><p>思路是将朋友的关系用边来表示，最后看parent数组中有多少根节点（等于-1）。</p><p>解法代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findCircleNum</span><span class="params">(self, M)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type M: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        edge = []</span><br><span class="line">        <span class="keyword">if</span> M == [] <span class="keyword">or</span> M[<span class="number">0</span>] == []:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(M)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(M[<span class="number">0</span>])):</span><br><span class="line">                <span class="keyword">if</span> i &lt;= j:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span> M[i][j] == <span class="number">1</span>:</span><br><span class="line">                    edge.append([i,j])</span><br><span class="line">                </span><br><span class="line">        parent = [<span class="number">-1</span>]*len(M)</span><br><span class="line">        rank = [<span class="number">0</span>]*len(M)</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">find_root</span><span class="params">(parent,x)</span>:</span></span><br><span class="line">            x_root = x</span><br><span class="line">            <span class="keyword">while</span> parent[x_root] != <span class="number">-1</span>:</span><br><span class="line">                x_root = parent[x_root]</span><br><span class="line">            <span class="keyword">return</span> x_root</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">union_joint</span><span class="params">(parent,x,y,rank)</span>:</span></span><br><span class="line">            x = find_root(parent,x)</span><br><span class="line">            y = find_root(parent,y)</span><br><span class="line">            <span class="keyword">if</span> x  != y:</span><br><span class="line">                <span class="keyword">if</span> rank[x] &lt; rank[y]:</span><br><span class="line">                    parent[x] = y</span><br><span class="line">                <span class="keyword">elif</span> rank[x] &gt; rank[y]:</span><br><span class="line">                    parent[y] = x</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    parent[x] = y</span><br><span class="line">                    rank[y] += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> edge:</span><br><span class="line">            union_joint(parent,e[<span class="number">0</span>],e[<span class="number">1</span>],rank)</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> parent:</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">-1</span>:</span><br><span class="line">                ans += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>哈希表，python示例</title>
      <link href="/2019/08/25/%E5%93%88%E5%B8%8C%E8%A1%A8-python%E7%A4%BA%E4%BE%8B/"/>
      <url>/2019/08/25/%E5%93%88%E5%B8%8C%E8%A1%A8-python%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>哈希表一直都是一个很重要的数据结构，从上大学开始，一直有听闻，面试题也有相当的涉及，接下来继续扫盲。</p><a id="more"></a><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p>哈希表根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把<strong>关键码值通过哈希函数映射到表中一个位置来访问记录</strong>，以加快查找的速度。</p><p>哈希表的工作原理如下</p><p><img src="/images/hash.png" alt=""></p><p>首先拿到key值，通过哈希函数将key值转化为数组的下标，在插入元素之前，判断该下标位置上是否已经存在元素，若已经存在元素则称为collision（碰撞）。</p><p>当元素发生碰撞时，存在很多方法来处理这种碰撞，常用的方法有<strong>链接法</strong>（java hashmap的实现），每一个index位置连一个链表，用来存储发生碰撞的元素。</p><p><img src="/images/link.png" alt=""></p><p><strong>另一种解决碰撞的方法为开放寻址法</strong>（python中dict的实现）。</p><p>开放寻址法指当前位置发生了碰撞，采用某种方法（线性，二次，双倍散列）对哈希表中其他位置进行访问。如果哈希表全都装满了则需要对哈希表进行扩容。</p><p><img src="/images/openadress.png" alt=""></p><h3 id="python-中dict常用方法"><a href="#python-中dict常用方法" class="headerlink" title="python 中dict常用方法"></a>python 中dict常用方法</h3><p>遍历操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dicts:</span><br><span class="line">    print(i)</span><br><span class="line">    print(dicts[i])</span><br></pre></td></tr></table></figure><p>删除操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dicts.pop(key)</span><br><span class="line">dicts.popitem() <span class="comment">#删除最后一个加入的元素</span></span><br><span class="line"><span class="keyword">del</span> dicts <span class="comment">#直接删除元素</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆排序，python实现</title>
      <link href="/2019/08/22/%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%8Cpython%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/08/22/%E5%A0%86%E6%8E%92%E5%BA%8F%EF%BC%8Cpython%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>堆排序这个名称一直困扰着我，现在扫一下盲。</p><a id="more"></a><h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>首先介绍一下堆的概念：堆是一棵完全二叉树，即指允许最后一层的叶子是不满的，其他层都是满的。叶子节点的出现顺序也是从左边开始向右边累加，不允许中断。父结点必须比子节点要大。</p><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p>堆排序的算法复杂度是O(nlog(n))。由于节点满足完全二叉树，因此可以通过下标的关系找到父节点，子节点。</p><p>例如当前节点为i，父节点：(i - 1) /2。左孩子：2i+1,右孩子：2i+2。因此堆排序的策略如下：</p><h3 id="堆排序步骤"><a href="#堆排序步骤" class="headerlink" title="堆排序步骤"></a>堆排序步骤</h3><ol><li>构造堆结构，从最后一个元素（叶子）的父节点开始，循环到根节点，每次执行heapify函数（三个节点，找最大的放到根位置）。</li><li>位于根节点的元素是最大的，每次将根节点的数拿出来，作为排序的最后一个值。然后将最后一个叶节点放到根的位置。依次循环下去，直到结束。</li></ol><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">9</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span><span class="params">(nums,n,i)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    i 表示要进行调换的根节点位置</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    c1 = <span class="number">2</span>*i + <span class="number">1</span></span><br><span class="line">    c2 = <span class="number">2</span>*i + <span class="number">2</span></span><br><span class="line">    max_index = i</span><br><span class="line">    <span class="keyword">if</span> c1 &lt;= n <span class="keyword">and</span> nums[c1] &gt; nums[i]:</span><br><span class="line">        max_index = c1</span><br><span class="line">    <span class="keyword">if</span> c2 &lt;= n <span class="keyword">and</span> nums[c2] &gt; nums[max_index]:</span><br><span class="line">        max_index = c2</span><br><span class="line">    <span class="keyword">if</span> max_index != i:</span><br><span class="line">        nums[max_index],nums[i] = nums[i],nums[max_index]</span><br><span class="line">        heapify(nums,n,max_index)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_heap</span><span class="params">(nums)</span>:</span></span><br><span class="line">    n = len(nums) - <span class="number">1</span></span><br><span class="line">    last_index = (n - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(last_index+<span class="number">1</span>)[::<span class="number">-1</span>]:</span><br><span class="line">        heapify(nums,n,i)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(nums)</span>:</span></span><br><span class="line">    print(nums)</span><br><span class="line">    build_heap(nums)</span><br><span class="line">    print(nums)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums))[::<span class="number">-1</span>]:</span><br><span class="line">        print(i)</span><br><span class="line">        nums[<span class="number">0</span>],nums[i] = nums[i],nums[<span class="number">0</span>]</span><br><span class="line">        heapify(nums,i<span class="number">-1</span>,<span class="number">0</span>)</span><br><span class="line">    print(nums)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">heap_sort(nums)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法扫盲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习代码的框架</title>
      <link href="/2019/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%A1%86%E6%9E%B6/"/>
      <url>/2019/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%9A%84%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>以pytorch为例，梳理一下深度学习中，数据的读取，神经网络的搭建，NMS，以及各个指标的计算流程。</p><a id="more"></a><h3 id="main-函数，程序入口，以及代码配置"><a href="#main-函数，程序入口，以及代码配置" class="headerlink" title="main 函数，程序入口，以及代码配置"></a>main 函数，程序入口，以及代码配置</h3><p>通常main函数中，通过实现argparse功能包，从函数的外部接受参数的传入，对数据，网络等进行一些基本的配置。argparse的使用方法：<a href="https://docs.python.org/zh-cn/3/library/argparse.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/argparse.html</a></p><p>main函数中一些常用的配置项：</p><ul><li>数据集的格式：coco，csv，pascal voc等等</li><li>数据的路径，包括训练集，测试集的路径等等</li><li>网络的一些细节配置，如深度，backbone 类型</li><li>一些功能的开关设置，如数据的增强等</li><li>训练过程中，一些变量的设置，比如epoch的设置，batch_size的设置等等</li></ul><h3 id="数据读取部分"><a href="#数据读取部分" class="headerlink" title="数据读取部分"></a>数据读取部分</h3><p>数据读取部分的操作包括数据集文件的读取，对图片进行数据的增强，继承dataloader实现数据的批量读取。</p><h4 id="数据文件的读取"><a href="#数据文件的读取" class="headerlink" title="数据文件的读取"></a>数据文件的读取</h4><p>这部分读取任务主要包括读取annotation文件，以及class_id文件，这里以csv格式的数据集文件为例。</p><p>首先实现一个CSVDataset类，继承至torch.utils.data.Dataset类。该类必须实现<code>__len__</code>,<code>__getitem__</code>两个方法。</p><p>在CSVDataset方法的<code>__init__</code>中，进行数据集文件的读取，最终将得到：</p><ul><li>self.classes</li><li>self.image_names : list 包含所有的数据集图片路径</li><li>self.image_data: dict[image_name] = [ {x1,y1,x2,y2,class_name},…]</li></ul><p><code>__getitem__</code>函数中需要实现的方法有根据下标来得到image，以及其对应的标注。最终返回的格式为：</p><p><code>sample = {&#39;img&#39;: img, &#39;annot&#39;: annot}</code>。在返回之前，如果有数据增强部分，还需要进行数据的增强。</p><h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>数据增强的方法有很多种，常用的图片的翻转，切割，resize，归一化等等。数据增强利用一张图片，得到它的许多副本，有效的增大数据集。数据增强能够起效果的一个本质因素在于，卷积操作对位移，视角，图片大小，光照等因素具有不变性。数据增强有线下增强和线上增强两种方式，后一种方式在dataloader提取数据的时候，才对数据进行增强。</p><p>数据增强的方法通常可以写成一个类，通过pytorch中的<code>transforms.Compose([Augumenter(),Resizer()])</code> 来对所有的增强方法进行整合。</p><p><strong>Normalizer</strong></p><p>实现一个Normalizer类，覆盖其中的<code>__call__</code>方法，对每张图片做一个正则化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Normalizer</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.mean = np.array([[[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]]])</span><br><span class="line">        self.std = np.array([[[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]]])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, sample)</span>:</span></span><br><span class="line"></span><br><span class="line">        image, annots = sample[<span class="string">'img'</span>], sample[<span class="string">'annot'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'img'</span>:((image.astype(np.float32)-self.mean)/self.std), <span class="string">'annot'</span>: annots&#125;</span><br></pre></td></tr></table></figure><p><strong>argument</strong></p><p>实现对图片的翻转，需要注意对标注也要进行处理。</p><p><strong>Resizer</strong></p><p>该方法意图将图片的大小限制在一定范围以内。因此在缩放的时候，需要找到最大的缩放比例,同时保证图片能够被32整除。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Convert ndarrays in sample to Tensors."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, sample, min_side=<span class="number">608</span>, max_side=<span class="number">1024</span>)</span>:</span> <span class="comment">#将图片resize到608，1024以下的大小</span></span><br><span class="line">        image, annots = sample[<span class="string">'img'</span>], sample[<span class="string">'annot'</span>]       <span class="comment"># 不能超过这个尺寸（有一边等于这个尺寸）</span></span><br><span class="line"></span><br><span class="line">        rows, cols, cns = image.shape</span><br><span class="line"></span><br><span class="line">        smallest_side = min(rows, cols)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rescale the image so the smallest side is min_side</span></span><br><span class="line">        scale = min_side / smallest_side</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check if the largest side is now greater than max_side, which can happen</span></span><br><span class="line">        <span class="comment"># when images have a large aspect ratio</span></span><br><span class="line">        largest_side = max(rows, cols)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> largest_side * scale &gt; max_side:</span><br><span class="line">            scale = max_side / largest_side</span><br><span class="line"></span><br><span class="line">        <span class="comment"># resize the image with the computed scale</span></span><br><span class="line">        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))</span><br><span class="line">        rows, cols, cns = image.shape</span><br><span class="line"></span><br><span class="line">        pad_w = <span class="number">32</span> - rows%<span class="number">32</span></span><br><span class="line">        pad_h = <span class="number">32</span> - cols%<span class="number">32</span></span><br><span class="line"></span><br><span class="line">        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)</span><br><span class="line">        new_image[:rows, :cols, :] = image.astype(np.float32) <span class="comment"># 两个边长需要保证被32整除，少掉的的那部分使用0来补全</span></span><br><span class="line"></span><br><span class="line">        annots[:, :<span class="number">4</span>] *= scale</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'img'</span>: torch.from_numpy(new_image), <span class="string">'annot'</span>: torch.from_numpy(annots), <span class="string">'scale'</span>: scale&#125;</span><br></pre></td></tr></table></figure><h3 id="数据调用-dataloader"><a href="#数据调用-dataloader" class="headerlink" title="数据调用 dataloader"></a>数据调用 dataloader</h3><p>pytorch通过实现dataloader方法来实现网络训练时，每次iteration的数据的输出。dataloader的逻辑是，每次从dataset中调用<code>__getitem__()</code>获取单个数据，然后组合成batch，在使用<code>collate_fn</code>参数对batch进行一些操作。</p><p><code>torch.utils.data.Dataloader</code><strong>中的参数</strong>：</p><blockquote><p><strong>dataset</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Dataset" target="_blank" rel="noopener"><em>Dataset</em></a>) – dataset from which to load the data.</p><p><strong>batch_size</strong>(<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>, <em>optional</em>) – how many samples per batch to load (default: 1).</p><p><strong>shuffle</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – set to <code>True</code>to have the data reshuffled at every epoch (default: False).</p><p><strong>sampler</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler" target="_blank" rel="noopener"><em>Sampler</em></a>, <em>optional</em>) – defines the strategy to draw samples from the dataset. If specified, <code>shuffle</code>must be False.</p><p><strong>batch_sampler</strong>(<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler" target="_blank" rel="noopener"><em>Sampler</em></a>, <em>optional</em>) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.</p><p><strong>num_workers</strong>(<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>, <em>optional</em>) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)</p><p><strong>collate_fn</strong>(<em>callable<strong>, </strong>optional</em>) – merges a list of samples to form a mini-batch.</p><p><strong>pin_memory</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – If <code>True</code>, the data loader will copy tensors into CUDA pinned memory before returning them.</p><p><strong>drop_last</strong>(<a href="https://docs.python.org/3/library/functions.html#bool" target="_blank" rel="noopener"><em>bool</em></a>, <em>optional</em>) – set to <code>True</code>to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If <code>False</code>and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)</p><p><strong>timeout</strong>(<em>numeric</em>, <em>optional</em>) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)</p><p><strong>worker_init_fn</strong>(<em>callable</em>, <em>optional</em>) – If not None, this will be called on each worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as input, after seeding and before data loading. (default: None)</p></blockquote><p>算法中使用如下参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)</span><br></pre></td></tr></table></figure><p>其中<code>dataset_train</code>为<code>Dataset</code>类的对象，如上实现数据问价读取的部分。<code>num_workers</code>设置了这个类的线程数。<code>batch_sampler</code> 设置了每次从数据集中返回一个batch的sample的策略。<code>collate_fn</code> 将一系列的样本融合成一个小的mini-batch。</p><p><strong>首先是batch_sampler:</strong></p><p>继承至采样器类，需要实现其中的<code>__len__</code>方法，<code>__iter__</code>方法。该参数的作用是将数据集做成许多group组成的一个list。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AspectRatioBasedSampler</span><span class="params">(Sampler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_source, batch_size, drop_last)</span>:</span></span><br><span class="line">        self.data_source = data_source</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">        self.groups = self.group_images()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        random.shuffle(self.groups)</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> self.groups:</span><br><span class="line">            <span class="keyword">yield</span> group</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            <span class="keyword">return</span> len(self.data_source) // self.batch_size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (len(self.data_source) + self.batch_size - <span class="number">1</span>) // self.batch_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">group_images</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># determine the order of the images</span></span><br><span class="line">        order = list(range(len(self.data_source)))</span><br><span class="line">        order.sort(key=<span class="keyword">lambda</span> x: self.data_source.image_aspect_ratio(x))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># divide into groups, one group = one batch</span></span><br><span class="line">        <span class="keyword">return</span> [[order[x % len(order)] <span class="keyword">for</span> x <span class="keyword">in</span> range(i, i + self.batch_size)] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(order), self.batch_size)]</span><br></pre></td></tr></table></figure><p>如上，这个方法将数据分别存入group中，然后组成一个groups的list。通过一个<code>__iter__()</code>方法，迭代的方式将数据输出。每次输出一个batch大小的数据。</p><p><strong>collate_fn参数：</strong></p><p>该参数接受来自batch_sampler的数据，对数据进行进一步的处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collater</span><span class="params">(data)</span>:</span></span><br><span class="line">    imgs = [s[<span class="string">'img'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    annots = [s[<span class="string">'annot'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    scales = [s[<span class="string">'scale'</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]     </span><br><span class="line">    widths = [int(s.shape[<span class="number">0</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    heights = [int(s.shape[<span class="number">1</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    batch_size = len(imgs)</span><br><span class="line">    max_width = np.array(widths).max()</span><br><span class="line">    max_height = np.array(heights).max()</span><br><span class="line">    padded_imgs = torch.zeros(batch_size, max_width, max_height, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">        img = imgs[i]</span><br><span class="line">        padded_imgs[i, :int(img.shape[<span class="number">0</span>]), :int(img.shape[<span class="number">1</span>]), :] = img</span><br><span class="line">    max_num_annots = max(annot.shape[<span class="number">0</span>] <span class="keyword">for</span> annot <span class="keyword">in</span> annots)</span><br><span class="line">    <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line">        annot_padded = torch.ones((len(annots), max_num_annots, <span class="number">5</span>)) * <span class="number">-1</span></span><br><span class="line">        <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> idx, annot <span class="keyword">in</span> enumerate(annots):</span><br><span class="line">                <span class="comment">#print(annot.shape)</span></span><br><span class="line">                <span class="keyword">if</span> annot.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                    annot_padded[idx, :annot.shape[<span class="number">0</span>], :] = annot</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        annot_padded = torch.ones((len(annots), <span class="number">1</span>, <span class="number">5</span>)) * <span class="number">-1</span></span><br><span class="line">    padded_imgs = padded_imgs.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'img'</span>: padded_imgs, <span class="string">'annot'</span>: annot_padded, <span class="string">'scale'</span>: scales&#125;</span><br></pre></td></tr></table></figure><p>上面的操作，将同一个batch中的图片的大小统一同样的大小。annotation的维度也统一到同样大小的维度。然后进行RGB通道的变换之后，放回一个dict。</p><p>上面这些步骤就完成了数据的loader，通过for循环从其中取得元素。</p><h3 id="retinanet网络结构"><a href="#retinanet网络结构" class="headerlink" title="retinanet网络结构"></a>retinanet网络结构</h3><p>下面从数据流动的角度分析一下retinanet的各个结构的组成。</p><p>retinanet的特征提取部分，使用的是resnet，resnet有多种深度的选择，分别有18，34，50，101，152五种深度。常用的网络深度为50，101:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span><span class="params">(num_classes, pretrained=False, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">"""Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(num_classes, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet50'</span>], model_dir=<span class="string">'.'</span>), strict=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>让我们一行一行来看，第一个调用了ResNet()类，创建了一个ResNet对象。ResNet继承至<code>nn.Module</code>,需要实现函数<code>__init__</code>以及<code>forward()</code>两个方法，通常将可学习的参数放到构造函数<code>__init__()</code>中，在<code>forward</code>中实现网络数据的流动，即可实现网络的自动求导机制。</p><p><strong>ResNet</strong></p><p>resnet首次提出残差的思想，传统的卷积网络或者全连接网络在信息传递的时候或多或少会存在信息丢失，损耗等问题，同时还有导致梯度消失或者梯度爆炸，导致很深的网络无法训练。ResNet通过学习残差的方式，在一定程度上解决了<strong>网络退化和梯度消失</strong>的问题。ResNet通过大量叠加残差块的方式，加深网络的深度的同时，保证了网络的梯度不消失。ResNet有着两种不同的残差单元。分别是basicBlock 和 bottleneck结构。深层次网络使用bottleneck结构，每次经过残差结构之前都对数据进行一次降维，大大降低了网络的参数量。</p><p><img src="/images/res_unit.png" alt=""></p><p>bottleneck的结构feature经过第一个1x1的卷积层，将特征的维度压缩，对压缩后的特征进行3x3的卷积，然后经过1x1卷积层，将特征的维度放大到原来的大小。</p><p>bottleneck的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None)</span>:</span></span><br><span class="line">        super(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                               padding=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv3 = nn.Conv2d(planes, planes * <span class="number">4</span>, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(planes * <span class="number">4</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        </span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        </span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>pytorch中常用的搭建网络的函数如下：</p><p>Conv2d卷积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">参数：</span><br><span class="line">in_channels(int) – 输入信号的通道</span><br><span class="line">out_channels(int) – 卷积产生的通道</span><br><span class="line">kerner_size(int <span class="keyword">or</span> tuple) - 卷积核的尺寸</span><br><span class="line">stride(int <span class="keyword">or</span> tuple, optional) - 卷积步长</span><br><span class="line">padding(int <span class="keyword">or</span> tuple, optional) - 输入的每一条边补充<span class="number">0</span>的层数</span><br><span class="line">dilation(int <span class="keyword">or</span> tuple, optional) – 卷积核元素之间的间距</span><br><span class="line">groups(int, optional) – 从输入通道到输出通道的阻塞连接数</span><br><span class="line">bias(bool, optional) - 如果bias=<span class="keyword">True</span>，添加偏置</span><br><span class="line">输入：</span><br><span class="line">input: (N,C_in,H_in,W_in) </span><br><span class="line">输出：</span><br><span class="line">output: (N,C_out,H_out,W_out)</span><br><span class="line">计算公式：Fout = (Fin + <span class="number">2</span>*padding-kernel)/stride + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>batchNorm2d：</p><p>在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。</p><p>在验证时，训练求得的均值/方差将用于标准化验证数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">BatchNorm2d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>)</span><br><span class="line">参数：</span><br><span class="line">num_features： 来自期望输入的特征数，该期望输入的大小为<span class="string">'batch_size x num_features x height x width'</span></span><br><span class="line">eps： 为保证数值稳定性（分母不能趋近或取<span class="number">0</span>）,给分母加上的值。默认为<span class="number">1e-5</span>。</span><br><span class="line">momentum： 动态均值和动态方差所使用的动量。默认为<span class="number">0.1</span>。</span><br><span class="line">affine： 一个布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br><span class="line">输入：（N, C，H, W) - 输出：（N, C, H, W）</span><br><span class="line">值得至于的是，参数num_feature写channel数即可。</span><br></pre></td></tr></table></figure><p>ReLU：修正线性单元函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.ReLU(inplace=<span class="keyword">False</span>)</span><br><span class="line">参数：</span><br><span class="line">inplace：表示是否进行覆盖计算，节省内存</span><br><span class="line">不会引起数据维度的变化</span><br></pre></td></tr></table></figure><p>MaxPool2d 层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size, stride=<span class="keyword">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, return_indices=<span class="keyword">False</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">参数：</span><br><span class="line">kernel_size(int <span class="keyword">or</span> tuple) - max pooling的窗口大小</span><br><span class="line">stride(int <span class="keyword">or</span> tuple, optional) - max pooling的窗口移动的步长。默认值是kernel_size</span><br><span class="line">padding(int <span class="keyword">or</span> tuple, optional) - 输入的每一条边补充<span class="number">0</span>的层数</span><br><span class="line">dilation(int <span class="keyword">or</span> tuple, optional) – 一个控制窗口中元素步幅的参数</span><br><span class="line">return_indices - 如果等于<span class="keyword">True</span>，会返回输出最大值的序号，对于上采样操作会有帮助</span><br><span class="line">ceil_mode - 如果等于<span class="keyword">True</span>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作</span><br><span class="line">输入: (N,C,H_&#123;<span class="keyword">in</span>&#125;,W_in) </span><br><span class="line">输出: (N,C,H_out,W_out)</span><br><span class="line">计算公式：Fout = (Fin + <span class="number">2</span>*padding - kernel)/stride + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>nn.Upsample 上采样操作对channel进行采样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nn.Upsample(size=<span class="keyword">None</span>, scale_factor=<span class="keyword">None</span>, mode=<span class="string">'nearest'</span>, align_corners=<span class="keyword">None</span>)</span><br><span class="line">给定上采样策略mode，上采样的大小：scale_factor</span><br></pre></td></tr></table></figure><p>nn.Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.inplanes, planes * block.expansion,</span><br><span class="line">                          kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="keyword">False</span>),</span><br><span class="line">                nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">            )</span><br></pre></td></tr></table></figure><p><strong>网络结构类继承至<code>nn.Module</code>,需要实现函数<code>__init__</code>以及<code>forward()</code>两个方法，通常在<strong>init</strong>中完成网络层的初始化工作，定义各类的网络层。在forward中完成网络层数据的流动。</strong></p><p>retinanet金字塔模型的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidFeatures</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, C3_size, C4_size, C5_size, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(PyramidFeatures, self).__init__()</span><br><span class="line">        <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">        self.P5_1           = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P5_upsampled   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.P5_2           = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">        self.P4_1           = nn.Conv2d(C4_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P4_upsampled   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.P4_2           = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># "P6 is obtained via a 3x3 stride-2 conv on C5"</span></span><br><span class="line">        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6"</span></span><br><span class="line">        self.P7_1 = nn.ReLU()</span><br><span class="line">        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line"></span><br><span class="line">        C3, C4, C5 = inputs</span><br><span class="line"></span><br><span class="line">        P5_x = self.P5_1(C5)</span><br><span class="line">        P5_upsampled_x = self.P5_upsampled(P5_x)</span><br><span class="line">        P5_x = self.P5_2(P5_x)</span><br><span class="line">        </span><br><span class="line">        P4_x = self.P4_1(C4)</span><br><span class="line">        P4_x = P5_upsampled_x + P4_x</span><br><span class="line">        P4_upsampled_x = self.P4_upsampled(P4_x)</span><br><span class="line">        P4_x = self.P4_2(P4_x)</span><br><span class="line"></span><br><span class="line">        P3_x = self.P3_1(C3)</span><br><span class="line">        P3_x = P3_x + P4_upsampled_x</span><br><span class="line">        P3_x = self.P3_2(P3_x)</span><br><span class="line"></span><br><span class="line">        P6_x = self.P6(C5)</span><br><span class="line"></span><br><span class="line">        P7_x = self.P7_1(P6_x)</span><br><span class="line">        P7_x = self.P7_2(P7_x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [P3_x, P4_x, P5_x, P6_x, P7_x]</span><br></pre></td></tr></table></figure><p>retinanet在金字塔之后，接了一个回归网络以及分类网络，分别对边框位置以及类别进行分类。</p><p><strong>回归网络</strong>简单的接了五个卷积层，保持feature的大小不变，每一个channel的维度最终降为num_anchors x 4，即每一个channel需要回归出num_anchors x 4 个坐标点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RegressionModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_features_in, num_anchors=<span class="number">9</span>, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(RegressionModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors*<span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = 4*num_anchors</span></span><br><span class="line">        out = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out.contiguous().view(out.shape[<span class="number">0</span>], <span class="number">-1</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>上诉最后一行值得注意一下view()函数相当于numpy中的reshape函数，但是要求数据必须在内存中是连续存储的。由于permute函数，改变了数据的分布（浅拷贝）。因此在使用view之前，需要执行contiguous函数使得数据内存连续分布。最终out的shape为[batch_size，w x h ，4]。上诉得到的out最终输入criterion中，计算loss。</p><p><strong>分类模型</strong>的网络结构和回归模型的结构相同，唯一不同的地方在于最终输出的channel的大小。分类模型输出的channel大小为anchor的数量乘以类别（num_anchor x num_classes）。即每一个框都要预测一个类别信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassificationModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_features_in, num_anchors=<span class="number">9</span>, num_classes=<span class="number">80</span>, prior=<span class="number">0.01</span>, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">        super(ClassificationModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_anchors = num_anchors</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors*num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.output_act = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line">        out = self.output_act(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = n_classes + n_anchors</span></span><br><span class="line">        out1 = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        batch_size, width, height, channels = out1.shape</span><br><span class="line"></span><br><span class="line">        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out2.contiguous().view(x.shape[<span class="number">0</span>], <span class="number">-1</span>, self.num_classes)</span><br></pre></td></tr></table></figure><p>最后一行首先将out的维度控制在anchor x num_classes，然后通过一个view将其变为[x.shape[0],W x H x anchor, num_classes]，每一个值表示一个框的类别，然后到criterion中去做预测。</p><p>Torch.cat 用法：<a href="https://blog.csdn.net/qq_39709535/article/details/80803003" target="_blank" rel="noopener">https://blog.csdn.net/qq_39709535/article/details/80803003</a></p><p>接下来需要生成anchor。</p><h3 id="anchor的生成"><a href="#anchor的生成" class="headerlink" title="anchor的生成"></a>anchor的生成</h3><p>anchor的设置上面，对于retinaNet最终的P3，P4，P5，P6，P7均有一个不同的设置。anchor的长宽比和scale的大小分别有三种设置，一共有9种组合。anchor的大小与feature map的大小也是相关的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.ratios = np.array([<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">self.scales = np.array([<span class="number">2</span>**<span class="number">0</span>,<span class="number">2</span>**(<span class="number">1.0</span>/<span class="number">3.0</span>),<span class="number">2</span>**(<span class="number">2.0</span>/<span class="number">3.0</span>)])</span><br></pre></td></tr></table></figure><p>几个常用的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = np.tile(a,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># a = [[1,2,3,1,2,3,1,2,3]</span></span><br><span class="line">       [<span class="number">1.2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure><p>np.repeat</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = np.repeat(a,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># a = [1,1,2,2,3,3]</span></span><br><span class="line"><span class="comment"># 与np.tile的区别是，他是一个元素一个元素的增加后进行排序的。tile则是一起增加。</span></span><br></pre></td></tr></table></figure><p>生成anchor的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Anchors</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None)</span>:</span></span><br><span class="line">        super(Anchors, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> pyramid_levels <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.pyramid_levels = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">        <span class="keyword">if</span> strides <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.strides = [<span class="number">2</span> ** x <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line">        <span class="keyword">if</span> sizes <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.sizes = [<span class="number">2</span> ** (x + <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line">        <span class="keyword">if</span> ratios <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.ratios = np.array([<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">if</span> scales <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.scales = np.array([<span class="number">2</span> ** <span class="number">0</span>, <span class="number">2</span> ** (<span class="number">1.0</span> / <span class="number">3.0</span>), <span class="number">2</span> ** (<span class="number">2.0</span> / <span class="number">3.0</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># image = [2,3,640,832]</span></span><br><span class="line">        image_shape = image.shape[<span class="number">2</span>:]</span><br><span class="line">        image_shape = np.array(image_shape)</span><br><span class="line">        image_shapes = [(image_shape + <span class="number">2</span> ** x - <span class="number">1</span>) // (<span class="number">2</span> ** x) <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute anchors over all pyramid levels</span></span><br><span class="line">        all_anchors = np.zeros((<span class="number">0</span>, <span class="number">4</span>)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, p <span class="keyword">in</span> enumerate(self.pyramid_levels):</span><br><span class="line">            anchors         = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)</span><br><span class="line">            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)</span><br><span class="line">            all_anchors     = np.append(all_anchors, shifted_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        all_anchors = np.expand_dims(all_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(all_anchors.astype(np.float32)).cuda()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_anchors</span><span class="params">(base_size=<span class="number">16</span>, ratios=None, scales=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Generate anchor (reference) windows by enumerating aspect ratios X</span></span><br><span class="line"><span class="string">    scales w.r.t. a reference window.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ratios <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        ratios = np.array([<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scales <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        scales = np.array([<span class="number">2</span> ** <span class="number">0</span>, <span class="number">2</span> ** (<span class="number">1.0</span> / <span class="number">3.0</span>), <span class="number">2</span> ** (<span class="number">2.0</span> / <span class="number">3.0</span>)])</span><br><span class="line"></span><br><span class="line">    num_anchors = len(ratios) * len(scales) <span class="comment"># 9个点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output anchors</span></span><br><span class="line">    anchors = np.zeros((num_anchors, <span class="number">4</span>)) <span class="comment"># 每一个位置上都有9个点，每个点都有四个坐标值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># scale base_size,feature 的大小与scale相乘，得到每一层anchor的大小</span></span><br><span class="line">    anchors[:, <span class="number">2</span>:] = base_size * np.tile(scales, (<span class="number">2</span>, len(ratios))).T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute areas of anchors</span></span><br><span class="line">    areas = anchors[:, <span class="number">2</span>] * anchors[:, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># correct for ratios 构造长宽比</span></span><br><span class="line">    anchors[:, <span class="number">2</span>] = np.sqrt(areas / np.repeat(ratios, len(scales)))</span><br><span class="line">    anchors[:, <span class="number">3</span>] = anchors[:, <span class="number">2</span>] * np.repeat(ratios, len(scales))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># transform from (x_ctr, y_ctr, w, h) -&gt; (x1, y1, x2, y2)</span></span><br><span class="line">    anchors[:, <span class="number">0</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">2</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line">    anchors[:, <span class="number">1</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">3</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shift</span><span class="params">(shape, stride, anchors)</span>:</span></span><br><span class="line">    shift_x = (np.arange(<span class="number">0</span>, shape[<span class="number">1</span>]) + <span class="number">0.5</span>) * stride</span><br><span class="line">    shift_y = (np.arange(<span class="number">0</span>, shape[<span class="number">0</span>]) + <span class="number">0.5</span>) * stride</span><br><span class="line"></span><br><span class="line">    shift_x, shift_y = np.meshgrid(shift_x, shift_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># shifts = [shape[0]*shape[1],4]</span></span><br><span class="line">    shifts = np.vstack((</span><br><span class="line">        shift_x.ravel(), shift_y.ravel(),</span><br><span class="line">        shift_x.ravel(), shift_y.ravel()</span><br><span class="line">    )).transpose()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add A anchors (1, A, 4) to</span></span><br><span class="line">    <span class="comment"># cell K shifts (K, 1, 4) to get</span></span><br><span class="line">    <span class="comment"># shift anchors (K, A, 4)</span></span><br><span class="line">    <span class="comment"># reshape to (K*A, 4) shifted anchors</span></span><br><span class="line">    A = anchors.shape[<span class="number">0</span>]</span><br><span class="line">    K = shifts.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 下面这一行进行了广播赋值，每一行都赋予维度不同的行进行广播，</span></span><br><span class="line">    <span class="comment"># 最终形成[1,A,4] + [k,1,4] = [k,A,4],其中k = shape[0]*shape[1]</span></span><br><span class="line">    <span class="comment"># 也就是说每一个像素位置都将产生9个anchor，每个anchor有四个坐标。 shape的大小则是由计算产生的</span></span><br><span class="line">    <span class="comment"># 每张图片在每个level处的大小在__init__处进行初始化</span></span><br><span class="line">    all_anchors = (anchors.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">                   shifts.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">    all_anchors = all_anchors.reshape((K * A, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> all_anchors</span><br></pre></td></tr></table></figure><p>每一行进行分析就是先设置每一层feature map的level，stride，sizes，ratios，scales的值。然后在forward里面<strong>generate_anchor()，对每一个level的feature生成符合要求的size的anchor</strong>，长宽比组合后共9种anchor。具体的设置可看代码。</p><p>然后进入shift()函数，shift()函数的作用是将anchor散布到每一个位置上。流程大概是，一张图片进来，分别计算出这种图片在每一层level上的size大小，然后根据每一层的anchor的大小，每一个像素点位置取9个anchor，然后返回一个$[shape[0]<em>shape[1]</em>9,4]$ 大小的矩阵。</p><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.meshgrid(x,y)<span class="comment"># 将x中元素与y中元素一一对应起来组合成坐标的形式。</span></span><br><span class="line">np.vstack((x,y))<span class="comment"># 将x，y中元素按照垂直方向叠加</span></span><br><span class="line"><span class="comment">#ravel()</span></span><br><span class="line">a = [[<span class="number">2</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">1</span>]]</span><br><span class="line">a.ravel() <span class="comment"># 将多维数组拉平，不存生新的副本 a = [2,2,1,1]</span></span><br><span class="line">a.flatten() <span class="comment"># 作用与上面函数相同，将返回一个数据副本</span></span><br><span class="line">np.squeeze([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]) <span class="comment"># 对维度为1的数据进行压缩，得到[1,2,3]</span></span><br><span class="line">a = a.reshape(<span class="number">-1</span>) <span class="comment"># 同样能够得到1维的数据</span></span><br><span class="line">a.transpose() <span class="comment"># 不指定参数表示对矩阵进行转置</span></span><br></pre></td></tr></table></figure><p>经过上面的过程，在for循环部分，将5层的anchor全部装入一个list中，anchor生成完毕。</p><p><strong>torch.cat函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">torch.cat((a,b),<span class="number">0</span>) <span class="comment"># 垂直方向 [[1,2,3],[3,4,5]]</span></span><br><span class="line">torch.cat((a,b),<span class="number">1</span>) <span class="comment"># 水平方向 [[1,2,3,4,5,6]]</span></span><br></pre></td></tr></table></figure><h3 id="focalLoss部分"><a href="#focalLoss部分" class="headerlink" title="focalLoss部分"></a>focalLoss部分</h3><p>focalLoss紧接着上面的一部分。现在回过头来梳理一下网络中数据流动到的位置：</p><p>将图片输入ResNet中，通过一个多层金字塔结构，输出5个不同深度feature map（P3，P4，P5，P6，P7），依次将这些层输入到regression网络和classification网络中，每一层都将得到$[batch,w<em>h,4]$的输出和$[batch,w</em>h*anchors,class_nums]$的输出，然后将所有结果cat到一起（水平拼接），即所有level上的anchor 的预测框会被cat到regression_anchor 和classification_anchor中。接下来要做的是判断这些anchor的好坏。根据我们的先验知识，我们产生了一部分anchor的设置，我们将网络产生的anchor和我们预生成的anchor输入focalLoss中，对anchor进行过滤，计算产生的loss。</p><p>下面介绍focalLoss：</p><p>focalLoss部分按batch为单位，每次输入一个batch的数据，然后进行loss的计算。首先计算预设置的anchor与当前图片GT的IoU。（重叠部分 / 相并部分）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_iou</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    area = (b[:, <span class="number">2</span>] - b[:, <span class="number">0</span>]) * (b[:, <span class="number">3</span>] - b[:, <span class="number">1</span>])</span><br><span class="line">    iw = torch.min(torch.unsqueeze(a[:, <span class="number">2</span>], dim=<span class="number">1</span>), b[:, <span class="number">2</span>]) -\</span><br><span class="line">    torch.max(torch.unsqueeze(a[:, <span class="number">0</span>], <span class="number">1</span>), b[:, <span class="number">0</span>])</span><br><span class="line">    ih = torch.min(torch.unsqueeze(a[:, <span class="number">3</span>], dim=<span class="number">1</span>), b[:, <span class="number">3</span>]) -\</span><br><span class="line">    torch.max(torch.unsqueeze(a[:, <span class="number">1</span>], <span class="number">1</span>), b[:, <span class="number">1</span>])</span><br><span class="line">    iw = torch.clamp(iw, min=<span class="number">0</span>)</span><br><span class="line">    ih = torch.clamp(ih, min=<span class="number">0</span>)</span><br><span class="line">    ua = torch.unsqueeze((a[:, <span class="number">2</span>] - a[:, <span class="number">0</span>]) * (a[:, <span class="number">3</span>] - a[:, <span class="number">1</span>]), dim=<span class="number">1</span>) + area - iw * ih</span><br><span class="line">    ua = torch.clamp(ua, min=<span class="number">1e-8</span>)</span><br><span class="line">    intersection = iw * ih</span><br><span class="line">    IoU = intersection / ua</span><br><span class="line">    <span class="keyword">return</span> IoU</span><br></pre></td></tr></table></figure><p>focalLoss主要对每一个anchor进入classification的分类结果，focalLoss的原理如下：</p><p><img src="/images/focal-loss.png" alt=""></p><p>整个网络的loss其实由两部分组成，一部分是分类loss，一部分是回归loss。分类loss即focal loss，回归部分的loss为边框回归的loss。实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment">#def __init__(self):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, classifications, regressions, anchors, annotations)</span>:</span></span><br><span class="line">        alpha = <span class="number">0.25</span></span><br><span class="line">        gamma = <span class="number">2.0</span></span><br><span class="line">        batch_size = classifications.shape[<span class="number">0</span>]</span><br><span class="line">        classification_losses = []</span><br><span class="line">        regression_losses = []</span><br><span class="line"></span><br><span class="line">        anchor = anchors[<span class="number">0</span>, :, :]</span><br><span class="line"></span><br><span class="line">        anchor_widths  = anchor[:, <span class="number">2</span>] - anchor[:, <span class="number">0</span>]</span><br><span class="line">        anchor_heights = anchor[:, <span class="number">3</span>] - anchor[:, <span class="number">1</span>]</span><br><span class="line">        anchor_ctr_x   = anchor[:, <span class="number">0</span>] + <span class="number">0.5</span> * anchor_widths</span><br><span class="line">        anchor_ctr_y   = anchor[:, <span class="number">1</span>] + <span class="number">0.5</span> * anchor_heights</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(batch_size):</span><br><span class="line"></span><br><span class="line">            classification = classifications[j, :, :]</span><br><span class="line">            regression = regressions[j, :, :]</span><br><span class="line"></span><br><span class="line">            bbox_annotation = annotations[j, :, :]</span><br><span class="line">            bbox_annotation = bbox_annotation[bbox_annotation[:, <span class="number">4</span>] != <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> bbox_annotation.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                regression_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line">                classification_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line"></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            classification = torch.clamp(classification, <span class="number">1e-4</span>, <span class="number">1.0</span> - <span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">            IoU = calc_iou(anchors[<span class="number">0</span>, :, :], bbox_annotation[:, :<span class="number">4</span>]) <span class="comment"># num_anchors x num_annotations</span></span><br><span class="line"></span><br><span class="line">            IoU_max, IoU_argmax = torch.max(IoU, dim=<span class="number">1</span>) <span class="comment"># num_anchors x 1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#import pdb</span></span><br><span class="line">            <span class="comment">#pdb.set_trace()</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute the loss for classification</span></span><br><span class="line">            <span class="comment"># target 的维度为类别的个数</span></span><br><span class="line">            targets = torch.ones(classification.shape) * <span class="number">-1</span></span><br><span class="line">            targets = targets.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># lt : less than 如果IoU_max的面积小于0.4，那么就认为没有匹配上</span></span><br><span class="line">            targets[torch.lt(IoU_max, <span class="number">0.4</span>), :] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            positive_indices = torch.ge(IoU_max, <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">            num_positive_anchors = positive_indices.sum()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># IoU_argmax记录着当前的anchor与哪一个GT比较匹配</span></span><br><span class="line">            <span class="comment"># 下面这个赋值语句就是给对应的anchor选择一个GT</span></span><br><span class="line">            <span class="comment"># 第一个参数选择候选的anchor，第二个参数将候选anchor的坐标值都取到</span></span><br><span class="line">            assigned_annotations = bbox_annotation[IoU_argmax, :]</span><br><span class="line"></span><br><span class="line">            targets[positive_indices, :] = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 下面一句表明对每个满足IoU条件的anchor，赋予一个类别。形成一个one hot编码（原先target的维度长度等于类别的个数）</span></span><br><span class="line">            targets[positive_indices, assigned_annotations[positive_indices, <span class="number">4</span>].long()] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            alpha_factor = torch.ones(targets.shape).cuda() * alpha</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            alpha_factor = torch.where(torch.eq(targets, <span class="number">1.</span>), alpha_factor, <span class="number">1.</span> - alpha_factor)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对focal weight进行统一的计算，然后赋值</span></span><br><span class="line">            focal_weight = torch.where(torch.eq(targets, <span class="number">1.</span>), <span class="number">1.</span> - classification, classification)</span><br><span class="line">            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)</span><br><span class="line">            <span class="comment">#      当y=1,即只有targets=1参与计算              当y=0，即只有targets=0参与</span></span><br><span class="line">            bce = -(targets * torch.log(classification) + (<span class="number">1.0</span> - targets) * torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># cls_loss = focal_weight * torch.pow(bce, gamma)</span></span><br><span class="line">            cls_loss = focal_weight * bce</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 注意对target的处理，当IoU在【0.4，0.5】之间时target=-1，不提供loss，其他情况均赋予一个cls_loss</span></span><br><span class="line">            cls_loss = torch.where(torch.ne(targets, <span class="number">-1.0</span>), cls_loss, torch.zeros(cls_loss.shape).cuda())</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算所有的loss在正例中的平均值</span></span><br><span class="line">            classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute the loss for regression</span></span><br><span class="line">            <span class="comment">#只有预测为正例的部分参与边框的回归，下面一部分为回归loss。</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> positive_indices.sum() &gt; <span class="number">0</span>:</span><br><span class="line">                assigned_annotations = assigned_annotations[positive_indices, :]</span><br><span class="line"></span><br><span class="line">                anchor_widths_pi = anchor_widths[positive_indices]</span><br><span class="line">                anchor_heights_pi = anchor_heights[positive_indices]</span><br><span class="line">                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]</span><br><span class="line">                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]</span><br><span class="line"></span><br><span class="line">                gt_widths  = assigned_annotations[:, <span class="number">2</span>] - assigned_annotations[:, <span class="number">0</span>]</span><br><span class="line">                gt_heights = assigned_annotations[:, <span class="number">3</span>] - assigned_annotations[:, <span class="number">1</span>]</span><br><span class="line">                gt_ctr_x   = assigned_annotations[:, <span class="number">0</span>] + <span class="number">0.5</span> * gt_widths</span><br><span class="line">                gt_ctr_y   = assigned_annotations[:, <span class="number">1</span>] + <span class="number">0.5</span> * gt_heights</span><br><span class="line"></span><br><span class="line">                <span class="comment"># clip widths to 1</span></span><br><span class="line">                gt_widths  = torch.clamp(gt_widths, min=<span class="number">1</span>)</span><br><span class="line">                gt_heights = torch.clamp(gt_heights, min=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi</span><br><span class="line">                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi</span><br><span class="line">                targets_dw = torch.log(gt_widths / anchor_widths_pi)</span><br><span class="line">                targets_dh = torch.log(gt_heights / anchor_heights_pi)</span><br><span class="line"></span><br><span class="line">                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))</span><br><span class="line">                targets = targets.t()</span><br><span class="line"></span><br><span class="line">                targets = targets/torch.Tensor([[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]]).cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                negative_indices = <span class="number">1</span> - positive_indices</span><br><span class="line"></span><br><span class="line">                regression_diff = torch.abs(targets - regression[positive_indices, :])</span><br><span class="line"></span><br><span class="line">                regression_loss = torch.where(</span><br><span class="line">                    torch.le(regression_diff, <span class="number">1.0</span> / <span class="number">9.0</span>),</span><br><span class="line">                    <span class="number">0.5</span> * <span class="number">9.0</span> * torch.pow(regression_diff, <span class="number">2</span>),</span><br><span class="line">                    regression_diff - <span class="number">0.5</span> / <span class="number">9.0</span></span><br><span class="line">                )</span><br><span class="line">                regression_losses.append(regression_loss.mean())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                regression_losses.append(torch.tensor(<span class="number">0</span>).float().cuda())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(classification_losses).mean(dim=<span class="number">0</span>, keepdim=<span class="keyword">True</span>), torch.stack(regression_losses).mean(dim=<span class="number">0</span>, keepdim=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>边框回归部分学习一个边框的平移以及缩放关系：</p><p><img src="/images/box-regress.png" alt=""></p><p>最终将得到的分类loss以及regression loss的平均值整合成一个stack，返回下一步。</p><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(a,b) <span class="comment">#水平方向将a与b进行拼接</span></span><br><span class="line">torch.clamp(a,min_val,max_val) <span class="comment"># 将a中的值控制在min_val与max_val之间，小于取min_val，大于取max_val</span></span><br><span class="line">max_val, max_index = torch.max(a,dim = <span class="number">1</span>) <span class="comment"># 返回每一列最大值以及每一列的最大值的索引</span></span><br><span class="line">torch.lt(a,<span class="number">0.4</span>) <span class="comment"># 返回a中值小于0.4的元素的下标，ge均类似</span></span><br><span class="line">torch.where(condition,true_val,false_val) <span class="comment"># 如果满足条件者该位置为true_val,否则为false_val,其中参数的维度均相同（比如都为三维）</span></span><br></pre></td></tr></table></figure><h3 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h3><p>训练部分有几个需要完成的工作：</p><ol><li>初始化网络，设置优化器等等</li><li>将数据从dataloader中取出来</li><li>将数据输入网络中，得到网络的loss值</li><li>对loss进行反向传播，一些操作如learning rate的降低，梯度的裁剪可以在其中完成</li><li>打印出每个batch训练的结果</li><li>当训练次数到达一定的epoch时，对网络进行evaluate</li><li>保存mAP较高的网络</li></ol><p>下面通过代码来解读：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将训练过程迁移到gpu上</span></span><br><span class="line"> use_gpu = <span class="keyword">True</span></span><br><span class="line"><span class="keyword">if</span> use_gpu:</span><br><span class="line">retinanet = retinanet.cuda()</span><br><span class="line">retinanet = torch.nn.DataParallel(retinanet).cuda()</span><br><span class="line">retinanet.training = <span class="keyword">True</span></span><br><span class="line"> <span class="comment"># 设置优化器为adam</span></span><br><span class="line">optimizer = optim.Adam(retinanet.parameters(), lr=<span class="number">1e-5</span>)</span><br><span class="line"> <span class="comment"># ；learning rate的缩减器</span></span><br><span class="line">scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=<span class="number">3</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line">loss_hist = collections.deque(maxlen=<span class="number">500</span>) <span class="comment"># 实现了两端的快速添加删除</span></span><br><span class="line">retinanet.train()</span><br><span class="line">retinanet.module.freeze_bn()</span><br><span class="line">print(<span class="string">'Num training images: &#123;&#125;'</span>.format(len(dataset_train)))</span><br><span class="line"><span class="comment"># 从dataloader中取数据</span></span><br><span class="line"> <span class="keyword">for</span> epoch_num <span class="keyword">in</span> range(parser.epochs):</span><br><span class="line">retinanet.train()</span><br><span class="line">retinanet.module.freeze_bn()</span><br><span class="line">epoch_loss = []</span><br><span class="line"><span class="keyword">for</span> iter_num, data <span class="keyword">in</span> enumerate(dataloader_train):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">       <span class="comment"># 清空梯度，由于pytorch在每次backward的时候，</span></span><br><span class="line">       <span class="comment"># 会进行梯度的累积，这样的做法方便训练RNN模型</span></span><br><span class="line">       <span class="comment"># 但是在训练普通模型的时候，需要将累积的梯度清空。</span></span><br><span class="line">       <span class="comment"># 清空后做backward梯度方向有利于梯度的整体下降</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">       <span class="comment"># 将数据传入网络中，得到loss</span></span><br><span class="line">classification_loss, regression_loss = retinanet([data[<span class="string">'img'</span>].cuda().float(), data[<span class="string">'annot'</span>]])</span><br><span class="line">classification_loss = classification_loss.mean()</span><br><span class="line">regression_loss = regression_loss.mean()</span><br><span class="line">loss = classification_loss + regression_loss</span><br><span class="line"><span class="keyword">if</span> bool(loss == <span class="number">0</span>):</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">       <span class="comment"># 误差的反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">       <span class="comment"># 梯度裁剪函数,第二个参数表明允许最大的梯度为0.1</span></span><br><span class="line">torch.nn.utils.clip_grad_norm_(retinanet.parameters(), <span class="number">0.1</span>)</span><br><span class="line">optimizer.step()</span><br><span class="line">loss_hist.append(float(loss))</span><br><span class="line">epoch_loss.append(float(loss))</span><br><span class="line">print(<span class="string">'Epoch: &#123;&#125; | Iteration: &#123;&#125; | Classification loss: &#123;:1.5f&#125; | Regression loss: &#123;:1.5f&#125; | Running loss: &#123;:1.5f&#125;'</span>.format(epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))</span><br><span class="line"><span class="keyword">del</span> classification_loss</span><br><span class="line"><span class="keyword">del</span> regression_loss</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">print(e)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">if</span> parser.dataset == <span class="string">'coco'</span>:</span><br><span class="line">print(<span class="string">'Evaluating dataset'</span>)</span><br><span class="line">     <span class="comment"># 验证集验证模型的有效性</span></span><br><span class="line">coco_eval.evaluate_coco(dataset_val, retinanet)</span><br><span class="line"><span class="keyword">elif</span> parser.dataset == <span class="string">'csv'</span> <span class="keyword">and</span> parser.csv_val <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">print(<span class="string">'Evaluating dataset'</span>)</span><br><span class="line">mAP = csv_eval.evaluate(dataset_val, retinanet)</span><br><span class="line">scheduler.step(np.mean(epoch_loss))</span><br><span class="line">   <span class="comment"># 保存训练好的模型</span></span><br><span class="line">torch.save(retinanet.module, <span class="string">'&#123;&#125;_retinanet_&#123;&#125;.pt'</span>.format(parser.dataset, epoch_num))</span><br><span class="line"> retinanet.eval()</span><br><span class="line">torch.save(retinanet, <span class="string">'model_final.pt'</span>.format(epoch_num))</span><br></pre></td></tr></table></figure><p>需要注意的点：</p><p>在网络进行训练或验证时，通常先进行一次：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.train()</span><br><span class="line"><span class="comment"># or evaluate</span></span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure><p>这样的目的是模型在train和eval的时候，需要执行的操作是不一样的。例如batchNorm和Dropout在eval的时候是不需要执行的。因此需要提前对网络进行设置。</p><h3 id="eval-验证"><a href="#eval-验证" class="headerlink" title="eval 验证"></a>eval 验证</h3><p>eval作为验证网络的性能，被安排在网络执行的最后，在每个batch结束，或者达到设定的epoch的时候，对网络进行测试。并以此为依据，是否对网络进行存储。</p><p>eval部分常用的指标是mAP，该指标通过计算recall以及precision的值来得到最终的结果。首先得到网络的eval的结果，然后从标注数据中得到anno的结果，进行mAP的计算。</p><p>得到网络的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_detections</span><span class="params">(dataset, retinanet, score_threshold=<span class="number">0.05</span>, max_detections=<span class="number">100</span>, save_path=None)</span>:</span></span><br><span class="line">    <span class="string">""" Get the detections from the retinanet using the generator.</span></span><br><span class="line"><span class="string">    The result is a list of lists such that the size is:</span></span><br><span class="line"><span class="string">        all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        dataset         : The generator used to run images through the retinanet.</span></span><br><span class="line"><span class="string">        retinanet           : The retinanet to run on the images.</span></span><br><span class="line"><span class="string">        score_threshold : The score confidence threshold to use.</span></span><br><span class="line"><span class="string">        max_detections  : The maximum number of detections to use per image.</span></span><br><span class="line"><span class="string">        save_path       : The path to save the images with visualized detections to.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A list of lists containing the detections for each image in the generator.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    all_detections = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(dataset.num_classes())] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(dataset))]</span><br><span class="line">    retinanet.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">            data = dataset[index]</span><br><span class="line">            scale = data[<span class="string">'scale'</span>]</span><br><span class="line">            <span class="comment"># run network</span></span><br><span class="line">            scores, labels, boxes = retinanet(data[<span class="string">'img'</span>].permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).cuda().float().unsqueeze(dim=<span class="number">0</span>))</span><br><span class="line">            scores = scores.cpu().numpy()</span><br><span class="line">            labels = labels.cpu().numpy()</span><br><span class="line">            boxes  = boxes.cpu().numpy()</span><br><span class="line">            <span class="comment"># correct boxes for image scale</span></span><br><span class="line">            boxes /= scale</span><br><span class="line">            <span class="comment"># select indices which have a score above the threshold</span></span><br><span class="line">            indices = np.where(scores &gt; score_threshold)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> indices.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># select those scores</span></span><br><span class="line">                scores = scores[indices]</span><br><span class="line">                <span class="comment"># find the order with which to sort the scores</span></span><br><span class="line">                <span class="comment"># 得到score从大到小的下标，然后选择其中的max_detections那么多个</span></span><br><span class="line">                scores_sort = np.argsort(-scores)[:max_detections]</span><br><span class="line">                <span class="comment"># select detections score从大到小</span></span><br><span class="line">                image_boxes      = boxes[indices[scores_sort], :]</span><br><span class="line">                image_scores     = scores[scores_sort]</span><br><span class="line">                image_labels     = labels[indices[scores_sort]]</span><br><span class="line">                image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=<span class="number">1</span>), np.expand_dims(image_labels, axis=<span class="number">1</span>)], axis=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># copy detections to all_detections</span></span><br><span class="line">                <span class="keyword">for</span> label <span class="keyword">in</span> range(dataset.num_classes()):</span><br><span class="line">                    <span class="comment"># 每一张图片均表示成一个index，对所有的label都遍历一边，每个label保存若干个anchor,没有的话则不保存</span></span><br><span class="line">                    all_detections[index][label] = image_detections[image_detections[:, <span class="number">-1</span>] == label, :<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># copy detections to all_detections</span></span><br><span class="line">                <span class="keyword">for</span> label <span class="keyword">in</span> range(dataset.num_classes()):</span><br><span class="line">                    all_detections[index][label] = np.zeros((<span class="number">0</span>, <span class="number">5</span>))</span><br><span class="line">            print(<span class="string">'&#123;&#125;/&#123;&#125;'</span>.format(index + <span class="number">1</span>, len(dataset)), end=<span class="string">'\r'</span>)</span><br><span class="line">    <span class="keyword">return</span> all_detections</span><br></pre></td></tr></table></figure><p>从标注文件中读取图片的标注信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_annotations</span><span class="params">(generator)</span>:</span></span><br><span class="line">    <span class="string">""" Get the ground truth annotations from the generator.</span></span><br><span class="line"><span class="string">    The result is a list of lists such that the size is:</span></span><br><span class="line"><span class="string">        all_detections[num_images][num_classes] = annotations[num_detections, 5]</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        generator : The generator used to retrieve ground truth annotations.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A list of lists containing the annotations for each image in the generator.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    all_annotations = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(generator.num_classes())] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(generator))]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(generator)):</span><br><span class="line">        <span class="comment"># load the annotations</span></span><br><span class="line">        annotations = generator.load_annotations(i)</span><br><span class="line">        <span class="comment"># copy detections to all_annotations</span></span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">            all_annotations[i][label] = annotations[annotations[:, <span class="number">4</span>] == label, :<span class="number">4</span>].copy()</span><br><span class="line">        print(<span class="string">'&#123;&#125;/&#123;&#125;'</span>.format(i + <span class="number">1</span>, len(generator)), end=<span class="string">'\r'</span>)</span><br><span class="line">    <span class="keyword">return</span> all_annotations</span><br></pre></td></tr></table></figure><p>得到标注数据之后，开始计算mAP指标，mAP指标由recall（判断正确的占所有正确类别的百分比），precision（判断正确的占预测结果中认为正确的百分比）。通过对这两个指数的积分来计算最终的mAP结果。</p><p>recall = TP/(TP + FN) 即真正预测对的，占所有正类的比例</p><p>precision = TP/(TP + FN) 即真正预测对的，占预测结果为正的比例</p><p>TP,FP,TN,FN这几个指标第一个字母表示预测是不是对的，第二个字母表示，预测的内容是什么（正类或者负类）。关于mAP的计算可以看： <a href="https://perper.site/2019/03/22/手撕mAP/" target="_blank" rel="noopener">这里</a></p><p>下面代码计算mAP的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_overlap</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    a: (N, 4) ndarray of float</span></span><br><span class="line"><span class="string">    b: (K, 4) ndarray of float</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    overlaps: (N, K) ndarray of overlap between boxes and query_boxes</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    area = (b[:, <span class="number">2</span>] - b[:, <span class="number">0</span>]) * (b[:, <span class="number">3</span>] - b[:, <span class="number">1</span>])</span><br><span class="line">    iw = np.minimum(np.expand_dims(a[:, <span class="number">2</span>], axis=<span class="number">1</span>), b[:, <span class="number">2</span>]) - np.maximum(np.expand_dims(a[:, <span class="number">0</span>], <span class="number">1</span>), b[:, <span class="number">0</span>])</span><br><span class="line">    ih = np.minimum(np.expand_dims(a[:, <span class="number">3</span>], axis=<span class="number">1</span>), b[:, <span class="number">3</span>]) - np.maximum(np.expand_dims(a[:, <span class="number">1</span>], <span class="number">1</span>), b[:, <span class="number">1</span>])</span><br><span class="line">    iw = np.maximum(iw, <span class="number">0</span>)</span><br><span class="line">    ih = np.maximum(ih, <span class="number">0</span>)</span><br><span class="line">    ua = np.expand_dims((a[:, <span class="number">2</span>] - a[:, <span class="number">0</span>]) * (a[:, <span class="number">3</span>] - a[:, <span class="number">1</span>]), axis=<span class="number">1</span>) + area - iw * ih</span><br><span class="line">    ua = np.maximum(ua, np.finfo(float).eps)</span><br><span class="line">    intersection = iw * ih</span><br><span class="line">    <span class="keyword">return</span> intersection / ua</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_ap</span><span class="params">(recall, precision)</span>:</span></span><br><span class="line">    <span class="string">""" Compute the average precision, given the recall and precision curves.</span></span><br><span class="line"><span class="string">    Code originally from https://github.com/rbgirshick/py-faster-rcnn.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        recall:    The recall curve (list).</span></span><br><span class="line"><span class="string">        precision: The precision curve (list).</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        The average precision as computed in py-faster-rcnn.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># correct AP calculation</span></span><br><span class="line">    <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">    mrec = np.concatenate(([<span class="number">0.</span>], recall, [<span class="number">1.</span>]))</span><br><span class="line">    mpre = np.concatenate(([<span class="number">0.</span>], precision, [<span class="number">0.</span>]))</span><br><span class="line">    <span class="comment"># compute the precision envelope</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line">    <span class="comment"># to calculate area under PR curve, look for points</span></span><br><span class="line">    <span class="comment"># where X axis (recall) changes value</span></span><br><span class="line">    i = np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># and sum (\Delta recall) * prec</span></span><br><span class="line">    ap = np.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    generator,</span></span></span><br><span class="line"><span class="function"><span class="params">    retinanet,</span></span></span><br><span class="line"><span class="function"><span class="params">    iou_threshold=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    score_threshold=<span class="number">0.05</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    max_detections=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    save_path=None</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="string">""" Evaluate a given dataset using a given retinanet.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        generator       : The generator that represents the dataset to evaluate.</span></span><br><span class="line"><span class="string">        retinanet           : The retinanet to evaluate.</span></span><br><span class="line"><span class="string">        iou_threshold   : The threshold used to consider when a detection is positive or negative.</span></span><br><span class="line"><span class="string">        score_threshold : The score confidence threshold to use for detections.</span></span><br><span class="line"><span class="string">        max_detections  : The maximum number of detections to use per image.</span></span><br><span class="line"><span class="string">        save_path       : The path to save images with visualized detections to.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A dict mapping class names to mAP scores.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># gather all detections and annotations</span></span><br><span class="line">    all_detections     = _get_detections(generator, retinanet, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path)</span><br><span class="line">    all_annotations    = _get_annotations(generator)</span><br><span class="line">    average_precisions = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">        false_positives = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        true_positives  = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        scores          = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        num_annotations = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(generator)):</span><br><span class="line">            detections           = all_detections[i][label]</span><br><span class="line">            annotations          = all_annotations[i][label]</span><br><span class="line">            num_annotations     += annotations.shape[<span class="number">0</span>]</span><br><span class="line">            detected_annotations = []</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> detections:</span><br><span class="line">                scores = np.append(scores, d[<span class="number">4</span>])</span><br><span class="line">                <span class="keyword">if</span> annotations.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 表示当前图片没有标注，因此你的标注结果都是错误的</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>) <span class="comment"># 对每个框找出覆盖最多的一个标注,返回标注所在的下标</span></span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br><span class="line">                <span class="keyword">if</span> max_overlap &gt;= iou_threshold <span class="keyword">and</span> assigned_annotation <span class="keyword">not</span> <span class="keyword">in</span> detected_annotations:</span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">0</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">1</span>)</span><br><span class="line">                    detected_annotations.append(assigned_annotation)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># no annotations -&gt; AP for this class is 0 (is this correct?)</span></span><br><span class="line">        <span class="keyword">if</span> num_annotations == <span class="number">0</span>:</span><br><span class="line">            average_precisions[label] = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># sort by score</span></span><br><span class="line">        indices         = np.argsort(-scores)</span><br><span class="line">        false_positives = false_positives[indices]</span><br><span class="line">        true_positives  = true_positives[indices]</span><br><span class="line">        <span class="comment"># compute false positives and true positives</span></span><br><span class="line">        <span class="comment"># 得到一个累加的数组的结果</span></span><br><span class="line">        false_positives = np.cumsum(false_positives)</span><br><span class="line">        true_positives  = np.cumsum(true_positives)</span><br><span class="line">        <span class="comment"># compute recall and precision</span></span><br><span class="line">        recall    = true_positives / num_annotations</span><br><span class="line">        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)</span><br><span class="line">        <span class="comment"># compute average precision</span></span><br><span class="line">        average_precision  = _compute_ap(recall, precision)</span><br><span class="line">        average_precisions[label] = average_precision, num_annotations</span><br><span class="line">    print(<span class="string">'\nmAP:'</span>)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(generator.num_classes()):</span><br><span class="line">        label_name = generator.label_to_name(label)</span><br><span class="line">        print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(label_name, average_precisions[label][<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> average_precisions</span><br></pre></td></tr></table></figure><p>几个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.argsort(scores) <span class="comment"># 根据从小到大返回元素的下标，小的在前</span></span><br><span class="line">np.argmax(overlaps,axis = <span class="number">1</span>) <span class="comment"># 找出每一列的最大值，返回他的下标</span></span><br><span class="line">np.cumsum(nums) <span class="comment"># 返回一个数组，数组中内容从头开始累加到当前位置</span></span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>经过上面几个流程我们大致梳理了一下一个网络的搭建，数据的传递，loss的计算，以及最后的验证的过程。</p><p>总结一下：</p><ol><li>构造dataloader，在这里头完成数据的读取，增强等工作</li><li>完成网络的搭建</li><li>完成网络的训练</li><li>完成验证集的测试工作</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>normalization</title>
      <link href="/2019/07/24/normalization/"/>
      <url>/2019/07/24/normalization/</url>
      
        <content type="html"><![CDATA[<p>Normalization 正则化在wikipedia上的解释是，使得某个东西更加正规和正常化的一个过程。深度学习中，正则化使用十分广泛，通常网络通过修改loss，添加参数的正则项，对参数的分布进行控制；或是在数据预处理阶段，对数据进行正则化操作。正则化操作通常指的是将数据大小范围缩放到[0,1]之间。<br><a id="more"></a></p><h3 id="对数据集的正则化操作"><a href="#对数据集的正则化操作" class="headerlink" title="对数据集的正则化操作"></a>对数据集的正则化操作</h3><blockquote><p>Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as <strong>k-nearest neighbors and artificial neural networks.</strong></p><p>正则化使用场景是数据特征范围差异大，且数据的分布未知。</p></blockquote><p>对于一般的数据集来说，我们不需要对其进行正则化操作。但如果数据集不同特征的数据范围相差过大时，我们需要对其进行正则化操作。因为数据范围大的数据，其波动对精度的影响很大，而数据范围小的特征，数据波动的影响不会有这么大，这样造成了结果精度无法提升。因此需要对数据进行正则化操作。使得数据局限在一个固定的范围内。</p><h3 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h3><p>我们知道，当一个网络与数据过度拟合，这个网络能够很好的反应训练数据，但是它的泛化性能也会大大下降。为了避免这种过拟合现象，做法通常有：</p><ol><li>削减特征的数量（难以确定哪些特征是需要丢弃的）</li><li>减少特征的参数，控制参数的分布，即使用正则项方法</li></ol><p>正则项的目的是为了对参数进行控制，包括：</p><ol><li>实现参数的稀疏化，即某些参数为0。参数的稀疏化能够自动对数据的特征进行筛选，过滤掉一些不需要的特征，同时起到简化模型的作用，避免过拟合。</li><li>最小化正则项能够尽量保持参数较小，参数小的好处在于计算方便，且在网络求导的过程中，产生的导数通常比较小，结果比较稳定。</li></ol><h4 id="范数-（norm）"><a href="#范数-（norm）" class="headerlink" title="范数 （norm）"></a>范数 （norm）</h4><p>在线性代数领域中，范数是一个函数，它为向量空间中的每个向量分配严格正长度或大小 。</p><p><strong>L0 范数：指向量空间中非0向量的个数</strong></p><p><strong>无穷范数：指所有向量中欧式距离的最大值作为无穷范数</strong></p><h4 id="参数正则项"><a href="#参数正则项" class="headerlink" title="参数正则项"></a>参数正则项</h4><p><strong>L0正则项：模型参数中，不为0的参数的个数</strong></p><p>​    L0正则化通过最小化不为0的参数的个数，以达到参数稀疏化的目的，使得模型自动选择特征。在使用时，由于L0正则项是一个NP hard问题，L1是L0的最优凸优化，因此通常用L1来代替L0。</p><p><strong>L1正则项：各个模型参数的绝对值之和</strong></p><p>​    最小化L1正则项能够将模型的参数变小，沿着0的方向靠近，降低网络的模型复杂度。添加L1正则项后方程如下：<br>$$<br>L = L_0 + \frac{\lambda}{n}\sum_{w}|W|<br>$$<br><strong>L2 正则项：各个参数的平方和再开根号。</strong></p><p>​    最小化L2正则项可以使得参数变小接近于0，当参数不会变成0（可以看下面的图来理解），因此L2将选择更多的特征，权重比较小，避免过拟合。方程如下：<br>$$<br>C=C_{0}+\frac{\lambda}{2 n} \sum_{w} w^{2}<br>$$<br><strong>lasso回归与岭参数</strong></p><p>L1正则化又称为losso回归，将L1正则项作为loss的惩罚函数。L2正则项又称为岭参数。同样可以将L2正则项作为公式的约束项。可以画图如下,其中等值线为原始的Loss，L1为正方形（绝对值），L2为一个圈（平方根）。可以看出来，图中的交点满足条件的点，因此可以看出L1正则项可以得到更多的稀疏解。</p><p><img src="../images/SR/L1L2_7_24.png" alt=""></p><h3 id="标准化操作（standardization）"><a href="#标准化操作（standardization）" class="headerlink" title="标准化操作（standardization）"></a>标准化操作（standardization）</h3><blockquote><p>Standardization is useful when your data has varying scales and the algorithm you are using does make assumptions about your data having a Gaussian distribution, such as <strong>linear regression, logistic regression and linear discriminant analysis.</strong></p><p>标准化使用场景是数据特征范围差异大，假设数据服从高斯分布。</p></blockquote><p>将数据标准化是指将数据rescale，使得数据的 $mean = 0,\sigma = 1$。数据的标准化操作如下：<br>$$<br>z=\frac{x-\mu}{\sigma}<br>$$<br>标准化操作对于很多机器学习的算法，在网络训练上有着很重要的作用。例如对于梯度下降法来说，处于中心（mean = 0）范围的数据，中心权重的参数更新将会加快。对于一些loss而言（MSE），利用欧式距离作为网络优化的目标，因此标准化操作是很重要的。</p><h3 id="Batch-Normalization（批量标准化）"><a href="#Batch-Normalization（批量标准化）" class="headerlink" title="Batch Normalization（批量标准化）"></a>Batch Normalization（批量标准化）</h3><p>其步骤如下，对一个batch中的数据进行标准化后，并学习$r,\beta$ 两个参数，对得到标准化后的值进行一个偏移，得到最终的结果：</p><p><img src="../images/SR/BN_7_24.png" alt=""></p><p><u>当进来一个batch的时候，具体的做法是，在数据输入到下一层神经元激活函数之前，计算整个batch的mean，variance，偏移后最终得到下一层的输入。</u></p><p><strong>为什么要加入Batch Normalization层？</strong></p><p>由于深层网络的输入，经过多层神经网络层的作用后发生偏移（ReLu激活函数输出均大于0，因此整体输出的mean将往大于0的方向偏移）。导致网络训练难以收敛，落入梯度饱和区导致梯度消失等问题。BN层重新通过将数据拉回N(0,1)的正态分布上，是的输入值落入激活函数梯度敏感的区域，避免梯度消失，加速网络的训练。（输入变小也有助于降低模型计算复杂度）。</p><p>但是仅仅做到这一步还不行，由于我们引入非线性的激活函数，使得网络能够学到一些非线性的性质。我们通过BN将输出拉回到N(0,1)分布上，削弱了激活函数的非线性部分的作用。因此BN通过学习两个参数$\gamma, \beta$ 来对输出做一个scale和shit操作。恢复学习到的非线性部分知识。最终得到的$y_i$ 在正态分布和非线性性质中做了一个trade off。</p><p><strong>Batch Normalization的作用</strong></p><ol><li>batch normalization极大的提升了网络训练的速度</li><li>每次BN都将网络的输出控制在一个范围内，近似于符合正态分布，能够起到正则项的作用</li><li>对参数的初始化要求降低，调参变得简单</li></ol><h4 id="layer-normalization"><a href="#layer-normalization" class="headerlink" title="layer normalization"></a>layer normalization</h4><p><img src="../images/SR/layer_normal_7_24.png" alt=""></p><p>layer normalization 正则化的方向是沿着feature的方向对CHW归一化，batch normalization 正则化的方向是以sample为单位，对NHW做归一化。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>image upsample-downsample method</title>
      <link href="/2019/07/23/image-upsample-downsample-method/"/>
      <url>/2019/07/23/image-upsample-downsample-method/</url>
      
        <content type="html"><![CDATA[<p>图像尺度的放大，缩小是图形学中一个十分常见的问题。然而这个过程并不是无损的，缩放的过程是一个非线性的过程，因此存在许多算法在效率，平滑度，清晰度和速度上进行一些权衡（trade-off）。在图形的缩放过程中，存在插值，采样等一些关键的步骤，下面对一些在图像缩放过程中使用的算法进行简要的介绍，这些算法均有其优缺点。</p><p>参考资料：<a href="https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic" target="_blank" rel="noopener">https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic</a></p><a id="more"></a><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>在处理图片的缩放问题时，需要解决的问题是：</p><ul><li>在放大过程中，新增的像素的颜色如何确定。</li><li>在缩小过程中，哪些像素需要被保留。</li></ul><h3 id="图形缩放"><a href="#图形缩放" class="headerlink" title="图形缩放"></a>图形缩放</h3><p>下面用一个1D的问题举例,如下图，y轴表示灰度图的灰度值:</p><p><img src="../images/SR/img_1d.png" alt=""></p><p>现在对这个图形进行进行放大，有两种做法：</p><ol><li>使用<strong>最近邻方法</strong>，用左边的像素填补这个位置的像素</li></ol><p><img src="../images/SR/upsample_7_23.png" alt=""></p><ol start="2"><li>使用线性插值的方法，利用前后位置的像素值生成该位置上的像素</li></ol><p><img src="../images/SR/interpolation_7_23.png" alt=""></p><p><strong>将这个问题一般化，我们通过引入卷积来完成这个操作。</strong>例如对于最近邻方法，可以使用[1,1,0]卷积核，对于插值法，可以使用[0.5,1,0.5]卷积核。</p><hr><p>与上述思路相同，我们将卷积核推广到2D的情况，同时在x和y方向上做卷积，各个像素的取值由卷积权重决定。</p><h4 id="Nearest-Neighbor-Resampling（最近邻采样）"><a href="#Nearest-Neighbor-Resampling（最近邻采样）" class="headerlink" title="Nearest Neighbor Resampling（最近邻采样）"></a>Nearest Neighbor Resampling（最近邻采样）</h4><p><img src="../images/SR/nnre.png" alt=""></p><p>用这种方式得到的图像块状比较明显，但是这种方法执行效率最快。</p><h4 id="Bilinear-Resampling-B-spline-order-1-（双线性插值）"><a href="#Bilinear-Resampling-B-spline-order-1-（双线性插值）" class="headerlink" title="Bilinear Resampling (B-spline order 1) （双线性插值）"></a>Bilinear Resampling (B-spline order 1) （双线性插值）</h4><p><img src="../images/SR/bilinear_7_23.png" alt=""></p><p>上诉公式是沿着x方向的线性差值的值，对于y方向同样用这种方式进行插值。</p><h4 id="Bicubic-Resampling-（双三次插值）"><a href="#Bicubic-Resampling-（双三次插值）" class="headerlink" title="Bicubic Resampling （双三次插值）"></a>Bicubic Resampling （双三次插值）</h4><p><img src="../images/SR/bicubic_7_23.png" alt=""></p><p>该方法需要选取的最近的16个像素点作为计算目标图像B(X,Y)处像素值的参数。每个位置的权重与像素值，以及像素的变化率有关。当a取-0.5是，bicubic函数有以下的形状：</p><p><img src="../images/SR/bicubic_shape_7_23.png" alt=""></p><p>该算法在各中图像的缩放过程中使用的最多。其中心点像素计算公式如下：<br>$$<br>\sum_{i=0}^{3} \sum_{j=0}^{3} a_{i j} x^{i} y^{j}<br>$$<br>其中参数a需要根据临近的四个点的像素值，偏导数等等来计算。具体的计算过程可以看<a href="https://en.wikipedia.org/wiki/Bicubic_interpolation" target="_blank" rel="noopener">wiki上的解释</a>。</p><hr><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>在处理具体问题时，我们知道一张图片在显示屏上是以点阵的方式排列的。当我们要放大，或者缩小时，例如用双三次插值时，对于每个像素点，无论是放大还是缩小，我们总能找到最邻近的16个位置，可以很方便的对图片进行缩放。此外，用卷积的方式进行求解，能够并行对图片进行处理，提高图片的处理效率。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Deep Learning for image Super-resolution: a Survey</title>
      <link href="/2019/07/23/Deep-Learning-for-image-Super-resolution-a-Survey/"/>
      <url>/2019/07/23/Deep-Learning-for-image-Super-resolution-a-Survey/</url>
      
        <content type="html"><![CDATA[<p>本篇论文是2019年2月份，发表在arxiv上的篇关于超分辨率的一篇综述。这篇文章系统且全面的介绍了一些基于深度学习的超分辨率方法。其中包括：</p><ul><li>超分辨率问题的定义 (problem setting)</li><li>benchmark datasets</li><li>性能评价指标 (performance metrics)</li><li>基于深度学习的超分辨率方法</li><li>特定领域的超分辨率应用 (domain-specific application)</li></ul><p>此外作者对比每个超分辨率方法，指出了网络的优点以及局限。最后对该领域的一些开放性问题(open issuse) 以及挑战提出了未来研究的方向。</p><a id="more"></a><h3 id="超分辨率问题的定义（problem-setting）"><a href="#超分辨率问题的定义（problem-setting）" class="headerlink" title="超分辨率问题的定义（problem setting）"></a>超分辨率问题的定义（problem setting）</h3><p>图像的超分辨率要解决的问题是：从一张低分辨率（LR）的图像中，恢复出一张高分辨率（HR）的图像。</p><p>通常来说，我们通过下面的方式得到低分辨率的图像：<br>$$<br>I_{x}=\mathcal{D}\left(I_{y} ; \delta\right)<br>$$<br>$I_x$ 表示低分辨率图像，$I_y$ 表示高分辨率图像，$D()$ 表示下采样的映射函数，$\delta$ 表示映射函数的参数。图片清晰度不够的原因可能有很多种，例如聚焦，图片压缩，传感器噪声等问题。一些学者提出了下面的模型来模拟这种失真的映射。<br>$$<br>\mathcal{D}\left(I_{y} ; \delta\right)=\left(I_{y} \otimes \kappa\right) \downarrow_{s}+n_{\zeta},{\kappa, s, \zeta} \subset \delta<br>$$<br>$I_{y} \otimes \kappa$ 表示HR图片与模糊核（blur kernel）k的卷积操作，下箭头表示下采样，$n_{\zeta}$ 表示方差为$\zeta$ 的白高斯噪声。</p><hr><p>目前大多数的数据库，产生LR图像的方法是直接对SR图像做一些下采样(双三次插值算法(bicubic interpolation))，同时对图片作抗锯齿（anti aliasing），去模糊等操作(blur) 。关于下采样，上采样的一些方法可以看 <a href="http://eeweb.poly.edu/~yao/EL5123/lecture8_sampling.pdf" target="_blank" rel="noopener">这个课件</a>，或<a href="https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic" target="_blank" rel="noopener">这里</a>。</p><p>关于超分问题，我们更关注的是如何由低分辨率的图片得到高分辨率的图片，即：<br>$$<br>\hat{I}_{y}=\mathcal{F}\left(I_{x} ; \theta\right)<br>$$<br>其中$\mathcal{F}()$ 为超分模型，由低分辨率图片生成高分辨率的图片。</p><p>对于一个典型的超分辨率问题来说，我们需要从一个LR图像中恢复出它的HR版本。模型的目标是最小化我们恢复出来的图片与原始HR图片的差距，<strong>目标方程</strong>如下：<br>$$<br>\hat{\theta}=\underset{\theta}{\arg \min } \mathcal{L}\left(\hat{I}_{y}, I_{y}\right)+\lambda \Phi(\theta)<br>$$<br>其中$\mathcal{L}\left(\hat{I}_{y}, I_{y}\right)$ 为生成的HR图像与原始图像的Loss，公式尾项是一个<strong>正则项</strong>。目前使用较多的loss为像素级别的MSE loss，同时一些组合型的loss也经常被使用。引入正则项的目的是控制参数的变化，使得网络更容易收敛。<a href="https://www.jianshu.com/p/70487abdf96b" target="_blank" rel="noopener">正则项可以看这里。</a></p><hr><h3 id="Benchmark-dataset"><a href="#Benchmark-dataset" class="headerlink" title="Benchmark dataset"></a>Benchmark dataset</h3><p>在一个典型的超分辨率的文章中，通常需要对一些公开数据集上进行试验，在这些公开数据集上的效果指标作为这个算法性能的评价标准。主要使用的数据集有：</p><p><img src="/images/SR/dataset_7_25.png" alt=""></p><hr><h3 id="Image-Quality-Assessment"><a href="#Image-Quality-Assessment" class="headerlink" title="Image Quality Assessment"></a>Image Quality Assessment</h3><p>图片质量的评价是一个与感知，视觉相关的问题。通常存在客观和主观的两类方法。其中客观方法根据指标计算模型直接计算得出，如MSE。主观方法则与人们的感知更为接近。下面介绍一下常用的评价方法。</p><h4 id="Peak-Signal-to-Noise-Ratio-峰值信噪比"><a href="#Peak-Signal-to-Noise-Ratio-峰值信噪比" class="headerlink" title="Peak Signal-to-Noise Ratio(峰值信噪比)"></a>Peak Signal-to-Noise Ratio(峰值信噪比)</h4><p>峰值信号比是一种图像的客观评价标准。他用最大值信号与背景噪声信号（重建与原始信号的差）的比值作为评价标准：<br>$$<br>\begin{aligned}<br>\operatorname{MSE} &amp;=\frac{1}{N} \sum_{i=1}^{N}(I(i)-\hat{I}(i))^{2} \\<br>\operatorname{PSNR} &amp;=10 \cdot \log _{10}\left(\frac{L^{2}}{\mathrm{MSE}}\right) \\<br>\end{aligned}<br>$$<br>其中L为图像点颜色的最大数值，若采样点采样8位表示，那么L = 255。该指标更加注重像素点之间的误差。典型的<strong>PSNR值在20到40之间</strong>。指标越高越好。</p><p>但是由于PSNR指标更多的放映相同位置上像素值的差异，而未考虑到人眼的视觉感知，因此作为质量评价指标是存在缺陷的。但这个指标仍是目前使用最多的一个指标。</p><p><strong>人眼视觉特征</strong></p><ol><li>对空间频率较低的对比差异敏感度高</li><li>人眼对亮度对比差异的敏感度较色度高</li><li>人眼对一个区域的感知结果会影响到周围邻近区域</li></ol><hr><h4 id="SSIM（Structural-Similarity-结构相似性）"><a href="#SSIM（Structural-Similarity-结构相似性）" class="headerlink" title="SSIM（Structural Similarity 结构相似性）"></a>SSIM（Structural Similarity 结构相似性）</h4><p>SSIM分别从亮度，对比度，结构三个方面度量图片的相似性。</p><p>首先计算图片的mean和variance：<br>$$<br>\begin{aligned}<br>\mu_{I} &amp;=\frac{1}{N} \sum_{i=1}^{N} I(i) \\<br>\sigma_{I} &amp;=\left(\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)^{2}\right)^{\frac{1}{2}} \\<br>\end{aligned}<br>$$<br><strong>亮度</strong>（luminance）指标（$\hat{I}$ 指生成的图片）:<br>$$<br>\mathcal{C}_{l}(I, \hat{I})=\frac{2 \mu_{I} \mu_{\hat{I}}+C_{1}}{\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}}<br>$$<br><strong>对比度（contrast）</strong>指标：<br>$$<br>\mathcal{C}_{c}(I, \hat{I})=\frac{2 \sigma_{I} \sigma_{\hat{I}}+C_{2}}{\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}}<br>$$<br><strong>结构对比度（structure comparison）</strong>指标：<br>$$<br>\begin{aligned}<br>\sigma_{I \hat{I}} &amp;=\frac{1}{N-1} \sum_{i=1}^{N}\left(I(i)-\mu_{I}\right)\left(\hat{I}(i)-\mu_{\hat{I}}\right) \\<br>\mathcal{C}_{s}(I, \hat{I}) &amp;=\frac{\sigma_{I \hat{I}}+C_{3}}{\sigma_{I} \sigma_{\hat{I}}+C_{3}} \\<br>\end{aligned}<br>$$<br>其中$C_1 = (K_1L)^2$,$C_2 = (K_2L)^2$,$C_3 = C_2 / 2$。</p><p>SSIM的指标有三面三个指标组合而成：<br>$$<br>\operatorname{SSIM}(I, \hat{I})=\left[\mathcal{C}_{l}(I, \hat{I})\right]^{\alpha}\left[\mathcal{C}_{c}(I, \hat{I})\right]^{\beta}\left[\mathcal{C}_{s}(I, \hat{I})\right]^{\gamma}<br>$$<br>通常使用下面这个形式：<br>$$<br>\operatorname{SSIM}(I, \hat{I})=\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(\sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\overline{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\tilde{I}}^{2}+C_{2}\right)}<br>$$<br>一般的，$k_1 = 0.01,k_2 = 0.03, L =255$。</p><p>此外还有一些主观的评价方法（mean opinion score），利用志愿者对生成图片的质量进行五个等级的评价，来确定图片的质量。</p><p>对于图片的颜色空间来说，常用的颜色空间有RGB空间与YCbCr。</p><hr><h3 id="基于有监督的超分辨率方法"><a href="#基于有监督的超分辨率方法" class="headerlink" title="基于有监督的超分辨率方法"></a>基于有监督的超分辨率方法</h3><h4 id="超分辨率框架分类"><a href="#超分辨率框架分类" class="headerlink" title="超分辨率框架分类"></a>超分辨率框架分类</h4><p>超分辨率框架总结下来有以下四种：</p><ol><li>Pre-upsampling Super-resolution</li><li>Post-upsampling Super-resolution</li><li>Progressive Upsampling Super-resolution</li><li>Iterative Up-and-down Sampling Super-resolution</li></ol><p>如下图：</p><p><img src="/images/SR/sr_structure_725.png" height="700px" width="600px"></p><p><strong>Pre-upsampling Super-resolution</strong></p><p>该方法在将图片送入网络前先用传统方法进行图片的放大（bicubic interpolation上采样），将图片放大到输出的要求大小，然后送入CNN网络中，学习一个端到端的从LR到HR的映射。</p><p>该方法的优点在于神经网络<strong>仅需要学习一张粗糙的（传统方法放大的）图片到HR图片的映射</strong>，大大降低了网络学习的难度；同时这种结构可以任意控制图片放大倍数。该方法框架也成为了一种较为主流的框架。</p><p>该方法的缺点在于：传统的图片放大算法中通常需要包含去噪，去模糊等操作，需要<strong>花费很大的时间以及空间</strong>。</p><hr><p><strong>Post-upsampling Super-resolution</strong></p><p>该方法将LR到HR的整个过程作为网络学习的目标，上采样层在网络的末端，这种设计可以极大发挥网络的潜力，同时能够显著降低网络训练时消耗的时间与空间。在train和inference阶段速度带来了很大的提升。</p><p>缺点：仅通过一个upsample层来放大图片，使得网络学习的难度大大提升；由于upsample层的放大尺度是固定的，如果更换一个倍数，就要更换一个训练模型。</p><hr><p><strong>Progressive Upsampling Super-resolution</strong></p><p>渐进式的上采样可以解决上诉post结构的问题（例如LapSRN网络 laplacian pyramid SR network）。该结构采用许多CNN的级联结构，每个阶段进行一个上采样重构HR，生成放大2倍，4倍，8倍等结果。</p><p>该模型的缺点是结构复杂，训练难度大等等。</p><hr><p><strong>Iterative Up-and-down Sampling Super-resolution</strong></p><p>该结构反复的放大，缩小图片，试图学习到一种后映射（back projection）的关系，该模型可以很好的学习到LR与HR之间的映射关系。基于该框架的网络DBPN也获得了NTIRE 2018的冠军。尽管这种up-down的结构设计标准还未确定，DBPN网络中存在着大量的复杂的结构设计以及繁重的人工设计过程，但是这种结构有很大的研究潜力。还需要进一步探索。</p><h4 id="传统插值上采样算法"><a href="#传统插值上采样算法" class="headerlink" title="传统插值上采样算法"></a>传统插值上采样算法</h4><ol><li>最近邻插值</li><li>线性插值</li><li>双三次插值</li></ol><p>详见<a href="www.baidu.com">这里</a></p><p>事实上，所有的差值算法完全通过图片自身的内容来实现超分辨率，因此他们并不能提供多于图片的信息，此外这些差值算法还引入了一些边界效应，例如计算复杂度，噪声，模糊等等。</p><h4 id="基于学习的上采样方法"><a href="#基于学习的上采样方法" class="headerlink" title="基于学习的上采样方法"></a>基于学习的上采样方法</h4><p><strong>转置卷积层 （transposed/ deconvolution layer）</strong></p><p> 转置卷积层的作用与正常卷积层的操作是相反的。转置卷积通过在像素间插入0来扩大图片的分辨率。下面是转置卷积层的工作原理：</p><p><img src="/images/SR/deconv.png" alt=""></p><p>首先对一张图片，每个像素点之间添加一个0值，然后用一个3 X 3 的卷积核，padding= 1 ，stride = 1对它进行卷积操作，最终得到一个大小为原先两倍的图片。</p><p>这种做法能够使得网络实现端到端的映射，但是他的缺点是，产生的图片会产生一些不等的重叠，从坐标轴上看，容易形成棋盘的割裂感，一定程度上伤害了SR的性能。</p><p><strong>子像素卷积（sub-pixel layer）</strong></p><p>子像素卷积在超分辨率领域使用十分广泛，用于扩大图片的像素。他的工作原理是执行一次卷积之后，产生一个多通道的feature map。然后将这些多通道的像素reshape到一个二维平面上。原理图如下：</p><p><img src="/images/SR/sub-pixel.png" alt=""></p><p>例如要将原始的feature map大小变大s倍，那么卷积核的channel数达到$s^2$。例如输入图片的大小为$w*h*c$，经过卷积操作后变为$w*h*s^2 c$ ，然后进过reshape成$sh*sw*c$，即完成了放大的操作。在原图的基础上放大了s倍。</p><p>子像素的上采样方法有一个重要的优点在于他有更大的感受野，能够提供更多的图片信息。但是感受野的分布是不对齐的，同时卷积层使用重复的感受野会导致不同卷积边界的不真实感。</p><h3 id="网络的设计"><a href="#网络的设计" class="headerlink" title="网络的设计"></a>网络的设计</h3><p>超分辨率发展到今天，需有有效的网络结构得到了验证，例如残差学习，密集连接块。这些结构结合上面提到的四种框架能够组合出各种有效的网络结构。</p><h4 id="残差学习-（residual-Learning）"><a href="#残差学习-（residual-Learning）" class="headerlink" title="残差学习 （residual Learning）"></a>残差学习 （residual Learning）</h4><p><img src="/images/SR/residual-learning.png" alt=""></p><p>残差学习最早由何凯明的resNet提出，在超分辨率领域残差学习主要有以下两种结构：</p><p><strong>全局残差学习 global residual learning</strong></p><p>由于在SR问题中，网络通常是端到端的，输入的图片与输出的图片有着很大的相关性。因此有些研究者通过直接学习输入与输出之间的残差，在输入与输出之间连接一条high way达到这个目的。因此网络仅仅需要学习输入与输出之间的残差部分（图片中的高频部分数据）。由于残差网路中绝大多数的区域值接近零，因此在网络的学习过程中能够大大降低运算量，尤其在pre-upsample框架中。</p><p><strong>局部残差学习（local residual learning）</strong></p><p>局部残差学习与resNet中的残差模块类似，在缓解网络退化，改善网络的学习能力上具有很好的效果。</p><h4 id="递归学习（Recursive-Learning）"><a href="#递归学习（Recursive-Learning）" class="headerlink" title="递归学习（Recursive Learning）"></a>递归学习（Recursive Learning）</h4><p><img src="/images/SR/recursive-learning.png" alt=""></p><p>为了不引入过多的参数同时实现更大的感受野并学习更高级别的特征，递归学习（其是指以递归方式多次应用相同模块）被引入到超分辨率领域中。很多工作中引入卷积结构、残差结构作为递归块，均在performance上有比较好的表现。</p><p>很多学者提出了很多与递归块结合的网络结构，例如将一个大的缩放因子分解成很多子问题，然后用力对结构解决这些子问题；将image upsample作为递归块等等。由于递归块同样面临着梯度的消失和梯度爆炸的问题，因此很多残差学习，多监督学习通常也会被引入到地柜结构中，来解决这些问题。</p><h4 id="多路径学习（multi-path-learning）"><a href="#多路径学习（multi-path-learning）" class="headerlink" title="多路径学习（multi-path learning）"></a>多路径学习（multi-path learning）</h4><p>多路径学习将特征传入模型的不同分支中，每个分支有着不同的结构，以此来提高模型的超分能力。</p><p><strong>全局多路径学习 Global Multi-path Learning</strong></p><p>全局的多路径学习通过利用不同路径来学习图片中的不同特征，例如用一些分支学习一些亚频特征；学习visible特征；学习全局结构；学习低频或高频部分；用于upsample图片等等</p><p>这种思路能够提升网络的特征提取能力。</p><p><strong>局部的多路径学习（local multi-path learning）</strong></p><p>受到inception结构的影响，引入一个block，这个block中使用不同的路径，进行不同尺度的特征提取。如下图：</p><p><img src="/images/SR/local-path.png" alt=""></p><p>分别对feature map应用一个3X3和5X5大小的核，在不同的尺度上对特征进行提取。通过这种方式可以在不同尺度上对特征进行提取，能够有效的提升网络的性能。</p><p><strong>特定尺度的路径学习（scale-specific multi-path learning）</strong></p><p><img src="/images/SR/scale-specific.png" alt=""></p><p>由于多分辨率问题对图片的方法尺度不同，网络需要重新训练，但是网络结构都是相同的。这种策略就是保留网络的主干部分（结构以及参数），在网络的头部和尾部添加一个与尺度相关的预处理路径以及一个upsample路径，每次对于特定的分辨率需求，选择相关的路径，而网络的特征提取以及中间部分都得到了保留。</p><h4 id="密集连接块（Dense-Connections）"><a href="#密集连接块（Dense-Connections）" class="headerlink" title="密集连接块（Dense Connections）"></a>密集连接块（Dense Connections）</h4><p>只从密集连接块被提出之后，这种结构就广泛的应用在超分辨率领域，结构如下：</p><p><img src="/images/SR/1.png" alt="1"></p><p>该种结构将当前层之前的feature map都作为这一层的输入，能够有效的避免梯度消失，增强信号的传递、特征的复用等。此外还有很多结构是在块级上做密集的连接，该结构证明在超分辨率领域中同样有效。</p><h4 id="通道注意力机制（channel-attention）"><a href="#通道注意力机制（channel-attention）" class="headerlink" title="通道注意力机制（channel attention）"></a>通道注意力机制（channel attention）</h4><p>通道注意力机制目的是给不同的channel赋予不同的权重，不同的channel在超分辨率问题上的作用是不同的，作者使用“压缩激发模块（squeeze-and-excitation）”对不同通道进行权重的赋值。</p><p><img src="/images/SR/channel-atten.png" alt=""></p><p>作者通过一个全局pooling将image的size变成1 X 1 X C，然后通过两个卷积层，得到每一个channel的权重。然后对feature map重新赋值，得到赋予权重的feature map。</p><h4 id="先进的卷积层（advanced-convolution）"><a href="#先进的卷积层（advanced-convolution）" class="headerlink" title="先进的卷积层（advanced convolution）"></a>先进的卷积层（advanced convolution）</h4><p><strong>空洞卷积 dilated convolution</strong></p><p>空洞卷积即在原始的卷积的基础上加上空洞，目的是为了增加图片的感受野。</p><p><img src="/images/SR/dilate-conv.png" height="300"> </p><p>将这种卷积应用在超分辨率问题上也能够使得模型性能得到提升。</p><p><strong>分组卷积（group convolution）</strong></p><p>分组卷积的概念是对feature map进行分组（channel维度上的划分），按童谣的比例划分卷积核，然后将每个分组再进行卷积，最终将卷积结果组合成一个feature输出。这种卷积的方式大大减少了参数的计算量，在性能上仅仅下降了一点。</p><p><img src="/images/SR/group-conv.png" alt=""></p><h4 id="像素递归学习-pixel-recurisive"><a href="#像素递归学习-pixel-recurisive" class="headerlink" title="像素递归学习 pixel recurisive"></a>像素递归学习 pixel recurisive</h4><p>大多数的SR方法在处理图像时像素之间是独立的，无法得到像素间的相关性，因此一些学者提出pixel by pixel的生成器，通过两个网络，分别学习图像的纹理结构信息以及像素间的序列依赖关系来生成HR图像。这种方法在某些方面有一个比较好的效果，但是训练过程十分的困难，计算量比较大。</p><h4 id="金字塔pooling"><a href="#金字塔pooling" class="headerlink" title="金字塔pooling"></a>金字塔pooling</h4><p>引入金字塔模型能够有效的利用图片全局以及局部的特征，在EDSR-PP网络中使用金字塔模型能够有效的提升网络的精度。</p><h4 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h4><p>小波变换可以很方便的的将图片的信号分解成高频的纹理细节和低频的拓扑结构。将小波变换应用在超分辨率问题上，从低分辨率的图片中提取出低频信息作为输入，输出高分辨率的高频信息。</p><h3 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a>学习策略</h3><h4 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h4><p>​    在超分辨率领域，损失函数用来衡量生成的HR图片与原始的HR图片之间的差距，同时指导模型的优化。下面简要介绍一下存在的一些损失函数的形式。其中$\hat{I}$ 表示原始超分辨图像，$I$ 表示生成的超分辨率图像。</p><p><strong>像素级别的loss （pixel loss）</strong></p><p>对比GT与生成的图片在像素级别上的L1以及L2 loss：<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text {pixel_L1 }}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left|\hat{I}_{i, j, k}-I_{i, j, k}\right| \\<br>\mathcal{L}_{\text {pixel_L2}}(\hat{I}, I) &amp;=\frac{1}{h w c} \sum_{i, j, k}\left(\hat{I}_{i, j, k}-I_{i, j, k}\right)^{2} \\<br>\end{aligned}<br>$$<br>L2 loss 相比较于L1 loss 来说，更加的惩罚比较大的误差，而对一些小的误差的容忍度更大。L1 loss在对性能和最终的收敛上比L2更好。对于指标PSNR来说，最小化pixel loss就可以达到最大化PSNR的目的。但是pixel loss没有将图片的质量考虑在内，因此生成的图片过于平滑，失去了高频的细节信息。</p><p><strong>满意度损失（content loss）</strong></p><p>基于感知的满意度损失，这个loss是一个L2 loss。他的不同点在于，我们将GT与生成的图片，分别输入一个欲训练好的分类网络中，取其高层特征（第$l$ 层）进行pixel wise上的loss计算。<br>$$<br>\mathcal{L}_{\text {content }}(\hat{I}, I ; \phi, l)=\frac{1}{h_{l} w_{l} c_{l}} \sqrt{\sum_{i, j, k}\left(\phi_{i, j, k}^{(l)}(\hat{I})-\phi_{i, j, k}^{(l)}(I)\right)^{2}}<br>$$<br>其中h,w,h是抽取出来的特征层的大小。</p><p>这个loss更加强调图片在生成上的相似性，最常用的分类网络是VGG，resNet。</p><p><strong>纹理损失（Texture Loss）</strong></p><p>一些文章认为图片的纹理由特征不同通道的相关性组成，定义为下面Gram matrix：<br>$$<br>G_{i j}^{(l)}(I)=\operatorname{vec}\left(\phi_{i}^{(l)}(I)\right) \cdot \operatorname{vec}\left(\phi_{j}^{(l)}(I)\right)<br>$$<br>上式中表示两个不同通道的向量的点乘结果。即第 $l$ 层特征向量的i通道和j通道的点乘结果。纹理损失依旧是L2损失，输入是生成图片和GT之间的纹理表示。<br>$$<br>\mathcal{L}_{\text {texture }}(\hat{I}, I ; \phi, l)=\frac{1}{c_{l}^{2}} \sqrt{\sum_{i, j}\left(G_{i, j}^{(l)}(\hat{I})-G_{i, j}^{(l)}(I)\right)^{2}}<br>$$<br>通过这种损失可以很好的得到较为真实的图片。但是仍然有一个难以解决的问题是，用于计算纹理损失的图片patch（方块，补丁）大小的确定依旧要根据经验来确定，太大或太小的patch使得生成的纹理不够真实。</p><p><strong>对抗损失（adversarial loss）</strong></p><p>我们使用一个SR模型作为生成器，另外我们需要定义一个判别器，下面的判别器D使用<strong>交叉熵</strong>来表示。生成器希望生成的样本判别器无法辨认，判别器希望能够鉴别出生成器生成的样本是假的。<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text {gan_ce_g}}(\hat{I} ; D) &amp;=-\log D(\hat{I}) \ <br>\mathcal{L}_{\text {gan_ce_d }\left(\hat{I}, I_{s} ; D\right)} &amp;=-\log D\left(I_{s}\right)-\log (1-D(\hat{I})) \\<br>\end{aligned}<br>$$<br>下面还有使用<strong>最小平方差</strong>最为判别器，能够得到更加真实的且高质量的结果。<br>$$<br>\begin{aligned}<br>\mathcal{L}_{\text{gan_ls_g}}(\hat{I} ; D) &amp;=(D(\hat{I})-1)^{2} \ <br>\mathcal{L}_{\text{gan_ls_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=(D(\hat{I}))^{2}+\left(D\left(I_{s}\right)-1\right)^{2} \end{aligned}<br>$$<br>下面是使用hinge loss形式的对抗损失：<br>$$<br>\begin{aligned} \mathcal{L}_{\text{gan_hi_g}}(\hat{I} ; D) &amp;=-D(\hat{I}) \ \mathcal{L}_{\text{gan_hi_d}}\left(\hat{I}, I_{s} ; D\right) &amp;=\min (0, D(\hat{I})-1)+\min \left(0,-D\left(I_{s}\right)-1\right) \\<br>\end{aligned}<br>$$<br>使用对抗损失很大程度上带来的感知质量的提升，虽然PSNR指数有所下降，但是MOS指数有上升，取得了一个很好的视觉效果，生成的图片更加的真实。</p><p><strong>循环连续损失 （Cycle Consistency Loss）</strong></p><p>改损失受到循环GAN的启发，所用的网络不仅需要从LR到SR，还需要从SR到LR，重新生成的LR需要和输入一致，因此loss 如下：<br>$$<br>\mathcal{L}_{\text {cycle }}\left(I^{\prime}, I\right)=\frac{1}{h w c} \sqrt{\sum_{i, j, k}\left(I_{i, j, k}^{\prime}-I_{i, j, k}\right)^{2}}<br>$$<br><strong>总差异损失（total variation loss）</strong></p><p>这个算是是为了压制在生成图像过程中生成的噪声对图像质量产生的影响。他的loss有相邻像素的差异组合成。<br>$$<br>\mathcal{L}_{\mathrm{TV}}(\hat{I})=\frac{1}{h w c} \sum_{i, j, k} \sqrt{\left(\hat{I}_{i, j+1, k}-\hat{I}_{i, j, k}\right)^{2}+\left(\hat{I}_{i+1, j, k}-\hat{I}_{i, j, k}\right)^{2}}<br>$$<br><strong>基于先验损失（prior based loss）</strong></p><p>对于特定的数据，可以引入一下数据所特有的先验特征。通过这种先验特征可以很快的提升网络对这类数据恢复的性能。</p><h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>BN的提出是为了消除网络训练过程中内部参数的偏移问题。具体做法是对每一个bach做一个归一化操作，并且训练两个变量用于还原网络的表达能力。因此我们在训练过程中可以使用更高的学习率，以及不用太在意参数的初始化值。因此BN在SR网络中同样得到了广泛的应用。</p><p>但是有一些学者认为BN使得网络丧失了尺度信息，使得网络失去灵活度，同样有些网络中去除BN后，取得了一个很好的性能。</p><h4 id="课程学习-Curriculum-learning"><a href="#课程学习-Curriculum-learning" class="headerlink" title="课程学习 Curriculum learning"></a>课程学习 Curriculum learning</h4><p>渐进性的课程学习方法指的是网络从一个简单的任务出发，逐渐增加问题的难度，以此来得到一个鲁棒的模型。</p><p>超分辨率问题本质上是一个病态问题（ill-posed problem），即一些干扰对结果的影响非常的大，且系统十分不稳定，难以从结果反推回输入。这些干扰包括噪声，图片的模糊度，以及超分辨的倍数等等。</p><p>课程学习可以通过渐进学习的方式来解决这些问题，对于放大倍数很大（例如8）的任务，可以利用该思想，现训练简单的情况，例如可以先放大2，4，8倍来解决这个问题，这种方式能够大大缩短网络的训练时间，提升性能。</p><h4 id="多监督问题-（multi-supervision）"><a href="#多监督问题-（multi-supervision）" class="headerlink" title="多监督问题 （multi-supervision）"></a>多监督问题 （multi-supervision）</h4><p>多监督问题在loss 中增加一些变量，用来对某些信号进行监督，最终能够得到一个性能较好的模型。</p><h3 id="其他有用的方法"><a href="#其他有用的方法" class="headerlink" title="其他有用的方法"></a>其他有用的方法</h3><p><strong>context-wise network fusion</strong></p><p>这种方式使用多个不同结构的网络，分别进行超分辨率的训练，然后依次将这些训练结果通过卷积层组合最终的结果（SRCNN），使用这种方法能够也能够达到state of art的效果，同时效率也是可以接受的。</p><p><strong>data augmentation</strong></p><p>数据增强方面，常用于网络中的方法有random cropping, flipping,scaling,rotation, color jittering, 此外还有一个特殊的增强方式，random shuffle RGB,随机打乱RGB的颜色值，这种方法能够消除颜色带来的偏差。</p><p><strong>multi-task learning</strong></p><p>多任务学习指的是将多种任务于SR任务结合，例如语义分割网络于SR网络结合（SFT-GAN）等，将去噪声网络和SR网络结合（DNSR），这种方式能够提供数据的先验，能够更好的提升SR的效果。</p><p><strong>network interpolation</strong></p><p>网络的结合，将基于pxiel loss和基于感知loss的两种方法结合起来，得到一种中间状态的网络，这种网络同时在PSNR和真实感上有很好的表现。</p><h3 id="无监督的方法"><a href="#无监督的方法" class="headerlink" title="无监督的方法"></a>无监督的方法</h3><p>在超分辨率问题上，由于很难获得真实数据的超分辨率结果，因此 通常的做法是使用一个下采样方法，从超分辨率图像中得到他的低分辨率版本你，组成一个数据对，因此监督学习更像是学习这个方法的逆方法，人们通常忽略了提前定义好的下采样方法给数据带来的副作用。对于无监督方法来说，直接使用高分辨率的图片，更加符合现实中的场景。无监督方法上，目前仍然有很多值得探索的地方。</p><h4 id="zero-shot-super-resolution"><a href="#zero-shot-super-resolution" class="headerlink" title="zero-shot super-resolution"></a>zero-shot super-resolution</h4><p>这个方法训练了一个预测核函数直接针对每张图片都生成一个下采样（degradation）核方法，使用这个核方法来构造数据集，采用不同的缩放尺度得到测试数据，然后训练一个CNN网络来实现SR。由于这个模型需要为每一张图片构造一个函数，因此需要更多的时间。</p><h4 id="weakly-supervised-Super-resolution"><a href="#weakly-supervised-Super-resolution" class="headerlink" title="weakly-supervised Super-resolution"></a>weakly-supervised Super-resolution</h4><p>弱监督的学习方法有两个思路，第一种是不是用传统的HR-to-LR的退化函数，而是学习一个网络来实现这个过程，然后构造一个数据集，然后使用这个数据集来训练SR模型。另一种是cycle-in-cycle的方法，同时学习LR-to-HR和HR-to-LR两方面。</p><p><strong>learning degradation</strong></p><p>有学者提出了一个两个阶段的学习网络，提出一个GAN网络，学习HR to LR，用这个网络生成一个LR-HR配对的数据集，然后训练一个LR to SR的GAN网络使用上诉的数据集进行训练，最终结果能够显著提升数据恢复的真实性。</p><p><strong>cycle in cycle super resolution</strong></p><p>CinCGAN网络使用了四个生成器，两个判别器。生成器分别为noise LR -&gt; clean LR -&gt; clean HR，另外两个生成器进行反方向的生成。然后生成器用于判别生成了LR和SR的真实性，这其中引入了大量的损失函数，来保证这一过程的合理性。此外，这个方法还有很多改进的地方，来降低它训练的难度。</p><h4 id="图像的深度先验"><a href="#图像的深度先验" class="headerlink" title="图像的深度先验"></a>图像的深度先验</h4><p>使用一个随机初始化参数的CNN，对一张输入的图像，直接恢复他的超分辨率图像，仅仅利用CNN的结构先验来解决这个问题。模型的效果比传统的双线性插值要好些，但是效果不如其他监督方法，这种方法给我门提供了一种思路，仅仅利用一些手工制作的先验对图像进行超分辨率的恢复。</p><h3 id="领域相关的应用"><a href="#领域相关的应用" class="headerlink" title="领域相关的应用"></a>领域相关的应用</h3><h4 id="高光谱影像-（Hyperspectral-Image-Super-resolution）"><a href="#高光谱影像-（Hyperspectral-Image-Super-resolution）" class="headerlink" title="高光谱影像 （Hyperspectral Image Super-resolution）"></a>高光谱影像 （Hyperspectral Image Super-resolution）</h4><p>高光谱影像在视觉任务中有着很多的用途，但是由于硬件的约束，收集到高质量的高光谱数据是十分的困难的，高光谱数据的分辨率因此也十分的低。因此在高光谱数据领域应用超分辨率方法是很有前景的。</p><p>基于高光谱的超分辨率工作有以下几种：</p><p>W. Huang, L. Xiao, Z. Wei, H. Liu, and S. Tang, “A new pan- sharpening method with deep neural networks,” <em>GRSL</em>, vol. 12, 2015.</p><p>G. Masi, D. Cozzolino, L. Verdoliva, and G. Scarpa, “Pansharp- ening by convolutional neural networks,” <em>Remote Sensing</em>, vol. 8, 2016. Y.Wei,Q.Yuan,H.Shen,andL.Zhang,“Boostingtheaccuracyof multispectral image pansharpening by learning a deep residual network,” <em>GRSL</em>, vol. 14, 2017.</p><p>Y. Qu, H. Qi, and C. Kwan, “Unsupervised sparse dirichlet-net for hyperspectral image super-resolution,” in <em>CVPR</em>, 2018.</p><h3 id="未来的研究方向"><a href="#未来的研究方向" class="headerlink" title="未来的研究方向"></a>未来的研究方向</h3><h4 id="网络结构设计"><a href="#网络结构设计" class="headerlink" title="网络结构设计"></a>网络结构设计</h4><p><strong>结合图片局部和全局信息</strong>： 更大的感受野能够帮助网络获得更多图片的纹理细节。</p><p><strong>结合图片中的高低频数据：</strong>cnn网络的浅层部分能够获取图像的颜色和边界信息，深层网络能够获取图像的语义信息。</p><p><strong>纹理注意力机制：</strong>不同的纹理反应出来的细节特征是不同的，引入注意力机制能够增强图片的真实性。</p><p><strong>轻量级的结构：</strong>预测一张DIV2k的图片，EDSR模型需要花费20s，这是难以接受的，因此我们需要精简网络结构。</p><p><strong>上采样层：</strong>当前使用的上采样层均存在着不同程度的缺陷，提出一个好的上采样层，能够提升网络效能。</p><h4 id="学习策略-1"><a href="#学习策略-1" class="headerlink" title="学习策略"></a>学习策略</h4><p><strong>损失函数：</strong> 当前仍未找到一个很好的损失函数，能够兼顾感知和pixel wise</p><p><strong>Normalization：</strong>BN归一化方法十分花费时间，需要找到它的替代结构</p><h4 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a><strong>评价指标</strong></h4><p>当前的评价指标有PSNR，SSIM，MOS三种，其中PSNR容易生成过于平滑的图像，SSIM根据图片的光照，对比度，结构来评价，当时离人的感知还有一定距离，MOS与人的感知比较接近，但是统计起来十分的耗费人力及复杂。</p><h4 id="现实场景的使用"><a href="#现实场景的使用" class="headerlink" title="现实场景的使用"></a><strong>现实场景的使用</strong></h4><p>无监督学习方向上，可以学习一个degradation函数，用于数据的上采样，更符合现实数据的现状。</p><p>一些特定领域的应用方面，超分辨率可以作为整个流程的一部分。</p>]]></content>
      
      
      <categories>
          
          <category> super resolution </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些提升效率的方法</title>
      <link href="/2019/07/23/%E4%B8%80%E4%BA%9B%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2019/07/23/%E4%B8%80%E4%BA%9B%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h4 id="在word或ppt中插入公式"><a href="#在word或ppt中插入公式" class="headerlink" title="在word或ppt中插入公式"></a>在word或ppt中插入公式</h4><ol><li>使用mathpix snipper工具，从截图中获取latex公式。</li><li>进入这个网站：<a href="https://www.latex4technics.com/" target="_blank" rel="noopener">https://www.latex4technics.com/</a> </li><li>输入latex公式，在右下角转化为mathml格式。</li><li>打开word，插入公式。以纯文本的格式粘贴mathml代码，word自动转化为公式。</li><li>ppt中需要从word得到的公式复制过来，不支持直接转换。</li></ol><h4 id="使用jupyter链接服务器"><a href="#使用jupyter链接服务器" class="headerlink" title="使用jupyter链接服务器"></a>使用jupyter链接服务器</h4><p>jupyter有几个好处，他可以单步执行，单步调试。可以在浏览器上看执行的结果，包括图片的显示这些。当跑的代码比较简单，是测试功能的代码的时候，可以使用jupyter。</p><p>jupyter的配置：<a href="https://www.jianshu.com/p/4012f7149eb8" target="_blank" rel="noopener">jianshu.com/p/4012f7149eb8</a></p><p>用mac连接远程服务器：</p><ol><li>服务器端输入：jupyter notebook –no-browser –port=8898</li><li>本地输入：ssh<code></code>-N -f -L 127.0.0.1:8898:127.0.0.1:8898 zhouwenhui@remote-machine</li><li>最后在浏览器访问：<a href="http://127.0.0.1:8898/" target="_blank" rel="noopener">http://127.0.0.1:8898/</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xigua-支持向量机</title>
      <link href="/2019/07/21/xigua-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2019/07/21/xigua-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<p>支持向量机主要目的在于找到 一个位于两类训练样本的正中间，该分界面对样本的局部扰动的鲁棒性最好。通过该分界面能够最大限度的对数据进行分类。</p><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>xigua-神经网络</title>
      <link href="/2019/07/20/xigua-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2019/07/20/xigua-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>“神经网络是具有适应性的简单单元组成的广泛，并行互连的网络，能够模拟生物神经系统对真实世界物体所作出的交互反应。”</p><a id="more"></a><h3 id="神经网络的发展"><a href="#神经网络的发展" class="headerlink" title="神经网络的发展"></a>神经网络的发展</h3><p>1943年，神经网络模型最早是由心理学家和数理逻辑学家在提出的MP模型，它揭示了“大脑活动是靠脑细胞的组合连接实现的。”</p><p>1949年，心理学家Hebb提出 “脑细胞间某种通路在参与某种活动时被加强。” 用现在的观点来看这一说法，即我们可以通过调整网络参数（权重），来改善网络的性能。</p><p>1956年，达特茅斯会议上，明斯基，麦卡锡，西蒙等人首次提供人工智能的概念，使得人工智能在成为计算机科学的一个分支。</p><p>1962年，感知机模型正式提出，它具有输入层，输出层和中间层。</p><p>1969年，明斯基的《percetion》一书出版，指出感知机不能解决高阶谓词问题，人工智能发展陷入低谷。</p><p>1982年，hopfield向美国科学院提出了关于神经网络的报告，引起美国军方的注意，引起了神经网络的第二次高潮。在这次高潮中，hopfield网络，boltzmann机以及BP算法得到提出。</p><p>2006年之后，hiton提出深度学习，引起了神经网络的第三次浪潮。</p><h3 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h3><p>1943年提出的“M-P神经元模型”如下：</p><p><img src="../images/mp.png" alt=""></p><p>输入乘以权重之后，减去一个偏置$\theta$ ，然后通过激活函数，得到这个神经元的输出。在早期，使用的激活函数为sigmoid函数：</p><p><br>$$<br>\sigma(z)=\frac{1}{1+\mathrm{e}^{-z}}<br>$$<br>sigmoid函数如图：</p><p><img src="../images/xigua/sigmoid.png" alt=""></p><p>sigmoid 的导数形式如下：<br>$$<br>\sigma(z)’=\frac{\mathrm{e}^{-z}}{(1+\mathrm{e}^{-z})^{2}} = \frac{1+\mathrm{e}^{-z}-1}{(1+\mathrm{e}^{-z})^{2}} = \sigma(z)*(1 - \sigma(z))<br>$$<br>由于sigmoid的导数函数形式简单，取值变化范围在(0,1)之间。神经网络就是有无数个像这样的神经元结构组合而成的一个包含许多参数的数学模型。</p><h4 id="激励函数"><a href="#激励函数" class="headerlink" title="激励函数"></a>激励函数</h4><p>激励函数的作用是将无限域的变换指定到有限范围内进行输出。同时增加网络的非线性建模能力，复杂程度。</p><p>Bengio对激活函数有如下的定义：</p><blockquote><p>激活函数是映射h：R-&gt;R，且几乎处处可导。</p><p>具有软饱和函数的性质：$\lim_{s-&gt;\inf} f’(s) = 0$ ，软饱和性质只当x趋向去正无穷或负无穷的时候，函数的导数为0。硬饱和指存在一个区域c，当x接近c边缘时，导数值变为0.</p></blockquote><p><strong>ReLu激活函数：</strong>该激活函数能够在一定程度上克服梯度消失的问题。</p><p><img src="../images/xigua/relu.png" alt=""></p><p>relu在$x&lt;0$部分为硬饱和，导数为0。在$x&gt;0$部分，导数为1，<strong>能够保持网络梯度不衰减，缓解梯度消失问题。</strong> 当部分输入落入饱和区时，<strong>将导致网络的稀疏性，同时导致对应的权重无法更新（神经元死亡）。</strong>relu的输出同时具有偏移现象，即输出的值均值大于0，偏移与神经元死亡是其主要弊病。</p><h4 id="误差反向传播"><a href="#误差反向传播" class="headerlink" title="误差反向传播"></a>误差反向传播</h4><p>BP算法沿着负梯度方向减小误差，利用链式法则对每一个梯度求一个$\Delta$ 值，用于更新网络的参数。当网络陷入一个极小点时，在该点处不存在负梯度方向，因此参数无法进行更新。此时网络可能陷入局部极小点或全局最小点。</p><p>如果网络陷入局部极小点，我们希望在网络的训练过程中，函数能够跳出该极小点。可以使用的方法有 <strong>模拟退火法</strong>，即在每一步迭代，以一定的概率接受次优解，可以一定程度上避免陷入局部极小。 <strong>随机梯度下降法</strong>，每次选择部分数据进行梯度的计算，因此该梯度方向不一定是全局的下降方向，随着函数的迭代，网络误差可以慢慢降到一个可以接受的水平。</p><h4 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h4><p>深度学习模型是深层次的神经网络，通过增加网络的层次，提高网络的容量，使得它能学到更加复杂的问题。但是多层神经网络难以用传统的BP算法进行训练，因此后来的学者们也提出了许多其他的算法。</p><h3 id="神经网络的实现"><a href="#神经网络的实现" class="headerlink" title="神经网络的实现"></a>神经网络的实现</h3><h4 id="pytorch中的torch-nn包"><a href="#pytorch中的torch-nn包" class="headerlink" title="pytorch中的torch.nn包"></a>pytorch中的torch.nn包</h4><p>pytorch中关于网络结构的函数在torch.nn这个包里头，此外torch.nn.functional中也有于torch.nn对应的相关函数。他们的区别在于torch.nn中的参数是可训练的，可变的。torch.nn.functional中的函数是不可训练的，进行一些数学运算，类似于tensor于Variable的区别。因此搭建网络结构的时候使用torch.nn，激活函数则使用torch.nn.functional。</p><p>贴一个解释很清楚的文章：<a href="https://blog.csdn.net/hawkcici160/article/details/80140059" target="_blank" rel="noopener">https://blog.csdn.net/hawkcici160/article/details/80140059</a></p><h4 id="pytorch中的torch-autograd包"><a href="#pytorch中的torch-autograd包" class="headerlink" title="pytorch中的torch.autograd包"></a>pytorch中的torch.autograd包</h4><p><code>autograd.Variable</code>是包的中央类，包含一个张量，并支持几乎所有定义的操作，在完成计算后，调用<code>.backward()</code>并自动计算所有梯度。可以通过<code>.data</code>属性访问原始张量，而将此变量的梯度累加到<code>.grad</code>。</p><p>Variable类中比tensor类多了几个其他的属性：data,grad_fn,grad,variable变量可以用来计算梯度。</p><p>下面这个文章有有详细介绍：<a href="https://www.jianshu.com/p/cbce2dd60120" target="_blank" rel="noopener">https://www.jianshu.com/p/cbce2dd60120</a></p><p>可以用variable来定义网络的参数。</p>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>19/7/2019 preview</title>
      <link href="/2019/07/19/19-7-2019-preview/"/>
      <url>/2019/07/19/19-7-2019-preview/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> dialog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前缀树🌲:trie</title>
      <link href="/2019/07/17/%E5%89%8D%E7%BC%80%E6%A0%91%F0%9F%8C%B2-trie/"/>
      <url>/2019/07/17/%E5%89%8D%E7%BC%80%E6%A0%91%F0%9F%8C%B2-trie/</url>
      
        <content type="html"><![CDATA[<p>前缀树是一种存储数据的树形结构。是一种高效的检索字符串的方法，是一种多叉树的结构。它的插入与删除的效率比较高，时间复杂度为O(m).</p><a id="more"></a><h3 id="前缀树"><a href="#前缀树" class="headerlink" title="前缀树"></a>前缀树</h3><p>前缀树的结构如下图所示：</p><p><img src="/images/trie.png" alt="trie"></p><p>前缀树的结构特点为：</p><ol><li>根节点不包含字符，除根结点外，其他节点只包含一个字符</li><li>从根节点出发叶子结点，组成一个完整的字符串</li><li>每个节点包含的字符均不相同</li></ol><h3 id="前缀树的实现"><a href="#前缀树的实现" class="headerlink" title="前缀树的实现"></a>前缀树的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.res = &#123;&#125; </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Inserts a word into the trie.</span></span><br><span class="line"><span class="string">        :type word: str</span></span><br><span class="line"><span class="string">        :rtype: None</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                a[i] = &#123;&#125;</span><br><span class="line">            a = a[i]</span><br><span class="line">        a[<span class="string">'end'</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Returns if the word is in the trie.</span></span><br><span class="line"><span class="string">        :type word: str</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            a = a[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'end'</span> <span class="keyword">in</span> a:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startsWith</span><span class="params">(self, prefix)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Returns if there is any word in the trie that starts with the given prefix.</span></span><br><span class="line"><span class="string">        :type prefix: str</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        a = self.res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> prefix:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            a = a[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># Your Trie object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = Trie()</span></span><br><span class="line"><span class="comment"># obj.insert(word)</span></span><br><span class="line"><span class="comment"># param_2 = obj.search(word)</span></span><br><span class="line"><span class="comment"># param_3 = obj.startsWith(prefix)</span></span><br></pre></td></tr></table></figure><p>上面代码用dict代替书的结构，一级一级的向下延展，前缀树由根节点往下，每一个节点的字节点就是他的key的数目，选择其中一个key，然后一级一级往下，当一个单词结束的时候，填入end作为终结符。</p>]]></content>
      
      
      
        <tags>
            
            <tag> — leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xigua:决策树</title>
      <link href="/2019/07/14/xigua-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2019/07/14/xigua-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<p>决策树是一类常见的机器学习算法，决策过程是基于树的结构进行的。叶子结点对应了树的决策结果，子节点对应了属性的测试（例如西瓜的颜色）。决策树的最终目的是产生一棵泛化能力强的树。</p><a id="more"></a><h3 id="决策树基本知识"><a href="#决策树基本知识" class="headerlink" title="决策树基本知识"></a>决策树基本知识</h3><h4 id="决策树子节点的生成"><a href="#决策树子节点的生成" class="headerlink" title="决策树子节点的生成"></a>决策树子节点的生成</h4><p>决策树的生成方式是一个递归的过程，有根结点开始，生成子节点的情况有下面三种：</p><ul><li>当前节点包含的样本全属于一个类别，无需划分</li><li>当前节点上所有样本的属性为空（例如缺失了身高这个数据），因此设置节点时，将该节点设置成样本中类别比例最大的那个。</li><li>当前节点所包含的样本集合为空时，采用样本的先验概率（例如身高为170的样本最多）来设置样本类</li></ul><h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p><strong>熵：</strong> entropy，希腊语原意为 <strong>内向性</strong>，<u>即一个系统不受外部干扰时，往内部最稳定状态发展的特性。</u> </p><p>熵同时可以作为<u>一个系统的混乱程度的度量</u>，即根据热力学第二定律，一个系统倾向于向增加混乱的程度发展，例如抛一枚硬币，最终的统计结果是正反面都是0.5的概率，对于预测来说，预测正面或者反面的不确定性都是最大的。</p><p><strong>信息熵：</strong> </p><p>信息熵是指接受数据中包含的信息量的平均值，是一种不确定性的度量，越随机的信源，熵越大。<strong>熵定义为概率分布的对数的相反数</strong>。也即是说，<u>当一个事件发生的可能性越小，当这个事件出现的时候，提供的信息就越多，不确定性越大，熵就越大。</u><br>$$<br>\mathrm{H}(X)=\mathrm{E}[\mathrm{I}(X)]=\mathrm{E}[-\ln (\mathrm{P}(X))]<br>$$<br>当数据取自有限样本是：<br>$$<br>\mathrm{H}(X)=\sum_{i} \mathrm{P}\left(x_{i}\right) \mathrm{I}\left(x_{i}\right)=-\sum_{i} \mathrm{P}\left(x_{i}\right) \log _{2} \mathrm{P}\left(x_{i}\right)<br>$$<br><strong>信息增益：</strong></p><p><u>信息增益指期望信息的有效减少量。</u>例如决策树，在一个分支上，选择一个属性进行划分，得到的信息增益越大证明划分结果不确定性越小，纯度越高。<br>$$<br>\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} E n t\left(D^{v}\right)<br>$$<br>然而信息增益趋向于选择分类更加细致的属性（分类越多，每一类的纯度也会越大），为了克服这个毛病，引入了信息增益率：<br>$$<br>g_{R}(D, A)=\frac{g(D, A)}{H_{A}(D)}<br>$$<br>其中：<br>$$<br>H_{A}(D)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|}<br>$$<br>信息增益率趋向于选择分类少的属性。（分类多，分母大）</p><p><strong>基尼指数：</strong></p><p>基尼指数比较直观，他反映了连续抽取两个样本，他们不一样的概率。因此越小表明纯度越纯。<br>$$<br>\operatorname{Gini}(\mathrm{p})=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}<br>$$<br>决策树缺失属性的处理情况：</p><ol><li>当属性缺失的情况下，选择最优的属性划分：可以修改信息增益函数，加上无缺失样本所占比例，无缺失样本中第k类所占比例，以及无缺失样本中某个属性所占比例等修正，得到划分的标准</li><li>当选定划分属性时，该属性缺失：将这些样本按照不同的概率，加入到所有的分支中</li></ol>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>xigua:线性模型(linear model)</title>
      <link href="/2019/07/14/xigua-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-linear-model/"/>
      <url>/2019/07/14/xigua-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-linear-model/</url>
      
        <content type="html"><![CDATA[<p>线性模型形式简单，易于建模，具有很好的解释性质。</p><a id="more"></a><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>线性模型试图学到一个通过属性的线性组合来进行预测的函数，线性模型将要学到下面的一个函数形式：<br>$$<br>f(x) = \omega^T x + b<br>$$<br>简单的来说，即通过训练数据 (x,y) 来学的线性模型的$\omega$ 和b，即可确定模型。</p><h3 id="线性模型-pytorch实现"><a href="#线性模型-pytorch实现" class="headerlink" title="线性模型 pytorch实现"></a>线性模型 pytorch实现</h3><p>在实现一个线性模型之前，我们首先确定一下算法实现的pipeline。</p><ul><li>数据准备：训练数据，label，以及测试数据的格式与读取形式。</li><li>模型的建立：模型类继承<code>torch.nn.Module</code>，实现其中的<code>__init__(),forward()</code>函数。</li><li>确定网络的criterion以及optimizer。</li><li>训练过程：每过一个step进行参数的更新。</li></ul><h4 id="数据准备部分"><a href="#数据准备部分" class="headerlink" title="数据准备部分"></a>数据准备部分</h4><p>在这个例子中，我们使用较为简单的数据作为输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0]]))</span><br><span class="line">y_data = Variable(torch.Tensor([[2.0],[4.0],[6.0]]))</span><br></pre></td></tr></table></figure><p>Vari3able 变量于Tensor的区别在于variable变量是可以计算梯度的，在梯度反向传播的时候进行梯度的计算。</p><h4 id="模型的建立"><a href="#模型的建立" class="headerlink" title="模型的建立"></a>模型的建立</h4><p>pytorch中模型类均需要继承一个父函数：<code>torch.nn.Module</code>.</p><p><code>torch.nn.module</code> 是所有网络的基类，我们定义的网络类，都需要继承自这个类。<code>torch.nn</code>这个类中包含各种网络层结构，linear，conv等等。对于我们的线性模型来说，我们可以定义一个网络类，然后在init中定义linear。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegressionModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义自己的网络需要继承torch.nn.Module类，实现其中的init以及forward方法:</span></span><br><span class="line"><span class="string">    torch.nn.Module:</span></span><br><span class="line"><span class="string">        torch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络</span></span><br><span class="line"><span class="string">        nn.Module是nn中十分重要的类,包含网络各层的定义及forward方法。</span></span><br><span class="line"><span class="string">        一般把网络中具有可学习参数的层放在构造函数__init__()中</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(LinearRegressionModel,self).__init__()</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        线性模型：torch.nn.Linear(in_features,out_features,bias=True)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># one in one out</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure><h4 id="criterion-and-optimizer"><a href="#criterion-and-optimizer" class="headerlink" title="criterion and optimizer"></a>criterion and optimizer</h4><p>Criterion 即为网络训练过程中，输出的预测值与groundTruth之间的差距，通常在二分类问题上可以使用MSE loss，crossentropy等等。如<code>torch.nn.MSELoss()</code></p><p>Optimizer 可以使用<code>torch.optim.SGD(linear_model.parameters(),lr = 0.01)</code>。</p><h4 id="train"><a href="#train" class="headerlink" title="train"></a>train</h4><p>网络训练过程中，设置训练的次数，首先将数据传如入网络中，然后使用criterion求出输出与groundtruth之间的偏差。在每一次参数更新时，首先将梯度置零，然后进行梯度的向后传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">  pre = linear_model(x_data)</span><br><span class="line">  loss = criterion(pre,label)</span><br><span class="line">  <span class="comment"># 清空参数</span></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line">  loss.backgrad() <span class="comment"># 参数向后传播</span></span><br><span class="line">  optimzer.step()</span><br></pre></td></tr></table></figure><h4 id="evaluate"><a href="#evaluate" class="headerlink" title="evaluate"></a>evaluate</h4><p>网络测试部分比较简单，将输入输入网络中，得到其输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = linear_model(new_var)</span><br><span class="line">print(<span class="string">'result &#123;&#125;'</span>.format(result.data[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> xigua </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Something about keras</title>
      <link href="/2019/05/24/Something-about-keras/"/>
      <url>/2019/05/24/Something-about-keras/</url>
      
        <content type="html"><![CDATA[<h3 id="PART-I-keras-progress"><a href="#PART-I-keras-progress" class="headerlink" title="PART I : keras progress"></a>PART I : keras progress</h3><ol><li>prepare data,process data</li><li>create model,loss,optimizer</li><li>feed data to model,set hyperparamers</li><li>add some callbacks method</li><li>train and save model,save the log</li></ol><p>there is a example go through the process</p><h3 id="PART-II-data-prepare"><a href="#PART-II-data-prepare" class="headerlink" title="PART II:  data prepare"></a>PART II:  data prepare</h3><p> 生成数据部分，数据基本上是存储为coco，或csv格式。将数据从硬盘中读入内存。然后构造一个生成器，目的在于批量的（batch size大小）读出数据，预处理数据。生成器简单的使用如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_func</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):        </span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> generate_func():    </span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><p>另一种做法是实现类的<code>__next__()</code>方法，每次调用一次该类，即间接调用该方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">generate</span><span class="params">(object)</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span> </span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        ... </span><br><span class="line">        data processing </span><br><span class="line">        <span class="keyword">return</span> batch_size data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># some layer in layers Dense,Dropout,Activation,Flatten</span></span><br><span class="line"><span class="comment"># cnn layer</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Convolution2D,MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils <span class="comment"># useful to transfrom data</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint <span class="comment"># save model</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> callbacks</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="comment"># prepare data</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">print(x_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="comment">#plt.imshow(x_train[0])</span></span><br><span class="line"><span class="comment"># tensorflow input(HxWxC)</span></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>],<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">x_test  = x_test.reshape(x_test.shape[<span class="number">0</span>],<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train = x_train.astype(<span class="string">'float32'</span>) /<span class="number">255</span></span><br><span class="line">x_test = x_test.astype(<span class="string">'float32'</span>) /<span class="number">255</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(x_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line"><span class="comment"># convert label to one hot</span></span><br><span class="line">print(y_train[:<span class="number">10</span>])</span><br><span class="line">y_train = np_utils.to_categorical(y_train,<span class="number">10</span>)</span><br><span class="line">y_test  = np_utils.to_categorical(y_test,<span class="number">10</span>)</span><br><span class="line">print(y_train[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">### define model</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 32,3,3 : output channel ,kernel_size</span></span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,activation = <span class="string">'relu'</span>,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line">print(model.output_shape)</span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size = (<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">### define loss and optimizer,and then compile it</span></span><br><span class="line">model.compile(loss = <span class="string">'categorical_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment">#print(model.get_config())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># callback，when a epoch/batch_size start/end,it will be called</span></span><br><span class="line">checkpointer  = ModelCheckpoint(filepath=<span class="string">'best_model.h5'</span>,verbose=<span class="number">1</span>,save_best_only=<span class="keyword">True</span>)</span><br><span class="line">earlyStopping = callbacks.EarlyStopping(monitor=<span class="string">'loss'</span>,patience=<span class="number">20</span>,verbose=<span class="number">1</span>,mode = <span class="string">'auto'</span>)</span><br><span class="line">reduce_lr     = callbacks.ReduceLROnPlateau(monitor=<span class="string">'loss'</span>,factor = <span class="number">1</span>/math.e,verbose=<span class="number">1</span>,patience=<span class="number">10</span>,min_lr=<span class="number">0.0001</span>)</span><br><span class="line">tensorboard   = callbacks.TensorBoard(log_dir=<span class="string">'./log'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># write log to csv</span></span><br><span class="line">csv_historyger = callbacks.CSVLogger(<span class="string">'training.history'</span>,separator=<span class="string">','</span>,append=<span class="string">'True'</span>)</span><br><span class="line"><span class="comment">### feed data to the network</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#print('exist model')</span></span><br><span class="line"><span class="comment">#del model</span></span><br><span class="line"><span class="comment">#print('loading model ...')</span></span><br><span class="line"><span class="comment">#model = load_model('./best_model.h5')</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x_train,y_train,batch_size=<span class="number">32</span>,epochs=<span class="number">2</span>,verbose=<span class="number">1</span>,validation_data=(x_test,y_test),callbacks = [checkpointer,earlyStopping,reduce_lr,tensorboard,csv_historyger])</span><br><span class="line"></span><br><span class="line">score = model.evaluate(x_test,y_test,verbose=<span class="number">0</span>)</span><br><span class="line">print(score)</span><br><span class="line">print(history.history)</span><br><span class="line">print(history.epoch)</span><br><span class="line">print(history.history[<span class="string">'val_loss'</span>])</span><br></pre></td></tr></table></figure><p>数据读取部分主要读取csv文件的image name，以及annotation。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RetinaNet 原理记录</title>
      <link href="/2019/05/16/RetinaNet-%E5%8E%9F%E7%90%86%E8%AE%B0%E5%BD%95/"/>
      <url>/2019/05/16/RetinaNet-%E5%8E%9F%E7%90%86%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>RetinaNet作为一个one stage 的检测算法，通过对图片进行网格划分。在每个feature上选取anchor，然后对这些anchor进行边框回归以及类别的回归。</p><a id="more"></a><p>RetinaNet和大多数的one stage算法相同，直接对图片进行边框的回归，这导致了在一开始回归的时候，算法产生了大量的anticipate anchor（two stage 算法产生anchor的方式是通过region proposal的方式产生1k～2k的边框），这些anchor大部分都不包含object，即作者提到的easy negativate。 因此anchor导致了正负样本的不均衡。</p><p>正负样本不均衡主要有以下两个问题：</p><ol><li>在网络进行训练时，一些easy negativate 样本对loss不起作用，网络收敛速度很慢。</li><li>由于存在大量的easy negativate 样本，因此在loss回归的过程，easy negativate样本将会覆盖掉真正有益的收敛方向，导致模型精度下降。</li></ol><p>基于上面的分析，作者提出了一种对新型的loss，这种loss能够对不同的easy，hard样本进行权重的赋值。使得loss更加倾向于学习一些hard样本。</p><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>focal loss 由标准的cross entropy loss 演化而来，为了简单期间，我们从二分类的cross entropy入手，开始介绍：</p><p><img src="/images/article/ce.png" alt=""></p><p>从上面的loss可以看出来，当一个样本为正样本时，其预测值越高，CE loss就越小。但是这个loss对所有的anchor都同等对待，当一些样本p很大或很小的时候，基本可以断定它的类别，这些样本对边框回归，类别分类的时候，起到很小的作用，因此需要被忽略，但是CE loss无法突出这一点，因此RetinaNet的focal loss就是为了解决这个问题提出来的。</p><p><img src="/images/article/focal-loss.png" alt=""></p><p>当p很大时，即可以轻松判断这个anchor的类别的时候，1-p将取得一个较小的值，通过前面的参数，可以大大减小其对loss的影响。即降低了对简单样本的权重，同样的，对于难分样本来说，loss的形式可以增加其在loss中的权重。</p><h3 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h3><p>RetinaNet是作者为了验证这个loss的有效性而提出的。RetinaNet主要由一个resnet作为backbone，分类部分使用了FPN，特征金字塔的形式进行特征的分类。它的网络结构如下如所示：</p><p><img src="/images/article/retina-frame.png" alt=""></p><p>事实上，RetinaNet最终输出了五层feature map，在这五层feature map进行anchor的选取。</p><p>首先由Resnet 最后的三层C3，C4，C5产生P3，P4，P5，然后在C5的后面接着生成了P6，P7。</p><p>由于不方便画图，放一下keras retinanet的代码：<a href="https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/models/retinanet.py" target="_blank" rel="noopener">github</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__create_pyramid_features</span><span class="params">(C3, C4, C5, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Creates the FPN layers on top of the backbone features.</span></span><br><span class="line"><span class="string">    Args</span></span><br><span class="line"><span class="string">        C3           : Feature stage C3 from the backbone.</span></span><br><span class="line"><span class="string">        C4           : Feature stage C4 from the backbone.</span></span><br><span class="line"><span class="string">        C5           : Feature stage C5 from the backbone.</span></span><br><span class="line"><span class="string">        feature_size : The feature size to use for the resulting feature levels.</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">        A list of feature levels [P3, P4, P5, P6, P7].</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C5_reduced'</span>)(C5)</span><br><span class="line">    P5_upsampled = layers.UpsampleLike(name=<span class="string">'P5_upsampled'</span>)([P5, C4])</span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P5'</span>)(P5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C4_reduced'</span>)(C4)</span><br><span class="line">    P4           = keras.layers.Add(name=<span class="string">'P4_merged'</span>)([P5_upsampled, P4])</span><br><span class="line">    P4_upsampled = layers.UpsampleLike(name=<span class="string">'P4_upsampled'</span>)([P4, C3])</span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P4'</span>)(P4)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C3_reduced'</span>)(C3)</span><br><span class="line">    P3 = keras.layers.Add(name=<span class="string">'P3_merged'</span>)([P4_upsampled, P3])</span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P3'</span>)(P3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P6 is obtained via a 3x3 stride-2 conv on C5"</span></span><br><span class="line">    P6 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P6'</span>)(C5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6"</span></span><br><span class="line">    P7 = keras.layers.Activation(<span class="string">'relu'</span>, name=<span class="string">'C6_relu'</span>)(P6)</span><br><span class="line">    P7 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P7'</span>)(P7)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [P3, P4, P5, P6, P7]</span><br></pre></td></tr></table></figure><h3 id="anchor的设置"><a href="#anchor的设置" class="headerlink" title="anchor的设置"></a>anchor的设置</h3><p>在设置anchor的时候，作者选用了一下几种设置：</p><p>anchor-size = [32, 64, 128, 256, 512] 对应P3～P7</p><p>anchor—scale = [2 xx0 ，2 xx(1/3 )，2 xx (2/3)]</p><p>anchor-wh = [1:2 ，1 ，2:1]</p><p>每一层anchor的大小为anchor-size 乘以 anchor-scale。然后使用三种长宽比，每一层，每一个位置得到九种大小的anchor。随后对这些位置的anchor进行边框回归以及类别的回归。</p><h3 id="Loss-的形式以及计算"><a href="#Loss-的形式以及计算" class="headerlink" title="Loss 的形式以及计算"></a>Loss 的形式以及计算</h3><p>稍后补充</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 张量操作</title>
      <link href="/2019/05/12/pytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/"/>
      <url>/2019/05/12/pytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>在编写网络，传入传出数据时，对数据的维度的操作，把握是很重要的，因此这篇文章介绍一下pytorch在数据维度的改变上的一些方法。</p><a id="more"></a><p>对于两个数组来说，融合方式有很多种，最常见的是沿着横向融合以及沿着纵向融合。在方法的参数体现上：</p><blockquote><p>dim = 0 ：数据沿着纵向融合。</p><p>dim = 1： 数据沿着横向融合。</p></blockquote><p><em>torch.cat()</em></p><p>torch.cat 方法对数据沿着不同方向进行如何，dim参数决定了融合的方向，需要注意的是需要<strong>融合方向上维度需要一致</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((a,b),<span class="number">0</span>) <span class="comment"># 纵向</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((a,b),<span class="number">1</span>) <span class="comment"># 横向</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br></pre></td></tr></table></figure><p><em>torch.view()</em></p><p>torch.view 在保证数组个数不变的前提下，任意改变数组的形状（需要注意的是 -1参数表明在满足其他维度大小的需求后，该维度的大小）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">3</span>,<span class="number">-1</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.view(<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br></pre></td></tr></table></figure><p><em>torch.squeeze()</em></p><p>压缩维度，使得为1的维度塌陷，维度缩减方向为dim = 0纵向，dim=1横向：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.squeeze(b,dim = <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.squeeze(b,dim = <span class="number">0</span>) <span class="comment">#纵向</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.shape</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p><em>torch.Tensor.narrow()</em></p><p>删除元素的维度缩减方式，<code>torch.Tensor.narrow(dim,start,length)</code>,dim表示缩减的方向（0，1），start表示起始的位置，length表示保留维度的长度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">5.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.narrow(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">5.</span>, <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure><p><em>torch.Tensor.permute()</em></p><p>张量维度之间的顺序调换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">5.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">5.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIT</title>
      <link href="/2019/05/06/GIT/"/>
      <url>/2019/05/06/GIT/</url>
      
        <content type="html"><![CDATA[<p>github本质上是一个存储代码的工具，如果你暂时没有这个需求的话，其实可以不用在意这个东西，但是如果你在开发一个项目，希望将代码存在云上，并且实时更新与本地一致，那么github以及git操作就显得很重要了。（以上全是废话，ps：第一次以对话的方式写博客有点🦢慌）</p><p>下面教程从github上创建一个repository开始，重复一下比较常用的重要的git步骤 👇</p><a id="more"></a><h3 id="创建repository"><a href="#创建repository" class="headerlink" title="创建repository"></a>创建repository</h3><p>手动上github官网，可视化方式创建一个repository，并添加上REMEAD.md等。由于我正在做深度学习作业，因此下面都将以DL_HW repository为例。</p><h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><p><code>git clone git@github.com:WenHui-Zhou/DL_HW.git</code></p><p>通过上面语句将项目clone到本地（前提是安装了git）。然后接下来所有操作都将在这个DL_HW文件夹下进行操作。 </p><h3 id="添加-gitignore"><a href="#添加-gitignore" class="headerlink" title="添加.gitignore"></a>添加.gitignore</h3><p><code>.gitignore</code> 文件是用来告诉git什么文件不需要上传，比如你写了一个深度学习的作业，其中用到的数据集图片，就可以不需要上传。例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tmp       # 忽略文件夹</span><br><span class="line">*.jpg     # 忽略文件</span><br><span class="line">.DS_Store</span><br></pre></td></tr></table></figure><p>关于<code>.gitignore</code>还有很多灵活的用法，但是我是二八原则的拥护者，留下个链接表示一下：<a href="http://www.chengxusheji.com/archives/121.html" target="_blank" rel="noopener">gitignore 用法</a></p><h3 id="add-and-commit"><a href="#add-and-commit" class="headerlink" title="add  and commit"></a>add  and commit</h3><p>本地的git维护着三棵树，第一个是工作目录，即本地的DL_HW。第二个是缓冲区index，临时保存改动，第三个是head，保存最后一次的提交结果。</p><p><img src="/images/trick/git.png" alt="git"></p><p><code>git add *</code> : 将所有修改添加到index中去，保存零时改动。比如刚刚写了一个<code>.gitignore</code>文件，这条指令把它添加到index 上。</p><p><code>git commit -m &quot;代码提交信息&quot;</code>：将index中保存的改动提交到head上去。</p><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>前一步的操作仅仅是在本地进行的，并没有将代码真正的更新到GitHub上</p><p><code>git push origin master</code>： 将head上的改动提交到master分支上，也可以换成其他分支。</p><h3 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h3><p>老实说现在用不到，留着以后补充</p><h3 id="some-tip"><a href="#some-tip" class="headerlink" title="some tip"></a>some tip</h3><p>1.Git clone的时候会clone下来所有的历史内容，可以限制仅仅clone最近改动后的版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:WenHui-Zhou/DL_HW.git --depth=1</span><br></pre></td></tr></table></figure><p>2.当有多个机子clone了相同的项目，要保证本地的代码为最新的，需要如下操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master(分支可改)</span><br></pre></td></tr></table></figure><h3 id="last"><a href="#last" class="headerlink" title="last"></a>last</h3><p>分享一个很不错的 <a href="http://www.bootcss.com/p/git-guide/" target="_blank" rel="noopener">教程链接</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dog and cat -- USE tf.contrib.slim</title>
      <link href="/2019/05/06/dog-and-cat-USE-tf-contrib-slim/"/>
      <url>/2019/05/06/dog-and-cat-USE-tf-contrib-slim/</url>
      
        <content type="html"><![CDATA[<p>深度学习作业之一：猫狗分类。使用tensorflow的一个轻量级的库 <code>tf.contrib.slim</code>实现。</p><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>猫狗分类的数据可以从gaggle官网中下载：<a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" rel="noopener">数据链接</a></p><p>解压后发现文件分为train和val，但并没有label，它的label通过文件名来区分。</p><h4 id="将下载下来的猫狗图片转化为tfrecord格式"><a href="#将下载下来的猫狗图片转化为tfrecord格式" class="headerlink" title="将下载下来的猫狗图片转化为tfrecord格式"></a>将下载下来的猫狗图片转化为tfrecord格式</h4><p><strong><u>tf.record: 二进制格式文件</u></strong></p><blockquote><p>To read data efficiently it can be helpful to serialize your data and store it in a set of files (100-200MB each) that can each be read linearly. This is especially true if the data is being streamed over a network. This can also be useful for caching any data-preprocessing.</p><p>The TFRecord format is a simple format for storing a sequence of binary records.</p></blockquote><p>tensorflow使用其Dataset API来管理数据，将数据直接放在graph中进行处理，整体对数据集进行上述数据操作，使代码更加简洁。将图片，label转化为tf.record格式，方便大数据集的分批，快速读取，同时在进行数据预处理时简化代码，加快处理速度。</p><p>TFRecord 的核心内容在于内部有一系列的 Example ，Example 是 protocolbuf 协议下的消息体。定义了你需要的数据集的信息。</p><p><u><strong>protocolbuf：</strong></u></p><p><code>protocolbuf</code>是 <code>Google</code>出品的一种轻量 &amp; 高效的结构化数据存储格式，具体介绍可以看 <a href="https://www.jianshu.com/p/1538bf85dad1" target="_blank" rel="noopener">这里</a></p><p>即通过将结构化的数据进行<strong>序列化</strong>(转为二进制)，更小更易于维护。</p><p><strong>因此这一部分的目的就是将猫狗的数据，以及对应的label，重新生成为tf.record格式文件，随后使用tensorflow提供的API进行数据的读取。</strong></p><p>ps:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    filename = <span class="string">"%05d.txt"</span> % i</span><br><span class="line">    open(filename, <span class="string">"w"</span>)</span><br></pre></td></tr></table></figure><p>上面代码命名文件时，i长度不足10000时前面补0，保证长度为5。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux配置环境</title>
      <link href="/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
      <url>/2019/04/24/linux%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<p>linux 环境配置是一个很重要又很烦人的过程，下面简要记录一下环境变量配置的方法与原则。</p><h3 id="系统配置文件的加载顺序"><a href="#系统配置文件的加载顺序" class="headerlink" title="系统配置文件的加载顺序"></a>系统配置文件的加载顺序</h3><p>登入linux并启动一个bash shell，默认情况下这时候系统将会去寻找环境变量的设置文件，为环境变量赋值。系统环境文件读取顺序如下：</p><p><img src="/images/trick/linux_set.png" alt=""></p><p>用户登录系统后首先会加载<code>/etc/profile</code>全局环境变量文件，这是Linux系统上默认的shell主环境变量文件。系统上每个用户登录后都会加载这个文件。</p><p>之后执行<code>/etc/profile.d</code>目录下的所有脚本文件，完成一些字体，颜色的设置</p><p>之后开始运行<code>～/.bash_profile</code>(用户环境变量文件)，在这个文件中，又会去找<code>$~/.bashrc</code>（用户环境变量文件） 。在<code>$～/.bashrc</code>文件中又会去找<code>/etc/bashrc</code>（全局环境变量文件），若没有则不执行。</p><p>对于Vim的配置来说，在vim开启的时候将会对其进行一些基础的配置。全局配置一般在<code>/etc/vim/vimrc</code>或者<code>/etc/vimrc</code>，对所有用户生效。用户个人的配置在<code>~/.vimrc</code>，打开vim时自动执行。</p><h3 id="linux-bash查找执行的顺序"><a href="#linux-bash查找执行的顺序" class="headerlink" title="linux bash查找执行的顺序"></a>linux bash查找执行的顺序</h3><p>shell执行命令时将去linux系统中寻找指令的执行代码。寻找顺序如下</p><ol><li>别名，使用alias创建的命令</li><li>关键字，如if，for</li><li>函数</li><li>内置指令，如cd等等</li><li>外部指令，在PATH路径中寻找</li></ol><h3 id="Linux-系统目录结构"><a href="#Linux-系统目录结构" class="headerlink" title="Linux 系统目录结构"></a>Linux 系统目录结构</h3><p>​    <img src="/images/trick/content.png" alt=""></p><p>以前很多的环境变量配置不明白，就是由于不清楚linux的目录结构，以及每个文件的位置。</p><h4 id="bin"><a href="#bin" class="headerlink" title="/bin"></a>/bin</h4><p>普通用户可以使用的命令的存放目录，十分重要。例如cp，cd这种。类似的目录：/usr/bin，/usr/local/bin等等。这个目录中的文件都是可执行的。作为基础系统所需要的最基础的命令就是放在这里。</p><h4 id="lib"><a href="#lib" class="headerlink" title="/lib"></a>/lib</h4><p>此目录下包含系统引导和在根用户执行命令时候所必需用到的共享库。类似的目录还/usr/lib，/usr/local/lib。</p><h4 id="home"><a href="#home" class="headerlink" title="/home"></a>/home</h4><p>在Linux机器上，普通用户主目录通常直接或间接地置在此目录下。用户可以在自己的目录下保存仅对自己的配置文件，定制文件，文档，数据等。</p><h4 id="root"><a href="#root" class="headerlink" title="/root"></a>/root</h4><p>用户root的$HOME目录。</p><h4 id="etc"><a href="#etc" class="headerlink" title="/etc"></a>/etc</h4><p>全局的配置文件存放目录。系统和程序一般都可以通过修改相应的配置文件，来进行配置。类似的目录有 /usr/etc。用户也可以直接在HOME目录底下写配置文件，系统读取配置文件时，先读取HOME目录底下的文件，优先级最高。如果不存在配置文件的话，才去/etc下读取系统配置。</p><h3 id="usr"><a href="#usr" class="headerlink" title="/usr"></a>/usr</h3><p>安装程序的时候，默认就是安装在此文件内部某个子文件夹内。输入命令后系统默认执行/usr/bin下的程序。当然/usr/bin 需要加入PATH中。</p><h3 id="usr-local"><a href="#usr-local" class="headerlink" title="/usr/local"></a>/usr/local</h3><p>安装本地程序的一般默认路径。当我们下载一个程序源代码，编译并且安装的时候，如果不特别指定安装的程序路径，那么默认会将程序相关的文件安装到这个目录的对应目录下。例如，安装的程序可执行文件被安装(安装实质就是复制到了/usr/local/bin下面），/usr/local/include则用来存放文件。</p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>因此看到这里，环境变量的配置就是针对我们安装的第三方库，它们一般存在于/usr/下的目录中，因此PATH需要添加到/usr/的路径。此外还有一种情况，就是当安装一个库时，可能会修改掉系统的文件的软链接，导致之前系统很多库无法使用。此时的做法是在用户目录下，创建虚拟环境，在虚拟环境的进行环境的配置，将配置文件写在/home/.bashrc 等文件中即可。</p><p>上面泛泛而谈，还需要大量实践来查缺补漏。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>安装python3.7，同时保留python3.6，python2.7等：<a href="https://segmentfault.com/a/1190000015628625" target="_blank" rel="noopener">【链接】</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>shell 编程</title>
      <link href="/2019/04/10/shell-%E7%BC%96%E7%A8%8B/"/>
      <url>/2019/04/10/shell-%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>shell 编程中常见，常用的语法。</p><p>在日常Linux上编写代码，整理文件时发现，学一点shell语句能够大大加快工作效率，事不宜迟，开始学习！</p><a id="more"></a><h3 id="shell-简介"><a href="#shell-简介" class="headerlink" title="shell 简介"></a>shell 简介</h3><p>shell脚本通常是以：<code>#!/bin/bash</code> 开头的一个文件。/bin/bash是bash编译器的路径。</p><p>bash命令序列通常使用分号 <code>;</code> 或者换行符来表示。</p><p>终端的输出使用<code>echo</code> 来输出。下面是一个简单的shell脚本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo hello world</span><br></pre></td></tr></table></figure><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>shell中所有变量的类型都是<strong>字符串</strong>，且无需提前定义。此外shell中规定了一些<strong>环境变量</strong>来存储操作系统中一些特殊的值。</p><p><strong>变量的赋值：</strong> <code>val=“value”</code> ，切记等号前后没有空格。<code>val = value</code> 这种形式是判断相等的操作。</p><p>输出变量：<code>echo $val</code> 或 <code>echo ${val}</code></p><p><strong>环境变量：</strong> 定义在系统父进程中，用于系统的设置，如HTTP_PROXY用与设置代理服务器。</p><p><code>export</code> 命令可以用来设置环境变量，至此之后，shell脚本执行任何应用都会继承整个变量。</p><p>最常用接触到的环境变量为PATH，PATH变量通常包含以下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $PATH</span><br><span class="line">/home/zhouwenhui/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr /games</span><br></pre></td></tr></table></figure><p>PATH中路径根据 <code>:</code>  做为分割符，每当用户执行一条指令时，linux根据PATH中路径从前往后寻找可执行文件。PATH通常定义在 <code>/etc/environment</code> 或 <code>/etc/profile</code> 系统层次，或 <code>~/.bashrc</code> 这种用户层次上。可以通过一下方式，增加寻找的路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH="$PATH:/new/folder"</span><br></pre></td></tr></table></figure><p>补充trick：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat a.txt | tr 'replace' 'value'</span><br></pre></td></tr></table></figure><p>将输出中的replace替换成value。</p><p>字符串长度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var=1234</span><br><span class="line">length=$&#123;#var&#125;</span><br></pre></td></tr></table></figure><p><code>UID</code> 是用户类型的一个标示，root用户的UID是0.</p><h3 id="shell-数学计算"><a href="#shell-数学计算" class="headerlink" title="shell 数学计算"></a>shell 数学计算</h3><p><code>let</code> 语句可以直接执行基本的算术操作，在变量名前不需要添加$.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">no1=4;</span><br><span class="line">no2=5;</span><br><span class="line">let result=no1+no2</span><br><span class="line">let no1++;</span><br><span class="line">let no1--;</span><br><span class="line">let no1+=1</span><br></pre></td></tr></table></figure><p>操作符[ ] 使用方法与let类似：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result=[ $no1 + no2 ];</span><br></pre></td></tr></table></figure><p>上诉的指令只能用来进行整数操作，浮点数操作将使用到bc工具包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt; <span class="built_in">echo</span> <span class="string">"4 * 0.56"</span> | bc</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt; 2.24</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;result=<span class="string">'echo "$no1 * 1.5"|bc'</span></span></span><br></pre></td></tr></table></figure><h3 id="文件描述以及重定向"><a href="#文件描述以及重定向" class="headerlink" title="文件描述以及重定向"></a>文件描述以及重定向</h3><p>将输出内容保存到temp.txt中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "this string will be save" &gt; temp.txt</span><br></pre></td></tr></table></figure><p>追加内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "add to the file temp" &gt;&gt; temp.txt</span><br></pre></td></tr></table></figure><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr=(1,2,3,4,5,6)</span><br></pre></td></tr></table></figure><h3 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias new_command = 'command sequence'</span><br></pre></td></tr></table></figure><p>直接写入配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 'alias cmd="command seq"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function fname()</span><br><span class="line">&#123;</span><br><span class="line">    statements;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 调用</span></span><br><span class="line">fname; # 执行</span><br><span class="line"><span class="meta">#</span><span class="bash">传递参数</span></span><br><span class="line">fname arg1,arg2;</span><br><span class="line"></span><br><span class="line">fname()</span><br><span class="line">&#123;</span><br><span class="line">  echo $1; # 第一个参数</span><br><span class="line">  echo $2; # 第二个参数</span><br><span class="line">  echo $@; # 所有参数，"$1" "$2" ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for var in list;</span><br><span class="line">do</span><br><span class="line">    command</span><br><span class="line">done;</span><br></pre></td></tr></table></figure><h3 id="while-循环"><a href="#while-循环" class="headerlink" title="while 循环"></a>while 循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while condition;</span><br><span class="line">do</span><br><span class="line">    command</span><br><span class="line">done;</span><br></pre></td></tr></table></figure><h3 id="util语句"><a href="#util语句" class="headerlink" title="util语句"></a>util语句</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x=0;</span><br><span class="line">until [ $x -eq 9 ];</span><br><span class="line">do</span><br><span class="line">    let x++;</span><br><span class="line">    echo $x;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="逻辑运算，简短比较"><a href="#逻辑运算，简短比较" class="headerlink" title="逻辑运算，简短比较"></a>逻辑运算，简短比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ condition ] &amp;&amp; action; # 若condition成立则执行action</span><br><span class="line">[ condition ] || action; # 若condition不成立，则执行action</span><br></pre></td></tr></table></figure><h3 id="比较与测试"><a href="#比较与测试" class="headerlink" title="比较与测试"></a>比较与测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if condition;</span><br><span class="line">then</span><br><span class="line">    commands;</span><br><span class="line">else if condition; then;</span><br><span class="line">    commands;</span><br><span class="line">else</span><br><span class="line">    commands;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="算术比较"><a href="#算术比较" class="headerlink" title="算术比较"></a>算术比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ $var -eq 0 ] # 判断是否相同</span><br><span class="line">[ $var -ne 0 ] # 当var非0时为真</span><br></pre></td></tr></table></figure><ul><li>-gt：大于</li><li>-lt：小于</li><li>-ge：大于或等于</li><li>-le：小于或等于</li></ul><p>结合多个条件测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ $var1 -ne 0 -a $var2 -gt 2 ] # 使用逻辑与-a</span><br><span class="line">[ $var1 -ne 0 -o $var2 -gt 2 ] # 逻辑或 -o</span><br></pre></td></tr></table></figure><h3 id="文件属性测试"><a href="#文件属性测试" class="headerlink" title="文件属性测试"></a>文件属性测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ -f $file_name ] file_name是一个正常的文件</span><br><span class="line">[ -x $var ] var 是可执行文件</span><br><span class="line">[ -d $var ] var是目录</span><br><span class="line">[ -e $var ] var是文件</span><br><span class="line">[ -w $var ] var为可写文件</span><br><span class="line">[ -r $var ] var为可读文件</span><br></pre></td></tr></table></figure><h3 id="字符串的比较"><a href="#字符串的比较" class="headerlink" title="字符串的比较"></a>字符串的比较</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[ $str1 = $str2 ]] # 字符串比较最好放在双中括号中，判断相等</span><br><span class="line">[[ $str1 &gt; $str2 ]] # 判断字符串大小</span><br><span class="line">[[ -z $str1 ]]      # 字符串为空则为真</span><br><span class="line">[[ -n $str1 ]]      # 字符串非空则为真</span><br><span class="line">if [[ -n $str1 ]] || [[ -z $str2 ]];</span><br><span class="line">then</span><br><span class="line">    echo 'something'</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="执行Linux指令"><a href="#执行Linux指令" class="headerlink" title="执行Linux指令"></a>执行Linux指令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a=$(ls)</span><br><span class="line">for file in $a;</span><br><span class="line">do</span><br><span class="line">    if [ -f $file ];</span><br><span class="line">    then</span><br><span class="line">        echo 'afile'</span><br><span class="line">    else</span><br><span class="line">        echo 'not file'</span><br><span class="line">    fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="cat-拼接"><a href="#cat-拼接" class="headerlink" title="cat 拼接"></a>cat 拼接</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat file1 file2 file3</span><br><span class="line">cat -s file # 输出过滤掉多余的空行</span><br><span class="line">cat -T file # 显示制表符</span><br><span class="line">cat -n file # 显示行号</span><br></pre></td></tr></table></figure><h3 id="文件查找find"><a href="#文件查找find" class="headerlink" title="文件查找find"></a>文件查找find</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">find base_path # 找出所有bash_path 底下的所有文件名</span><br><span class="line">find . -name 'car*' # 找含特定字符的文件</span><br><span class="line">find . \( -name "*.txt" -o -name "*.pdf" \) # 匹配多个</span><br><span class="line">find /home/ -path "*/slynux/*" # 匹配路径以及文件名</span><br><span class="line">find . ! -name '*.txt' # 不找txt结尾的</span><br><span class="line">find . -maxdepth 1 -name 'f*' # 深度为1，只找当前目录</span><br><span class="line">find . -type d #将所有目录输出来 f为普通文件，l为软链接</span><br><span class="line">find . -type f -name "*.swp" -delete # 删除匹配的文件</span><br></pre></td></tr></table></figure><h3 id="find选项-exec-与其他指令结合使用"><a href="#find选项-exec-与其他指令结合使用" class="headerlink" title="find选项-exec 与其他指令结合使用"></a>find选项-exec 与其他指令结合使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -name <span class="string">".c"</span> -<span class="keyword">exec</span> &#123;&#125;\; <span class="comment">#&#123;&#125;将匹配所有的文件，然后执行</span></span><br><span class="line">find . -type f -name <span class="string">".jpg"</span> -<span class="keyword">exec</span> cp &#123;&#125; ./file/ \;<span class="comment"># 拷贝</span></span><br></pre></td></tr></table></figure><h3 id="玩转-xargs"><a href="#玩转-xargs" class="headerlink" title="玩转 xargs"></a>玩转 xargs</h3><p>xargs以标准的输入作为主要的数据流：<code>command| xargs</code>。xargs从stdin接收到的数据重新格式化，将其作为参数提供给其他指令。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VOC 数据集</title>
      <link href="/2019/04/09/VOC-%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2019/04/09/VOC-%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>本篇文章介绍VOC数据集的格式以及将CSV标注转化成CSV格式文件的方法。</p><a id="more"></a><h3 id="VOC-数据集"><a href="#VOC-数据集" class="headerlink" title="VOC 数据集"></a>VOC 数据集</h3><p>VOC 数据集可以从<a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="noopener">官网</a>下载，通常有</p><p>train： VOCtrainval_11-May-2012.tar，VOCtrainval_06-Nov-2007.tar</p><p>test：VOCtest_06-Nov-2007.tar</p><p>解压后得到的文件目录结构如下：</p><p>VOCDevkit:</p><ul><li>Annotations：存放着图片类别以及box信息,一张图片对应一个xml文件</li><li>ImageSets：里头有几个文件夹，目标检测问题只要关注Main，里头将保存训练集，测试集的图片名，用txt文件进行保存。</li><li>JPEGImages：保存着数据集图片</li><li>SegmentationClass</li><li>SegmentationObject</li></ul><p>对于目标检测问题关注以上三个文件夹就可以了。</p><hr><h3 id="将scv文件转化为voc格式"><a href="#将scv文件转化为voc格式" class="headerlink" title="将scv文件转化为voc格式"></a>将scv文件转化为voc格式</h3><p>csv格式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_url,x1,y1,x2,y2,label</span><br></pre></td></tr></table></figure><p>且同一张图片由于可能会有多个框，所以会有多条记录，代码需要完成图片的软链接建立，图片的命名，并建立新名字的txt文件，包括train和text。同时生成每张图片的xml。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> traceback <span class="keyword">import</span> print_exc</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_anno_xml</span><span class="params">(img,annos)</span>:</span></span><br><span class="line">    anno_folder = <span class="string">"./Annotations"</span></span><br><span class="line">    im = Image.open(<span class="string">'./JPEGImages/'</span> + img)</span><br><span class="line">    width, height = im.size</span><br><span class="line"></span><br><span class="line">    xml_file = open((anno_folder + <span class="string">'/'</span> + img.split(<span class="string">'.'</span>)[<span class="number">0</span>] + <span class="string">'.xml'</span>), <span class="string">'w'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'&lt;annotation&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;filename&gt;'</span> + img + <span class="string">'&lt;/filename&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;folder&gt;cartoon_VOC&lt;/folder&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;size&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;width&gt;'</span> + str(width) + <span class="string">'&lt;/width&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;height&gt;'</span> + str(height) + <span class="string">'&lt;/height&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'        &lt;depth&gt;3&lt;/depth&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'    &lt;/size&gt;\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> anno <span class="keyword">in</span> annos:</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;object&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;name&gt;'</span> + anno[<span class="number">-1</span>] + <span class="string">'&lt;/name&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;pose&gt;Unspecified&lt;/pose&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;truncated&gt;0&lt;/truncated&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;difficult&gt;0&lt;/difficult&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmin&gt;'</span> + anno[<span class="number">0</span>] + <span class="string">'&lt;/xmin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymin&gt;'</span> + anno[<span class="number">1</span>] + <span class="string">'&lt;/ymin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmax&gt;'</span> + anno[<span class="number">2</span>] + <span class="string">'&lt;/xmax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymax&gt;'</span> + anno[<span class="number">3</span>] + <span class="string">'&lt;/ymax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;/bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;/object&gt;\n'</span>)</span><br><span class="line">    xml_file.write(<span class="string">'&lt;/annotation&gt;'</span>)</span><br><span class="line">    xml_file.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> [<span class="string">'train'</span>,<span class="string">'test'</span>]:</span><br><span class="line">    ftxt = open(file_name+<span class="string">'.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">    <span class="keyword">with</span> open(file_name+<span class="string">'_dataset.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        reader = csv.reader(f)</span><br><span class="line">        img     = <span class="string">''</span></span><br><span class="line">        pre_img = <span class="string">''</span></span><br><span class="line">        annos  = []</span><br><span class="line">        reader = list(reader)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> reader:</span><br><span class="line">            <span class="keyword">if</span> img != line[<span class="number">0</span>] <span class="keyword">and</span> img != <span class="string">''</span>:</span><br><span class="line">                <span class="comment"># ceate soft link</span></span><br><span class="line">                pos = line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>].find(<span class="string">'.'</span>)</span><br><span class="line">                img_id = <span class="string">'0'</span>*(<span class="number">5</span>-len(str(count)))+str(count)</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    os.symlink(line[<span class="number">0</span>],<span class="string">'JPEGImages/'</span>+img_id+line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>][pos:])</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    print(e.__class__.__name__)</span><br><span class="line">                    print_exc()</span><br><span class="line">                ftxt.write(img_id+<span class="string">'\n'</span>)</span><br><span class="line">                write_anno_xml(img_id+line[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>][pos:],annos)</span><br><span class="line">                img   = line[<span class="number">0</span>] </span><br><span class="line">                annos.clear()</span><br><span class="line">                annos.append(line[<span class="number">1</span>:])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                img   = line[<span class="number">0</span>]</span><br><span class="line">                annos.append(line[<span class="number">1</span>:])</span><br><span class="line">            sys.stdout.write(<span class="string">'&#123;&#125;/&#123;&#125;\r'</span>.format(count,len(reader)))</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">    ftxt.close()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 基本语法</title>
      <link href="/2019/03/29/pytorch-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/"/>
      <url>/2019/03/29/pytorch-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>本篇文章将记录pytorch使用过程中的一些值得记录的trick。</p><a id="more"></a><h3 id="pytorch-基本工作流"><a href="#pytorch-基本工作流" class="headerlink" title="pytorch 基本工作流"></a>pytorch 基本工作流</h3><p>【0】引入必要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>【1】准备数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor(<span class="number">1.</span>,requires_grad=<span class="keyword">True</span>)</span><br><span class="line">x = torch.randn(<span class="number">10</span>,<span class="number">3</span>) <span class="comment"># 10*3的矩阵</span></span><br><span class="line">y = torch.randn(<span class="number">10</span>,<span class="number">2</span>) <span class="comment"># 10*2</span></span><br></pre></td></tr></table></figure><p>【2】网络搭建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义网络层，网络输入输出参数等等，下面使用pytorch内置的函数</span></span><br><span class="line"></span><br><span class="line">linear = nn.Linear(<span class="number">3</span>,<span class="number">2</span>) <span class="comment"># 搭建一个输入channel为3，输出channel为2的全连接网络</span></span><br><span class="line">print(linear.weight)    <span class="comment"># torch以及替我们定义好了参数</span></span><br><span class="line">print(linear.bias)</span><br></pre></td></tr></table></figure><p>【3】损失函数以及优化器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = nn.optim.SGD(linear.parameters(),lr = <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><p>【4】网络正向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred = linear(x)</span><br><span class="line"><span class="comment"># 计算loss</span></span><br><span class="line">loss = criterion(pred,y)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><p>这一点和tensorflow很不一样，tensorflow要先搭建好整个网络，然后将数据feed进去，pytorch则是动态构建网络图，边搭建网络边进行传值。</p><p>【5】网络后向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 后向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line">print(<span class="string">'dl/dw'</span>,linear.weight.grad)</span><br><span class="line">print(<span class="string">'dl/db'</span>,linear.bias.grad)</span><br><span class="line"><span class="comment"># 使用optimizer的方式更新参数</span></span><br><span class="line">optimizer.step() <span class="comment"># 一次更新参数</span></span><br><span class="line"></span><br><span class="line">pred = linear(x)</span><br><span class="line">loss = criterion(pred,y) <span class="comment">## 重复上诉步骤直到完成参数拟合</span></span><br></pre></td></tr></table></figure><h3 id="torch与numpy相互转化"><a href="#torch与numpy相互转化" class="headerlink" title="torch与numpy相互转化"></a>torch与numpy相互转化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">4</span>]]) <span class="comment"># numpy.array</span></span><br><span class="line">y = torch.from_numpy(x)     <span class="comment"># torch.tensor</span></span><br><span class="line">z = y.numpy()               <span class="comment"># tensor to numpy</span></span><br></pre></td></tr></table></figure><h3 id="torch-导入数据的pipline（流程）"><a href="#torch-导入数据的pipline（流程）" class="headerlink" title="torch 导入数据的pipline（流程）"></a>torch 导入数据的pipline（流程）</h3><p>torchvision是torch中一个用于 <strong>生成图片，数据集，模型类，欲训练模型</strong>的包。它主要包含一下几个部分：</p><ol><li><strong>torchvision.datasets</strong>:  用于导入一些比较流行的开源数据集（cifar等）</li><li><strong>torchvision.models</strong>: 包含了很多流行的网络框架，包括alexnet，VGG，resnet，以及一下欲训练模型</li><li><strong>torchvision.transforms</strong>: 定义了一些常用的数据预处理的函数，如random crop，rotate等等</li><li><strong>torchvision.utils</strong>: 里头定义了很多好用的函数，如保存图片等</li></ol><h3 id="torchvision-datasets-的使用"><a href="#torchvision-datasets-的使用" class="headerlink" title="torchvision.datasets 的使用"></a>torchvision.datasets 的使用</h3><p>下载，导入数据，以及按一定的batch取出数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get the dataset</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">'.'</span>,train=<span class="keyword">True</span>,transform=torchvision.transforms.toTensor(),download = <span class="keyword">True</span>)</span><br><span class="line">image,label = train_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">loader = torch.utils.data.Dataloader(dataset = train_data,batch_size = <span class="number">64</span>,shuffle=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment">#每次load 一个大小为64的batch的数据</span></span><br><span class="line">train_iter = iter(loader)</span><br><span class="line">image,label = train_iter.next()</span><br></pre></td></tr></table></figure><h3 id="pytorch-训练minist数据集中的一些方法"><a href="#pytorch-训练minist数据集中的一些方法" class="headerlink" title="pytorch 训练minist数据集中的一些方法"></a>pytorch 训练minist数据集中的一些方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 读取数据</span></span><br><span class="line">train = torchvision.datasets.MNIST(root=<span class="string">'./'</span>,train=<span class="keyword">True</span>,transform=torchvision.transforms.ToTensor(),download = <span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># data loader</span></span><br><span class="line">data_loader = torch.utils.data.DataLoader(dataset = train,batch_size = <span class="number">100</span>,shuffle = <span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">for</span> image,label <span class="keyword">in</span> data_loader:</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> num_epoch:</span><br><span class="line">  <span class="keyword">for</span> i ,(image,label) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    output = model(image.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">    loss = criterion(output,label)</span><br><span class="line">    optimizer.zero_grad()  <span class="comment">#切记，在计算导数前要将导数置零</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> i+<span class="number">1</span> == <span class="number">100</span>:</span><br><span class="line">      print(<span class="string">'epoch:&#123;&#125;/&#123;&#125;,step:&#123;&#125;/&#123;&#125;,loss:&#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>,num_epochs,i+<span class="number">1</span>,total_step,loss))</span><br></pre></td></tr></table></figure><h4 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不算梯度</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  correct = <span class="number">0</span></span><br><span class="line">  total = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> image,label <span class="keyword">in</span> val_loader:</span><br><span class="line">    output = model(image.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">    _,predict = torch.max(output.data,<span class="number">1</span>)</span><br><span class="line">    total+= label.size(<span class="number">0</span>)</span><br><span class="line">    correct += (predict == label).sum().numpy()</span><br><span class="line">print(<span class="string">'accuracy: &#123;&#125;'</span>.format(correct/total))</span><br><span class="line">torch.save(model.state.dict,<span class="string">'model_param.ckpt'</span>)</span><br></pre></td></tr></table></figure><p>其中<code>val,index = torch.max(matrix,1)</code>，计算matrix中每一列的最大值，返回最大值以及他的下标。</p><h3 id="构建网络结构"><a href="#构建网络结构" class="headerlink" title="构建网络结构"></a>构建网络结构</h3><p>torch.nn 主要复制网络的构建，但是很多时候，torch.nn中不满足我们需要的网络，因此我们需要自己定义。<code>torch.nn</code>继承至<code>nn.Module</code>，<code>nn.Module</code>为所有网络的基类。当我们的网络类继承这个方法时，需要实现<code>__init__(),forward()</code>两个函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NerualNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,hidden_size,output_size)</span>:</span></span><br><span class="line">    super(NerualNet,self).__init__()</span><br><span class="line">    self.fc1  = nn.Linear(input_size,hidden_size)</span><br><span class="line">    self.ReLu = nn.ReLU()</span><br><span class="line">    self.fc2  = nn.Linear(hidden_size,output_size)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">    out = self.fc1(x)</span><br><span class="line">    out = self.ReLu(out)</span><br><span class="line">    out = self.fc2(out)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>调用时<code>model = NerualNet(input_size,hidden_size,output_size)</code>，每次使用<code>model(x)</code>即自动执行forward。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(in_channels,out_channels,kernel_size,stride=<span class="number">1</span>,padding=<span class="number">0</span>,dilation=<span class="number">1</span>,groups=<span class="number">1</span>,bias=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="构建一个sequence"><a href="#构建一个sequence" class="headerlink" title="构建一个sequence"></a>构建一个sequence</h3><p>sequence 将在其中的网络层从上到下连接上一层的输出作为下一层的输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of using Sequential</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># Example of using Sequential with OrderedDict</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">'conv1'</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">'relu1'</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">'conv2'</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">'relu2'</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure><h3 id="图片预处理集合"><a href="#图片预处理集合" class="headerlink" title="图片预处理集合"></a>图片预处理集合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Image preprocessing modules</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Pad(<span class="number">4</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor()])</span><br></pre></td></tr></table></figure><p>其中transforms.ToTensor()将 PIL image tensor (H, W, C) in range [0,255] to a torch.Tensor(C, H, W) in the range [0.0, 1.0]。</p><h3 id="pytorch-保存以及导入预训练参数"><a href="#pytorch-保存以及导入预训练参数" class="headerlink" title="pytorch 保存以及导入预训练参数"></a>pytorch 保存以及导入预训练参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet(residual,[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]).to(device)</span><br><span class="line">...</span><br><span class="line">torch.save(model,<span class="string">'model.ckpt'</span>) <span class="comment"># save the structure</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'model_para.ckpt'</span>) <span class="comment"># save the parameter</span></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = torch.load(<span class="string">'model.ckpt'</span>)</span><br><span class="line"><span class="comment"># 下面的resnet结构需要提前定义好 </span></span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'model_para.ckpt'</span>))</span><br></pre></td></tr></table></figure><h3 id="resent实现需要注意的地方"><a href="#resent实现需要注意的地方" class="headerlink" title="resent实现需要注意的地方"></a>resent实现需要注意的地方</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Residual block</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels, stride=<span class="number">1</span>, downsample=None)</span>:</span></span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(in_channels, out_channels, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(out_channels, out_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        <span class="keyword">if</span> self.downsample:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># ResNet</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        self.in_channels = <span class="number">16</span></span><br><span class="line">        self.conv = conv3x3(<span class="number">3</span>, <span class="number">16</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</span><br><span class="line">        self.layer1 = self.make_layer(block, <span class="number">16</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self.make_layer(block, <span class="number">32</span>, layers[<span class="number">1</span>], <span class="number">2</span>)</span><br><span class="line">        self.layer3 = self.make_layer(block, <span class="number">64</span>, layers[<span class="number">2</span>], <span class="number">2</span>)</span><br><span class="line">        self.avg_pool = nn.AvgPool2d(<span class="number">8</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">64</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_layer</span><span class="params">(self, block, out_channels, blocks, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        downsample = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> (stride != <span class="number">1</span>) <span class="keyword">or</span> (self.in_channels != out_channels):</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                conv3x3(self.in_channels, out_channels, stride=stride),</span><br><span class="line">                nn.BatchNorm2d(out_channels))</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.in_channels, out_channels, stride, downsample))</span><br><span class="line">        self.in_channels = out_channels</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(out_channels, out_channels))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.conv(x)</span><br><span class="line">        out = self.bn(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.layer1(out)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">        out = self.avg_pool(out)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>这段代码在结构设计上，将residual从整个网络中剥离出来。residual部分在resnet中多次使用，可以起到代码复用。这residual这一部分同样继承了nn.module，在resnet中进行调用。在整个网络反向求导的过程中，同样可以反向传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out = out.view(out.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="comment"># 即保持第一维不变，然后后面的所有的维度特征进行flatten展开。类似于reshape。</span></span><br><span class="line">out = out.shape(out.size(<span class="number">0</span>),<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>在对resent进行evaluate的时候，需要先执行<code>model.eval()</code>。这是因为bn，dropout这些操作在训练和测试的阶段不一样。</p><h3 id="pytorch中的LSTM的调用"><a href="#pytorch中的LSTM的调用" class="headerlink" title="pytorch中的LSTM的调用"></a>pytorch中的LSTM的调用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Recurrent neural network (many-to-one)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, num_layers, num_classes)</span>:</span></span><br><span class="line">        super(RNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=<span class="keyword">True</span>)</span><br><span class="line">        self.fc = nn.Linear(hidden_size, num_classes)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Set initial hidden and cell states </span></span><br><span class="line">        h0 = torch.zeros(self.num_layers, x.size(<span class="number">0</span>), self.hidden_size).to(device) </span><br><span class="line">        c0 = torch.zeros(self.num_layers, x.size(<span class="number">0</span>), self.hidden_size).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward propagate LSTM</span></span><br><span class="line">        out, _ = self.lstm(x, (h0, c0))  <span class="comment"># out: tensor of shape (batch_size, seq_length, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Decode the hidden state of the last time step</span></span><br><span class="line">        out = self.fc(out[:, <span class="number">-1</span>, :])<span class="comment"># 因为有许多层，只要最后一层</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>其中LSTM调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.LSTM(input_size,hidden_size,num_layers，batch_first=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># input_size 指输入的一个数据含有的特征数（维度）</span></span><br><span class="line"><span class="comment"># hidden_size 指隐藏输出具有的特征</span></span><br><span class="line"><span class="comment"># num_layer 指共有多少个LSTM层叠在一起</span></span><br><span class="line"><span class="comment"># batch_first 指LSTM输出的h和c第一个维度都为batch</span></span><br></pre></td></tr></table></figure><p>h：hidden</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h0 = torch.zeros(self,num_layers,x.size(<span class="number">0</span>),self.hidden_size)</span><br><span class="line"><span class="comment"># 指hidden处的参数</span></span><br><span class="line"><span class="comment"># num_layers值共有几层</span></span><br><span class="line"><span class="comment"># batch_size=x.size(0) 共有几个batch</span></span><br><span class="line"><span class="comment"># hidden_size: 输出的hidden特征数</span></span><br></pre></td></tr></table></figure><p>c：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c0 = torch.zeros(self.num_layers,x.size(<span class="number">0</span>),self.hidden_size)</span><br><span class="line"><span class="comment"># 参数与上相同</span></span><br></pre></td></tr></table></figure><p>调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out,(hn,cn) = self.lstm(x,(h0,c0))</span><br></pre></td></tr></table></figure><h3 id="一个较大项目的代码布局逻辑"><a href="#一个较大项目的代码布局逻辑" class="headerlink" title="一个较大项目的代码布局逻辑"></a>一个较大项目的代码布局逻辑</h3><p><code>train.py</code> : 程序开始执行的地方，作为整个项目的核心指挥，负责对个个部分进行调度。他的主要思路如下：</p><p>【1】通过argparse接受传入的各种配置参数，包括数据集的路径，model的存储路径等等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ = <span class="string">'__main__'</span>:</span><br><span class="line">  parse = argparse.ArgumentParser()</span><br><span class="line">  parse.add_element(<span class="string">'--model_path'</span>,type=str,default=<span class="string">'./models'</span>,help=<span class="string">'saving training model'</span>)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>【2】调用main() 函数，开始执行程序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先执行image progressing步骤，对图片进行预处理部分</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">  transforms.RandomCrop(args.crop_size),</span><br><span class="line">  trnasforms.RandomHorizontalFlip(),</span><br><span class="line">  ...</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># build data loader</span></span><br><span class="line"><span class="comment"># 此处实现了一个继承torch.utils.data.Dataset的数据集处理类，实现了__init__以及__getitem__。</span></span><br><span class="line">data_loader = get_loader(args.image_dir, args.caption_path, vocab,transform, args.batch_size,shuffle=<span class="keyword">True</span>, num_workers=args.num_workers) </span><br><span class="line"></span><br><span class="line"><span class="comment"># build the model</span></span><br><span class="line"><span class="comment"># 此处实现了一个model类，继承至nn.Module</span></span><br><span class="line">encoder = EncoderCNN(args.embed_size).to(device)</span><br><span class="line">decoder = DecoderRNN(args.embed_size, args.hidden_size, len(vocab), args.num_layers).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示loss以及optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">    params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())</span><br><span class="line">    optimizer = torch.optim.Adam(params, lr=args.learning_rate)</span><br><span class="line">    </span><br><span class="line"><span class="comment">## train the model,通过data loader来产生数据</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(args.num_epochs):</span><br><span class="line">  <span class="comment"># 获取batch数据，进行训练以及预测</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD 复现</title>
      <link href="/2019/03/29/SSD-%E5%A4%8D%E7%8E%B0/"/>
      <url>/2019/03/29/SSD-%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>SSD是经典的one-stage目标检测框架，在速度和精度上都比Faster RCNN，YOLO（V1？）要更胜一筹。这次复现SSD作为理解网络以及学习pytorch的一个机会，这篇文章将尽可能的详细记录SSD的复现细节。（好大的flag🍐）</p><a id="more"></a><p>在复现SSD之前，我想就pytorch的两大部件进行一下介绍，分别是数据集模块（<code>torch.utils.data.Dataset</code>）以及网络模块(<code>torch.nn.Module</code>)。</p><h3 id="数据集模块"><a href="#数据集模块" class="headerlink" title="数据集模块"></a>数据集模块</h3><p> pytorch数据读取主要有三个类：</p><ul><li>Dataset </li><li>DataLoader </li><li>DataLoaderIter</li></ul><p>他们使用的方式为Dataset做为参数传入DatasetLoader中，DataLoader做为参数传入DataLoaderIter中。</p><p>因此完成pytorch数据集读取模块第一步要做的是：</p><p>【1】定义<strong>数据集类</strong>。</p><p><code>torch.utils.data.Dataset</code> 是一个抽象类，因此继承Dataset需要实现他的两个方法，<code>__len__()</code>，<code>__getitem__()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line">data_set = &#123;<span class="number">1</span>:<span class="string">'a'</span>,<span class="number">2</span>:<span class="string">'b'</span>,<span class="number">3</span>:<span class="string">'c'</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(data.Dataset)</span>:</span><span class="comment">#需要继承data.Dataset</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 1. Initialize file path or list of file names.</span></span><br><span class="line">        self.data = data_set</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># 每次读取一张图片以及对应的label，</span></span><br><span class="line">        <span class="comment"># 可以对图片进行一些flip等操作（torchvision.Transform).</span></span><br><span class="line">        <span class="comment"># 最终返回的是一个含有(image,label)的pair</span></span><br><span class="line">        <span class="comment"># 可以在init()函数的位置处生成csv_reader,或是一些list，集合</span></span><br><span class="line">        <span class="keyword">return</span> index, self.data[index]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data)</span><br></pre></td></tr></table></figure><p>对于这个Dataset这个类，只要实现了这两个函数，然后每次调用的的时候都能出来一个img，label，内部无论是list，generator都是可行的。</p><p>在<code>__getitem__()</code> 处可以执行一些图片变换等工作，torchvision.transforms中有着许多对图片的增强操作。常用的有<code>Resize</code> , <code>RandomCrop</code> , <code>Normalize</code> , <code>ToTensor</code> (这个<strong>极为重要</strong>, 可以把一个PIL或numpy图片转为<code>torch.Tensor</code>）</p><p>【2】定义dataLoader</p><p>dataLoader的定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False)</span><br></pre></td></tr></table></figure><p>其中<code>dataset</code>即上面定义的dataset，<code>batch_size</code>指一次调用该函数，输出的样本个数。<code>num_workers</code>指线程数，当大于等于1时就表示多线程。<code>collate_fn</code> 用于定制输出的batch，通过传入lambda表达式来实现，即当一张图片对应多个边框的时候，就需要进行图片以及边框的匹配。</p><p>dataLoader还实现了一个<code>__iter__()</code> 函数，这个函数输入为dataLoader，输出为dataLoaderIter，是一个迭代器。</p><p>具体使用如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset = CustomClass()</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">10</span>,...)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">  <span class="comment"># data[0]为图片</span></span><br><span class="line">  <span class="comment"># data[1]为标准</span></span><br><span class="line">  <span class="comment"># 共有10对</span></span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="网络结构模块"><a href="#网络结构模块" class="headerlink" title="网络结构模块"></a>网络结构模块</h3><p>pytorch 使用<code>nn.Module</code> 来构建网络，在pytorch中每一个网络层都是一个<code>nn.Module</code>类，并且类之间相互嵌套。<code>nn.Module</code>中有两个比较重要的部分，分别是</p><p><code>__init__()</code> ：完成逻辑模块的初始化。</p><p><code>forward()</code>：完成计算图的正向传递的过程。例如nn.Linear模块的定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinear</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">()</span>:</span></span><br><span class="line">    super(MyLinear,self).__init__()</span><br><span class="line">    </span><br><span class="line">    self.w = nn.Parameter(torch.randn(outp,inp))</span><br><span class="line">    self.b = nn.Parameter(torch.randn(outp))</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">    x = x @ self.w.t() + self.b</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>pytorch中提供了许多现成的类可供使用：</p><ul><li><code>nn.conV2d</code></li><li><code>nn.MaxPool2d</code></li><li><code>nn.ReLu</code></li><li><code>nn.BatchNorm2d</code></li></ul><p>同时<code>nn.Sequential</code>实现了一个序列，用来构建网络模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_size,out_size,kernel_size,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    nn.ReLu()</span><br><span class="line">   nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">  ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>输入将按照网络层从上到下进行参数的传递。</p><p>此外nn.Module类还会对网络的参数进行管理，<code>nn.parameters()</code>中将会保存着网络所有的参数。便于参数的管理。</p><p>我们可以使用nn.module构建许多的网络层，然后通过输入输出传值的方式将他们连成一个计算图。</p><p>下面将按照数据的读入，网络的搭建，网络的训练，以及效果的评估几个方面进行。</p><h3 id="SSD-复现"><a href="#SSD-复现" class="headerlink" title="SSD 复现"></a>SSD 复现</h3><p>参考<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="noopener">github链接</a>。</p><p><strong>【1】数据的准备</strong></p><p>数据集是一些由视频切帧而来的图片，一秒切一帧，对于每张图，由相应的标注信息，标注信息csv格式。通过读取csv数据集的方式，来完成数据的读取（github版本为使用pycocotool读取数据）。通过继承data.Dataset以及实现dataLoader的方式来获取数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># csv格式为：url,x1,y1,x2,y2,label</span></span><br><span class="line">TRAIN_ROOT = <span class="string">'./data/train_dataset.csv'</span></span><br><span class="line">VAL_ROOT   = <span class="string">'./data/val_dataset.csv'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detection_collate</span><span class="params">(batch)</span>:</span></span><br><span class="line">    targets = []</span><br><span class="line">    imgs    = []</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> batch:</span><br><span class="line">        imgs.append(sample[<span class="number">0</span>])</span><br><span class="line">        targets.append(sample[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> imgs,targets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">csv_loader</span><span class="params">(data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data_root,transform = transforms.ToTensor<span class="params">()</span>)</span>:</span></span><br><span class="line">        self.data_root  = data_root</span><br><span class="line">        self.dataset    = &#123;&#125;</span><br><span class="line">        self.imgs_index = &#123;&#125;</span><br><span class="line">        self.transform  = transform</span><br><span class="line">        self.index      = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> open(self.data_root,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> line[<span class="number">0</span>] <span class="keyword">in</span> self.dataset:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]].append(line[<span class="number">1</span>:<span class="number">5</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]] = [line[<span class="number">1</span>:<span class="number">5</span>],]</span><br><span class="line">                    self.imgs_index[self.index] = line[<span class="number">0</span>]</span><br><span class="line">                    self.index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        img_path = self.imgs_index[index]</span><br><span class="line">        label    = self.dataset[img_path]</span><br><span class="line">        img      = cv2.imread(img_path)</span><br><span class="line">        img      = self.transform(img)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(label)):</span><br><span class="line">            label[i][<span class="number">0</span>] = float(label[i][<span class="number">0</span>])</span><br><span class="line">            label[i][<span class="number">1</span>] = float(label[i][<span class="number">1</span>])</span><br><span class="line">            label[i][<span class="number">2</span>] = float(label[i][<span class="number">2</span>])</span><br><span class="line">            label[i][<span class="number">3</span>] = float(label[i][<span class="number">3</span>])</span><br><span class="line">        label  = np.array(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.index+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">dataset    = csv_loader(TRAIN_ROOT)</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">2</span>,collate_fn = detection_collate)</span><br><span class="line"><span class="keyword">for</span> img,label <span class="keyword">in</span> dataloader:</span><br><span class="line">    print(img)</span><br><span class="line">    print(label)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>如上，可以看出我们使用detection_collate方法来对每个batch size中读到的数据进行二次组织。</p><p>【2】网络的构建</p><p>数据已经准备好了，接下来要做的就是将网络搭建起来，然后将数据输入。</p><p>ssd的网络的backbone是vgg网络，利用vgg网络提取图片特征。</p><p>vgg的结构如下：</p><p><img src="./images/CNNnet/VGG16.png" alt=""></p><p>实现backbone的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">base = &#123;</span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'C'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>,</span><br><span class="line">            <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>],</span><br><span class="line">    <span class="string">'512'</span>: [],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="hard-negative-mining"><a href="#hard-negative-mining" class="headerlink" title="hard negative mining"></a>hard negative mining</h3><p>SSD 中对feature map位置的提取6个或4个边框，这些边框的尺寸由一些超参数决定。在进行网络训练之前，需要对生成的这些边框进行正负样本的标注，标注的标准在于这些边框与GT边框的IoU重合度，如果重合度大于0.5，则表示这个边框是证样本，小于0.3表示这个边框是负样本。</p><p>在对正负样本进行标注时，一般要保证正样本：负样本的个数为1:3。但是对于一张图片来说，其上大部分的框都是负样本，因此需要进行hard negative mining将一些得分较高的negative 做为hard negative。</p><p>hard negative mining一般是，有正负样本，然后分类器分出来一些分错的负样本（容易将负样本看成正样本的那些样本），即假阳性(false positive )，也就是说在对负样本分类时候，loss比较大（label与prediction相差较大）的那些样本，这些就是hard negative/困难样本，进行重新训练。</p><p>网络搭建部分主要继承nn.Module模块，继承init以及forward模块，实现网络结构的搭建，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python </span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录各层的channel</span></span><br><span class="line">base   = [<span class="number">64</span>,<span class="number">64</span>,<span class="string">'M'</span>,<span class="number">128</span>,<span class="number">128</span>,<span class="string">'M'</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="string">'C'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="string">'M'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>] <span class="comment"># M表示floor（边角舍弃）方式的Maxpooling，C表示ceil（补全）方式的Maxpooling</span></span><br><span class="line"><span class="comment"># vgg之后的各各层</span></span><br><span class="line">extras = [<span class="number">256</span>,<span class="string">'S'</span>,<span class="number">512</span>,<span class="number">128</span>,<span class="string">'S'</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>]</span><br><span class="line"><span class="comment">#每一层每个像素位置将取出的边框个数</span></span><br><span class="line">mboxes = [<span class="number">4</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(base,input_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    base: 各层的channel</span></span><br><span class="line"><span class="string">    input_channel：传入数据的维度</span></span><br><span class="line"><span class="string">    batch_norm：是否使用bn</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    这个函数主要使用一个list，将每一层的函数存储起来，用base来控制当前层是什么</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = input_channel</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> base:</span><br><span class="line">        <span class="keyword">if</span>   v == <span class="string">'M'</span>:<span class="comment"># 表示是一个maxpooling</span></span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">'C'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="keyword">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels,v,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d,nn.BatchNorm2d(v),nn.ReLU(inplace=<span class="keyword">True</span>)] <span class="comment"># inplace=True 指它将直接修改input的值，而不重新分配空间</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    pool5   = nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">    conv6   = nn.Conv2d(<span class="number">512</span>,<span class="number">1024</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">6</span>,dilation=<span class="number">6</span>)</span><br><span class="line">    conv7   = nn.Conv2d(<span class="number">1024</span>,<span class="number">1024</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">    layers += [pool5,conv6,nn.ReLU(inplace=<span class="keyword">True</span>),conv7,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(extras,in_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="comment"># extra layers added to vgg for feature scaling</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = in_channel</span><br><span class="line">    flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras):</span><br><span class="line">        <span class="keyword">if</span> in_channels!=<span class="string">'S'</span>:</span><br><span class="line">            <span class="keyword">if</span> v == <span class="string">'S'</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,extras[k+<span class="number">1</span>],kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag],stride=<span class="number">2</span>,padding=<span class="number">1</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,v,kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag])]</span><br><span class="line">            flag = <span class="keyword">not</span> flag</span><br><span class="line">        in_channels = v</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg,extras_layers,mbox,num_classes)</span>:</span></span><br><span class="line">    loc_layers  = []</span><br><span class="line">    conf_layers = []</span><br><span class="line">    vgg_source  = [<span class="number">21</span>,<span class="number">-2</span>] <span class="comment"># vgg的21层即conv4_3,和-2层即fc7</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(vgg_source):</span><br><span class="line">        loc_layers  += [nn.Conv2d(vgg[v].out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]           <span class="comment"># location 有四个参数</span></span><br><span class="line">        conf_layers += [nn.Conv2d(vgg[v].out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)] <span class="comment"># 类别预测将有class_num个数</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras_layers[<span class="number">1</span>::<span class="number">2</span>],<span class="number">2</span>):     <span class="comment"># 这里就是说取extras中奇数层，然后取bounding box，从第二层开始</span></span><br><span class="line">        loc_layers  += [nn.Conv2d(v.out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">        conf_layers += [nn.Conv2d(v.out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> vgg,extras_layers,(loc_layers,conf_layers)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">priorBox</span><span class="params">(obejct)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    在feature map上计算初始边框的坐标</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,cfg)</span>:</span></span><br><span class="line">        <span class="comment"># 将config中的一些超参赋值过来</span></span><br><span class="line">        self.image_size    = cfg[<span class="string">'min_dim'</span>]</span><br><span class="line">        self.num_priors    = len(cfg[<span class="string">'aspect_ratios'</span>])</span><br><span class="line">        self.variance      = cfg[<span class="string">'variance'</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]</span><br><span class="line">        self.feature_maps  = cfg[<span class="string">'feature_maps'</span>]</span><br><span class="line">        self.min_sizes     = cfg[<span class="string">'min_sizes'</span>]</span><br><span class="line">        self.max_sizes     = cfg[<span class="string">'max_sizes'</span>]</span><br><span class="line">        self.steps         = cfg[<span class="string">'steps'</span>]</span><br><span class="line">        self.aspect_ratios = cfg[<span class="string">'aspect_ratios'</span>]</span><br><span class="line">        self.clip          = cfg[<span class="string">'clip'</span>]</span><br><span class="line">        self.version       = cfg[<span class="string">'name'</span>]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Variances must be greater than 0'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">            mean = []</span><br><span class="line">            <span class="keyword">for</span> k ,f <span class="keyword">in</span> enumerate(self.feature_maps):</span><br><span class="line">                f_k = self.image_size / self.steps[k]</span><br><span class="line">                s_k = self.min_sizes[k] / self.image_size   </span><br><span class="line">                s_k_prime = sqrt(s_k*(self.max_sizes[k]/self.image_size))</span><br><span class="line">                <span class="keyword">for</span> i,j <span class="keyword">in</span> product(range(f),repeat=<span class="number">2</span>):</span><br><span class="line">                    <span class="comment"># unit center x,y</span></span><br><span class="line">                    cx  = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    cy  = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    <span class="comment">#aspect_ratio: 1</span></span><br><span class="line">                    mean += [cx,cy,s_k,s_k]</span><br><span class="line">                    mean += [cx,cy,s_k_prime,s_k_prime]</span><br><span class="line">                    <span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">                        mean += [cx,cy,s_k*sqrt(ar),s_k/sqrt(ar)]</span><br><span class="line">                        mean += [cx,cy,s_k/sqrt(ar),s_k*sqrt(ar)]</span><br><span class="line">            <span class="comment"># back to torch land</span></span><br><span class="line">            output = torch.Tensor(mean).view(<span class="number">-1</span>,<span class="number">4</span>)</span><br><span class="line">            <span class="keyword">if</span> self.clip:</span><br><span class="line">                output.clamp_(max=<span class="number">1</span>,min=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,phase,size,base,extras,head,num_classes)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        phase:  train,test</span></span><br><span class="line"><span class="string">        size:   ssd输入图片的大小，也即是版本把</span></span><br><span class="line"><span class="string">        base:   vgg的网络结构</span></span><br><span class="line"><span class="string">        extras: vgg之后的那些层</span></span><br><span class="line"><span class="string">        head:   loc，conf 的boxes</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(SSD,self).__init__()</span><br><span class="line">        self.phase       = phase</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.cfg         = (coco,voc)[num_classes == <span class="number">21</span>]  <span class="comment"># config.py 中对数据集的一些配置</span></span><br><span class="line">        self.priorbox    = PriorBox(self.cfg)</span><br><span class="line">        self.priors      = Variable(self.priorbox.forward(),volatile=<span class="keyword">True</span>)</span><br><span class="line">        self.size        = size</span><br><span class="line"></span><br><span class="line">        <span class="comment">## ssd net</span></span><br><span class="line">        self.vgg         = nn.ModuleList(base)</span><br><span class="line">        self.L2Norm      = L2Norm(<span class="number">512</span>,<span class="number">20</span>)</span><br><span class="line">        self.extras      = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        self.loc         = nn.ModuleList(head[<span class="number">0</span>])</span><br><span class="line">        self.conf        = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> phase == <span class="string">'test'</span>:</span><br><span class="line">            self.softmax = nn.Softmax(dim = <span class="number">-1</span>)</span><br><span class="line">            <span class="comment">## detection.py</span></span><br><span class="line">            self.detect  = Detect(num_classes,<span class="number">0</span>,<span class="number">200</span>,<span class="number">0.01</span>,<span class="number">0.45</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        sources = list()</span><br><span class="line">        loc     = list()</span><br><span class="line">        conf    = list()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg to conv4_3 relu</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        s = self.L2Norm(x)</span><br><span class="line">        sources.append(s)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg up to fc7</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>,len(self.vgg)):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply extra layers</span></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(self,extras):</span><br><span class="line">            x = F.relu(v(x),inplace=<span class="keyword">True</span>)</span><br><span class="line">            <span class="keyword">if</span> k%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                sources.append(x)</span><br><span class="line">        <span class="keyword">for</span> (x,l,c) <span class="keyword">in</span> zip(sources,self.loc,self.conf):</span><br><span class="line">            loc.append(l(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line">            conf.append(c(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line"></span><br><span class="line">        loc  = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> loc],<span class="number">1</span>)</span><br><span class="line">        conf = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> conf],<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self,phase == <span class="string">'test'</span>:</span><br><span class="line">            output = self.detect(</span><br><span class="line">                loc.vire(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                self.softmax(conf.view(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes)),</span><br><span class="line">                self.priors.type(type(x.data))</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output = (</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                conf,vire(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes),</span><br><span class="line">                self.priors</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span><span class="params">(self,base_file)</span>:</span></span><br><span class="line">        other,ext = os.path.splitext(base_file)</span><br><span class="line">        <span class="keyword">if</span> ext == <span class="string">'.pkl'</span> <span class="keyword">or</span> <span class="string">'.pth'</span>:</span><br><span class="line">            self.load_state_dict(torch.load(base_file,</span><br><span class="line">                                            map_location=<span class="keyword">lambda</span> storage,loc:storage))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'sorry wrong'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span><span class="params">(phase,size=<span class="number">300</span>,num_classes=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">'test'</span> <span class="keyword">and</span> phase != <span class="string">'train'</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    base_,extras_,head_ = multibox(vgg(base[str(size)],<span class="number">3</span>),add_extras(extras[str(size)],<span class="number">1024</span>),</span><br><span class="line">                                  mbox[str(size)],num_classes)</span><br><span class="line">    <span class="keyword">return</span> SSD(phase,size,base_,extras_,head_,num_classes)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 论文复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手撕mAP</title>
      <link href="/2019/03/22/%E6%89%8B%E6%92%95mAP/"/>
      <url>/2019/03/22/%E6%89%8B%E6%92%95mAP/</url>
      
        <content type="html"><![CDATA[<p>mAP在很多检测任务中使用十分频繁，微软的COCO数据集专门提供了一套API，实现预测模型的mAP计算（pycocotools），本篇文章打算用最原始的方式手撕mAP，希望使得对整个指标更好的理解。文章参考Retina-net，并在其基础上进行修改。</p><a id="more"></a><h3 id="mAP是什么？"><a href="#mAP是什么？" class="headerlink" title="mAP是什么？"></a>mAP是什么？</h3><p><strong>mAP</strong>： mean Average Precision, 即各类别AP的平均值，例如COCO数据集，共有80+1类（背景），对每一个类别的物体求一个AP，mAP即为所有目标AP的平均值。</p><p><strong>AP</strong>：AP为PR曲线（precision-recall）与x轴围成的面积</p><p><strong>Pricision</strong>：TP/（TP+FP），即预测为真（预测结果放后面即TP）当中，真正为真的比例。</p><p><strong>Recall</strong>：TP/（TP+FN），即预测为真当中真正为真的个数，占所有样本中真个数的比例。</p><p>对于TP，FP，TN，FN表示四种情况，其中T，F是从结果来看，是否预测正确。P，N则是从预测来看，预测正误。</p><p><strong>TP</strong>：预测是对的，预测样本结果为真。该类样本的个数</p><p><strong>FP</strong>：预测是错的，预测样本为真。该类个数。</p><p><strong>TN</strong>：预测是对的，预测样本为假。该类个数。</p><p><strong>FN</strong>：预测是错的，预测样本为假。该类个数。</p><p><strong>真假鉴定：</strong>当预测边框与GT的边框重合程度，PASCAL数据集中，认为IoU大于0.5认为是真，小于0.5认为是假。</p><p><strong>IoU：</strong>预测边框与GT边框的 重叠面积/两个边框并集</p><p><strong>mAP-IoU[0.5, 0.95]</strong>：COCO要求IOU阈值在[0.5, 0.95]区间内每隔0.05取一次，将这个IoU作为真假边框的评判边界。可以计算出10个IoU下的mAP值，然后这10个还要再做平均，即为最后的mAP。</p><h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><p>指标虽然很多，但是都是很简单的指标，耐心的理解一下，也不辛苦的。看完上面的指标有几个疑问：</p><ol><li>IoU计算的时候需要边框与GT对应起来，每个GT对应一个边框后不再参与后面边框的匹配。那么与哪个GT边框对应呢，这是个问题？<strong>（置信度+IoU最大）</strong></li><li>AP在计算的时候需要计算AP曲线下方的面积，这个该怎么算呢？</li><li>计算precision，recall的时候需要每个类单独算，然后用于之后算AP，感觉是几个循环，外循环是个遍历类别，内循环对每个预测边框做一下循环，具体怎么实现呢？</li></ol><h3 id="实作"><a href="#实作" class="headerlink" title="实作"></a>实作</h3><p>这一部分将按照输入数据，数据处理，计算IoU，计算Precision，Recall，计算AP等步骤。</p><p><strong>预测结果数据</strong>：假设经过模型预测得到一个csv格式的预测结果，格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/<span class="number">1.j</span>pg,<span class="number">10</span>,<span class="number">78</span>,<span class="number">25</span>,<span class="number">34</span>,face,<span class="number">0.9</span></span><br></pre></td></tr></table></figure><p>分别是图片的位置，预测的边框（左上）（x,y,w,h)，label，以及置信度。</p><p><strong>GT数据</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/<span class="number">1.j</span>pg,<span class="number">15</span>,<span class="number">80</span>,<span class="number">30</span>,<span class="number">32</span>,face</span><br></pre></td></tr></table></figure><p>分别是图片的位置，边框位置以及标签。</p><p><strong>数据处理：</strong></p><p>为了更好的计算每一个类别预测的precision以及recall，直觉上来说，应该需要一个比较好的格式方便计算，我们可以将这种格式设置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_detections = [img_index][label][box_index]</span><br></pre></td></tr></table></figure><p>意思为每一个图片，对应若干个label（例如一张图上对应桌子，人），每个label对应若干个边框，（例如一张图片中有多个人）。</p><p>因此第一步需要把csv格式的数据转换为上面的格式，在转换之前需要借助道dcit字典。目的是为了对相同的图片的label。boxes进行汇总。dict的格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  img1:&#123;label1:[[box1],[box2]...],label2:[[box1],[box2]...]..&#125;</span><br><span class="line">  img2:&#123;label1:[[box1]]&#125;</span><br><span class="line"> ]</span><br></pre></td></tr></table></figure><p>即外围是一个list[],保存每一张图片的信息。每个图片是一个字典，key为图片名，val是另一个保存label和boxes的字典，这个字典的key为label名，val为多个boxes的list结构。</p><p>下面代码是读取csv文件，并将数据转化为上诉格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">img_name = &#123;&#125;     <span class="comment"># imgId: 1</span></span><br><span class="line">boxes_label_scores = &#123;&#125; <span class="comment"># imgId: [[x,y,w,h,score],...]</span></span><br><span class="line">class_num = <span class="number">1</span> <span class="comment"># 表示类别个数</span></span><br><span class="line"></span><br><span class="line">pre_gt_csv = <span class="string">'score_mintest.csv'</span></span><br><span class="line">   </span><br><span class="line"><span class="keyword">with</span> open(pre_gt_csv,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">   reader = csv.reader(f)</span><br><span class="line">   lines = list(reader)</span><br><span class="line">   <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">       <span class="keyword">if</span> len(line) &lt; <span class="number">7</span>:</span><br><span class="line">            line.append(<span class="string">'1'</span>) <span class="comment"># 当为GT的时候，最后需要添上置信度为1</span></span><br><span class="line">       <span class="keyword">if</span> float(line[<span class="number">-1</span>]) &lt; score_threshold:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">       <span class="keyword">if</span> line[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> img_name.keys():</span><br><span class="line">            img_name[line[<span class="number">0</span>]] = <span class="number">1</span></span><br><span class="line">            temp = line[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">            temp.append(line[<span class="number">-1</span>])       <span class="comment"># [x,y,w,h,score]</span></span><br><span class="line">            box_dict = &#123;&#125;</span><br><span class="line">            box_dict[line[<span class="number">5</span>]] = [temp]  <span class="comment"># label:[[],[]]</span></span><br><span class="line">              <span class="comment">#&#123;img: &#123;label_name:[x,y,w,h,socre],[x2,y2,w2,h2,score2]...&#125;,img:&#123;...&#125;.. &#125;</span></span><br><span class="line">            boxes_label_scores[line[<span class="number">0</span>]] = box_dict</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># the image is exist</span></span><br><span class="line">            temp = line[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">            temp.append(line[<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> line[<span class="number">5</span>] <span class="keyword">in</span> boxes_label_scores[line[<span class="number">0</span>]].keys():</span><br><span class="line">                boxes_label_scores[line[<span class="number">0</span>]]    [line[<span class="number">5</span>]].append(temp)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                boxes_label_scores[line[<span class="number">0</span>]][line[<span class="number">5</span>]] = [temp]</span><br></pre></td></tr></table></figure><p>在进行边框对比的时候，我们希望对置信度高的边框提前进行IoU的判断，因此对boxes_label_scores中的boxes进行置信度的排序<strong>(解决第一个问题)</strong>，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> boxes_label_scores:</span><br><span class="line">    labels = boxes_label_scores[img]</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels.keys():</span><br><span class="line">        boxes = boxes_label_scores[img][label]</span><br><span class="line">        boxes = sorted(boxes,  key=<span class="keyword">lambda</span> x: float(x[<span class="number">-1</span>]),reverse=<span class="keyword">True</span>)</span><br><span class="line">        boxes_label_scores[img][label] = boxes</span><br></pre></td></tr></table></figure><p>由于上面字典的结构，key与label均为真实值，然后我们希望用all_detections这个list的结构来代替，因此需要引入图片与下标，label与下标的一一对应关系。</p><p><strong>图片与下标对应：</strong>我们对测试集中读取的图片从上到下，依次进行计数。该数对应该图片的Id（切记，在进行GT比较时，顺序不能乱）。</p><p><strong>label与下标对应：</strong> 将其转化为下标，从0开始一次进行计数。</p><p>也可以专门生成一张数字与图片，数字与类别一一对应的表格，比较直观。上诉方法则比较方便，但是容易混乱。因此将字典结构赋值给三重数组代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all_detections : [img1[label1],[label2]..] ; img2: label1,label2...</span></span><br><span class="line">all_detections = [[<span class="keyword">None</span> <span class="keyword">for</span> i <span class="keyword">in</span> boxes_label_scores[img].keys()] <span class="keyword">for</span> img <span class="keyword">in</span> boxes_label_scores.keys()]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#inds_keys = list(img_name.keys()) # [img1,img2,...n-1]</span></span><br><span class="line">inds = img_name.keys() <span class="comment"># 充当图片的id，与图片一一对应</span></span><br><span class="line"><span class="comment"># ind与图片路径一一对应</span></span><br><span class="line"><span class="keyword">for</span> ind,img <span class="keyword">in</span> (enumerate(inds)): <span class="comment"># 每次得到img_name 即图片路径</span></span><br><span class="line">    <span class="comment"># index 与label一一对应</span></span><br><span class="line">    <span class="keyword">for</span> index,label <span class="keyword">in</span> enumerate(boxes_label_scores[img].keys()):</span><br><span class="line">        all_detections[ind][index] = boxes_label_scores[img][label]     <span class="comment">## ind为图片，index为类别，从0开始</span></span><br><span class="line"><span class="keyword">return</span> all_detections</span><br></pre></td></tr></table></figure><p><strong>计算precision，recall</strong></p><p>生成数据之后需要根据数据去计算TP，FP，TN，FN等参数。一个直观的想法就是大循环是个label，然后每次算出一个类的AP之后，保存一下，循环结束了算一个平均。</p><p>计算precision即计算预测边框中真正预测对的部分占预测为真的个数。计算recall即计算预测边框中TP与总的GT的比例。因此我们以label为大循环，一次去遍历每一张图片，然后去更新TP，FP的值。如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">inds = list(range(len(img_name.keys()))) <span class="comment"># 充当图片的id，与图片一一对应</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> range(class_num): <span class="comment"># </span></span><br><span class="line">        false_positives = np.zeros((<span class="number">0</span>,))  <span class="comment"># precision = TP/（TP+FP）Recall = TP/（TP+FN）</span></span><br><span class="line">        true_positives  = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        scores          = np.zeros((<span class="number">0</span>,))</span><br><span class="line">        num_annotations = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> inds:</span><br><span class="line">            detections           = all_detections[i][label]   <span class="comment"># image：i，class：label</span></span><br><span class="line">            annotations          = all_annotations[i][label]</span><br><span class="line">            num_annotations     += len(annotations)   <span class="comment">#.shape[0]       # boxes的个数</span></span><br><span class="line">            detected_annotations = []</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> detections:</span><br><span class="line">                scores = np.append(scores, float(d[<span class="number">4</span>]))</span><br><span class="line">                <span class="comment">#if annotations.shape[0] == 0:</span></span><br><span class="line">                <span class="keyword">if</span> len(annotations) == <span class="number">0</span>: <span class="comment"># 预测为真，但这个label的个数是0</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>)</span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>)</span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br><span class="line">                <span class="keyword">if</span> max_overlap &gt;= iou_threshold \</span><br><span class="line">                   <span class="keyword">and</span> assigned_annotation <span class="keyword">not</span> <span class="keyword">in</span> detected_annotations: <span class="comment"># IoU满足条件，分配的标注没有被标注过</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">0</span>)     <span class="comment"># FP += 0</span></span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">1</span>)      <span class="comment"># TP += 1</span></span><br><span class="line">                  detected_annotations.append(assigned_annotation) </span><br><span class="line">                <span class="keyword">else</span>:                                                   <span class="comment"># 标注已经使用过</span></span><br><span class="line">                    false_positives = np.append(false_positives, <span class="number">1</span>) </span><br><span class="line">                    true_positives  = np.append(true_positives, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>值得注意的是，false_positives与true_positives并不是直接算个和，而是将每一张图片是否为TP，FP按照1，0保留下来。如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">false_positives = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>] <span class="comment"># 下标表示图片的序号，0表示否，1表示真</span></span><br></pre></td></tr></table></figure><p>这样存储的好处在于随后计算AP（PR曲线下方面积）时，方便计算。</p><h3 id="计算单个-label的AP"><a href="#计算单个-label的AP" class="headerlink" title="计算单个 label的AP"></a>计算单个 label的AP</h3><p>上一个部分代码得到了每张图片的PR值结果。计算AP值即算PR曲线的下方面积，因为不能直接算积分，因此我们需要想想办法。PR图是一张recall为x轴，precision为y轴的曲线，随着图片进行叠加，分别计算出P，R值，然后绘制出曲线。为了保证PR值尽量准确，我们首先对图片进行置信度从高到低的一个排序，然后累加计算其PR值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># no annotations -&gt; AP for this class is 0 (is this correct?)</span></span><br><span class="line"><span class="keyword">if</span> num_annotations == <span class="number">0</span>:</span><br><span class="line">    average_precisions[label] = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># sort by score</span></span><br><span class="line">indices         = np.argsort(-scores)</span><br><span class="line">false_positives = false_positives[indices] </span><br><span class="line">true_positives  = true_positives[indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute false positives and true positives</span></span><br><span class="line">false_positives = np.cumsum(false_positives) <span class="comment"># 依次累加</span></span><br><span class="line">true_positives  = np.cumsum(true_positives)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute recall and precision num_annotations也是据图片累加的</span></span><br><span class="line">recall    = true_positives / num_annotations</span><br><span class="line">precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)</span><br></pre></td></tr></table></figure><p>上诉代码首先根据scores对PR值进行排序，然后对每张图片从1…n累加计算出TP，FP值，因此最终得到的TP，FP也是一个长度为图片个数的数组。</p><p>计算AP的方法：</p><p>计算AP通常有两种方式，一种是07年以前的11点法，第二种是则是对每一个点都计算差值。</p><h4 id="Calculating-the-interpolation-performed-in-all-points"><a href="#Calculating-the-interpolation-performed-in-all-points" class="headerlink" title="Calculating the interpolation performed in all points"></a><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics" target="_blank" rel="noopener">Calculating the interpolation performed in all points</a></h4><p>该部分参考github上的讲解。先看图，对于Precision与Recall的插值如下，</p><p><img src="../images/trick/AP1.png" alt=""></p><p>也就是说，对于precision来说，从末尾开始，precision每个点的取值都等于其前一个点与当前点的最大值，即<code>mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])</code>。当遇到更大的precision时，重新开始重复上面计算，得到许多矩形框如下,计算该面积即可：</p><p><img src="../images/trick/AP2.png" alt=""></p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_ap</span><span class="params">(recall, precision)</span>:</span></span><br><span class="line">    <span class="string">""" Compute the average precision, given the recall and precision curves.</span></span><br><span class="line"><span class="string">    Code originally from https://github.com/rbgirshick/py-faster-rcnn.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        recall:    The recall curve (list).</span></span><br><span class="line"><span class="string">        precision: The precision curve (list).</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        The average precision as computed in py-faster-rcnn.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># correct AP calculation</span></span><br><span class="line">    <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">    mrec = np.concatenate(([<span class="number">0.</span>], recall, [<span class="number">1.</span>]))</span><br><span class="line">    mpre = np.concatenate(([<span class="number">0.</span>], precision, [<span class="number">0.</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the precision envelope</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># to calculate area under PR curve, look for points</span></span><br><span class="line">    <span class="comment"># where X axis (recall) changes value</span></span><br><span class="line">    i = np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># and sum (\Delta recall) * prec</span></span><br><span class="line">    ap = np.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br></pre></td></tr></table></figure><h3 id="计算IoU"><a href="#计算IoU" class="headerlink" title="计算IoU"></a>计算IoU</h3><p>当我们在计算Precision与Recall的时候需要判断样本是否是真样本，因此需要计算IoU值，计算IoU的大致思路如下，首先对一张图片，拿到一个置信度最高的边框，然后对该边框与该图片所有的GT边框都计算一个IoU，选出一个IoU值最大的GT边框作为与该边框匹配的边框。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> compute_overlap</span><br><span class="line">overlaps            = compute_overlap(np.expand_dims(d, axis=<span class="number">0</span>), annotations)</span><br><span class="line">                assigned_annotation = np.argmax(overlaps, axis=<span class="number">1</span>)</span><br><span class="line">                max_overlap         = overlaps[<span class="number">0</span>, assigned_annotation]</span><br></pre></td></tr></table></figure><p>其中compute_overlap库是一个动态链接库，即为一个.so文件，通过.c文件编译而来。<a href="https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/utils/compute_overlap.pyx" target="_blank" rel="noopener">overlap代码github地址</a>。算法就是那样了，retina-net作者偷懒，直接用了fast rcnn的代码，我也偷个懒😂。</p><p>值得注意的是，每当一个GT边框被使用过之后，需要将其标记一下，避免下次重复计算。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>求mAP的方法需要通过预测网络提前生成测试集的box，然后将pred_csv, GT_csv传入方法中，最终求返回每个类别的AP。</p>]]></content>
      
      
      <categories>
          
          <category> 手撕系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python Tip</title>
      <link href="/2019/03/20/python-Tip/"/>
      <url>/2019/03/20/python-Tip/</url>
      
        <content type="html"><![CDATA[<h3 id="字符串查找元素"><a href="#字符串查找元素" class="headerlink" title="字符串查找元素"></a>字符串查找元素</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">astr = <span class="string">'1234'</span></span><br><span class="line">astr.find(<span class="string">'1'</span>) <span class="comment"># 返回下标或-1</span></span><br><span class="line">astr.rfind(<span class="string">'1'</span>) <span class="comment"># 反向查找</span></span><br></pre></td></tr></table></figure><h3 id="python-lambda-表达式"><a href="#python-lambda-表达式" class="headerlink" title="python lambda 表达式"></a>python lambda 表达式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">g = <span class="keyword">lambda</span> x:x+<span class="number">1</span> <span class="comment"># x为输入，x+1为输出: g(1) = 2</span></span><br><span class="line"><span class="comment"># python 中自带的lambda表达式</span></span><br><span class="line"><span class="comment"># foo =[2, 18, 9, 22, 17, 24, 8, 12, 27]</span></span><br><span class="line"><span class="comment"># 输出：[18, 9, 24, 12, 27]</span></span><br><span class="line">filter(<span class="keyword">lambda</span> x:x%<span class="number">3</span> ==<span class="number">0</span>,foo)</span><br><span class="line"><span class="comment"># map,将foo中每个元素都算一下</span></span><br><span class="line"><span class="comment">#输出：[14, 46, 28, 54, 44, 58, 26, 34, 64]</span></span><br><span class="line">map(<span class="keyword">lambda</span> x: x * <span class="number">2</span> + <span class="number">10</span>, foo)</span><br><span class="line"><span class="comment">#reduce 类加</span></span><br><span class="line">reduce(<span class="keyword">lambda</span> x, y: x + y, foo)</span><br></pre></td></tr></table></figure><h3 id="获取图片大小"><a href="#获取图片大小" class="headerlink" title="获取图片大小"></a>获取图片大小</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">'whatever.png'</span>)</span><br><span class="line">width, height = im.size</span><br></pre></td></tr></table></figure><h3 id="python-🀄️的类"><a href="#python-🀄️的类" class="headerlink" title="python 🀄️的类"></a>python 🀄️的类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">    self.name = name</span><br><span class="line">    self.__sex = man <span class="comment">## 在属性前加上两个_ 变成私有变量</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">    print(<span class="string">'hello'</span>+self.name)</span><br></pre></td></tr></table></figure><p>python中前后都有双下划线的变量是特殊变量，如<code>__ver__</code>,可以直接访问，定义式避免这种定义方式。例外，仅有一个下划线，如<code>_name</code>,这种变量表示不要轻易访问，但是它是可以被直接访问的。</p><h3 id="获取变量信息"><a href="#获取变量信息" class="headerlink" title="获取变量信息"></a>获取变量信息</h3><p>例如<code>dog = Animal(&#39;dog&#39;)</code>:</p><ul><li><code>type(dog)</code> 来获取dog的类型。</li><li><code>isinstance(dog,Animal)</code> 判断dog的类型</li><li><code>hasattr(obj, attr)</code> 判断类是否有attr方法/属性</li><li><code>getattr(obj,attr[,default])</code>:得到属性的值</li><li><code>setattr(obj, attr, value)</code>: 设置属性的值</li><li><code>dir(dog)</code>: 获取dog的所有属性和方法</li></ul><h3 id="类方法，静态方法"><a href="#类方法，静态方法" class="headerlink" title="类方法，静态方法"></a>类方法，静态方法</h3><p>可以使用类或实例直接访问：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">class_info</span><span class="params">(cls)</span>:</span></span><br><span class="line">    print(cls)</span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">static_info</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'something'</span>)</span><br></pre></td></tr></table></figure><h3 id="定制类以及魔法方法"><a href="#定制类以及魔法方法" class="headerlink" title="定制类以及魔法方法"></a>定制类以及魔法方法</h3><p>python中有一类方法，使用双下划线包裹起来：<code>__new__</code>等等，这类方法称为魔法方法，可以对类提供特殊的功能，方便定制类。</p><p><code>__new__(cls)</code>: 当创建一个类时，首先调用<code>__new__(cls)</code>方法，之后再调用<code>__init__()</code></p><p><code>__str__</code>: 当我们直接输出一个实例时，如<code>print(dog)</code>,得到的输出为：<code>&lt;__main__.Animal object at 0x10c37aa50&gt;</code>,通过覆盖<code>__str__</code> 方法可以输出我们想要的内容。</p><p><code>__repr__</code>: 当我们不用print时，调用该方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="string">'Animal object (name: %s)'</span> % self.name</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="string">'lalal'</span></span><br><span class="line">print(Animal(dog))  <span class="comment">## 调用__str__()</span></span><br><span class="line">Animal(dog) <span class="comment">## 调用 __repr__()</span></span><br></pre></td></tr></table></figure><p><code>__iter__(),__next__()</code>: 定义该方法使得类允许迭代调用,首先调用<code>__iter__()</code> 获得一个迭代器，然后每次迭代调用next。（可以不定义iter）。</p><p><code>__geitem__</code> 用于获取值，类似地，<code>__setitem__</code> 用于设置值，<code>__delitem__</code> 用于删除值，让我们看下面一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.coordinate = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"point(%s)"</span> % self.coordinate</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.coordinate.get(key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setitem__</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        self.coordinate[key] = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__delitem__</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">del</span> self.coordinate[key]</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'delete %s'</span> % key</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.coordinate)</span><br><span class="line"></span><br><span class="line">    __repr__ = __str__</span><br></pre></td></tr></table></figure><p>调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'x'</span>] = <span class="number">2</span>    <span class="comment"># 对应于 p.__setitem__('x', 2)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'y'</span>] = <span class="number">5</span>    <span class="comment"># 对应于 p.__setitem__('y', 5)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p             <span class="comment"># 对应于 __repr__</span></span><br><span class="line">point(&#123;<span class="string">'y'</span>: <span class="number">5</span>, <span class="string">'x'</span>: <span class="number">2</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(p)        <span class="comment"># 对应于 p.__len__</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'x'</span>]        <span class="comment"># 对应于 p.__getitem__('x')</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p[<span class="string">'y'</span>]        <span class="comment"># 对应于 p.__getitem__('y')</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> p[<span class="string">'x'</span>]    <span class="comment"># 对应于 p.__delitem__('x')</span></span><br><span class="line">delete x</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p</span><br><span class="line">point(&#123;<span class="string">'y'</span>: <span class="number">5</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(p)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><p><code>__getattr__()</code> 只有在属性不存在的情况下才会被调用。</p><p>与 <code>__getattr__</code> 一起使用的还有 <code>__setattr__</code>, <code>__delattr__</code>，类似 <code>obj.attr = value</code>, <code>del obj.attr</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=<span class="number">0</span>, y=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span><span class="params">(self, attr)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> attr == <span class="string">'z'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">raise</span> AttributeError(<span class="string">"Point object has no attribute %s"</span> % attr)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span><span class="params">(self, *args, **kwargs)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">'call func set attr (%s, %s)'</span> % (args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> object.__setattr__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__delattr__</span><span class="params">(self, *args, **kwargs)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">'call func del attr (%s, %s)'</span> % (args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> object.__delattr__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">call func set attr ((<span class="string">'x'</span>, <span class="number">3</span>), &#123;&#125;)</span><br><span class="line">call func set attr ((<span class="string">'y'</span>, <span class="number">4</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z = <span class="number">7</span></span><br><span class="line">call func set attr ((<span class="string">'z'</span>, <span class="number">7</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">8</span>, <span class="keyword">in</span> __getattr__</span><br><span class="line">AttributeError: Point object has no attribute w</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w = <span class="number">8</span></span><br><span class="line">call func set attr ((<span class="string">'w'</span>, <span class="number">8</span>), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.w</span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> p.w</span><br><span class="line">call func <span class="keyword">del</span> attr ((<span class="string">'w'</span>,), &#123;&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.__dict__</span><br><span class="line">&#123;<span class="string">'y'</span>: <span class="number">4</span>, <span class="string">'x'</span>: <span class="number">3</span>, <span class="string">'z'</span>: <span class="number">7</span>&#125;</span><br></pre></td></tr></table></figure><p> <code>__call__</code> 方法,对实例进行调用就好像对函数调用一样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>+<span class="number">1</span></span><br><span class="line">a = A()</span><br><span class="line">a() <span class="comment"># 将调用__call__方法</span></span><br></pre></td></tr></table></figure><p>使用 <code>__slots__</code> 来告诉 Python 只给一个固定集合的属性分配空间，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span><span class="params">(object)</span>:</span></span><br><span class="line">    __slots__ = (<span class="string">'x'</span>, <span class="string">'y'</span>)       <span class="comment"># 只允许使用 x 和 y</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=<span class="number">0</span>, y=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">a = Point()</span><br><span class="line">a.z = <span class="number">1</span> <span class="comment"># 报错，只允许对x,y赋值</span></span><br></pre></td></tr></table></figure><p>定义<code>@property以及@setter</code> 方法，第一个将方法当作属性来用，第二个将这个方法当作属性来赋值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Exam</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, score)</span>:</span></span><br><span class="line">        self._score = score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, val)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> val &lt; <span class="number">0</span>:</span><br><span class="line">            self._score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> val &gt; <span class="number">100</span>:</span><br><span class="line">            self._score = <span class="number">100</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._score = val</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e = Exam(<span class="number">60</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score = <span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score = <span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e.score</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure><p><code>super()</code>:当使用子类与夫类方法相同时会发生覆盖，如果希望保留父类则调用super方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span>（<span class="number">111</span>）</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().greet()</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'WangWang...'</span></span><br></pre></td></tr></table></figure><p>使用元类：元类主要用来拦截类的创建，修改类的定义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrefixMetaclass</span><span class="params">(type)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, name, bases, attrs)</span>:</span></span><br><span class="line">        <span class="comment"># 给所有属性和方法前面加上前缀 my_</span></span><br><span class="line">        _attrs = ((<span class="string">'my_'</span> + name, value) <span class="keyword">for</span> name, value <span class="keyword">in</span> attrs.items())  </span><br><span class="line"></span><br><span class="line">        _attrs = dict((name, value) <span class="keyword">for</span> name, value <span class="keyword">in</span> _attrs)  <span class="comment"># 转化为字典</span></span><br><span class="line">        _attrs[<span class="string">'echo'</span>] = <span class="keyword">lambda</span> self, phrase: phrase  <span class="comment"># 增加了一个 echo 方法</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> type.__new__(cls, name, bases, _attrs)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span><span class="params">(metaclass=PrefixMetaclass)</span>:</span></span><br><span class="line">    name = <span class="string">'foo'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bar</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'bar'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bar</span><span class="params">(Foo)</span>:</span></span><br><span class="line">    prop = <span class="string">'bar'</span></span><br></pre></td></tr></table></figure><p>创建迭代器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fib</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回迭代器对象本身</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回容器下一个元素</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.a, self.b = self.b, self.a + self.b</span><br><span class="line">        <span class="keyword">return</span> self.a</span><br></pre></td></tr></table></figure><p><code>__iter__()</code> 创建迭代器，<code>__next__()</code>每次迭代均调用该方法取得迭代值。</p><p>创建生成器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fib</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"><span class="meta">... </span>        a, b = b, a + b</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> a</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> item <span class="keyword">in</span> f:  <span class="comment"># 每次执行到yield返回一个值并停止，第二次调用f.next()时冲yield处开始执行</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> item &gt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> item</span><br></pre></td></tr></table></figure><h3 id="Python-OS模块"><a href="#Python-OS模块" class="headerlink" title="Python OS模块"></a>Python OS模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dir <span class="keyword">in</span> os.listdir(<span class="string">'./'</span>):  <span class="comment"># 当前路径下的所有文件</span></span><br><span class="line">  print(dir)</span><br><span class="line">os.path.abspath(<span class="string">'.'</span>) <span class="comment"># 得到绝对路径</span></span><br><span class="line">os.path.dirname(<span class="string">'file.txt'</span>) <span class="comment"># 　获取当前文件的父目录</span></span><br><span class="line">os.path.basename(<span class="string">'./path/to/file.txt'</span>) <span class="comment"># 输出file.txt，得到文件名</span></span><br><span class="line">os.path.splitext(<span class="string">'afile.txt'</span>) <span class="comment"># 输出(afile,txt),分离文件名和扩展名</span></span><br><span class="line">os.path.split(<span class="string">'/path/file.txt'</span>)<span class="comment"># (path,file.txt)，分离目录与文件</span></span><br><span class="line">os.path.isfile/os.path.isdir() <span class="comment">#判断是否是目录或文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##遍历目录</span></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(<span class="string">'/Users/ethan/coding'</span>):</span><br><span class="line">     <span class="keyword">print</span> root</span><br><span class="line">     <span class="keyword">print</span> dirs</span><br><span class="line">     <span class="keyword">print</span> files</span><br></pre></td></tr></table></figure><h3 id="python-zip函数"><a href="#python-zip函数" class="headerlink" title="python zip函数"></a>python zip函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">zipped = zip(a,b)<span class="comment">#[(1,4),(2,5),(3,6)]</span></span><br></pre></td></tr></table></figure><h3 id="print-重定向"><a href="#print-重定向" class="headerlink" title="print 重定向"></a>print 重定向</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'afile.txt'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  a = <span class="string">'this is a string'</span></span><br><span class="line">  b = <span class="number">11</span></span><br><span class="line">  <span class="keyword">print</span> &gt;&gt; a,b</span><br><span class="line"><span class="comment">## 重定向将a,b输入afile.txt 中</span></span><br></pre></td></tr></table></figure><h3 id="sys-stdout-标准输出"><a href="#sys-stdout-标准输出" class="headerlink" title="sys.stdout 标准输出"></a>sys.stdout 标准输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys.stdout.write(<span class="string">'&#123;&#125;/&#123;&#125;\r'</span>.format(step,len(lines)))<span class="comment"># 控制台输出</span></span><br><span class="line">sys.stdout.flush() <span class="comment"># 将控制台输出的抹掉</span></span><br></pre></td></tr></table></figure><h3 id="xlsx文件读取"><a href="#xlsx文件读取" class="headerlink" title="xlsx文件读取"></a>xlsx文件读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line"></span><br><span class="line">XLSX_PATH = <span class="string">'./video_id.xlsx'</span></span><br><span class="line"></span><br><span class="line">workbook = xlrd.open_workbook(XLSX_PATH)</span><br><span class="line">print(workbook.sheet_names())  <span class="comment">#得到所有表的表名</span></span><br><span class="line"></span><br><span class="line">id_list = []</span><br><span class="line"><span class="keyword">for</span> sheet <span class="keyword">in</span> workbook.sheet_names():</span><br><span class="line">    booksheet = workbook.sheet_by_name(sheet) <span class="comment"># 根据表名得到表</span></span><br><span class="line">    col = booksheet.col_values(<span class="number">0</span>)[<span class="number">1</span>:] <span class="comment"># 得到表的第一列</span></span><br><span class="line">    id_list += col </span><br><span class="line">    print(<span class="string">'sheet name: '</span>+ sheet)</span><br><span class="line">    print(col)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'total account:'</span> +str(len(id_list)))</span><br><span class="line"></span><br><span class="line">from_slsx_get_video(id_list)</span><br></pre></td></tr></table></figure><h3 id="progressbar-进度条的使用"><a href="#progressbar-进度条的使用" class="headerlink" title="progressbar 进度条的使用"></a>progressbar 进度条的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> progress <span class="keyword">import</span> *</span><br><span class="line">progress = ProgressBar()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> progress(range(<span class="number">1000</span>)):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="python-enumerate使用"><a href="#python-enumerate使用" class="headerlink" title="python enumerate使用"></a>python enumerate使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">  print(i,label)</span><br></pre></td></tr></table></figure><h3 id="python-argsort"><a href="#python-argsort" class="headerlink" title="python argsort()"></a>python argsort()</h3><p>argsort是numpy的一个函数，这个函数的作用是返回从小到大排序后的元素下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">-1</span>])</span><br><span class="line">sort_index = np.argsort(a)</span><br><span class="line">a = a[b] <span class="comment"># 进行排序</span></span><br></pre></td></tr></table></figure><h3 id="numpy-cumsum"><a href="#numpy-cumsum" class="headerlink" title="numpy cumsum()"></a>numpy cumsum()</h3><p>cumsum()这个函数用来对数组依次累加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.cumsum(a) <span class="comment"># b = [1,3,6]</span></span><br></pre></td></tr></table></figure><h3 id="numpy-maximum"><a href="#numpy-maximum" class="headerlink" title="numpy maximum()"></a>numpy maximum()</h3><p>这个函数的输入为两个数组，然后生成一个数组，每个位置上为这两个数组中较大的那个。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.array([<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">c = np.maximum(a,b) <span class="comment"># c = [2,2,3]</span></span><br></pre></td></tr></table></figure><h3 id="python-排序算法"><a href="#python-排序算法" class="headerlink" title="python 排序算法"></a>python 排序算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>]</span><br><span class="line">a.sort() <span class="comment"># 输出为空，直接改变a</span></span><br><span class="line">sorted(a) <span class="comment"># 输出排序后的结果，但不改变a</span></span><br></pre></td></tr></table></figure><h3 id="Python-中的序列"><a href="#Python-中的序列" class="headerlink" title="Python 中的序列"></a>Python 中的序列</h3><p>序列是python 中最基本的数据结构。序列对象均可以进行索引，分片，迭代，加，乘操作，可以用in判断元素是否存在序列中。其中list，tuple，str都属于序列。</p><h3 id="list-列表"><a href="#list-列表" class="headerlink" title="list 列表"></a>list 列表</h3><p>list是可修改的一个变量，可以对他进行任意的修改。可以使用list()函数，对str字符串，和tuple进行转化成list。下面对list的各种函数进行讲解：</p><h4 id="index"><a href="#index" class="headerlink" title="index"></a>index</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># index 用于从列表中寻找第一个出现元素的下标</span></span><br><span class="line">nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]</span><br><span class="line">nums.index(<span class="number">2</span>)</span><br><span class="line">nums.index(<span class="number">9</span>) <span class="comment"># 如果找不到则抛出异常</span></span><br></pre></td></tr></table></figure><h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于计算一个元素出现的个数</span></span><br><span class="line">nums.count(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="append"><a href="#append" class="headerlink" title="append"></a>append</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于在元素末尾增加元素</span></span><br><span class="line">nums.append(<span class="number">8</span>)</span><br><span class="line">nums.append([<span class="number">9</span>,<span class="number">8</span>]) <span class="comment"># 将[9,8]作为一个整体加入 nums = [1,2,..,[8,9]]</span></span><br></pre></td></tr></table></figure><h4 id="extend"><a href="#extend" class="headerlink" title="extend"></a>extend</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将list进行融合</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">a.extend(b) <span class="comment"># a = [1,2,3,4,5,6]</span></span><br><span class="line"><span class="comment">## extend 元素不允许直接添加一个元素</span></span><br><span class="line">a.extend(<span class="number">3</span>) <span class="comment"># 报错</span></span><br><span class="line">a.extend([<span class="number">3</span>])</span><br></pre></td></tr></table></figure><h4 id="insert"><a href="#insert" class="headerlink" title="insert"></a>insert</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#insert(pos,val)</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a.insert(<span class="number">1</span>,<span class="number">4</span>) <span class="comment"># a = [1,4,2,3]</span></span><br></pre></td></tr></table></figure><h4 id="pop"><a href="#pop" class="headerlink" title="pop"></a>pop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于移除list中的元素，默认是最后一个,返回值为移除的数</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a.pop() <span class="comment"># a = [1,2,3]</span></span><br><span class="line">a.pop(<span class="number">1</span>) <span class="comment"># a = [1,3]</span></span><br></pre></td></tr></table></figure><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># remove(val) 移除list中值为val的元素</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a.remove(<span class="number">2</span>) <span class="comment"># 移除第一个相同的，a = [1,2,3,3,4]</span></span><br><span class="line">a.remove(<span class="number">8</span>) <span class="comment"># 若不在list中，则抛出异常</span></span><br></pre></td></tr></table></figure><h4 id="reverse"><a href="#reverse" class="headerlink" title="reverse"></a>reverse</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 反转数组</span></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a.reverse() <span class="comment"># a = [3,2,1]</span></span><br></pre></td></tr></table></figure><h4 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法直接对list进行排序，修改list的值</span></span><br><span class="line">a= [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">a.sort() <span class="comment"># 直接修改a, a = [1,2,3]</span></span><br><span class="line">a.sort(reverse=<span class="keyword">True</span>) <span class="comment"># 反向排序</span></span><br><span class="line"><span class="comment"># 此外可以指定key，进行一些多列的排序</span></span><br><span class="line">student_tuples = [</span><br><span class="line">        (<span class="string">'john'</span>, <span class="string">'A'</span>, <span class="number">15</span>),</span><br><span class="line">        (<span class="string">'jane'</span>, <span class="string">'B'</span>, <span class="number">12</span>),</span><br><span class="line">        (<span class="string">'dave'</span>, <span class="string">'B'</span>, <span class="number">10</span>),</span><br><span class="line">]</span><br><span class="line">sorted(student_tuples,key=<span class="keyword">lambda</span> student:student[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmp 指定函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare</span><span class="params">(x,y)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x-y</span><br><span class="line">sorted(alist,cmp = compare)</span><br></pre></td></tr></table></figure><h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a>sorted</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法不是list的方法，返回值为排序结果，不改变a</span></span><br><span class="line">a = [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">sorted(a) <span class="comment"># 返回值为[1,2,3]，a不变</span></span><br></pre></td></tr></table></figure><h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h3><p>元组是一种不可变的序列，不可对tuple进行修改，它用()来表示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = (<span class="number">1</span>,)  <span class="comment"># 当仅有一个元素的时候，必须叫上一个逗号</span></span><br><span class="line">c =() <span class="comment"># 空元组</span></span><br><span class="line">tuple <span class="comment"># 可以进行索引分片，与正常的序列相同</span></span><br></pre></td></tr></table></figure><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>字符串是一种序列，满足索引，分片，加法，乘法等操作，并且字符串也是不可变的变量。</p><h4 id="find"><a href="#find" class="headerlink" title="find"></a>find</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find函数用于找字符串中的子串的位置</span></span><br><span class="line">astr = <span class="string">'this is a dog'</span></span><br><span class="line">astr.find(<span class="string">'is'</span>) <span class="comment"># 返回第一个子串出现的位置</span></span><br><span class="line">astr.find(<span class="string">'is'</span>,<span class="number">4</span>) <span class="comment"># 指定起始位置</span></span><br><span class="line">astr.find(<span class="string">'is'</span>,<span class="number">4</span>,<span class="number">7</span>) <span class="comment"># 指定起始和结束位置</span></span><br></pre></td></tr></table></figure><h4 id="split"><a href="#split" class="headerlink" title="split"></a>split</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split 指定一个分割符对字符串进行分割</span></span><br><span class="line">a = <span class="string">'a,b,c,d'</span></span><br><span class="line">a.split(<span class="string">','</span>) <span class="comment"># 返回一个list数组</span></span><br></pre></td></tr></table></figure><h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># join 函数类似于split的逆函数</span></span><br><span class="line"><span class="string">','</span>.join([<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'3'</span>]) <span class="comment"># 得到一个字符串：'1,2,3'</span></span><br><span class="line"><span class="string">''</span>.join([<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>])  <span class="comment"># 得到一个字符串：‘abc’</span></span><br></pre></td></tr></table></figure><h4 id="strip"><a href="#strip" class="headerlink" title="strip"></a>strip</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于删除左右两边的空格</span></span><br><span class="line">a = <span class="string">'   sdssd   '</span></span><br><span class="line">a.strip() <span class="comment"># a = 'sdssd'</span></span><br><span class="line">a = <span class="string">'##sadsd sasd%%%'</span></span><br><span class="line">a.strip(<span class="string">'#%'</span>) <span class="comment"># 删除左右两边的#与%</span></span><br></pre></td></tr></table></figure><h4 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于体会匹配项</span></span><br><span class="line">a = <span class="string">'this is a dog'</span></span><br><span class="line">a.replace(<span class="string">'is'</span>,<span class="string">'isnt'</span>) <span class="comment"># a = 'this isnt a dog'</span></span><br></pre></td></tr></table></figure><h4 id="lower-upper"><a href="#lower-upper" class="headerlink" title="lower/upper"></a>lower/upper</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回字符变大或者变小的结果</span></span><br><span class="line">a = <span class="string">'ABC'</span></span><br><span class="line">a.lower() <span class="comment"># 放回abc，但是a仍然不变</span></span><br></pre></td></tr></table></figure><h3 id="dict-字典"><a href="#dict-字典" class="headerlink" title="dict 字典"></a>dict 字典</h3><p>dict是有key-value组成的一个类型。</p><p>创建，遍历字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">adict = &#123;&#125;</span><br><span class="line">adict[<span class="string">'a'</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 遍历</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> adict:</span><br><span class="line">  print(k,adict[k])</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> adict.keys():</span><br><span class="line">  print(k,adict[k])</span><br></pre></td></tr></table></figure><p>判断元素是否在字典中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&#125;</span><br><span class="line">d[<span class="string">'a'</span>] = <span class="number">1</span></span><br><span class="line">d[<span class="string">'b'</span>] = <span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'b'</span> <span class="keyword">in</span> d:</span><br><span class="line">  print(<span class="string">'b is a key'</span>)</span><br></pre></td></tr></table></figure><h4 id="clear"><a href="#clear" class="headerlink" title="clear"></a>clear</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d.clear() <span class="comment"># 清空所有项</span></span><br></pre></td></tr></table></figure><h4 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 浅复制</span></span><br><span class="line">d2 = d1.copy() <span class="comment"># 对d2的改变同样也会改变d1</span></span><br><span class="line"><span class="comment"># 深复制，生成许多独立的样本</span></span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">d2 = deepcopy(d1) <span class="comment"># d2与d1无关</span></span><br></pre></td></tr></table></figure><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#访问字典中的元素</span></span><br><span class="line">d.get(<span class="string">'key_val'</span>) <span class="comment"># 返回值，如果没有的话返回None</span></span><br><span class="line">d.get(<span class="string">'key_val'</span>，；<span class="string">'default val'</span>) <span class="comment"># 如果无，放回default val</span></span><br></pre></td></tr></table></figure><h4 id="update"><a href="#update" class="headerlink" title="update"></a>update</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将两个字典进行相加</span></span><br><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>&#125;</span><br><span class="line">b = &#123;<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line">b.update(a) <span class="comment"># b = &#123;'a':1,'b':2&#125;</span></span><br></pre></td></tr></table></figure><h4 id="Items-keys-values"><a href="#Items-keys-values" class="headerlink" title="Items,keys,values"></a>Items,keys,values</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#items将dict项以list的方式返回，keys将key以list的方式返回</span></span><br><span class="line">d = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k ,v <span class="keyword">in</span> d.items():</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> d.keys():</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> d.values():</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="pop-1"><a href="#pop-1" class="headerlink" title="pop"></a>pop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除key</span></span><br><span class="line">d = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line">d.pop(<span class="string">'a'</span>) <span class="comment"># 返回a的val 1</span></span><br><span class="line">d.popitem() <span class="comment"># 随机删除掉一对键值对</span></span><br></pre></td></tr></table></figure><h4 id="对字典进行排序"><a href="#对字典进行排序" class="headerlink" title="对字典进行排序"></a>对字典进行排序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">student = [&#123;<span class="string">'name'</span>: <span class="string">'john'</span>, <span class="string">'score'</span>: <span class="string">'B'</span>, <span class="string">'age'</span>: <span class="number">15</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'jane'</span>, <span class="string">'score'</span>: <span class="string">'A'</span>, <span class="string">'age'</span>: <span class="number">12</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'dave'</span>, <span class="string">'score'</span>: <span class="string">'B'</span>, <span class="string">'age'</span>: <span class="number">10</span>&#125;]</span><br><span class="line">sorted(student,key = <span class="keyword">lambda</span> stu:stu[<span class="string">'age'</span>])</span><br></pre></td></tr></table></figure><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set是一个元素不重合的集合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = set()</span><br><span class="line">a.add(<span class="string">'0'</span>) <span class="comment"># 添加元素</span></span><br><span class="line"><span class="comment">#遍历集合</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line">  print(e)</span><br><span class="line">e.remove(<span class="string">'0'</span>) <span class="comment"># 删除元素</span></span><br></pre></td></tr></table></figure><h4 id="交集，并集，差集"><a href="#交集，并集，差集" class="headerlink" title="交集，并集，差集"></a>交集，并集，差集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s1 = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">s2 = &#123;<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">s3 = s1&amp;s2  <span class="comment"># 交集，s3 = &#123;3&#125;</span></span><br><span class="line">s4 = s1|s2 <span class="comment"># 并集，s4 = &#123;1,2,3,4,5&#125;</span></span><br><span class="line">s5 = s1 - s2 <span class="comment"># 差集，s5 = &#123;1,2&#125;</span></span><br><span class="line"><span class="comment"># 判断是否是子集</span></span><br><span class="line">s1.issubset(s2) <span class="comment"># s1是否是s2的子集</span></span><br></pre></td></tr></table></figure><h3 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(x, y, z=<span class="number">0</span>, *args, **kwargs)</span>:</span></span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 其中x,y为必须传入的参数，z默认参数，</span></span><br><span class="line"><span class="comment"># *args 接受无限制的值参数，变为一个list</span></span><br><span class="line"><span class="comment">#**kwargs 接受键值参数，最后变成一个dict</span></span><br></pre></td></tr></table></figure><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x</span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">map(square,a) <span class="comment"># 返回值为[1,4,9]</span></span><br></pre></td></tr></table></figure><h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reduce(<span class="keyword">lambda</span> x, y: x * y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])  <span class="comment"># 相当于 ((1 * 2) * 3) * 4</span></span><br></pre></td></tr></table></figure><h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter(<span class="keyword">lambda</span> x: x &lt; <span class="string">'g'</span>, <span class="string">'hijack'</span>) <span class="comment"># 返回 ac</span></span><br></pre></td></tr></table></figure><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeitalic</span><span class="params">(func)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapped</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"&lt;i&gt;"</span> + func() + <span class="string">"&lt;/i&gt;"</span></span><br><span class="line">    <span class="keyword">return</span> wrapped</span><br><span class="line"></span><br><span class="line"><span class="meta">@makeitalic</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure><p>即调用hello的时候会提前调用makeitalic，对hello进行装饰。</p><h3 id="pdb-python调试工具"><a href="#pdb-python调试工具" class="headerlink" title="pdb python调试工具"></a>pdb python调试工具</h3><p>pdb是调试代码的一个工具包，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pdb </span><br><span class="line">a = <span class="string">"aaa"</span></span><br><span class="line">pdb.set_trace() </span><br><span class="line">b = <span class="string">"bbb"</span></span><br><span class="line">c = <span class="string">"ccc"</span></span><br><span class="line">final = a + b + c </span><br><span class="line"><span class="keyword">print</span> final</span><br></pre></td></tr></table></figure><p>代码在set_trace()处进入暂停，输入<code>n + enter</code>进入下一行，下一次敲回车将重复上一个操作。输入<code>q</code>退出程序。在控制台允许执行print等代码来获取结果。</p><p>查看当前位置前后11行的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l</span><br></pre></td></tr></table></figure><p>查看当前所有的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll</span><br></pre></td></tr></table></figure><p>添加断点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b line-number</span><br><span class="line">tbreak line-number <span class="comment"># 添加临时断点</span></span><br></pre></td></tr></table></figure><p>清除断点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cl <span class="comment"># 清除所有断点</span></span><br><span class="line">cl line-number <span class="comment"># 清除该行断点</span></span><br></pre></td></tr></table></figure><p>打印变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p expression</span><br></pre></td></tr></table></figure><p>逐行调试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n 下一条</span><br><span class="line">s 下一行，能进入函数题</span><br><span class="line">r 跳过函数体</span><br><span class="line">c 跳到下一个断点</span><br><span class="line">unt line-number 一直执行到line-number</span><br><span class="line">a 查看函数参数</span><br></pre></td></tr></table></figure><h3 id="关于python的相对导入问题"><a href="#关于python的相对导入问题" class="headerlink" title="关于python的相对导入问题"></a>关于python的相对导入问题</h3><p>python包导入的时候不同的层级关系可以使用<code>..</code> 或<code>.</code> 来表示上一层目录和当前目录。这种层级关系是通过module中<code>__name__</code>字段来定义的，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">package/</span><br><span class="line">    __init__.py</span><br><span class="line">    subpackage1/</span><br><span class="line">        __init__.py</span><br><span class="line">        moduleX.py</span><br><span class="line">    moduleA.py</span><br></pre></td></tr></table></figure><p>在这个package的同级目录中调用<code>moduleX.py</code>文件时，该文件<code>__name__</code>就<code>.package.subpackage1.moduleX</code>，因此该moduleX反过来去调用moduleA，可以写作<code>from .. import moduleA</code> 。但是如果在同一个文件目录下执行脚本的话，该文件夹下就会变成top-level script，name就变成了<code>__main__</code>，因此层级结构就会失效。</p><p><strong>因此含有这些层级结构的脚本，不允许直接运行，而是需要由外层的文件来间接调用。</strong></p><h3 id="python-捕获异常"><a href="#python-捕获异常" class="headerlink" title="python 捕获异常"></a>python 捕获异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> traceback <span class="keyword">import</span> print_exc</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> something wrong</span><br><span class="line"><span class="keyword">except</span> Exception, e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'type is:'</span>, e.__class__.__name__</span><br><span class="line">    print_exc()</span><br><span class="line">    <span class="comment"># print "exception happened!"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN 复现</title>
      <link href="/2019/03/16/Faster-RCNN-%E5%A4%8D%E7%8E%B0/"/>
      <url>/2019/03/16/Faster-RCNN-%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>Faster RCNN是目标检测领域的一个benchmark，具有很好的借鉴意义。<a href="http://perper.site/%2F2019%2F02%2F14%2FFaster-RCNN%E8%AF%A6%E8%A7%A3%2F" target="_blank" rel="noopener">Faster RCNN详解</a>介绍了Faster RCNN的网络结构，检测流程，以及一些训练过程等，接下来主要想通过<a href="https://github.com/smallcorgi/Faster-RCNN_TF" target="_blank" rel="noopener">github上的repo</a>来复现一下论文，并在自己的数据集上跑一下结果。</p><a id="more"></a><h3 id="准备环节"><a href="#准备环节" class="headerlink" title="准备环节"></a>准备环节</h3><p><strong>.so文件</strong>：.so文件是Linux下共享库文件，也是ELF格式文件。类似于DLL。.so文件能够节约资源，加快代码速度，方便代码的升级。</p><p><strong>.o文件</strong>：目标文件,相当于windows中的.obj文件</p><p><strong>.a文件</strong>：静态库,是好多个.o合在一起,用于静态连接</p><p>其中这些共享链接文件与操作系统相关，换一个系统时需要重新生成。</p><p><strong>pycocotools:</strong>这个文件库的作用是操纵coco数据集的一些api。安装方法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><br></pre></td></tr></table></figure><h3 id="环境的配置"><a href="#环境的配置" class="headerlink" title="环境的配置"></a>环境的配置</h3><p>参考tensorpack的 <a href="https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN" target="_blank" rel="noopener">readme</a>。将所有环境配置好，以及数据集的格式。</p><h3 id="COCO-train2017数据标注格式："><a href="#COCO-train2017数据标注格式：" class="headerlink" title="COCO train2017数据标注格式："></a>COCO train2017数据标注格式：</h3><p>整个json共有一下几个字段：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">    <span class="attr">"categories"</span>: [category]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中<code>info,licenses</code>字段表示一些数据集以及证书信息。</p><p><code>images</code>字段表示图片路径信息，有以下几个字段：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">"images": [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"license"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"file_name"</span>: <span class="string">"000000397133.jpg"</span>,</span><br><span class="line">            <span class="attr">"coco_url"</span>: <span class="string">"/val2017/000000397133.jpg"</span>,</span><br><span class="line">            <span class="attr">"height"</span>: <span class="number">427</span>,</span><br><span class="line">            <span class="attr">"width"</span>: <span class="number">640</span>,</span><br><span class="line">            <span class="attr">"date_captured"</span>: <span class="string">"2013-11-14 17:02:52"</span>,</span><br><span class="line">            <span class="attr">"flickr_url"</span>: url,</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">397133</span></span><br><span class="line">        &#125;,</span><br></pre></td></tr></table></figure><p>关键字段为<code>coco_url</code>，即为图片的路径名，<code>id</code>:与annotations字段image_id相对应的一个id。</p><p><code>annotation</code>字段包含以下内容：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">annotation&#123;</span><br><span class="line">    "id": int,    </span><br><span class="line">    "image_id": int,</span><br><span class="line">    "category_id": int,</span><br><span class="line">    "segmentation": RLE or [polygon],</span><br><span class="line">    "area": float,</span><br><span class="line">    "bbox": [x,y,width,height],</span><br><span class="line">    "iscrowd": 0 or 1,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>image_id</code>:与images字段中id对应，找到图片的真实路径</p><p><code>category_id</code>：images box中的类别信息</p><p><code>segmentation</code>：mask的区域，即多边形区域</p><p><code>bbox</code>：目标boundding box[top left x position, top left y position, width, height]</p><p><code>iscrowd</code>：0 or 1，0表示segmentation为RLE格式，1表示其为polygon格式。</p><h3 id="将原有标准修改为COCO格式"><a href="#将原有标准修改为COCO格式" class="headerlink" title="将原有标准修改为COCO格式"></a>将原有标准修改为COCO格式</h3><p>由于源码中大量使用道其他字段，因此基本上都需要补充完整。</p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>对于大部分的源码思路都可以视为：</p><ul><li>准备数据，配置网络，设置holder</li><li>设置权重和bias</li><li>搭建网络</li><li>设置损失函数，设置优化器</li><li>step by step训练网络</li></ul><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--logdir'</span>, help=<span class="string">'log directory'</span>, default=<span class="string">'train_log/maskrcnn'</span>)</span><br><span class="line">...</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="comment">## 使用</span></span><br><span class="line">print(args.logdir)</span><br></pre></td></tr></table></figure><p>COCO数据集中有81类，我们使用的数据集仅有两类，因此需要对数据集部分进行修改。</p>]]></content>
      
      
      <categories>
          
          <category> 论文复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>awk,grep 学习</title>
      <link href="/2019/03/16/awk,grep-%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/03/16/awk,grep-%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>awk是一个文本解释型语言，在文本处理领域十分的常用。awk的典型用途如：</p><ul><li>文本处理</li><li>执行算术运算</li><li>执行字符串操作</li></ul><a id="more"></a><h3 id="awk的工作流："><a href="#awk的工作流：" class="headerlink" title="awk的工作流："></a>awk的工作流：</h3><p>awk的工作流十分简单：<strong>读取-&gt;执行-&gt;重复</strong></p><p>read：从标准输入流中读取一行</p><p>execute：所有awk执行对文本中每一行都执行处理</p><p>repeat：处理过程不断重复，直到文件到达结尾</p><h3 id="awk命令行"><a href="#awk命令行" class="headerlink" title="awk命令行"></a>awk命令行</h3><p>awk的命令行格式为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk [option] afile.py</span><br></pre></td></tr></table></figure><p>我们可以使用单引号来指定awk命令，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk '&#123;print&#125;' afile.py</span><br></pre></td></tr></table></figure><p>以下语句输出数据中第三列和第四列：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '&#123;print $3 "\t" $4&#125;' marks.txt</span><br></pre></td></tr></table></figure><p>其中<code>-F</code>设置分割符为<code>,</code>，awk默认分割符号为空格。在使用程序语句如<code>print</code>时，需要加上大括号。其中<code>$3,$4</code>表示数据中的第3列和第4列。<code>$0</code>表示一整行都输出。</p><p>以下语句输出匹配字符(不指定输出则输出一整行)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk '/a/' aw.txt # 输出含有a的一整行</span><br><span class="line">awk '/a/ &#123;print $1 $2&#125;'  aw.txt # 输出含有a的行的1,2列</span><br></pre></td></tr></table></figure><p>重定向输出：即将awk的输出，输出到文件中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk '/a/' aw.txt &gt;&gt; new.txt</span><br></pre></td></tr></table></figure><p>不显示重复行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '!seen[$1]++' aw.txt</span><br></pre></td></tr></table></figure><p>其中seen可以看成一个字典dict，当没有这个值的时候!seen[$1] == 0,因此允许输出。但当这个值以及存在时，则不输出。</p><p>单引号内可以使用各种判断语句：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F , '$1&gt;$2 &#123;print $0&#125;' aw.txt</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）</span></span><br><span class="line">$ awk <span class="string">'&#123;print $1,$4&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 指定 , 为分割符（-F），将字符串分割</span></span><br><span class="line">$  awk -F, <span class="string">'&#123;print $1,$2&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 多个分割符，先用 空格后用 ,</span></span><br><span class="line">$ awk -F <span class="string">'[ ,]'</span>  <span class="string">'&#123;print $1,$2,$5&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 设置变量 -v</span></span><br><span class="line">$ awk -va=1 -vb=s <span class="string">'&#123;print $1,$1+a,$1b&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 过滤出第一列大于2的数</span></span><br><span class="line">$ awk <span class="string">'$1&gt;2'</span> log.txt </span><br><span class="line"><span class="comment"># CSV_PATH为输入，TRAIN_PATH为输出 ,-v 为定义变量</span></span><br><span class="line">awk -v min_area=<span class="variable">$&#123;MIN_AREA&#125;</span> -F <span class="string">','</span> <span class="string">'&#123;   </span></span><br><span class="line"><span class="string">    area=(($4-$2)*($5-$3));</span></span><br><span class="line"><span class="string">    if(area&gt;min_area)&#123;</span></span><br><span class="line"><span class="string">        print $0;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span>&lt;<span class="variable">$&#123;CSV_PATH&#125;</span> &gt;&gt; <span class="variable">$&#123;TRAIN_PATH&#125;</span></span><br></pre></td></tr></table></figure><p><a href="https://coolshell.cn/articles/9070.html" target="_blank" rel="noopener">awk参考链接</a></p><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><p>grep是类unix系统中执行正则表达式的命令 ,下面是grep使用的<a href="https://www.cnblogs.com/sky-heaven/p/10187395.html" target="_blank" rel="noopener">15个场景</a>：</p><ol><li>下面语句判断文件中是否含有搜索的内容：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep 'tf' afile.py</span><br><span class="line">cat afile.py |grep 'tf'</span><br></pre></td></tr></table></figure><ol start="2"><li>从多个文件中查找指定字符：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 文件夹有demo_1.txt,demo_2 文件</span></span><br><span class="line">grep 'this' demo_1.txt demo_2.txt</span><br><span class="line">grep 'this' demo_*</span><br></pre></td></tr></table></figure><ol start="3"><li>忽略大小写(-i)：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -i 'The' demo.txt</span><br></pre></td></tr></table></figure><ol start="4"><li>在文件中匹配正则表达式：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep 'a*b' demo.txt</span><br></pre></td></tr></table></figure><ol start="5"><li>grep -w 完全匹配</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -w 'ab' demo.txt</span><br><span class="line">grep -iw 'ab' demo.txt # 不区分大小写</span><br></pre></td></tr></table></figure><ol start="6"><li>grep显示匹配出的前后几行</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -A 3 'a' demo.txt # 显示a出现的行，以及后三行</span><br><span class="line">grep -B 3 'a' demo.txt # 显示a出现的行，以及前三行</span><br><span class="line">grep -C 3 'a' demo.txt # 显示a出现的行，以及上下三行</span><br></pre></td></tr></table></figure><ol start="7"><li>用GREP_OPTIONS来让查找的项醒目</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export GREP_OPTIONS='--color=auto' GREP_COLOR='100;8'</span><br></pre></td></tr></table></figure><ol start="8"><li>用grep -r来搜索所有的文件及子目录</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -r 'file' *</span><br></pre></td></tr></table></figure><ol start="9"><li>显示不匹配的项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v 'match' demo.txt</span><br></pre></td></tr></table></figure><ol start="10"><li>匹配多个项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -e '1' -e 'a' -e 'q' demo.txt</span><br><span class="line">grep -v -e '1' -e 'q' demo.txt # 输出一个都不匹配的项</span><br></pre></td></tr></table></figure><ol start="11"><li>计算匹配的项</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -c 'a' aw.txt</span><br><span class="line">grep -v -c 'a' aw.txt # 不匹配的项</span><br></pre></td></tr></table></figure><ol start="12"><li>显示匹配的文件名:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -l 'a' a*  #输出a开头且匹配的文件名</span><br></pre></td></tr></table></figure><ol start="13"><li>只显示匹配的字符串：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -o 'a.*b' aw.txt  # 而不是显示一行</span><br></pre></td></tr></table></figure><ol start="14"><li>显示匹配字符的行号:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n 'a' aw.txt</span><br></pre></td></tr></table></figure><ol start="15"><li>显示匹配字符的字节位置：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -b 'a' aw.txt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vim 学习</title>
      <link href="/2019/03/13/Vim-%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/03/13/Vim-%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="Vim-简介"><a href="#Vim-简介" class="headerlink" title="Vim 简介"></a>Vim 简介</h3><p>Vim是在Linux环境下的一种强大的文本编辑工具，之所以学习它，是由于在服务器上写代码需要直接在服务器上操作，不像windows上有那种简单课操作的编辑器，如sublime等等。</p><h3 id="Vim-模式"><a href="#Vim-模式" class="headerlink" title="Vim 模式"></a>Vim 模式</h3><p>Vim与大多数文本编辑器不同，它的默认模式为移动光标，删除文本等，而不是大多数编辑器那样直接为插入模式。</p><p><strong>普通模式：</strong></p><p>普通模式能进行的操作如移动光标，删除文本等。</p><p>删除指令：</p><p><code>dd</code> ：删除当前行</p><p><code>d</code>+ 上下左右移动指令，分别表示删除上一行，左一个，下一行，或右一个</p><p><code>2dd</code>: 删除两行</p><p><strong>插入模式：</strong></p><p>在普通模式按i，或a进入插入模式，ESC推出插入模式。</p><p><strong>可视模式：</strong></p><p>这个模式类似与普通模式，对样本有高亮</p><p><strong>命令行模式：</strong></p><p>在命令行模式中可以输入会被解释成并执行的文本。例如执行命令（<code>:</code>键），搜索（<code>/</code>和<code>?</code>键）或者过滤命令（<code>!</code>键）</p><h3 id="游标使用："><a href="#游标使用：" class="headerlink" title="游标使用："></a>游标使用：</h3><p>h，j，k，l：分别表示上下左右移动</p><p>w: 向下一个单词，b: 向上一个单词</p><h3 id="进入插入模式"><a href="#进入插入模式" class="headerlink" title="进入插入模式"></a>进入插入模式</h3><p><code>i</code> : 当前光标出插入</p><p><code>A</code>: 当前光标所在行最后一个位置插入 </p><p><code>o</code>: 当前光标的下一行插入</p><p><code>a</code>: 当前光标的后一个位置</p><h3 id="退出Vim模式"><a href="#退出Vim模式" class="headerlink" title="退出Vim模式"></a>退出Vim模式</h3><p><code>:x</code>: 保存并退出，等同于<code>:wq</code></p><p><code>:q!</code>: 强制退出，不保存</p><p><code>:q</code>: 退出不保存</p><p><code>shift + zz</code>: 退出并保存</p><h3 id="删除文本"><a href="#删除文本" class="headerlink" title="删除文本"></a>删除文本</h3><p>普通模式下的删除文本操作。</p><p><code>x</code>: 删除当前光标处的一个字符</p><p><code>X</code>:删除光标前一个字符</p><p><code>dd</code>: 删除整行</p><p><code>dw</code>: 删除整个单词</p><p><code>D</code>: 删除至句尾</p><p><code>d^</code>: 删除至句首</p><p><code>dG</code>: 删除至文章末尾</p><p><code>d1G</code>: 删除至文章开头</p><h3 id="重复执行上次命令"><a href="#重复执行上次命令" class="headerlink" title="重复执行上次命令"></a>重复执行上次命令</h3><p>普通模式下<code>.</code>表示重复执行上一次命令。执行相同执行操作代码：<code>N&lt;command&gt;</code>,如<code>10x</code>,<code>20dd</code>,<code>d5w</code>。</p><p>显示行号: <code>:set nu</code></p><h3 id="行间跳跃"><a href="#行间跳跃" class="headerlink" title="行间跳跃"></a>行间跳跃</h3><p><code>NG</code>: 游标跳到第N行</p><p><code>gg</code>: 游标跳到第一行</p><p><code>G</code>: 游标跳到最后一行</p><p><code>ctrl + o</code>: 回到上一次跳转的位置</p><h3 id="行内跳跃"><a href="#行内跳跃" class="headerlink" title="行内跳跃"></a>行内跳跃</h3><p><code>w</code>: 跳到下一个单词的开头</p><p><code>e</code>: 当前单词的结尾</p><p><code>0</code>: 跳到行头</p><p><code>$</code>: 跳到行尾</p><p><code>f 字母</code>：向后搜索字母并跳到第一个该字母的位置</p><p><code>F 字母</code>：向前搜索字母，第一个字母位置</p><p><code>t 字母</code>： 向后搜索字母，并跳到这个字母的前一个数</p><p><code>T 字母</code>： 向前搜索字母，并跳到其后一个数</p><p><code>~</code>: 将字母大小写转换</p><h3 id="文本的复制"><a href="#文本的复制" class="headerlink" title="文本的复制"></a>文本的复制</h3><p><code>yy</code>: 复制游标所在的整行</p><p><code>3yy</code>：复制3行</p><p><code>y0</code>: 复制到行首</p><p><code>y$</code>: 复制到行尾</p><h2 id="字符替换及坐标操作"><a href="#字符替换及坐标操作" class="headerlink" title="字符替换及坐标操作"></a>字符替换及坐标操作</h2><p><code>r + &lt;替换字母&gt;</code>: 替换掉光标所在位置的字母</p><p><code>R</code>： 连续替换，知道按下esc</p><p><code>cc</code>: 删掉这一行，换为插入模式</p><p><code>cw</code>: 删掉一个词然后进入插入模式</p><p><code>C</code>: 删除光标位置一直到行末，进入插入模式</p><p><code>u</code>: 撤销当前操作</p><p><code>U</code>: 撤销当前所有操作</p><h3 id="指令替换"><a href="#指令替换" class="headerlink" title="指令替换"></a>指令替换</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%s/imgs/car_openimg\/imgs # 使用car_openimg/imgs替换imgs</span><br></pre></td></tr></table></figure><h3 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h3><p><code>shift + &gt;</code>: 向右缩进</p><p><code>shift + &lt;</code>: 向左缩进</p><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p><code>/ + word</code>: 表示查找word，输入n或N查找下一个位置</p><p><code>? + word</code>: 与上相同，只不过查找方向不同</p><p><code>\*</code>: 查找游标所在位置的单词</p><p><code>g\*</code>： 查找部分符合要求的单词</p><h3 id="视窗"><a href="#视窗" class="headerlink" title="视窗"></a>视窗</h3><p><code>:new</code>: 新建视窗</p><p><code>:close</code>: 关闭视窗</p><p><code>:q</code>: 同上</p><h3 id="执行外部shell命令"><a href="#执行外部shell命令" class="headerlink" title="执行外部shell命令"></a>执行外部shell命令</h3><p><code>:! command</code>:执行外部shell 命令</p><p><code>:w filename</code>: 将当前编辑的文件另存为filename</p><p>vim 确认当前的括号：</p><p><code>shift + e</code>: 光标跳到当前内容的第一个框</p><p>重复上次操作：小数点 <code>.</code></p><h3 id="VIM-打开多个文件"><a href="#VIM-打开多个文件" class="headerlink" title="VIM 打开多个文件"></a>VIM 打开多个文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim 1.py 2.py</span><br><span class="line">:bn ## 切换</span><br></pre></td></tr></table></figure><h3 id="Vim-行移动"><a href="#Vim-行移动" class="headerlink" title="Vim 行移动"></a>Vim 行移动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dd,k,p</span><br></pre></td></tr></table></figure><p>k为向上移动，当移动到合适的位置时用p粘贴。</p><h3 id="tabe-多标签切换"><a href="#tabe-多标签切换" class="headerlink" title="tabe 多标签切换"></a>tabe 多标签切换</h3><p><code>:tabe a.txt</code>： 打开a.txt 文件</p><p><code>gt</code>: 在多标签中切换</p><p><code>:tabc</code> 关闭标签，或<code>:x</code>等</p><h3 id="vim-跳转到变量或函数的定义处"><a href="#vim-跳转到变量或函数的定义处" class="headerlink" title="vim 跳转到变量或函数的定义处"></a>vim 跳转到变量或函数的定义处</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ ,ctrl+i #跳转</span><br><span class="line">ctrl + o : #跳转回来</span><br></pre></td></tr></table></figure><p>查找鼠标所在位置的字符：<code>gd</code></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux trick</title>
      <link href="/2019/03/13/linux-trick/"/>
      <url>/2019/03/13/linux-trick/</url>
      
        <content type="html"><![CDATA[<h3 id="pickle-文件"><a href="#pickle-文件" class="headerlink" title="pickle 文件"></a>pickle 文件</h3><p>pickle文件的解释如下：</p><blockquote><p>It is used for serializing and de-serializing a Python object structure. Any object in python can be pickled so that it can be saved on disk. </p></blockquote><p>即用来将python对象序列化后存放在磁盘上的一个工具包。</p><p> Pickling is a way to convert a python object (list, dict, etc.) into a character stream.</p><p>pickle主要有两个功能，<code>dump</code> 以及<code>load</code>：</p><blockquote><p>pickle has two main methods. The first one is dump, which dumps an object to a file object and the second one is load, which loads an object from a file object.</p></blockquote><p>dump用来将dict，list等等保存成pickle文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line">file = open(<span class="string">'pickleObject.pickle'</span>,<span class="string">'wb'</span>)</span><br><span class="line">pickle.dump(a,file)</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure><p>load用来将pickle文件读出来，还原成python object</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">file = open(<span class="string">'pickleObject.pickle'</span>,<span class="string">'rb'</span>)</span><br><span class="line">b = pickle.load(file)  <span class="comment"># b == a is a dict</span></span><br><span class="line">print(b[<span class="string">'a'</span>])</span><br></pre></td></tr></table></figure><p><strong>linux 操作：</strong></p><p>管道命令?</p><p>查看文件夹下文件个数：</p><p><code>ls -l |grep &quot;^-&quot;|wc -l</code></p><p>写txt文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line">f = open(<span class="string">'a.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> a.keys():</span><br><span class="line">    f.write(key+<span class="string">'\n'</span>)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><p>读txt文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">'a.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">    print(line,end = <span class="string">''</span>)</span><br></pre></td></tr></table></figure><p>assert语句：</p><p>在发生错误时让算法崩溃。其用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression,<span class="string">'报错语句'</span></span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> expression:</span><br><span class="line">    <span class="keyword">raise</span> AssertionError</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> type(a_str)== str</span><br></pre></td></tr></table></figure><p>读当前文件夹下的文件名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> os.listdir(<span class="string">'./'</span>):</span><br><span class="line">    print(path)</span><br></pre></td></tr></table></figure><p>复制：将文件file1复制到dir1下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp file1 dir1</span><br></pre></td></tr></table></figure><p>python 找到最后一个.的位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">str.rfind(<span class="string">'.'</span>, beg=<span class="number">0</span> end=len(str))</span><br></pre></td></tr></table></figure><h3 id="python-set操作"><a href="#python-set操作" class="headerlink" title="python set操作"></a>python set操作</h3><p>set 中保存不重复的key。</p><p>创建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aset = &#123;<span class="string">'apple'</span>,<span class="string">'orange'</span>,<span class="string">'pea'</span>&#125;</span><br></pre></td></tr></table></figure><p>判断set中是否含有key：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">'apple'</span> <span class="keyword">in</span> aset:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>set集合的交并集操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a-b <span class="comment"># a中包含而b中不包含的元素</span></span><br><span class="line">a|b <span class="comment"># a与b的元素并集</span></span><br><span class="line">a&amp;b <span class="comment"># a与b中元素的交集</span></span><br><span class="line">a^b <span class="comment"># 不同时包含于a与b中元素</span></span><br></pre></td></tr></table></figure><p>Set 删除操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aset.remove(<span class="string">'apple'</span>)</span><br></pre></td></tr></table></figure><p>Linux 复制文件夹：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r dirname .</span><br></pre></td></tr></table></figure><p>Vim 撤销：<code>u</code></p><p>python 在指定文件位置处添加字符后重新保存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">f1.open(<span class="string">'a.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line">content = f1.read()</span><br><span class="line">pos = content.find(<span class="string">'word'</span>)</span><br><span class="line">content = content[:word+<span class="number">4</span>]+<span class="string">'add something'</span>+content[word+<span class="number">4</span>:]</span><br><span class="line">f1.close()</span><br><span class="line">f2 = open(<span class="string">'a.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">f2.write(content)</span><br></pre></td></tr></table></figure><h3 id="shell-语言"><a href="#shell-语言" class="headerlink" title="shell 语言"></a>shell 语言</h3><p>用shell写成的文件通常被保存为<code>.sh</code>后缀。被称为脚本Bash的应用程序。 可以理解为在linux电脑上的一系列系统操作，比如下载文件，进入某个文件夹，下载某个文件等等。即可以通过shell程序来指挥kernel，让系统达成我们需要的硬件任务。</p><p>示例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Program:</span></span><br><span class="line"><span class="comment"># This program shows "Hello World!" in your screen.</span></span><br><span class="line"><span class="comment"># History:</span></span><br><span class="line"><span class="comment"># 2015/07/16 VBird First release</span></span><br><span class="line">PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/<span class="built_in">local</span>/bin:/usr/<span class="built_in">local</span>/sbin:~/bin</span><br><span class="line"><span class="built_in">export</span> PATH</span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"Hello World! \a \n"</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><p>第一行：<code>#!/bin/bash</code> 作用为宣告这个档案内的语法使用bash的语法，所有的sh文件必须有这一句。其他的<code>#</code> 则表示注释作用。</p><p><code>#</code> 号注释部分：建议你一定要养成说明该script的习惯：1.内容与功能； 2.版本资讯； 3.作者与联络方式； 4.建档日期；5.历史纪录等等</p><p>PATH部分为主要的环境变量，用来保存当前的路径信息。</p><p>echo那一句为程序的主要执行部分。</p><p>使用<code>sh hello.sh</code> 来执行代码。</p><p>shell变量：</p><p>变量名不加美元符号，而且变量名和等号之间不能有空格。使用变量是在变量名之前加上美元符：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">your_name=<span class="string">'zhouwh'</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$your_name</span></span><br></pre></td></tr></table></figure><p>定义只读变量：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">myUrl=<span class="string">"http://www.google.com"</span></span><br><span class="line"><span class="built_in">readonly</span> myUrl  <span class="comment"># 之后无法修改</span></span><br></pre></td></tr></table></figure><p>删除变量：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unset</span> variable_name</span><br></pre></td></tr></table></figure><p>Shell 字符串：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str=<span class="string">'单引号，双引号，不用都行'</span></span><br><span class="line">str=<span class="string">"this is \" <span class="variable">$your_name</span> \""</span> <span class="comment">#需要转义的情况，双引号里头允许出现</span></span><br></pre></td></tr></table></figure><p>字符串拼接：直接使用双引号即可：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用双引号拼接</span></span><br><span class="line">greeting=<span class="string">"hello, "</span><span class="variable">$your_name</span><span class="string">" !"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$greeting</span></span><br></pre></td></tr></table></figure><p>获取字符串长度：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">string=<span class="string">"abcd"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#string&#125;</span> <span class="comment">#输出 4</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;string:1:3&#125;</span> <span class="comment"># 输出 bcd 子串</span></span><br></pre></td></tr></table></figure><p>控制语句：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if 语句</span></span><br><span class="line"><span class="keyword">if</span> condition</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    command1 </span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    commandN </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment"># for 语句</span></span><br><span class="line"><span class="keyword">for</span> loop <span class="keyword">in</span> 1 2 3 4 5</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"The value is: <span class="variable">$loop</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#while语句</span></span><br><span class="line"><span class="keyword">while</span> condition</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">command</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="awk-语句："><a href="#awk-语句：" class="headerlink" title="awk 语句："></a>awk 语句：</h3><p>awk是一个强大的文本分析工具，简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。其基本的用法如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'&#123;[pattern] action&#125;'</span> &#123;filenames&#125;</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以空格为分割符，输出log.txt 文件中的每一行的第1和第4个数（从1开始）</span></span><br><span class="line">$ awk <span class="string">'&#123;print $1,$4&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 指定 , 为分割符（-F），将字符串分割</span></span><br><span class="line">$  awk -F, <span class="string">'&#123;print $1,$2&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 多个分割符，先用 空格后用 ,</span></span><br><span class="line">$ awk -F <span class="string">'[ ,]'</span>  <span class="string">'&#123;print $1,$2,$5&#125;'</span>   log.txt</span><br><span class="line"><span class="comment"># 设置变量 -v</span></span><br><span class="line">$ awk -va=1 -vb=s <span class="string">'&#123;print $1,$1+a,$1b&#125;'</span> log.txt</span><br><span class="line"><span class="comment"># 过滤出第一列大于2的数</span></span><br><span class="line">$ awk <span class="string">'$1&gt;2'</span> log.txt </span><br><span class="line"><span class="comment"># CSV_PATH为输入，TRAIN_PATH为输出</span></span><br><span class="line">awk -v min_area=<span class="variable">$&#123;MIN_AREA&#125;</span> -F <span class="string">','</span> <span class="string">'&#123;</span></span><br><span class="line"><span class="string">    area=(($4-$2)*($5-$3));</span></span><br><span class="line"><span class="string">    if(area&gt;min_area)&#123;</span></span><br><span class="line"><span class="string">        print $0;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span>&lt;<span class="variable">$&#123;CSV_PATH&#125;</span> &gt;&gt; <span class="variable">$&#123;TRAIN_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除第一列</span></span><br><span class="line">awk <span class="string">'&#123;$1="";print $0&#125;'</span>  file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除第一行</span></span><br><span class="line">awk -F <span class="string">'\t'</span> <span class="string">'NR==1&#123;next&#125; &#123;print $0&#125;'</span> <span class="comment"># 当NR==1时跳过</span></span><br></pre></td></tr></table></figure><p><strong>CSV 文件</strong>（Comma Separated Values file，即逗号分隔值文件）为一种纯文本文件。</p><p>python 读取csv文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'stocks.csv'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f_csv = csv.reader(f)</span><br><span class="line">    headers = next(f_csv)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> f_csv:</span><br><span class="line">        <span class="comment"># Process row</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>python保存csv文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'some.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    writer.writerow([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure><p>python dict合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_dict = dict(dict1.items()+dict2.items())</span><br></pre></td></tr></table></figure><h3 id="Python-virtualenv"><a href="#Python-virtualenv" class="headerlink" title="Python virtualenv"></a>Python virtualenv</h3><p><code></code>virtualenv`创建一个拥有自己安装目录的环境, 这个环境不与其他虚拟环境共享库, 能够方便的管理python版本和管理python库。</p><p>安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure><p>创建新环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv zhou_env</span><br></pre></td></tr></table></figure><p>激活：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ./bin/activate</span><br></pre></td></tr></table></figure><p>退出虚拟环境：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure><h3 id="matplotlib-画图"><a href="#matplotlib-画图" class="headerlink" title="matplotlib 画图"></a>matplotlib 画图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">data = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">print(type(data))</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">绘制直方图</span></span><br><span class="line"><span class="string">data:必选参数，绘图数据</span></span><br><span class="line"><span class="string">bins:直方图的长条形数目，可选项，默认为10</span></span><br><span class="line"><span class="string">normed:是否将得到的直方图向量归一化，可选项，默认为0，代表不归一化，显示频数。normed=1，表示归一化，显示频率。</span></span><br><span class="line"><span class="string">facecolor:长条形的颜色</span></span><br><span class="line"><span class="string">edgecolor:长条形边框的颜色</span></span><br><span class="line"><span class="string">alpha:透明度</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">plt.hist(data, bins=<span class="number">40</span>, normed=<span class="number">0</span>, facecolor=<span class="string">"blue"</span>, edgecolor=<span class="string">"black"</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment"># 显示横轴标签</span></span><br><span class="line">plt.xlabel(<span class="string">"区间"</span>)</span><br><span class="line"><span class="comment"># 显示纵轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">"count"</span>)</span><br><span class="line"><span class="comment"># 显示图标题</span></span><br><span class="line">plt.title(<span class="string">"bbox—count"</span>)</span><br><span class="line">plt.savefig(<span class="string">'aimg.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="文件传输"><a href="#文件传输" class="headerlink" title="文件传输"></a>文件传输</h3><p><code>rz</code>: 在iterm2中输入rz指令，将会出现一个窗口选择文件，开始上传到当前文件夹。</p><p><code>sz filename</code>: iterm2 弹出一个窗口，选择保存文件的地址。 </p><p>vim 隐藏到后台：<code>ctrl + z</code></p><p>命令行调出vim：<code>fg</code></p><p>linux看文件大小：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls -lsh</span><br><span class="line">du -sh *</span><br></pre></td></tr></table></figure><h3 id="打包文件"><a href="#打包文件" class="headerlink" title="打包文件"></a>打包文件</h3><p>压缩：<code>tar czvf file.tar ./filename</code>,czvf表示create zip view file<br>解压缩：<code>tar xzvf file.tar</code>，xzvf表示extract zip view file</p><h3 id="过滤数据集中不合适的记录"><a href="#过滤数据集中不合适的记录" class="headerlink" title="过滤数据集中不合适的记录"></a>过滤数据集中不合适的记录</h3><ol><li>找出不合适的记录：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat all_box.csv | grep '不合适记录名'  # grep拿cat的输出当作输入</span><br></pre></td></tr></table></figure><ol start="2"><li>维护一个delete_imgs.txt 文件，用来存放不合适记录</li><li>使用delete_imgs.txt 文件中不合适记录来查看all_box.csv(数据集)中不合适的记录。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -f delete_imgs.txt  all_box.csv</span><br></pre></td></tr></table></figure><ol start="4"><li>删掉不合适记录，得到合适记录的输出，将输出存成一个新的new_box</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v -f delete_imgs.txt all_box.csv &gt; new_box.csv</span><br></pre></td></tr></table></figure><ol start="5"><li>查看剩下的合适条数：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat new_box.csv |wc -l # -l 行数 -w 字数</span><br></pre></td></tr></table></figure><h3 id="命令行输出"><a href="#命令行输出" class="headerlink" title="命令行输出"></a>命令行输出</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat *.csv &gt; all_box.csv</span><br></pre></td></tr></table></figure><p>awk判断字段1不重复的记录数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F ',' '!seen[$1++]' train_set.csv |wc -l</span><br></pre></td></tr></table></figure><p>linux 查看显卡运行状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><h3 id="python-shuffle操作"><a href="#python-shuffle操作" class="headerlink" title="python shuffle操作"></a>python shuffle操作</h3><p>shuffle操作将数据集打乱：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">list = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">random.shuffle(list)</span><br></pre></td></tr></table></figure><p>tmux:</p><p>tmux 可以在终端软件重启后通过命令行恢复上次的 session ,即当你训练网络中断时，下次开启仍然可以重新连接。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tmux ls  # 列出所有的tmux会话</span><br><span class="line">tmux new -s zhouwenhui  # 创建新的会话</span><br><span class="line">tmux -2 attach -t zhouwenhui # 重新进入原来的session</span><br><span class="line">ctrl + b , d # 暂时退出当前会话</span><br><span class="line">ctrl + b , c # 新建窗口</span><br><span class="line">ctrl + b , w # 切换窗口</span><br><span class="line">exit # 退出当前窗口</span><br></pre></td></tr></table></figure><h3 id="Linux创建账号"><a href="#Linux创建账号" class="headerlink" title="Linux创建账号"></a>Linux创建账号</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">useradd zhouwh</span><br><span class="line">passwd zhouwh</span><br><span class="line">userdel [-r] zhouwh # 删掉用户</span><br></pre></td></tr></table></figure><h3 id="Linux-给用户赋予root权限"><a href="#Linux-给用户赋予root权限" class="headerlink" title="Linux 给用户赋予root权限"></a>Linux 给用户赋予root权限</h3><p> vim /etc/passwd 文件，找到新创建的用户所在行，把用户ID修改为 0即可，如下。</p><blockquote><p>zhouwh​：x:0:1002::/home/zhouwh:/bin/bash</p></blockquote><h3 id="Linux用户切换"><a href="#Linux用户切换" class="headerlink" title="Linux用户切换"></a>Linux用户切换</h3><p>新建的用户的目录在/home/zhouwh底下，使用如下语句可以实现自由的切换。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su - zhouwh # 切换到zhouwh 用户</span><br><span class="line">su - root # 切换到root 用户</span><br></pre></td></tr></table></figure><h3 id="Linux-安装anaconda"><a href="#Linux-安装anaconda" class="headerlink" title="Linux 安装anaconda"></a>Linux 安装anaconda</h3><p>在anaconda上下载相应版本的安装软件，然后执行以下操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-4.4.0-Linux-x86_64.sh ## 安装</span><br><span class="line">echo 'export PATH="~/anaconda3/bin:$PATH"' &gt;&gt; ~/.bashrc# 环境变量</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 国内镜像</span><br><span class="line">rm -rf anaconda # 卸载</span><br></pre></td></tr></table></figure><h3 id="Json-的读写"><a href="#Json-的读写" class="headerlink" title="Json 的读写"></a>Json 的读写</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Writing JSON data:&#123;'a': 'Runoob', 'b': 7&#125;</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(data, f)</span><br><span class="line"><span class="comment"># Reading data back</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></table></figure><h3 id="dict-to-json"><a href="#dict-to-json" class="headerlink" title="dict to json"></a>dict to json</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  json.dump(data,f)</span><br></pre></td></tr></table></figure><h3 id="打开文件头几行-末尾几行"><a href="#打开文件头几行-末尾几行" class="headerlink" title="打开文件头几行/末尾几行"></a>打开文件头几行/末尾几行</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat afile.txt|head -n <span class="number">100</span></span><br><span class="line">cat afile.txt|tail -n <span class="number">100</span></span><br></pre></td></tr></table></figure><h3 id="指定运行的GPU"><a href="#指定运行的GPU" class="headerlink" title="指定运行的GPU"></a>指定运行的GPU</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2 python train.py</span><br></pre></td></tr></table></figure><h3 id="实时显示GPU使用率"><a href="#实时显示GPU使用率" class="headerlink" title="实时显示GPU使用率"></a>实时显示GPU使用率</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi -l 1</span><br></pre></td></tr></table></figure><h3 id="执行程序时滚动屏幕"><a href="#执行程序时滚动屏幕" class="headerlink" title="执行程序时滚动屏幕"></a>执行程序时滚动屏幕</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctrl+b 之后 + [</span><br></pre></td></tr></table></figure><h3 id="bashrc"><a href="#bashrc" class="headerlink" title=".bashrc"></a>.bashrc</h3><p>基于linux/unix的系统一般情况下都将 bash 作为默认的终端 shell。因此可以通过修改 bashrc 配置文件对执行的命令进行一些自定义。</p><p><strong>.bashrc是一个纯文本文件，用于保存和加载不同用户的终端首选项和环境变量</strong>,bash 在每次启动时都会自动载入 bashrc 配置文件中的内容。每次修改.bashrc文件后使用source ~/.bashrc进行环境的激活。</p><p><strong>终端首选项</strong>：最常用的一种方式为为linux系统命令定义别名，方便定制输入。</p><p><strong>环境变量：</strong>Linux是一个多用户操作系统，可以在linux中为不同的系统定制不同的环境变量。</p><h3 id="环境变量的设置"><a href="#环境变量的设置" class="headerlink" title="环境变量的设置"></a>环境变量的设置</h3><p>环境变量可以分为系统环境变量和用户环境变量。</p><h4 id="系统环境变量："><a href="#系统环境变量：" class="headerlink" title="系统环境变量："></a><strong>系统环境变量：</strong></h4><p>系统变量的设置将对所有的用户均生效。</p><p>对<code>/etc/profile</code>文件添加环境变量将对所有用户均有效。例如添加CLASSPATH变量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile    </span><br><span class="line">export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib</span><br></pre></td></tr></table></figure><h3 id="用户环境变量"><a href="#用户环境变量" class="headerlink" title="用户环境变量"></a>用户环境变量</h3><p>在用户目录下修改文件.bash_profile,改变的量仅对该用户有效。如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash.profile</span><br><span class="line">export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib</span><br></pre></td></tr></table></figure><p>直接在命令行运行：<code>export 变量名=变量值</code>仅对当前的shell有效。</p><h3 id="bashrc-profile-bash-profile-的区别"><a href="#bashrc-profile-bash-profile-的区别" class="headerlink" title=".bashrc,profile,.bash.profile 的区别"></a>.bashrc,profile,.bash.profile 的区别</h3><p><img src="../images/codingTip/peizhifile.png" alt=""></p><h3 id="Linux-中常见的环境变量"><a href="#Linux-中常见的环境变量" class="headerlink" title="Linux 中常见的环境变量"></a>Linux 中常见的环境变量</h3><p><strong>PATH：</strong>指定命令的搜索路径,中间用冒号隔开。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=&lt;PATH1&gt;:&lt;PATH2&gt;:&lt;PATH3&gt;:&lt;PATH4&gt;</span><br></pre></td></tr></table></figure><p>在配置文件中修改PATH：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH='~/anaconda3/bin/:$PATH'</span><br></pre></td></tr></table></figure><p><strong>HOME：</strong>指定用户的主工作目录</p><p><strong>HISTSIZE：</strong>指保存历史命令记录的条数</p><p><strong>LOGNAME：</strong>指当前用户的登录名。</p><p><strong>HOSTNAME：</strong>指主机的名称</p><p><strong>SHELL：</strong>指当前用户用的是哪种Shell</p><p><strong>LANG/LANGUGE：</strong>和语言相关的环境变量</p><h3 id="Linux-查看环境变量"><a href="#Linux-查看环境变量" class="headerlink" title="Linux 查看环境变量"></a>Linux 查看环境变量</h3><ul><li>echo 显示某个环境变量值 echo $PATH</li><li>export HELLO=”hi” 设置新的环境变量</li><li>env 显示所有环境变量</li></ul><h3 id="linux-创建快捷键"><a href="#linux-创建快捷键" class="headerlink" title="linux 创建快捷键"></a>linux 创建快捷键</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias ict="ssh xxx@ictvr.ml -p 11111"</span><br></pre></td></tr></table></figure><h3 id="Linux-打印出目录下文件决定路径"><a href="#Linux-打印出目录下文件决定路径" class="headerlink" title="Linux 打印出目录下文件决定路径"></a>Linux 打印出目录下文件决定路径</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for f in 'ls cat';do echo '/data/cartoon_detect_data/'$f;done &gt; total.txt</span><br></pre></td></tr></table></figure><h3 id="python-查看文件大小"><a href="#python-查看文件大小" class="headerlink" title="python 查看文件大小"></a>python 查看文件大小</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lht</span><br></pre></td></tr></table></figure><h3 id="下载视频"><a href="#下载视频" class="headerlink" title="下载视频"></a>下载视频</h3><p>runonce服务器上,sh tmp.sh,/root/cartoon_data_prepare，其中需要视频id，从表格中读取。</p><h3 id="linux截取字符串前n个字符"><a href="#linux截取字符串前n个字符" class="headerlink" title="linux截取字符串前n个字符"></a>linux截取字符串前n个字符</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -c1-100 file.py # 前100个字符</span><br></pre></td></tr></table></figure><h3 id="linux-shell判断外部传入的参数"><a href="#linux-shell判断外部传入的参数" class="headerlink" title="linux shell判断外部传入的参数"></a>linux shell判断外部传入的参数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ ! -n "$1" ] ;then  # 判断是否有个参数</span><br><span class="line">    echo "you have not input a word!"</span><br><span class="line">else</span><br><span class="line">    echo "the word you input is $1"</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># </span></span></span><br><span class="line">if [-e "$1"] ; then #判断传入的参数是否是个文件/目录</span><br></pre></td></tr></table></figure><h3 id="linux-批量更改文件名"><a href="#linux-批量更改文件名" class="headerlink" title="linux 批量更改文件名"></a>linux 批量更改文件名</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rename 's/search/replace/;' test*.jpg</span><br></pre></td></tr></table></figure><h3 id="linux-awk复制文件"><a href="#linux-awk复制文件" class="headerlink" title="linux awk复制文件"></a>linux awk复制文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $1&#125;'</span> ~/zhouwenhui/mAP/test_set.csv| <span class="keyword">while</span> read day ; do  cp <span class="string">"$day"</span> <span class="string">"./aaa"</span>; done</span><br></pre></td></tr></table></figure><h3 id="创建软链接"><a href="#创建软链接" class="headerlink" title="创建软链接"></a>创建软链接</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s a/path to/soft_path</span><br></pre></td></tr></table></figure><p>soft_path为软链接。</p><h3 id="linux-批量删除文件"><a href="#linux-批量删除文件" class="headerlink" title="linux 批量删除文件"></a>linux 批量删除文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf PAD8_*.jpg</span><br></pre></td></tr></table></figure><h3 id="传输大文件"><a href="#传输大文件" class="headerlink" title="传输大文件"></a>传输大文件</h3><p>mac上通过rz,sz与服务器之间传输文件，由于文件过大（百兆）容易导致内存不足。因此需要先将文件拆分后一个一个上传（下载）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">split -b100k ev.zip ev  # 将ev.zip文件分成每个文件100k的小文件，由ev开头，如evab ...</span><br><span class="line">md5sum ev.zip # 查看原文件的md5值</span><br><span class="line">sz ev* # 将小文件依次下载</span><br><span class="line">cat ev* &gt; ev.zip #本地将所有小文件还原</span><br><span class="line">md5sum ev.zip  #查看还原文件的md5值，是否之前相同</span><br></pre></td></tr></table></figure><h3 id="查看后台进程"><a href="#查看后台进程" class="headerlink" title="查看后台进程"></a>查看后台进程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux</span><br></pre></td></tr></table></figure><h3 id="杀死进程"><a href="#杀死进程" class="headerlink" title="杀死进程"></a>杀死进程</h3><p>当执行一个多线程的任务的时候，使用 ctrl+z停止进程，然后根据进程的id号，依次杀死进程。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow 笔记（CNN分类器VI）</title>
      <link href="/2019/03/13/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88CNN%E5%88%86%E7%B1%BB%E5%99%A8VI%EF%BC%89/"/>
      <url>/2019/03/13/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88CNN%E5%88%86%E7%B1%BB%E5%99%A8VI%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="CNN分类网络"><a href="#CNN分类网络" class="headerlink" title="CNN分类网络"></a>CNN分类网络</h2><p>CNN网络在原来网络的基础上加入了卷积层，对特征进行提取后分类，能够提升网络的分类准确率，同时在网络中加入了dropout，缓解网络的过拟合。</p><a id="more"></a><p>写一个分类器的基本思路如下：</p><p><strong>Assemble graph:</strong></p><ol><li>read data</li><li>create placeholder</li><li>create weight and bias in a layer</li><li>create a net structure</li><li>specify loss function</li><li>create optimizer</li></ol><p><strong>train model:</strong></p><ol><li>specify the epochs,iteration,batch-size</li><li>initial variables</li><li>step by step run the optimizer（use feed_dict to feed data into x,y placeholder）</li></ol><p><strong>tf.Session() encapsulates the environment</strong></p><p>对于mnist分类来说，需要注意的是，我们将输入向量的大小设置成28*28*1的形式，然后通过卷积进行操作。如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">x_image = tf.reshape(xs,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>]) <span class="comment"># [nsample,width,height,channel]</span></span><br></pre></td></tr></table></figure><p>对于卷积层tensorflow中使用<code>tf.nn.conv2d</code>来创建。该函数的参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(input,W,stride,padding)</span><br><span class="line"><span class="comment"># input表示输入的参数</span></span><br><span class="line"><span class="comment"># filter:W表示卷积核的参数即：[kernel_w,kernel_h,in_channel,out_channel]</span></span><br><span class="line"><span class="comment"># stride表示步长：[1,x_move,y_move,1]</span></span><br><span class="line"><span class="comment"># padding = 'SAME' / 'VALID' 卷积后大小不变 / 卷积后大小变小</span></span><br></pre></td></tr></table></figure><p>创建一个卷积层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x)</span>:</span></span><br><span class="line"> <span class="comment"># conv weight: [kernel_w,kernel_h,in_channel,out_channel]</span></span><br><span class="line">    Weights = tf.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>],stddev = <span class="number">0.1</span>)</span><br><span class="line">    bias = tf.constant(<span class="number">0.1</span>,[<span class="number">32</span>])</span><br><span class="line">    <span class="comment"># stride = [1,x_move,y_move,1]</span></span><br><span class="line">    output = tf.nn.conv2d(x,Weight,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding = <span class="string">'SAME'</span>)</span><br><span class="line">    <span class="keyword">return</span> output+bias</span><br></pre></td></tr></table></figure><p>对于池化层，tensorflow中使用的函数<code>tf.nn.max_pool</code>，该函数的参数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.max_pool(input,ksize,stride,padding)</span><br><span class="line"><span class="comment"># input为输入的数据</span></span><br><span class="line"><span class="comment"># ksize:表示卷积核大小，[1,kernel_w,kernel_h,1]</span></span><br><span class="line"><span class="comment"># stride: [1,x_move,y_move,1]</span></span><br><span class="line"><span class="comment"># padding = 'SAME' / 'VALID'</span></span><br></pre></td></tr></table></figure><p>创建一个max pooling 层:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pooling</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding = <span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure><p>dropout层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.dropout(x,keep_prob = <span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># x: 输入的向量</span></span><br><span class="line"><span class="comment"># keep_prob：dropout的比例</span></span><br><span class="line"><span class="comment"># keep_prob通常是一个tf.placeholder,在训练时设为一个小数，在测试时设为1</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create placeholder</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])/<span class="number">255.</span></span><br><span class="line">    ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line">    keep_prob = tf.placeholder(tf.float32) <span class="comment"># dropout rate</span></span><br><span class="line">    x_image = tf.reshape(xs,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>]) <span class="comment"># nsample,28,28,channel</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'conv1'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">32</span>]))</span><br><span class="line">    out_conv1 = tf.nn.conv2d(x_image,Weights,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)+bias <span class="comment"># 28,28,32</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'pool1'</span>):</span><br><span class="line">    out_pool1 = tf.nn.max_pool(out_conv1,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>) <span class="comment"># 14,14,32</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'conv2'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">64</span>]))</span><br><span class="line">    out_conv2 = tf.nn.conv2d(out_pool1,Weights,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>) <span class="comment">#[14,14,64]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'pool2'</span>):</span><br><span class="line">    out_pool2 = tf.nn.max_pool(out_conv2,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)<span class="comment">#[7,7,64]</span></span><br><span class="line">    out_pool2 = tf.reshape(out_pool2,[<span class="number">-1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>]) <span class="comment"># nsample,7*7*64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc1'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape = [<span class="number">1024</span>]))</span><br><span class="line">    out_fc1 = tf.nn.relu(tf.matmul(out_pool2,Weights)+bias)</span><br><span class="line">    drop_out_fc1 = tf.nn.dropout(out_fc1,keep_prob) <span class="comment"># nsample,1024</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc2'</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.truncated_normal([<span class="number">1024</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>,shape=[<span class="number">10</span>]))</span><br><span class="line">    prediction = tf.matmul(drop_out_fc1,Weights)+bias <span class="comment"># nsample,10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create running environment</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment">## compute accuracy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(X,Y)</span>:</span></span><br><span class="line">    pred = sess.run(prediction,feed_dict=&#123;xs:X,keep_prob:<span class="number">1</span>&#125;)</span><br><span class="line">    correct = tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(Y,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))</span><br><span class="line">    <span class="keyword">return</span> sess.run(accuracy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'optimizer'</span>):</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#initialization</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># visualization</span></span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'./log'</span>,sess.graph)</span><br><span class="line"><span class="comment"># train</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch,keep_prob:<span class="number">0.5</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(mnist.test.images[:<span class="number">1000</span>],mnist.test.labels[:<span class="number">1000</span>]))</span><br></pre></td></tr></table></figure><h3 id="Tensorflow-保存变量"><a href="#Tensorflow-保存变量" class="headerlink" title="Tensorflow 保存变量"></a>Tensorflow 保存变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w = tf.Variable([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],dtype = tf.float32,name = <span class="string">'weight'</span>)</span><br><span class="line">b = tf.Variable([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]],dtype = tf.float32,name = <span class="string">'bias'</span>)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"my_net/save_net.ckpt"</span>)</span><br><span class="line">    print(<span class="string">"Save to path: "</span>, save_path)</span><br></pre></td></tr></table></figure><h3 id="提取变量restore"><a href="#提取变量restore" class="headerlink" title="提取变量restore"></a>提取变量restore</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 先建立 W, b 的容器</span></span><br><span class="line">W = tf.Variable(np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>)), dtype=tf.float32, name=<span class="string">"weights"</span>)</span><br><span class="line">b = tf.Variable(np.arange(<span class="number">3</span>).reshape((<span class="number">1</span>, <span class="number">3</span>)), dtype=tf.float32, name=<span class="string">"biases"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里不需要初始化步骤 init= tf.initialize_all_variables()</span></span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 提取变量</span></span><br><span class="line">    saver.restore(sess, <span class="string">"my_net/save_net.ckpt"</span>)</span><br><span class="line">    print(<span class="string">"weights:"</span>, sess.run(W))</span><br><span class="line">    print(<span class="string">"biases:"</span>, sess.run(b))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SSD M2Det 详解</title>
      <link href="/2019/03/10/SSD-M2Det-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/10/SSD-M2Det-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>SSD是经典的one-stage算法，可以认为是关于类别的多尺度分类网络，作为很多one-stage网络的基础框架，有必要阅读一下。</p><p>M2Det是今年（2019）CPVR论文，基于SSD框架的扩展，M2Det 若采用 single-scale inference 可达到 11 FPS, AP 41 的准确率，采用 multi-scale inference 可达到 AP 44.2 的准确度。</p><a id="more"></a><h2 id="SSD-详解"><a href="#SSD-详解" class="headerlink" title="SSD 详解"></a>SSD 详解</h2><blockquote><p>SSD: Single Shot MultiBox Detector</p><p>submit time：2015</p><p><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="网络的背景及作用"><a href="#网络的背景及作用" class="headerlink" title="网络的背景及作用"></a>网络的背景及作用</h3><p>当前网络通过提取候选框等方式进行目标检测，运行速度对于一些应用场景来说太慢了。</p><p>SSD是一种使用单个深度神经网络来检测图像中的目标的方法，SSD 速度的根本改进来自消除边界框proposal和随后的像素或特征重采样阶段。他的主要特点如下：</p><ul><li>one-stage检测器，用于多个类别目标检测，比先前技术相比（YOLO）速度更快，且更准确。</li><li>SSD方法的核心是<strong>使用小卷积滤波器来预测特征图上固定的一组默认边界框的类别分数和位置偏移。</strong></li><li>为了实现高检测精度，我们从<strong>不同尺度的特征图产生不同尺度的预测</strong>，并且通过宽高比来明确地分离预测。</li><li>这些设计特性得到了简单的端到端训练和高精度，进一步提高速度和精度的权衡，即使输入相对低分辨率图像。</li></ul><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/images/article/SSD.png" alt=""></p><p>SSD的检测过程如下：</p><ol><li>SSD输入为包含类别以及真实框标记的图片数据。 </li><li>卷积处理时，我们在具有不同尺度（例如（b）和（c）中的8×8和4×4）的若干特征图中的<strong>每个位置处选择不同横宽比的小集合（例如4个）默认框</strong>。 </li><li>对于每个默认框，我们预测对所有对象类别（c 1，c2，…，cp）的形状偏移和置信度。在训练时，我们首先将这些默认框匹配到真实标签框。 例如，两个默认框匹配到猫和狗，这些框为正，其余视为负。 </li><li>模型损失是位置损失（例如平滑L1 [6]）和置信损失（例如Softmax）之间的加权和。 </li></ol><p> SSD方法基于前馈卷积网络，采用多尺度特征度检测的方式，产生固定大小的边界框集合和框中对象类别的分数，接着是非最大化抑制步骤以产生最终检测,如下图：</p><p><img src="/images/article/SSDstructure.png" alt=""></p><ul><li><p>输入：300x300</p></li><li><p>经过VGG-16（只到conv4_3这一层，由于更深的网络特征难以恢复）</p></li><li><p>经过几层卷积，得到多层尺寸逐渐减小的feature map</p></li><li><p>每层feature map分别做3x3卷积，每个feature map cell对应k个类别和4个bounding box offset，同时对应原图中6（或4）个anchor，<strong>即每一个位置将会预测4或6个anchor，然后每个anchor有k个类别概率值以及4个位置偏移值。</strong></p></li><li><p>38x38层, 最后3x3层, 1x1层三个feature map的每个feature map cell只对应4个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，其他feature map的feature map cell对应6个anchor，分别为宽高比: 1:1两种，1:2, 2:1两种，1:3， 3:1两种。因此总共有<br>$$<br>38* 38*4+19*19*6+10*10*6+5*5*6+3*3*4+1*1*4=8732<br>$$<br>个anchor。</p></li></ul><h3 id="anchor的中心："><a href="#anchor的中心：" class="headerlink" title="anchor的中心："></a>anchor的中心：</h3><p>每层的feature map cell对应的anchor中心的计算方法如下<br>$$<br>(\frac{i+0.5}{|fk|},\frac{j+0.5}{|fk|})<br>$$<br>其中i,j是当前的位置，fk是当前feature map的大小。</p><h3 id="anchor缩放因子"><a href="#anchor缩放因子" class="headerlink" title="anchor缩放因子:"></a>anchor缩放因子:</h3><p>$$<br>S_k = S_{min}+\frac{S_{max}-S_{min}}{m-1} (k-1),k\in[1,m]<br>$$</p><p>缩放因子指不同大小的feature map对应不同大小的anchor。<em>m</em>表示最终有m个 feature maps将要作为预测,对每一个k层的feature map计算其anchor的大小，即$ S_k$。 此外$S_{min}$ 为 0.2，$S_{max}$ 为 0.9。因此对于所有层，scale都在[0.2,0.9]之间。</p><p>对于每一个尺度，都可以计算其相应的anchor大小，如下：<br>$$<br>\begin{align}<br>w_k^{\alpha} &amp;= S_k \sqrt{\alpha_r} \\<br>h_k^{\alpha} &amp;= S_k \sqrt{\alpha_r}\\<br>\alpha \in &amp;{1,2,3,\frac{1}{2},\frac{1}{3}}<br>\end{align}<br>$$<br>特别的，当 $a_r=1$ 时，增加一种 $s_k = \sqrt{s_{k-1}{s_{k+1}}}$ ，对应6种anchor的长宽比，对于4个anchor来说，不使用3和$\frac{1}{3}$。</p><h3 id="网络损失函数"><a href="#网络损失函数" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>SSD的损失函数由两部分组成，分别是置信度损失（softmax loss)以及位置损失（L1 loss），如下：<br>$$<br>L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))<br>$$<br>其中N是匹配的GT框个数，当N = 0时loss等于0。$\alpha$是置信度与位置loss之间的一个权衡因子。</p><p>对于置信度loss ：<br>$$<br>L_{conf}(x,c) = - \sum_{i\in Pos}^N x_{ij}^p log(\hat{c}_{i}^p) - \sum_{i\in Neg} log(\hat{c}_{i}^0)\quad where \quad\hat{c}_{i}^p=\frac{exp^{c_{i}^p}}{\sum_p exp(c_{i}^p)}<br>$$<br>即softmax的交叉熵loss。</p><p>位置损失如下：<br>$$<br>\begin{align}<br>L_{loc}(x,l,g)&amp;=\sum_{i\in Pos}^N \sum_{m \in {cx,cy,w,h}}x_{ij}^k smooth_{L1}(l_i^m-\hat{g}_j^m) \\<br>\hat{g}_j^{cx}&amp;=(g_j^{cx}-d_i^{cx})/d_i^w \quad \hat{g}_j^{cy}=(g_j^{cy}-d_i^{cy})/d_i^h\\<br>\hat{g}_j^{w}&amp;=log(\frac{g_j^w}{d_i^w})\quad \hat{g}_j^{h}=log(\frac{g_j^h}{d_i^h})<br>\end{align}<br>$$<br>其中g表示GT的边框中心，d表示预测的边框的中心，该loss与Faster RCNN的loss 相同。即我们去学习的是边框的偏移量，而不是直接预测边框。当预测值l与g的指标相同时即完成，反向可推导出目标的边框。</p><h3 id="样本选择"><a href="#样本选择" class="headerlink" title="样本选择"></a>样本选择</h3><p>正样本：预测框与GT的重叠程度大于0.5的认为是正样本</p><p>副样本：将边框置信度排序，找出置信度高的边框，保持正负比例为1:3.</p><h3 id="train-trick"><a href="#train-trick" class="headerlink" title="train trick"></a>train trick</h3><p><img src="/images/article/ssdtrain.png" alt=""></p><p>SSD使用了诸如数据增强，空洞卷积等操作，是的进度进一步提升。</p><p>数据增强的方式为：</p><ul><li>整图输入</li><li>截取图上一部分进行输入</li><li>随机crop</li><li>将上面的图片都resize到一个固定大小，输入网络</li></ul><h3 id="MS-COCO上的精度"><a href="#MS-COCO上的精度" class="headerlink" title="MS COCO上的精度"></a>MS COCO上的精度</h3><p>SSD在coco上的精度如下：</p><p><img src="/images/article/ssdcocoTest.png" alt=""></p><hr><h2 id="M2Det-详解"><a href="#M2Det-详解" class="headerlink" title="M2Det 详解"></a>M2Det 详解</h2><p>M2Det是一个one-stage的目标检测网络。基于SSD框架扩展而来。主要的思想是Multi-Level Feature Pyramid Network(MLFPN)，多层次的特征金字塔网络。</p><h3 id="网络的背景及应用"><a href="#网络的背景及应用" class="headerlink" title="网络的背景及应用"></a>网络的背景及应用</h3><p>论文中提出物体分类和物体检测问题上的缩放尺度变化矛盾，即物体分类模型提取高层次的特征，高层次的特征往往更容易学到具有辨别力的信息，模型会专注于一些辨认力强的点，例如鸟🐦，倾向于检测翅膀。</p><p>但是由于物体检测问题需要将整个物体框起来，仅仅识别出有辨别力的点无法保证完全把目标框起来，因此作者提出使用浅层的特征来辅助学习目标的检测任务，即确定边框位置。</p><p><strong>因此高阶的特征有助于分类，低价的特征有助于物体的检测。</strong></p><p>作者提出，通常解决尺度变化的问题采样的方法是<strong>从输入图像提取出的特征金字塔，从而克服原始图片的缩放问题</strong>。该方法可以同时用于训练和测试阶段中，相对开销较小，易于集成，适合end-to-end。本文的目的即是构造一个更加高效的金字塔模型用于检测不同缩放大小的对象。作者将该结构加入到SSD中去，取得了超过benchmark的成绩。</p><h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p>作者通过对比多种金字塔特征提取方式，总结了这些模型的确定，并提出自己的特征提取方式。</p><p>先前模型的缺点：</p><ul><li>先前的模型都是基于分类网络作为特征提取的主干网络，对目标检测任务而言，先前金字塔结构提取的特征表达不足以预测目标位置。即特征太少。</li><li>每个feature map仅由主干网络的single level给出，仅含单层信息不够全面。</li></ul><p><img src="/images/article/M2detpyramid.png" alt=""></p><ul><li>SSD型：使用了主干网络的最后两层，再加上4个使用stride=2卷积的下采样层构成；</li><li>FPN型：也称为U型网络，经过上采样操作，然后对应融合相同的scale；</li><li>STDN型：基于DenseNet的最后一个dense block，通过池化和scale-transfer操作来构建；</li><li>MLFPN型：Multi-level&amp;Multi-scale</li></ul><p>MLFPN结构如下，对主干网络(vgg)提取到的特征进行融合；然后通过TUM和FFM提取更有代表性的Multi-level&amp;Mutli-scale特征；最后通过SFAM融合多级特征，得到多级特征金字塔用于最终阶段的预测。</p><p><img src="/images/article/M2Detstructure.png" alt=""></p><h3 id="FFMv1"><a href="#FFMv1" class="headerlink" title="FFMv1"></a>FFMv1</h3><p>FFMv1整合了VGG网络中浅层conv4_3的特征以及深层conv5_3的特征作为base feature（从Figure1中可以看出）。其结构如下所示，先进行一个1*1的卷积压缩channel，然后upsample到相同的大小，进行如何得到base feature。</p><p><img src="/images/article/MMFv1.png" alt=""></p><p>###TUM</p><p>TUM的结构是一个U-Net的结构，如Figure1所示。他的内部结构如下：</p><p><img src="/images/article/TUM.png" alt=""></p><p> TUM结构输出的左右feature map均输入SFAM中，同时将最大一个feature map(128,40,40)传入FFMv2中作为下一次TUM的输入。</p><h3 id="FFMv2"><a href="#FFMv2" class="headerlink" title="FFMv2"></a>FFMv2</h3><p>FFMv2输入为base feature与上一层最大的feature map结构如下：</p><p><img src="/images/article/ffmv2.png" alt=""></p><p>通过堆叠TUM以及FFMv2产生不同层次的feature map，最终分别提取出图片的shallow，medium，deep的特征。每个TUM以及FFMv2的输出特征计算如下：</p><p><img src="/images/article/multi-scale.png" alt=""></p><h3 id="尺度特征聚合模块SFAM"><a href="#尺度特征聚合模块SFAM" class="headerlink" title="尺度特征聚合模块SFAM"></a>尺度特征聚合模块SFAM</h3><p>SFAM负责将每个金字塔的输入聚合起来，得到Multi-level feature pyramid。然后输出值prediction layer。</p><p><img src="/images/article/SFAM.png" alt=""></p><p>每个TUM都会输出一个六层的特征金字塔，SFAM首先对每一层相同channel的特征进行融合。第二步采用SENet的方法，即是透过 Fully-connected layer 来学习每个 feature 应该给多少权重。最终 prediction layer 会接受的是 i 个不同尺度的 Feature maps。</p><h3 id="模块配置"><a href="#模块配置" class="headerlink" title="模块配置"></a>模块配置</h3><ul><li>M2Det 网络采用VGG-16和ResNet-101作为特征提取的主干网络。</li><li>MLFPN的默认配置包含有8个TUM，每个TUM包含5个跨步卷积核5个上采样操作，输出为6个不同scale的特征。</li><li>在检测阶段，<strong>为6组金字塔特征每组后面添加两个卷积层，以分别实现位置回归和分类。</strong></li><li>后处理阶段，使用soft-NMS来过滤无用的包围框。</li></ul><h3 id="网络损失函数-1"><a href="#网络损失函数-1" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>网络的顺势函数沿用了SSD的方法，即置信度softmax损失以及边框回归损失。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>data training tip</title>
      <link href="/2019/03/08/data%20training%20tip/"/>
      <url>/2019/03/08/data%20training%20tip/</url>
      
        <content type="html"><![CDATA[<h2 id="Json-文件格式切换"><a href="#Json-文件格式切换" class="headerlink" title="Json 文件格式切换"></a>Json 文件格式切换</h2><p>数据集中Json文件挤在一堆，需要将其格式化输出，Json文件格式化代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">json.dumps(&#123;<span class="string">'a'</span>: <span class="string">'Runoob'</span>, <span class="string">'b'</span>: <span class="number">7</span>&#125;, sort_keys=<span class="keyword">False</span>, indent=<span class="number">4</span>, separators=(<span class="string">','</span>, <span class="string">': '</span>))</span><br><span class="line"><span class="comment"># 输出如下：</span></span><br><span class="line"><span class="comment">#&#123;</span></span><br><span class="line"><span class="comment">#    "a": "Runoob",</span></span><br><span class="line"><span class="comment">#    "b": 7</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure><p>文件改写实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'../dataset/train_round1/train_no_poly.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> fin:</span><br><span class="line">    js = json.load(fin)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'train_no_poly.json'</span>, <span class="string">'w+'</span>) <span class="keyword">as</span> fout:</span><br><span class="line">        json.dump(js, fout,sort_keys=<span class="keyword">False</span>, indent=<span class="number">4</span>, separators=(<span class="string">','</span>, <span class="string">': '</span>),ensure_ascii=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p><strong>Json 处理字符串读写和文件读写：</strong></p><p>处理字符串：<code>json.loads(fileDir)</code>得到字符串，<code>json.dumps(dataDict)</code>得到Json文件。</p><p>处理文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Writing JSON data</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(data, f)</span><br><span class="line"><span class="comment"># Reading data back</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'data.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></table></figure><h2 id="MAC-git-使用"><a href="#MAC-git-使用" class="headerlink" title="MAC git 使用"></a>MAC git 使用</h2><p><strong>安装Git</strong>：<a href="https://www.jianshu.com/p/7edb6b838a2e" target="_blank" rel="noopener">链接</a></p><p><strong>验证是否成功链接远程github</strong>：<code>ssh -T git@github.com</code>，如果正确返回 hi wenhui-zhou.</p><p><strong>提交本地项目到GitHub上</strong>：</p><ol><li><p>在GitHub网站上创建一个仓库</p></li><li><p>复制其clone 链接，将仓库clone到本地:</p><p><code>git clone git@github.com:WenHui-Zhou/learnGit.git</code></p></li><li><p>打开learnGit文件夹，将工程文件保存在这个目录下</p></li><li><p>提交修改，将工程上传到GitHub上</p><p><code>git add fileName</code>：在仓库目录下，将文件添加到本地仓库。</p><p><code>git add .</code> ：将所有文件添加到本地仓库。</p><p><code>git commit -m &quot;some comments&quot;</code>：添加评论。</p><p><code>git push</code>：上传到远端仓库。</p></li></ol><h3 id="github-更新文件"><a href="#github-更新文件" class="headerlink" title="github 更新文件"></a>github 更新文件</h3><ol><li><code>git status</code>：查看仓库状态，如果有所不同的话，会显示不同的文件。</li><li><code>git add file</code>：将更改的文件加入到本地仓库。</li><li><code>git commit -m &quot;comment&quot;</code>：添加评论。</li><li><code>git push</code>：将代码提交到GitHub上。</li></ol><h3 id="git-getch"><a href="#git-getch" class="headerlink" title="git getch"></a>git getch</h3><p>当与人协作时，远程主机有了更新，可以通过<code>git fetch</code> 来取得更新的内容。</p><ol><li><code>git fetch origin master:tmp</code>，在本地创建一个tmp分支，将远程master 分支的代码下载到tmp分支上。</li><li><code>git diff tmp</code>，比较本地代码与从远端下载下来的代码的区别。</li><li><code>git merge tmp</code>，合并分支到本地的master。</li><li><code>git branch -d tmp</code>，如果不想要tmp分支的话，则可以删除。</li></ol><h3 id="git-pull"><a href="#git-pull" class="headerlink" title="git pull"></a>git pull</h3><p><code>git pull</code>：将远端代码与本地代码直接融合，等于上面的git fetch + git merge。</p><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>将本地<strong>更新的分支</strong>推送到远程主机。因此我们每次进行远端数据的更新操作之前需要更新一下本地的分支。即：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m "comment" // 在本地分支上添加文件并添加评论</span><br><span class="line">git push  // 将远端分支进行更新</span><br></pre></td></tr></table></figure><h3 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h3><p>在GitHub上点击fork将其他用户的仓库更新到自己的GitHub下，然后进行clone到本地，进行一些工程上的修改。这个库当前属于你，照样执行上面的<code>git push</code>等操作。完成后在GitHub上发起pull request，然后系统会对比两个工程的修改之处，然后发起request，在其他用户那边将会多一个request操作，可以同意，则进行merge。</p><h3 id="同步fork的库与原始的库"><a href="#同步fork的库与原始的库" class="headerlink" title="同步fork的库与原始的库"></a>同步fork的库与原始的库</h3><p>使用指令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git remote add  //添加本地库</span><br><span class="line">git fetch       // 将远端的不同fetch到本地</span><br><span class="line">git merge        // 融合</span><br><span class="line">git push         // 更新到自己的GitHub上</span><br></pre></td></tr></table></figure><h3 id="iteration、epoch、batchsize的含义"><a href="#iteration、epoch、batchsize的含义" class="headerlink" title="iteration、epoch、batchsize的含义"></a>iteration、epoch、batchsize的含义</h3><ul><li>epoch：数据集所有数据训练过一遍为一个epoch，类似于一本书，epoch为几就是要看几遍。</li><li>batch-size：一次迭代（更新参数）所使用的数据数量。类似于书中每个章节。</li><li>iteration：总共的迭代次数，一次迭代所用的数据为一个batch-size，即一次看一章。因此迭代的次数为dataset/batch-size，每本书看epoch次，因此iteration = epoch * (dataset/batch-size)。</li></ul><h3 id="python-dict的用法"><a href="#python-dict的用法" class="headerlink" title="python dict的用法"></a>python dict的用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">adict = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125; <span class="comment">#创建</span></span><br><span class="line">dict(zip([<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])) </span><br><span class="line">print(adict[<span class="string">'a'</span>]) <span class="comment"># 访问</span></span><br><span class="line">adict[<span class="string">'a'</span>] = <span class="number">2</span> <span class="comment"># 修改</span></span><br><span class="line">adict.pop(<span class="string">'a'</span>) <span class="comment"># 删除</span></span><br><span class="line">adict.get(<span class="string">'a'</span>) <span class="comment"># 如果没有这个key返回None</span></span><br><span class="line"><span class="keyword">for</span> key,values <span class="keyword">in</span>  dict.items(): <span class="comment"># 同时获得key和val</span></span><br><span class="line">    print(key,values)</span><br></pre></td></tr></table></figure><h3 id="python-中的类"><a href="#python-中的类" class="headerlink" title="python 中的类"></a>python 中的类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(object)</span>:</span>  <span class="comment"># 继承object</span></span><br><span class="line">    <span class="comment"># 数据成员</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,score)</span>:</span>  <span class="comment"># 类函数的第一个参数固定为self</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br><span class="line">        <span class="comment">## 私有成员,变量名前加上两个下划线__,只能类函数内部访问</span></span><br><span class="line">        self.__name = name</span><br><span class="line">    <span class="comment"># 方法成员</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getname</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getscore</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.score</span><br><span class="line"><span class="comment">#创建对象</span></span><br><span class="line">stu = Student(<span class="string">'xiaoming'</span>,<span class="number">100</span>)</span><br><span class="line">print(stu.getname())</span><br><span class="line">stu.sex = <span class="string">'man'</span> <span class="comment"># 外部添加数据变量</span></span><br></pre></td></tr></table></figure><h4 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">'animal is runing'</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cat</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">acat = cat()</span><br><span class="line">acat.run() <span class="comment"># 调用父类的run函数</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cat</span><span class="params">(Animal)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">'cat is runing'</span>)</span><br><span class="line">acat.run() <span class="comment"># 执行自己的run函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#多态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runrun</span><span class="params">(animal)</span>:</span></span><br><span class="line">    animal.run()</span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">runrun(animal) <span class="comment"># animal类</span></span><br><span class="line">runrun(cat) <span class="comment"># animal 子类</span></span><br><span class="line">runrun(aman) <span class="comment"># 类中含有run()的类也可以</span></span><br></pre></td></tr></table></figure><h4 id="property属性"><a href="#property属性" class="headerlink" title="property属性"></a>property属性</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">socre</span><span class="params">(self)</span>:</span>   <span class="comment"># 把socre变成一种数据属性，对象可以直接赋值</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"><span class="meta">    @birth.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, value)</span>:</span><span class="comment"># 对于score赋值的规则限制，在setter里头</span></span><br><span class="line">        <span class="keyword">if</span> value&gt;<span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'score must between 0 ~ 100!'</span>)</span><br><span class="line">        self._score = value</span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">s = Student()</span><br><span class="line">s.score = <span class="number">100</span></span><br><span class="line">print(s.score)</span><br></pre></td></tr></table></figure><h4 id="classmethod-类"><a href="#classmethod-类" class="headerlink" title="classmethod 类"></a>classmethod 类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">    bar = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func1</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'foo'</span>) </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">(cls)</span>:</span>      <span class="comment"># 方法类必须使用cls作为参数，不需要初始化</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'func2'</span>)</span><br><span class="line">        <span class="keyword">print</span> (cls.bar)</span><br><span class="line">        cls().func1()   <span class="comment"># 调用 foo 方法</span></span><br><span class="line">A.func2()               <span class="comment"># 不需要实例化</span></span><br></pre></td></tr></table></figure><h4 id="staticmethod"><a href="#staticmethod" class="headerlink" title="staticmethod"></a>staticmethod</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">()</span>:</span>      <span class="comment"># 静态方法，对参数没有要求</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'func2'</span>)</span><br><span class="line">A.func2()               <span class="comment"># 不需要实例化</span></span><br></pre></td></tr></table></figure><h3 id="下载单个文件夹"><a href="#下载单个文件夹" class="headerlink" title="下载单个文件夹"></a>下载单个文件夹</h3><p>在github上进入该文件夹所在的目录，复制文件夹链接：</p><p><a href="https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN" target="_blank" rel="noopener">https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN</a></p><p>随后在服务器上输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svn checkout https://github.com/tensorpack/tensorpack/trunk/examples/FasterRCNN</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO V2,V3详解</title>
      <link href="/2019/03/08/YOLO-V2-V3%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/08/YOLO-V2-V3%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>YOLO V2,YOLO V3是基于YOLO V1 的基础上，对网络进行改进，使得mAP，检测精度提升，同时仍保持较快的检测速度。本文将详细介绍V2，V3的特点。</p><a id="more"></a><h2 id="YOLO-V2-详解"><a href="#YOLO-V2-详解" class="headerlink" title="YOLO V2 详解"></a>YOLO V2 详解</h2><blockquote><p> YOLO9000: Better, Faster, Stronger</p><p>submit time: 2016</p><p><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>YOLO V2 在保持与V1基本框架相同的情况下，对网络进行了各种调优，主要做的修改如下：</p><p><img src="/images/article/YOLOchange.png" alt=""></p><h3 id="batch-norm"><a href="#batch-norm" class="headerlink" title="batch norm"></a>batch norm</h3><p>Batch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。</p><h3 id="high-resolution-classifier"><a href="#high-resolution-classifier" class="headerlink" title="high resolution classifier"></a>high resolution classifier</h3><p>当前大部分网络的预训练模型都是在ImageNet上224*224大小的图片上进行fintune的，YOLO V2首次用448*448大小的图片对分类网络进行fintune（10 epoch），使用高分辨率分类器后，YOLOv2的mAP提升了约4%。</p><h3 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h3><p>YOLOv1直接对目标进行边框预测，由于目标的尺度变换范围很大，导致了YOLOv1在精确定位方面表现较差。YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框。YOLOv2借鉴了Faster R-CNN中RPN网络的先验框策略。RPN对CNN特征提取器得到的特征图（feature map）进行卷积来预测每个位置的边界框以及置信度（是否含有物体）。</p><p>YOLOv2采用 416 * 416大小的图片作为输入。下采样的总步长为 32，对于 416*416大小的图片，最终得到的特征图大小为13*13，维度是奇数，这样特征图恰好只有一个中心位置。对于一些大物体，它们中心点往往落入图片中心位置，此时使用特征图的一个中心点去预测这些物体的边界框相对容易些。YOLO V2每个cell与yolov1类似，都分别去预测目标的IoU，以及每个框的类别预测值。使用anchor之后精度有点下降，但是YOLO V2的召回率（预测为真的占GT中真的比例）大大提升。原因是使用了anchor每张图片预测的边框数大大提升。</p><h3 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h3><p>在预测边框时传统的如Faster RCNN使用的是手工设置边框大小，yolov2中采用kmeans聚类的方法，选用box与聚类中心box之间的IOU值作为距离指标，即离的则认为是那一类，作者选择了五个先验框作为聚类中。</p><h3 id="New-Network-Darknet-19"><a href="#New-Network-Darknet-19" class="headerlink" title="New Network: Darknet-19"></a>New Network: Darknet-19</h3><p>YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。</p><h3 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a>Direct location prediction</h3><p>yolov2 采用不同于RPN的边框回归的方法，yolov2回归的目标是预测边界框中心点相对于对应cell左上角位置的相对偏移值。</p><p><img src="/images/article/yolobounding.png" alt=""></p><p>yolov2为每个cell预测5个bounding box，为每个bounding box预测五个坐标值，使用如下的公式进行边框的回归。</p><p><img src="/images/article/boundregression.png" alt=""></p><p>结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。</p><h3 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h3><p>由于YOLOv2模型中只有卷积层和池化层，为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔一定的iterations之后改变模型的输入图片大小。YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值.</p><h3 id="YOLO-V2-训练"><a href="#YOLO-V2-训练" class="headerlink" title="YOLO V2 训练"></a>YOLO V2 训练</h3><p>YOLOv2的训练主要包括三个阶段。</p><ul><li>第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224 * 224 ，共训练160个epochs</li><li>第二阶段将网络的输入调整为 448*448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs</li><li>第三个阶段就是修改Darknet-19分类模型为检测模型，并在检测数据集上继续finetune网络</li></ul><p><img src="/images/article/yolo2train.jpg" alt=""></p><p>其网络结构为：<a href="https://ethereon.github.io/netscope/#/gist/d08a41711e48cf111e330827b1279c31" target="_blank" rel="noopener">链接</a></p><p><img src="/images/article/yolo2structure.jpg" alt=""></p><h2 id="YOLO-V3"><a href="#YOLO-V3" class="headerlink" title="YOLO V3"></a>YOLO V3</h2><blockquote><p>YOLOv3: An Incremental Improvement</p><p>Submit time: 2018</p><p><a href="https://arxiv.org/abs/1804.02767" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>YOLO V3在速度和精度上比YOLO V2有了很大的提升，同时网络结构也复杂了不少，通过改变网络来权衡速度和精度。YOLO V3 的主要改进如下：</p><h3 id="Darknet-53"><a href="#Darknet-53" class="headerlink" title="Darknet-53"></a>Darknet-53</h3><p>YOLOV3作者使用了Darknet 53作为特征提取网络， Darknet 53是一个在Imagenet.做预训练的网络，YOLOV3 <strong>共有106 fully convolutional</strong> 。因此在速度上较YOLOV2慢一些。网络结构如下：</p><p><img src="/images/article/darknet.png" alt=""></p><p><img src="/images/article/y3.png" alt=""></p><h3 id="Detection-at-three-Scales-多尺度预测"><a href="#Detection-at-three-Scales-多尺度预测" class="headerlink" title="Detection at three Scales 多尺度预测"></a>Detection at three Scales 多尺度预测</h3><p>v3最显着的特点是它可以在三种不同的尺度上进行检测（32，16，8）。YOLO是一个完全卷积网络，通过在网络中的三个不同位置处应用1 x 1内核进行预测，每个尺度均预测三个边框，每一个边框的参数为$N ×N ×[3∗(4+1+80)] $，4表示边框的偏离值，1表示目标预测，80表示共80个类别。</p><p>多尺度的检测很好的客服了小物体的预测问题。</p><p><img src="/images/article/y3pre.jpg" alt=""></p><h3 id="No-more-softmaxing-the-classes"><a href="#No-more-softmaxing-the-classes" class="headerlink" title="No more softmaxing the classes"></a>No more softmaxing the classes</h3><p>作者使用sigmoid函数代替原来的softmax。由于softmax函数存在一个先验假设，即一个物体只能属于一个类别，这种假设在COCO集合上不成立。例如一个目标同时属于person和women，因此作者选择了sigmoid。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow 笔记（分类器 III）</title>
      <link href="/2019/03/08/TensorFlow-%E7%AC%94%E8%AE%B0%EF%BC%88%E5%88%86%E7%B1%BB%E5%99%A8-III%EF%BC%89/"/>
      <url>/2019/03/08/TensorFlow-%E7%AC%94%E8%AE%B0%EF%BC%88%E5%88%86%E7%B1%BB%E5%99%A8-III%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>本篇文章详细的从头到尾实现一下mnist分类器。</p><a id="more"></a><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>建立一个mnist数据集的数字分类器，需要做的主要有，</p><ul><li>从数据集中下载数据。</li><li>添加网络层（参数为，输入，输入size，输出size，激活函数），</li><li>定义输入数据的<code>placeholder</code>，构建网络结构，定义层。</li><li>定义loss，优化器.</li><li>定义计算精度的函数</li><li>定义train过程，以及精度的输出过程</li></ul><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tf.examples.tutorials.minst <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="添加网络层"><a href="#添加网络层" class="headerlink" title="添加网络层"></a>添加网络层</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_Function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variables(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variables(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.1</span>)</span><br><span class="line">    Wx_add_b = tf.matmul(input,Weights)+bias</span><br><span class="line">    <span class="keyword">if</span> actication_Function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_add_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_Function(Wx_add_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h3 id="构建网络结构"><a href="#构建网络结构" class="headerlink" title="构建网络结构"></a>构建网络结构</h3><p>网络为三层网络，一个输入层，一个隐藏层，一个输出层。均为全连接。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line">prediction = add_layer(xs,<span class="number">784</span>,<span class="number">10</span>,<span class="keyword">None</span>)<span class="comment">#仅有一层</span></span><br></pre></td></tr></table></figure><h3 id="Loss，优化器"><a href="#Loss，优化器" class="headerlink" title="Loss，优化器"></a>Loss，优化器</h3><p>分类问题的损失通常选用交叉熵，优化器可以选用SGD来优化。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction,labels = ys)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure><h3 id="计算精度"><a href="#计算精度" class="headerlink" title="计算精度"></a>计算精度</h3><p>这里要算的数据是预测值与GT之间的差。数据格式为one-hot类型，因此计算步骤先判断每一行是否相等，然后去平均即可,传入的数据为测试集数据。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeAccuracy</span><span class="params">(xtest,ylabel)</span>:</span></span><br><span class="line">    pred = sess.run(prediction,feed_dict=&#123;xs = xtest&#125;)</span><br><span class="line">    correct = tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(ylabel,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))</span><br><span class="line">    result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="train-过程"><a href="#train-过程" class="headerlink" title="train 过程"></a>train 过程</h3><p>使用batch-size SGD的方式进行训练更新：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(opertimizer,feed_dict = &#123;xs:x_batch,ys:y_batch&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            print(computeAccuracy(mnist.test.images,mnist.test.labels))</span><br></pre></td></tr></table></figure><p>整个过程完成，可以通过增加网络层，修改激活函数，learning rate等方式来测试结果。</p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">写一个分类器，首先定义数据</span></span><br><span class="line"><span class="string">然后定义判别层，层包括输入，输入维度，输出维度，激活函数,权重</span></span><br><span class="line"><span class="string">然后是构造结构</span></span><br><span class="line"><span class="string">写loss</span></span><br><span class="line"><span class="string">写opertimizer</span></span><br><span class="line"><span class="string">然后开始训练</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#get the data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST'</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_Fcuntion = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.1</span>)</span><br><span class="line">    Wx_add_b = tf.matmul(input,Weights)+bias</span><br><span class="line">    <span class="keyword">if</span> activation_Fcuntion <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_add_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_Fcuntion(Wx_add_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个三层的神经网络用于mnist 的分类，分别是输入层，输出层，隐藏层</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义输入</span></span><br><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#构造层次</span></span><br><span class="line">prediction = add_layer(xs,<span class="number">784</span>,<span class="number">10</span>,tf.nn.leaky_relu)</span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=ys)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeLoss</span><span class="params">(xtest,ylabel)</span>:</span></span><br><span class="line">    pre = sess.run(prediction,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    correct_rate = tf.equal(tf.argmax(pre,<span class="number">1</span>),tf.argmax(ylabel,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_rate,tf.float32))</span><br><span class="line">    result = sess.run(accuracy,feed_dict=&#123;xs:xtest&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    x_batch,y_batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;xs:x_batch,ys:y_batch&#125;)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(computeLoss(mnist.test.images,mnist.test.labels))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLO V1 详解</title>
      <link href="/2019/03/07/YOLO-V1-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/07/YOLO-V1-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>YOLO 系列检测方法是不同于RCNN系列检测方法的另一种思路，其速度相比于Faster RCNN要快很多，但是精度上基于Faster RCNN框架的算法表现要更好一些，下面介绍YOLO V1.</p><a id="more"></a><blockquote><p>You Only Look Once:Unified, Real-Time Object Detection</p><p>Submit time: 2016.5</p><p><a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="网络的作用及背景"><a href="#网络的作用及背景" class="headerlink" title="网络的作用及背景"></a>网络的作用及背景</h3><p>YOLO在做目标检测时将任务作为一个空间上分开的目标框及其类别置信度的回归问题。单个神经网络一次计算就能够直接从整幅图象预测目标框和类别置信度（one-stage）。</p><p><img src="/images/article/YOLOv1.png" alt=""></p><p>YOLO的训练基于整幅图像，而且能够直接对检测任务进行优化。这个统一的模型在目标检测方面相比传统方法有多个好处。</p><ul><li>YOLO极其之快，YOLO是一个回归问题，省去了复杂的pineline</li><li>YOLO是在整幅图像上全局检测。检测过程中能够包含全局的上下文信息</li><li>YOLO学习到的是物体更加泛化的表示。在如艺术画像上，性能较优</li><li>精度上，YOLO的精度略差于最优的精度</li></ul><h3 id="网络的输入"><a href="#网络的输入" class="headerlink" title="网络的输入"></a>网络的输入</h3><p>将图片划分成SxS个方格，然后对每个方格，预测C个类别的置信度，置信度为confidence X IoU。</p><p>SxS个方格每个方格还输出B个(x,y,width,height,confidence)，表示边框的预测。</p><h3 id="YOLO-V1的网络结构"><a href="#YOLO-V1的网络结构" class="headerlink" title="YOLO V1的网络结构"></a>YOLO V1的网络结构</h3><p>yolo的训练思路为对一张图片划分成S*S大小的网格，然后每个网格预测B的检测框，以及这些检测框的置信度（与GT的IoU程度）。每个边框包含5个变量，分别是(x,y,width,height,confidence)。其中x,y指边框的中心，confidence指置信度。</p><p>对于每一个网络，我们同时计算一下其内含每种物品类别的条件概率：$Pr(Class_i|Object)$，条件概率不受检测的边框数影响，因此对于每个网格还需要预测C个类别的条件概率（是否包含该类别的概率）。当我们测试时，将C个类别的条件概率与边框预测值执行度相乘，得到：<br>$$<br>Class-confidence = Pr(Class_i|Object) * IOU_{truth}^{predict}<br>$$<br>从而得到每个检测框各个类别的分类置信得分。这些分数就同时包含了检测框中出现某类的概率以及检测框和目标的匹配程度。</p><p><img src="/images/article/yolodetect.png" alt=""></p><p><strong>网络结构：</strong>网络一共有24个卷积层和两个全连接层。模型初始的卷积层从图像中提取特征，而全连接层则预测输出概率和坐标。</p><p><img src="/images/article/yolov1structure.png" alt=""></p><h3 id="训练过程以及Loss计算"><a href="#训练过程以及Loss计算" class="headerlink" title="训练过程以及Loss计算"></a>训练过程以及Loss计算</h3><p>YOLO中每个网格可以预测多个检测框。在训练阶段对于一个物体的预测，只分配一个预测框，这种分配是基于与GT当前的IOU最大的预测。这会导致不同检测框之间的特殊化。每一个预测都会在预测特定的尺寸、长宽比、物体种类方面有更好的表现，从而提高整体的召回率。</p><p>网络优化的loss 如下：</p><p><img src="/images/article/yolov1loss.png" alt=""></p><p>其中$\mathbb I_{i}^{obj}$表示网格i中出现了物体 ，$\mathbb I_{ij}^{obj}$ 表示网格i中第j个框负责预测。loss中第一项表示预测边框与GT边框中心的MSE loss，第二项表示预测边框与GT边框长宽的MSE loss，第三项表示对含有物体的网格的每个预测边框置信度的MSE loss，第四项是对不含有物体的网格的每个边框置信度的MSE loss，第五项是对每个网格含有C个类别的条件概率的MSE loss。</p><p>为了训练过程更加的稳定，使用loss从小到大，同时使用dropout和数据增强，防止过拟合。</p><h3 id="YOLO-V1-特点"><a href="#YOLO-V1-特点" class="headerlink" title="YOLO V1 特点"></a>YOLO V1 特点</h3><ul><li>YOLO 在推理时，即图片预测时预测速度非常快，只需要一次网络评估。在Pascal VOC上，每张图像上网络预测<strong>98个边界框和每个框的类别概率</strong>。</li><li>YOLO对相邻物体检测效果不好：由于每个网格只预测两个检测框并且只能用有一个类别。这种设置限制了小目标，以及密集目标的检测效果。</li><li>很难泛化到一些新的或者不寻常的长宽比的检测目标：由于模型是直接从数据中学习边框预测，因此对于一些边框不规则的情形难以检测。</li><li>损失函数对大检测框和小检测框的误差是相同对待的。一个小的误差对于一个大的检测框通常都是比较温和可以接受的，但是一个小的误差对一个小的检测框的IOU有着较大的影响。主要的误差来源就是不准确的坐标定位。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>YOLO V1在先对图片划分S*S个网格，然后对每个网格均做2个边框的预测，以及对所有C个类别计算每个类别对象存在网格内部的条件概率。因此对每个网格检测的变量如下：</p><p><img src="/images/article/yolopred.png" alt=""></p><p>对于每一个对象，用对象中心的落在的网格来预测这个对象的边框，如下图：</p><p><img src="/images/article/yolotrain.jpg" alt=""></p><p>最终通过最小化loss，对边框进行预测。</p><p><img src="/images/article/yololosspic.png" alt=""></p><p>最终得到预测结果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bag of Freebies for Training Object Detection Neural Networks</title>
      <link href="/2019/03/05/Bag-of-Freebies-for-Training-Object-Detection-Neural-Networks/"/>
      <url>/2019/03/05/Bag-of-Freebies-for-Training-Object-Detection-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<p>这是一篇关于目标检测，语义分割领域，<strong>数据预处理</strong>以及网络<strong>调参的技巧文章</strong>。这些技巧对一些强大的算法，如Faster-RCNN，YOLO的性能有很大的提升。<br><a id="more"></a></p><blockquote><p>Bag of Freebies for Training Object Detection Neural Networks<br>submit time: 2019.2<br><a href="https://arxiv.org/pdf/1902.04103.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>这篇文章在没有损失网络速度的前提下，介绍了一些通用的微调方法，使得网络的性能得到了大大的提升，网络的精度得到大幅提升。</p><p>作者首先探讨数据增强方面，图像<strong>mixup</strong>的方法。随后作者探讨了在目标检测训练的pipeline，例如 <strong>learning rate scheduling</strong>, <strong>weight decay</strong> ，<strong>synchronized BatchNorm.</strong> 第三，作者探讨了将上面这些方法共同作用在一个两步或一步检测网络中所带来的性能提升。</p><h3 id="mixup"><a href="#mixup" class="headerlink" title="mixup"></a>mixup</h3><p>本文的研究者认识到了多目标检测任务的特殊性质有利于实现空间不变的变换，因此提出了一种用于目标检测任务的视觉相干（visually coherent）图像混合方法。使用mixup，但是beta分布选择较大a&gt;=1,b&gt;=1(而不是传统的0.2)，融合后的图片显得和现实一致。同时没有对mixup进行空间上的扭曲，使用几何形状保持的对齐方式对图片进行融合。<br><img src="/images/article/mixup.png" alt=""><br>如上图第一中传统mixup的方式作者认为仅仅是引入了一些noise。第二种mixup的方式不对图片进行distort，同时与视觉一致，数据增强效果更好。</p><h3 id="Classification-Head-Label-Smoothing"><a href="#Classification-Head-Label-Smoothing" class="headerlink" title="Classification Head Label Smoothing"></a>Classification Head Label Smoothing</h3><p>大部分的目标检测或语义分割网络中使用的loss 是基于softmax的交叉熵loss，这种loss 鼓励检测到的目标类别为正类别为1，其他为0。softmax函数如下：<br>$$<br>p_i = \frac{e^{z_i}}{\sum_j e^{z_j}}<br>$$<br>因此loss鼓励$e^{z_i} &gt;&gt; e^{z_j},i != j$这种极端情形，十分容易发生过拟合现象。因此使用label smoothing 来缓解这一现象。具体做法如下：<br>我们对groundtruth q进行smoothing操作，q在变换前是one hot编码形式，通过如下变换：<br>$$<br>q_i = (1 - \epsilon )q_i + \frac{\epsilon}{K}<br>$$<br>其中$\epsilon$ 是一个很小的数，完成smoothing 操作。</p><h3 id="Data-Pre-processing"><a href="#Data-Pre-processing" class="headerlink" title="Data Pre-processing"></a>Data Pre-processing</h3><p>作者采用了一下的数据增强方式：</p><ul><li>随机几何变换. 包括随机裁剪, 随机扩张, 随机水平翻转，随机缩放等等。</li><li>随机颜色抖动：包括亮度，色调，饱和度，对比度。</li></ul><h3 id="cosine-learning-rate-decay-and-Warm-up-learning-rate"><a href="#cosine-learning-rate-decay-and-Warm-up-learning-rate" class="headerlink" title="cosine learning rate decay and Warm up learning rate"></a>cosine learning rate decay and Warm up learning rate</h3><p>通常在训练过程中，学习率都是从一个较大的值开始然后在训练过程中不断减少，最常用的是 Step schedule（阶梯式衰减）。例如，训练一定的Epoch之后，学习率衰减为原来的 0.1。Step schedule 使得急剧学习率的急剧下降，造成训练不稳定的问题。因此作者选择更为平滑的 Cosine 学习率衰减策略。<br><img src="/images/article/learingrate.png" alt=""></p><h3 id="Synchronized-Batch-Normalization"><a href="#Synchronized-Batch-Normalization" class="headerlink" title="Synchronized Batch Normalization"></a>Synchronized Batch Normalization</h3><p>在多GPU环境下，对于一些batch size很小网络，在训练的时候BN会导致一些性能的下降。这个问题可以通过同时进行BN来解决。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileNet V2 详解</title>
      <link href="/2019/03/04/MobileNet-V2-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/04/MobileNet-V2-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>MobileNet V2 是在V1的基础上做了一些结构上的调整，主要有<strong>inverted residual</strong> 以及<strong>Linear Bottlenecks</strong>的改进。使得mobileNet v2 的精度进一步提高，结构进一步合理。<br><a id="more"></a></p><blockquote><p>MobileNetV2: Inverted Residuals and Linear Bottlenecks<br>submit time: 2018<br><a href="https://arxiv.org/pdf/1801.04381.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="mobileNets的背景及作用"><a href="#mobileNets的背景及作用" class="headerlink" title="mobileNets的背景及作用"></a>mobileNets的背景及作用</h3><p>mobileNet V1在设计的时候使用deepwise separable conv代替传统的卷积，大大降低了模型的计算量和复杂度，但是其仍然存在以下两个缺陷：</p><ul><li><strong>直筒型的结构影响网络性能</strong>，后续的网络如ResNet等，在网络中重复使用图像特征能够提高网络的性能。（引入inverted residual）</li><li><strong>depthwise Convolution 导致特征退化问题</strong>：由于depthwise conv使用很小的卷积核（1x1），经过BN归一化，以及relu激活之后很容易变为0，即变成死节点,<strong>导致特征退化</strong>。（我的理解是，对于一个1x1的kernel来说，归一化过程可能会把它变成负数，然后relu激活后就会变成死节点。但是对于kernel size比较大的卷积，要使整个卷积核上的数都变成负数要难很多，因此不会有很严重的特征退化问题。）（引入linear bottlenecks）.</li></ul><p>mobileNet v2 通过引入inverted residual，将图像中的特征反复使用，提高网络的性能。对于特征退化的问题，通过linear bottleneck，去掉网络中的relu等步骤，能够缓解特征的退化。<br><img src="/images/article/v2detial.png" alt=""></p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性激活函数。</p><p>线性瓶颈的倒置残差结构：模块的输入为一个低维的压缩表示特征，首先将其扩展到高维并用轻量级depthwise conv 进行卷积。随后用线性卷积（linear conv）将特征投影回低维表示。</p><p><strong>MobileNet v2 模型的特点：</strong></p><p><img src="/images/article/linearBottle.png" alt=""><br>如上图，mobileNet v2在V1基础上进行了改进。</p><p>相同点：<br>mobileNet v2由v1发展而来，继承了<strong>深度可分卷积</strong>（depthwise seperable conv），采用深度卷积和逐点卷积来代替传统的卷积操作，使得计算量大大减小。<a href="http://perper.site/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener">参考链接</a></p><p>不同点：<br><strong>V2在每个DW卷积之前加入了一层PW的卷积，主要作用是用于提升特征的channel数。</strong>由于DW层无法提升feature map的通道数，于是先通过PW提升feature map的通道数，PW卷积的大小为：Mx1x1，卷积核的个数可以控制，也即为卷积后得到feature map的通道数。至于提升channel的具体原因如下：</p><blockquote><p>当我们查看深层卷积层所有的d通道像素时，在这些值中编码的信息实际上位于某个流形中，这些流形结构可以嵌入到低维子空间中。<br>ReLu在高层空间中的变换有助于增加网络的非线性。对于ReLU（Bx）激活后的非0部分，输入空间与输出空间之间的特征映射是线性变换。另一方面，当ReLU破坏通道时（relu小于0的部分），它会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。<br>总而言之，以下两个特性表明感兴趣的流形区域位于较高维激活空间的低维子空间中：</p><ol><li>如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。</li><li>只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。</li></ol></blockquote><p>因此我们需要先对channel通道进行升维。假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。线性可以防止非线性破坏太多的信息。</p><p><strong>Linear Bottleneck：</strong>V2 去掉了第二个 PW 的激活函数。论文作者称其为 Linear Bottleneck。这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。由于第二个 PW 的主要功能就是降维，降维之后使用线性瓶颈层来获取低秩信息，防止非线性破坏太多信息。</p><p><strong>倒置残差：</strong><br><img src="/images/article/inverted_residual.png" alt=""><br>V2的 shortcut  设计与ResNet相反，呈一个纺锥型，中间大两头小，因此称为<strong>倒置残差</strong>。使用倒置设计是由于其内存效率要高得多。<br>网络将PW层得到的feature map先扩展6倍，然后通过DW卷积，与一个shortcut上来的feature map融合之后再输入PW卷积。</p><p>mobileNet的结构单元如下：<br><img src="/images/article/v1structure.png" alt=""><br><img src="/images/article/V2structure.png" alt=""></p><p>网络结构参数如下：<br><img src="/images/article/v2net.png" alt=""></p><p>整体的结构如下：<a href="https://zhuanlan.zhihu.com/p/33075914" target="_blank" rel="noopener">参考链接</a><br><img src="/images/article/structureV2.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow 笔记（搭建网络-II）</title>
      <link href="/2019/03/04/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-II%EF%BC%89/"/>
      <url>/2019/03/04/Tensorflow%20%E7%AC%94%E8%AE%B0%EF%BC%88%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-II%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>本篇文章主要讲网络搭建过程中的代码以及注意要点。<br><a id="more"></a></p><h3 id="添加网络层"><a href="#添加网络层" class="headerlink" title="添加网络层"></a>添加网络层</h3><p>定义网络结构，然后将网络层添加到神经网络中。定义网络层的主要步骤有：</p><ul><li>确定网络的参数：<strong>输入，输入的size，输出的size，激励函数</strong></li><li>定义weight，biases</li><li>计算output</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_function = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+<span class="number">0.01</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(input,Weights)+biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        output = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = activation_function(Wx_bias_b)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>可以看出来，网络层神经元的个数即为输出的outsize的大小。</p><h3 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h3><p>以下为搭建一个三层神经网络，其中输入层为1个神经元，输出层为1个神经元，隐藏层为10个神经元。搭建网络是需要完成的事情为：</p><ol><li>定义数据，网络层中的参数维度</li><li>定义传入的参数placeholder，loss，optimizer等</li><li>值得注意的是，数据的维度变化需要十分注意</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># create data</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.rand(x_data.shape[<span class="number">0</span>],x_data.shape[<span class="number">1</span>])</span><br><span class="line">y_GT = np.square(x_data)+<span class="number">0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># placeholder</span></span><br><span class="line">xs = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>]) <span class="comment">#表示样本数，和每个样本的维度为1</span></span><br><span class="line">ys = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># structure</span></span><br><span class="line">l1 = add_layer(ms,<span class="number">1</span>,<span class="number">10</span>,tf.nn.relu)</span><br><span class="line">output = add_layer(l2,<span class="number">10</span>,<span class="number">1</span>,<span class="keyword">None</span>)</span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),<span class="number">1</span>))</span><br><span class="line">optimizer = tf.train.GrandientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#train</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br></pre></td></tr></table></figure><p><strong>代码详解如下：</strong></p><ol><li><p><code>x_data = np.linspace(-1,1,300)[:,np.newaxis]</code>：其中<code>np.linspace(-1,1)</code>生成-1，到1之间的300个数。<code>[:,np.newaxis]</code>指将生成的数据维度提升。原来是1x300，现在是300x1，由1为变为300维，每个数据占一个维度。</p></li><li><p><code>xs = tf.placeholder(tf.float32,[None,1]) #表示样本数，和每个样本的维度为1</code>：其中<code>[None,1]</code>有一种含义为，当你不知道样本数的时候，抓住每个样本的维度即可。</p></li><li><code>tf.reduce_sum(tf.square(output-ys),1)</code>: 其中<code>tf.reduce_sum()</code>这个函数为求和函数，第一个参数是一个<strong>数组</strong>，第二个参数默认则为<strong>所有数之和</strong>。第二个参数为0，则为<strong>列之和（0）</strong>，第二个参数为1则为<strong>行之和（1）</strong>。<code>tf.reduce_mean()</code>参数含义与求和函数一致。</li><li>在写网络结构的时候，用placeholder，暂时忘记掉真实的数据，先构建好框架后，然后传入参数。</li></ol><h3 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h3><p>可视化模块一般使用<code>matplotlib.plot as plt</code> 来绘图。</p><p><strong>matplotlib的层次结构：</strong><br>matplotlib的结构类似与一个树状结构。<code>Figure</code> : 为层次结构中的最外层，内部可包含多张plot图像。plot图层次结构可包含的对象例如刻度线，单独的线条，图例和文本框。几乎每个“元素”都是一个Python对象。具体代码实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.linspace(-np.pi,np.pi,<span class="number">300</span>)</span><br><span class="line">xsin = np.sin(x)</span><br><span class="line">xcos = np.cos(x)</span><br><span class="line">plt.subplot(<span class="number">221</span>) <span class="comment"># 表明共有2列，2行的图片要画，现在拿到第一个来画</span></span><br><span class="line">plt.plot(x,xsin) <span class="comment"># 要画折线图，如果点很密集，就是曲线图</span></span><br><span class="line">plt.xlabel(<span class="string">'x轴'</span>) <span class="comment"># 所有属于这个子图的小对象，如颜色，图例，都可以修改</span></span><br><span class="line">plt.subplot(<span class="number">222</span>) <span class="comment"># 表明2列2行，现在要画第二个</span></span><br><span class="line">plt.plot(x,xcos)</span><br><span class="line">plt.subplot(<span class="number">223</span>) <span class="comment"># 表明2行2列，现在要画第三个</span></span><br><span class="line">plt.scatter(x,xsin) <span class="comment"># 要画散点图</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>如上，每次使用<code>plt.subplot(xxx)</code>交换控制的子图，非常好懂哈哈哈。</p><p>下面是搭建网络，绘制拟合图的完整代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'KMP_DUPLICATE_LIB_OK'</span>]=<span class="string">'True'</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">添加层需要考虑的因素有几个，首先输入的数据，输入的数据尺度，输出的尺度（神经元个数），激活函数</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(input,in_size,out_size,activation_function = None)</span>:</span></span><br><span class="line">    <span class="comment">#定义权重</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size,out_size]))</span><br><span class="line">    bias = tf.Variable(tf.zeros([<span class="number">1</span>,out_size])+ <span class="number">0.01</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(input,Weights) + bias</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">构建神经网络：</span></span><br><span class="line"><span class="string">1. 搭建一个输入层仅有一个神经元，隐藏层10个神经元，输出层1个神经元的网络</span></span><br><span class="line"><span class="string">2. 需要定义数据，网络层，输入输出，placeholder，loss ，optimizer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># np.linspace(-1,1,10)[:,np.newaxis],引入新维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create data</span></span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:,np.newaxis]</span><br><span class="line"></span><br><span class="line">noise = np.random.rand(<span class="number">300</span>,<span class="number">1</span>)</span><br><span class="line">y_GT = np.square(x_data) + <span class="number">0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># create network</span></span><br><span class="line"></span><br><span class="line">xs = tf.placeholder(tf.float32,x_data.shape)</span><br><span class="line">ys = tf.placeholder(tf.float32,y_GT.shape)</span><br><span class="line"></span><br><span class="line">l1 = add_layer(xs,<span class="number">1</span>,<span class="number">10</span>,activation_function=tf.nn.relu)</span><br><span class="line">output = add_layer(l1,<span class="number">10</span>,<span class="number">1</span>,activation_function=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(output-ys),<span class="number">1</span>))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#illustration</span></span><br><span class="line">ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">plt.scatter(x_data,y_GT)</span><br><span class="line"></span><br><span class="line">plt.ion() <span class="comment"># 动态画图，不停止</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_GT&#125;))</span><br><span class="line">            predict = sess.run(output,feed_dict=&#123;xs:x_data&#125;)</span><br><span class="line">        <span class="comment">#    plt.plot(x_data,predict)</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                ax.lines.remove(lines[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># plot the prediction</span></span><br><span class="line">            lines = plt.plot(x_data, predict, <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">            plt.pause(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure></p><h3 id="TensorBoard-可视化"><a href="#TensorBoard-可视化" class="headerlink" title="TensorBoard 可视化"></a>TensorBoard 可视化</h3><p>Tensorboard 作为tensorflow网络结果可视化的一个比较好的工具，他使用<code>tf.name_scope(&quot;name&quot;):</code>的方式对部分元件进行整体的命名。并且支持多层的嵌套。如下例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"layer"</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"Weight"</span>):</span><br><span class="line">        Weights = tf.Variable(tf.random.normal([<span class="number">300</span>,<span class="number">1</span>]),name = <span class="string">'W'</span>)</span><br></pre></td></tr></table></figure><p>tensorboard工作的思路是将文件写入磁盘，然后由浏览器进行访问，写入磁盘的语句如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'./log'</span>,sess.graph)</span><br></pre></td></tr></table></figure><p>最后在命令行中，进入文件目录输入指令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir = 'log/'</span><br></pre></td></tr></table></figure><p>随后在浏览器中输入：<code>0.0.0.0:6006</code>即可预览。</p><p>tensorboard还可以监控单个变量的变化情况，使用histogram直方图来显示。<code>tf.summary.histogram</code>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Weight"</span>):</span><br><span class="line">    Weights = tf.Variable(tf.random.normal([<span class="number">300</span>,<span class="number">1</span>]),name = <span class="string">'W'</span>)</span><br><span class="line">    tf.summary.histogram(name,Weight)</span><br></pre></td></tr></table></figure><p>tensorboard看一个一维的变量，如loss，使用<code>tf.summary.scalar</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce.mean(tf.reduce.sum(tf.square(y-p_pred),<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'loss'</span>,loss)</span><br></pre></td></tr></table></figure><p>最后需要对所有的summary进行融合：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merged = tf.summary.merge_all()</span><br></pre></td></tr></table></figure><p>接下来在训练的时候更新参数,然后使用<code>writer.add_summary(result,step)</code>来将summary写入文件中。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            result = sess.run(merged,feed_dict=&#123;xs:x_data,ys:y_GT&#125;)</span><br><span class="line">            writer.add_summary(result,step)</span><br></pre></td></tr></table></figure><p>接着使用命令行运行即可.x</p>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileNets 详解</title>
      <link href="/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>mobileNets为谷歌开发的，为<strong>移动或嵌入式端</strong>视觉应用开发的一个轻量级高效模型。<br><a id="more"></a></p><blockquote><p>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications<br>submit time: 2017<br><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="mobileNets的背景及作用"><a href="#mobileNets的背景及作用" class="headerlink" title="mobileNets的背景及作用"></a>mobileNets的背景及作用</h3><p><strong>背景：</strong>在很多CNN的是被问题中，总体趋势是使用更深层次更加复杂的模型来实现更高的精度。然后提高精度的代价往往是网络在尺度和速度的性能变差，对于一些要求时效且计算资源有限的任务这些网络难以完成。</p><p><strong>mobileNets：</strong>本文介绍的moblieNets具有<strong>高效的网络结构和两个超参数</strong>，以便构建非常小的，快速度的模型，可以轻松匹配移动和嵌入式视觉应用的设计要求。</p><p>本文提出了一类网络结构，允许模型开发人员选择与其应用程序的资源限制（延迟，大小）相匹配的小型网络。MobileNets主要侧重于优化速度，但也能够产生小型网络，我们介绍了两个简单的全局超参数，可以在时间和准确性之间进行有效折中。</p><p><strong>深度可分离卷积：</strong><br><img src="/images/article/deepwiseconv.png" alt=""></p><p>一个传统的大小为$M*N*D_k*D_k$的卷积核，对一个大小为$D_F*D_F$的features map进行卷积，他的计算量为：$N*M*D_k*D_k*D_F*D_F$.<br>MobileNets基于深度可分离卷积构建，深度可分离卷积由两层构成：<strong>depthwise convolutions</strong>和<strong>pointwise convolutions</strong>，分别对将$M*N*D_k*D_k$的大小的卷积核进行深度（channel）和尺寸（$D_k$）上的分割：<br>其中M为通道数，N为卷积核个数，$D_k$为卷积核大小。</p><ul><li>depthwise convolution：将$M*D_k*D_k$的卷积核分解为$1*D_k*D_k$，一共M组卷积核（不使用N），即每个卷积核仅对一个通道进行处理。对于一个大小为$D_F*D_F$的features map他的计算量为：$M*D_k*D_k*D_F*D_F$.</li><li>Pointwise convolution（1x1卷积）：即将$M*D_k*D_k$的卷积核分解为$M*1*1$大小的卷积核共有N个，用来创建depthwise层的线性叠加。该层的计算量为$N*M*D_F*D_F$.</li></ul><p>Deep-wise 分离卷积相比于传统卷积的计算量减少如下：<br>$$<br>\frac{M*D_k*D_k*D_F*D_F+N*M*D_F*D_F}{N*M*D_k*D_k*D_F*D_F} = \frac{1}{N} + \frac{1}{D_K^2}<br>$$<br>计算量得到了显著的下降，而模型准确率仅下降了一点点，MobileNets对两层卷积层都使用了BatchNormalization和ReLU非线性激活。 一个转换的例子如下：<br><img src="/images/article/deepwise.png" alt=""></p><h3 id="MobileNets-网络结构"><a href="#MobileNets-网络结构" class="headerlink" title="MobileNets 网络结构"></a>MobileNets 网络结构</h3><p>网络共28层，大大量重叠的deepwise结构组成，最后接一个argpooling送入全连接层进行softmax分类。网络中大部分参数及计算来自1*1的卷积层，以及最后的全连接层。<br>网络很少使用BN以及数据增强技术，因为小网络不易发生过拟合现象。<br><img src="/images/article/deepwisestructure.png" alt=""></p><h4 id="超参-Width-multiplier（更小的模型）"><a href="#超参-Width-multiplier（更小的模型）" class="headerlink" title="超参 Width multiplier（更小的模型）"></a>超参 Width multiplier（更小的模型）</h4><p>我们使用一个参数$\alpha$，称为width multiplier。它的作用是在每层均匀地减负网络。对于一个给定的层和$\alpha$，输入通道的数量从M变成$\alpha M$，输出通道的数量从N变成$\alpha$N。深度可分离卷积的计算复杂度变为原来的$\alpha$倍。<br>α在(0,1]之间，通常设为1，0.75，0.5和0.25。Width multiplier有减少计算复杂度和参数数量（大概α二次方）的作用。用于定义新的简化结构，但需要重新进行训练。计算复杂度如下：<br>$$<br>\alpha M*D_k*D_k*D_F*D_F+\alpha N* \alpha M*D_F*D_F<br>$$</p><h4 id="超参-Resolution-Multiplier-（Reduced-Representation）"><a href="#超参-Resolution-Multiplier-（Reduced-Representation）" class="headerlink" title="超参 Resolution Multiplier （Reduced Representation）"></a>超参 Resolution Multiplier （Reduced Representation）</h4><p>使用超参数$\rho$用于减小图片的尺度，$\rho$的范围在(0,1]之间，用于缩减图片的大小，计算复杂度如下：<br>$$<br>\alpha M*D_k*D_k* \rho D_F* \rho D_F+\alpha N* \alpha M*\rho D_F* \rho D_F<br>$$</p><p>通过调整$\alpha,\rho$来使得模型在资源使用和精确度上执行折中。</p><h3 id="网络的损失函数"><a href="#网络的损失函数" class="headerlink" title="网络的损失函数"></a>网络的损失函数</h3><p>网络损失函数较为简单，即为feature map接一个全连接层，然后连上softmax loss。<br>$$<br>Loss = \sum_I y_i \log p_i<br>$$</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>MobileNets 是一个目标识别网络，即用来判断一张图片的类别。它在原有CNN的基础上，将卷积层进行了deepWise 和pointWise上的分解，参数量大大减少，精度仅下降一点点。缩减结构的同时，使用两个超参数控制参数的大小以及图片的大小，在精度和资源上进行权衡。此外，MobileNets可以作为许多网络的特征提取部分，例如Faster RCNN的特征提取部分等等，精度在可以满足的情况下，大大降低了网络的参数量。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow 笔记（基础部分-I）</title>
      <link href="/2019/03/03/TensorFlow-%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/03/03/TensorFlow-%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>TensorFlow是一个开源的软件包，用于各种感知以及语言理解的机器学习，深度学习任务。<br><a id="more"></a></p><h2 id="简单例子："><a href="#简单例子：" class="headerlink" title="简单例子："></a>简单例子：</h2><p>使用MSE loss去拟合一条二维的直线，优化方式选择SGD。步骤如下：</p><ol><li>定义训练数据，以及GroundTruth</li><li>搭建tensorflow的结构，包括变量的定义(weight,bias)，损失函数的定义，优化器的定义</li><li>执行tensorflow，使用tf.Session()定义回话，用于执行tensorflow计算图。设置epoch的次数（执行次数）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#create data</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>) <span class="comment"># 100个 0～1之间的数</span></span><br><span class="line">y_data = x_data*<span class="number">0.3</span> + <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create tensorflow structure</span></span><br><span class="line">Weights = tf.Variable(tf.random.uniform([<span class="number">1</span>],<span class="number">-1.0</span>,<span class="number">1.0</span>))</span><br><span class="line">Bias = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">y = Weights*x_data + Bias</span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># execute</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(Weights),sess.run(Bias))</span><br></pre></td></tr></table></figure><p>这里头可说的东西有很多，首先是：<code>np.random.rand(100)</code>,即：</p><h3 id="numpy产生随机数的方式："><a href="#numpy产生随机数的方式：" class="headerlink" title="numpy产生随机数的方式："></a>numpy产生随机数的方式：</h3><p>为什么重要，因为很多神经网络中参数的初始化，都是使用numpy来完成的，以前没仔细记录导致一知半解，自己写不出来。<a href="https://www.jianshu.com/p/214798dd8f93" target="_blank" rel="noopener">详细链接</a></p><ol><li><code>np.random.rand(4,2)</code>: 表示产生（0，1）之间的float随机数，维度为4x2.  <code>np.random.rand(4,2,3)</code>:维度为4x2x3.</li><li><code>np.random.randn(4,2)</code>: 表示产生一组符合正态分布的数 N ( 0,1 )，维度是4x2.</li><li><code>np.random.randint(low,high,size = (4,2))</code>: 表示产生一组整数，维度为4x2，大小在[low,high)之间。</li><li><code>np.random.seed(1) np.random.rand(5)</code>:表示指定了seed，该seed下产生的随机数是相同的。</li></ol><h3 id="tensorflow中表示变量的函数：tf-Variable"><a href="#tensorflow中表示变量的函数：tf-Variable" class="headerlink" title="tensorflow中表示变量的函数：tf.Variable()"></a>tensorflow中表示变量的函数：tf.Variable()</h3><p>tensorflow中所有的变量使用函数定义，<code>tf.Variable</code> 类用于操纵变量，该变量可以通过op运算来更改他的值。<br><strong>定义变量：</strong><br><code>weights  = tf.Variable(&lt;initial-value&gt;,name = &lt;optional&gt;)</code><br><strong>变量的初始化：</strong><br>与其他语言不同，tensorflow在使用变量的时候需要先进行初始化操作。可以这么理解，<strong>tensorflow内部是以执行Graph的形式进行计算的，之前的所有操作，如定义变量，仅仅是构建Graph的结构，但是并没有真正的将值传入Graph节点中，因此需要tf.Session()来执行初始化操作，为变量节点赋值。</strong>初始化如下：<br><code>init  = tf.global_variables_initializer()</code><br><code>sess = tf.Session()</code><br><code>sess.run(init)</code></p><h3 id="tensorflow-产生随机数"><a href="#tensorflow-产生随机数" class="headerlink" title="tensorflow 产生随机数"></a>tensorflow 产生随机数</h3><ol><li><code>tf.random.uniform([2,3],minval = -1,maxval = 1,seed = None)</code>：表示产生均匀分布的随机数，大小在[minval,maxval]之间。</li><li><code>tf.random.normal([2,3],mean = 0,stddev = 1)</code>： 表示产生正态分布的随机数，服从N（0，1）。</li><li><code>tf.truncated.normal([2,3],mean = 0,stddev = 1)</code>：表示生成范围在[mean-2stddev,mean+2stddev]范围内的正态分布随机数。</li><li><code>tf.random.shuffle([1,2,3,4])</code>：表示沿着第一维，对数组进行重新排列。</li></ol><p>此外初始化为0: <code>tf.zeros([2,3])</code></p><h3 id="tensorflow-中的Loss"><a href="#tensorflow-中的Loss" class="headerlink" title="tensorflow 中的Loss"></a>tensorflow 中的Loss</h3><p><strong>MSE Loss：(L2)</strong><br><code>mse = tf.reduce_mean(tf.square(y_pre,y))</code><br><strong>MAE Loss: (L1)</strong><br><code>mae = tf.losses.absolute_difference(y_pre,y)</code><br><code>mae_loss = tf.reduce_sum(mae)</code></p><p><strong>处理分类问题交叉熵Loss：</strong><br><code>softmax_sparse = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,logits = y_pred)</code><br><code>loss = tf.reduce_mean(softmax_sparse)</code><br>其中不要求y-true 是one-hot 格式。</p><p><strong>优化器：</strong><br>tensorflow中的优化器共有其中，均在<code>tf.train</code> 这个类中，使用的时候看具体的应用。<code>optimizer = tf.train.GradientDescentOptimizer(0.5)</code><br><code>train = optimizer.minimize(optimizer)</code></p><h3 id="tf-Session-会话控制："><a href="#tf-Session-会话控制：" class="headerlink" title="tf.Session() 会话控制："></a>tf.Session() 会话控制：</h3><p>Session 用于执行计算图中的节点，因此获取一个值，或者是最小化loss等操作，都需要使用Session来激活部分计算图。使用如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    sess.run(train)</span><br></pre></td></tr></table></figure></p><h3 id="tf-constant-常量："><a href="#tf-constant-常量：" class="headerlink" title="tf.constant() 常量："></a>tf.constant() 常量：</h3><p>tensorflow 用 <code>tf.constant()</code> 来申请一个常量，常量指不能被修改的数。<br><code>matrix1 = tf.constant([[1,2],[3,4]])</code></p><h3 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder"></a>tf.placeholder</h3><p><code>tf.placeholder(tf.float32,[3,2])</code>:表示数据类型为<code>tf.float32</code>，大小为3x2。使用placeholder的目的是：</p><ul><li>placeholder 可以作为一个参数，专门用来将数据传入函数中</li><li>由于tensorflow是计算图模型，如果使用变量传参数的话，计算图将会变得很大，不便与计算，因此使用placeholder来代替</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">input1 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">input2 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">ouput = tf.multiply(input1,input2)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output,feed_dict=&#123;input1:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>]],input2:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]&#125;))</span><br></pre></td></tr></table></figure><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.relu(features,name = <span class="keyword">None</span>) <span class="comment"># 下面均相同</span></span><br><span class="line">tf.nn.relu6</span><br><span class="line">tf.nn.crelu</span><br><span class="line">tf.nn.elu</span><br><span class="line">tf.nn.selu</span><br><span class="line">tf.nn.softplus</span><br><span class="line">tf.nn.softsign</span><br><span class="line">tf.nn.dropout</span><br><span class="line">tf.nn.bias_add</span><br><span class="line">tf.sigmoid</span><br><span class="line">tf.tanh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tensorflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ESRGAN 详解</title>
      <link href="/2019/03/02/ESRGAN-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/02/ESRGAN-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="ESRGAN-详解"><a href="#ESRGAN-详解" class="headerlink" title="ESRGAN 详解"></a>ESRGAN 详解</h3><p>ESRGAN网络是在SRGAN的基础上，对对抗损失以及感知损失进一步的改善，引入residual-in residual Dense Block(残差密集块)来组建网络而取代了网络中的BN。并且借鉴了相对GAN的思想，让给判别器预测相对的真实性，而不是完全相同。<br><a id="more"></a><br>ESRGAN网络的作者是香港中文大学的学生，他对学习的建议是多看论文多实验，自己push自己！显然能力越大舞台越大！</p><blockquote><p>ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks<br>submit time:2018 ECCV<br><a href="https://arxiv.org/pdf/1809.00219.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h4 id="ESRGAN-的作用"><a href="#ESRGAN-的作用" class="headerlink" title="ESRGAN 的作用"></a>ESRGAN 的作用</h4><p>传统提升SR（super resolution）的方法是使用Peak Signal-to-Noise Ratio(PSNR)峰值信噪比，即最小化生成图片与GT之间的MSE loss，但是这种优化策略倾向于输出平滑的结果而没有足够多的具体细节。<br>这篇文章在SRGAN的基础上进行改进，提升了图片超分辨率的精度，作者从三个方面提升修改模型：</p><ul><li>引入密集残差块（RDDB）去除了BN，节省内存空间提升模型的结构，使之具有更大的容量和更易于训练。</li><li>辨别器使用相对平均GAN（RaGAN），即判断“是否一个图像相比于另一个更真实”而不是“是否一个图像是真或假”。这个改进有助于生成器恢复更真实的纹理细节。</li><li>SRGAN感知损失部分，使用激活函数之前的VGG features map，而不是SRGAN激活之后的feature map，调整后的感知损失提供了清晰的边缘和更具有视觉体验的结果</li></ul><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><strong>生成器部分：</strong><br><img src="/images/article/ESRGAN.png" alt=""><br>生成器结构上的改进：</p><ul><li>去除所有的BN层</li><li>用残差基础块代替原始基础块</li></ul><p><img src="/images/article/ESRGANgen.png" alt=""><br>BN在训练期间需要计算整个训练集的均值和方差，当训练集和测试集差异很大的时候会引入伪影，造成图像的模糊，通过在残差块中去除BN层，有助于提高泛化能力，能够减少空间和计算复杂度。</p><p>生成器训练过程的tip：<br>1）残差缩放，例如将残差乘以0和1之间的常数（图中$\beta$），然后将它们添加到主路径以防止不稳定。<br>2）较小的初始化参数，当初始参数方差变小时，残差结构更容易训练。</p><p><strong>判别器部分：（相对判别器）</strong><br>判别器部分使用相对判别，也即是说真实图像与生成图像哪个更加真实一些。<br><img src="/images/article/ESRGANdis.png" alt=""><br>如上图，真实判别器为$D(x_r) = \sigma (C(x))$,其中$\sigma$ 为sigmoid函数，$C(x)$为sigmoid转换前判别器的输出。相对判别器在则判断是的，真实图像是否比生成图像更加的真实：<br>$$<br>D_{ra}(x_r,x_f) = \sigma(C(x_r) - E[C(x_f)] )<br>$$<br>其中$E[C(x_f)]$为在mini-batch中所有的生成图片取均值。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><strong>生成器部分：</strong><br>生成器的loss由三部分组成：</p><p>$$<br>L_G = L_{percep}+ \lambda L_G^{Ra} + \eta L_1<br>$$<br>其中$L_{percep}$为vgg中激活函数之前的features map与GT的features map的MSE loss（同SRGAN），$L_{G}^{Ra}$损失为对抗损失（与判别器对称）：<br>$$<br>L_G^{Ra} = -E_{x_r}[log(1-D_{Ra}(x_r,x_f))] - E_{x_f}[log(D_{Ra}(x_f,x_r))]<br>$$<br>即生成器的目标是另判别器将生成图片判断成比原始图像真实。$L_1$ loss 表示恢复图像与真实图像之间的L1 距离：$$L_1 = E_{x_a} || G(x_i)-y||_1$$</p><p><strong>判别器部分：</strong><br>判别器loss与生成器对抗loss对称，如下：<br>$$<br>L_D^{Ra} = -E_{x_r}[log(D_{Ra}(x_r,x_f))] - E_{x_f}[log(1 - D_{Ra}(x_f,x_r))]<br>$$<br>判别器的目标是将原始图片判别成更加的真实。</p><h4 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h4><ul><li>用密集残缺块来代替原有的基础块，去除了BN</li><li>对GAN进行修改，进而去判断相对真实感</li><li>对激活前的features map做MSE提升恢复精度</li></ul><p><strong>网络插值：</strong>为了去除PSNR导致的像素平滑，同时保证感知质量。可以通过训练一个PSNR 的生成器$G_{PSNR}$，然后基于GAN网络的$G_{GAN}$进行fine tune,然后利用插值模型得到一个插值网络。<br>$$<br>\theta_{G}^{INTERP} = (1-\alpha) \theta_G^{PSNR}+\alpha \theta_G^{GAN}<br>$$<br>因此可以通过调整$\alpha$的大小来调整网络输出PSNR指标与视觉效果。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>网络在SRGAN的基础上进行了大量的改进，包括在训练方法上，loss的设计上等等，最终取得了较好的恢复结果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微电阻成像</title>
      <link href="/2019/03/02/%E5%BE%AE%E7%94%B5%E9%98%BB%E6%88%90%E5%83%8F/"/>
      <url>/2019/03/02/%E5%BE%AE%E7%94%B5%E9%98%BB%E6%88%90%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="微电阻成像"><a href="#微电阻成像" class="headerlink" title="微电阻成像"></a>微电阻成像</h3><p><strong>原理：</strong></p><p><strong>微电阻率扫描成像测井</strong>采用多个有序排列、间距几毫米的钮扣电极测量井壁地层电阻率，并形成分辨率很高的井壁图像，从而对地层进行细微分析的电阻率测井方法。<br><a id="more"></a><br>它采用多个压向井壁的极板，每个极板上的多排钮扣状小电极向井壁地层发射电流，由于电极所接触的井壁岩石的结构、成分及所含流体的不同引起电流变化，<strong>电流的变化反映了正对电极处井壁地层电阻率的变化。</strong>经过适当的处理，可以描绘为彩色或灰度等级的<strong>井壁电阻率图像</strong>，对地层岩性、沉积特征、构造特征、裂缝及洞穴等进行分析。</p><p><strong>微电阻图像：</strong></p><p>将电阻率数据进行处理，然后进行颜色的映射，得到的结果如下：<br><img src="/images/ictproject/test.jpg" alt=""><br>上图宽表示井口的周长，长表示测井的深度（图中仅为部分长度）。可以看出来，途中存在倾斜的黑色条道，只是由于探测的时候设备仅仅有六个探测口，然后每次探测完一个深度探测口发生旋转，继续进行探测。黑色条道即为探测器之间的距离。</p><p><strong>任务：</strong></p><p>根据已有的数据，恢复出黑色条道部分的数据。</p><h2 id="workFlow"><a href="#workFlow" class="headerlink" title="workFlow"></a>workFlow</h2><hr><h3 id="2019-3-5"><a href="#2019-3-5" class="headerlink" title="2019.3.5"></a>2019.3.5</h3><p>沟通需求之后发现暂时需要实现有数据部分的数据恢复工作，接下来用网络跑一下看看效果。如果效果好的话，改写到tensorflow的版本。</p><p>下图是使用ESRGAN恢复得到超分辨后的结果。右图是原图放大到像素级别的效果，左图是图片恢复后的效果图。<br><img src="/images/ictproject/SRresult.png" alt=""></p><hr><h3 id="2019-3-3"><a href="#2019-3-3" class="headerlink" title="2019.3.3"></a>2019.3.3</h3><p>do something in this place</p><hr><h3 id="2019-3-2"><a href="#2019-3-2" class="headerlink" title="2019.3.2"></a>2019.3.2</h3><p>看了一些对微电阻成像图像的应用，发现人们会根据有数据部分的图像来推测没有数据的部分，通常使用曲线的先验来判断的，如下：<br><img src="/images/ictproject/电阻率图像.png" alt=""><br>也就是说我们可以对数据进行标注，然后加入一下曲线先验信息等，然后采用深度学习的方法来做。</p><p>专业人员可以从电阻率的分布曲线看出岩石的类型，如下图，因此可以认为电阻率在空间分布上是存在一定的规律的。是不是可以找一个指标来表示这种分布？<br><img src="/images/ictproject/中砂岩.png" alt=""></p><hr>]]></content>
      
      
      <categories>
          
          <category> 项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux操作及远程服务器访问</title>
      <link href="/2019/03/02/linux%E6%93%8D%E4%BD%9C%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE/"/>
      <url>/2019/03/02/linux%E6%93%8D%E4%BD%9C%E5%8F%8A%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX19BQHW8XCRQyLug4sCcv33F1/S0R4wO0TZSyJeUuHciuN1srS9iaWL5tCwURU7TFLG6Z/d/WaWoGcU1+kbsNaqGUfUwP9KTdZX+lYBvS9N95OIqYnpVeYjvdmx4U7rNNHbvlhgflWc2efAxx2Kj0JMtSTaTNZ/CAPx/mQnhsD2PClh3OrtIfIpZoxtBJtys9lPzYlCNNu2ITyD8Ju45jmhLNDMP6jEZGTbpe3Q4KaU4oCQ2QsTISbKyBO5LLkW404e2wr9rrjYqLSCWqfAd0ZfekYaTD9RQAwvEBGNdc4zdlcHFYs8NwldeYZnmzCJlVIEaa0/9NtPYF9n8fjXjfofDJjzNFzMna/j6pn3LPANU76l42CUjylOLWhyCrZ+3NMoARrpme6vBudwaON/SIxQ8civWu725zC132Gm4/gY1+fcDjzow+3ZXtQYetLrwT7RUBI6a38vtyddu1JD9VwoMhrpmkji++OLUfTV70FLAfYoIZhESD9+STkZSqpL0tA/TxbjS0/rFLsBUWnf+jDmEFqdE9FDIlKj9MGARuaT5xpHTb6egRB6LQqdMLmWdOyjQ7AA+j168cc+IoTvJeiZZbUIlpeKlL9vify6yyXImWLs6gq6KUG4kt/jCxYfJy8n5ariG74mQcjbmnab+8banj94bheZR1XSOpBCtHShsURqNjNqWWNl4pNFK2NEqGMmyjA7je5F1hsOMeGDW2lOm3b1bcgVUZVU3Jh90OXo9zMQ3PfSb66UUBOsNFNitBeSNwCi4pQ+cYm7uCUkF7/J6AN5daA0vRzrojAGzM+P6xNrnk5NFweLgk9ALlmNyJA4eUxTLZwK6zMQF+nXr9GOLCQVuV/BCNaWW86lZqX3JHF2O7+Fptm3xnOK68CvOkXm9TUlWdh0k803O4uVxQ1VPeuI+86CCoCv9rmcSpAbDV/1sz6hAV/a0viIqphjGVk4s1feYfvCi+9RL74VvkRmt48zC51SxS5w9sy3BVhE0rUESBX6DduvHB6RmvbmEWzzoF0tLP1RQbrRXXOGfW2hngkbYCIwROmIZcGr3wtsZtpfKJtS6mz0vdTdDREoiLbEbypF182jJm0jTOS9kloq5DNairG9rjOLAnlPEV7gw9ci3cJl4ImZxt1/leRvZpK7kQcCjYhlsOxdcEH0K9fiKl02+jxTRx+Ay6T5HbitZNZL2TT5MFJFvIFT4wW8XdEaPo1Ucpk74fHArXNLqlVf++L0mKCJTbXPcfFHE9fBvk18TE0z9lYCIUA1s9+ZyeoWt4NtRmoQvS9ML18L4GrdrCGGruZmpC8xdwjUcCdTQsmbTtU+uWrjjsRGAmdInJvaO7hWA/jr7Qa1M7jxBCo56ldPLkC82dN+KL5Ql63tIEijDnWjCUpe1BF772gicXGKg6USpvo62N2baascIixnc/x3UPsP0PCcIR9YftbUnV7rVNnRbTVjMGWAvvJtjeK0M56qb3T5dMPLR8My0b6OniZ5W0UFWy3vlxI9OBf+vtrdGe2W/dS1qVeHDFrOaKLxbdg++cgjiu5Lj0dJYhgCWWgaRm6h1HHiNPy/9o22jqDc/yY9RCzEdeafHlumHegrYtda2IoX0LdMs/1JpHeWQksJ8nEhdBemX+D29M9Nq1/XRbSqjg6j7LWsnXe11NeVtGe3aeJq56AiMltWnr89FYHrwpSi7NoDxXHdrTFOM4RhIw4YF1YDXzTbJiUbdjXx9H/chyQmOk/RCxViYNaNryU4HFnJFnVKG1fSxYu5Foq19zZ0LTSfYCAOwequ/4eAV82aJPurvkLb3DYTDk34Xx12GRLyATXWe36Q8er5HpBEVGAmGHJiujnlO8h3ZBv/vrOFEGdekIL4POnVtThWWnt1/HEqEIi1GRs6WtoIl19WVvA9Bp/Bz0dtT3sjQQftiGVy48Dy19LtAJ8ZK5R2gbmhJkPWpYAJfhXsYz9QspPvUkdLc1X+PPCFdjNBUiG+0q9PfOIxnHUi+ChZNcYCFQk9DEyzvuWPscHdN2hl4m9j5ct1JQl+7MvcNm9W2Qwy2E6EgVjaJlHf5SuLIUsS+x9lRhACOufLtrXbhNo+Be+Kv/jp9a1q2CaGiYG7xe9tzvmzhqpkckk/vatIjEOjhFpSqEJCagLvDmg+BuBYHsbURql/nAKbDPz6ZKJAjLNeLOVtgsewdIz6A3za2AeMICCe/EDXt/IUCXIqnXQfsNGIvuhxerUma86gHWjku1pzP9djDdwCqlaPRgQcvS177sb+EQaCK8NqOcuyhxnqbhIj2EdIYCspNMepdyijebW7Nx4aalYnkus5NwYNJYd+C54/utYH0vJaI08EGFaAb6l/S7a2OeHunUckCRV6E6yFrB06beChIqMuLR1ZXJSHcg06fBaldp8LqYv55d9lKfIPgwF+XPSpI1OOnznuEbiXEwGhWaZ/MLLAmJ0J0mzDxW98W8XJCMRMgt8WgbG1R8//FapAhEXq/IuM3QbDtGIxzB5N3/xFzO9h39deJNhl1SjRZFPpO1Z26Hs+Zosp4q2PUtR90DjFsYkMnzi5YgRe8VnY6k9/LSuf3js9ot3TclCLJPbstkkDaTNVPdJoly4dp8kwFXVdEPMAyDIlrNubS5MvodvbMjzlAoEtBY87Pdhn27BnIn6qwR3NP0OT9vE7KeV+sBxHg3RTtDYk48MVLlrm2cfU4XmFxhpYwh+MtD6dPiU9Uy3O/0HMzFWeJ6tLhO/rXUGfv04o6NiGqYLH6xdMyhdMkEzHHuJdmNFthxixQMYevr39CwxTwbY/GtoTXHjQ9mR4kJWPJ7cuibzBAbUGu7uU2Vl1CRDiRzLCtziFJZMQmf3vGS7/uX3mhyzHSYgmyAkeru8JVXxdvnyX33LOwbpPcifZ32hSWVSByquMShlMH7PZWeDIq49ami+COeUckEdLojyuqvf6/t4nJQL713Whg+kh3hk/an3oa7Ad1Qej1sZHTIhuw1Bqo904NKf46ZqNwIszBZ+eRjoRfXlv/lVEIWA3DXydX9XAEejlQD/YAf1rA9FvYy/xsxuVrJ8F5URxDIWU+/C9LlY9YZe+IZ7STUiJnqRUby1DgsuwVRV0RW4DgwzLzMDtUIpccZTfySpAmLbuuswnEyk6mUOnaCDuHo41SsLmsnlbNdepWWIvoq3ir6tK8jQn21QpxFpXtZsieJUjmDqAbSdEzTmZcJ1R6gJ4G7ll+fiW7hK89CKRbqNovHRBG7b6+/joWFHCHmgjGP0M/71QiyeBOFq4wIHT3Ymq7FCmlOtNO0pMEe8CLTJcFJP3O/Fgp3VOjW52GqrtkPIzfo4ex3sso7hmDkd7fpICH/dVLxkQP1eRlmYTDDnjbWXCy8A782/ZN/c2HQnjhczqFtvGwLw4V95Hyck/mMUsYCmk4fusr6pcXb8ZUBwuYqWhVpgjkdv52aELR++0nefu1Pf3s7owrt4n449jYRjdzzLKYIJJP5PVtM2utQ8tW4qcw2KeV679vSuUpkNovZO1ZXCBrdDoYJTPl2LxpVO0+62i7NfLBcDcjS4RFUHQQn57Qj1s0Ynujvxtg5Ykz1wv4Y1vKfc5lajBeOJ7X6uOJpUvuTUwKfQQ6dEviR6LPxpDamo4P2z0c2tTENq26Dg2TXzuN0ny11NvqrFvxch2rtL7PeKrb5SB0piYuXwjNoPhR234xrD06/0zJaWY8SzP7n0OFyHYPq/lcP1cjLibgif8HA0eDcK2C/RSQxZJYJD2x26+9m31ysjdclmGwXS+qXXQd9fC/Io5wwxORDx0b9a2QAEKjcU2wVtZ+b1LOfeFvtStf/UjaKrZpwNwPuhKxuCN/MaUJpm6/Ec6Gu+g8ixpjI4qpbKWuu6Qll/2xJGe0sqIXpefbhsP8OOtbvdRPg2U0E9/ql4Uy9Gj0OuU/ckGHnXwY9XSeb23Z8jB13urOM+cdcD9+a25OqTrBRHE+WaWQy0OUdqfba0Xa7vFBTjxWS2cCu6Wz9c8+b+1cXeDFubbB8/iZVAsncNBnJsvOtT49LG4bvdBPEY7FNyDqbceWrPTdeRj3QNyjG+LDQExHZNzWY74jmz9n4mqKLxwqWRIFcNBw0RZPQYCazgxKlOcKzb0BVuOZO/DISJVlKujfeF9gEE7/maMYYDQPxrLPG6gJz5gw5GYhuGJDZCm4Pb85LQolyQJM8ww9vOzyH+ncEAX1J+3cAJVB1dji46jEYFtHMF/9RVBue5eEk4mkvWgAiyxJFPcbiD1OvqTeqU4Iz9h3xZHA6Y3+1SOn3fH4HRhDQ8iB7tPbiz4tOHLAy5219zczTc3H/8ARPSt1gk6jJ6wGdnuRlng/JepuOcCu3fY/FNFz2sC23OehjGOhvfvpDoQOOcrbp0EGIE896ad89zI6S4ZcXuRq7j+/rLRGx9u/8quGy/2i/QFg9vxd8Ai04J2E6bc3yXI8MZfcmfyLl+pJV6AUhHEnqaluzs89UZ+fonlEODK+mRod0pWRVTyZJvnxZ2/pYkto9+YP9brp1BGHRvuFgySN5ldLxpAVXS6r2Dq4wfDlSSBlwal28Kt7DZcIY6utwC1kwIzOLVMXA1NFvC1Sq1YWboShf2Xioj1FaTgwDNlIL2qDq4Y/cTwcnSKC8BHRNlNr2IzSdbnXCZ33/CPmaBUQuWairIIiH12DElU8N7vEv2dc1oIeXlfipZq1nfNhcaZOlbS+pVUC7xy4tQlP2+Iv6COfnQsS9STpd7b+oBtNRrGEqUsSXKE8IEucZMAf3MCyhomll4IaC3UP+9SfqgfANNDlCzg0umJA46dj7rVyLiMpBO0kQgmwKmrRKuTVgGs7y15s3KEhFJUyH7viBXOGNjEiANKXTxwbjU9WPgZt0YQTpZ3pbNKdmJHzeL0zhAIafOf/21ayWpzdMCUVGfYz8vRGrr929chpkMxow0zt4jVafF370PAVFE4FrZz+1+9d0nwsMjw50pV1eNpgSxZgNU3xDJrai7Y01bwJWmow/3MAi2LqoVen05Est3XTQ5VNwE9NvJIVd+DKfgdVmdfzjeoAN4lCO6abyQR7/1Bf/HfIf24h/9Z+WouKMiHsGd5Jw/SzEEJB/YxuWMgAths/fT/FirOD3O4681a/Cbf5MsaExXL4uL6CwTQx+bNPzHqDLeQWD6sEhfJYKFoMG/DIOW2PZOogztaN799lMWDbVRLp3NwkzDCMtPtaRahsegdk0QPcVtHZH320On4TV8exo/9UZRVTk5B1586CYq7xObSNifGS6GxaPLDtDYyw9aCsraRY675qkHfboF1dWQgLdvzS2Y6DnKH+FFsd5X2q6Wpqu/FcJsvBsX8lW/kRMI0+C8LqBQ2wvXeGugWJGKaloWqi4MVKt+DEdx1OxIEMMOTPXIBDdjrT3gcSahNz3DP4FqQXLSpoh1P7q9wdGTVpYmz0qrCC6mFmCbsAAUGgnFDxwqYLn4Q+K3AYiksz+7epuEGi5BmZfg4AhjEPpx3WR6wWT4O6BnykWvbG/I17TWQy39Xg9uaMiFR2SxFUgCVfIFHbOCAlmthxCQAJJlRkd8dl7XgVPWnnjF0FCI7bG2kIPIpXqsi0W4Pt2aSxlDfIVz6b4TmmdZ2jjlMWg04rXc5xFVy0tvmea7dm7vjWrZt9+wUvHXWuz7MKUYMoriN5E78Mu2iHXuXl8WzmVVfuzOnxryMQ1H/iwzf1V+MXPIKFOutiKDb7+ns0T8LGEjhXwmRVIe08fNznrT/w/9SiBPZhJFRUT/+JOezLMoC437h4capCV6Z3HqUHlXYVrX+LIi9VZ2mDAFOxgaAx/NYVciWgzIy+oMlegoyTPXFZT/rwZKsRYRvATqu9UXacmH/RPtMIyIVcaA/QIODNMjCSJ1bAp96KEFt/zkKamyuTr8UoRZcCsLfyY6NxdrWPm4fWP3jXUC52nKvGWu+eafe6raUreNnUaZ/vAgypPyZgdNyBG7V0ve2IEBrwVnn900MBFC9miZQK4tTf5D2NteW0CpuHGCnd6gHOyRT87QbUxQVfyPymRxyDCHMwIRbyFJn2Whsd5uyOCcGT/wivCtGjmT02BTdOuJogAZzmm/nIm12PgQxnjvCWdUiqaCYf911IkbTI+u91HnLJZ7RAMsrV4vmI0cZkeL3kLj3K2QzhTJTr5CntA6JHb0U9uunR1a2aJn7Iy9dC3fnUTjSoBXAixy8QKwXTqxq/4LEAKxf3qUGZiqPV4KgcsoDR8nI5mKOrx7CpDWeUXcT/ZLMuVy7TC05tDDGgvlK56iG1iGDrc/BVmwAudkeGVpK5UFeItwb3oje+HDBflu0qGfAasIdEjW4y1UX7Afoac71qnIauAsYYGenfuszh5yp+1VhPbHIDxWklF3v/wl9/WAjQixrv9ixeTwhLDNi63QMqmjwfEJw6fzkyAsrlR2jL7H9R5vIRSWm1/bnf+B4F8UBfbHQvOrCpRhtVPa8NiZ00j6VVY9VsZmslQn2PbAvy5NQ1aXg0uS8yL41EC+1ookDWA+WxqxLUMUJWoSHLZ3NhzjvjitZTgP45sam4jhvOD/g2j6G8nwdVv3ztko57udL4T1zUsZKvW3i3X4809qdsz5wrEqLckp2+Z9TEK2dInkf1yNydqR+yxnkACLEG7Xw3LkiGV5gGBXff84aFB+uO3a0VYMGWsPuy2U3U45j96RJHAlb4P+U7WpND46PLyM+2fITbILa0yRA3Wyw7l59952OerVglz9j2nWh+SRevHl03Ay7slFbXaddAe1ST1IzWTEYVFbVoshE98W+ERxTU28zbgrtq4tMXWseAUCyYrp/AH+lhNX/GL+67k9H3jYTEqwZowH6/Y96Qx3dLksWeu+pKGq8W2C+yt370I7IqIp7sxCkcXMwx5ZOo+boeR0D1D/9oY7+6f9EYlG+u/okne2LYUshZZsiJfz/fhQ4TWQHauFVG3pQIZ5PTlDulTbMuxSzowHdVakYyp45MGOiCYEMye+Yzhll2bLUxo2Wpr2QOV0hbETsXy/fJhl0yHlSMy+Zvq9KmI5+sHnGGsx/uCotq/mCKjmJVhIeDmUW0THCUp8qfMsQ3AWmcS5Ew0aDLTDtFkWhYsQ1aLBGYde9WJVFk7t5gnKwBIyBNfA5/5tRUy6tIiOqZGlY/PrPMeL7exa75vr+FNhvT1cEu8txj0RRX9YNdlYI8uSHL3nWI0j1EozyPLy1erN+suzQlI2u0RXGp8IBUtyHFMivNzj7JK38cm5qz5eaI+QnzKHZ/e+ISgw+CLftJetZanbtCDIzBAHCwiYul9QawKQiVI13wYRiG5hQNC5+JmLTQLjD5O401RpAClpQy7ndSHk0OUnN8m4fAGnwwFsH7PGRKQQuiizKlRe00GBRccBuqxQb2hHMOS6VJM0hYyWOH0znLMIsApLJThmT2+im5mEYl3wQ+nd1fHVgo7KQeVUYSjWq0ZdPSATAYfVF9EA4HVF0L2YTN6tXAH+zMA/G4qHkUDnlrMCc0W2SJESyYXq/3Eyjmwj4n3tOQCV7OC2x5K6/voZmVl3T/vWTHTIU/Q0A2APtxRWcqVsDYxPDs3XgOPDMjHChofCvtpDKLSQ5VuceAbXuctPYXQPu/ZfbHrSt/mS+WU2OxSahuh1PEIHFQZiMpker+vDRGaevZyhExNsPd4aCqRyBlGJun8kja6BMHGX+bN2nPIis2c4bgUuXWyg+9PxRZrzkGRLfJ41znbxMXhNH0HH1o2DOXP2ZYvvyiW6OYwT0v2uRGVGJu2rMY1ZRbTJZ44CCKOB+pJkFllvYIjsxKgDHUf99/zXtCrVbTa/wd24azHjna7hUCNSAkpcsdFU7ySxjw6voq7Sv2Mb6kBlJ90Jzmsum6tsblAdOvOapX0SWtXiwnddtvy6/mDDFO2nuU+gGTbtjPObDOgaK3XFKeYCmg+jCkbtxwgJ1H4Ida3uhmbAfeukgvK6sLQSeS+/zvQ1D+f7tq0ObaPHnLBEEfPh0AsYxYjZ5qOTjQYzzCWEov0K7Q2aVLD5TqMmBqZg85WvlOWOuoMuWFPVscLxr3fluQPRgzl7XA59GVaJ2H/ZK0fVWMkJM0gyXCA/h23sfd6dkaB6fU2yWyPl5jZlRoKuoaB5Oz+K+HyPqqndio38jaGIyefPb2B8OoM/4nTxdE8heF9AnBhYEAnh8pAGpk/Q5n/r2h36NlPBijHN+8RtGEzXilmtJYOb25I1g1At6rv9EpQY0YxCyrmPHS8HOi3NWxYN7ic1r8vo1m/iflySrwK5/pzLVBG540aLObAiNDFj01Dnd7ZzDQL7HjcZjTHZsErxId+iYNuTok7J/w8pjhB8rCx2FsktZztcaVqlzX5gzO/GF4+sncM5ENQwWE/5AFpa6Thdk8xoEBCUbf6cNb70UYqlNOoK1+PsA/R5Sycgjss6wU2mNkZCpdZRFQYjsMQshuJRKuxTLJs6Wsw15U+2cqYfhtC/cKCCdYDQRCNFBGzaIREle220bF5KM3lKU672+SYiT6HLmNkXGNks6yfIzxYipnY2aUMW7keiS6E7j8LCIhjE2qhSh4n4AnWTtO8rjoJ2UkcYT1LgRaaBsbkAuyOoDic8y7pUeCSuvvRn1gNWc7FwY8Av369j+EcESlcHhbyoWHkaEMU3foS7rR/vvAPv0LpUcxVRKJn5nVTyJk/02SuO7C4P5m0erQCQbOP0a/dw2+irUyFevWD8o6MMJqSQuGZKOChxo3rSgWGzwbqV8b0B2Pl/9pY9Z+8MWe56XFkmI+RVVGeQSxf7BO8W96B3Gp2mvn81ghSI01lBT6LGMCpVtRqN4TMLzDW0SFdbyFTctLaPH3AXH5MsaL3Gtr7gtsTAernm+Qglin6bVDwNG7SbauNzwUEjCFeFUXq/6U/MoK3dcr2fteafxWvuHRRgEXc/HCyFor/KdhMdtkg+VrXd6+f9rswtG0oboqwA1eifJUwIYB3xgS7thBFTbrdvUd3kn0INpGZ3Jsb4343t3uwJedzLNidbeTKBWYyp6m/lJqQPAf0NAEKvMgGt5qz6oNknGYuO5By0GE9jjxLLRKIDP4SzExa0igYdBJmpmWoLQEw8WyYWfb868UOqn73MhMI+BHfW+c32QLE2gKNox/TXdPzqOf0tZxVsnEUCsxQj4rZtbY16PxcKGCokoOkaaQzVhUA5Pw+629YsqsEwbH8MUnIDssWRCB0SQAfRM53UvJl7TjM+u1MVhTo4I6ztAeTUSwFLR6uhl7k2B470gu+LJQL+7E8d4XYhnmCI0sjMRKI9VMCDe9N8y7jRB+5S9nikbTKZWjNse6aJQXTfUx2ctAcgWAo9b+85lM//k8kHRQViTyhMO/YBY9oBTRD1Qf7BItQapQHaztqpBIoTrb2RqHTeltFaGsAd0A8+868U00rQgam/4wXEonVNBN0XdCkFEDfWXUaQ0XALMRGiRpghjRln03hqjoYZ+reg8Gwzp2lNqtAFinh/eqNh8S3AIGvqkNf+ShUTcHZ3JiOtRdFjH/trRlGjGpx5W/NwPUrKpVsS8YxeE0jmMc9N4Uyx0uzBVmhgC3gmGHMSzzF7FH6bSXNy9gAEXVNH0YljChx4XruDtGmecoV/LYk4xXHeO/hzku5DVYRQwYBd2+fpxxSxr1QJ+e8gHBhYGB1soeeh6vmXvYs1mWGFeZsQOCmXjhB1cFBemzslzM6L9v4vvjegqv4J5RtJcZA81CTcyE4I/cR5t6ZcdLMUTH4Ep1GO9a3+d/4n0p66Sdo9Y3WXBvpnUR4WFEMsZI6nTUK3mkgvGZRUffNlvIp7JFn6qDJC9zUNCqmK8oFW/Y5TvCZoqw5EdsS81Yqy3YCRPq4Lo6D6Piw3G2t37tPof2Om7jLf3JMcpg5s0UKKBzG/LcpM2bNKeZsvgECS6tuzCTz/cGnCJaGzGysMP3JDp5fmlmyluBQOTHrTDNGE1+rFFsaA8JaxonJTxRa6z125+XvV0t/fPOoL6LcHiptiZb0QSdQkhgxH4CbBFEXVhT3cxe4UFcaoFyviTIQMSgaDl7Hfo1NcDeAaYueW6ofpS9iYdf+HJDG9o3jWeDE6vjae3sqjCTLNRbVrLTQ0e5ksEkng4SQPs4TloeLyR+AO0CJ5sK796pyXa6Ujx6vqu3z0qT4kWY6Xiyi6+qgjbAbw5goAVk7BGGEKaGf7fLcqjaZjOirrZ/A52XE3qi3mto7wxezI80wR0X3216FtjWVeMntfV3DLsw/PeYHrCfdrpn8DvDsy8gu6WpXz9nWUooBnhKRwXSGW0+/r+QOICpXre2D2+HUGAqG9R/OlzdfI0CIg/zuX9Ll6unuL6O8UgEEZXTc218QU45wvhPEOu2MBYSFqkI6Pprpb2dikMJnGgo1aGIC1HCwFVXEYgLr7MZ8HTUWp4Q9Tj8b2I+9z8KE9/2geMa5po58UYxz/U/Im5lZrCdIQuz4u85CAnV6i7oox7GsATH5Mk/v4END9WNmsKeoXBQQ6UGj685iIk37b8ajKjbHwZw9Z4BGw69rnEvQjhTkR4P7QqJvtBcOEbt7Qh1dW9GBJWsP7J8nKQOiuMGNe4hQshSipbIjKhxqebjwEmYFhBh6cVmcW+h1g9ACZ7n30gjnR7J4U356i3du/ExEVb+Guv6BePELRlCHNNLMzYJ1tYA7sov9xenydkIfRPVy+eCohWXI+jJMdbAupf1xghDV4MVCTsKljgqgj5pf6PeOZhFMRheL6qlyZ2LYFDCoFUKJne5vdI65GkQAkgiWibND5gNk74rDm4x+mhku//HIfstGq5TV+cwspbvX2Vt8Ate3XHgSfXLLWQsy5b/RLMkPS/rcwk5f4flJsx4BoFGX45TNaWRyG+fL3GP/NMp7Hn7OCYV1dPjw8mGtiNNQMUi2ZNbe5x2BhJQyVsfT0IMiiF7YpBn/xStVG0Z37IYtMfxS3KUChcnERH9d+Dwn6CZgC+psgC30lHddff6w9/wdmPk1C7Sj5w3VyqDat8i235v0CI2Yn3MRjci7rTsHbj66V6vyNgjJPB2r8XZtMwg0OnJK9rLOCR8HtJ3YAdCDY1EDOsAjRVTgvpwADEQ+L17643HV80iVDw40G/qIIIHKNuEnk1pI9Sl2we9CBUc8iFZ2pfEjpQbefIE+w8PTvt161qfBWptXXaIDoodGFZvcXfKMGXmI5kWK7NApILIUXcmCakOC2ai4s37jHY5ZPlUQv+oeMyhX/628BGlXCyddiZntnHnGlK+2QXVatPePQAUCB3nZa7HCsvEVxn4IhrrR3ANyjshV46dg78wYX8MM+Zy+NP37HU6QKE3npXBU0kf/bk7zouZz5SydSHj7HcTRcldQBwpo66LOaIYWDadUhSDYbtp22iOoVRg5mhKdRuRn4rdtzN3Y0VE+2bXEXWvWqsdwZm58jCRvv80YoPpHRMPSELuByx+vJ0755T+le6Y5p+vOQ/VvjZT1lXYK4PyBA8u+PqfxNK/CVnSeGzztzZ9WgfomhtaMy53BNrtoOwVC4VQqzzUnuW9S9LOrNtUnWsHta+325YcS3+KT20oXO6e8qkSfYTWT2GQvJtcSLiLs7e4N04D++YGuZKT8UwdUpINQSbxyY/7SYjQ8gyjFzsrk1pC5IbockPgX0nrZL1JKsTSUKu4JNpcZ/FrawwsgX0x5nO6X6/6PYNppiRWH7yeG31d3iJ5Rfdq2a7L7uGEvDkSqAz4IJBAcDXoRYb2KIhv/iS+lfyNtzyRcnM1975LRVFrG4FX62rkg2T/hoQ7Wa/f8OkSu/BV4wd4mDFilx6D5v0Jhxhzky9l5U4YVSJvFHIraQexuyYsQvu8dGPU3gIvp3PMDCspSuG1ZluGs9XS9l/P/V7TlZLvWo3JfbBBTCvay1w6ZAgYoyS4QA4grMvoYTutR7ydGxI6caFRHwH+YlIB3nQUNRB9SwXIWR7KA73S0q1OGvoH3ijtDPLWpbQAyhWxHrbcfa8/SMO8N/sewkeP0uK/Z4BZSKGZxts1v6vSLQrvUK5ybPP7YI6FQAGoJWEGa1YenxqCROYb6oeZoKMRKEcQJISqFIleFjtRVhIk+9Zw39zzf9lFtfySyvG2nUtypxdYRXJp1StHPxkDMSV2xiC3O+TIcgpj7VXVP5m92aRv3SBlaOfI0bXe3zmQl4PamzgTA59bXQ9qfnRIWZQzikT1vOQyZMJ7J447u9AvXxg44R8TqzgLbuhyGykeareDhNanvSqnsDHRzFtZF7wK6j/tKSdx9gWMTNpRfXj7OOgh4jGwx5GgebP2Gb99e7EUzhukVLJrYKuSPI+44AW3QCi5hpDy4ZqNL7vdyzO2CNFUiV3AymAVxySNQoykc6b8XFKQ9jecpzJcUQ==</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRGAN 详解</title>
      <link href="/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/03/01/SRGAN-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="SRGAN"><a href="#SRGAN" class="headerlink" title="SRGAN"></a>SRGAN</h3><p>SRGAN是一个这篇文章将生成对抗学习用于基于单幅图像的高分辨重建，不同于传统的CNN的方法，SRGAN得到的超分辨率的图片放大四倍之后还是能够体现细节感。</p><blockquote><p>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network<br>submit time:2017<br><a href="https://arxiv.org/abs/1609.04802" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h4 id="SRGAN的作用"><a href="#SRGAN的作用" class="headerlink" title="SRGAN的作用"></a>SRGAN的作用</h4><p>SRGAN目标从一个<strong>低分辨率</strong>的图片中生成它的<strong>高分辨率版本</strong>。</p><p><strong>传统CNN方法：</strong>基于深度学习的高分辨率图像重建已经取得了很好的效果，其方法是通过一系列低分辨率图像和与之对应的高分辨率图像作为训练数据，学习一个从低分辨率图像到高分辨率图像的映射函数。但是当图像的放大倍数在4以上时，很容易使得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为传统的方法使用的代价函数一般是最小均方差（MSE），使得生成的图像有较高的信噪比，但是缺少了高频信息，出现过度平滑的纹理。作者还做了实验，证明并不是信噪比越高超分辨率效果越好。<br><strong>本文的做法：</strong>应当使重建的高分辨率图像与真实的高分辨率图像无论是低层次的像素值上，还是高层次的抽象特征上，和整体概念和风格上，都应当接近。因此在loss部分，SRGAN加上了feature map部分的MSE loss。</p><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/images/ictproject/SRGAN.png" alt=""></p><p><strong>生成网络部分：</strong>SRResnet，由残差结构，BN，PReLU组成，用于实现高分辨率的生成。<br><strong>判别器部分：</strong>由大量卷积层，Leaky ReLU,BN等结构组成，用于判别图像的真实性。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>SGGAN的损失函数由两部分组成：<br><img src="/images/ictproject/SR.png" alt=""><br>content loss，以及adversarial loss组成。<br><strong>content loss：</strong>传统算法使用的是还原图像与GT图像之间的MSE损失，作者为了避免放大后特征过于平滑，认为高层次（features map）也应当相似。因此定义了VGG feature map loss。<br><img src="/images/ictproject/vggMSE.png" alt=""><br>其中$\phi_{i,j}$表示feature map的位置在j-th conv 与i-th Max pooling 中间的部分。即同时对GT与生成的图片提取feature map，然后最小化这两种features map的MSE loss。</p><p><strong>adversarial loss：</strong>对抗网络部分的loss为判别器判别loss，即当生成器生成的图片，判别器认为为真实的图片时，该loss取得最小。<br><img src="/images/ictproject/SRGen.png" alt=""></p><h4 id="SRGAN输入输出以及亮点"><a href="#SRGAN输入输出以及亮点" class="headerlink" title="SRGAN输入输出以及亮点"></a>SRGAN输入输出以及亮点</h4><p><strong>SRGAN的训练数据：</strong><br>GT：为原始高分辨率的图片<br>train data：原始图片经过高斯滤波得到的图片<br>输出：即为最终恢复高分辨率之后的图片</p><p>亮点：</p><ul><li>训练了一个SRResnet，由Resnet生成的一张恢复高分辨率的图片，然后将这张图片与GT传入Vgg网络中，训练一个MSE loss 最小。</li><li>重新设计了Loss，将features map的MSE Loss，与对抗网络的Loss结合。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>这篇文章可以比较好的恢复分辨率低的问题，结合了高层特征Loss以及对抗网络的loss共同作用，得到比较好的还原结果。</p><p>看这篇文章的本意是想要对电阻成像数据进行恢复，这么看来，恢复的前提需要GT，但是数据集中并不存在这部分数据，因此这种方法可能需要进行修改。我觉得一个思路可能可以行得通，首先对电阻成像数据进行切割，然后将切割后的小batch图像作为GT，进行训练，可能可行。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>project two</title>
      <link href="/2019/02/25/project-two/"/>
      <url>/2019/02/25/project-two/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>谈看论文和记笔记</title>
      <link href="/2019/02/23/%E8%B0%88%E7%9C%8B%E8%AE%BA%E6%96%87%E5%92%8C%E8%AE%B0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/02/23/%E8%B0%88%E7%9C%8B%E8%AE%BA%E6%96%87%E5%92%8C%E8%AE%B0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本篇纯属个人体会之谈。</p><h3 id="如何看论文"><a href="#如何看论文" class="headerlink" title="如何看论文"></a>如何看论文</h3><p>这几天看了些论文，遂总结一下看论文的方法。我尝试了很多方法之后觉得下面这种方式比较合适：<br><strong>找论文</strong><br>找论文一般的的途径就是找综述文章，找博客总结类的文章，里头一般就按时间顺序排好列出若干重要的论文，打好基础后专门去看与(🌧️这个表情还蛮可爱)问题相关的文章。<br><strong>看文章</strong></p><ul><li>下载文章后，网上找翻译，对照着翻译大致通读一遍文章</li><li>通读完文章之后，上网找对该文章总结的博客，越多越好</li><li>结合自己的认识，参考博客总结一下文章内容，尝试复述</li></ul><h3 id="如何总结文章"><a href="#如何总结文章" class="headerlink" title="如何总结文章"></a>如何总结文章</h3><p>上次看到一个博客里头关于文章的总结结构十分的好，值得借鉴一下：</p><ol><li>这个网络是用来干什么用的，有什么好的特点, <strong>网络的背景及作用</strong></li><li>然后直接搬出代码，讲这个网络的网络结构，简直一目了然，<strong>网络结构</strong></li><li>讲一下结构中特殊的部分，以及好处，<strong>网络的亮点</strong></li><li>第三部分讲损失函数，这个也很精彩，因为一个网络知道他的网络结构和损失函数就了解的差不多了，<strong>损失函数</strong></li><li>第四部分讲测试的输入输出，讲清楚就知道怎么用的，<strong>网络输入与输出</strong></li><li>最后做了一下总结，清晰易懂 ，<strong>总结</strong></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN系列论文</title>
      <link href="/2019/02/23/GAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87/"/>
      <url>/2019/02/23/GAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h3 id="GAN系列论文"><a href="#GAN系列论文" class="headerlink" title="GAN系列论文"></a>GAN系列论文</h3><h3 id="Generative-Adversarial-Networks-GAN"><a href="#Generative-Adversarial-Networks-GAN" class="headerlink" title="Generative Adversarial Networks(GAN)"></a>Generative Adversarial Networks(GAN)</h3><blockquote><p>Generative Adversarial Networks<br>submit time: 2014<br><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">arxiv link</a></p></blockquote><p>生成对抗网络中含有两个模型（均由多层感知机实现）：</p><ul><li>生成模型G：用来将<strong>随机样本映射到真实数据分布</strong></li><li>判别模型D用来<strong>估计样本来自真实样本的概率</strong></li></ul><p>G的训练目标是最大化D产生错误的概率，D训练的目标是最大化真实样本的判别概率。相当于一个极小化极大的双方博弈过程。<br><img src="/images/resume/gan.jpg" alt=""><br>以上是模型的结构图，生成器的输入一个随机分布的数据，判别器输入的是真实样本和生成的数据，做一个二分类，最后通过一个sigmoid函数输出样本的概率。</p><p>训练D来最大化分配正确标签的概率即$\log(D(x))$.我们同时训练G来最小化$\log(1−D(G(z)))$。换句话说，D和G的训练是关于值函数$V(G,D)$的极小化极大的二人博弈问题：<br>$$<br>\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x)]+E_{z∼pz(z)}[log(1−D(G(z)))].<br>$$</p><ul><li>$Pdata(x)$：真实数据的分布；<br>$x$：真实数据；<br>$P(Z)$：生成数据的分布；<br>$Z$：生成的数据；<br>$G(Z)$：生成器网络；<br>$D(X)$：判别器网络。</li></ul><h4 id="GAN的训练过程"><a href="#GAN的训练过程" class="headerlink" title="GAN的训练过程"></a>GAN的训练过程</h4><p>首先对具体的问题定义出生成器和判别器（多层的感知机）。<br><strong>1. 训练判别器（discriminator）</strong><br><img src="/images/resume/train_discrimintor.png" alt=""><br>如上图，判别器的优化目标是上式两项期望和最大。输入为真实数据和生成的数据。由于log函数是一个增函数，他的形状如下：<br><img src="/images/resume/log.png" alt=""><br>因此当判别器将真实数据判错时，第一项得到的D(x)的值将小于1，当判别器将生成数据判断成真实数据时，第二项的1 - D(G(x))将小于1。由上式可知由于错判将会导致上式的期望接近无穷小。因此最大化这个式子（等于0表示完美的判别），可以使得判别器尽可能对数据正确判别。<br><strong>1. 训练生成器（generator）</strong><br><img src="/images/resume/train_generator.png" alt=""><br>生成器的目标是最小化上图中的式子。由于第二个式子在优化的时候能够提供很大的梯度，使得算法快速收敛，因此通常使用第二个式子作为生成器的目标函数。式子含义十分明显，就是使得G(x)生成的数据分布与真实数据分布无限接近，D(x) = 1时，函数取得最大值。<br>整个训练过程如下图所示，判别器和生成器交替优化训练：<br><img src="/images/resume/total.png" alt=""><br><strong>全局最优解：</strong><br>不断迭代上式，上诉方程最终会收敛到一个全局最优解。<br>首先固定G，优化D，得到D的全局最有解为：<br>$$<br>D(x) = \frac{P_{data}(x)}{P_{data}(x) + P_g(x)}<br>$$<br>上式可以通过对目标方程求导得到。将上式带入到目标方程里去最优化G的结果，最终我们将得到如下方程：<br><img src="/images/resume/CG.png" alt=""><br>即两个KL散度减去log(4)，由于KL散度的值大于等于0，当且仅当：$P_z(z) = P_{g}(x)$时，该方程取得最小值-log(4)。<br>我们知道，当固定D去优化G时，优化的最优结果应为生成的数据分布与真实分布相同：<br>$$P_z(z) = P_{g}(x)$$<br>上式恰好等于D(x)最优条件下，G(x)的最优结果，因此通过迭代的方式去优化GAN的目标函数能够同时得到最优的生成模型和判别模型，并使得生成的数据与原始数据尽可能的相似。<br>（具体的式子推导过程可参考论文）。<br>因此判别器D(x)的全局最优解为：<br>$$<br>D(x) = \frac{1}{2}<br>$$<br><strong>例子：</strong><br><img src="/images/resume/aganstructure.png" alt=""><br><img src="/images/resume/GANexample.png" alt=""></p><h3 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h3><p>由于单纯的GAN的生成器太过自由了，对于较大的图片，较多的pixel的情形，基于简单 GAN 的方式就不太可控。于是Conditional Generative Adversarial Networks提出了条件型的生成对抗网络，通过给GAN中的G和D增加一些条件性的约束，来解决训练太自由的问题。</p><p>在生成模型（G）和判别模型（D）的建模中均引入了条件变量y，这里y可以是label，可以是tags，可以是来自不同模态是数据，甚至可以是一张图片。</p><p>$$<br>\min_G \max_D V(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].<br>$$</p><ul><li>在生成器模型中，条件变量y实际上是作为一个额外的输入层（additional input layer），它与生成器的噪声输入p(z)组合形成了一个联合的隐层表达；</li><li>在判别器模型中，y与真实数据x共同作为输入，并输入到一个判别函数当中。<br><img src="/images/resume/conditionalGAN.png" alt=""></li></ul><p><strong>常见的输入结构如下：</strong></p><p><img src="/images/resume/condstructure1.png" alt=""><br><img src="/images/resume/condstructure2.png" alt=""></p><p><strong>模型的训练过程：</strong><br><img src="/images/resume/condtrain.png" alt=""></p><p><strong>论文中作者使用的例子：</strong><br>在MNIST数据集的实验中，对于生成器模型，将label的one-hot编码与100维的均匀分布的噪声输入融合起来作为输入，输出是784维的生成数据，与数据集28*28的维度一致。对于判别器模型，作者使用了一个maxout的激活层连接输入数据（与生成器输入相同），随后将maxout与判别器相连。</p><h3 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h3><blockquote><p>Image-to-Image Translation with Conditional Adversarial Networks<br>submit time: 2016<br><a href="https://arxiv.org/pdf/1611.07004v1.pdf" target="_blank" rel="noopener">arxiv link</a></p></blockquote><h3 id="pix2pix网络的主要作用及特点"><a href="#pix2pix网络的主要作用及特点" class="headerlink" title="pix2pix网络的主要作用及特点"></a>pix2pix网络的主要作用及特点</h3><p>pix2pix是一个基于CGAN改造的一个做图像变换的网络，在CGAN的基础上修改了生成器G的网络结构，及判别器D网络的网络结构。同时引入一个生成图片与样本间的L1 loss增强生成图片的低频信息。</p><h3 id="pix2pix-网络结构"><a href="#pix2pix-网络结构" class="headerlink" title="pix2pix 网络结构"></a>pix2pix 网络结构</h3><p>以下网络结构都是用了<code>conv-BatchNorm-ReLu</code>的单元结构。<br><strong>生成器G(X)的网络结构：</strong><br>生成器的网络结构是U-Net结构，即encoder-decoder加上skip layer的类型<br><img src="/images/resume/unet.png" alt=""><br>这种结构在输入与输出之间共享图片底层的信息，有利于图片细节的还原。<br>具体每一层的尺寸看代码注释：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">encoder_1: [batch, 256, 256, in_channels] =&gt; [batch, 128, 128, ngf]</span><br><span class="line">encoder_2: [batch, 128, 128, ngf] =&gt; [batch, 64, 64, ngf * 2]</span><br><span class="line">encoder_3: [batch, 64, 64, ngf * 2] =&gt; [batch, 32, 32, ngf * 4]</span><br><span class="line">encoder_4: [batch, 32, 32, ngf * 4] =&gt; [batch, 16, 16, ngf * 8]</span><br><span class="line">encoder_5: [batch, 16, 16, ngf * 8] =&gt; [batch, 8, 8, ngf * 8]</span><br><span class="line">encoder_6: [batch, 8, 8, ngf * 8] =&gt; [batch, 4, 4, ngf * 8]</span><br><span class="line">encoder_7: [batch, 4, 4, ngf * 8] =&gt; [batch, 2, 2, ngf * 8]</span><br><span class="line">encoder_8: [batch, 2, 2, ngf * 8] =&gt; [batch, 1, 1, ngf * 8]</span><br><span class="line"></span><br><span class="line">decoder_8: [batch, 1, 1, ngf * 8] =&gt; [batch, 2, 2, ngf * 8 * 2]</span><br><span class="line">decoder_7: [batch, 2, 2, ngf * 8 * 2] =&gt; [batch, 4, 4, ngf * 8 * 2]</span><br><span class="line">decoder_6: [batch, 4, 4, ngf * 8 * 2] =&gt; [batch, 8, 8, ngf * 8 * 2]</span><br><span class="line">decoder_5: [batch, 8, 8, ngf * 8 * 2] =&gt; [batch, 16, 16, ngf * 8 * 2]</span><br><span class="line">decoder_4: [batch, 16, 16, ngf * 8 * 2] =&gt; [batch, 32, 32, ngf * 4 * 2]</span><br><span class="line">decoder_3: [batch, 32, 32, ngf * 4 * 2] =&gt; [batch, 64, 64, ngf * 2 * 2]</span><br><span class="line">decoder_2: [batch, 64, 64, ngf * 2 * 2] =&gt; [batch, 128, 128, ngf * 2]</span><br><span class="line">decoder_1: [batch, 128, 128, ngf * 2] =&gt; [batch, 256, 256, generator_outputs_channels]</span><br></pre></td></tr></table></figure></p><p><strong>判别器的网络结构：</strong><br>判别器为卷积网络，结构如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">layer_1: [batch, 256, 256, in_channels * 2] =&gt; [batch, 128, 128, ndf]</span><br><span class="line">layer_2: [batch, 128, 128, ndf] =&gt; [batch, 64, 64, ndf * 2]</span><br><span class="line">layer_3: [batch, 64, 64, ndf * 2] =&gt; [batch, 32, 32, ndf * 4]</span><br><span class="line">layer_4: [batch, 32, 32, ndf * 4] =&gt; [batch, 31, 31, ndf * 8]</span><br><span class="line">layer_5: [batch, 31, 31, ndf * 8] =&gt; [batch, 30, 30, 1]</span><br></pre></td></tr></table></figure></p><p><strong>网络的总体架构如下：</strong><br><img src="/images/resume/pix2pix.png" alt=""></p><h3 id="pix2pix的出彩的结构："><a href="#pix2pix的出彩的结构：" class="headerlink" title="pix2pix的出彩的结构："></a>pix2pix的出彩的结构：</h3><p><strong>选择PatchGAN进行训练：</strong></p><p>为了能更好得对图像的局部做判断，作者提出patchGAN的结构，也就是说把图像等分成patch，分别判断每个Patch的真假，最后再取平均！PatchGAN可以看成另一种形式的纹理损失或样式损失。在具体实验时，70x70的尺寸比较合适。</p><p><strong>损失函数加入L1 loss：</strong><br>众所周知，用L1和L2 loss重建的图像很模糊，也就是说L1和L2并不能很好的恢复图像的高频部分(图像中的边缘等)，但能较好地恢复图像的<strong>低频部分</strong>(图像中的色块)。</p><p><strong>图片的高低频信息：</strong><br>（1）低频就是颜色缓慢变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，梯度较小的一块区域，这部分就是低频。<br>（2）高频就是相邻区域之间灰度相差很大，这就是变化快，梯度变化明显，即边缘部分，即<strong>高频显示图像边缘。图像的细节</strong>处也就是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。</p><h3 id="pix2pix的损失函数"><a href="#pix2pix的损失函数" class="headerlink" title="pix2pix的损失函数"></a>pix2pix的损失函数</h3><p>pix2pix在CGAN的基础上加上了生成图像与原始图像的L1 loss：<br>$$<br>L_{L1}(G)=E_{y∼p_{data(x,y)},z∼p_z(z)}[‖y−G(x,z)‖_1]<br>$$<br>加入L1 loss增强了生成器对低频部分的还原（颜色变化平缓的部分，色块等等）。因此最总的loss为：</p><p>$$<br>G^∗=\min_G \max_D L_{cGAN}(G,D)+\lambda L_{L1}(G)<br>$$<br>其中：<br>$$<br>\min_G \max_D L_{cGAN}(D,G)=E_{x∼pdata(x)}[\log D(x|y)]+E_{z∼pz(z)}[log(1−D(G(z|y)))].<br>$$</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>由于网络引入L1 loss，同时它是学习一个输入图片到输出图片的位移映射，映射范围十分有限，因此当训练集中不存在输入图片类似的样式时，输出的结果将不可控。</p><h3 id="pix2pix-总结"><a href="#pix2pix-总结" class="headerlink" title="pix2pix 总结"></a>pix2pix 总结</h3><p>pix2pix是cGAN网络出来之后，在图片变化上使用的第一个网络。网络的亮点在于生成器与判别器使用<code>conv-BatchNorm-ReLu</code>单元的U-Net结构，在目标函数上引入L1 loss，使得生成的图片更加的真实。网络训练方便，使用了SGD + adam共同训练，使用了BN，dropout等技术等等。最终结果图如下：<br><img src="/images/resume/result.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>project one</title>
      <link href="/2019/02/22/project-one/"/>
      <url>/2019/02/22/project-one/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>语义分割简要总结</title>
      <link href="/2019/02/22/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/"/>
      <url>/2019/02/22/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="语义分割简要总结"><a href="#语义分割简要总结" class="headerlink" title="语义分割简要总结"></a>语义分割简要总结</h3><p>CNN padding 的方式：</p><ul><li>valid padding：当卷积到边界时，最后边界位置不够卷积则直接舍弃。</li><li>SAME padding：当卷积到边界时，最后边界位置不够卷积则用0补充，保持图片尺寸大小不变。</li></ul><p>视觉未来研究方向：</p><ul><li>三维数据集</li><li>序列数据集</li><li>使用图卷积网络（GCN）对点云进行分割</li><li>上下文知识</li><li>实时分割</li><li>存储空间</li><li>序列数据的时间一致性</li><li>多视角整合</li></ul><h4 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h4><p>FCN之后，CNN网络在语义分割领域引起了人们极大的兴趣。SegNet在FCN的基础上引入了更多的shortcut，它不是直接对不同层的feature map进行融合，而是通过Max pooling的方式传到后面的层中，这种方式能够包含更多的信息。<br><img src="/images/FCN/segnet_architecture.png" alt="segnet_architecture"></p><h4 id="Dilated-Convolutions孔洞卷积"><a href="#Dilated-Convolutions孔洞卷积" class="headerlink" title="Dilated Convolutions孔洞卷积"></a>Dilated Convolutions孔洞卷积</h4><p>在FCN中有两个关键，一个是pooling减小图像尺寸增大感受野，另一个是upsampling扩大图像尺寸。在先减小再增大尺寸的过程中，将会有一些信息损失掉，那么能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？答案就是dilated conv 空洞卷积。<br><img src="/images/FCN/dilated.png" alt="dilated"><br><strong>空洞卷积的一个最大的特点就是可以增大感受野，避免使用pooling。</strong>图中，对于一个7x7的图像patch（a图），只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7<br>(a) 普通卷积，1-dilated convolution，卷积核的感受野为$3 \times 3 = 9$。<br>(b) 扩张卷积，2-dilated convolution，卷积核的感受野为$7 \times 7 = 49$。<br>(c) 扩张卷积，4-dilated convolution，卷积核的感受野为$15 \times 15 = 225$。<br><img src="/images/FCN/dilategif.gif" alt="dilategif"><br>但是由于dilated convolution 存在一些问题：</p><ul><li>kernel 并不连续，也就是并不是所有的 pixel 都用来计算了，因此这里将信息看做 checker-board 的方式会损失信息的连续性。（在还原的标注图片上就会出现一些不连续的小格）</li><li>对于一些尺寸比较小的物体分割效果差。</li></ul><p><strong>解决方案：</strong><br><strong>通向标准化设计：Hybrid Dilated Convolution (HDC)</strong>，图森组的文章对其提出了较好的解决的方法。他们设计了一个称之为 HDC 的设计结构。</p><ul><li>第一个特性是，叠加卷积的 dilation rate 不能有大于1的公约数。比如 [2, 4, 6] 则不是一个好的三层卷积，依然会出现 gridding effect。</li><li>第二个特性是，我们将 dilation rate 设计成 锯齿状结构，例如 [1, 2, 5, 1, 2, 5] 循环结构。</li><li>第三个特性是，我们需要满足这个式子：<br><img src="/images/FCN/tusample.png" alt="tusample"><br>就可以保证对所有的pixel都能够卷积到，同时层次的锯齿结构对小物体也有很好的检测效果。<h3 id="DeepLab-V1："><a href="#DeepLab-V1：" class="headerlink" title="DeepLab V1："></a><strong>DeepLab V1：</strong></h3></li></ul><p>DCNNs的成功得益于<strong>DCNNs定位图像变换（平移等）的内在不变性</strong>, 这一属性能加强它们学习数据的分层抽象能力。不变性非常适用于高级视觉任务（目标检测）。但不利于低级任务，如语义分割，哪些我们需要知道他们精确的位置信息而不是他们的抽象特征。</p><p><strong>DCNN定位图像变换的内在不变性理解：</strong>即对图像进行pooling 降低分辨率提高感受野，尽管图像变得比较模糊，位置信息也不准确，但是不影响网络对物体的识别，但是对于位置信息比较关心的语义分割来说就是一大缺点。</p><p>DCNN在图像标注任务应用上的两大技术障碍:</p><ul><li><strong>信号的降采样，分辨率低：</strong><br> DCNN中多次的max-pooling及downsampling(striding)造成信号分辨率减小, 信息失真比较严重</li><li><strong>空间不灵敏性：</strong><br> DCNN对空间信息不敏感，它可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓</li></ul><h4 id="孔洞卷积："><a href="#孔洞卷积：" class="headerlink" title="孔洞卷积："></a><strong>孔洞卷积：</strong></h4><p>对于<strong>信息降采样，信息丢失</strong>的问题，我们使用’atrous’孔洞卷积，减少pooling的使用，同时扩展感受野，以获得更多的上下文信息。<br><img src="/images/FCN/holeconv.png" alt="holeconv"><br>其中（a）为stride为2的pooling，pooling之后四个神经元的感受野对应为7。（b）中为stride = 1的pooling，四个神经元的感受野为5，虽然保留了更多的信息，但是感受野降低了，信息更加的冗余。（c）中使用stride=1，hole = 2的卷积核，四个神经元的感受野仍然为7，同时保留了更多的信息（features map的分辨率较高）。</p><p><strong>感受野的计算：</strong><br>感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。<br>当已知上一层的感受野计算下一层的感受野时有：<br>$$<br>r = (m-1) <em> stride+ksize<br>$$<br>其中m为上一层的感受野。<br><strong>空洞卷积的感受野计算：</strong><br>dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\</em>3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。</p><h4 id="全连接的CRF（条件随机场）"><a href="#全连接的CRF（条件随机场）" class="headerlink" title="全连接的CRF（条件随机场）"></a>全连接的CRF（条件随机场）</h4><p>DCNN的预测图可以可靠的预测物体的存在与粗略的位置，但不能精确的定位目标的轮廓，其内在的不变性限制了对位置精度的预测<strong>（平移不变性破坏了模型对位置信息的预测）</strong>，<strong>本文使用了全连接的CRF作为后处理操作，通过耦合DCNN的识别能力进一步优化分割的边缘。</strong><br><strong>DenseDRF：</strong><br>对于每一个位置i，如果有观测值$x_i$(该位置的颜色)，标签$y_i$(类别信息)，。以像素为节点，像素与像素之间的关系作为边，就可以构成一个条件随机场，通过观测$x_i$的值来推断对应的类别信息$y_i$。<br><img src="/images/FCN/crf.png" alt="crf"><br>denseCRF的公式如下：<br><img src="/images/FCN/crfformula.png" alt="crfformula"><br>由式子可以看出来，CRF预测像素类别和像素的颜色强度，像素位置有关系，<strong>模型包含耦合相邻节点的能量项，有利于对空间邻近像素进行相同标签的分配。    </strong><br>下图是dilate conv + CRF的组合效果。<br><img src="/images/FCN/convCRF.png" alt="convCRF"></p><h4 id="Deeplab-v2"><a href="#Deeplab-v2" class="headerlink" title="Deeplab v2"></a>Deeplab v2</h4><p>deeplab v2在v1的基础上进行升级，其提出的<strong>ASPP技术来更好地分割多尺度的物体</strong>。通过采用最新的ResNet 图像分类DCNN构建了DeepLab的残差网络变体，实现了<strong>更好的语义分割性能。</strong><br>deeplab v2的特点：</p><ul><li>使用Atrous Convolution 代替原来上采样的方法，能有效地扩大卷积核的视野，增加更多的上下文信息而不增加参数的数量或计算量。 </li><li>提出多孔空间金字塔池化(ASPP)，在多尺度上鲁棒地分割物体。ASPP使用多个采样率和有效视野的滤波器对features map进行多尺度信息提取。 </li><li>第三，通过合并DCNN和概率图模型全连接CRF方法，增强物体边界的定位。</li></ul><p>DCNN应用于语义图像分割中的三个挑战:</p><ol><li><strong>特征分辨率下降问题解决：</strong><br>该问题是由连续DCNN层中的最大池化和下采样(滑动步长)的重复组合引起的。为了克服这一障碍并有效地产生更密集的特征图，<strong>将最后的池化层替换为atrous convolution 层</strong><br><img src="/images/FCN/convcompare.png" alt="convcompare"></li><li><p><strong>多尺度下的物体的存在</strong><br>该问题由于物体的多尺度状态引起的，有些物体太小或者太大无法检测出来。处理这种情况的一个标准方法是向DCNN提供相同图像的重缩放版本，然后聚合特征或分数图，但开销很大。我们的方法：<strong>我们有效地使用具有不同采样率的多个并行的多孔卷积层来实现对特征图的采样，称之为“多孔 space pyramid pooling”(ASPP)技术。</strong>在多个尺度上捕获物体的上下文信息。<br><img src="/images/FCN/spppool.png" alt="spppool"></p></li><li><p><strong>DCNN位移不变性导致对位置定位模糊：</strong><br>一种减轻此问题的方法是当计算最终的分割结果时使用跳跃层(skip-layers)从多个网络层提取特征。我们的方法是：<strong>通过全连接的条件随机场(CRF)来提高模型捕获精细细节的能力。</strong></p></li></ol><p><img src="/images/FCN/deeplap2.png" alt="deeplap2"></p><h4 id="deeplap-v2工作流程"><a href="#deeplap-v2工作流程" class="headerlink" title="deeplap v2工作流程"></a>deeplap v2工作流程</h4><ol><li>将所有全连接的层转换为卷积层</li><li>通过多孔卷积层对conv5输出的features map进行多尺度的特征提取，提高特征分辨率以及感受野，然后送入softmax进行分类。此时产生的features map大小为原图的1/8</li><li>采用双线性插值对features map进行8倍上采样以达到原始图像分辨率</li><li>生成全连接的CRF的输入，优化分割结果 </li></ol><p>值得注意的是：特征图的训练和全连接CRF的训练是分开进行的，先用DCNN生成预测结果图，然后用全连接CRF进行分割结果的优化。<br><img src="/images/FCN/resultCRF.png" alt="resultCRF"><br>上图是DCNN产生的预测图，然后通过1，2，10次的CRF迭代的结果。</p><h4 id="deeplab-v3"><a href="#deeplab-v3" class="headerlink" title="deeplab v3"></a>deeplab v3</h4><p>V3在v2的基础上进行了结构上了一些改进，<br><img src="/images/FCN/deeplabv3.png" alt="deeplabv3"><br>v3，v3+，Xecption这里实在不想在看了，以后有机会回来补充。先留一个flag。可能就是之后几天里某一天吧。state of art 似乎绕不过。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview Summary</title>
      <link href="/2019/02/21/Interview-Summary/"/>
      <url>/2019/02/21/Interview-Summary/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DP动态规划问题</title>
      <link href="/2019/02/21/DP%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/"/>
      <url>/2019/02/21/DP%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="DP动态规划问题"><a href="#DP动态规划问题" class="headerlink" title="DP动态规划问题"></a>DP动态规划问题</h3><p>  动态规划方法常常应用于解决优化问题，通常分析一个问题是否可以用动态规划方法求解可以从以几个方面判断：</p><ol><li>原问题可分，原问题的数据结构(array,tree,graph)可以进行划分。</li><li>原问题有最优子结构。</li><li>原问题的最优解将由一系列的子问题的解组合而成。</li></ol><p>动态规划法的一般<strong>思路</strong>为，通过枚举所有可能的分类策略，来组合成最优解。关键步骤在于找到一个合适的递推公式，将原问题转化为一个多步决策的问题。</p><p> 下面是重点介绍几个DP问题，以及他们的解题过程。 </p><p><strong>矩阵连乘问题：</strong><br> 问题描述：给定n个矩阵 $（A_1,A_2,A_3…..A_n）$，其中$A_i$与$A_{i+1}$是可乘的，i=1,2,…n-1。考察n个矩阵的连乘积 $A_1A_2A_3,….A_n$ 。由于矩阵乘法满足结合律，试提出矩阵连乘积最优计算次序，使得计算量最小。<br><strong>分析：</strong>确定矩阵相乘次序的问题等价于在原始序列上添加括号。通过改变不同位置上的矩阵的计算次序，能够减小矩阵乘法所需要的计算次数。经典的序列划分问题。现在来判断该问题是否可以用动态规划方法来求解：</p><ol><li>原问题是否可分：假设找到一个位置k添加括号能够得到最优解，因此将原问题转化为（1，k）与（k+1，n）两个序列，子问题性质与原问题完全相同，因此问题可分。</li><li>问题的递推公式（最优子结构）： $$ OPT[1,n] = OPT[1,k]+OPT[k+1,n] + p_0p_kp_{n+1} $$</li><li>由于子问题之间不存在相互关系，原问题的最优解由一系列子问题的最优解组成。 </li></ol><p><strong>矩阵连乘问题求解：</strong><br>若使用递归的方法，对原问题进行枚举，枚举每一种加括号的方式，能够得到原问题的解，但是计算量巨大，对这道题来说，他的时间复杂度是：$2^{n-1}$算法框架如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">recursive_matrix_chain(i,j)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> i == j then</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    OPT(i,j) = INF</span><br><span class="line">    <span class="keyword">for</span> k=i to j<span class="number">-1</span>:</span><br><span class="line">        q = recursive_matrix_chain(i,k)+</span><br><span class="line">            recursive_matrix_chain(k+<span class="number">1</span>,j)+</span><br><span class="line">            p[i]*p[k+<span class="number">1</span>]*p[j+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> q&lt;OPT(i,j):</span><br><span class="line">            OPT(i,j) = q</span><br><span class="line">     <span class="keyword">return</span> OPT(i,j)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>memorizing technique：</strong>动态规划法的英文为dynamic programming，programming 这个词最早有tabular这个词演化而来，tabular意为表格，因此DP方法可以直观的理解为动态填表法。动态规划法的一个重要思想就是：<strong>对子问题的结果进行保存。</strong><br>算法框架如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">memorize_matrix_chain(i,j)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> OPT[i,j] != <span class="literal">NULL</span>:  <span class="comment">//如果子问题已经算过了，就可以不用算了</span></span><br><span class="line">        <span class="keyword">return</span> OPT[i,j]</span><br><span class="line">    <span class="keyword">if</span> i == j:            <span class="comment">//递归法的出口</span></span><br><span class="line">        OPT[i,j] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> k = i to j - <span class="number">1</span>:  <span class="comment">//对每一个子问题划分情况进行枚举</span></span><br><span class="line">            q = memorize_matrix_chain(i,k)+</span><br><span class="line">                memorize_matrix_chain(k+<span class="number">1</span>,j)</span><br><span class="line">                + p[i]*p[k+<span class="number">1</span>]*p[j+<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> q &lt; OPT[i,j]:</span><br><span class="line">                OPT[i,j] = q</span><br><span class="line">    <span class="keyword">return</span> OPT[i,j]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该方法的时间复杂度为： $T(n) = O(n^3)$ ，动态规划问题的时间复杂度计算方法为：子问题的个数子问题的时间，对于本题： $O(n^2)n = O(n^3) $<br>一种更快的实现方法，从底往上计算省略递归步骤。 具体思路是：先将分割的长度由2到n进行遍历，每次拿出一个长度然后对其进行由i到j每个位置的划分，均求一个最大，对每次的结果进行保存，最后得出结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">matrix_chain_multiplication()</span><br><span class="line">&#123;</span><br><span class="line">    for i = 1 to n :</span><br><span class="line">        OPT[i,i] = 0</span><br><span class="line">    for l = 2 to n :  //子串的长度由2到n递增</span><br><span class="line">        for i = 1 to n - l + 1: //l长度下，对i所有可能位置进行遍历</span><br><span class="line">            j = i + l -1        // j移到子串的最后位置上</span><br><span class="line">            opt[i,j] = INF       </span><br><span class="line">            for k = i to j - 1: //对每一个位置均遍历一下括号的位置</span><br><span class="line">                q = opt[i,k]+opt[k+1,j]+p[i]*p[k+1]*p[j+1]</span><br><span class="line">                if q &lt; opt[i,j]:</span><br><span class="line">                    opt[i,j] = q</span><br><span class="line">                    s[i,j] = k</span><br><span class="line">    return opt[1,n]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>0/1背包问题</strong><br> 给定一个集合其中有S个物品，每个物品i有一个重量 w_i 和一个价值 v_i ，每个物品只有一个，你有一个能装重量为W的背包。问怎么装使得所装物品的价值最大。</p><p>分析：我们将0/1背包问题转化成一个多步决策的问题，在第i步决定是否选择第i个物品。因此有一下的递推表达式：<br>$$ opt({1,2,…n},W) = \max \begin{cases}  opt({1,2,…n-1},W)  &amp;   opt({1,2,…n-1},W-w_n)+v_n \end{cases}<br>$$<br>算法框架如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Knapsack(n,w)</span><br><span class="line">&#123;</span><br><span class="line">    for w = 1 to W:</span><br><span class="line">        OPT[0,w] = 0</span><br><span class="line">    for i = 1 to n:  //现在拿i个物品</span><br><span class="line">        for w = 1 to W:  // 现在拿出w个空间来装</span><br><span class="line">            if w &gt; w[i]:  //当前拿出的空间够装现在的货物</span><br><span class="line">            OPT[i,w] = max(opt[i-1][w],opt[i-1][w-w[i]]+v[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>回退法判断物品是否被取走：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void traceback()</span><br><span class="line">&#123;</span><br><span class="line">    for i = n to 2:</span><br><span class="line">        if(m[i][c] == m[i-1][c]):</span><br><span class="line">            x[i] = 0</span><br><span class="line">        else:</span><br><span class="line">            x[i] = 1</span><br><span class="line">            c -= w[i]</span><br><span class="line">    x[1] = m[1][c]&gt;0? 1:0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>时间复杂度为 O(nW) 伪多项式时间。$ O(nW) = O(n*2^{logW})$ ，W为输入的长度，当W很大时，算法效率很低。需要注意的是，我们选择物品的顺序是从头到尾挑选，而不是在一个子集中随机挑选。</p><p> <strong>最小覆盖点问题：</strong><br> 问题描述：在一个图中找到最少的点，使其能够覆盖图中所有的边。</p><p>问题分析：这个问题可以用一个树的结构的分析。当选取当前的点作为最优结果中的一点时，从从改点的所有子节点作为新的子问题，否则选取所有的儿子节点，从其孙子节点作为子问题。 该问题的最优子结构为：<br>$$ opt(root) = \min ( 1 + \sum_copt(c)  ,  children + \sum_gopt(g) )$$<br>算法框架如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vertex_cover(root)</span><br><span class="line">&#123;</span><br><span class="line">    if(root == NULL):</span><br><span class="line">       return 0</span><br><span class="line">    opt(root) = min(sum_of_child+opt(g),1+opt(c))</span><br><span class="line">    return opt(root)     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>动态规划问题的适用于求解那些子问题存在大量重复的问题，可以通过存储中间结果的方式大大缩小程序的复杂度。通常的求解方式有递归法，动态填表法。</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>语义分割系列 -- FCN详解</title>
      <link href="/2019/02/20/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%B3%BB%E5%88%97-FCN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/20/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%B3%BB%E5%88%97-FCN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="语义分割系列-–-FCN详解"><a href="#语义分割系列-–-FCN详解" class="headerlink" title="语义分割系列 – FCN详解"></a>语义分割系列 – FCN详解</h3><p>FCN是深度学习用于语义分割领域的开山之作，他的主要核心贡献在于：</p><ul><li><strong>全卷积（convolutional）：</strong>采样端对端的卷积网络，将普通分类网络的<strong>全连接层换上对应的卷积层（FCN）</strong></li><li><strong>上采样(upsample)</strong>：即反卷积（deconvolution），恢复图片的位置信息等，反卷积层可以通过最小化误差学习得到。</li><li><strong>跳跃连接(skip layer)</strong>：通过连接不同卷积层的输出到反卷积层，来改善上采样很粗糙的问题。</li></ul><blockquote><p>FCN：Fully Convolutional Networks for Semantic Segmentation<br>submit time: 2015<br><a href="https://arxiv.org/abs/1411.4038.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><h4 id="FCN与CNN"><a href="#FCN与CNN" class="headerlink" title="FCN与CNN"></a>FCN与CNN</h4><p>通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于<strong>图像级的分类和回归任务</strong>，因为它们最后都期望得到整个输入图像的一个数值描述<strong>（概率）</strong>，比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。<br>如下：下图中的猫, 输入AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高。<br><img src="/images/FCN/CNN.png" alt="CNN"><br>FCN相对用于图片分类领域的经典网络如Alexnet, VGG, Googlenet等只是在最后几层稍作了修改，替换，以让它们适用在了semantic segmentation上面。下图中可看出FCN相当于分类CNN网络在模型后端所有的变化。<br>FCN<img src="/images/FCN/FCN.png" alt="FCN"><br><strong>全卷积：</strong><br>前端输入，一般CNN分类网络选择使用固定大小的image patch来作为输入，这个patch往往是从原图当中剪切出来的；<strong>而FCN网络则使用整张原图来作为输入，允许图片大小不固定。</strong>然后在模型的后端，CNN分类网络会使用FC层对最后的CNN层生成出的feature map进行处理，从而丢掉由前端CNN各层处理所一直保存着的图片上敏感区域的位置信息，进而只抽象表达出它的类别信息来，以交由后面的softmax等层来最终预测出它的类别概率分布；<strong>FCN则不同，它丢掉了CNN分类网络后端的FC层，进而保留了图片上的区域位置信息，又在其后加上了几层CNN来进一步分析处理，整合主干网络输出特征，最终它生成出有着C+1（C为目标类别数，+1是为了考虑进去图片背景）个channels的heat map（本质上可以理解为是cnn所产生的feature map）来。</strong><br>由于FCN网络前端CNN处理过程中会不断选择用Pool来整合、下采样特征，从而扩大后来层次的receptive fields，因此最终我们生成出来的heat map其大小肯定要小于原输入图片大小。<strong>实际上最终生成的feature map比原图片缩小s倍</strong>，s为图片中下采样层次stride的乘积即累积下采样步长。<br>而我们Semantic segmentation的目标是要预测输入图片每个像素点的可能类别。因此我们要想办法将输出的heat map与input raw image关联起来。简单的话可以直接使用线性二次插值来解决。<strong>FCN中通过在网络最后加入步长为s的deconvolution层来使得最终的网络输出heat map具有与输入原图一样的大小</strong>。<br><strong>全连接层-&gt;卷积层</strong></p><ul><li>第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为k=7，padding = 0,stride = 1,共4096个卷积核，这样输出数据体就为[1x1x4096]了。</li><li>第二个全连接层，令其滤波器尺寸为K=1，共有4096个卷积核，这样输出数据体为[1x1x4096]。</li><li>对最后一个全连接层，令其K=1，共1000个卷积核，最终输出为[1x1x1000]</li></ul><p><strong>上采样：</strong><br>下图是一个反卷积的过程，首先在feature map上增加padding，padding的大小为Kernel size - 1，padding部分用0来填充。随后使用卷积核在对该feature 进行卷积操作。该图是一个strides(步长)为1的反卷积，即FULL卷积方式：<br><strong>full: 滑动步长为1，图片大小为N1xN1，卷积核大小为N2xN2，卷积后图像大小：N1+N2-1 x N1+N2-1</strong><br><img src="/images/FCN/upsample.gif" alt="upsample"><br>下图是步长为2的反卷积，可以使得图片变大，反卷积中步长指的是原图像素间填充0的行数。这时候原图中就会出现孔，可以这么理解，反卷积与卷积对应，当卷积stride为2的时候，表明下一次卷积将跨越两个像素。<strong>当反卷积stride为2时，意味着反卷积的步长为0.5，即需要走2步才能走到下一个像素位置。</strong><br><img src="/images/FCN/upsample_stride.gif" alt="upsample_stride"><br>反卷积效果：<br><img src="/images/FCN/deconv.png" alt="deconv"></p><p><strong>跳跃连接(skip layer)：</strong><br>由于直接从最后的feature map上采样到图片大小，精度上过于粗糙，这是因为当网络较深时可以学到比较深度的特征，同时过深的网络也会丢失空间位置信息。这意味着较浅层的输出具有更多位置信息。如果我们将两者结合起来，我们就提高结果。<br><img src="/images/FCN/fcndeconv.jpg" alt="fcndeconv"><br><strong>训练过程：</strong><br>第一阶段：<br><img src="/images/FCN/step1.jpg" alt="step1"><br>用经典的分类网络进行初始化，最后两层参数不使用。<br><img src="/images/FCN/step2.jpg" alt="step2"><br>从特征图（16*16*4096）预测分割小图（16*16*21），之后直接上采样为大图。<br>反卷积（橙色）的步长为32，即特征图放大16倍，这个网络称为FCN-32s。<br><img src="/images/FCN/step4.jpg" alt="step3](/images/FCN/step3.jpg)上采样分为两次完成：第一次为橙色×2。在第二次上采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。 第二次反卷积步长为16，这个网络称为FCN-16s。!step4"><br>升采样分为三次完成（橙色×3）。进一步融合了第3个pooling层的预测结果。 第三次反卷积步长为8，记为FCN-8s。 </p><h4 id="LOSS"><a href="#LOSS" class="headerlink" title="LOSS"></a>LOSS</h4><p>FCN的loss 为交叉墒loss，先接一个soft Max将网络的输出转化为概率。用概率计算交叉墒。<br>tensorflow 中调用的函数为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,</span><br><span class="line">labels=tf.squeeze(annotation, squeeze_dims=[<span class="number">3</span>]),name=<span class="string">"entropy"</span>)))</span><br></pre></td></tr></table></figure></p><p>CNN 网络优化通常使用的是SGD，随机梯度下降法来优化。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cross entropy 交叉熵以及softmax</title>
      <link href="/2019/02/20/cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax/"/>
      <url>/2019/02/20/cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A5%E5%8F%8Asoftmax/</url>
      
        <content type="html"><![CDATA[<h3 id="cross-entropy-交叉熵以及softmax"><a href="#cross-entropy-交叉熵以及softmax" class="headerlink" title="cross entropy 交叉熵以及softmax"></a>cross entropy 交叉熵以及softmax</h3><p>交叉熵常常用在CNN网络中，作为网络的loss，他描述的是模型数据分布与训练数据之间的相似程度。最小化交叉熵等价于模型产生数据与训练数据相似度越高。</p><p><strong>信息量：</strong><br>用来衡量一件事情的不确定程度，一件事情发生概率越大，他的不确定性越小，信息量越少。信息量的计算公式为：<br>$$<br>I(x_0) = - \log(P(x_0))<br>$$<br>例如，当$p(x_0) = 0.1,I(x_0) = 3.32$，$p(x_0) = 0.999,I(x_0) = 0.0014$</p><p><strong>熵：</strong><br>用于衡量一个系统的混乱程度，代表一个系统信息量的总和。当一个系统信息量越大越不稳定。熵等于所有事件所带来的信息期望总和。<br>$$<br>H(x) = - \sum_{x\in X}p(x) \log p(x)<br>$$<br><strong>交叉熵：</strong><br>交叉熵描述两个事件之间的相互关系：<br>$$<br>H(A,B) = -\sum_i P_{A}(x_i)log(P_{B}(x_i))<br>$$</p><p><strong>如何计算两个分布之间的不同： KL散度</strong><br>KL散度，有时候也叫KL距离，一般被用于计算两个分布之间的不同，KL散度不具备有对称性。<br>$$<br>D_{KL}(A||B) = \sum_i P_A(x_i)\log(\frac{P_A(x_i)}{P_B(x_i)}) = \sum_{i}P_{A}(x_i)log(P_{A}(x_i ))- \sum_i P_{A}(x_i)log(P_{B}(x_i))<br>$$<br>由上式可以发现，<strong>KL散度 = - 熵 + 交叉熵</strong>，当熵固定不变时，认为交叉熵等价于KL散度。</p><p><strong>机器学习中使用交叉熵代替KL散度：</strong><br>机器学习的过程中希望在训练数据上模型学到的分布 P(model) 和训练数据groundtruth的分布 P(real) 越接近越好，可以通过优化KL散度，使其KL散度最小来达到目的。<strong>由于训练数据groundtruth是固定的因此求解KL散度将会等价于求解交叉熵。</strong>因此最小化交叉熵将会得到一个比较好模型。</p><p><strong>softmax：</strong><br>在神经网络分类任务来说，最后一层将会输出x的一维特征，<strong>每一个位置表示一个特征表示值。这个表示值越大认为这张图片是这个类别的概率越大。</strong>因此可以用特征表示值来判断类别。但是在实际运用中，特征表示值的用途不大, 我们更希望得到具有统计意义的概率。例如可以利用概率来优化KL散度，使得预测结果更加准确。<strong>softmax它将多个神经元的输出，映射到（0,1）区间内，表示类别的概率，从而进行多分类。</strong><br>softmax的公式如下：<br>$$<br>S_i = \frac{e^{V_i}}{\sum_j{e^{V_j}}}<br>$$<br>其中V表示神经网络输出的一维数组。</p><p>softmax在实际使用时需要注意数值溢出的问题。如上公式，在计算概率的时候存在指数运算，当V数值很大的时候将会发生溢出。因此需要对上式做一下处理，将指数部分同时减去指数中的最大值。<br>$$<br>D = max(V) \\<br>S_i = \frac{e^{V_i - D}}{\sum_j{e^{V_j - D}}} = \frac{e^{V_i}}{\sum_j{e^{V_j}}} / \frac{D}{D}<br>$$<br>经过处理后，保证数值不会发生溢出现象。</p><h3 id="神经网络中的应用"><a href="#神经网络中的应用" class="headerlink" title="神经网络中的应用"></a>神经网络中的应用</h3><p>大多数的CNN网络中，均适用softmax + cross entropy作为损失函数。<br>首先是交叉熵LOSS：<br>$$<br>Loss = -\sum_i P_{groundtruth} \log P_{predict}<br>$$<br>其中$P_{groundtruth}$是真值的类别分布概率。在多分类问题中，一张图片只属于一个类别，因此$P_{groundtruth}$表示成one hot编码，即[0,0,…,1,0,0]这种形式。对于$P_{predict}$来说，神经网络输出的特征值经过softmax层，转换为概率的形式。因此Loss 最终会等于：$$-\log p_i$$i表示这个图片真实的类别。</p><h4 id="交叉熵-softmax反向求导："><a href="#交叉熵-softmax反向求导：" class="headerlink" title="交叉熵+ softmax反向求导："></a><strong>交叉熵+ softmax反向求导：</strong></h4><p>由上式可知，交叉熵的形式非常简单，其中$p_i$由softmax计算得到。带入softmax公式，得到交叉熵最后的形式为：<br>$$<br>L =  - \log \frac{e^{V_{i}}}{\sum_j e^{V_{j}}}<br>$$</p><p><strong>对交叉熵的求导：</strong><br>在进行BP方向传播的时候，更新参数的时候，误差需要由交叉熵提供，即$-\log p_i$，然后对每一个参数值通过链式法制都求一次偏导,例如对$W_{ij}$：<br>$$<br>\frac{\partial{L}}{\partial{W_{ij}}} = - \frac{1}{\frac{e^{a_i}}{\sum_k e^{a_k}}} \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}} \frac{\partial{a_j}}{\partial{W_{ij}}}<br>$$<br><strong>对softmax进行求导如下：</strong><br>上式中间部分为对softmax求导，令<br>$$<br> y_i = \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}<br>$$<br>对softmax求偏导数：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_k e^{a_k}} }}{\partial{a_{j}}}<br>$$<br>当 <code>i!=j</code> 时：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ 0 - e^{a_i}e^{a_j}}{\Sigma^2}=-\frac{e^{a_i}}{\Sigma}\frac{e^{a_j}}{\Sigma}=-y_iy_j<br>$$<br>当 <code>i==j</code> 时：<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}} = \frac{\partial{ \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} }}{\partial{a_{j}}}= \frac{ e^{a_i}\Sigma - e^{a_i}e^{a_j}}{\Sigma^2}=\frac{e^{a_i}}{\Sigma}\frac{\Sigma - e^{a_j}}{\Sigma}=y_i(1 - y_j)<br>$$<br>求导过程比较简单，算一下就知道了，不要害怕。得到误差对权重的偏导数就可以对该权重进行更新了，CNN网络通常使用的更新方式为SGD。</p><h4 id="SGD-随机梯度下降法"><a href="#SGD-随机梯度下降法" class="headerlink" title="SGD 随机梯度下降法"></a>SGD 随机梯度下降法</h4><p>最优化算法的核心是从当前点走到下一个点，是的目标函数得到下降。即$x_0 -&gt; x_1$，最优化算法考虑两个问题，即从当前点，<strong>移动的方向和步长</strong>。可以写成下面形式：<br>$$<br>x_{k+1} = x_k + \eta P_k<br>$$<br>其中$P_k$是前进方向。令$P_k = -\nabla f_k$，即负梯度方向时，下降速度最快。这种方法在及其学习中称为梯度下降法。他有一个缺点，就是需要严格求解出整个数据集的梯度，才能走到下一步。而且十分容易陷入局部极小点,因此我们使用SGD来改善这一现象。<br>SGD 算法的表达式和GD差不多:<br>$$x_{t+1}=x_t+\eta_t g_t$$<br>这里 $g_t$ 就是所谓的Stochastic Gradient，它满足 $E[g_t]=-\nabla f(x_t)$。它对导数的要求非常低，导数算起来非常快。由于数据样本中存在大量无用的冗余信息，因此使用随机梯度下降法可以得到近似的下降梯度，而仅仅话费少量的计算资源。<br><strong>softmax tensorflow 实现版本</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># downlown the data</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input data</span></span><br><span class="line">X = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">Y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"><span class="comment"># model variable</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"><span class="comment"># define model</span></span><br><span class="line">y_predict = tf.matmul(X,W) + b</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=y_predict))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train_step = optimizer.minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">global_initial = tf.global_variables_initializer()</span><br><span class="line">sess.run(global_initial)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step,feed_dict=&#123;X:batch[<span class="number">0</span>],Y:batch[<span class="number">1</span>]&#125;)</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_predict,<span class="number">1</span>),tf.argmax(Y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line">print(sess.run(accuracy,feed_dict=&#123;X:mnist.test.images,Y:mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">print(sess.run(b))</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 题解(持续更新)</title>
      <link href="/2019/02/20/LeetCode-%E9%A2%98%E8%A7%A3/"/>
      <url>/2019/02/20/LeetCode-%E9%A2%98%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>本篇文章置顶，长期更新，用于记录日常刷题题解以及需要注意的tip。<br><a id="more"></a></p><p>2019年的关键词：思路要紧！</p><hr><p>28/5/2019</p><h3 id="116-Populating-Next-Right-Pointers-in-Each-Node-117"><a href="#116-Populating-Next-Right-Pointers-in-Each-Node-117" class="headerlink" title="116.Populating Next Right Pointers in Each Node,117"></a><a href="https://leetcode.com/problems/populating-next-right-pointers-in-each-node/" target="_blank" rel="noopener">116.Populating Next Right Pointers in Each Node</a>,117</h3><p>这一题看leetcode上的表示方式十分的唬人，实际上还算是比较简单。思路就是层次遍历，然后每次遍历用两个数来维护每一层的遍历次数。在元素进队列的时候进行左右的连接。（116的树为完全树，117的树不是完全树，同样的做法）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val, left, right, next):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        que    = []</span><br><span class="line">        que.append(root)</span><br><span class="line">        count  = <span class="number">1</span></span><br><span class="line">        record = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> len(que) &gt; <span class="number">0</span>:</span><br><span class="line">            node = que.pop(<span class="number">0</span>)</span><br><span class="line">            count -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                que.append(node.left)</span><br><span class="line">                record += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> len(que)&gt;<span class="number">1</span>:</span><br><span class="line">                    que[<span class="number">-2</span>].next = que[<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                que.append(node.right)</span><br><span class="line">                record += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> len(que)&gt;<span class="number">1</span>:</span><br><span class="line">                    que[<span class="number">-2</span>].next = que[<span class="number">-1</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">                node.next = <span class="keyword">None</span></span><br><span class="line">                count = record</span><br><span class="line">                record = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><hr><p>21/5/2019</p><h3 id="103-Path-Sum-II"><a href="#103-Path-Sum-II" class="headerlink" title="103. Path Sum II"></a><a href="https://leetcode.com/problems/path-sum-ii/" target="_blank" rel="noopener">103. Path Sum II</a></h3><p>思路：这一题可以沿着深度遍历的方向去做，然后在遍历的过程中，记录下路径。然后判断，当前path上的元素之和是否等于sum，并且当前节点是叶子结点。划重点：<u>sum(path) + root.val</u> 之和来判断，而不是把所有val都加到path上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.result = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_path</span><span class="params">(self,root,sums,path)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> sum(path) + root.val == sums <span class="keyword">and</span> root.left == <span class="keyword">None</span> <span class="keyword">and</span> root.right == <span class="keyword">None</span>:</span><br><span class="line">            self.result.append((path+[root.val])[:])</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        path.append(root.val)</span><br><span class="line">        self.find_path(root.left,sums,path)</span><br><span class="line">        self.find_path(root.right,sums,path)</span><br><span class="line">        <span class="keyword">if</span> path!=[]:</span><br><span class="line">            path.pop()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span><span class="params">(self, root, sum)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type sum: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        path = []</span><br><span class="line">        self.find_path(root,sum,path)</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br></pre></td></tr></table></figure><h3 id="114-Flatten-Binary-Tree-to-Linked-List"><a href="#114-Flatten-Binary-Tree-to-Linked-List" class="headerlink" title="114.Flatten Binary Tree to Linked List"></a><a href="https://leetcode.com/problems/flatten-binary-tree-to-linked-list/" target="_blank" rel="noopener">114.Flatten Binary Tree to Linked List</a></h3><p>思路：这一题太巧妙啦，要把所有节点压到右支上，这时候用的方法是先后续遍历，用一个变量记录上一个节点，然后作为当前节点的右节点，同时砍掉当前的左节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flatten</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: None Do not return anything, modify root in-place instead.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.prev = <span class="keyword">None</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(root)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">            dfs(root.right)</span><br><span class="line">            dfs(root.left)</span><br><span class="line">            root.right = self.prev</span><br><span class="line">            root.left = <span class="keyword">None</span></span><br><span class="line">            self.prev = root</span><br><span class="line">        dfs(root)</span><br></pre></td></tr></table></figure><hr><p>19/4/2019</p><h3 id="107-Binary-Tree-Level-Order-Traversal-II"><a href="#107-Binary-Tree-Level-Order-Traversal-II" class="headerlink" title="107. Binary Tree Level Order Traversal II"></a><a href="https://leetcode.com/problems/binary-tree-level-order-traversal-ii/" target="_blank" rel="noopener">107. Binary Tree Level Order Traversal II</a></h3><p>思路：哇，类似的专题好多啊，这一题要求按层次，从最后一层依次打印到第一层，与前面几题的区别在于，每次将层插入第一个位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrderBottom</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        line =[root]</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        val = []</span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            num-=<span class="number">1</span></span><br><span class="line">            val.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                res.insert(<span class="number">0</span>,val[:])</span><br><span class="line">                val = []</span><br><span class="line">                num = len(line)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>18/4/2019</p><h3 id="102-Binary-Tree-Level-Order-Traversal"><a href="#102-Binary-Tree-Level-Order-Traversal" class="headerlink" title="102. Binary Tree Level Order Traversal"></a><a href="https://leetcode.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="noopener">102. Binary Tree Level Order Traversal</a></h3><p>思路：层次遍历一棵树，最近做的题都比较接地气啊，都是大一做的题，哈哈我感觉记得这么清楚全要谢谢林老师。这一题要求把每一行的的元素依次打印出来，每一行一个list。</p><p>用队列结构来处理这个问题。首先从根节点开始，依次进队列，每次循环头节点出队列，并将其子节点进队列。然后维护一个计数器，计数器初始化为每一行list长度，当这个变量变成0的时候说明这一行已经遍历完成了。重新开一个list。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        line = []</span><br><span class="line">        line.append(root)</span><br><span class="line">        val = []</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            val.append(node.val)</span><br><span class="line">            num -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> node.left != <span class="keyword">None</span>:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right != <span class="keyword">None</span>:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                res.append(val)</span><br><span class="line">                val = []</span><br><span class="line">                num = len(line)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="103-Binary-Tree-Zigzag-Level-Order-Traversal"><a href="#103-Binary-Tree-Zigzag-Level-Order-Traversal" class="headerlink" title="103. Binary Tree Zigzag Level Order Traversal"></a><a href="https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/" target="_blank" rel="noopener">103. Binary Tree Zigzag Level Order Traversal</a></h3><p>思路：这一题沿着Z字形进行输出，只需要在上一题的基础上加一个记录层数的变量即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zigzagLevelOrder</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        line = []</span><br><span class="line">        line.append(root)</span><br><span class="line">        val = []</span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        level = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> len(line):</span><br><span class="line">            node = line.pop(<span class="number">0</span>)</span><br><span class="line">            num -= <span class="number">1</span></span><br><span class="line">            val.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                line.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                line.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                num = len(line)</span><br><span class="line">                <span class="keyword">if</span> level%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                    val.reverse()                    </span><br><span class="line">                    res.append(val)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    res.append(val)</span><br><span class="line">                val = []</span><br><span class="line">                level += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>15/4/2019</p><h3 id="96-Unique-Binary-Search-Trees"><a href="#96-Unique-Binary-Search-Trees" class="headerlink" title="96. Unique Binary Search Trees"></a><a href="https://leetcode.com/problems/unique-binary-search-trees/" target="_blank" rel="noopener">96. Unique Binary Search Trees</a></h3><p>思路：这一题说给一个数字，求出所有平衡二叉树的个数。根据平衡二叉树的性质可以知道，左子树小于根节点，右子树大于根节点。因此有这种关系：</p><p>f(1) = f(0) x f(2), f(2)=f(1) x f(1), …  f(n) = f(n-1)xf(0)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numTrees</span><span class="params">(self,n)</span>:</span></span><br><span class="line">    res = [<span class="number">0</span>] *(n+<span class="number">1</span>)</span><br><span class="line">    res[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(j):</span><br><span class="line">        res[i] += res[j]*res[i-j<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="94-Binary-Tree-Inorder-Traversal"><a href="#94-Binary-Tree-Inorder-Traversal" class="headerlink" title="94. Binary Tree Inorder Traversal"></a><a href="https://leetcode.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="noopener">94. Binary Tree Inorder Traversal</a></h3><p>这一题要求按中序遍历的方式输出一颗二叉树。可用递归的方式解决。想起这道题，林老师上课的画面迎面而来，哈哈。</p><p>中序遍历思路为沿着树的枝往下走，当回溯时，第二次遇到这个节点的时候返回，此时记录下遍历的节点值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,root)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left)</span><br><span class="line">        self.res.append(root.val)</span><br><span class="line">        self.dfs(root.right)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.dfs(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br></pre></td></tr></table></figure><h3 id="101-Symmetric-Tree"><a href="#101-Symmetric-Tree" class="headerlink" title="101. Symmetric Tree"></a><a href="https://leetcode.com/problems/symmetric-tree/" target="_blank" rel="noopener">101. Symmetric Tree</a></h3><p>思路：这一题判断树是否是镜像。用树的结构进行递归，每次递归判断是否为镜像，如果不是则返回False。每次进行递归的时候传入树的对称边。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,left,right)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="keyword">None</span> <span class="keyword">or</span> right == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">if</span> left != right:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">if</span> left.val != right.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> self.dfs(left.left,right.right) <span class="keyword">and</span> self.dfs(left.right,right.left)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span><span class="params">(self, root)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span> self.dfs(root.left,root.right)</span><br></pre></td></tr></table></figure><hr><p>25/3/2019</p><h3 id="92-Reverse-Linked-List-II"><a href="#92-Reverse-Linked-List-II" class="headerlink" title="92. Reverse Linked List II"></a>92. <a href="https://leetcode.com/problems/reverse-linked-list-ii/" target="_blank" rel="noopener">Reverse Linked List II</a></h3><p><strong>分析：</strong>这一题需要定义头节点，关于元素的调换的问题，都需要定义头节点。然后记住tail，head，思路清晰一点，就很好做了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseBetween</span><span class="params">(self, head, m, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type m: int</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> m == n:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        dummy = ListNode(<span class="number">-1</span>)</span><br><span class="line">        dummy.next = head</span><br><span class="line">        p = dummy</span><br><span class="line">        newhead = p</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            newhead = p</span><br><span class="line">            p = p.next</span><br><span class="line">        tail = p</span><br><span class="line">        q = p</span><br><span class="line">        p = p.next</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n-m):</span><br><span class="line">            p_pre = p.next</span><br><span class="line">            p.next = q</span><br><span class="line">            q = p</span><br><span class="line">            p = p_pre</span><br><span class="line">        tail.next = p_pre</span><br><span class="line">        newhead.next = q</span><br><span class="line">        <span class="keyword">return</span> dummy.next</span><br></pre></td></tr></table></figure><h3 id="93-Restore-IP-Addresses"><a href="#93-Restore-IP-Addresses" class="headerlink" title="93. Restore IP Addresses"></a><a href="https://leetcode.com/problems/restore-ip-addresses/" target="_blank" rel="noopener">93. Restore IP Addresses</a></h3><p><strong>分析：</strong>这一题蛮有意思的我感觉。它的内循环是从1到3，即截取的字符长度，每个截取的长度都作为ip地址的一部分。每次截取子串的时候需要对他们进行合法性判断。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.res = []</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(self,s,ret,index,count)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> count&gt;<span class="number">4</span>:</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">4</span> <span class="keyword">and</span> index == len(s):</span><br><span class="line">      self.res.append(res[:<span class="number">-1</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">      <span class="keyword">if</span> i + index &gt; len(s):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      temp = s[index,index+i]</span><br><span class="line">      <span class="keyword">if</span> (temp[<span class="number">0</span>] == <span class="string">'0'</span> <span class="keyword">and</span> len(temp)&gt;<span class="number">1</span>) <span class="keyword">and</span> (len(temp) <span class="keyword">and</span> int(temp)&gt;=<span class="number">256</span>):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      helper(s,ret+temp+<span class="string">'.'</span>,index+i,count+<span class="number">1</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">restoreIpAddresses</span><span class="params">(self,s)</span>:</span></span><br><span class="line">    self.helper(s,<span class="string">''</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> self.res</span><br></pre></td></tr></table></figure><hr><p>24/3/2019</p><h3 id="91-Decode-Ways"><a href="#91-Decode-Ways" class="headerlink" title="91. Decode Ways"></a><a href="https://leetcode.com/problems/decode-ways/" target="_blank" rel="noopener">91. Decode Ways</a></h3><p><strong>分析：</strong>这一题是典型的动态规划题，主要就是想到状态转移方程该怎么写就行了。有几种情况要进行分析。首先当前位置上为0的时候，当前的字母需要与前一个字母组成一个合法数据才行。否则就是按照正常的方式单个字母，两个字母的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numDecodings</span><span class="params">(self, s)</span>:</span> <span class="comment"># 动态规划</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> len(s) == <span class="number">0</span> <span class="keyword">or</span> s[<span class="number">0</span>] == <span class="string">'0'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [<span class="number">0</span>]*len(s)</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">'0'</span>:</span><br><span class="line">                <span class="comment"># 必须与前一个组成一个二位数</span></span><br><span class="line">                <span class="keyword">if</span> s[i<span class="number">-1</span>] == <span class="string">'2'</span> <span class="keyword">or</span> s[i<span class="number">-1</span>] == <span class="string">'1'</span> :</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                        dp[i] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        dp[i] = dp[i<span class="number">-2</span>]</span><br><span class="line">            <span class="keyword">elif</span> int(s[i<span class="number">-1</span>:i+<span class="number">1</span>])&lt;=<span class="number">26</span> <span class="keyword">and</span> s[i<span class="number">-1</span>]!=<span class="string">'0'</span>:</span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                    dp[i] = <span class="number">2</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i] = dp[i<span class="number">-1</span>]+dp[i<span class="number">-2</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i] = dp[i<span class="number">-1</span>]</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> dp[len(s)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><p>23/3/2019</p><p>这两天的状态和前两天一样，没办法调整🤢</p><h3 id="90-Subsets-II"><a href="#90-Subsets-II" class="headerlink" title="90. Subsets II"></a><a href="https://leetcode.com/problems/subsets-ii/" target="_blank" rel="noopener">90. Subsets II</a></h3><p>这题用递归的方法做，我觉得在做题的时候应该要多总结思路，首先就要确定这一题是什么类型的题目。然后向方法，一定唔要无头苍蝇似的，面试题差不多就median了，加油咯⛽️。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,nums,pos,temp,res)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> sorted(temp) <span class="keyword">not</span> <span class="keyword">in</span> res:</span><br><span class="line">            res.append(sorted(temp))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(pos,len(nums)):</span><br><span class="line">            temp.append(nums[i])</span><br><span class="line">            self.dfs(nums,i+<span class="number">1</span>,temp,res)</span><br><span class="line">            temp.pop()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsetsWithDup</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        self.dfs(nums,<span class="number">0</span>,[],res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>这一题有一个地方，需要注意一下，就是深浅拷贝的问题。（错过的问题）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">temp = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">a = temp <span class="comment"># 浅拷贝，a随着temp而变化</span></span><br><span class="line">a = temp[:] <span class="comment"># 深拷贝，a与temp无关</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">a = copy.deepcopy(temp) <span class="comment"># 深拷贝</span></span><br><span class="line"><span class="comment">## 排序问题</span></span><br><span class="line">a.sort() <span class="comment"># 直接改变a</span></span><br><span class="line">sorted(a) <span class="comment"># 返回值为排序后的结果</span></span><br></pre></td></tr></table></figure><h3 id="89-Gray-Code"><a href="#89-Gray-Code" class="headerlink" title="89. Gray Code"></a>89. <a href="https://leetcode.com/problems/gray-code/" target="_blank" rel="noopener">Gray Code</a></h3><p><strong>分析：</strong>这一题本来想要递归的方法来做，但是奈何，递归不满足格雷码依次变一位的原则。因此本题采用格雷码的公式求解。G(i) = i ^ (i/2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">grayCode</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>&lt;&lt;n):</span><br><span class="line">            res.append(i^i&gt;&gt;<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><hr><p>21/3/2019</p><h3 id="100-Same-Tree"><a href="#100-Same-Tree" class="headerlink" title="100. Same Tree"></a><a href="https://leetcode.com/problems/same-tree/submissions/" target="_blank" rel="noopener">100. Same Tree</a></h3><p>最近有点儿奇怪呀， 明天想着做的事情，都没能做起来。</p><p><strong>分析：</strong> 这一题用递归调用的方式求解。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSameTree</span><span class="params">(self, p, q)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type p: TreeNode</span></span><br><span class="line"><span class="string">        :type q: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> p == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> q==<span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> q == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">if</span> p.val != q.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> self.isSameTree(p.right,q.right) <span class="keyword">and</span> self.isSameTree(p.left,q.left)</span><br></pre></td></tr></table></figure><hr><p>18/3/2019</p><h3 id="73-Set-Matrix-Zeroes"><a href="#73-Set-Matrix-Zeroes" class="headerlink" title="73. Set Matrix Zeroes"></a>73. Set Matrix Zeroes</h3><p><img src="/images/leetcode/73.png" alt=""></p><p>一直想刷题一直没刷，很惭愧。</p><p><strong>分析：</strong> 这一题是找出行活列含1的数，然后将整行置0。对呀python的数组，可以整行整行的赋值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix[key] = [<span class="number">0</span>]*n   <span class="comment"># 对key这一行整行赋值</span></span><br><span class="line"><span class="comment">#对列赋值,不可以整行</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">  matrix[i][key] = <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setZeroes</span><span class="params">(self, matrix)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type matrix: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: None Do not return anything, modify matrix in-place instead.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        dict_x = &#123;&#125;</span><br><span class="line">        dict_y = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> len(matrix) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> len(matrix[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        m = len(matrix)</span><br><span class="line">        n = len(matrix[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">                <span class="keyword">if</span> matrix[i][j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dict_x:</span><br><span class="line">                        dict_x[i] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> dict_y:</span><br><span class="line">                        dict_y[j] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> dict_x.keys():</span><br><span class="line">            matrix[key] = [<span class="number">0</span>]*n</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> dict_y.keys():</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">                matrix[i][key] = <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="77-Combinations"><a href="#77-Combinations" class="headerlink" title="77. Combinations"></a>77. Combinations</h3><p><img src="/images/leetcode/77.png" alt=""></p><p><strong>分析：</strong>这一题目的就是用递归的方式来求解，需要记住的是上一次的递归起点。需要注意的一点是，当一个list要添加另一个list作为一项时，使用：<code>list.append(list1[:])</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,n,idx,k,res,cur)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">      res.append(cur[:])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(idx,n):</span><br><span class="line">        <span class="keyword">if</span> k &gt; n-i:</span><br><span class="line">          <span class="keyword">return</span> []</span><br><span class="line">        cur.append(i+<span class="number">1</span>)</span><br><span class="line">        self.dfs(n,i+<span class="number">1</span>,k<span class="number">-1</span>,res,cur)</span><br><span class="line">        cur.pop()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">combine</span><span class="params">(self,n,k)</span>:</span></span><br><span class="line">    res = []</span><br><span class="line">    cur = []</span><br><span class="line">    dfs(n,<span class="number">0</span>,k,res,cur)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="78-Subsets"><a href="#78-Subsets" class="headerlink" title="78. Subsets"></a>78. Subsets</h3><p><img src="/images/leetcode/78.png" alt=""></p><p><strong>分析：</strong>这一题的思路是，看到这种递归问题，想到需要用循环来做。需要所有长度的情况都考虑进去。需要把所有的长度都考虑进去。因此要维护一个长度，由于不重复，因此需要维护一个下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,nums,idx,ilen,res,cur)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> ilen &gt; len(nums):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> len(cur) == ilen:</span><br><span class="line">            res.append(cur[:])    </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(idx,len(nums)):</span><br><span class="line">            cur.append(nums[i])</span><br><span class="line">            self.dfs(nums,i+<span class="number">1</span>,ilen+<span class="number">1</span>,res,cur)</span><br><span class="line">            cur.pop()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = []</span><br><span class="line">        cur = []</span><br><span class="line">        self.dfs(nums,<span class="number">0</span>,<span class="number">0</span>,res,cur)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="80-Remove-Duplicates-from-Sorted-Array-II"><a href="#80-Remove-Duplicates-from-Sorted-Array-II" class="headerlink" title="80. Remove Duplicates from Sorted Array II"></a>80. <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/" target="_blank" rel="noopener">Remove Duplicates from Sorted Array II</a></h3><p>这题从头扫描到尾巴，当情况符合的时候进行覆盖。le表示重复的个数，每一次覆盖条件满足都需要覆盖。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeDuplicates</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        le = <span class="number">0</span></span><br><span class="line">        pos = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i<span class="number">-1</span>] == nums[i]:</span><br><span class="line">                le += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> le&lt;<span class="number">2</span>:</span><br><span class="line">                    pos+=<span class="number">1</span></span><br><span class="line">                    nums[pos] = nums[i]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                le = <span class="number">0</span></span><br><span class="line">                pos+=<span class="number">1</span></span><br><span class="line">                nums[pos] = nums[i]</span><br><span class="line"> <span class="comment">#       nums[pos] = nums[len(nums)-1]</span></span><br><span class="line">        <span class="keyword">return</span> pos+<span class="number">1</span></span><br></pre></td></tr></table></figure><hr><p>14/3/2019</p><p><img src="/images/leetcode/71.png" alt=""></p><p><strong>分析：</strong> 犹豫要不要用python刷题，发现python实在是方便,这一题用stack的思路来做。首先用<code>/</code>把字符进行分割，然后用一个dict组织。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">simplifyPath</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type path: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        str = path.split(<span class="string">'/'</span>)</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> str:</span><br><span class="line">            <span class="keyword">if</span> ch == <span class="string">'..'</span>:</span><br><span class="line">                <span class="keyword">if</span> len(res) != <span class="number">0</span>:</span><br><span class="line">                    res.pop()</span><br><span class="line">            <span class="keyword">elif</span> ch!=<span class="string">''</span> <span class="keyword">and</span> ch!=<span class="string">'.'</span>:</span><br><span class="line">                res.append(ch)</span><br><span class="line">        ans = <span class="string">'/'</span></span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> res:</span><br><span class="line">            ans += ch+<span class="string">'/'</span></span><br><span class="line">        <span class="keyword">if</span> len(ans) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        <span class="keyword">return</span> ans[:len(ans)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><p>11/3/2019</p><h3 id="63-Unique-Paths-II"><a href="#63-Unique-Paths-II" class="headerlink" title="63. Unique Paths II"></a>63. Unique Paths II</h3><p><img src="/images/leetcode/63.png" alt=""></p><p><strong>分析：</strong>用动态规划做，递推公式为：$path[i][j] = path[i-1][j]+path[i][j-1]$。需要先把第一行和第一列先填上1。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; obstacleGrid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(obstacleGrid.size() == <span class="number">0</span>||obstacleGrid[<span class="number">0</span>].size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][<span class="number">0</span>] == <span class="number">1</span> ) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> height = obstacleGrid.size();</span><br><span class="line">        <span class="keyword">int</span> width = obstacleGrid[<span class="number">0</span>].size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt;&gt; path(height,<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt;(width,<span class="number">0</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;width&amp;&amp;obstacleGrid[<span class="number">0</span>][i]!=<span class="number">1</span>;i++)&#123;</span><br><span class="line">            path[<span class="number">0</span>][i] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height&amp;&amp;obstacleGrid[i][<span class="number">0</span>]!=<span class="number">1</span>;i++)&#123;</span><br><span class="line">            path[i][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;width;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[i][j] == <span class="number">1</span>) <span class="keyword">continue</span>;</span><br><span class="line">                path[i][j] = path[i<span class="number">-1</span>][j]+path[i][j<span class="number">-1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> path[height<span class="number">-1</span>][width<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="64-Minimum-Path-Sum"><a href="#64-Minimum-Path-Sum" class="headerlink" title="64. Minimum Path Sum"></a>64. Minimum Path Sum</h3><p><img src="/images/leetcode/64.png" alt=""></p><p><strong>分析：</strong>这一题和上一题差不多，唯一的区别在于这一题是找到最小的代价，因此去min就可以了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minPathSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(grid.size() == <span class="number">0</span> || grid[<span class="number">0</span>].size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> height = grid.size();</span><br><span class="line">        <span class="keyword">int</span> width = grid[<span class="number">0</span>].size();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;width;i++)&#123;</span><br><span class="line">            grid[<span class="number">0</span>][i] += grid[<span class="number">0</span>][i<span class="number">-1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;height;j++)&#123;</span><br><span class="line">            grid[j][<span class="number">0</span>] += grid[j<span class="number">-1</span>][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span> ;i&lt;height;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;width;j++)&#123;</span><br><span class="line">                grid[i][j] += min(grid[i<span class="number">-1</span>][j],grid[i][j<span class="number">-1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> grid[height<span class="number">-1</span>][width<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="65-Valid-Number"><a href="#65-Valid-Number" class="headerlink" title="65. Valid Number"></a>65. Valid Number</h3><p><img src="/images/leetcode/65.png" alt=""></p><p><strong>分析：</strong>字符串的转移这种问题很讨厌啊，情况太多了，总之思路就是从头到位扫一遍，判断很多边界情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isNumber</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>( !s.empty() )&#123;</span><br><span class="line">          s.erase(<span class="number">0</span>,s.find_first_not_of(<span class="string">" "</span>));</span><br><span class="line">          s.erase(s.find_last_not_of(<span class="string">" "</span>) + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">1</span>&amp;&amp;s[<span class="number">0</span>] == <span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">        amap[<span class="string">'-'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'+'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'.'</span>] = <span class="number">0</span>;</span><br><span class="line">        amap[<span class="string">'e'</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;s.size())&#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="string">'0'</span>&lt;=s[i]&amp;&amp;s[i]&lt;=<span class="string">'9'</span>)&#123;</span><br><span class="line">                flag = <span class="number">1</span>;</span><br><span class="line">                i++;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'-'</span>||s[i] == <span class="string">'+'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'-'</span>] + amap[<span class="string">'+'</span>] &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;s[i<span class="number">-1</span>]==<span class="string">'e'</span>)&#123;</span><br><span class="line">                        i++;</span><br><span class="line">                        <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i!= <span class="number">0</span>&amp;&amp;s[i<span class="number">-1</span>]!=<span class="string">'e'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    i++;</span><br><span class="line">                        <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                amap[s[i]]++;</span><br><span class="line">                i++;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'.'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'.'</span>] != <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'e'</span>]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span>||(<span class="string">'0'</span>&lt;=s[i<span class="number">-1</span>]&amp;&amp;s[i<span class="number">-1</span>]&lt;=<span class="string">'9'</span>))&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'.'</span>]++;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(s[i<span class="number">-1</span>]==<span class="string">'-'</span>||s[i<span class="number">-1</span>]==<span class="string">'+'</span>)&#123;</span><br><span class="line">                     i++;</span><br><span class="line">                    amap[<span class="string">'.'</span>]++;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'e'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap[<span class="string">'e'</span>]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;(<span class="string">'0'</span>&lt;=s[i<span class="number">-1</span>]&amp;&amp;s[i<span class="number">-1</span>]&lt;=<span class="string">'9'</span>))&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'e'</span>]++;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(s[i<span class="number">-1</span>]==<span class="string">'.'</span>&amp;&amp;flag == <span class="number">1</span>)&#123;</span><br><span class="line">                    i++;</span><br><span class="line">                    amap[<span class="string">'e'</span>]++;</span><br><span class="line">                    <span class="keyword">if</span>(i&gt;=s.size()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(amap[<span class="string">'.'</span>]||amap[<span class="string">'-'</span>]||amap[<span class="string">'+'</span>])&#123;</span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="69-Sqrt-x"><a href="#69-Sqrt-x" class="headerlink" title="69. Sqrt(x)"></a>69. Sqrt(x)</h3><p><img src="/images/leetcode/69.png" alt=""></p><p><strong>分析：</strong>这一题用二分法做比较快。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">mySqrt</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line"><span class="comment">//        int a = 0;</span></span><br><span class="line"><span class="comment">//        a = sqrt(x);</span></span><br><span class="line"><span class="comment">//        return a;</span></span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> r = x;</span><br><span class="line">        <span class="keyword">while</span>(l&lt;=r)&#123;</span><br><span class="line">            <span class="keyword">int</span> m = l+(r-l)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(m&gt;(x/m))&#123;</span><br><span class="line">                r = m<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                l = m+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> l<span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>10/3/2019</p><h3 id="54-Spiral-Matrix"><a href="#54-Spiral-Matrix" class="headerlink" title="54. Spiral Matrix"></a>54. Spiral Matrix</h3><p><img src="/images/leetcode/54.png" alt=""></p><p><strong>分析：</strong>这一题用最简单的四个循环这种思路求救最合适！然后需要注意的是，在对边界进行缩减的时候，需要保证仍然满足begin&lt;end的条件。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; spiralOrder(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(matrix.size() == <span class="number">0</span> || matrix[<span class="number">0</span>].size() == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> rowbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> rowend = matrix.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> colbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> colend = matrix[<span class="number">0</span>].size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(rowbegin&lt;=rowend&amp;&amp;colbegin&lt;=colend)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colbegin;i&lt;=colend;i++)&#123;</span><br><span class="line">                res.push_back(matrix[rowbegin][i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rowbegin++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowbegin;i&lt;=rowend;i++)&#123;</span><br><span class="line">                res.push_back(matrix[i][colend]);</span><br><span class="line">            &#125;</span><br><span class="line">            colend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend || colbegin&gt;colend) <span class="keyword">return</span> res;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colend;i&gt;=colbegin;i--)&#123;</span><br><span class="line">                res.push_back(matrix[rowend][i]);</span><br><span class="line">            &#125;</span><br><span class="line">            rowend--;</span><br><span class="line">             <span class="keyword">if</span>(rowbegin&gt;rowend || colbegin&gt;colend) <span class="keyword">return</span> res;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowend;i&gt;=rowbegin;i--)&#123;</span><br><span class="line">                res.push_back(matrix[i][colbegin]);</span><br><span class="line">            &#125;</span><br><span class="line">            colbegin++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="55-Jump-Game"><a href="#55-Jump-Game" class="headerlink" title="55. Jump Game"></a>55. Jump Game</h3><p><img src="/images/leetcode/55.png" alt=""></p><p><strong>分析：</strong>与某一题很类似，总之记住记住当前位置能达到的最远距离的方法来求解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canJump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() &lt;= <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> lastindex = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(lastindex&lt;nums.size())&#123;</span><br><span class="line">            cur = max(lastindex+nums[lastindex],cur);</span><br><span class="line">            <span class="keyword">if</span>(cur&gt;=nums.size()<span class="number">-1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(cur==lastindex &amp;&amp; nums[lastindex] == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            lastindex++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="59-Spiral-Matrix-II"><a href="#59-Spiral-Matrix-II" class="headerlink" title="59. Spiral Matrix II"></a>59. Spiral Matrix II</h3><p><img src="/images/leetcode/59.png" alt=""></p><p><strong>分析：</strong>这一题属于构造nxn的一个数组，可以按照读取的方式进行构造。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; generateMatrix(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; matrix(n,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n,<span class="number">0</span>));</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> matrix;</span><br><span class="line">        <span class="keyword">int</span> rowbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> rowend = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> colbegin = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> colend = n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(rowbegin&lt;=rowend &amp;&amp; colbegin&lt;=colend)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colbegin;i&lt;=colend;i++)&#123;</span><br><span class="line">                matrix[rowbegin][i] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            rowbegin++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowbegin;i&lt;=rowend;i++)&#123;</span><br><span class="line">                matrix[i][colend] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            colend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend)</span><br><span class="line">                <span class="keyword">return</span> matrix;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = colend;i&gt;=colbegin;i--)&#123;</span><br><span class="line">                matrix[rowend][i] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            rowend--;</span><br><span class="line">            <span class="keyword">if</span>(rowbegin&gt;rowend &amp;&amp; colbegin&gt;colend)&#123;</span><br><span class="line">                <span class="keyword">return</span> matrix;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = rowend;i&gt;=rowbegin;i--)&#123;</span><br><span class="line">                matrix[i][colbegin] = count++;</span><br><span class="line">            &#125;</span><br><span class="line">            colbegin++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> matrix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="60-Permutation-Sequence"><a href="#60-Permutation-Sequence" class="headerlink" title="60. Permutation Sequence"></a>60. Permutation Sequence</h3><p><img src="/images/leetcode/60.png" alt=""></p><p><strong>分析：</strong>递归全排列，当满足长度的个数到达k个时得到结果。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">    <span class="built_in">string</span> ans;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> n,<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(res.size() == n)&#123;</span><br><span class="line">            count++;</span><br><span class="line">            <span class="keyword">if</span>(count == k)&#123;</span><br><span class="line">                ans = res;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(count!=k)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(visit[i]==<span class="number">1</span>) <span class="keyword">continue</span>;</span><br><span class="line">                res += to_string(i);</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                dfs(n,k);</span><br><span class="line">                res = res.substr(<span class="number">0</span>,res.size()<span class="number">-1</span>);</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">getPermutation</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">         visit = <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n+<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line">        dfs(n,k);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="61-Rotate-List"><a href="#61-Rotate-List" class="headerlink" title="61. Rotate List"></a>61. Rotate List</h3><p><img src="/images/leetcode/61.png" alt=""></p><p><strong>分析：</strong>这题需要处理掉循环插的情况，即取模即可。然后就是正常的链表。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">rotateRight</span><span class="params">(ListNode* head, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>||head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        <span class="keyword">int</span> n = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">auto</span>  p = head;</span><br><span class="line">        <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            n++;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        k = k%n;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>) <span class="keyword">return</span> head;</span><br><span class="line">        p = head;</span><br><span class="line">        <span class="keyword">while</span>(n - k <span class="number">-1</span> &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            k++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> q = p-&gt;next;</span><br><span class="line">        <span class="keyword">auto</span> ans = q;</span><br><span class="line">        p-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">while</span>(q-&gt;next!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            q = q-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        q-&gt;next = head;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="70-Climbing-Stairs"><a href="#70-Climbing-Stairs" class="headerlink" title="70. Climbing Stairs"></a>70. Climbing Stairs</h3><p><img src="/images/leetcode/70.png" alt=""></p><p><strong>分析：</strong>动态规划法求解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n,<span class="number">0</span>);</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[i] = dp[i<span class="number">-1</span>]+dp[i<span class="number">-2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>7/3/2019</p><p>不知道为什么漏了6号，我明明都有做🐸</p><h3 id="51-N-Queens"><a href="#51-N-Queens" class="headerlink" title="51. N-Queens"></a>51. N-Queens</h3><p><img src="/images/leetcode/51.png" alt=""></p><p>N皇后递归最经典的问题，我觉得我在求解递归的问题的时候思路不是很清晰，总是做的不好，有必要总结一下。</p><h4 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h4><p>递归就是你需要确定一个循环机制，然后每次递归需要进行标记（不标记的话每次都执行一样的东西了），当然是根据条件进行标记的。因此对于递归的条件判断也需要十分注意，每次递归结束需要释放掉当前状况所添加的约束。</p><ol><li>定义约束变量，比如visit矩阵用于判断是否遍历过</li><li>确定主循环，主循环指需要对所有的子问题进行完整解析</li><li>将当情况的约束加到visit上，进行递归</li><li>确定递归返回条件，比如temp.size()&gt;=n</li><li>结束递归将当前约束释放掉</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//回溯法</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; res;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; visit;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; temp,<span class="keyword">int</span> pos,<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == n)&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(pos&gt;=n) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="function"><span class="built_in">string</span> <span class="title">s</span><span class="params">(n,<span class="string">'.'</span>)</span></span>;</span><br><span class="line">            <span class="keyword">if</span>(pos == <span class="number">0</span>)&#123;</span><br><span class="line">                s[i] = <span class="string">'Q'</span>;</span><br><span class="line">                temp.push_back(s);</span><br><span class="line">                visit[pos][i] = <span class="number">1</span>;</span><br><span class="line">                dfs(temp,pos+<span class="number">1</span>,n);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">                visit[pos][i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>((i==<span class="number">0</span>||visit[pos<span class="number">-1</span>][i<span class="number">-1</span>]!=<span class="number">1</span>)&amp;&amp;</span><br><span class="line">                    (i+<span class="number">1</span>==n||visit[pos<span class="number">-1</span>][i+<span class="number">1</span>]!=<span class="number">1</span>))&#123;</span><br><span class="line">                <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[j][i] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">int</span> tempi = i<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">int</span> tempj = pos<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&gt;=<span class="number">0</span>&amp;&amp;tempi&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj--][tempi--] == <span class="number">1</span>)&#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i+<span class="number">1</span>;</span><br><span class="line">                tempj = pos+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&lt;n&amp;&amp;tempi&lt;n)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj++][tempi++] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i+<span class="number">1</span>;</span><br><span class="line">                tempj = pos<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&gt;=<span class="number">00</span>&amp;&amp;tempi&lt;n)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj--][tempi++] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                tempi = i<span class="number">-1</span>;</span><br><span class="line">                tempj = pos+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">while</span>(tempj&lt;n&amp;&amp;tempi&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(visit[tempj++][tempi--] == <span class="number">1</span>) &#123;flag = <span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;</span><br><span class="line">                    s[i] = <span class="string">'Q'</span>;</span><br><span class="line">                    temp.push_back(s);</span><br><span class="line">                    visit[pos][i] = <span class="number">1</span>;</span><br><span class="line">                    dfs(temp,pos+<span class="number">1</span>,n);</span><br><span class="line">                    temp.pop_back();</span><br><span class="line">                    visit[pos][i] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; solveNQueens(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;=<span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        visit = <span class="built_in">vector</span>(n,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n,<span class="number">0</span>));</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; temp;</span><br><span class="line">        dfs(temp,<span class="number">0</span>,n);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="206-Reverse-Linked-List"><a href="#206-Reverse-Linked-List" class="headerlink" title="206. Reverse Linked List"></a>206. Reverse Linked List</h3><p>递归题</p><p><img src="/images/leetcode/206.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">reverseList</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>||head-&gt;next == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* p = head-&gt;next;</span><br><span class="line">        ListNode* q = head;</span><br><span class="line">        q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">while</span>(p)&#123;</span><br><span class="line">            <span class="keyword">auto</span> temp = p-&gt;next;</span><br><span class="line">            p-&gt;next = q;</span><br><span class="line">            q = p;</span><br><span class="line">            p = temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> q;</span><br><span class="line">        <span class="comment">//递归做法，先将所有的节点打散，然后从最后一个慢慢往前连接</span></span><br><span class="line"><span class="comment">/*        if(head==NULL||head-&gt;next == NULL) return head;</span></span><br><span class="line"><span class="comment">        auto last = head-&gt;next;</span></span><br><span class="line"><span class="comment">        head-&gt;next = NULL;</span></span><br><span class="line"><span class="comment">        ListNode* newhead = reverseList(last);</span></span><br><span class="line"><span class="comment">        last-&gt;next = head;</span></span><br><span class="line"><span class="comment">        return newhead;*/</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="226-Invert-Binary-Tree"><a href="#226-Invert-Binary-Tree" class="headerlink" title="226. Invert Binary Tree"></a>226. Invert Binary Tree</h3><p><img src="/images/leetcode/226.png" alt=""></p><p><strong>分析：</strong>在每一次递归时进行左右交换。树的遍历方式算是递归的一种。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">TreeNode* <span class="title">invertTree</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">auto</span> p = root-&gt;left;</span><br><span class="line">        root-&gt;left = root-&gt;right;</span><br><span class="line">        root-&gt;right = p;</span><br><span class="line">        invertTree(root-&gt;left);</span><br><span class="line">        invertTree(root-&gt;right);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="104-Maximum-Depth-of-Binary-Tree"><a href="#104-Maximum-Depth-of-Binary-Tree" class="headerlink" title="104. Maximum Depth of Binary Tree"></a>104. Maximum Depth of Binary Tree</h3><p><img src="/images/leetcode/104.png" alt=""></p><p><strong>分析：</strong>每一次进步一个深度，然后如果为零返回。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> maxn = <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode* root,<span class="keyword">int</span> level)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">        dfs(root-&gt;left,level+<span class="number">1</span>);</span><br><span class="line">        dfs(root-&gt;right,level+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span>(maxn&lt;level) maxn = level;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        dfs(root,<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>5/3/2019</p><h3 id="49-Group-Anagrams"><a href="#49-Group-Anagrams" class="headerlink" title="49. Group Anagrams"></a>49. Group Anagrams</h3><p><img src="/images/leetcode/49.png" alt="49"></p><p><strong>分析：</strong>这道题使用哈希表来解决，记录是否有相同的元素被访问过。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; groupAnagrams(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; strs) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(strs.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; amap;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;strs.size();i++)&#123;</span><br><span class="line">            <span class="keyword">auto</span> temp = strs[i];</span><br><span class="line">            sort(temp.begin(),temp.end());</span><br><span class="line">            <span class="keyword">if</span>(amap.count(temp) == <span class="number">0</span>)&#123;</span><br><span class="line">                amap[temp] = res.size();</span><br><span class="line">                <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; a;</span><br><span class="line">                a.push_back(strs[i]);</span><br><span class="line">                res.push_back(a);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res[amap[temp]].push_back(strs[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="82-Remove-Duplicates-from-Sorted-List-II"><a href="#82-Remove-Duplicates-from-Sorted-List-II" class="headerlink" title="82. Remove Duplicates from Sorted List II"></a>82. Remove Duplicates from Sorted List II</h3><p><img src="/images/leetcode/82.png" alt=""></p><p><strong>分析：</strong>这一题的思路其实很简单，就是当你要删除一个数的时候，你应该保证目前的指针指向要删除的数的前一个,因此需要保证next和next之后的数都不为空。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">deleteDuplicates</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* dummy = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        dummy-&gt;next = head;</span><br><span class="line">        <span class="keyword">auto</span> p = dummy;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next &amp;&amp; p-&gt;next-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val == p-&gt;next-&gt;next-&gt;val)&#123;</span><br><span class="line">                <span class="keyword">int</span> same = p-&gt;next-&gt;val;</span><br><span class="line">                <span class="keyword">while</span>(p-&gt;next&amp;&amp;p-&gt;next-&gt;val == same)&#123;</span><br><span class="line">                    p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dummy-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="83-Remove-Duplicates-from-Sorted-List"><a href="#83-Remove-Duplicates-from-Sorted-List" class="headerlink" title="83. Remove Duplicates from Sorted List"></a>83. Remove Duplicates from Sorted List</h3><p><img src="/images/leetcode/83.png" alt=""></p><p><strong>分析：</strong>这一题比较好做，唯一要注意的是不要判断p不为空。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">deleteDuplicates</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        <span class="keyword">auto</span> p = head;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val == p-&gt;val)&#123;</span><br><span class="line">               p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> p = p-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="86-Partition-List"><a href="#86-Partition-List" class="headerlink" title="86. Partition List"></a>86. Partition List</h3><p><img src="/images/leetcode/86.png" alt=""></p><p><strong>分析：</strong>我发现我链表的题做得还行。这一题思路是先走到链表尾巴，然后遇到比目标大的数，就截取下来放到最后。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">partition</span><span class="params">(ListNode* head, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        ListNode* dummy = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        dummy-&gt;next = head;</span><br><span class="line">        <span class="keyword">auto</span> p = dummy;</span><br><span class="line">        <span class="keyword">auto</span> q = head;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(p-&gt;next)&#123;</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">        q = p;</span><br><span class="line">        p = dummy;</span><br><span class="line">        <span class="keyword">while</span>(count)&#123;</span><br><span class="line">            count--;</span><br><span class="line">            <span class="keyword">if</span>(p-&gt;next-&gt;val &lt; x)&#123;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                q-&gt;next = p-&gt;next;</span><br><span class="line">                p-&gt;next = p-&gt;next-&gt;next;</span><br><span class="line">                q = q-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> dummy-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="87-Scramble-String"><a href="#87-Scramble-String" class="headerlink" title="87. Scramble String"></a>87. Scramble String</h3><p><img src="/images/leetcode/87.png" alt=""></p><p><strong>分析：</strong>这一题用递归的方法做，感觉所有用递归的方法其实都是最耗时的方法，更好的方法可能是动态规划方法。总之递归之后应该有一个动归才是。然后基本思路是做两次判断，第一次两个串切在同一个位置上，第二次在首尾位置上。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isScramble</span><span class="params">(<span class="built_in">string</span> s1, <span class="built_in">string</span> s2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s1.size()==<span class="number">0</span>||s2.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(s1 == s2) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; letters(<span class="number">26</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s1.size();i++)&#123;</span><br><span class="line">            letters[s1[i]-<span class="string">'a'</span>]++;</span><br><span class="line">            letters[s2[i]-<span class="string">'a'</span>]--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">26</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(letters[i]!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;s1.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(isScramble(s1.substr(<span class="number">0</span>,i),s2.substr(<span class="number">0</span>,i))&amp;&amp;</span><br><span class="line">              isScramble(s1.substr(i),s2.substr(i))) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(isScramble(s1.substr(<span class="number">0</span>,i),s2.substr(s1.size()-i))&amp;&amp;</span><br><span class="line">              isScramble(s1.substr(i),s2.substr(<span class="number">0</span>,s1.size()-i))) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>4/3/2019</p><h3 id="46-Permutations"><a href="#46-Permutations" class="headerlink" title="46. Permutations"></a>46. Permutations</h3><p><img src="/images/leetcode/46.png" alt=""><br><strong>分析：</strong>这一题是典型的排列问题，用递归的方式完成，然后用一个数组来标记当前的位置是否被读取过。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == nums.size())&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(visit[i] == <span class="number">0</span>)&#123;</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                temp.push_back(nums[i]);</span><br><span class="line">                dfs(nums,visit,temp);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; permute(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit(nums.size(),<span class="number">0</span>);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        dfs(nums,visit,temp);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="47-Permutations-II"><a href="#47-Permutations-II" class="headerlink" title="47. Permutations II"></a>47. Permutations II</h3><p><img src="/images/leetcode/47.png" alt=""><br><strong>分析：</strong>这一题与上一题的一个改善是，有重复的数，去重复的一个方法是对数组排序，如果当前的元素与上一个元素相同，并且上一个元素没有被访问过（意味着上一个元素曾经在这个位置上），直接跳过这个位置进入下一个位置。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//  set&lt;vector&lt;int&gt;&gt; res;</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(temp.size() == nums.size())&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(visit[i] == <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i<span class="number">-1</span>] == nums[i]&amp;&amp;visit[i<span class="number">-1</span>] == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                temp.push_back(nums[i]);</span><br><span class="line">                visit[i] = <span class="number">1</span>;</span><br><span class="line">                dfs(nums,visit,temp);</span><br><span class="line">                visit[i] = <span class="number">0</span>;</span><br><span class="line">                temp.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; permuteUnique(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; visit(nums.size(),<span class="number">0</span>);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        dfs(nums,visit,temp);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="45-Jump-Game-II"><a href="#45-Jump-Game-II" class="headerlink" title="45. Jump Game II"></a>45. Jump Game II</h3><p><img src="/images/leetcode/45.png" alt=""><br><strong>分析：</strong>这一题用动态规划或者greedy来做，具体看代码即可。dp中对i之前每个位置进行判断，时间复杂度为$O(n^2)$ , greedy中cur指当前能到最远位置，last指上一步能到最远位置。然后需要排除掉一步不走的情况。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="comment">/*    int jump(vector&lt;int&gt;&amp; nums) &#123;</span></span><br><span class="line"><span class="comment">        if(nums.size() == 0) return 0;</span></span><br><span class="line"><span class="comment">        vector&lt;int&gt; dp(nums.size(),INT_MAX);</span></span><br><span class="line"><span class="comment">        dp[0] = 0;</span></span><br><span class="line"><span class="comment">        for(int i = 0;i&lt;nums.size() ;i++)&#123;</span></span><br><span class="line"><span class="comment">            for(int j = 0;j&lt;i;j++)&#123;</span></span><br><span class="line"><span class="comment">                if(nums[j]&gt;=i-j)&#123; </span></span><br><span class="line"><span class="comment">                    dp[i] = min(dp[i],dp[j]+1);</span></span><br><span class="line"><span class="comment">                &#125;</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return dp[nums.size()-1];</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">jump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> last = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size()<span class="number">-1</span> ;i++)&#123;</span><br><span class="line">            cur = max(cur,i+nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(i == last)&#123;</span><br><span class="line">                last = cur;</span><br><span class="line">                res++;</span><br><span class="line">                <span class="keyword">if</span>(last&gt;=nums.size()<span class="number">-1</span>) <span class="keyword">return</span> res;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="50-Pow-x-n"><a href="#50-Pow-x-n" class="headerlink" title="50. Pow(x, n)"></a>50. Pow(x, n)</h3><p><img src="/images/leetcode/50.png" alt=""><br><strong>分析：</strong>由于指数乘法可以由比他小的指数乘起来得到，一次可以用分治法来做。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">myPow</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">int</span> n1)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n1 == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1.0</span>;</span><br><span class="line">        <span class="keyword">if</span>(n1 == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> n = n1;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;<span class="number">0</span>)&#123;</span><br><span class="line">            n = -n;</span><br><span class="line">            x = <span class="number">1.0</span>/x;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">double</span> res = myPow(x,n/<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span>(n%<span class="number">2</span> == <span class="number">0</span>) <span class="keyword">return</span> res*res;</span><br><span class="line">        <span class="keyword">return</span> res*res*x;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>3/3/2019</p><h3 id="40-Combination-Sum-II"><a href="#40-Combination-Sum-II" class="headerlink" title="40. Combination Sum II"></a>40. Combination Sum II</h3><p><img src="/images/leetcode/40.png" alt=""><br><strong>分析：</strong>这一题用递归来求解，对于重复的问题，在执行一次递归之后，对重复的元素进行排除。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; candidates,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp,<span class="keyword">int</span> target,<span class="keyword">int</span> pos)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target == <span class="number">0</span>)&#123;</span><br><span class="line">            res.push_back(temp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = pos;i&lt;candidates.size()&amp;&amp;target&gt;=candidates[i];i++)&#123;</span><br><span class="line">            temp.push_back(candidates[i]); </span><br><span class="line">            dfs(candidates,temp,target-candidates[i],i+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">while</span>(i+<span class="number">1</span>&lt;candidates.size()&amp;&amp;candidates[i] == candidates[i+<span class="number">1</span>]) i++;</span><br><span class="line">            temp.pop_back();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum2(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">if</span>(candidates.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        sort(candidates.begin(),candidates.end());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        dfs(candidates,temp,target,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="42-Trapping-Rain-Water"><a href="#42-Trapping-Rain-Water" class="headerlink" title="42. Trapping Rain Water"></a>42. Trapping Rain Water</h3><p><img src="/images/leetcode/42.png" alt=""><br><strong>分析：</strong>这一题之前做过，思路就是用两个数组，从左到右记录最大的val，从右到左记住最大的val，然后水坑的值就等于三个数组相减。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">trap</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(height.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; left(height.size());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; right(height.size());</span><br><span class="line">        left[<span class="number">0</span>] = height[<span class="number">0</span>];</span><br><span class="line">        right[height.size()<span class="number">-1</span>] = height[height.size()<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;height.size();i++)&#123;</span><br><span class="line">            left[i] = max(left[i<span class="number">-1</span>],height[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = height.size()<span class="number">-2</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">            right[i] = max(right[i+<span class="number">1</span>],height[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;height.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = min(left[i],right[i])-height[i];</span><br><span class="line">            <span class="keyword">if</span>(temp&gt;<span class="number">0</span>) res += temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="44-Wildcard-Matching"><a href="#44-Wildcard-Matching" class="headerlink" title="44. Wildcard Matching"></a>44. Wildcard Matching</h3><p><img src="/images/leetcode/44.png" alt=""><br><strong>分析：</strong>字符串匹配问题多可以用动态规划来求解，思考动态规划问题的时候不要想太多步。就想着当前这一步有多少种情况就可以了。同时需要注意边界问题。<br>递推情况如下：<br>当<code>p[j] = &#39;*&#39;</code>:</p><ul><li>s[i-1]和p[j-1]进行匹配，s[i]和p[j]进行匹配。此时考虑*表示1个字符。</li><li>s[i-1]已经和p[j]进行了匹配，s[i]也仍然和p[j]进行匹配。此时考虑*表示n个字符。</li><li>s[i]和p[j - 1]进行了匹配，此时考虑*表示0个字符。</li></ul><p>当<code>p[j] = &#39;?&#39;</code>等：<br>p[j-1]与s[i-1]进行匹配，p[j],s[i]匹配。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = s.size(),n = p.size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(m+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(n+<span class="number">1</span>,<span class="literal">false</span>));</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(p[i<span class="number">-1</span>] == <span class="string">'*'</span>) dp[<span class="number">0</span>][i] = dp[<span class="number">0</span>][i<span class="number">-1</span>]; <span class="comment">// s为空，p为连续* 号</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j&lt;=n;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(p[j<span class="number">-1</span>] == <span class="string">'*'</span>)&#123;</span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j]||dp[i][j<span class="number">-1</span>]||dp[i<span class="number">-1</span>][j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(p[j<span class="number">-1</span>] == <span class="string">'?'</span>||p[j<span class="number">-1</span>] == s[i<span class="number">-1</span>])&#123;</span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m][n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="67-Add-Binary"><a href="#67-Add-Binary" class="headerlink" title="67. Add Binary"></a>67. Add Binary</h3><p><img src="/images/leetcode/67.png" alt=""><br><strong>分析：</strong>做过类似的面试题，然后思路就是这样没错了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">addBinary</span><span class="params">(<span class="built_in">string</span> a, <span class="built_in">string</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = a.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> m = b.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> add = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;=<span class="number">0</span>&amp;&amp;m&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> le = a[n] - <span class="string">'0'</span>;</span><br><span class="line">            <span class="keyword">int</span> ri = b[m] - <span class="string">'0'</span>;</span><br><span class="line">            <span class="keyword">if</span>(le+ri+add&gt;=<span class="number">2</span>)&#123;</span><br><span class="line">                res = to_string(le+ri+add <span class="number">-2</span>) + res;</span><br><span class="line">                add = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res = to_string(le+ri+add) + res;</span><br><span class="line">                add = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            n--;</span><br><span class="line">            m--;</span><br><span class="line">        &#125;</span><br><span class="line">        res = (n&gt;=<span class="number">0</span>? a.substr(<span class="number">0</span>,n+<span class="number">1</span>):b.substr(<span class="number">0</span>,m+<span class="number">1</span>)) + res;</span><br><span class="line">        <span class="keyword">if</span>(add == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> left = n&gt;=<span class="number">0</span>? n:m;</span><br><span class="line">        <span class="keyword">while</span>(left&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(res[left] == <span class="string">'0'</span>)&#123;</span><br><span class="line">                res[left] = <span class="string">'1'</span>;</span><br><span class="line">                <span class="keyword">return</span> res;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res[left] = <span class="string">'0'</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            left--;</span><br><span class="line">        &#125;</span><br><span class="line">        res = <span class="string">'1'</span>+ res;</span><br><span class="line">        <span class="keyword">return</span> res;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>2/3/2019</p><h3 id="32-Longest-Valid-Parentheses"><a href="#32-Longest-Valid-Parentheses" class="headerlink" title="32. Longest Valid Parentheses"></a>32. Longest Valid Parentheses</h3><p><img src="/images/leetcode/32.png" alt=""><br><strong>分析：</strong>这一题括号匹配，用栈的结构来解决，每次将括号的下标存入栈的结构中。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestValidParentheses</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxn = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; sta;</span><br><span class="line">        sta.push(<span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s[i] == <span class="string">'('</span>)&#123;</span><br><span class="line">                sta.push(i);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                sta.pop();</span><br><span class="line">                <span class="keyword">if</span>(!sta.empty())</span><br><span class="line">                maxn = max(maxn,i-sta.top());</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    sta.push(i);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="34-Find-First-and-Last-Position-of-Element-in-Sorted-Array"><a href="#34-Find-First-and-Last-Position-of-Element-in-Sorted-Array" class="headerlink" title="34. Find First and Last Position of Element in Sorted Array"></a>34. Find First and Last Position of Element in Sorted Array</h3><p><img src="/images/leetcode/34.png" alt=""><br>这一题题目要求复杂度是O(log(n)) 很显然就是用二分法来做的，然后如果找到了target，就往target的两边去找相同的元素。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; searchRange(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res = &#123;<span class="number">-1</span>,<span class="number">-1</span>&#125;;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> high = nums.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> mid;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;=high)&#123;</span><br><span class="line">            mid = (low+high)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] == target) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;target)&#123;</span><br><span class="line">                high = mid<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                low = mid+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(low&gt;high) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(i = mid<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] != target) &#123;<span class="keyword">break</span>;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res[<span class="number">0</span>] = i+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(i = mid + <span class="number">1</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=target) &#123; <span class="keyword">break</span>;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res[<span class="number">1</span>] = i<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="36-Valid-Sudoku"><a href="#36-Valid-Sudoku" class="headerlink" title="36. Valid Sudoku"></a>36. Valid Sudoku</h3><p><img src="/images/leetcode/36.png" alt=""><br><strong>分析：</strong>判断横排，竖排，里头九宫格即可。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isValidSudoku</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt;&amp; board)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(board.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//横排</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap.count(board[i][j]) != <span class="number">0</span> &amp;&amp;board[i][j]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                amap[board[i][j]] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//竖排</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(amap.count(board[j][i])!=<span class="number">0</span>&amp;&amp;board[j][i]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                amap[board[j][i]] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//九宫格</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">9</span>;i += <span class="number">3</span>)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;<span class="number">9</span>;j+=<span class="number">3</span>)&#123;</span><br><span class="line">                <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; amap; </span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> h = i;h&lt;i+<span class="number">3</span>;h++)&#123;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> k = j;k&lt;j+<span class="number">3</span>;k++)&#123;</span><br><span class="line">                        <span class="keyword">if</span>(amap.count(board[h][k])!=<span class="number">0</span>&amp;&amp;board[h][k]!=<span class="string">'.'</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                        amap[board[h][k]] = <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="39-Combination-Sum"><a href="#39-Combination-Sum" class="headerlink" title="39. Combination Sum"></a>39. Combination Sum</h3><p><img src="/images/leetcode/39.png" alt=""><br><strong>分析：</strong>经典的一道递归题，下次一定要会做才行，因为最基本的递归就长这个样子。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">digui</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates,<span class="keyword">int</span> target,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp,<span class="keyword">int</span> pos)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target == <span class="number">0</span>) res.push_back(temp);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = pos;i&lt;candidates.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(target&gt;=candidates[i])&#123;</span><br><span class="line">                temp.push_back(candidates[i]);</span><br><span class="line">                digui(candidates,target-candidates[i],temp,i);</span><br><span class="line">                temp.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">if</span>(candidates.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">        digui(candidates,target,temp,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>1/3/2019</p><h3 id="38-Count-and-Say"><a href="#38-Count-and-Say" class="headerlink" title="38. Count and Say"></a>38. Count and Say</h3><p><img src="/images/leetcode/38.png" alt=""><br><strong>分析：</strong>这一题是递归的题，出口是n = 0 或 1，然后用for循环判断当前生成的字符。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">countAndSay</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>) <span class="keyword">return</span> <span class="string">"1"</span>;</span><br><span class="line">        <span class="built_in">string</span> s = countAndSay(n<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">string</span> newS = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">while</span>(i+<span class="number">1</span>&lt;s.size()&amp;&amp;s[i] == s[i+<span class="number">1</span>])&#123;</span><br><span class="line">                count++;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            newS += to_string(count) + s[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newS;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>2/28/2019</p><h3 id="30-Substring-with-Concatenation-of-All-Words"><a href="#30-Substring-with-Concatenation-of-All-Words" class="headerlink" title="30. Substring with Concatenation of All Words"></a>30. Substring with Concatenation of All Words</h3><p><img src="/images/leetcode/30.png" alt=""><br><strong>分析：</strong>控制一个words的所有字符长度的子串，然后在子串里面看是否满足条件。用hash_map做。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; findSubstring(<span class="built_in">string</span> s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; words) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(s.empty()||words.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">int</span> m = words[<span class="number">0</span>].size();</span><br><span class="line">        <span class="keyword">int</span> n = words.size();</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; m1;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;words.size();i++)&#123;</span><br><span class="line">            ++m1[words[i]];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;=(<span class="keyword">int</span>)s.size()-m*n;i++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;s.size();</span><br><span class="line">            <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt; m2;</span><br><span class="line">            <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(;j&lt;words.size();j++)&#123;</span><br><span class="line">                <span class="built_in">string</span> t = s.substr(i+j*m,m);</span><br><span class="line">                <span class="keyword">if</span>(m1.find(t) == m1.end()) <span class="keyword">break</span>;</span><br><span class="line">                ++m2[t];</span><br><span class="line">                <span class="keyword">if</span>(m2[t]&gt;m1[t]) <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(j == words.size()) res.push_back(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>2/26/2019</p><h3 id="53-Maximum-Subarray"><a href="#53-Maximum-Subarray" class="headerlink" title="53. Maximum Subarray"></a>53. Maximum Subarray</h3><p><img src="/images/leetcode/53.png" alt=""><br><strong>分析：</strong>这一题时简单的DP问题，用一个数存之前的序列和，当和小于0时则清零。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxn = INT_MIN;</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(ans&lt;<span class="number">0</span>) ans = <span class="number">0</span>;</span><br><span class="line">            ans += nums[i];</span><br><span class="line">            maxn = max(maxn,ans);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="15-3Sum"><a href="#15-3Sum" class="headerlink" title="15. 3Sum"></a>15. 3Sum</h3><p><img src="/images/leetcode/15.png" alt=""></p><p><strong>分析：</strong>这一题要找出所有的相加为0的组合，可以定义三个变量，用来控制数组中相加的数字，一个数字控制外循环，里头两个数字当遇到与前一个相同时，需要跳过。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; threeSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> res; </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> begin = i+<span class="number">1</span>,end = nums.size()<span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i<span class="number">-1</span>]==nums[i]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">while</span>(begin&lt;end)&#123;</span><br><span class="line">                <span class="keyword">int</span> result = nums[i]+nums[end]+nums[begin];</span><br><span class="line">                <span class="keyword">if</span>(i!=end&amp;&amp; result == <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp = &#123;nums[i],nums[begin],nums[end]&#125;;</span><br><span class="line">                    res.push_back(temp);</span><br><span class="line">                    end--;</span><br><span class="line">                    <span class="keyword">while</span>(end&gt;=<span class="number">0</span>&amp;&amp;nums[end+<span class="number">1</span>] == nums[end]) end--;</span><br><span class="line">                    begin++;</span><br><span class="line">                    <span class="keyword">while</span>(begin&lt;nums.size()&amp;&amp;nums[begin<span class="number">-1</span>] == nums[begin]) begin++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(i==end||result&gt;<span class="number">0</span>) end--;</span><br><span class="line">                <span class="keyword">else</span> begin++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="16-3Sum-Closest"><a href="#16-3Sum-Closest" class="headerlink" title="16. 3Sum Closest"></a>16. 3Sum Closest</h3><p><img src="/images/leetcode/16.png" alt=""><br>这一题是上一题的变形，省去了判断过滤重复的步骤，只要求一个绝对值最接近1就好。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">threeSumClosest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = INT_MAX;</span><br><span class="line">        <span class="keyword">int</span> ans;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> j = i+<span class="number">1</span>,k = nums.size()<span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">while</span>(j&lt;k)&#123;</span><br><span class="line">                <span class="keyword">int</span> result = nums[i]+nums[j]+nums[k];</span><br><span class="line">                <span class="keyword">if</span>(i!=k&amp;&amp;<span class="built_in">abs</span>(result-target)&lt;=sum)&#123;</span><br><span class="line">                    sum = <span class="built_in">abs</span>(result-target);</span><br><span class="line">                    ans = result;</span><br><span class="line">                    <span class="keyword">if</span>(result&lt;target)j++;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(result&gt;target) k--;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(result&gt;target) k--;</span><br><span class="line">                <span class="keyword">else</span> j++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="17-Letter-Combinations-of-a-Phone-Number"><a href="#17-Letter-Combinations-of-a-Phone-Number" class="headerlink" title="17. Letter Combinations of a Phone Number"></a>17. Letter Combinations of a Phone Number</h3><p><img src="/images/leetcode/17.png" alt=""><br>这一题比较简单，把存结果的数组当作栈来用就行了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; letterCombinations(<span class="built_in">string</span> digits) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(digits.size() == <span class="number">0</span>) <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;&gt; alphabet = &#123;</span><br><span class="line">            &#123;&#125;, &#123;&#125;,&#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>&#125;,&#123;<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>&#125;,&#123;<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>&#125;,&#123;<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>&#125;,&#123;<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>&#125;,&#123;<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>&#125;,&#123;<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>&#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; tem(alphabet[digits[<span class="number">0</span>]-<span class="string">'0'</span>]);</span><br><span class="line">        <span class="built_in">string</span> a =<span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;tem.size();i++)&#123;</span><br><span class="line">             a += tem[i];</span><br><span class="line">             res.push_back(a);</span><br><span class="line">             a = <span class="string">""</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;digits.size();i++)&#123;</span><br><span class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; te(alphabet[digits[i]-<span class="string">'0'</span>]);</span><br><span class="line">            <span class="keyword">int</span> resSize = res.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j&lt;resSize;j++)&#123;</span><br><span class="line">                <span class="built_in">string</span> ahead = res[<span class="number">0</span>];</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>;k&lt;te.size();k++)&#123;</span><br><span class="line">                    res.push_back(ahead+te[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                res.erase(res.begin());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="18-4Sum"><a href="#18-4Sum" class="headerlink" title="18. 4Sum"></a>18. 4Sum</h3><p><img src="/images/leetcode/18.png" alt=""><br><strong>分析：</strong>这一题是前面三个数的加强版，注意一些重复的判断就行了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; fourSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() &lt; <span class="number">4</span>) <span class="keyword">return</span> res;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums[i] == nums[i<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i+<span class="number">1</span>;j&lt;nums.size();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j&gt;i+<span class="number">1</span>&amp;&amp;nums[j] == nums[j<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">int</span> begin = j+<span class="number">1</span>,end = nums.size()<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">while</span>(begin&lt;end)&#123;</span><br><span class="line">                    <span class="keyword">int</span> result = nums[i]+nums[j]+nums[begin]+nums[end];</span><br><span class="line">                    <span class="keyword">if</span>(result == target)&#123;</span><br><span class="line">                        res.push_back(&#123;nums[i],nums[j],nums[begin],nums[end]&#125;);</span><br><span class="line">                        begin++;</span><br><span class="line">                        end--;</span><br><span class="line">                        <span class="keyword">while</span>(end&gt;begin&amp;&amp;nums[end] == nums[end+<span class="number">1</span>]) end--;</span><br><span class="line">                        <span class="keyword">while</span>(begin&lt;end&amp;&amp;nums[begin<span class="number">-1</span>] == nums[begin]) begin++;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(result &gt; target) end--;</span><br><span class="line">                    <span class="keyword">else</span> begin++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="19-Remove-Nth-Node-From-End-of-List"><a href="#19-Remove-Nth-Node-From-End-of-List" class="headerlink" title="19. Remove Nth Node From End of List"></a>19. Remove Nth Node From End of List</h3><p><img src="/images/leetcode/19.png" alt=""><br><strong>分析：</strong>这一题要求执行一趟，删除掉倒数第n个节点。可以用两个指针来完成，第一个指针领先第二个指针n的位置，当第一个指针到达终点时，第二个指针的位置就是倒数n的位置。然后需要注意删除第一个元素的情况。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">removeNthFromEnd</span><span class="params">(ListNode* head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        ListNode* pre = head;</span><br><span class="line">        ListNode* last = head;</span><br><span class="line">        ListNode* pos = head;</span><br><span class="line">        <span class="keyword">while</span>(n--)&#123;</span><br><span class="line">            pos = pos-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(pos == <span class="literal">NULL</span>) <span class="keyword">return</span> head-&gt;next; <span class="comment">//当删除第一个元素时</span></span><br><span class="line">        <span class="keyword">while</span>(pos!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            pre = last;</span><br><span class="line">            last = last-&gt;next;</span><br><span class="line">            pos = pos-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        pre-&gt;next = last-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="22-Generate-Parentheses"><a href="#22-Generate-Parentheses" class="headerlink" title="22. Generate Parentheses"></a>22. Generate Parentheses</h3><p><img src="/images/leetcode/22.png" alt=""><br><strong>分析：</strong>这是一道很经典的递归的题目，我做出一道就有感觉了。就是说看递归一定是这一步做了某种选择，待会还要回来。而且要比较注重递归程序的出口。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> nn;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ans;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">digui</span><span class="params">(<span class="built_in">string</span> res,<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(res.size() == <span class="number">2</span>*nn)&#123; ans.push_back(res);<span class="keyword">return</span>;&#125;</span><br><span class="line">        <span class="keyword">if</span>(left&lt;nn)  digui(res+<span class="string">"("</span>,left+<span class="number">1</span>,right);</span><br><span class="line">        <span class="keyword">if</span>(right&lt;nn&amp;&amp;right&lt;left) digui(res+<span class="string">")"</span>,left,right+<span class="number">1</span>);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; generateParenthesis(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> ans;</span><br><span class="line">        nn = n;</span><br><span class="line">        digui(<span class="string">""</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="24-Swap-Nodes-in-Pairs"><a href="#24-Swap-Nodes-in-Pairs" class="headerlink" title="24. Swap Nodes in Pairs"></a>24. Swap Nodes in Pairs</h3><p><img src="/images/leetcode/24.png" alt=""><br>调换两个数，需要三个指针，然后注意特殊情况只有一个数的时候的。直接放回head。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">swapPairs</span><span class="params">(ListNode* head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        ListNode* pre = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        ListNode* first = head;</span><br><span class="line">        ListNode* second = head-&gt;next;</span><br><span class="line">        pre-&gt;next = head;</span><br><span class="line">        <span class="keyword">if</span>(second == <span class="literal">NULL</span>) <span class="keyword">return</span> head;</span><br><span class="line">        head = second;</span><br><span class="line">        <span class="keyword">while</span>(second != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            pre-&gt;next = second;</span><br><span class="line">            first-&gt;next = second-&gt;next;</span><br><span class="line">            second-&gt;next = first;</span><br><span class="line">            pre = first;</span><br><span class="line">            first = first-&gt;next;</span><br><span class="line">            <span class="keyword">if</span>(first!=<span class="literal">NULL</span>) second = first-&gt;next;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> head;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="29-Divide-Two-Integers"><a href="#29-Divide-Two-Integers" class="headerlink" title="29. Divide Two Integers"></a>29. Divide Two Integers</h3><p><img src="/images/leetcode/29.png" alt=""><br><strong>分析：</strong>这一题由于有越界问题，可以用long long申请变量，保证不会溢出。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">divide</span><span class="params">(<span class="keyword">int</span> dividend, <span class="keyword">int</span> divisors)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> divide = dividend;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> divisor = divisors;</span><br><span class="line">        <span class="keyword">if</span>(divisor == <span class="number">0</span>) <span class="keyword">return</span> divide;</span><br><span class="line">        <span class="keyword">int</span> sign = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(divisor&lt;<span class="number">0</span>) sign = <span class="number">-1</span>,divisor *= <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">if</span>(divide&lt;<span class="number">0</span>) sign *= <span class="number">-1</span>,divide *= <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">long</span> time = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(divide&gt;=divisor)&#123;</span><br><span class="line">            time++;</span><br><span class="line">            divide -= divisor;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(time*sign&gt;INT_MAX) <span class="keyword">return</span> INT_MAX;</span><br><span class="line">        <span class="keyword">if</span>(time*sign&lt;INT_MIN) <span class="keyword">return</span> INT_MIN;</span><br><span class="line">        <span class="keyword">return</span> time*sign;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><h3 id="4-median-of-two-sorted-array"><a href="#4-median-of-two-sorted-array" class="headerlink" title="4. median of two sorted array"></a>4. median of two sorted array</h3><p><img src="/images/leetcode/4median of two sort array.png" alt=""><br><strong>分析：</strong><br>这一题要找两个排序好的数组的中位数。</p><blockquote><p>中位数有一个性质就是一定位于数列的中间位置，而且中位数左边的数都小于中位数，中位数右边的数都大于中位数</p></blockquote><p>因此我们对数组位置进行分析时，需要保持中位数位置一定为数组长度的一半，又因为这道题对两个排序好的数组寻找中位数，因此可以分别对他们使用分治法求解。<br><img src="/images/leetcode/4median_analysis.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums2)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//首先拿到数组的长度，并设置nums1的长度大于nums2</span></span><br><span class="line">        <span class="keyword">int</span> m = nums1.size();</span><br><span class="line">        <span class="keyword">int</span> n = nums2.size();</span><br><span class="line">        <span class="keyword">if</span>(m&gt;n)&#123;   </span><br><span class="line">            <span class="keyword">auto</span> temp = nums1;</span><br><span class="line">            nums1 = nums2;</span><br><span class="line">            nums2 = temp;</span><br><span class="line">            swap(n,m);</span><br><span class="line">        &#125;<span class="comment">// n &gt; m</span></span><br><span class="line">        <span class="keyword">int</span> imin = <span class="number">0</span>,imax = m,half = (m+n+<span class="number">1</span>)/<span class="number">2</span>; <span class="comment">//half保证了长度为数列的一半</span></span><br><span class="line">        <span class="comment">//接下来在nums2数组中对中位数位置进行遍历</span></span><br><span class="line">        <span class="keyword">while</span>(imin&lt;=imax)&#123;</span><br><span class="line">            <span class="keyword">int</span> i = (imax-imin)/<span class="number">2</span> + imin; <span class="comment">// seperate nums1</span></span><br><span class="line">            <span class="keyword">int</span> j = half - i; <span class="comment">// j为num2的分割点，可以看出来j为一半的长度，不是下标</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;m &amp;&amp; nums1[i]&lt;nums2[j<span class="number">-1</span>]) <span class="comment">// i is too small</span></span><br><span class="line">            &#123;</span><br><span class="line">                imin = i+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(i&gt;<span class="number">0</span>&amp;&amp;nums1[i<span class="number">-1</span>]&gt;nums2[j])&#123; <span class="comment">// i is to big</span></span><br><span class="line">                imax = i<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;  <span class="comment">// ferfect</span></span><br><span class="line">                <span class="keyword">int</span> max_left,min_right;</span><br><span class="line">                <span class="keyword">if</span>(i == <span class="number">0</span>)&#123;</span><br><span class="line">                    max_left = nums2[j<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(j == <span class="number">0</span>)&#123;</span><br><span class="line">                    max_left = nums1[i<span class="number">-1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    max_left = max(nums2[j<span class="number">-1</span>],nums1[i<span class="number">-1</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>((m+n)%<span class="number">2</span> == <span class="number">1</span>)&#123;</span><br><span class="line">                    <span class="keyword">return</span> max_left;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i == m)&#123;</span><br><span class="line">                        min_right = nums2[j];</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(j == n)&#123;</span><br><span class="line">                        min_right = nums1[i];</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span>&#123;</span><br><span class="line">                        min_right = min(nums1[i],nums2[j]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">return</span> (min_right+max_left)/<span class="number">2.0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="26-Remove-Duplicates-from-Sorted-Array"><a href="#26-Remove-Duplicates-from-Sorted-Array" class="headerlink" title="26. Remove Duplicates from Sorted Array"></a>26. Remove Duplicates from Sorted Array</h3><p><img src="/images/leetcode/26.png" alt=""></p><p><strong>分析：</strong><br>这一题思路比较简单，由于数组是排序过的，因此重复的数在相邻的位置上。所以做法就是用i遍历一边数组，用j保持数组不重复的长度，当出现不重复时<code>j++</code>，将不重复的数补充到j位置上。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">removeDuplicates</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(i&lt;nums.size()&amp;&amp;nums[j] == nums[i])&#123;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(i&lt;nums.size())</span><br><span class="line">            &#123;</span><br><span class="line">                j++;nums[j] = nums[i];</span><br><span class="line">            &#125;   </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> j+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="837-New-21-Game"><a href="#837-New-21-Game" class="headerlink" title="837. New 21 Game"></a>837. New 21 Game</h3><p><img src="/images/leetcode/21.png" alt="Alt text"></p><p><strong>分析：</strong><br>先吐槽一下自己，最近刷题有点儿太慢了。<br>这一题的题意是说，Alice每次都可以在1～W之间随机选择一个数，当Alice选择的数累加起来大于等于K的时候，Alice停止游戏。这时候这个累加和如果大于N那么Alice就输了，小于等于N Alice就赢了。题目叫我们算Alice赢得概率，就是累加和小于等于N的概率。</p><p>这一题可以用DP来求解,维护一个累加和窗。设dp[i]为当前累加和为i的时候的概率。要求i的概率有下面关系：<code>dp[i] = 1/w * (dp[i-1]+dp[i-2]...dp[i-w])</code>，即我可以先选择i-1，然后选1。由于可以选择的数只有W个，因此窗口宽度为W。对于累加和有下面的关系：</p><ul><li>i&lt;K : Wsum += dp[i] 表明当前的i可以作为下一次两步选择的第一步</li><li>i-W&gt;=0: Wsum -= dp[i-W] 表明对于下一个i来说，因为W的范围限定，取不到第dp[i-W]作为前两步选择的第一步，需要把概率减去，维护窗内概率。</li><li>N&gt;= i &gt;=K: res += dp[i]；结果为res,即这个时候分数在K与N之间。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">new21Game</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> K, <span class="keyword">int</span> W)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(K == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 共有N+1个状态</span></span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; dp(N+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">double</span> Wsum = <span class="number">1.0</span>;  <span class="comment">// 记录前W个数的概率</span></span><br><span class="line">        <span class="keyword">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">        dp[<span class="number">0</span>] =<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            dp[i] = Wsum/W;</span><br><span class="line">            <span class="keyword">if</span>(i&lt;K) Wsum+=dp[i];  <span class="comment">// 当前的i可以作为下一次两步选择的第一步</span></span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                res += dp[i];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(i-W&gt;=<span class="number">0</span>) Wsum -= dp[i-W];  <span class="comment">//对于下一个i来说，当前的i-W下一个无法取到</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="481-Magical-String"><a href="#481-Magical-String" class="headerlink" title="481. Magical String"></a>481. Magical String</h3><p><img src="/images/leetcode/481.png" alt=""></p><p>这一题的题意是说，1和2将会交替出现，最开始1先出现，然后去产生下面的数，最后会发现产生的数组和每一行数字的个数序列将会是同一个序列。最后统计一下序列中1的个数。<br>数字的产生规则如下：</p><ul><li>先产生1</li><li>1与2交替出现</li><li>当前字符串最末尾的数字控制添加入字符串的字符个数，如122，表示下一次将加入2个1，变成12211</li><li>前三个数比较特殊，直接生成122</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">magicalString</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">string</span> s = <span class="string">"122"</span>;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(s.size()&lt;n)&#123;</span><br><span class="line">    s+= <span class="built_in">string</span>(s[i++]-<span class="string">'0'</span>,s.back() == <span class="string">'1'</span>? <span class="string">'2'</span>:<span class="string">'1'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count(s.begin(),s.begin()+n,<span class="string">'1'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>有几个新函数记录一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = string(char_num,char); //产生char_num个char</span><br><span class="line">count(s.begin(),s.begin()+n,&apos;1&apos;);//计算字符串s中含&apos;1&apos;的个数</span><br></pre></td></tr></table></figure></p><h3 id="2-Add-Two-Numbers"><a href="#2-Add-Two-Numbers" class="headerlink" title="2. Add Two Numbers"></a>2. Add Two Numbers</h3><p><img src="/images/leetcode/2.png" alt=""><br>这一题题意说的是用链表表示数字，表头为个位。然后将两个链表相加，计算他们的和，返回一个新的链表。<br>这一题比较简单，要注意的有种情况：</p><ul><li>链表相加完，有一个链表长度还有剩余</li><li>链表要记录进位，最后可能进位项还为1</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        ListNode* head = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">auto</span> p = head;</span><br><span class="line">        <span class="keyword">int</span> step = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l1!=<span class="literal">NULL</span>&amp;&amp;l2!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = l1-&gt;val + l2-&gt;val+step;</span><br><span class="line">            <span class="keyword">if</span>(sum&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                sum -= <span class="number">10</span>;</span><br><span class="line">                step = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                step = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            p-&gt;next = <span class="keyword">new</span> ListNode(sum);</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">            l1 = l1-&gt;next;</span><br><span class="line">            l2 = l2-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> l = l1 != <span class="literal">NULL</span> ? l1 : l2;</span><br><span class="line">        <span class="keyword">if</span>(l!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(l!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = l-&gt;val +step;</span><br><span class="line">                <span class="keyword">if</span>(sum&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                    sum -= <span class="number">10</span>;</span><br><span class="line">                    step = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    step = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                p-&gt;next = <span class="keyword">new</span> ListNode(sum);</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">                l = l-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(step==<span class="number">1</span>)&#123;</span><br><span class="line">            p-&gt;next = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> head-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="数据大小及其表示的问题"><a href="#数据大小及其表示的问题" class="headerlink" title="数据大小及其表示的问题"></a>数据大小及其表示的问题</h3><ol><li><p>整数int的上下界：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最小的表示方式：-1&lt;&lt;31，INT_MIN</span><br><span class="line">最大的表示方式：1&lt;&lt;31 -1,INT_MAX</span><br></pre></td></tr></table></figure></li><li><p>其他类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unsigned int -&gt;UINT_MAX</span><br><span class="line">long-&gt;LONG_MAX</span><br><span class="line">unsigned long-&gt;ULONG_MAX</span><br></pre></td></tr></table></figure></li><li><p>无穷大的选择：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int INF = 0x7fffffff;</span><br></pre></td></tr></table></figure></li></ol><p><code>0x7fffffff</code> 是32-bit int的最大值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int INF = 0x3f3f3f3f</span><br></pre></td></tr></table></figure><p><code>0x3f3f3f3f</code>的十进制是1061109567，是10^9级别的（和一个数量级），而一般场合下的数据都是小于10^9的，可以用来表示无穷大。此外，<code>0x3f3f3f3f * 2 =2122219134</code>，这非常大但却没有超过32-bit int的表示范围，所以0x3f3f3f3f能够满足“无穷大加无穷大还是无穷大”的需求。<br>如果我们想要将某个数组清零，我们通常会使用memset(a,0,sizeof(a))。但是当我们想将某个数组全部赋值为无穷大时，就不能使用memset函数而得自己写循环了，因为memset是按字节操作的。如果我们将无穷大设为0x3f3f3f3f，0x3f3f3f3f的每个字节都是0x3f！所以要把一段内存全部置为无穷大，我们只需要memset(a,0x3f,sizeof(a))。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="keyword">sizeof</span>(a));  <span class="comment">//给a数组置0</span></span><br><span class="line"><span class="built_in">memset</span>(a，<span class="number">0x3f</span>,<span class="keyword">sizeof</span>(a));<span class="comment">//给a数组赋值正无穷</span></span><br></pre></td></tr></table></figure><ol start="4"><li>表示一个很小的数：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const long double eps = 1e-8;</span><br></pre></td></tr></table></figure></li></ol><p><code>1e-8</code> 是0.00000001，用来表示一个很小很小的数，通常可以用来判断两个数是否相同，即精度的差距。</p><hr><p>2/22/1019</p><h3 id="3-Longest-Substring-Without-Repeating-Characters"><a href="#3-Longest-Substring-Without-Repeating-Characters" class="headerlink" title="3. Longest Substring Without Repeating Characters"></a>3. Longest Substring Without Repeating Characters</h3><p><img src="/iamges/leetcode/3.png" alt=""><br><strong>分析：</strong><br>这一题题目非常好理解，找到字符串中的最长非重复子串。一看这一题的题目就感觉会有大量的元素比较，重复计算，因此可以用DP来做，用一个数组存储子问题的解。</p><p>维护一个数组res[j]，用来存储子问题的解，遍历原始数组，如果发现循环到的元素s[i]与res中最后一个位置所代表的元素不同，这res[j]++;如果发现相同这<code>j++;res[j] = res[j-1]-1</code>。具体写代码的时候里面有很多陷阱，看代码注释：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res(s.size());</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        res[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;s.size();i++)&#123; </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = j;k&lt;i;k++)&#123; <span class="comment">//判断当前循环元素与子串中是否有重复</span></span><br><span class="line">                <span class="keyword">if</span>(s[k]==s[i])&#123;</span><br><span class="line">                    flag = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(j&gt;=i) <span class="keyword">continue</span>;  <span class="comment">//由于底下有i--的操作，需要保证j&lt;i</span></span><br><span class="line">            <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;  <span class="comment">// all different</span></span><br><span class="line">                res[j]++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;           <span class="comment">//如果有重复</span></span><br><span class="line">                flag = <span class="number">0</span>;</span><br><span class="line">                j++;        <span class="comment">//res表示的子串向前缩减</span></span><br><span class="line">                i--;        <span class="comment">//当前遍历到的元素需要保留</span></span><br><span class="line">            res[j] = res[j<span class="number">-1</span>]<span class="number">-1</span>&gt;<span class="number">0</span>? res[j<span class="number">-1</span>]<span class="number">-1</span> : <span class="number">1</span>; <span class="comment">//保证res[j]最小为1</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> *max_element(res.begin(),res.end());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p><strong>tip：</strong><br>关于vector找最大值最小值：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> maxValue = *max_element(s.begin(),s.end());</span><br><span class="line"><span class="keyword">int</span> minValue = *min_element(s.begin(),s.end());</span><br></pre></td></tr></table></figure></p><h3 id="5-Longest-Palindromic-Substring"><a href="#5-Longest-Palindromic-Substring" class="headerlink" title="5. Longest Palindromic Substring"></a>5. Longest Palindromic Substring</h3><p><img src="/images/leetcode/5.png" alt=""></p><p><strong>分析：</strong><br>找到最长的回文子串，可以用一个窗口去扫描，窗口的长度有2到字符串长度。该做法的时间复杂度为$O(n^2)$。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">longestPalindrome</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> length = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> l = <span class="number">2</span>;l&lt;=s.size();l++)&#123; <span class="comment">// 回文的长度</span></span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;l&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;s.size()-l+<span class="number">1</span>;i++)&#123;</span><br><span class="line">                <span class="keyword">int</span> j = i+l<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">int</span> temp = i;</span><br><span class="line">                <span class="keyword">while</span>(temp&lt;j)&#123;  <span class="comment">// 判断窗口内是否满足回文</span></span><br><span class="line">                    <span class="keyword">if</span>(s[temp]==s[j])&#123;</span><br><span class="line">                        temp++;</span><br><span class="line">                        j--;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span>&#123;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(temp&gt;=j)&#123;  <span class="comment">//说明满足回文</span></span><br><span class="line">                    pos = i;</span><br><span class="line">                    length = l;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> s.substr(pos,length);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>2/23/2019</p><h3 id="6-ZigZag-Conversion"><a href="#6-ZigZag-Conversion" class="headerlink" title="6. ZigZag Conversion"></a>6. ZigZag Conversion</h3><p><img src="/images/leetcode/6.png" alt=""><br><strong>分析：</strong>这一题题意要求生成zigZag字形的序列，如图。可以用下标间关系求解，规定i为行数，j为要输出位置的下标，则该序列中下标间存在以下关系：</p><ul><li>V口向上： j += 2*（numRows-i-1）</li><li>V口向下：j +=2i</li><li>第一行和最后一行处于V的交界位置，需要排除掉一种即可。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">convert</span><span class="params">(<span class="built_in">string</span> s, <span class="keyword">int</span> numRows)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">if</span>(numRows == <span class="number">1</span>) <span class="keyword">return</span> s;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;numRows;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> j = i;</span><br><span class="line">            <span class="keyword">while</span>(j&lt;s.size())&#123;</span><br><span class="line">                res += s[j];</span><br><span class="line">                j += <span class="number">2</span>*(numRows-i<span class="number">-1</span>);</span><br><span class="line">                <span class="keyword">if</span>(j&lt;s.size()&amp;&amp;i!=<span class="number">0</span>&amp;&amp;i!=numRows<span class="number">-1</span>)&#123;</span><br><span class="line">                    res += s[j];</span><br><span class="line">                &#125;</span><br><span class="line">                j += <span class="number">2</span>*i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="8-String-to-Integer-atoi"><a href="#8-String-to-Integer-atoi" class="headerlink" title="8. String to Integer (atoi)"></a>8. String to Integer (atoi)</h3><p><img src="/images/leetcode/8.png" alt=""><br><strong>分析：</strong>这一题做的我很狼狈，可以按从头到尾扫描的方式来做，我的做法太蠢了。特例很多。</p><ul><li>从头到位扫描。</li><li>当判断一个string 转成int是否超过精度的时候，可以申请一个long long类型的变量，判断他是否大于边界值。</li><li>char 转int的方式： <code>str[i] - &#39;0&#39;;</code>即可。 </li></ul><p>我的做法：（不推荐，虽然挺快的）<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(str.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">string</span> s = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;str.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s ==<span class="string">""</span>&amp;&amp;str[i] == <span class="string">' '</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(s==<span class="string">""</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">isdigit</span>(str[i])) s = str[i];</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(str[i] ==<span class="string">'-'</span>) s += <span class="string">'-'</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(str[i] == <span class="string">'+'</span>) s += <span class="string">'+'</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">if</span>(!<span class="built_in">isdigit</span>(str[i])) <span class="keyword">break</span>;</span><br><span class="line">                s+=str[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size() == <span class="number">1</span> &amp;&amp; s[<span class="number">0</span>] == <span class="string">'-'</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>((s[<span class="number">0</span>]==<span class="string">'+'</span>||s[<span class="number">0</span>]==<span class="string">'-'</span>)&amp;&amp;!<span class="built_in">isdigit</span>(s[<span class="number">1</span>])) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(s[<span class="number">0</span>] == <span class="string">'-'</span>)&#123;</span><br><span class="line">            flag = <span class="number">-1</span>;</span><br><span class="line">            s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(s[<span class="number">0</span>] == <span class="string">'+'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(s.size()&gt;<span class="number">1</span>&amp;&amp;s[<span class="number">0</span>]==<span class="string">'0'</span>)&#123;</span><br><span class="line">                s = s.substr(<span class="number">1</span>,s.size()<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">string</span> min = <span class="string">"2147483648"</span>;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;<span class="number">10</span>)  <span class="keyword">return</span> flag == <span class="number">1</span>? INT_MAX:INT_MIN;</span><br><span class="line">        <span class="keyword">if</span>(s.size()&gt;=min.size()&amp;&amp;s&gt;=min) <span class="keyword">return</span> flag == <span class="number">1</span>? INT_MAX:INT_MIN; </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> stoi(s)*flag;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>比较合理的做法：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(str.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> base = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sign = <span class="number">1</span>,i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(str[i] == <span class="string">' '</span>) i++;</span><br><span class="line">    <span class="keyword">if</span>(str[i] == <span class="string">'+'</span>) i++;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(str[i] == <span class="string">'-'</span>) sign = <span class="number">-1</span>,i++;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;str.size()&amp;&amp;str[i]&gt;=<span class="string">'0'</span>&amp;&amp;str[i]&lt;=<span class="string">'9'</span>)&#123;</span><br><span class="line">        base = base*<span class="number">10</span> + str[i++]-<span class="string">'0'</span>;</span><br><span class="line">        <span class="keyword">if</span>(base&gt;INT_MAX) <span class="keyword">return</span> sign == <span class="number">1</span>?INT_MAX:INT_MIN;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> base*sign;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="35-Search-Insert-Position"><a href="#35-Search-Insert-Position" class="headerlink" title="35. Search Insert Position"></a>35. Search Insert Position</h3><p><img src="/images/leetcode/35.png" alt=""><br><strong>分析：</strong> 这一题可以用分治法来做，主要的点在于当要找的数不存在时，它如果比num[high]大，那么插入点为high（需要保证high&gt;=0），如果比high小，插入点为high+1<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">searchInsert</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> high = nums.size()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;=high)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (high+low)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] == target) <span class="keyword">return</span> mid;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;target) high = mid <span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">else</span> low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(high&gt;=<span class="number">0</span>&amp;&amp;nums[high]&gt;target) <span class="keyword">return</span> high;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> high+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr><p>24/2/2019</p><h3 id="10-Regular-Expression-Matching"><a href="#10-Regular-Expression-Matching" class="headerlink" title="10. Regular Expression Matching"></a>10. Regular Expression Matching</h3><p><img src="/images/leetcode/10.png" alt=""><br>这道题的题意是判断两个字符串是否能够匹配，由于*号可以替换多个字符，因此这一题有一个递归的过程，也就是说，替换的个数可能是1，2…等等。所以要用递归的方法求解。</p><ul><li>当<code>p[1] == &#39;*&#39;</code>: 两种情况，<code>*</code>直接跳过；match一个字符；</li><li>当<code>p[1]!=*</code>: 则两个字符对应位置match</li></ul><p><strong>递归解法：</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p.empty())</span><br><span class="line">            <span class="keyword">return</span> s.empty();</span><br><span class="line">        <span class="keyword">if</span>(p[<span class="number">1</span>]==<span class="string">'*'</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> isMatch(s,p.substr(<span class="number">2</span>))||(!s.empty()&amp;&amp;(s[<span class="number">0</span>] == p[<span class="number">0</span>]||p[<span class="number">0</span>]==<span class="string">'.'</span>)&amp;&amp;isMatch(s.substr(<span class="number">1</span>),p));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> !s.empty()&amp;&amp;(s[<span class="number">0</span>]==p[<span class="number">0</span>]||p[<span class="number">0</span>]==<span class="string">'.'</span>)&amp;&amp;isMatch(s.substr(<span class="number">1</span>),p.substr(<span class="number">1</span>));</span><br><span class="line">      </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>动态规划法利用dp数组把所有的子情况都进行保存。有以下几种情形：</p><ul><li><code>dp[i][j]</code>: s(0,i) ,p(0,j)是否match</li><li>当 <code>p[j-1] != *</code>: <code>dp[i][j] == d[i-1][j-1]&amp;&amp;s[i-1] == p[j-1]</code> </li><li>当<code>p[j-1] == *</code>： 两种：有替换或无替换：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[i][j] = dp[i-1][j] //in this case, a* counts as multiple a </span><br><span class="line">dp[i][j] = dp[i][j-1] // in this case, a* counts as single a </span><br><span class="line">dp[i][j] = dp[i][j-2] // in this case, a* counts as empty</span><br></pre></td></tr></table></figure></li></ul><p><strong>动态规划：</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">string</span> p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p.empty())</span><br><span class="line">            <span class="keyword">return</span> s.empty();</span><br><span class="line">        <span class="keyword">int</span> len1=s.size(),len2=p.size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(len1+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(len2+<span class="number">1</span>,<span class="literal">false</span>));</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>]=<span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;=len1;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=len2;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(p[j<span class="number">-1</span>]==<span class="string">'*'</span>)</span><br><span class="line">                    dp[i][j] = dp[i][j<span class="number">-2</span>] || ( i&gt;<span class="number">0</span> &amp;&amp; dp[i<span class="number">-1</span>][j] &amp;&amp; (s[i<span class="number">-1</span>]==p[j<span class="number">-2</span>] || p[j<span class="number">-2</span>]==<span class="string">'.'</span>) );</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    dp[i][j] = i&gt;<span class="number">0</span> &amp;&amp; dp[i<span class="number">-1</span>][j<span class="number">-1</span>] &amp;&amp; (s[i<span class="number">-1</span>]==p[j<span class="number">-1</span>] || p[j<span class="number">-1</span>]==<span class="string">'.'</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[len1][len2];</span><br><span class="line">    &#125; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="12-Integer-to-Roman"><a href="#12-Integer-to-Roman" class="headerlink" title="12. Integer to Roman"></a>12. Integer to Roman</h3><p><img src="images/leetcode/12.png" alt=""></p><p><strong>分析：</strong><br>这一题题意要求将普通数字表示称罗马数字，注意一一对应的关系即可。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">intToRoman</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">string</span> res = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">while</span>(num&gt;=<span class="number">1000</span>)&#123;</span><br><span class="line">            res += <span class="string">"M"</span>;</span><br><span class="line">            num -= <span class="number">1000</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">900</span>)&#123;</span><br><span class="line">            res+= <span class="string">"CM"</span>;</span><br><span class="line">            num -= <span class="number">900</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">500</span>) res+=<span class="string">'D'</span>,num -= <span class="number">500</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">400</span>) res += <span class="string">"CD"</span>,num -= <span class="number">400</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">                res +=<span class="string">'C'</span>;</span><br><span class="line">                num-=<span class="number">100</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">90</span>)&#123;</span><br><span class="line">            res += <span class="string">"XC"</span>;</span><br><span class="line">            num -= <span class="number">90</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">50</span>) res += <span class="string">'L'</span>,num -= <span class="number">50</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">40</span>)res+=<span class="string">"XL"</span>,num -= <span class="number">40</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">10</span>)&#123;</span><br><span class="line">                res +=<span class="string">'X'</span>;</span><br><span class="line">                num -= <span class="number">10</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(num&gt;=<span class="number">9</span>)&#123;</span><br><span class="line">            res += <span class="string">"IX"</span>;</span><br><span class="line">            num -= <span class="number">9</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(num&gt;=<span class="number">5</span>) res += <span class="string">"V"</span>,num -= <span class="number">5</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(num&gt;=<span class="number">4</span>)res +=<span class="string">"IV"</span>,num-=<span class="number">4</span>;</span><br><span class="line">            <span class="keyword">while</span>(num&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">                res +=<span class="string">'I'</span>;</span><br><span class="line">                num -= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络-- CNN</title>
      <link href="/2019/02/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/"/>
      <url>/2019/02/19/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/</url>
      
        <content type="html"><![CDATA[<h3 id="卷积神经网络-–-CNN"><a href="#卷积神经网络-–-CNN" class="headerlink" title="卷积神经网络 – CNN"></a>卷积神经网络 – CNN</h3><p>CNN最早由LeCun 在1998年《Gradient-based learning applied to document recognition》中提出，并提出了一个目标检测的模型：LeNet-5，随后在2012年ImageNet竞赛上，基于CNN网络的AlexNet取得了第一，且正确率超出第二近10%，取得了历史性的突破。CNN开始大放异彩，VGG Net，Google Net，ResNet等，都是基于CNN网络的一些杰出的工作。</p><p><img src="/images/CNNnet/CNNhistory.png" alt="CNNhistory"></p><h4 id="CNN基本模块"><a href="#CNN基本模块" class="headerlink" title="CNN基本模块"></a>CNN基本模块</h4><p>CNN由输入和输出层以及多个隐藏层组成，隐藏层可分为<strong>卷积层</strong>，<strong>池化层</strong>、<strong>RELU层</strong>和<strong>全连通层</strong>，如下图：<br><img src="/images/CNNnet/conv.jpg" alt="conv"><br><strong>输入层</strong><br>CNN的输入为原始图像，三维（RGB）或二维的向量。<br><strong>卷积层</strong><br>卷积层是CNN的核心，卷积层由一组可学习的滤波器（filter）或内核（kernels）组成，它们具有小的感受野，每个卷积核具有kernel size，padding，stride等参数。从图像的左上角依次做内积操作，提取出图片的高层次特征。<br><strong>pooling layer</strong><br>池化层对conv后输出的feature map进行下采样操作，这样的好处有降低参数的数量，防止过拟合等作用。<br><strong>relu激活函数</strong><br>在CNN中使用relu激活函数，在网络中引入了非线性。通过relu激活函数传递卷积运算的结果。因此，最终特征映射中的值不是简单的线性关系。<br><strong>全连接层</strong><br>全连接层的输入是一维向量，需要将pooling 层的输出向量flatten成一个一维的向量，然后输入到全连接层中，最后送到soft Max层进行类别的分类。</p><p><strong>值得注意的是：</strong>在很多CNN网络结构中，pooling层的<strong>kernel = 2x2, stride = 2 ， padding = 0</strong>,经过这样的pooling后，<strong>输出图片缩小一半</strong>。 卷积层的<strong>kernel = 3x3, stride = 1， padding = 1</strong>。经过这样的卷积，<strong>输出大小与输入相同</strong>。</p><h4 id="CNN的特点"><a href="#CNN的特点" class="headerlink" title="CNN的特点"></a>CNN的特点</h4><p><strong>局部感知</strong><br>局部感知即卷积核的感受野，指的是卷积核所覆盖的像素面积，由于每个卷积核所覆盖的面积仅是很少的一部分，是局部特征，即为局部感知。CNN是一个从局部到整体的过程（局部到整体的实现是在全连通层）。下图是全连接层和卷积层的对比。<br><img src="/images/CNNnet/localview.png" alt="localview"></p><p><strong>权重共享</strong><br>传统的神经网络的参数量巨大，例如对1000X1000像素的图片做一次全连接操作，需要（1000X1000）10的6次方个参数。而CNN除全连接层外，卷积层的参数完全取决于滤波器的设置大小，比如10x10的滤波器，仅有100个参数。整个图片共享一组滤波器的参数，参数数量少，计算简单。<br><strong>多卷积核</strong><br>一种卷积核代表的是一种特征，为获得更多不同的特征集合，允许有多个卷积核，卷积生成的feature map有几个channel就有几个卷积核。</p><h4 id="dropout技术"><a href="#dropout技术" class="headerlink" title="dropout技术"></a>dropout技术</h4><p>dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，<strong>随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5）</strong>，与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。<br><img src="/images/CNNnet/dropout.png" alt="dropout"><br><strong>dropout的实现：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元</span></span><br><span class="line"><span class="comment">#dropout函数的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(x, level)</span>:</span></span><br><span class="line"><span class="keyword">if</span> level &lt; <span class="number">0.</span> <span class="keyword">or</span> level &gt;= <span class="number">1</span>:<span class="comment">#level是概率值，必须在0~1之间</span></span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'Dropout level must be in interval [0, 1[.'</span>)</span><br><span class="line">retain_prob = <span class="number">1.</span> - level</span><br><span class="line">    <span class="comment">#我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样</span></span><br><span class="line"><span class="comment">#硬币 正面的概率为p，n表示每个神经元试验的次数</span></span><br><span class="line"><span class="comment">#因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。</span></span><br><span class="line">sample=np.random.binomial(n=<span class="number">1</span>,p=retain_prob,size=x.shape)<span class="comment">#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了</span></span><br><span class="line"><span class="keyword">print</span> sample</span><br><span class="line">x *=sample<span class="comment">#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0</span></span><br><span class="line"><span class="keyword">print</span> x</span><br><span class="line">x /= retain_prob  <span class="comment"># 归一化</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#对dropout的测试</span></span><br><span class="line">x=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],dtype=np.float32)</span><br><span class="line">dropout(x,<span class="number">0.4</span>)</span><br></pre></td></tr></table></figure></p><p>dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。<br><strong>dropout能防止过拟合：</strong></p><ul><li>多样化学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。</li><li>阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不应该依赖于另外一个神经元。</li></ul><h3 id="CNN经典框架："><a href="#CNN经典框架：" class="headerlink" title="CNN经典框架："></a>CNN经典框架：</h3><h4 id="LeNet："><a href="#LeNet：" class="headerlink" title="LeNet："></a><strong>LeNet：</strong></h4><p>开始用于手写数字字体识别32*32，处理不了大型的图片，用于缺少计算机资源的时候。3个卷积层大小为5x5，2个pooling 层，大小为2x2。<br><img src="/images/CNNnet/Lenet.png" alt="Lenet"></p><ul><li>输入层，尺寸大于任何一个字母，以保证每个字母都会出现在第七层单元的感受野的中心。</li><li>中间五层分别是：卷积层→降采样层→卷积层→降采样层→卷积层。</li><li>第一个卷积层使用了六种滤波器，因此具有六个通道的 feature maps 。</li><li>第二个卷积层上升到16个通道。每一个通道与前6个通道的关系都不一样，见上图，目的是破坏对称性，迫使每个通道学习不同的特征（理想情况是互补特征）。</li><li>在全连接层，特征进行内积和非线性激活。</li><li>最后是输出层，10种数字对应10个输出单元，分别计算输出向量和该分类参考向量的欧式距离。</li><li>loss 为 MSE loss，输出向量和分类参考向量最近则将其判为这一类。<h4 id="AlexNet："><a href="#AlexNet：" class="headerlink" title="AlexNet："></a><strong>AlexNet：</strong></h4>AlexNet在2012年imageNet比赛上大放异彩，引发了神经网络的高潮，AlexNet共有5个卷积，5个pool，loss为softMax loss。<br><img src="/images/CNNnet/AlexNet.jpg" alt="AlexNet"></li></ul><p>该网络有以下的创新：<br>A. ReLU<br>之前使用的 tanh 和 sigmoid 激活函数都存在饱和区。改用无饱和的 ReLU ，收敛速度可以达到数倍于 tanh ！<br>B. Training on Multiple GPUs<br>2个 GPU 协同，最直接的作用是加快了训练速度。作者尝试将网络改为单GPU，同时保证参数数量不变，速度略逊于双 GPUs 。<br>C. Overlapping Pooling<br>实验证明，重叠池化可以更好地抑制过拟合，使准确率提高约0.4%和0.3%。<br>D. Data Augmentation<br>最简单的抑制过拟合技术，就是 label-preserving transformations 。简单来说，就是让图像进行各种不影响目标本质的变换，扩大数据量。</p><pre><code>- 镜像对称变换；- 图像光照强度和色彩变换。</code></pre><p>第二点具体而言：</p><pre><code>- 先提取 RGB 三通道分量；- 对每一个通道分别进行主成分分析，提取出主成分；- 然后再进行三通道的随机系数线性组合。</code></pre><p>E. Dropout<br>如果我们有多个不同的模型合作进行预测，那么泛化误差将会有效降低。问题是，训练多个模型的计算成本很高昂。Dropout 为我们提供了新思路：让这些模型分享相同的权重系数，但神经元的输出结果不尽相同。<br>具体而言，是让 hidden neuron 的输出有50%的概率被置零。这样，每次反向传播时，参考的 loss 都是由不同模型计算得到的。<br>总的来说，<strong>Dropout 技术打破了神经元之间的依赖性，强迫网络学习更鲁棒的神经元连接。</strong>我们只在全连接层使用，因为全连接层的连接非常多。在测试阶段不采用 Dropout 。Dropout 会延长收敛时间，但能有效抑制过拟合。</p><h4 id="VGG-Net："><a href="#VGG-Net：" class="headerlink" title="VGG Net："></a><strong>VGG Net：</strong></h4><p>VGG相对Googlenet虽然精度略逊些，但其整体网络框架还是延续了Alexnet及更早的Lenet等的一贯思路，此外还更深入的探讨了ConvNet深度对模型性能可能的影响。由于其整个网络结构的简单、强大，VGG16/VGG19曾一度广泛被用作各种检测网络框架像Faster-RCNN/SSD等的主干特征提取网络，直到Resnet提出之后，它才渐渐完成了其历史使命，退居二线。<br><img src="/images/CNNnet/VGGnet.jpg" alt="VGGnet"><br>VGGnet有许多中深度的版本，他们基本采用了3x3的Conv kernel，pad/stride为1，只是在其中的若干Conv层后会置MaxPool层来作特征的上采样以高度抽象特征，节省后续的计算。然后在每个网络的最后则是同其它分类网络一样的若干个FCs层及Softmax。其中VGG16与VGG19最为受人欢迎（最深）。</p><p>作者表明：<strong>两个级联的3x3 conv或三个级联的3x3 conv分别在理论上等价于一个5x5 conv及一个7x7 conv。</strong>不过它们所具的模型参数要大大小于后面两者的参数。同时作者实验表明更深（层数更多）而非更宽（conv channels更多）的网络有着自动规则自己参数的能力，因此有着更好的学习能力。VGG使用与AlexNet相同的SGD对网络进行训练。VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），<strong>采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）</strong>，相比于AlexNet使用更小的卷积核级联，更深的网络。</p><h4 id="GoogleNet：（inception）"><a href="#GoogleNet：（inception）" class="headerlink" title="GoogleNet：（inception）"></a><strong>GoogleNet：（inception）</strong></h4><p>尽管VGG可以在ImageNet上表现很好，但是将其部署在一个适度大小的GPU上是困难的，因为需要VGG在内存和时间上的计算要求很高。由于卷积层的通道数过大，VGG并不高效。<br>在此之前经典的CNN模型像LeNet/Alexnet/VGG等无不是一个模子即使用Conv/Pool/Normalization/Activation等层来不断累积而成。模型对数据集概率分布的表达能力则往往通过单纯增加模型的深度（层数）或宽度（层的channels数）来提高（当然这也亦是当下深度学习领域的共识）。但这样进行网络设计一般会等来巨量的计算开销，因为每一层channels数目的增加都会随着层深而指数级增加，这大大地限制了模型的实际应用。</p><p>GoogleNet则从提高精度以及减少计算量的角度出发，想通过一种spared layer architecture来实现较优的多维度特征表达（inception module），然后通过对这种结构进行叠加，中间不时再插入一些MaxPool层以减少参数数目（从而节省内存与计算开销），最终就形成了Inception v1分类模型。<br><img src="/images/CNNnet/inception.jpg" alt="inception"><br>GoogleNet团队计算效率以及GPU对密集计算的优化等等，选择了<strong>密集计算子结构组合而成的稀疏模块</strong>来用于特征提取及表达，这就是用于构建Inception v1的Inception module如上图中a所示。其中1x1/3x3/5x5这三种Conv kernels的选择决定是基于方便，因为这几种kernels用的多，而且比较容易对齐,padding。<br>但是a中的模型计算量太大，因此作者在每个子conv层里使用了<strong>1x1的conv</strong>来作上一层的输入<strong>feature maps的channels数缩减、归总</strong>。例如：<br>假设输入时 256 个 feature map 进来，256 个 feature map 输出，假设 Inception 层只执行 3x3 的卷积，那么这就需要这行 (256x256) x (3x3) 次卷积左右（大约 589,000 次计算操作），此时每一个特征的channel为256。<br>现在 Bottleneck layer 的思想是先来减少特征的通道数， 操作量(每次卷积核参数)是：<br>256(channel)×64(个) × 1×1 = 16,000s  -&gt; 与1x1的卷积层做一次卷积，通道数缩减为64<br>64(channel)× 64(个) × 3×3 = 36,000s<br>64× 256(个) × 1×1 = 16,000s<br>上诉处理能够大大减小计算量。<br>模型的最后会选通过一个7x7的AvgPool层来处理最终的feature maps，大大降低了参数量。然后再由FC层汇总生成1000个输出，进而由Softmax来得到1000类的概率分布。</p><h4 id="ResNet："><a href="#ResNet：" class="headerlink" title="ResNet："></a><strong>ResNet：</strong></h4><p>Resnet分类网络是当前应用最为广泛的CNN特征提取网络。它的提出于2015年。<br><strong>残差学习：</strong><br>若将输入设为X，将某一有参网络层设为H，那么以X为输入的此层的输出将为H(X)。一般的CNN网络如Alexnet/VGG直接通过训练学习出参数函数H的表达，即直接得到H(X)。<br>而残差学习则是学习输入、输出之间的<strong>残差即H(X) - X</strong>。即学习得到 (H(X) - X) 。最终的网络输出为：<strong>残差+X，其中X直接由identity mapping得到</strong>，而H(X) - X则为有参网络层要学习的输入输出间残差，优化难度大大减小。<br><img src="/images/CNNnet/residual.jpg" alt="residual"><br><strong>identity mapping：</strong>我们在输入与输出之间建立了一条连接，成为identity map，主要作用是将X传递到输出中，当输出与输入的channel数不一致时，通过直接补0或者用1x1 conv来映射。<br>在处理一些很复杂的数据集时，作者引入bottleneck结构，即下图的1x1 的conv，第一个conv用来降低通道数，最后一个conv用来恢复通道数，这样的操作是的中间的conv维度不受输入影响，降低运算量。<br><img src="/images/CNNnet/bottleneck.png" alt="bottleneck"></p><p><strong>退化现象：</strong>退化现象产生的原因在于当模型的结构变得复杂时，随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。通过建立identity map可以将浅层的信息传入深层网络，可以很好的缓解退化现象。</p><h4 id="inception-V2-V3："><a href="#inception-V2-V3：" class="headerlink" title="inception V2/V3："></a><strong>inception V2/V3：</strong></h4><p>inception V2/V3遵循上面的思路，进一步对inception v1结构中较大的卷积核进行分解。例如将5x5的卷积核分解成两个级联的3x3的卷积核，减少参数的同时，增加了网络的学习能力。<br><img src="/images/CNNnet/convsmall.jpg" alt="convsmall"><br><strong>更高效的下采样方式：</strong><br>由于对features map做pooling将会损失掉一部分的信息，为了减少这种信息的损失，在VGGnet中，通常的做法是pooling 的同时增大features map的channel的数量。googlenet中的做法是，分类对features map进行conv以及pooling，然后将最后得到的feature maps进行组合，得到最终的feature map。<br>作者认为，inception v1 中的辅助分类器起到的作用是对网络底层的参数进行归一化的作用，因此inception v3 在inception v2的基础上在辅助分类器中使用BN对参数进行regularization。同时在最终的loss中增加了标签平滑，用label的先验避免过拟合发生。</p><h4 id="inception-v4"><a href="#inception-v4" class="headerlink" title="inception v4"></a><strong>inception v4</strong></h4><p>inception v4使用tensorflow完成，涉及结构更加复杂，计算量也相比比较小。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中常用的技术（面试考点）</title>
      <link href="/2019/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%88%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%EF%BC%89/"/>
      <url>/2019/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%88%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="深度学习中常用的技术（面试考点）"><a href="#深度学习中常用的技术（面试考点）" class="headerlink" title="深度学习中常用的技术（面试考点）"></a>深度学习中常用的技术（面试考点）</h3><p>（一）神经网络中，防止过拟合的方法有：</p><ul><li>early stop（及早停止），当在测试集上出现错误率上升时，及时停止。</li><li>data expanding (扩大训练数据)</li><li>dropout 技术（随机丢弃）</li><li>加入正则项</li><li>BN（让激活函数的输入分布保持在一个稳定状态来尽可能避免它们陷入梯度饱和区。）</li></ul><h4 id="dropout技术"><a href="#dropout技术" class="headerlink" title="dropout技术"></a>dropout技术</h4><p>dropout是一种防止过拟合的正则化技术，具体做法是，对每个隐藏层的输入进行一个概率判决，比如我们设置概率为0.5（通常命名为keep_prob）,根据0.5，<strong>随机生成一个跟隐藏层神经元个数相同的向量，true:false的比例是1：1（因为keep_prob=0.5）</strong>，与隐藏层的神经元进行相乘，那么会有一半隐藏层的神经元被舍弃，不参与训练。重复迭代上诉操作。<br><img src="/images/trick/dropout.png" alt="dropout"><br><strong>dropout的实现：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用一个二项分布的函数，等概率的生成0/1，既可以随机的屏蔽掉某些神经元</span></span><br><span class="line"><span class="comment">#dropout函数的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(x, level)</span>:</span></span><br><span class="line"><span class="keyword">if</span> level &lt; <span class="number">0.</span> <span class="keyword">or</span> level &gt;= <span class="number">1</span>:<span class="comment">#level是概率值，必须在0~1之间</span></span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'Dropout level must be in interval [0, 1[.'</span>)</span><br><span class="line">retain_prob = <span class="number">1.</span> - level</span><br><span class="line">    <span class="comment">#我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样</span></span><br><span class="line"><span class="comment">#硬币 正面的概率为p，n表示每个神经元试验的次数</span></span><br><span class="line"><span class="comment">#因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。</span></span><br><span class="line">sample=np.random.binomial(n=<span class="number">1</span>,p=retain_prob,size=x.shape)<span class="comment">#即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了</span></span><br><span class="line"><span class="keyword">print</span> sample</span><br><span class="line">x *=sample<span class="comment">#0、1与x相乘，我们就可以屏蔽某些神经元，让它们的值变为0</span></span><br><span class="line"><span class="keyword">print</span> x</span><br><span class="line">x /= retain_prob  <span class="comment"># 归一化</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#对dropout的测试</span></span><br><span class="line">x=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],dtype=np.float32)</span><br><span class="line">dropout(x,<span class="number">0.4</span>)</span><br></pre></td></tr></table></figure></p><p>dropout通常使用在一些较大的网络中，在训练阶段使用，在测试或者预测时并不会去dropout，工业上的做法是在输入的X上乘以P得到X的期望，或者输入不做变化而是对所有的有dropout层都做X/p。<br><strong>dropout能防止过拟合：</strong></p><ul><li>多尺度学习：由于每次dropout舍弃的神经元均不相同，因此每次训练都产生一个不同的神经网络。这种组合多种神经网络的综合效果的方式能够有效的缓解过拟合效应。</li><li>阻止特征的协同作用：可以通过阻止某些特征的协同作用来缓解。在每次训练的时候，每个神经元有百分之50的几率被移除，这样可以让一个神经元的出现不依赖于另外一个神经元。</li></ul><h4 id="Batch-Normalization-参考链接"><a href="#Batch-Normalization-参考链接" class="headerlink" title="Batch Normalization 参考链接"></a>Batch Normalization <a href="https://zhuanlan.zhihu.com/p/34879333" target="_blank" rel="noopener">参考链接</a></h4><p>深层网络难以训练，由于底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；参数的变化导致每一层的输入分布会发生改变，进而上层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。<br><strong>Internal Covariate Shift：</strong> 在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。<br>因此而带来的问题：</p><ul><li>上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低</li><li>网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（可以使用线性整流函数ReLU因为它可以在一定程度上解决训练进入梯度饱和区的问题）</li></ul><p><strong>缓解Internal Covariate shift</strong><br>ICS产生的原因是由于参数更新带来的网络中每一层输入值分布的改变，并且随着网络层数的加深而变得更加严重，因此我们可以通过固定每一层网络输入值的分布来对减缓ICS问题。常用的方法如下：<br><strong>白化</strong>：<br>使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1；而ZCA白化则保证了所有特征分布均值为0，方差相同；去除特征之间的相关性。<br>但是由于白化操作计算成本高，且将会改变网络每一层参数的分布，使得网络底层学到的信息被丢弃<br><strong>batch normalization</strong><br> 单独对每个特征进行normalizaiton(每一层)，让每个特征都有均值为0，方差为1的分布，减少计算量。线性变换操作，让网络恢复本身的表达能力。<br>BN插在在全连接层之后如下图：<br><img src="/images/trick/bn.png" alt="bn"><br>BN操作如下：<br><img src="/images/trick/bnstep.png" alt="bnstep"></p><ol><li>对输入取均值</li><li>对输入取方差</li><li>计算normalize后的输入（其中 $\epsilon$ 是为了防止方差为0产生无效计算）</li><li>反标准化进行学习</li></ol><p>反标准化是为了让神经网络能够学习batch normalization的平移拉伸，让数据再能够尽可能恢复本身的表达能力就好，达到学习的目的。</p><p><strong>BN作用：</strong></p><ul><li>BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度</li><li>BN使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定。<strong>BN不会受到权重scale的影响</strong>，因此其能够使模型保持在一个稳定的训练状态；而没有加入BN的网络则在一开始就由于学习率过大导致训练失败BN的网络能够克服如此bad的权重初始化</li><li>BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题</li><li><strong>BN具有一定的正则化效果</strong>：在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，在一定程度上对模型起到了正则化的效果。</li></ul><h4 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h4><p><strong>L1 正则项：</strong> L1是模型各个参数的绝对值之和,将它添加到损失函数上：<br>$$\min  \frac{1}{N}\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_1<br>$$<br><strong>L2 正则项：</strong>是模型各个参数的平方和的开方值：<br>$$<br>\min  \frac{1}{N} \sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + C||\omega||_{2}^{2}<br>$$<br>添加L1和L2正则项之后的损失函数如下：<br><img src="/images/trick/normal.jpg" alt="normal"><br>如图可以看出，如果仅有损失函数的话，优化目标为损失函数最内圈的紫色的环。但是给loss function加上正则化项，能使得新得到的优化目标函数h = f+normal，需要在f和normal中做一个权衡（trade-off），即最优解应该使得正则项和模型损失函数之和最小。</p><p>可以看出来，<strong>L1正则项与loss更多的相交于坐标轴，因此L1更容易产生稀疏解。L2的解比较接近与坐标轴，L2范数能让解比较小（靠近0），但是比较平滑（不等于0）</strong>。</p><p><strong>正则项降低过拟合程度：</strong></p><ul><li>L1正则化：在loss function后边所加正则项为L1范数，加上L1范数容易得到稀疏解（0比较多），能够避免过拟合。有助于生成一个稀疏权重矩阵，进而可用于特征选择。</li><li>L2正则化：在loss function后边所加正则项为L2范数的平方，L2控制w的大小，则w的幅度较小且较均匀。一般认为参数值较小的模型比较简单，能适应不同的数据集，一定程度上避免了过拟合。（缺点是L2对离群点敏感，而且容易造成梯度爆炸）</li><li>在Faster RCNN中，边框回归通常情况下，使用平方误差最小，即L2loss，但是由于，L2 loss对离群点比较敏感，同时，当预测边框距离真值边框比较远的时候，容易出现梯度爆炸的问题，因此使用smooth L1替代L2 loss，smooth L1 相比于正常的L1它是可导的。且导数是一个常数。</li></ul><p><strong>如何处理数据特征缺失项：</strong></p><ul><li>如果数据集样本很多，可以删除掉缺失的特征的个别样本。</li><li>用平均值，中位数，众数进行替换补全。（人为的增加了噪声）</li><li>使用一些机器学习的算法对数据特征进行恢复，如EM算法等等，KNN算法</li></ul><p><strong>异常值的检测：</strong></p><ul><li>当数值在$(\mu -3\sigma,\mu+3\sigma)$之外时，属于异常数值。</li><li>使用K nearnest neighbour计算每一个点的K近邻，然后距离临近点距离最远，而且周围的邻居位置很稀疏的情况下，这个点很可能是异常点。</li></ul><p><strong>canny边缘检测介绍：</strong><br>canny边缘检测是一个基于图像梯度的边缘检测算法。由于图像边缘即图像中的高频部分，噪音也属于高频信息，因此首先需要对图像进行去噪（高斯滤波器），然后提取图片梯度，然后对提取的梯度做一些例如非极大值抑制等处理，总之canny算子没有考虑到图片全局的信息，仅仅使用了梯度来提取边缘。对于一些梯度不明显的边缘信息可能无法很好的提取。</p><p><strong>max pooling 与 average pooling的应用有何不同：</strong></p><p>使用pooling技术将小邻域内的特征点整合，同时保持某种不变性（旋转、平移、伸缩等）。<strong>average-pooling对领域内特征取平均值</strong>，结果融合了所有的特征。平均操作类似与平滑处理，能够保留图片的低频信息，即更多的保留图像的背景信息。因此更多用在最后的分类中。<br>max-pooling对领域内的特征值取最大值，即能够极大的保留图片的边缘信息，纹理信息。一张图片的高频信息能够极大程度的表示一个物体，因此进行下采样特征缩减时更多用到max-pooling。</p><p><strong>训练过程中学习率如何调整：</strong></p><ul><li>从大到小依次衰减</li><li>或者使用RMSprop更新法，在累计梯度的平方项上进行衰减。</li></ul><p><strong>CNN网络中全连接层的作用：</strong><br>全连接层将学到的“分布式特征表示”映射到样本标记空间（进行分类）。全连接层参数过多（一个大型的分类问题，参数量通常占到80%）不宜有太多层全连接层。<br>是把卷积提取的特征看做多层感知机的输入节点，后面只需要接两层全连接理论上就可以拟合任意非线性函数，</p><p><strong>GAP（全局平均池化）：</strong><br>将每张feature的值全部加起来，取平均，每一个均值代表一个类别。比如有10个类，就在最后输出10个 feature map，每个feature map中的值加起来求平均值，这十个数字就是对应的概率或者叫置信度。然后把得到的这些平均值直接作为属于某个类别的 confidence value，再输入softmax中分类。用GAP代替全连接层可以大幅减小参数量，同时检测效果不会变差。</p><p><strong>维度灾难：</strong><br>对于大多数数据，在一维空间或者说是低维空间都是很难完全分割的，但是在高维空间间往往可以找到一个超平面，将其完美分割。于是我们将维度提升，例如从2维到3维这样就可以区分开物体了。但是无限制的增大数据的纬度，会出现分类进度极速下降的问题。即分类器过拟合，出现维度灾难。</p><p><strong>聚类方法：</strong><br>K-means 聚类</p><ul><li>首先确定样本的类别数n，然后在样本上随机确定n个中心</li><li>然后计算每一个样本到样本中心的距离，将该样本划分到距离它最近的那一类中</li><li>对划分过的样本重新计算各类的类中心</li><li>重复上述步骤，直到类中新位置不发生明显变化为止</li></ul><p>基于密度的聚类方法(DBSCAN)</p><ul><li>首先确定半径r和minPoints. 从一个没有被访问过的任意数据点开始，以这个点为中心，r为半径的圆内包含的点的数量是否大于或等于minPoints，如果大于或等于minPoints则该点被标记为central point，反之则会被标记为noise point。 </li><li>重复上面的步骤，如果一个noise point存在于某个central point为半径的圆内，则这个点被标记为边缘点，反之仍为noise point。重复上述步骤，直到所有的点都被访问过。 </li></ul><p><strong>混合高斯模型（GMM）最大期望（EM）聚类：</strong></p><ul><li>选择簇的数量（与K-Means类似）并随机初始化每个簇的高斯分布参数（均值和方差）。</li><li>给定每个簇的高斯分布，计算每个数据点属于每个簇的概率。一个点越靠近高斯分布的中心就越可能属于该簇。 </li><li>基于这些概率我们计算高斯分布参数使得数据点的概率最大化，可以使用数据点概率的加权来计算这些新的参数，权重就是数据点属于该簇的概率。 </li><li>重复迭代2和3直到在迭代中的变化不大。</li></ul><p><strong>自顶向下的层次分类：</strong></p><ul><li>将所有样本视为一类，然后对样本进行m次二分实验，然后选择一种分类，分类后的两簇SSE（Sum of the Squared Error）之和最小。</li><li>选择最大SSE的簇，然后对他重复上述分类，直到分类到k个簇。</li></ul><p><strong>L1 loss 为什么会导致稀疏解：</strong><br>如下图，原函数设为L，它的极小点为绿色的点，不在原点。加上L2 loss之后L+L2的极小点为黄点。加上L1后L+L1的极小点为红点。<br><img src="/images/trick/L1loss.jpg" alt=""></p><p>为什么L1 loss的最小点就是原点呢？<br>要形成极小值点，以上图为例，x<0 时="" l+c|x|="" 的导数要小于0(函数减)，同理x="">0 时导数&gt;0 (函数增)，x从左边趋近于0 时，C|x|的导数是-C，假设此时 L 的导数为 La ，必须有 La -C &lt;0，即C&gt;La，同理x从右边趋近于0时，必须有 Lb + C &gt; 0 ，即C&gt;-Lb，所以说C要大于L在0点附近的绝对值。<strong>即原点左右两边的导数正负不同，原点为一个极小点。</strong></0></p><p><strong>海量数据球中位数：</strong><br>使用堆的思想。查找中位数，也就是找出中间最大的数字，总共10G的数据，查找第5G大的数据，创建一个1G的大顶堆，遍历一遍这个10G的数据，找出前1G大的数据，在这个大顶堆中找出最小的值，这个最小的值就是这10G数据中第1G大的元素，然后利用这个元素在创建大顶堆，比这个元素小的才能进堆，那么就创建了从1G到2G的元素，这么一来，就找到了第2G大的元素，利用第2G大的元素就可以找到第5G大的元素，这么一来就可以找到中位数了。</p><p><strong>pooling 层如何进行反向传播：</strong></p><ul><li>max pooling层：对于max pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项的值都是0；</li><li>mean pooling层：对于mean pooling，下一层的误差项的值会平均分配到上一层对应区块中的所有神经元。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN详解</title>
      <link href="/2019/02/14/Faster-RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/14/Faster-RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="Faster-RCNN详解"><a href="#Faster-RCNN详解" class="headerlink" title="Faster RCNN详解"></a>Faster RCNN详解</h3><p>Faster RCNN 是在Fast RCNN的基础上，进一步改进，解决select search 算法选择候选框速度太慢的问题。</p><blockquote><p>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks<br>submit time: 2016<br><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>fast R-CNN和faster R-CNN之间的区别在于我们不使用特殊区域提议方法来创建region  proposal。而是训练一个<strong>region proposal network（RPN）</strong>，<strong>该网络将features map 作为输入并输出region proposals。然后将这些proposal输入Fast R-CNN中的RoI池化层</strong>。以下是fast RCNN与Faster RCNN的网络结构对比图。<br><img src="/images/fasternet/structure.png" alt="structure"><br><strong>Faster RCNN 关键步骤：</strong></p><ul><li>Conv layers。作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层<strong>提取image的feature maps</strong>。该feature maps被共享用于后续RPN层和全连接层。</li><li>Region Proposal Networks。<strong>RPN网络用于生成region proposals</strong>。该层通过softmax判断anchors属于foreground或者background，<strong>再利用bounding box regression修正anchors获得精确的proposals</strong>。</li><li>Roi Pooling。该层收集输入的feature maps和proposals，综合这些信息后<strong>提取proposal feature maps</strong>，送入后续全连接层判定目标类别。</li><li>Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。</li></ul><p>Faster RCNN 网络是用于目标检测的一种比较流行的框架。它主要由以下四个部分组成</p><ul><li>分别是conv layer 输入为原始图片，用于提取图片的feature map</li><li>RPN网络，输入为features map，用于生成region proposal，该层为features map 上每个像素生成若干个anchors（9个），随后通过softmax 判断每个anchor是属于foreground（目标）或者background（背景），再利用bounding box regression修正anchors获得精确的proposal位置。</li><li>RoI pooling，该层输入为proposal位置信息和features map，通过proposal的位置信息在features map 上提取region features map候选区，然后通过pooling产生一个固定长度的特征，送入全连接层进行目标判别。</li><li>classification，利用proposal feature maps计算proposal的类别，同时再次进行一次bounding box regression，对proposal位置进行精修，随后将结果输出。</li></ul><p>总结一套介绍网络框架的先后顺序的方法。</p><font color="red"> 可以先大后小，按照先后顺序从前到后，按功能性介绍一件事情，每件事情的功能介绍的时候，说清楚输入，工作流程附带其具体功能，输出。</font><p><strong>Faster RCNN 详细网络结构如图：</strong><br><img src="/images/fasternet/fasterrcnn_structure.jpg" alt="fasterrcnn_structure"></p><p>将一副任意大小PxQ的图像，首先缩放至固定大小MxN，然后将MxN图像送入网络；而卷积层 Conv layers中包含了<strong>13个conv层+13个relu层+4个pooling层</strong>；<strong>RPN网络</strong>首先经过3x3卷积，再分别生成foreground anchors与bounding box regression偏移量，然后计算出proposals；而<strong>Roi Pooling层则利用proposals以及feature maps，提取proposal feature</strong>送入后续全连接和softmax网络作classification。</p><h4 id="conv-layer"><a href="#conv-layer" class="headerlink" title="conv layer"></a>conv layer</h4><p><img src="/images/fasternet/vgg.jpg" alt="vgg"></p><p>Conv layers部分共有13个conv层，13个relu层，4个pooling层。</p><ul><li>所有的conv层都是： kernel_size=3 ， pad=1 ，stride=1，因此conv层不改变原图大小</li><li>所有的pooling层都是： kernel_size=2 ，pad=0 ， stride=2，pooling 层将原图缩小为原来的一半</li><li>经过Conv layer后，一个MxN大小的矩阵将变为(M/16)x(N/16)</li></ul><h4 id="Region-Proposal-Networks-RPN"><a href="#Region-Proposal-Networks-RPN" class="headerlink" title="Region Proposal Networks(RPN)"></a>Region Proposal Networks(RPN)</h4><p>Faster RCNN 层在fast RCNN 的基础上，对提取候选框进行优化。</p><p><img src="/images/fasternet/RPN.jpg" alt="RPN"></p><p>RPN网络分为2条线，上面一条通过<strong>softmax分类anchors获得foreground和background</strong>（检测目标是foreground），<strong>下面一条用于计算anchors的bounding box regression偏移量</strong>，以获得精确的proposal。而最后的Proposal层则负责综合foreground anchors和bounding box regression偏移量获取proposals，同时剔除太小和超出边界的proposals。其实整个网络到了Proposal Layer这里，就完成了相当于目标定位的功能。</p><h5 id="anchors"><a href="#anchors" class="headerlink" title="anchors"></a>anchors</h5><p>anchor为由一个中心点，周围生成了9个矩形，矩形长宽比由三个尺寸<code>1:1,1:2;2:1</code>三种，如下图，基本覆盖了各种尺寸和形状，引入检测中常用到的多尺度方法。<br><img src="/images/fasternet/anchor.jpg" alt="anchor"><br>Faster RCNN遍历Conv layers计算获得的feature maps，<strong>为feature map上每一个点都配备这9种anchors作为初始的检测框</strong>。这样做获得检测框很不准确，之后将会在RPN层，以及最后进行2次的bounding box regression修正检测框位置。<br><img src="/images/fasternet/convmap.jpg" alt="convmap"><br>如上图，对于每一个点的k个anchor来说，从conv layer提取出得特征具有256维，对于每一个anchor，需要分foreground与background，因此共有2k个score，对于每一个anchor共有$(x_1,y_1,x_2,y_2)$四个坐标值。因此共有4k个coordinates。在训练阶段，程序将会从这些anchor中挑选出一些合适的anchor进行训练。<br><strong>因此RPN最终就是在<font color="red">原图尺度上</font>，对每一个像素设置9个尺度的候选anchor。然后用cnn去判断哪些Anchor是里面有目标的foreground anchor，哪些是没目标的backgroud。所以，仅仅是个二分类而已！</strong><br>那么Anchor一共有多少个？原图800x600，VGG下采样16倍，feature map每个点设置9个Anchor，所以：<br>$$<br>ceil(800/16) \times ceil(600/16) \times 9=50\times38 \times9=17100<br>$$<br>其中ceil()表示向上取整，是因为VGG输出的feature map size= 50*38。</p><p><img src="/images/fasternet/generateAnchor.jpg" alt="generateAnchor"></p><h4 id="softmax判定foreground与background"><a href="#softmax判定foreground与background" class="headerlink" title="softmax判定foreground与background"></a>softmax判定foreground与background</h4><p>RPN网络中利用anchors和softmax初步提取出foreground anchors作为候选区域。<br><img src="/images/fasternet/softmax.jpg" alt="softmax"><br>features map 首先做一个1*1的卷积，这个卷积的作用是生成一个$W*H*(9*2)$大小的矩阵。该矩阵用于存储上面提到的foreground与background信息（2*k score）。将该特征后接softmax分类获得foreground anchors，也就相当于初步提取了检测目标候选区域box（一般认为目标在foreground anchors中）。前后两个reshape 操作目的为便于程序实现。<br>clc layer输出预测区域共k个，每个有的2个参数，即预测为前景的概率和背景的概率，损失用softmax loss（cross entropy loss）。监督信息是Y=0,1，表示这个区域是否为groundtruth。确定groundtruth时，我们需要确定k个区域中的各个区域是不是有效的，是前景还是背景。<br>K个区域分配标签规则：</p><ul><li>与某个ground truth(GT)的IoU最大的区域的分配正标签</li><li>与任意GT的IoU大于0.7的区域分配正标签</li><li>与所有GT的IoU都小于0.3的区域分配负标签</li></ul><h4 id="bounding-box-regression原理"><a href="#bounding-box-regression原理" class="headerlink" title="bounding box regression原理"></a>bounding box regression原理</h4><p>对于窗口一般使用四维向量  (x, y, w, h) 表示，分别表示窗口的中心点坐标和宽高。对于图 11，红色的框A代表原始的Foreground Anchors，绿色的框G代表目标的GT，我们的目标是寻找一种关系，使得输入原始的anchor A经过映射得到一个跟真实窗口G更接近的回归窗口G’，即：<br><img src="/images/fasternet/bbox.jpg" alt="bbox"></p><p>给定：$anchor A=(A_{x}, A_{y}, A_{w}, A_{h}) 和 GT=[G_{x}, G_{y}, G_{w}, G_{h}]$<br>寻找一种变换F，使得：$F(A_{x}, A_{y}, A_{w}, A_{h})=(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})，$其中$(G_{x}^{‘}, G_{y}^{‘}, G_{w}^{‘}, G_{h}^{‘})≈(G_{x}, G_{y}, G_{w}, G_{h})$<br>那么经过何种变换F才能从图10中的anchor A变为G’呢？ 比较简单的思路就是先做平移，然后进行缩放，边框回归与RCNN中边框回归相同。<a href="https://blog.csdn.net/u014433413/article/details/78194855" target="_blank" rel="noopener">bounding box 原理参考链接</a><br>RPN中所涉及的边框回归首先经过一个1*1的卷积层，输出一个$W*H*(9*4)$的矩阵，用于存储box的坐标信息（4k coordinate）<br><img src="/images/fasternet/rpnbbox.jpg" alt="rpnbbox"></p><font color="red">RPN值得注意的地方: </font><br>- RPN在原图的尺度上选择anchor的大小<br>- anchor的数目是feature map上每个像素选择9个长宽比不同的矩形<br>- soft Max层用于判断anchor是否为前景（含有目标）<br>- bounding box regression 预测的输出是anchor的偏移变换<br>- proposal层，结合前景的anchor（背景anchor被忽略）与anchor偏移变换，对anchor位置进行调整，计算出proposal的精确位置。<br>- bounding  box 本质上是学习一个W权重矩阵，即那个1*1的网络的参数（输出为4K regreason,对应anchor的（x，y,w,h）四个偏移），利用W参数乘以 CNN pool5层输出的features map，通过最小二乘，得到anchor的偏移。<br>- 为什么bounding box regression不直接预测坐标呢？ 因为坐标间的关系不是简单的一维关系，难以优化。当anchor 与 ground truth比较接近时，他们之间的位置关系（偏移）就可以用一维关系来近似。<br>- proposal层输出的proposal坐标是在原图的尺度上的proposal坐标。<br><br>#### proposal layer<br>RPN 最后一层为proposal layer，用于前景anchors，以及anchor对应的边框回归微调参数$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$和im_info=[M, N, scale_factor]（传入Faster RCNN前首先reshape到固定MxN，im_info则保存了此次缩放的所有信息）来计算产生的proposal位置，<strong>此时输出的proposal坐标为原图尺度上的proposal坐标</strong>。<br><br><strong>Proposal Layer forward（caffe layer的前传函数）按照以下顺序依次处理：</strong><br><br>- <strong>生成anchors</strong>：利用$[d_{x}(A),d_{y}(A),d_{w}(A),d_{h}(A)]$对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致）<br>- 按照输入的foreground softmax scores<strong>由大到小排序anchors</strong>，<strong>提取前pre_nms_topN(e.g. 6000)个anchors，</strong>即提取修正位置后的foreground anchors。<br>- <strong>限定超出图像边界的foreground anchors为图像边界</strong>（防止后续roi pooling时proposal超出图像边界）<br>- <strong>剔除非常小（width&lt;threshold or height&lt;threshold）的foreground anchors</strong><br>- <strong>进行nonmaximum suppression</strong><br>- <strong>再次按照nms后的foreground softmax scores由大到小排序fg anchors，提取前post_nms_topN(e.g. 300)结果作为proposal = [x1, y1, x2, y2]输出。</strong><br>输出的proposal=[x1, y1, x2, y2]，由于在第三步中将anchors映射回原图判断是否超出边界，所以<strong>这里输出的proposal是对应MxN输入图像尺度的</strong>。<br>RPN网络结构主要步骤如下：<br><strong>生成anchors -&gt; softmax分类器提取前景 anchors -&gt; bbox reg回归前景 anchors -&gt; Proposal Layer生成proposals</strong><br><br>#### RoI pooling layer<br>RoI Pooling layer负责收集proposal，并计算出proposal feature maps，送入后续网络。Rol pooling层有2个输入：<br>- 原始的feature maps<br>- RPN输出的proposal boxes（大小各不相同）<br><br><strong>RoI Pooling layer forward过程：</strong><br><br>- 由于proposal是对应$ M\times N$ 尺度的，所以首先使用spatial_scale参数将其映射回 $(M/16)\times(N/16) $大小的feature map尺度；<br>- 再将每个proposal对应的feature map区域水平分为 $\text{pooled_w}\times \text{pooled_h} $的网格；<br>- 对网格的每一份都进行max pooling处理。<br><br>经过上述处理后，即使大小不同的proposal输出结果都是 $\text{pooled_w}\times \text{pooled_h}$ 固定大小，实现了固定长度输出。<br><br>#### Classification<br><br>Classification部分利用已经获得的proposal feature maps，通过full connect层与softmax计算每个proposal具体属于那个类别（如人，车，电视等），输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置偏移量bbox_pred，用于回归更加精确的目标检测框。<br><img src="/images/fasternet/classfication.jpg" alt="classfication"><br>从PoI Pooling获取到7x7=49大小的proposal feature maps后，送入后续网络，可以看到做了如下2件事：<br>- 通过全连接和softmax对proposals进行分类<br>- 再次对proposals进行bounding box regression，获取更高精度的rect box<br><br>#### Faster R-CNN训练<br>Faster R-CNN的训练，是在已经训练好的model（如VGG_CNN_M_1024，VGG，ZF）的基础上继续进行训练。实际中训练过程分为6个步骤：<br><br>- 在已经训练好的model上，训练RPN网络<br>- 利用步骤1中训练好的RPN网络<br>- 第一次训练Fast RCNN网络<br>- 第二训练RPN网络<br>- 再次利用步骤4中训练好的RPN网络<br>- 第二次训练Fast RCNN网络<br>可以看到训练过程类似于一种“迭代”的过程，不过只循环了2次。至于只循环了2次的原因是应为作者提到：”A similar alternating training can be run for more iterations, but we have observed negligible improvements”，即循环更多次没有提升了。<br><br><img src="/images/fasternet/train.jpg" alt="train"><br><br>#### RPN 训练<br><br>与检测网络类似的是，依然使用Conv Layers提取feature maps。整个网络使用的Loss如下：<br>$$<br>L({p_i},{t_i})=\frac{1}{N_{cls}}\sum_{i} L_{cls}(p_i,p_i^*)+\lambda \frac{1}{N_{reg}}\sum_{i} p_i^* L_{reg} (t_i,t_i^*)<br>$$<br><br>上述公式中 i 表示anchors index，$ p_{i}$ 表示foreground softmax probability，$p_{i}^{*}$代表对应的GT predict概率（即当第i个anchor与GT间IoU&gt;0.7，认为是该anchor是foreground，$p_{i}^{*}=1$；反之IoU&lt;0.3时，认为是该anchor是background，$ p_{i}^{*}=0 $；至于那些0.3&lt;IoU&lt;0.7的anchor则不参与训练）；t代表predict bounding box，$ t^{*} $ 代表对应foreground anchor对应的GT box。可以看到，整个Loss分为2部分：<br><br>- cls loss，即rpn_cls_loss层计算的softmax loss，用于分类anchors为forground与background的网络训练<br>- reg loss，即rpn_loss_bbox层计算的soomth L1 loss，用于bounding box regression网络训练。注意在该loss中乘了 $p_{i}^{*}$ ，相当于只关心foreground anchors的回归（其实在回归中也完全没必要去关心background）。<br><br><font color="red">Smooth L1 loss 相比于L2 loss对离群点更加不敏感，更加鲁棒。当预测值与目标相差很大时，L2 loss的梯度是x-t，容易产生梯度爆炸，而L1的梯度为常数，使用L1 loss 可以防止梯度爆炸。 </font><p>关于softMax loss 和 边框回归loss与fast RCNN 相同。<a href="http://perper.site/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener">链接</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fast RCNN详解</title>
      <link href="/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/14/Fast-RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="Fast-RCNN详解"><a href="#Fast-RCNN详解" class="headerlink" title="Fast RCNN详解"></a>Fast RCNN详解</h3><p>SPP-Net改造了RCNN，使用SPP layer使得输入图片大小不受限制，同时使用region proposal映射的方式，大大加速了目标检测的速度，但是SPP-net训练需要花费很多时间，同时fine-tune不能越过SPP层，因为pyramid BP开销太大了（金字塔感受野比较大），只能fine-tune全连接层，tune不到卷积层，所以在一些较深的网络上准确率上不去。<br>Fast RCNN 受到SPP-Net网络，在网络卷积层后加入ROI层（region of interesting）。此外，损失函数使用了多任务损失函数(multi-task loss)，将分类和边框回归两个loss统一到一个网络中一起训练。</p><blockquote><p>Fast RCNN<br>submit time: 2015<br><a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>Fast RCNN网络结构如下：<br><img src="/images/fastnet/fastnet.jpg" alt="fast RCNN"><br><strong>Fast RCNN关键步骤：</strong></p><ul><li>select search 算法提取2k个region proposal 区域</li><li>将整张图片输入CNN网络中，提取出整张图片的特征</li><li>将2k个region proposal区域映射到feature maps上（RoI projection）</li><li>通过RoI pooling layer，将features map上的大小不一致的region proposal变成固定长度的特征向量。</li><li>将特征向量通过一系列FCs层分别输入softMax，以及bbox regression。利用Softmax Loss(探测分类概率) 和Smooth L1 Loss(探测边框回归)对分类概率和边框回归(Bounding box regression)联合训练。</li></ul><h4 id="ROI-pooling-layer"><a href="#ROI-pooling-layer" class="headerlink" title="ROI pooling layer"></a>ROI pooling layer</h4><p>RoI池化层使用<strong>最大池化</strong>将任何有效区域内的特征转化成一个小的<strong>带有固定空间范围HxW（比如7×7）的特征图</strong>，其中H和W是层的超参数，和任何特定的RoI无关。本文中，一个RoI是针对卷积特征图的一个矩形窗口。每个RoI定义成四元组（r, c, h, w），左上角为（r, c），高和宽是（h, w）。<br>RoI最大池化将hxw的RoI窗口分成HxW的子窗口网格，每个子窗口大小大约是h/H x w/W。然后每个子窗口进行最大池化放入网格对应的单元。池化以标准最大池化的形式独立应用在每个特征图的channel上。RoI层是SPPnets中的空间金字塔层的一个特例，因为他是一个一层的金字塔结构。<strong>即将一个h<em>w大小的框转化为H</em>W大小的框，每个H*W的网格为h/H x w/W区域内最大的值(max-pooling)表示。</strong></p><h4 id="为目标检测任务做微调"><a href="#为目标检测任务做微调" class="headerlink" title="为目标检测任务做微调"></a>为目标检测任务做微调</h4><ul><li>分层采样得到SGD的<strong>mini-batch</strong>，首先采样N个images，然后每个image采样R/N个ROIs。来自同一个image的ROIs在前向后向传输时共享计算和内存，减小N 则能降低mini-batch的计算。这种分层采样的策略实际中不会减慢收敛速度。作者使用N=2, R=128， 并发现SGD迭代次数比R-CNN的还少。</li><li>联合优化softmax分类器和bbox regressor回归器</li></ul><h4 id="Multi-task-Loss"><a href="#Multi-task-Loss" class="headerlink" title="Multi-task Loss"></a>Multi-task Loss</h4><h5 id="softmax类别分类器"><a href="#softmax类别分类器" class="headerlink" title="softmax类别分类器"></a>softmax类别分类器</h5><p>R-CNN与SPPNet均使用SVM作为分类器，而Fast R-CNN使用softmax作为分类器，以下为真实类属u的log loss，即p的值越到loss越接近1。<br>$$<br>L_{cls}(p, u) = -logp_u<br>$$</p><p>softmax函数可以将连续数值转换为相对概率：<br>$$<br>P_i= \frac{e^{V_i}}{\sum_i^C{e^{V_i}}}​<br>$$<br>实际应用中，<strong>使用 Softmax 需要注意数值溢出的问题</strong>。因为有指数运算，如果 V 数值很大，经过指数运算后的数值往往可能有溢出的可能。所以，<strong>需要对 V 进行一些数值处理：即 V 中的每个元素减去 V 中的最大值</strong>。<br>$$<br>\begin{align}<br>D = \max(V) \nonumber\\<br>P_i= \frac{e^{V_i-D}}{\sum_i^C{e^{V_i-D}}} \nonumber<br>\end{align}<br>$$<br>由于log函数不会改变函数单调性，所以通常对softMax函数取一个 $-\log$，表示损失函数。</p><h5 id="边框回归loss："><a href="#边框回归loss：" class="headerlink" title="边框回归loss："></a>边框回归loss：</h5><p>边框回归使用$L_1$ loss，第二个loss $L_{loc}$是定义真值和预测值上，第一个是针对类u的真实标注约束框回归目标 $v=(v_x, v_y, v_w, v_h)$，第二个也是针对类u的预测值$t^u = (t^u_x, t^u_y, t^u_w, t^u_h)$。对于约束框回归，边框回归的loss为：<br>$$<br>L_{loc}(t^{u},v) = \sum_{ i \in {x,y,w,h}} smooth_{L_{1}}(t_i^u - u_i)<br>$$<br>其中：<br><img src="/images/fastnet/L_1loss.png" alt="L_1loss"></p><h5 id="联合loss："><a href="#联合loss：" class="headerlink" title="联合loss："></a>联合loss：</h5><p>$$<br>L(p,u,t^u,v) = L_{cls}(p,u)+\lambda[u\geq 1]  L_{loc}(t^{u},v)<br>$$</p><p>其中中括号项代表这样一个函数：当u ≥ 1时，返回1，否则返回0。根据约定代表全部剩余一切的背景类标注成u=0。所以对于背景RoI而言，没有真是标注框信息，因而$L_{loc}$就忽略了。</p><h4 id="Mini-Batch-采样"><a href="#Mini-Batch-采样" class="headerlink" title="Mini-Batch 采样"></a>Mini-Batch 采样</h4><p>微调阶段，每次SGD迭代所用的mini-batch从N=2个images中获取， 这N个images随机选择，mini-batch的大小为128，每个image中采样64个ROIs。其中25%的样本为正样本，也就是IOU大于0.5的，其他样本为负样本，同样使用了困难负样本挖掘的方法（hard negative mining），也就是负样本的IOU区间为[0.1，0.5），负样本的u=0，$[u\geq 1]$函数为艾弗森指示函数。</p><h4 id="RoI-反向传播"><a href="#RoI-反向传播" class="headerlink" title="RoI 反向传播"></a>RoI 反向传播</h4><p>不同于SPPNet，ROI Pooling可以反向传播，以Max Pooling为例，根据链式法则，对于最大位置的神经元偏导数为1，对于其他神经元偏导数为0。ROI Pooling 不用于常规Pooling，因为很多的region proposal的感受野可能是相同的或者是重叠的，因此在一个Batch_Size内，我们需要对于这些重叠的神经元偏导数进行求和，因此反向传播公式如下：<br>$$<br>\frac{\partial L }{ \partial x_{i}} = \sum_r \sum_{j} [i = i^*(r,j)]\frac{\partial L }{\partial y_{rj}}<br>$$</p><ul><li>$i^*(r, j) = argmax (i)∈R(r,j)$，也就是在R(r, j)这个区域中做max pooling得到的结果</li><li>$[i =  i  * (r, j)]$ 是一个条件表达式，就是判断input的xi是否是max pooling的结果，如果不是，输出的梯度就不传到这个值上面,不提供loss</li><li>r是RoI数量，j是在一个region中，与x对应的输出个数</li><li>$y_{rj}$是第j个跟x对应的输出</li></ul><p>如下，RoI层反向传播例子：<br><img src="/images/fastnet/roiBP.png" alt="roiBP"><br>fast rcnn的网络结构如下：<br><img src="/images/fastnet/structure.png" alt="structure"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SPP-Net详解</title>
      <link href="/2019/02/13/SPP-Net%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/13/SPP-Net%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h3 id="SPP-Net详解"><a href="#SPP-Net详解" class="headerlink" title="SPP-Net详解"></a>SPP-Net详解</h3><p>在fast RCNN 之前，RCNN的进化中SPP Net的思想对其贡献很大，下面先介绍一下SPP Net。</p><h4 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h4><blockquote><p>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition<br>submit time: 2015<br><a href="https://arxiv.org/pdf/1406.4729.pdf" target="_blank" rel="noopener">arxiv link</a> </p></blockquote><p>空间金字塔池化spatial pyramid pooling，是一种词袋(Bag-of-Words, BoW)模型的扩展。池袋模型是计算机视觉领域最成功的方法之一。它将图像切分成粗糙到精细各种级别，然后整合其中的局部特征。SPP-net允许任意尺寸的输入，也允许图像可以有各种尺寸和缩放尺度。SPP使用了多级别的空间箱(bin)，而滑窗池化则只用了一个窗口尺寸。多级池化对于物体的变形十分鲁棒。<br><strong>RCNN的不足之处</strong><br> 1）<strong>输入图像需要crop成固定尺寸将导致失真</strong>：rcnn里将所有的region warp成固定尺寸，导致图片会出现不同程度的缺失和失真扭曲<br>2）时间和空间成本高：对每个region proposals都需要过一遍AlexNet，且需要落盘到本地磁盘，存储量大<br>3）检测速度慢：对每个regions proposals均需要分别提取特征，用VGG16一幅图片需要47s</p><p><strong>SPP-Net关键步骤：</strong></p><ul><li>通过<strong>select search算法</strong>提取出2k个proposal region</li><li>将整张图片输入CNN中提取特征，得到整张图片的feature maps</li><li>将选择性搜索得到的2k个proposal区域<strong>映射</strong>到feature maps上(RCNN需要对每一个proposal提取一次特征，SPP-net只需要提取一次)</li><li>对feature map上的候选框采用<strong>金字塔空间池化</strong>，提取出固定长度的特征向量，输入FC层(SPP-net不需要对图片进行crop等操作)</li><li>将proposals区域的特征向量输入SVM分类器中进行类别分类。</li></ul><p><img src="/images/sppnet/whole.png" alt="whole"></p><h4 id="SPP-Net-解决了下面几个问题："><a href="#SPP-Net-解决了下面几个问题：" class="headerlink" title="SPP-Net 解决了下面几个问题："></a>SPP-Net 解决了下面几个问题：</h4><ol><li><font color="red">如何解决输入图片尺寸必须固定的要求？</font><h5 id="金字塔池化"><a href="#金字塔池化" class="headerlink" title="金字塔池化"></a>金字塔池化</h5> <img src="/images/sppnet/pooling layer.png" alt="pooling layer"><br>如上图由features map上确定的region proposal大小不固定，将提取的region proposal分别经过三个卷积4*4，2*2，1*1，都将得到一个长度为21的向量(21是数据集类别数，可以通过调整卷积核大小来调整)，因此不需要对region proposal 进行尺寸调整。<br> <img src="/images/sppnet/crop.png" alt="crop"></li><li><font color="red">如何解决只进行一次特征提取的要求?</font><br> SPP-Net在原图上选择region proposals区域，随后对图片提取特征，得到整张图片的features map，然后通过映射将region proposals区域映射到features map上，得到region proposal区域的特征。因此仅仅需要对原图提取一次特征即可。<br> <img src="/images/sppnet/compare.png" alt="compare"></li><li><font color="red">如何将region proposal映射到特征空间?</font><br>SPP-Net在提取完整图像的feature map后，要将候选框的位置映射到feature map中得到对应特征。映射原则如下：<br>假设(x,y)是原始图像上的坐标点，(x′,y′)是特征图上的坐标，<strong>S是CNN中所有的步长的乘积</strong>，那么左上角的点转换公式如下：<br>$$x′=\frac{x}{S}+1$$<br>右下角的点转换公式为：<br>$$x′=\frac{x}{S}−1$$<br>计算S有下面例子：<br><img src="/images/sppnet/stride.png" alt="stride"><br>论文中使用的ZF-5: S = 2*2*2*2 = 16<br>Overleaf-5/7：S = 2*3*2 = 12</li><li><font color="red">SPP-Net训练策略：</font><br>理论上，无论输入什么尺寸的图像，都可以输入SPP-net中进行训练。但是实际上由于GPU实现中，更适合在固定尺寸的输入图像上，因此提出了一些训练策略。</li></ol><ul><li>Single-size training:使用固定的224x224的输入，是从原始图像中裁切得到的，目的是为了数据扩增；对于给定的输入尺寸，可以预先计算出空间金字塔池化需要的bin size，假如feature map是axa的大小，那么在SPP layer中，窗口尺寸$win=\frac{a}{n}$上取整，步长$stride=\frac{a}{n}$下取整。</li><li>Multi-size training：考虑两种输入，180x180和224x224，这里不再用裁切，而是直接进行缩放，比如把224x224的图像直接缩放为180x180，它们之间的区别只是分辨率不同。实现两个固定输入尺寸的网络，训练过程中先在1号网络上训练一个epoch，然后用它的权重去初始化2号网络，训练下一个epoch；如此转换训练。通过共享两种尺寸输入的网络参数，实现了不同输入尺寸的SPP-Net的训练。</li></ul><h4 id="原始图片中的ROI如何映射到到feature-map"><a href="#原始图片中的ROI如何映射到到feature-map" class="headerlink" title="原始图片中的ROI如何映射到到feature map"></a>原始图片中的ROI如何映射到到feature map</h4><p><strong>感受野：</strong><br>卷积神经网络CNN中，某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。感受野的大小是由kernel size，stride，padding , outputsize 一起决定的。<br><img src="/images/sppnet/inspect field.jpg" alt="inspect field"><br><strong>经过一层卷积后输出的features map大小计算：</strong><br>   $$W_2 = （W_1- K + 2P）/S + 1$$<br>（其中 $W_1$是输入卷积层的特征的尺寸，K是卷积核大小，P是填充padding，S是步长stride）<br><strong>上一层features map大小计算：</strong><br>  $$W_1 = (W_2 - 1)*S -2P+K$$ </p><p><strong>感受野的计算：</strong><br>感受野是这一层一个元素对应输入层的区域大小，可以一层一层回推到输入层。对于这一层相对于上一层的感受野也就是卷积核的大小。<br>当已知上一层的感受野计算下一层的感受野时有：<br>$$<br>r = (m-1) <em> stride+ksize<br>$$<br>其中m为上一层的感受野。<br><strong>空洞卷积的感受野计算：</strong><br>dilate rate = 1与普通卷积相同。dilate rate = 2可以视为卷积核由3\</em>3变成了5*5，计算方法相同。对于dilate rate = 3，可可视为卷积核变成了9*9。<br><strong>感受野坐标映射：</strong><br>     $$p_i = s_i \cdot p_{i+1} +( (k_i -1)/2 - padding)$$<br>     <strong>SPP-Net中的坐标映射：</strong><br>     SPP-Net 是把原始ROI的左上角和右下角 映射到 feature map上的两个对应点。 有了feature map上的两队角点就确定了 对应的 feature map 区域(下图中橙色)。变换公式见上。<br>     <img src="/images/sppnet/spp.png" alt="spp"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p> SPPNet在R-CNN的基础上提出了改进，通过候选区域和feature map的映射，配合SPP层的使用，从而达到了CNN层的共享计算，减少了运算时间，允许输入图片的大小不固定。Fast R-CNN受SPPNet的启发，进一步改进完网络。</p><p> <img src="/images/sppnet/spp_net.png" alt="spp net"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RCNN详解</title>
      <link href="/2019/02/11/RCNN%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/11/RCNN%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><p>目标检测任务主要有两个不同的思路。一种思路是借鉴语义分割的做法，这方面的工作有YOLO和SSD另一种思路是把目标检测看作分类任务（bounding box中对象的类别）和回归任务（回归bounding box）的组合。主要的工作有R-CNN，SPP-Net，Fast R-CNN，Faster R-CNN。方法一速度快但精度稍差，方法二速度慢但精度高，是主流方法。</p><h4 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h4><p>RCNN: Region-based Convolutional Network<br>Submitted on 2014 </p><p>RCNN目标识别的主要任务为检测物体类别以及边框的大小以及位置。<br><strong>主要贡献：</strong></p><ul><li>根据Selective search 算法提取Region proposal。</li><li>将每个Region Proposal 缩放到统一大小后输入CNN，输出固定大小的特征。</li><li>将特征用SVM进行分类。</li><li>训练一个回归器，对边框（bounding box）进行微调。</li></ul><p><strong>边框的选择：</strong><br>原始产生边框的方法为通过滑窗的方式产生region proposal，作者做过实验，原话如下：</p><blockquote><p>我们也考虑了采用滑动窗口方法。然而，在我们的网络中，具有五个卷积层的单元在输入图像中具有非常大的接收场（195×195像素）和步进（32×32像素），这使得在滑动窗口内的精确定位成为开放的技术挑战。</p></blockquote><p><strong>selective search 算法</strong></p><ul><li>使用一种过分割手段，将图像分割成小区域 (2k~3k 个)</li><li>查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置</li><li>输出所有曾经存在过的区域，所谓候选区域</li></ul><p>selective search 合并规则：<strong>颜色相近(颜色直方图)；纹理相近(梯度直方图)；合并后总面积小的；合并后总面积在其BBOX中所占比例大的(保证合并后形状规则)</strong></p><p><strong>多样化与后处理</strong><br>为尽可能不遗漏候选区域，上述操作在多个颜色空间中同时进行（RGB,HSV,Lab等）。在一个颜色空间中，使用上述四条规则的不同组合进行合并。所有颜色空间与所有规则的全部结果，在去除重复后，都作为候选区域输出。</p><p><img src="/images/selective search.png" alt="selective search"></p><h4 id="RCNN卷积："><a href="#RCNN卷积：" class="headerlink" title="RCNN卷积："></a><strong>RCNN卷积：</strong></h4><p><img src="/images/RCNN.png" alt="RCNN"><br>将生成的region proposal <strong>减去像素平均值</strong>后，使用<strong>各向异性</strong>的缩放方式（直接缩放），将图片缩放到<strong>227*227</strong>大小，随后对每个proposal 提取特征，<strong>对每个proposal经过五层卷积层以及两层全连接层，在cf7层得到提取出的4096维特征。</strong>提取特征使用了<strong>pre-training的AlexNet网络</strong>，作者原文如下：</p><blockquote><p>检测面临的第二个挑战是带标记的数据很少，目前可用的数量不足以训练大型CNN … 本文的第二个主要贡献是识别网络在大型辅助数据集(ILSVRC)上进行监督预训练，然后对小数据集(PASCAL)进行指定域的微调，这是在数据稀缺时训练高容量CNN模型的有效方法。</p></blockquote><p><strong>即提取特征需要训练一个大型的CNN识别网络</strong>，作者使用了hinton在2012年image net上做识别的AlexNet，此网络提取的特征为4096维，之后送入一个4096-&gt;1000的全连接(fc)层进行1000个类别的分类，学习率0.01。<strong>针对特定的小数据集对该识别网络进行微调</strong>。同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。 学习率0.001，网络各层参数不变。每一个batch包含32个正样本（属于20类）和96个背景（背景多于正样本是因为实际图片中背景部分就是比样本要多）。网络结构如下：<br><img src="/images/提取特征.png" alt="提取特征"></p><h4 id="目标类别与分类器"><a href="#目标类别与分类器" class="headerlink" title="目标类别与分类器"></a>目标类别与分类器</h4><p><font color="red"><strong>作者在cf7层提取出特征后，未直接通过最后一层softMax层进行分类，而是将cf7层提取出的特征用于训练SVM分类器。</strong></font>原因在于： svm训练和cnn训练过程的正负样本定义方式不同，softmax得到的结果比svm精度低。</p><ul><li>cnn在训练的时候，对训练数据做了比较宽松的标注（例如bounding box只包含物体的一部分，我们也把它标注为正样本），采用这个方法的主要原因在于<strong>CNN容易过拟合，要扩大正样本的样本量</strong>，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松<strong>(IOU只要大于0.5的region proposal都被标注为正样本)</strong></li><li>svm分类器原理是最小距离最大化，样本的定义越严格分类效果越好，所以对于训练样本数据的IOU要求比较严格<strong>（大于0.7为正样本）</strong></li></ul><p><strong>SVM训练</strong><br>对每一个类别训练一个二分类器，我们用IoU重叠阈值来解决正负样本的问题，<strong>在0.3阈值以下的区域被定义为负样本，0.3-0.7阈值的样本被忽略，0.7-1.0的样本被定义为正样本。</strong>（重叠阈值0.3是通过在验证集上尝试了0,0.1,…,0.5的不同阈值选择出来的。选择这个阈值是很重要，将很大程度上影响最后的结果。）正样本被简单地定义为每个类的检测框真值。我们提取了特征并应用了训练标签，就可以对每一个类别训练一个线性SVM，当我们用CNN提取2000个候选框，可以得到2000 * 4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096 * N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，就可以得到结果。</p><p><strong>边框回归</strong><br>学习一个<strong>线性回归器</strong>，用于bounding box的边框回归，<strong>输入为Alexnet pool5的输出</strong>。bbox回归认为候选区域和ground-truth之间是线性关系(因为在最后从SVM内确定出来的区域比较接近ground-truth,这里近似认为可以线性关系)。<br>训练回归器的输入为N对值，${(P^i, G^i)}_{i=1,2,…,N}$，分别为候选区域的框坐标和真实的框坐标。这里选用的Proposal必须和Ground Truth的IoU大于0.6才算是正样本(避免一些远离groundtruth的边框参与计算)，通过学习四个变换函数，得到变换后的边框坐标。<br><img src="/images/边框回归.png" alt="边框回归"><br>对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。所谓脊回归，就是对于一个线性模型，在原来的损失函数加入参数的l2范数的惩罚项。<br>当使用最小二乘法计算线性回归模型参数的时候，如果数据集合矩阵（也叫做设计矩阵(design matrix)）XX，存在多重共线性，那么最小二乘法对输入变量中的噪声非常的敏感，其解会极为不稳定。为了解决这个问题，就有了这一节脊回归（Ridge Regression ）。<br><strong>脊回归</strong><br>当矩阵存在多重共线性的时候（数学上称为病态矩阵），最小二乘法求得的参数W在数值上会非常的大，输入变量X有一个微小的变动，其反应在输出结果上也会变得非常大，因而结果对输入变量噪声非常敏感。</p><p>如果能限制参数W的增长，使W不会变得特别大，那么模型对输入W中噪声的敏感度就会降低。这就是脊回归和套索回归（Ridge Regression and Lasso Regrission）的基本思想。为了限制模型参数W的数值大小，就在模型原来的目标函数上加上一个惩罚项，这个过程叫做正则化（Regularization）。</p><ul><li>如果惩罚项是参数的$l_2$范数，就是脊回归(Ridge Regression)</li><li>如果惩罚项是参数的$l_1$范数，就是套索回归（Lasso Regrission）</li><li>正则化同时也是防止过拟合有效的手段</li></ul><p><strong>非极大值抑制（NMS）：</strong><br>RCNN 网络会对一个目标标定了多个标定框，使用极大值抑制算法滤掉多余的标定框。<br><img src="/images/beforeNMS.png" alt="beforeNMS| center"><br>NMS算法搜索局部的极大值，并且抑制那些分数低的窗口。首先对RCNN产生的边框分类概率从大到小排序，将最大概率边框设置为保留边框，并选择与该边框重合IoU大于某一个阈值的所有边框，将他们过滤，接下来从剩下的边框中重复上述步骤，直到所有边框都被处理过。<br><img src="/images/afterNMS.png" alt="afterNMS | center"></p><p>RCNN网络结构图：<br><img src="/images/rcnn1.png" alt="rcnn1"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MAC 私人订制</title>
      <link href="/2019/02/07/MAC-%E7%A7%81%E4%BA%BA%E8%AE%A2%E5%88%B6/"/>
      <url>/2019/02/07/MAC-%E7%A7%81%E4%BA%BA%E8%AE%A2%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h4 id="配置git"><a href="#配置git" class="headerlink" title="配置git"></a>配置git</h4><p>Mac上安装Xcode命令行工具，命令行工具包是一个小型独立包,可供下载独立于Xcode的和允许您执行命令行开发OS X:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-select --install</span><br></pre></td></tr></table></figure></p><p>设置用户名，邮箱：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;wenhui-zhou&quot;</span><br><span class="line">git config --global user.email &quot;765647930@qq.com&quot;</span><br></pre></td></tr></table></figure></p><p>创建ssh-key：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></p><p>在当前目录下找到/.ssh/id_rsa.pub，将其中的内容配置到GitHub账号中的ssh中完成配置。<br>验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></p><p>若输出一下内容则说明配置成功。</p><blockquote><p>Hi WenHui-Zhou! You’ve successfully authenticated, but GitHub does not provide shell access.</p></blockquote><h4 id="网络端口"><a href="#网络端口" class="headerlink" title="网络端口"></a>网络端口</h4><p>80端口：http端口，用于网页访问<br>443端口：https访问端口，用于https的网页访问<br>http与https是两种不同的协议，https协议安全xing</p><h4 id="Mac-系统环境配置"><a href="#Mac-系统环境配置" class="headerlink" title="Mac 系统环境配置"></a>Mac 系统环境配置</h4><p>Mac系统的环境变量，加载顺序为：</p><ol><li>/etc/profile </li><li>/etc/paths </li><li>~/.bash_profile </li><li>~/.bash_login </li><li>~/.profile </li><li>~/.bashrc</li></ol><p>/etc/profile和/etc/paths是系统级别的，系统启动就会加载，后面几个是当前用户级的环境变量。后面3个按照从前往后的顺序读取，如果~/.bash_profile文件存在，则后面的几个文件就会被忽略不读了，如果~/.bash_profile文件不存在，才会以此类推读取后面的文件。~/.bashrc没有上述规则，它是bash shell打开的时候载入的。</p><h4 id="windows上hexo博客迁移到Mac上的方法"><a href="#windows上hexo博客迁移到Mac上的方法" class="headerlink" title="windows上hexo博客迁移到Mac上的方法"></a>windows上hexo博客迁移到Mac上的方法</h4><ul><li>安装node.js</li><li>安装git</li><li>安装hexo（使用npm安装）</li><li>新建博客文件夹，依次<code>hexo init,sudo npm install</code></li><li>将原来文件夹中的文件替换Mac文件夹中的文件</li><li>博客恢复使用</li></ul><h4 id="安装anaconda后设置iterm的默认python版本"><a href="#安装anaconda后设置iterm的默认python版本" class="headerlink" title="安装anaconda后设置iterm的默认python版本"></a>安装anaconda后设置iterm的默认python版本</h4><p>打开iterm环境配置文件：<code>vim ~/.zshrc</code><br>在文件末尾添加指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### Mac选择大段文字的方法</span><br><span class="line"></span><br><span class="line">由于使用触控板，抛弃了鼠标，但是选择大段文字则成了一个问题，还好有解决方案：</span><br><span class="line">选择段落：鼠标在段落内点击三下即选中</span><br><span class="line">选择大段篇幅：按住shift，鼠标在起始位置点击一下，在末尾点击一下即选中。</span><br><span class="line"></span><br><span class="line">#### 电池使用次数</span><br><span class="line"></span><br><span class="line">mac居然有点电池的充放电次数一说，以后使用电脑尽量插着插头。</span><br><span class="line">人事有代谢给我一个启发就是，万事万物都有尽头的一天，比如一个茶杯，身体，细胞等等，每天都在消耗，只是没人给你列一个上限而已。</span><br><span class="line"></span><br><span class="line">#### MAC 开启本地服务器</span><br><span class="line">MAC 开启本地的服务器，可以通过http的方式传递文件，具体做法如下：</span><br><span class="line">1. 打开终端，移动到需要分享文件的文件夹下；</span><br><span class="line">2. 在终端中输入：`python -m http.server 80`，开启web服务；</span><br><span class="line">3. 查询本机ip（百度输入本机IP即可），随后访问 `http://ip` 即可。</span><br><span class="line">4. 该方法下载文件夹：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">wget -r -np -nH -R index.html http://include/file</span><br></pre></td></tr></table></figure></p><ul><li><code>-r</code> : 遍历所有子目录</li><li><code>-np</code> : 不到上一层子目录去</li><li><code>-nH</code> : 不要将文件保存到主机名文件夹</li><li><code>-R index.html</code> : 不下载 index.html 文件</li></ul>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法-递归</title>
      <link href="/2019/01/30/%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/"/>
      <url>/2019/01/30/%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h4 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h4><p>递归(recursion)，是指函数的定义中使用函数自身的方法。用于表示用相似的方法重复事物的过程。</p><h5 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h5><p>从 1~n 这 n 个整数中随机选取任意多个，输出所有可能的选择方案。</p><h5 id="输出格式："><a href="#输出格式：" class="headerlink" title="输出格式："></a>输出格式：</h5><p>输入一个整数n。</p><h5 id="输出格式：-1"><a href="#输出格式：-1" class="headerlink" title="输出格式："></a>输出格式：</h5><p>输出所有的方案。</p><h5 id="数据范围："><a href="#数据范围：" class="headerlink" title="数据范围："></a>数据范围：</h5><p>1 $\leq n \leq15$</p><h5 id="输入样例："><a href="#输入样例：" class="headerlink" title="输入样例："></a>输入样例：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure><h5 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">3</span><br><span class="line">2</span><br><span class="line">2 3</span><br><span class="line">1</span><br><span class="line">1 3</span><br><span class="line">1 2</span><br><span class="line">1 2 3</span><br></pre></td></tr></table></figure><h4 id="方案一："><a href="#方案一：" class="headerlink" title="方案一："></a>方案一：</h4><p>主循环确定方案的长度，循环里头进一个dfs()，来控制填入的数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">20</span>];<span class="comment">//记录序列</span></span><br><span class="line"><span class="keyword">int</span> vis[<span class="number">20</span>]; <span class="comment">//记录是否访问过</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> pos,<span class="keyword">int</span> tar,<span class="keyword">int</span> start)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(pos == tar+<span class="number">1</span>)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;=tar;i++)&#123;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;a[i]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = start;i&lt;=n;i++)&#123;</span><br><span class="line"><span class="keyword">if</span>(!vis[i])&#123;</span><br><span class="line">vis[i] = <span class="literal">true</span>;</span><br><span class="line">a[pos] = i;</span><br><span class="line">dfs(pos+<span class="number">1</span>,tar,i+<span class="number">1</span>);</span><br><span class="line">vis[i] = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; n;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i&lt;= n;i++)&#123;</span><br><span class="line">dfs(<span class="number">1</span>,i,<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="二进制优化："><a href="#二进制优化：" class="headerlink" title="二进制优化："></a>二进制优化：</h4><p>用二进制表示选了哪些书，用来代替之前使用的a[20]数组。<br><strong>| 或操作将i位置置为1（选中）：</strong>  <code>state |= 1&lt;&lt;(i-1)</code><br><strong>^ 异或操作将i位置还原为0（未选）：</strong> <code>state ^= 1&lt;&lt;(i-1)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">bool vis[20];</span><br><span class="line">void dfs(int pos,int tar,int start,int state)&#123;</span><br><span class="line">if(pos == tar+1)&#123;</span><br><span class="line">for(i = 1;i&lt;=n;i++)&#123;</span><br><span class="line">if((state&gt;&gt;i)&amp;1) cout &lt;&lt; i&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">for(int i = start;i&lt;=n;i++)&#123;</span><br><span class="line">if(!vis[i])&#123;</span><br><span class="line">vis[i] = true;</span><br><span class="line">state |= 1&lt;&lt;(i-1);</span><br><span class="line">dfs(pos+1,tar,i+1,state);</span><br><span class="line">state ^= 1&lt;&lt;(i-1);</span><br><span class="line">vis[i] = false;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">cout&lt;&lt;endl;</span><br><span class="line">cin &gt;&gt; n;</span><br><span class="line">for(int i =1;i&lt;= n;i++)&#123;</span><br><span class="line">dfs(1,i,start = 1, 0);</span><br><span class="line">&#125;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="状态压缩递归："><a href="#状态压缩递归：" class="headerlink" title="状态压缩递归："></a>状态压缩递归：</h4><p>用一个$2^n$的数的各个位上取0或取1来表示选中或未选中。</p><blockquote><p>000 ： \n<br>001 ： 1<br>010 ： 2<br>011 ： 3<br>……</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">int n;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">cin&gt;&gt; n;</span><br><span class="line">for(int state = 1;state&lt; 1&lt;&lt;n;state++)&#123;</span><br><span class="line">for(int j = 0;j&lt;n;j++)&#123;</span><br><span class="line">if(state&gt;&gt;j&amp;1) cout&lt;&lt;j+1&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="状态压缩的递归："><a href="#状态压缩的递归：" class="headerlink" title="状态压缩的递归："></a>状态压缩的递归：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int n;</span><br><span class="line">//u表示当前枚举到的数，state表示二进制的表示，记录哪些数字被选过</span><br><span class="line">void dfs(int u,int state)&#123;</span><br><span class="line">if(u == n)&#123;</span><br><span class="line">for(int i = 0;i&lt;=n;i++)&#123;</span><br><span class="line">if(state &gt;&gt; i &amp;1)&#123;</span><br><span class="line">cout&lt;&lt;i+1&lt;&lt;&quot; &quot;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">cout&lt;&lt;endl;</span><br><span class="line">return;</span><br><span class="line">&#125;</span><br><span class="line">dfs(u+1,state); // 不用u这个数</span><br><span class="line">dfs(u+1,state|(1&lt;&lt;u)); //用u这个数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">cin &gt;&gt;n;</span><br><span class="line">dfs(0,0);</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循环神经网络RNN,LSTM</title>
      <link href="/2019/01/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-LSTM/"/>
      <url>/2019/01/29/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-LSTM/</url>
      
        <content type="html"><![CDATA[<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><h4 id="RNN适用背景"><a href="#RNN适用背景" class="headerlink" title="RNN适用背景"></a>RNN适用背景</h4><p>当一段序列是连续的，且序列长度不一（音频序列），难以直接差分成一个个独立的样本来训练DNN/CNN，传统的神经网络无法用前面的场景来影响后面的预测。此时，可以使用RNN来解决这个问题。</p><p>循环神经网络内部具有循环边，允许信息持续存在。前一个节点传递消息给他的后继者。结构如下图：<br><img src="/images/RNN.jpg" alt="RNN"><br>正是借助于这个链式的信息传导结构，RNN在处理序列相关的数据时，具有先天的优势。</p><h4 id="RNN的缺点"><a href="#RNN的缺点" class="headerlink" title="RNN的缺点"></a>RNN的缺点</h4><p>在需要利用的历史信息离当前节点较近时，RNN能够利用该信息去进一步学习。但是当需要的背景信息离当前的节点距离较远时，RNN无法学到这些信息，即RNN无法处理这种需要长连接的信息。</p><h3 id="LSTM-NetWork"><a href="#LSTM-NetWork" class="headerlink" title="LSTM NetWork"></a>LSTM NetWork</h3><p>长短式记忆模型是一种特殊的RNN模型，能够解决长依赖无法学习的问题。<br>所有循环神经网络均具有相同的模块链，在标准的RNN中，该重复的模块链是一个简单的tanh层。<br><img src="/images/RNN module.jpg" alt="RNN module"><br>LSTM中的重复模块则由四个部分组成。<br><img src="/images/LSTM.jpg" alt="LSTM"></p><h4 id="LSTM背后的思想"><a href="#LSTM背后的思想" class="headerlink" title="LSTM背后的思想"></a>LSTM背后的思想</h4><p>LSTM关键是细胞的状态，表示细胞状态的这条水平线从图中顶部穿过。细胞在链上运行，其下有一些小的线性操作作用在它的上面。<br><img src="/images/cell state.jpg" alt="cell state"><br>LSTM模型中具有很多门（gate）结构。他有一个sigmoid神经节点和一个点乘运算组成。sigmoid输出0到1之间的数字，表明这个组件可以有多少信息可以通过。LSTM中有三个门，用于控制细胞的状态。<br><img src="/images/gate.jpg" alt="gate"></p><h4 id="一步步拆解LSTM"><a href="#一步步拆解LSTM" class="headerlink" title="一步步拆解LSTM"></a>一步步拆解LSTM</h4><p>LSTM第一步为决定从输入中丢弃什么信息，这一步称为<strong>遗忘门</strong>，遗忘门的输入为$h_{t-1}$（前一个细胞的输出）与$X_t$（当前细胞输入），通过一个sigmoid，输出0-1之间的数，添加到上一个细胞的状态$C_{t-1}$中。<br><img src="/images/loss gate.jpg" alt="loss gate"><br>下一步决定细胞需要的存储信息。该部分由两步构成。sigmoid层决定了哪些值需要更新，接下来一个tanh层创建候选向量$C_t$，该向量将会被加入到细胞状态中。<br><img src="/images/input gate.jpg" alt="input gate"><br>更新上一个状态值$C_{t-1}$，生成$C_{t}$<br><img src="/images/output_gate_2.jpg" alt="output_gate_2"><br>最后决定我们要输出什么，此输出将局域我们的细胞状态，首先先运行一个sigmoid层，他决定我们要输出的细胞状态的哪些部分。随后将单元格通过tanh（将值规范化到-1到1之间），并乘以sigmoid 输出，得到最后的$h_t$部分。<img src="/images/output.jpg" alt="output"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol><li><strong>为什么具有记忆功能</strong>：由于存在递归结构，上一时刻的隐层的状态参与到了这个时刻的计算过程中，即每一步的选择和决策参考了上一次的状态。</li><li><strong>为什么LSTM的记忆时间长（解决长连接问题）</strong>：由于传统的RNN在训练过程中引入一个激活函数，经过多步推导之后，这个乘子连乘，当参数发生轻微变化时，梯度将发生距离的波动，甚至将导致梯度消失问题。为了解决这个问题，特意设计了一个CEC常数误差流，即激活函数是线性的，将上一个节点的output由连乘改为连加。$|f_{ij}(x) W_{ij}| = 1,W_{ij}$是上一个状态与下一个状态的权值连接。误差没有衰减，使得序列很长之前带来的影响仍然能够保持到最后。LSTM在原来RNN的基础上是一个叫做CEC的部件，这个部件保证了误差将以常数的形式流动。同时添加输入门和输出门，使得模型变成非线性的。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目总结</title>
      <link href="/2019/01/25/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"/>
      <url>/2019/01/25/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="sketch2Cloth虚拟试衣总结"><a href="#sketch2Cloth虚拟试衣总结" class="headerlink" title="sketch2Cloth虚拟试衣总结"></a>sketch2Cloth虚拟试衣总结</h3><p>虚拟试衣允许用户定制衣服的纹理，颜色。能够改善生成图像的真实感。虚拟试衣项目分成训练数据的处理以及GAN图片生成。</p><h4 id="Human-parsing："><a href="#Human-parsing：" class="headerlink" title="Human-parsing："></a>Human-parsing：</h4><p>输入一张人像图片，使用DeepLab+SSL框架对人体图像不同部位进行解析标记。从而根据不同分类的标记信息可以将图片分割成人体皮肤部分，服饰部分，首饰部分等等。<br><img src="/images/data processing.jpg" alt="data processing"><br>根据不同的标注信息，仅保留含有人体皮肤，脑袋的图片；以及保留仅含有服饰的图片。随后对含有服饰的图片<strong>提取边缘信息</strong>，得到服饰的边缘纹理。最终将人体皮肤信息与服饰边缘信息相结合，得到最终的图片和标记，完成数据的预处理。这样处理的好处是，<strong>保留了绝大部分人体皮肤，头发等信息</strong>，利用GAN进行服饰样式生成时，仅需要生成服饰的颜色，纹理信息，尽可能保证图片的真实感。</p><h4 id="DeepLab-v2"><a href="#DeepLab-v2" class="headerlink" title="DeepLab v2"></a>DeepLab v2</h4><ul><li>将多孔卷积应用到密集预测任务上，有效扩大感受野。</li><li>采用多看空金字塔模型，使用不同采样率多尺度获取图像上下文信息。</li><li>将DCNN与完全连接条件场（CRFS）结合，增强物体边界定位。</li><li>SSL：引入自监督结构敏感学习方法进行训练，将人体姿态引入解析结果中，提升实验性能。</li></ul><h4 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h4><ul><li>canny 算子：通过计算像素梯度幅值，方向，确定图片的边缘信息。使用费最大值抑制使得边缘更加清晰。比较看重像素的梯度变化，不看重整体的空间信息。</li><li>edge detection using structure forest：使用随机森林算法学习一个隐状态，将图形映射成边缘。</li><li>HED：整体嵌套边缘检测，将多次度的Edge进行融合，得到整体信息对边缘信息的反映。HED有vgg改造而来，可提取图片特征信息，多次度同和，反映了空间特征。</li></ul><h4 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h4><p>在CGAN的基础上加上L1约束，作为图片的生成器。</p><ul><li>GAN 生成对抗网络，同时训练一个生成器和判别器。优化生成器使其生成的东西更接近原始样本，优化判别器，使其能够更好地判断样本的真假。JS散度：度量两个概率分布的相似度，但是当两个分布距离很远时，将会导致梯度消失。因此引入wasserstein（earth-mover距离）：能够在联合分布的下，样本间的距离，当两个分布距离很远时，也可以提供梯度。</li><li>CGAN条件生成网络，GAN生成数据太过于自由，数据不可控。因此条件生成对抗网络，在生成器与判别器作用是加入一个条件概率，使得结果更符合实际条件。</li><li>pix2pix：在CGAN的基础上加入L1约束（模糊图片），使得生成图像更接近真实图。自动学习损失函数。使用U-net,使得上层图像获取更多的底层图像信息。</li></ul><h3 id="海量地震数据三维可视化"><a href="#海量地震数据三维可视化" class="headerlink" title="海量地震数据三维可视化"></a>海量地震数据三维可视化</h3><ul><li>地震数据segy文件解析：segy文件为GB级别的数据，对多种格式的解析，里头包含了五种不同的数据存储格式，需要对地震数据进行解析以及筛选合适的数据这些操作。</li><li>地震数据预处理：使用SVD分解技术，留下数据中分量比较中的那部分数据</li><li>数据分块读取：按切片载入内存，设计颜色传递函数，使用shader将绘制部分迁移到GPU上执行。使用shader进行绘制。Shader上分为上色，</li></ul>]]></content>
      
      
      <categories>
          
          <category> 项目总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AutoMatic Image Colorization 整理</title>
      <link href="/2019/01/23/AutoMatic-Image-Colorization-%E6%95%B4%E7%90%86/"/>
      <url>/2019/01/23/AutoMatic-Image-Colorization-%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>《<strong>Let there be Color:</strong>  Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simutaneous Classification》 是由三位知名的日本学者，发表在2016年的SIGGRAPH上，该模型实现的图片颜色恢复效果十分的好。<br>原文地址：<a href="http://iizuka.cs.tsukuba.ac.jp/projects/colorization/data/colorization_sig2016.pdf" target="_blank" rel="noopener">Let there be Color:</a><br>项目地址：<a href="http://iizuka.cs.tsukuba.ac.jp/projects/colorization/en/" target="_blank" rel="noopener">Automatic Image Colorization</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文利用CNN提取图片全局先验信息(global priors)和局部图片特征信息(local image features)，并对特征进行融合，端对端(end to end)的对灰度图片进行自动上色。</p><blockquote><p>图片语义信息：<br>&emsp;视觉层： 即底层颜色，纹理，形状等等。<br>&emsp;对象层： 属性特征，如某一对象某一时刻的状态<br>&emsp;概念层： 最接近人类理解，如室内，室外，沙子，海水等</p></blockquote><p>全局特征将反映：概念层信息，如室内室外，白天黑夜等等<br>局部特征信息反映：局部材质，物体的位置信息等</p><h3 id="色彩空间"><a href="#色彩空间" class="headerlink" title="色彩空间"></a>色彩空间</h3><p>作者采用Lab颜色空间，L表示亮度，a，b表示颜色光谱绿-红和蓝-黄。Lab编码中有一个灰度层，颜色层变为两个，因此只需要预测两个通道。<br><img src="/images/color_space.jpg" alt="Lab颜色空间"><br>由图可以看出人们对亮度信息比较敏感。人眼中有94%的细胞由于探测亮度，6%的细胞用于探测颜色。因此我们将图片保存成灰度图即保留了图片大部分的信息，又节省空间。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/images/model.png" alt="网络结构"><br>网络结构大体由两部分组成。<br><strong>第一部分：</strong> low-level features 低特征提取，mid-level features 中特征提取，fusion layer 融合层，colorization network上色层组成。<br><strong>第二部分：</strong> low-level features 低特征提取，全局特征提取两部分组成。<br>网络的输入为灰度图，第一部分输入是原图，由于第一部分只有卷积操作，因此对图片尺寸没有要求。第二部分输入是经过resize成224<em>224大小的图片。包含全链接层，对输入大小有限制。<br><em>*预测流程：</em></em>将图片输入，经过低特征，中特征和全局特征的提取，一起来预测两个色彩图层即a和b，然后通过上采样，恢复到原图大小，与灰度图层L融合一起组成lab图片。</p><h4 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h4><p>第一部分包含上色层，可以对图片进行上色，但是由于未加入全局的语义信息，所以效果不好。可以这样认为，根据全局特征得到的图片语义信息（室内或室外），利用全局语义信息进一步决定对图片的上色方案。<br><img src="/images/color compare.png" alt="Alt text"></p><h4 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h4><p>网络第二部分是一个标准的卷积神经网络，全局特征提取层输出是一个1*1*256的一个张量，通过融合层将语义信息加入第一部分网络中。整个网络的损失函数为：<br>$$<br>L(y^{color},y^{class}) = ||y^{color} - y^{color,*}||^2_{FRO} - \alpha (y_{l^{class}}^{color} - \log(\sum^{N}_{i = 0} exp(y_i^{class})))<br>$$</p><p>前半部分是一个预测颜色和真实颜色间的一个MSE Loss，后半部分是预测一个分类交叉熵loss。由于分类loss不影响上色，将$\alpha$设置为0，仅适用上色部分的loss。</p><h3 id="融合层"><a href="#融合层" class="headerlink" title="融合层"></a>融合层</h3><p>$$<br>y_{u,v}^{fusion} = \sigma (b + W [y^{global},y^{mid}_{u,v}]^T)<br>$$</p><p>其中$y^{global}$是一个1*1*256的张量，b是一个$\frac{H}{8}*\frac{H}{8}*256$的一个长方体，将y与b头尾拼在一起，构成一个$\frac{H}{8}* \frac{H}{8}*512$的张量。</p><h3 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h3><p>将第二部分的输入换成一张其他风格的图片，图片类型要求相同，最终形成的图片的风格将发生改变。<br><img src="/images/style_change.jpg" alt="风格迁移"></p><h3 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h3><ul><li>网络输入为多分辨率图片</li><li>网络中无池化层</li><li>上采样过程采用最近邻算法</li><li>所有的上色模型无法解决毛衣的上色问题，因为毛衣颜色不存在先验，是不确定的。如天空，海洋的颜色则是确定的。</li></ul><h3 id="PREFERENCE"><a href="#PREFERENCE" class="headerlink" title="PREFERENCE"></a>PREFERENCE</h3><ul><li><a href="https://blog.csdn.net/u010030977/article/details/78846198" target="_blank" rel="noopener">preference1</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型性能评估指标概要</title>
      <link href="/2019/01/23/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E6%A6%82%E8%A6%81/"/>
      <url>/2019/01/23/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E6%A6%82%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<p>模型性能评价指标能够对模型预测结果性能好坏进行评价。以下列举了常用的模型评价指标。</p><h3 id="AUC评价指标"><a href="#AUC评价指标" class="headerlink" title="AUC评价指标"></a>AUC评价指标</h3><p>AUC（area under thr curve）指标常用来评估二分类模型的性能，指的是ROC曲线与x轴围成的面积。AUC不依赖于判决阀值。<br>判别矩阵如下:</p><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:right">正样本</th><th style="text-align:center">负样本</th></tr></thead><tbody><tr><td style="text-align:left">预测为正</td><td style="text-align:right">TP(真正例)</td><td style="text-align:center">FP(假正例)</td></tr><tr><td style="text-align:left">预测为负</td><td style="text-align:right">FN(假负例)</td><td style="text-align:center">TN(真负例)</td></tr></tbody></table><p>随着阈值t的取值不同，有：<br>真正率（正样本预测为正的概率）：<br>$$<br>TPR = \frac{TP}{TP+FN}<br>$$<br>假正率（负样本预测为正的概率）：<br>$$<br>FPR = \frac{FP}{FP+TN}<br>$$<br>因此TPR与FPR是关于t的一个函数：<br><img src="/images/predict_matrix.jpg" alt="判别参数关系图"></p><p>AUC即为如下曲线下的面积：<br><img src="/images/AUC.jpg" alt="AUC为曲线下方面积"></p><p><img src="/images/nlp/image-20200314114031556.png" alt="image-20200314114031556" style="zoom:50%;"><br>$$<br>AUC = \int_{t = 0}^{1} y(t) dx(t)<br>$$<br>AUC实际表现为把正样本排在负样本前面的概率。同时AUC对政府样本的比例不敏感。AUC越大表明模型区分正例和负例的能力越强，AUC常常依赖于具体的任务。</p><p><strong>AUC准确来说，在二分类中，就是正例预测为正的概率，大于负例预测为正的概率。AUC越大预分类能力越强，AUC对样本正负比例不敏感。</strong></p><p><strong>精确率：</strong><br>$$<br>Pricision = \frac{TP}{TP+FP}<br>$$<br>精确度pricision指的是我判断为真的里头，确实为真的概率。</p><p><strong>召回率：</strong><br>$$<br>Recall = \frac{TP}{TP+FN}<br>$$<br>召回率recall指的是我判断是真的里头，确实为真的占样本所有为真的概率。</p><p><strong>F1 score:</strong><br>$$<br>\frac{2}{F_{1}} = \frac{1}{Precision}+\frac{1}{Recall}<br>$$<br>F1是precision和recall的调和均值， F1 score作为正负样本不均衡的评价方式.<br><a href="https://blog.argcv.com/articles/1036.c" target="_blank" rel="noopener">参考链接</a></p><h3 id="mAP"><a href="#mAP" class="headerlink" title="mAP:"></a>mAP:</h3><p>mAP指mean average precision，即各个类别AP的平均值。</p><p>AP：指precision与recall曲线的下面部分。</p><p>对于IoU = 0.5:0.05:0.95分别计算mAP，随后平均得到最后的mAP：指的是将IoU从0.5一直递增到0.95，然后每一个IoU均计算一个AP值，然后对所有的AP值取平均，得到最终的mAP。</p><h3 id="BenchMark，SOTA-与Baseline"><a href="#BenchMark，SOTA-与Baseline" class="headerlink" title="BenchMark，SOTA 与Baseline"></a>BenchMark，SOTA 与Baseline</h3><p>一个算法的benchmark指的是，它的<strong>性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏</strong>。<br>state-of-the-art（SOTA）：能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。</p><p>baseline：表示<strong>比这个算法性能还差的基本上不能接受的</strong>，除非方法上有革命性的创新点，而且还有巨大的改进空间和超越benchmark的潜力，只是因为是发展初期而性能有限。所以baseline有一个自带的含义就是“<strong>性能起点</strong>”。</p><p>总结一下就是：<strong>benchmark是属于较好的水准，baseline则代表了及格线。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 模型评价 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>human head detect summary</title>
      <link href="/2019/01/23/human%20head%20detect%20summary/"/>
      <url>/2019/01/23/human%20head%20detect%20summary/</url>
      
        <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ 刷题常用数据及函数的语法记录</title>
      <link href="/2019/01/21/C-%E5%88%B7%E9%A2%98%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/"/>
      <url>/2019/01/21/C-%E5%88%B7%E9%A2%98%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<ul><li><h3 id="字符串操作："><a href="#字符串操作：" class="headerlink" title="字符串操作："></a>字符串操作：</h3><p> <strong>int to string：</strong> &emsp;<code>string a  = to_string(int)</code><br> <strong>string to int：</strong>&emsp; <code>int a = stoi(string)</code><br> <strong>char to int：</strong> &emsp;  <code>int a = char_b - 48</code><br> <strong>字符串中查找字符： </strong></p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> a = <span class="string">"abcd"</span>;</span><br><span class="line"><span class="built_in">string</span> b = <span class="string">"ab"</span>;</span><br><span class="line"><span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> pos = a.find(b,start); <span class="comment">// start可省略，默认从0开始</span></span><br><span class="line"><span class="comment">//如果查找不存在返回string::npos</span></span><br><span class="line"><span class="keyword">if</span>(a.find(b) == <span class="built_in">string</span>::npos) <span class="built_in">cout</span>&lt;&lt;<span class="string">"dont exist"</span>;</span><br></pre></td></tr></table></figure><p> <strong>截取子串： </strong>&emsp; <code>string a  = astring.substr(startpos,length)</code></p></li><li><h3 id="vector操作："><a href="#vector操作：" class="headerlink" title="vector操作："></a><strong>vector操作：</strong></h3><p> <strong>vector 删除：</strong><br> <code>vector_a.erase(iter_pos)</code>,<code>vector_a.erase(iter_begin(),iter_end())</code><br> <strong>vector排序：</strong>匿名函数的形式<br> <code>nums.sort(nums.begin(),nums.end(),[](int a,int b){return a&gt;b;})</code></p></li><li><h3 id="unordered-map操作"><a href="#unordered-map操作" class="headerlink" title="unordered_map操作:"></a><strong>unordered_map操作:</strong></h3><p>  unordered_map实现使用了哈希表，可以在$O(1)$时间复杂度访问到对应元素，缺点为要花费较高的空间复杂度。<br>  map实现使用的对应结构为红黑树（类似平衡树），查找元素使用的复杂度为$O(\log n)$。<br>  <strong>unordered_map声明：</strong> &emsp;<code>unordered_map&lt;char,int&gt; map;</code><br>  <strong>unordered_map插入键值对：</strong><br>  &emsp;<code>map[&#39;a&#39;] = 1;</code>,<code>map.insert(make_pair(&#39;a&#39;,1));</code><br>  <strong>unordered_map查找元素：</strong><br>  &emsp; <code>if(map.find(&#39;B&#39;) == map.end()){dont exist}</code>，<br>  &emsp; <code>if(map.count(&#39;B&#39;) == 0){dont exist}</code><br>  <strong>unordered_map移除元素：</strong><br>  &emsp;<code>map.erase(map.begin())</code>,<br>  &emsp;<code>map.erase(map.begin(),map.end())</code>,<br>  &emsp;<code>map.erase(&#39;A&#39;)</code></p></li><li><h3 id="中值的取法："><a href="#中值的取法：" class="headerlink" title="中值的取法："></a><strong>中值的取法：</strong></h3>  防止整数溢出：<code>int mid = left + (right-left)/2;</code></li><li><h3 id="大数组开成全局变量："><a href="#大数组开成全局变量：" class="headerlink" title="大数组开成全局变量："></a><strong>大数组开成全局变量：</strong></h3>  <code>int weight[N][M];</code><br>  原因是计算机会将把虚拟内存空间分配给程序。虚拟内存空间分为栈空间和堆空间。所有开在函数内部的变量会开在栈里，所有开在静态变量，全局变量会开在堆里。C++默认栈空间大小为4M，所以一般将大数组开到全局变量中去。</li><li><h3 id="异或的作用（-）："><a href="#异或的作用（-）：" class="headerlink" title="异或的作用（^）："></a><strong>异或的作用（^）：</strong></h3><ol><li>用异或实现配偶：0^1=1，1^1=0</li><li><p>lowbit运算：给一个n快速找到二进制中最低的一个1，lowbit(100100) = 100 -&gt;树状数组的基本操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int lowbit(int n)&#123;</span><br><span class="line">      return (~n + 1) &amp; n; // return (-n)^n; 补码就是负数</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>位运算与底层的电路实现有关，无论什么操作都只用O(1)时间。</p></li></ol></li></ul><ul><li><h3 id="STL中的全排列操作："><a href="#STL中的全排列操作：" class="headerlink" title="STL中的全排列操作："></a><strong>STL中的全排列操作：</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">while(next_permutation(A.begin(),A.end()))&#123; ... &#125; //从小到大产生排列组合，当排列组合全部产生结束时返回false</span><br><span class="line">prev_permutation(A.begin(),A.end());   // 从大到小生成排列数，直接改变vector里头的值</span><br></pre></td></tr></table></figure></li><li><h3 id="sprintf"><a href="#sprintf" class="headerlink" title="sprintf()"></a>sprintf()</h3><p>   C 库函数 int sprintf(char <em>str, const char </em>format, …) 发送格式化输出到 str 所指向的字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sprintf(str, &quot;Pi 的值 = %f&quot;, M_PI); // str = &quot;Pi 的值 = 3.141593&quot;</span><br><span class="line">sprintf(str,&quot;%02d:%02d&quot;,h,m); // %02d 指的是整数h的宽度为2，如果不够的话前面补0.(3-&gt;03)</span><br></pre></td></tr></table></figure></li><li><h3 id="set用法：-set是一个内部元素唯一的集合，定义：set-lt-vector-lt-int-gt-gt-res"><a href="#set用法：-set是一个内部元素唯一的集合，定义：set-lt-vector-lt-int-gt-gt-res" class="headerlink" title="set用法： set是一个内部元素唯一的集合，定义：set&lt;vector&lt;int&gt;&gt; res;"></a><strong>set用法：</strong> set是一个内部元素唯一的集合，定义：<code>set&lt;vector&lt;int&gt;&gt; res;</code></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> iter = res.begin();iter!=res.end();iter++) ...</span><br><span class="line">res.clear(); <span class="comment">//删除所有的元素</span></span><br><span class="line">res.empty(); <span class="comment">//判断是否为空集合</span></span><br><span class="line">res.rbegin() == res.end();</span><br></pre></td></tr></table></figure></li><li><h3 id="vector的用法："><a href="#vector的用法：" class="headerlink" title="vector的用法："></a>vector的用法：</h3><p>  初始化：<code>vector&lt;int&gt; vec(size,0);</code><br>  添加元素：<code>vec.push_back(val);vec.insert(vec.begin(),val);</code><br>  删除元素：<code>vec.pop_back();vec.erase(vec.begin())</code></p><pre><code>`vec.erase(vec.begin(), vec.begin()+3);`</code></pre><p>  查找：<code>find(vec.begin(),vec.end(),val) != vec.end()</code><br>  排序:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sort(vec.begin(),vec.end()); </span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">myfun</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> a&lt;b; <span class="comment">// 生序</span></span><br><span class="line">&#125;</span><br><span class="line">sort(vec.begin(),vec.end(),myfun); </span><br><span class="line">sort(vec.begin(),vec.end(),[](<span class="keyword">int</span> a,<span class="keyword">int</span> b)&#123;<span class="keyword">return</span> a&lt;b;&#125;)</span><br></pre></td></tr></table></figure></li><li><h3 id="lambda-表达式："><a href="#lambda-表达式：" class="headerlink" title="lambda 表达式："></a>lambda 表达式：</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> func = [c](<span class="keyword">int</span> a,<span class="keyword">int</span> b) &#123; <span class="keyword">return</span> a &lt; b; &#125;;</span><br></pre></td></tr></table></figure><p>  其中c为表达式外边的变量，a,b为传入表达式的变量。</p></li><li><h3 id="string-中find函数"><a href="#string-中find函数" class="headerlink" title="string 中find函数"></a>string 中find函数</h3><p><code>int pos = str.find(char,int begin = 0,int end = str.size())</code></p><p><code>//if(pos == string::npos) cant find it else return the index of char</code></p></li><li><h3 id="string-中的substr"><a href="#string-中的substr" class="headerlink" title="string 中的substr"></a>string 中的substr</h3><p><code>string str = s.substr(begin,num)//表示从begin开始，共num个数</code></p><p><code>string str = s.substr(begin)//表示从begin开始到最后</code></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Github 建站</title>
      <link href="/2019/01/19/Github-%E5%BB%BA%E7%AB%99/"/>
      <url>/2019/01/19/Github-%E5%BB%BA%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>github上搭建一个博客网站（windows）</p><p><strong>1. 前期准备</strong></p><ul><li><strong>node.js:</strong> 2009年由Ryan推出的，基于javascript（负责解释并执行代码）与google 浏览器V8引擎（c++编写的一个超快的解释器）的一个后端服务器应用程序。旨在增大服务器并发连接的数量（非阻塞，时间驱动I/O）。</li><li><strong>git:</strong>开源分布式版本控制系统。<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">见链接</a></li><li><strong>hexo:</strong>一个快速简洁的博客框架。<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">见链接</a>，hexo支持makdown，<strong>是一个生成静态网页，并将网页上传到服务器上的工具。</strong></li></ul><p><strong>2. Github上创建一个registry</strong></p><ul><li>Github上新建项目，项目必须要遵守格式：账户名.github.io，同时勾选Initialize this repository with a README。（eg：WenHuiZhou.github.io）</li></ul><p><strong>3. 下载安装node.js，以及git</strong><br><strong>4. 安装hexo</strong></p><ul><li>命令行内输入指令：<code>npm install -g hexo-cli</code><br>&emsp;&emsp;npm (node package manager)：运行在node.js上的一个使用javascript写的类库管理器，npm内置于node.js中，作为node.js的包管理器。可以使用npm来查找安装一些库(nmp install jquery.js)。<br>&emsp;&emsp;有时使用npm进行下载文件时经常出现网络上的问题，此时可以对npm换源。<code>npm config set registry https://registry.npm.taobao.org</code></li><li>创建文件夹，作为hexo博客文件存储文件夹，输入指令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init&lt;blog&gt;</span><br><span class="line"><span class="built_in">cd</span> &lt;blog&gt;</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><pre><code>完成创建后hexo将生成如下文件：</code></pre><p><img src="/images/hexo_forder.jpg" alt="hexo生成目录结构"></p><ul><li>正常使用中修改最多的文件夹为<strong>_config.yml</strong>，其中包括博客的基础配置以及模板信息。<strong>source</strong>为写文章所需的目录，如果要针对下载的模板修改，那么需要修改<strong>themes</strong>模板目录。</li><li><strong>启动hexo：</strong><br><code>hexo g</code>：hexo生成网页（generate），<br><code>hexo s</code>：hexo启动服务器server。</li></ul><p><strong>5 . hexo 连接 github</strong></p><ul><li>打开git bash，进入blog文件夹</li><li><p>配置用户名，以及邮箱输入：<br><code>git config --global user.name WenHuiZhou</code><br><code>git config --global user.email myemail</code></p><p>  每次使用git进行commit时都需要用到用户名和邮箱记录。用于指定push到的github。</p></li></ul><p><strong>6. SSH密钥登陆：</strong></p><ul><li>利用密钥生成器制作一对密钥——一只公钥和一只私钥。将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。<ul><li>生成密钥对：<code>ssh -keygen -t rsa -C &quot;myemail.com&quot;</code>，将生成id_rsa 和 id_rsa.pub两个文件。</li><li>添加密钥对到ssh-agent：<code>eval &quot;$(ssh-agent -s)&quot;</code></li><li>添加生成的SSH key到ssh-agent：<code>ssh-add ~/.ssh/id_rsa</code></li></ul></li></ul><p><strong>7 .设置github的ssh密匙</strong></p><ul><li>打开github setting，将添加ssh key，将id_rsa.pub内容复制进去即可。</li><li>在git bash上输入<code>ssh -T git@github.com</code> 此时返回 hi WenHuiZhou表明配置成功。</li></ul><p><strong>8 . 配置_config.yml文件</strong></p><ul><li><p>在_config.yml文件最后添加：<br><code>deploy:type:gitrepository:git@github.com:WenHui-Zhou/WenHuiZhou.github.io.gitbranch: master</code></p><p>  repository地址可以从github上download那得到。</p></li></ul><p><strong>9. 在hexo上写博客</strong></p><ul><li><code>hexo new post &quot;blog name&quot;</code>，hexo将会在<strong>source</strong>文件夹中生成.md文件，编辑.md文件写博客。</li><li><code>hexo s</code>: 进入本地博客地址观察效果</li><li><code>hexo d -g</code>: 将博客上传至github上</li><li>输入github上的访问地址：<strong><a href="https://wenhui-zhou.github.io/">https://wenhui-zhou.github.io/</a></strong>即可博客网站。</li></ul><p><strong>10. 总结</strong></p><ul><li>使用hexo和github搭建了一个博客</li><li>使用hexo模板 maupassant对博客进行美化，<a href="https://www.haomwei.com/technology/maupassant-hexo.html" target="_blank" rel="noopener">见链接</a></li><li>该模板还需要做大量的个人定制工作，这是接下来要做的。</li></ul><p><strong>PREFERENCE</strong></p><ul><li><a href="https://www.jianshu.com/p/1c888a6b8297?utm_source=oschina-app" target="_blank" rel="noopener">reference1</a></li><li><a href="https://buptwc.com/2018/05/10/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%B6%85%E9%AA%9A%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%9F/" target="_blank" rel="noopener">reference2</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 建站 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> netStation </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
