<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WenHuiZhou</title>
  
  <subtitle>perper（打起精神！）</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wenhui-zhou.github.io/"/>
  <updated>2020-05-21T13:55:46.728Z</updated>
  <id>https://wenhui-zhou.github.io/</id>
  
  <author>
    <name>WenHuiZhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>序列化RNN系列</title>
    <link href="https://wenhui-zhou.github.io/2020/05/21/%E5%BA%8F%E5%88%97%E5%8C%96RNN%E7%B3%BB%E5%88%97/"/>
    <id>https://wenhui-zhou.github.io/2020/05/21/序列化RNN系列/</id>
    <published>2020-05-21T05:52:45.000Z</published>
    <updated>2020-05-21T13:55:46.728Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么需要RNN"><a href="#为什么需要RNN" class="headerlink" title="为什么需要RNN"></a>为什么需要RNN</h3><p>当我们遇到一些数据是序列的，长度不定的，数据的先后，顺序，是存在相互影响的语义的。对于这类问题，因此就出现了RNN这种结构，能够能够的提取序列数据的特征。</p><h3 id="RNN结构"><a href="#RNN结构" class="headerlink" title="RNN结构"></a>RNN结构</h3><p><img src="/images/nlp/image-20200521141220698.png" alt="image-20200521141220698" style="zoom:50%;"></p><p>最简单的RNN的结构如上所示，左边是一个RNN单元，右边是将这个单元展示后得到的网络。最早的激活函数使用tanh，该网络的特殊之处在于，下一个阶段网络的输入由上一阶段的输出以及x共同组成，用公式表示如下：<br>$$<br>\begin{array}{l}O_{t}=g\left(V \cdot S_{t}\right) \ S_{t}=f\left(U \cdot X_{t}+W \cdot S_{t-1}\right)\end{array}<br>$$</p><h3 id="RNN的优点"><a href="#RNN的优点" class="headerlink" title="RNN的优点"></a>RNN的优点</h3><ol><li>RNN可以记录时间序列上的信息，对于序列数据，前后语义有着相互联系的场景比较适用。</li><li>RNN可以处理文本，语音这些数据，数据的输出长度可以是不定的。</li></ol><h3 id="RNN的缺点"><a href="#RNN的缺点" class="headerlink" title="RNN的缺点"></a>RNN的缺点</h3><ol><li><p>梯度消失和梯度爆炸问题，当对RNN进行梯度求导的时候，得到的表达式是参数的一个连乘形式，任意时刻对$W_s$求偏导如下：<br>$$<br>\frac{\partial L_{t}}{\partial W_{x}}=\sum_{k=0}^{t} \frac{\partial L_{t}}{\partial O_{t}} \frac{\partial O_{t}}{\partial S_{t}}\left(\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}\right) \frac{\partial S_{k}}{\partial W_{x}}<br>$$<br>随着网络加深，连乘项越来越多，将S用tanh激活函数带入，下面表达式可变为：<br>$$<br>\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}= \prod_{j=k+1}^{t} \tanh ^{\prime} W_{s}<br>$$<br>即一个参数累乘的形式，当网络足够深的时候，如果参数小于一，则会出现梯度消失的问题，如果参数大于1，多次连乘的结果将导致梯度爆炸。</p></li><li><p>RNN网络难以训练，并且如果使用的是tanh或者relu激活函数，它无法处理非常长的序列。</p></li></ol><p>通过上面可以发现，只要解决了掉偏导公式中参数连乘的哪一项就可以解决梯度问题，LSTM就是按照这个思路，将这一项变成0或者1。</p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>LSTM即long short Term memory，LSTM的结构比普通的RNN要复杂一些，由三个门结构组成，分别是遗忘门，输入门，输出门：</p><p><img src="/images/nlp/image-20200521155345276.png" alt="image-20200521155345276" style="zoom:50%;"></p><p>首先是<strong>遗忘门</strong>，对输入的数据做一些选择性的遗忘，控制是否遗忘由sigmoid决定。其次是<strong>输入门</strong>，利用sigmoid对输入数据进行取舍，tanh对输入数据赋予权重。<strong>输出门</strong>：利用sigmoid对输入进行取舍，然后用tanh对数据进行加权，得到下一个输入。</p><p>（通过sigmoid后的特征，最后通过一个乘法加入到网络中）</p><h3 id="为什么LSTM能够解决梯度消失问题"><a href="#为什么LSTM能够解决梯度消失问题" class="headerlink" title="为什么LSTM能够解决梯度消失问题"></a>为什么LSTM能够解决梯度消失问题</h3><p>接在RNN的后面分析，LSTM梯度求导过程每一项中也存在一个累乘项，但是LSTM这个累乘项在LSTM中为0或者为1，因此有效避免了累乘导致的梯度消失问题。</p><p>传统RNN梯度计算如下：<br>$$<br>\frac{\partial L_{3}}{\partial W_{s}}=\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial S_{2}} \frac{\partial S_{2}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial S_{2}} \frac{\partial S_{2}}{\partial S_{1}} \frac{\partial S_{1}}{\partial W_{s}}<br>$$<br>LSTM中有表达式：<br>$$<br>\prod_{j=k+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}}=\prod_{j=k+1}^{t} \tanh ^{\prime} \sigma\left(W_{f} X_{t}+b_{f}\right) \approx 0 | 1<br>$$<br>因此LSTM:<br>$$<br>\frac{\partial L_{3}}{\partial W_{s}}=\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{3}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{2}}{\partial W_{s}}+\frac{\partial L_{3}}{\partial O_{3}} \frac{\partial O_{3}}{\partial S_{3}} \frac{\partial S_{1}}{\partial W_{s}}<br>$$<br>梯度中不存在累乘项，因此可以克服梯度消失和梯度爆炸的问题。</p><h3 id="LSTM具有记忆功能"><a href="#LSTM具有记忆功能" class="headerlink" title="LSTM具有记忆功能"></a>LSTM具有记忆功能</h3><p>由于LSTM每次计算都有参考到上一时刻的LSTM状态，每一步决策均使用到了上一次的中间结果，因此具有记忆功能。</p><h3 id="LSTM具记忆时间长"><a href="#LSTM具记忆时间长" class="headerlink" title="LSTM具记忆时间长"></a>LSTM具记忆时间长</h3><p>由于LSTM将连乘项转化为1或者0，因此有效解决了梯度爆炸和梯度消失的问题，可以保存距离当前位置比较远的位置的信息，因此LSTM具有记忆时间长的功能。</p><h3 id="LSTM存在的问题"><a href="#LSTM存在的问题" class="headerlink" title="LSTM存在的问题"></a>LSTM存在的问题</h3><p>无法并行运算，LSTM计算效率太低。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;为什么需要RNN&quot;&gt;&lt;a href=&quot;#为什么需要RNN&quot; class=&quot;headerlink&quot; title=&quot;为什么需要RNN&quot;&gt;&lt;/a&gt;为什么需要RNN&lt;/h3&gt;&lt;p&gt;当我们遇到一些数据是序列的，长度不定的，数据的先后，顺序，是存在相互影响的语义的。对于这类问
      
    
    </summary>
    
      <category term="面试准备" scheme="https://wenhui-zhou.github.io/categories/%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/"/>
    
    
  </entry>
  
  <entry>
    <title>2D animation,SVG文件</title>
    <link href="https://wenhui-zhou.github.io/2020/05/13/2D-animation-SVG%E6%96%87%E4%BB%B6/"/>
    <id>https://wenhui-zhou.github.io/2020/05/13/2D-animation-SVG文件/</id>
    <published>2020-05-13T08:00:44.000Z</published>
    <updated>2020-05-18T08:18:41.761Z</updated>
    
    <content type="html"><![CDATA[<p>这篇post主要为了了解动画的原理，始末，已经一些常用的技术路线，为之后可能遇到的工作做准备。</p><a id="more"></a><h3 id="动画是什么"><a href="#动画是什么" class="headerlink" title="动画是什么"></a>动画是什么</h3><p>计算机动画即利用计算机绘制技术，绘制图画，为了制造连续的假象，将画面显示在计算机上，然后很块的用另一个相似但有一些移动的画面替代，制造平滑移动的假象。</p><p>由于人脑和眼存在<strong>视觉停留</strong>的现象，眼和脑会将看到的画面存储几分之一秒，然后将场景切换的跳跃平滑掉。因此制作动画的一个基本最低切换帧率为12帧，在这个帧率是人们比较能够接受的帧率。通常电影为24帧，当帧率提升到60帧以上时，为人眼处理图像的极限，画面真实感将不再提升。</p><h3 id="SVG"><a href="#SVG" class="headerlink" title="SVG"></a>SVG</h3><p>SVG是一种基于XML的标记语言，是由万维网联盟开发的开放标准，用于描述二维的矢量图形。是一个基于文本的开放web标准，可以与CSS，DOM，HTML在统一标准下使用。SVG是可伸缩的矢量图像，本质上是一段文本，可以被编辑，检索，压缩，编辑和创建的。</p><p>通过上面的介绍，容易发现SVG和万维网联盟的其他标准类似，是一种专门为了互联网而生的一种产物。</p><p>SVG文件大小比较小，可用代码进行绘图，支持web协议，可在网页中打开。</p><h3 id="pose-animator"><a href="#pose-animator" class="headerlink" title="pose-animator"></a>pose-animator</h3><p>由模型得到的点位信息的结构如下：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200514223027223.png" alt="image-20200514223027223" style="zoom:50%;"></p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200514223058374.png" alt="image-20200514223058374" style="zoom:50%;"></p><p>修改代码，将pose的keypoint信息通过json传入，得到相同的结果：</p><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200518161834873.png" alt="image-20200518161834873" style="zoom:40%;"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇post主要为了了解动画的原理，始末，已经一些常用的技术路线，为之后可能遇到的工作做准备。&lt;/p&gt;
    
    </summary>
    
      <category term="动画" scheme="https://wenhui-zhou.github.io/categories/%E5%8A%A8%E7%94%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>RDSNet总结文档</title>
    <link href="https://wenhui-zhou.github.io/2020/05/12/RDSNet%E6%80%BB%E7%BB%93%E6%96%87%E6%A1%A3/"/>
    <id>https://wenhui-zhou.github.io/2020/05/12/RDSNet总结文档/</id>
    <published>2020-05-12T03:03:27.000Z</published>
    <updated>2020-05-21T05:51:29.407Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="welcome to my blog,enter password to read." />    <label for="pass">welcome to my blog,enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      welcome to my blog,enter password to read.
    
    </summary>
    
      <category term="面试准备" scheme="https://wenhui-zhou.github.io/categories/%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/"/>
    
    
  </entry>
  
  <entry>
    <title>约束项以及约束的含义</title>
    <link href="https://wenhui-zhou.github.io/2020/05/11/%E7%BA%A6%E6%9D%9F%E9%A1%B9%E4%BB%A5%E5%8F%8A%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%90%AB%E4%B9%89/"/>
    <id>https://wenhui-zhou.github.io/2020/05/11/约束项以及约束的含义/</id>
    <published>2020-05-11T08:26:07.000Z</published>
    <updated>2020-05-12T14:57:22.026Z</updated>
    
    <content type="html"><![CDATA[<p>我们在训练神经网络的时候，总是希望网络能够有很强的抗干扰能力，对参数，对数据波动不敏感。因此我们需要引入约束项，规范参数的分布。</p><a id="more"></a><h3 id="扰动敏感"><a href="#扰动敏感" class="headerlink" title="扰动敏感"></a>扰动敏感</h3><p>很多时候我们希望得到一个稳健的模型，稳健的含义<strong>一是对参数扰动稳定性强</strong>，即当模型参数变为$f_w + \Delta x$</p><p><strong>二是对输入的稳定性强。</strong>即当x变成$x+\Delta x$作为输入的时候，网络结果不该发生比较大的变化。</p><h3 id="Lipschitz约束"><a href="#Lipschitz约束" class="headerlink" title="Lipschitz约束"></a>Lipschitz约束</h3><p>当我们希望网络足够稳定，当$||x_1 - x_2||$ 很小时，我们希望$\left|f_{w}\left(x_{1}\right)-f_{w}\left(x_{2}\right)\right|$ 也尽可能小，尽可能谁也说不准，于是Lipschitz提出了一个具体的约束，即存在某个常数C（仅仅与参数有关），<br>$$<br>\left|f_{w}\left(x_{1}\right)-f_{w}\left(x_{2}\right)\right| \leq C(w) \cdot\left|x_{1}-x_{2}\right|<br>$$<br>上诉便是L约束，我们希望C越小越好。</p><p>进一步简化公式，可以将公式转化为如下：<br>$$<br>\left|W\left(x_{1}-x_{2}\right)\right| \leq C\left|x_{1}-x_{2}\right|<br>$$</p><h3 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h3><p>我们可以将上诉的参数C转换为矩阵范数问题，矩阵范数相当于向量的模长。定义矩阵的范式来表示常量C，进而实现L约束。</p><h3 id="F范数"><a href="#F范数" class="headerlink" title="F范数"></a>F范数</h3><p>F范数指的是将矩阵视为一个向量，求解向量的欧式模长：<br>$$<br>|W|_{F}=\sqrt{\sum_{i, j} w_{i j}^{2}}<br>$$<br>通过柯西不等式可以得到F范数是W的一个上界，当我们不要求高的精度的情况下，选择F模是一个比较好的选择（计算量比较小）。</p><h3 id="L2-范数"><a href="#L2-范数" class="headerlink" title="L2 范数"></a>L2 范数</h3><p>L2范数指的是参数的平方和：<br>$$<br>\lambda\left(\sum_{i, j} w_{i j}^{2}\right)<br>$$<br>L2正则项能够很好的满足L约束，从而降低模型对输入扰动的敏感性，将L2正则项加入loss中。</p><p>L2范数将参数控制在比较小的水平，使得网络能够快速收敛，L2参数不会变为0，将选择比较多的特征，同时避免网络的过拟合。</p><h3 id="L1-范数"><a href="#L1-范数" class="headerlink" title="L1 范数"></a>L1 范数</h3><p>L1范数指的是参数的和：<br>$$<br>\sum_{i, j} ||w_{i j}||<br>$$<br>优化L1的目标将导致参数趋于0，使得参数变得稀疏化，使得模型自动选择特征，降低网络的复杂度。</p><p>正则化操作可见：<a href="https://perper.site/2019/07/24/normalization/" target="_blank" rel="noopener">https://perper.site/2019/07/24/normalization/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在训练神经网络的时候，总是希望网络能够有很强的抗干扰能力，对参数，对数据波动不敏感。因此我们需要引入约束项，规范参数的分布。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习总结" scheme="https://wenhui-zhou.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
  </entry>
  
  <entry>
    <title>优化器总结</title>
    <link href="https://wenhui-zhou.github.io/2020/05/04/%E4%BC%98%E5%8C%96%E5%99%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://wenhui-zhou.github.io/2020/05/04/优化器总结/</id>
    <published>2020-05-04T07:15:24.000Z</published>
    <updated>2020-05-11T08:25:17.817Z</updated>
    
    <content type="html"><![CDATA[<p>本文总结了常用的优化器，以及优化器的优缺点等。</p><a id="more"></a><h3 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h3><p>批量梯度下降，每次更新整个数据集计算一次梯度，确定是每次迭代比较耗时，遇到比较大的数据集则比较棘手。BGD容易陷入局部极小值点。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J(\theta)<br>$$</p><h3 id="Stochastic-gradient-Descent"><a href="#Stochastic-gradient-Descent" class="headerlink" title="Stochastic gradient Descent"></a>Stochastic gradient Descent</h3><p>随机梯度下降，每次更新时根据单个样本对梯度进行更新。SGD的优点是计算较快，缺点是会造成loss的剧烈震荡。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i)} ; y^{(i)}\right)<br>$$<br>SGD剧烈震荡可能会使得最后loss降到一个比较小的局部极小值点上。</p><h3 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h3><p>MBGD 小批样本的梯度下降，每次经过n个样本后才更新模型参数。这样的好处是可以降低参数更新时的方差，使得收敛更加稳定，另一方面可以利用矩阵计算来计算计算的速度。<br>$$<br>\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i: i+n)} ; y^{(i: i+n)}\right)<br>$$</p><h3 id="普通梯度下降方法总结"><a href="#普通梯度下降方法总结" class="headerlink" title="普通梯度下降方法总结"></a>普通梯度下降方法总结</h3><ul><li>对于SGD方法来说，算法不能够保证很好的收敛性，如果learning rate选择太小，收敛速度比较慢，如果learning rate 选择过大则loss过分震荡无法收敛。</li><li><p>学习率的一种策略是逐步的降低learning rate的大小，如果数据是稀疏的，我们希望对出现频率低的特征进行大一点的更新。</p></li><li><p>此外对于非凸函数，当梯度下降时，loss陷入鞍点时，所有维度的梯度都为0，导致SGD方法无法更新参数。</p></li></ul><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>针对上面SGD容易陷入局部位置，可以利用前一次梯度更新的方向，作为一个动量，使当前loss脱离当前的位置。</p><p>加入前一次更新的动量，可以使得loss在梯度方向不变的方向上更新速度加快，在梯度方向变化的方向上，使更新速度变慢，可以起到收敛并减小震荡的作用。</p><p>缺点是动量完全取决于上一次的梯度方向，先验知识不足。<br>$$<br>\begin{array}{l}v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta} J(\theta) \ \theta=\theta-v_{t}\end{array}<br>$$</p><h3 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h3><p>NAG在momentum的基础上，对网络下一步更新方向进行微调：<br>$$<br>\begin{array}{l}v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta} J\left(\theta-\gamma v_{t-1}\right) \ \theta=\theta-v_{t}\end{array}<br>$$<br>利用动量调整网络下一步迭代的方向。</p><p> NAG 会先在前一步的累积梯度上有一个大的跳跃，然后衡量一下梯度做一下修正，这种预期的更新可以避免我们走的太快。</p><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>Adagrad在上面的基础上，改进了学习率，由于上诉的学习率无法自己调整，因此Adagrad通过累计梯度的方式，学习模型的学习率。<br>$$<br>\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot \nabla_{\theta} J\left(\theta_{i}\right)<br>$$<br>其中 $G_t$ 是个对角矩阵， (i,i) 元素就是 t 时刻参数 $θ_i$ 的梯度平方和。</p><p>我们累计每一次梯度的平方，接着让学习率除以它的开方。这个的作用是为了改变不同参数的学习率。假如一个参数的梯度一直很大，那么通过这个约束，它改变的就越少。假如一个参数的梯度一直很小，那么通过这个约束它，它变化的也就越快。</p><p>缺点是，随着梯度的累积，权重步长难免变得很小。</p><h3 id="adadelta"><a href="#adadelta" class="headerlink" title="adadelta"></a>adadelta</h3><p>adadelta使用梯度的均方根（先平方，在求平均，最后开方）作为分母，替代了所有t时刻的梯度平方，仅仅需要保留上一次的均方根和这一次的梯度值，减小了算法占用的空间。</p><p>相比于adagrad，分母使用了梯度平方的衰减平均值，公式如下：<br>$$<br>\Delta \theta_{t}=-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}+\epsilon}}g_{t}<br>$$<br>其中：<br>$$<br>g_{t}=\nabla_{\theta} J\left(\theta\right)<br>$$<br>E的计算仅仅与上一次的E与这次的梯度有关：<br>$$<br>E\left[g^{2}\right]_{t}=\gamma E\left[g^{2}\right]_{t-1}+(1-\gamma) g_{t}^{2}<br>$$<br>更新公式为：<br>$$<br>\theta_t =\theta_{t-1} + \Delta \theta_{t-1}<br>$$<br>学习率初值为：RMS[Δθ]</p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>这个方法与adadelta类似，是hinton在课上提出来的，建议将E的超参数设置为0.9：<br>$$<br>\begin{array}{l}E\left[g^{2}\right]_{t}=0.9 E\left[g^{2}\right]_{t-1}+0.1 g_{t}^{2} \ \theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}+\epsilon}} g_{t}\end{array}<br>$$</p><h3 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h3><p>adam设计了一种新的参数自适应学习的方法，存储了梯度的平方等衰减值，更新公式如下：<br>$$<br>\begin{array}{l}m_{t}=\beta_{1} m_{t-1}+\left(1-\beta_{1}\right) g_{t} \ v_{t}=\beta_{2} v_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2}\end{array}<br>$$<br>其中m，v初始化为0，初始化为0矫正检查之后即为：<br>$$<br>\begin{array}{l}\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}} \ \hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}}\end{array}<br>$$<br>迭代公式如下：<br>$$<br>\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{v}_{t}}+\epsilon} \hat{m}_{t}<br>$$<br>即adam同时结合了momentum和adadelta的特点，对梯度和累积梯度做一个叠加。</p><p>参数设置为β1 ＝ 0.9，β2 ＝ 0.999，ϵ ＝ 10e−8。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BGD方法是最基础的梯度下降方法，每次遍历整个数据集</p><p>SGD方法对单个样本计算梯度，速度快，但是容易陷入鞍点</p><p>MBGD方法采用小样本更新梯度，loss震荡比较平缓</p><p>Momentum方法采用前一个梯度方向作为动量，使得梯度快速下降，能够脱离鞍点</p><p>NAG在动量的基础上，加上对梯度方向上的调整</p><p>adagrad方法通过累积梯度平方对学习率进行调整</p><p>adadelta方法通过计算每一时刻梯度的平方和的根，通过动量的方式调整平方根，从而调整梯度</p><p>RMSprop在adadelta的基础上，设定了动量的参数，是adadelta的一种</p><p>adam使用一种结合动量和动态调节学习率的方法</p><p>如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam（动态调节loss）</p><p>Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum</p><p>随着梯度变的稀疏，Adam 比 RMSprop 效果会好。</p><p>整体来讲，Adam 是最好的选择。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文总结了常用的优化器，以及优化器的优缺点等。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习总结" scheme="https://wenhui-zhou.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
  </entry>
  
</feed>
