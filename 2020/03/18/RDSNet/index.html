<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="cheer up"><meta name="baidu-site-verification" content="9pSIuwCbvi"><meta name="google-site-verification" content="YzcCTjF6VoVlNAtL37_S4vFjzFwYTAFZzD51Il2IGKY"><title>RDSNet | WenHuiZhou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">RDSNet</h1><a id="logo" href="/.">WenHuiZhou</a><p class="description">perper（打起精神！）</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">RDSNet</h1><div class="post-meta">Mar 18, 2020<span> | </span><span class="category"><a href="/categories/深度学习/">深度学习</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2020/03/18/RDSNet/#vcomment"><span class="valine-comment-count" data-xid="/2020/03/18/RDSNet/"></span><span> 条评论</span></a><div class="post-content"><p>RDSNet的一个亮点在于同一个网络同时学习目标检测和目标分割，这两个任务相互促进提升模型精度。RDSNet提出了双流结构，分别取学习目标尺度和像素尺度上的物体。同时两条流上的信息相互融合，相互促进各自的训练。object level为pixel level提供了实例信息，为pixel提供一些分割上的先验。pixel level为object level重新定义边框的定位，提升精度。</p>
<p>在这个结构中，来自两个流的信息是交替融合，即对象层的信息引入实例意识和翻译差异到像素级，像素级的信息-在对象级别细化对象的定位精度作为回报</p>
<a id="more"></a>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>目标识别</strong>上，找出一个tight bounding box是非常具有挑战的，即要么无法全部选中目标，要么bounding 太大选中过多。</p>
<p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200318110910599.png" alt="image-20200318110910599" style="zoom:40%;"></p>
<p>一个主要的原因是我们在做边框回归的时候，由于逐点回归并不能直接感知整个对象，因此将这个问题转化为pixel wise更加合理，即根绝mask的大小，找到一个最小的包围盒。</p>
<p><strong>实例分割</strong>的目的是进一步预测除类别外的每个对象的每像素二值掩码。核心思想是：实例分割时，像素类别是具有实例感知的。如在MASK-RCNN中，mask是根据网络提取出来的单独的proposal来生成的，因此具有整个对象的感知。但是这种方法必须依赖于目标检测的结果。</p>
<p>通过上面的分析，这里两种任务时能够相互促进的，因此作者提出了RDSNet，一种互惠的目标检测方法和实例分割网络（RDSNet）来利用这两项任务之间的关系。</p>
<p>RDSNet利用双流结构，即对象流和像素流，同时这两条流的信息相互融合，具体来说，对象流集中在对象级别特征是一个回归的检测器，而像素流关注像素级特征，结构沿用FCN的结构，以保证高分辨率输出。</p>
<p>为了利用来自对象流的对象级提示，提出了<strong>一个相关模块和一个裁剪模块</strong>，该模块将实例感知和翻译方差特性引入到像素流，并产生实例感知的分割掩码。然后，提出了一种基于掩模的边界求精模块，以减小定位误差像素流，即基于实例掩码生成更精确的边界框。</p>
<p>RDSNet充分考虑了目标检测和实例分割任务之间的相互关系.与以往的方法相比，它有以下三个优点：1）由RDSNet生成的掩码对不同尺度的对象具有一致的高分辨率；2）由于具有巧妙的裁剪模块，掩码对检测结果的依赖性较小；3）更准确和更准确；更紧密的包围盒是用一种新的像素级公式得到的对象包围盒位置。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200318114954524.png" alt="image-20200318114954524" style="zoom:50%;"></p>
<h4 id="双流结构"><a href="#双流结构" class="headerlink" title="双流结构"></a>双流结构</h4><p>RDSNet的核心是双流结构，即对象流和像素流。这两条流共用相同的FPN（Lin等人.2017a）主干，然后为每个相应的任务分离。这种平行结构支持对象级和像素级信息的分离以及不同任务的可变分辨率。</p>
<p><strong>对象流</strong>。对象流侧重于对象级信息，包括对象类别，位置等。可有各种回归的检测器充当（Liu等）。此外，我们还添加了一个与分类和回归分支并行的新分支，以提取每个锚点（或位置）的对象特征。这条流负责产生检测结果，稍后将由像素级信息进一步提取信息（见SEC.3.3）。</p>
<p><strong>像素流</strong>。像素流的重点是像素级信息，并遵循FCN（2015）的高分辨率输出设计。具体来说，每像素特征是在这个流中提取的，并且用于通过使用对象级信息生成实例掩码（参见SEC.3.2）。</p>
<p><strong>对象感知：相关性模块</strong></p>
<p>主要思路是将实例信息融合到像素上来，以便做分割处理：<br>$$<br>M_{o}=\operatorname{softmax}\left(\Psi(U) \star \phi\left(v_{o}\right)\right)<br>$$<br>其中 $v_0$ 表示从obejct stream上的特征，U表示来着像素流的特征，将两个特征映射之后，做一个卷积操作，然后在M0上计算一个pixelwise的交叉熵损失，作为最后loss的一部分。</p>
<p>其中U的维度为1xdxhxw，v的维度为2xdx1x1，其中2表示当前像素是属于前景还是背景。因此U与v做完卷积之后，得到的维度是2x1xwxh，即每一个位置上有两个值，表示前景和背景的概率。每一个anchor对应一个v，与U做完卷积之后计算softmax得到一个二值图。因此可以发现，网络检测出多少anchor，最终segmentation的时候，就会输出多少张二值图，理论上每一个二值图表示一个对象。</p>
<p>2xkxdx1x1 representation即表示anchor对象的深层含义。</p>
<p><strong>翻译改变到翻译不变</strong></p>
<p>由于上诉相关模块对每一个object生成的mask覆盖了整个图像，由于卷积操作产生了大量的噪声。我们使用一个裁剪模块来克服这个问题。可以利用物体的边框进行裁剪，边框以外的像素设置成背景，但是这种做法又会受到检测结果的影响，因此我们选择裁剪进过扩展后的边框，保证mask对box的依赖比较小。同时扩展后的边框引入了更多的背景，使得背景也容易被区分出来。需要注意的是，我们引入背景的时候也需要保持正负样本的平衡（1:1），可以使用背景像素的OHEM算法。</p>
<h4 id="由mask得到精确边框"><a href="#由mask得到精确边框" class="headerlink" title="由mask得到精确边框"></a>由mask得到精确边框</h4><p>利用从对象流和像素流中获得的边界框和实例掩码，得到每个对象的更精确的边界框。虽然回归边界框可能包含定位错误，但我们认为它们在一定程度上仍然为对象边界位置提供了合理的先验。因此，我们的提法联合擦除检测和分割结果。</p>
<h3 id="网络损失函数"><a href="#网络损失函数" class="headerlink" title="网络损失函数"></a>网络损失函数</h3><p>最终的loss：<br>$$<br>L=L_{c l s}+\lambda_{r} L_{r e g}+\lambda_{m} L_{m a s k}<br>$$<br>即分类损失，边框回归损失，相关模块产生的mask损失。</p>
<h3 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h3><p><strong>数据的组织形式</strong></p>
<p>GT中segmentation部分采用coco的标注格式，即ploygon多边形的轮廓坐标[x1,y1,x2,y2,x3,y3…]。</p>
<p>box部分则表明GT中的目标所在的外包围盒。</p>
<p><strong>dataset部分：</strong> 数据输出为[img, gt_bboxes, gt_labels, gt_masks]</p>
<p>代码结构：</p>
<ul>
<li>backbone: usually an FCN network to extract feature maps, e.g., ResNet, MobileNet.</li>
<li>neck: the component between backbones and heads, e.g., FPN, PAFPN.</li>
<li>head: the component for specific tasks, e.g., bbox prediction and mask prediction.</li>
<li>roi extractor: the part for extracting RoI features from feature maps, e.g., RoI Align.</li>
</ul>
<h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>IoU：即预测的mask与GT的重叠程度<br>$$<br>I O U(A, B)=\frac{|A \cap B|}{|A \cup B|}<br>$$<br>dice：与IoU相似，也是用来评价与GT的重叠程度：<br>$$<br>\operatorname{dice}(A, B)=\frac{2|A \cap B|}{|A|+|B|}<br>$$<br>相同的结果比值上，dice的值要比IoU稍微大一点。</p>
<p>COCO数据集的验证方式得到的结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603</span><br><span class="line">Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.499</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463</span><br><span class="line">Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501</span><br><span class="line">Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000</span><br></pre></td></tr></table></figure>
<p>其中IoU表示阈值，用于区分正负样本，然后计算precision和recall，得到的结果如上。</p>
<p>下面是各个模型的指标，可以作为一个baseline，可以说明效果不错。</p>
<p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200320153558364.png" alt="image-20200320153558364" style="zoom:50%;"></p>
<p>但是这个结果仅仅只是检测的结果，过于segmentation部分的结果并没有。</p>
<p>这个需要我自己去写一个。</p>
<p>对于segmentation的指标有：</p>
<p><strong>pa：</strong> 是标记正确的像素占总像素的比例</p>
<p><strong>mpa：</strong>每个类别被正确分类像素的比例，之后求所有类的平均</p>
<p><strong>mIU：</strong>在每个类上求IoU，再求平均</p>
<p><strong>fwIU：</strong>根据每个类出现的频率为其设置权重，再算IoU</p>
<p><strong>FCN模型的检测结果如下，可以做为一个baseline</strong></p>
<p><img src="/Users/zhouwenhui/blog/source/images/nlp/image-20200320152311238.png" alt="image-20200320152311238" style="zoom:50%;"></p>
<p>验证集574张图片，能够检测出人的图像有：384张</p>
<p>验证后指标分别如下：</p>
<p>pa: 0.9326967388628634</p>
<p>person pa: 0.948784433562702; ski pa 0.7863983575482737</p>
<p>person mIU: 0.8811813306596593; ski mIU 0.47062399967040647</p>
<p><strong>人体倒立的效果不好：</strong></p>
<p>目前有的数据增强操作有：resize：[(1333, 640), (1333, 800)]，randomFilp（左右翻转），Normalize，Pad</p>
<p>增加上下翻转的操作，同时翻转mask和box:</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>WenHui Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2020/03/18/RDSNet/">https://wenhui-zhou.github.io/2020/03/18/RDSNet/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>| 本博客所有文章除特别声明外，均采用 <a href="&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot;" rel="&quot;external" nofollow&quot;="" target="&quot;_blank&quot;">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！ </li></ul></div><br><div class="tags"></div><div class="post-nav"><a class="pre" href="/2020/03/25/problem-summary/">problem summary</a><a class="next" href="/2020/03/14/LR-推导/">LR 推导</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'civq9nKD49NpRALooR9Llqmf-gzGzoHsz',
  appKey:'JggO9HaSi1Lfx17nt16oDfsI',
  placeholder:'Shall we talk',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/3D重建/">3D重建</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/effective-cpp/">effective cpp</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/super-resolution/">super resolution</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/webSearch/">webSearch</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/xigua/">xigua</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/建站/">建站</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/手撕系列/">手撕系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐系统/">推荐系统</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/模型评价/">模型评价</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛/">比赛</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法扫盲/">算法扫盲</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学习方法/">统计学习方法</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文复现/">论文复现</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">23</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/3D重建/">3D重建</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试准备/">面试准备</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目/">项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/">项目总结</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/interview/" style="font-size: 15px;">interview</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/项目总结/" style="font-size: 15px;">项目总结</a> <a href="/tags/3D重建/" style="font-size: 15px;">3D重建</a> <a href="/tags/netStation/" style="font-size: 15px;">netStation</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a> <a href="/tags/tool/" style="font-size: 15px;">tool</a> <a href="/tags/SR/" style="font-size: 15px;">SR</a> <a href="/tags/dialog/" style="font-size: 15px;">dialog</a> <a href="/tags/tip/" style="font-size: 15px;">tip</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/learning-cpp/" style="font-size: 15px;">learning cpp</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/—-leetcode/" style="font-size: 15px;">— leetcode</a> <a href="/tags/职业规划/" style="font-size: 15px;">职业规划</a> <a href="/tags/tips/" style="font-size: 15px;">tips</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/超分辨率/" style="font-size: 15px;">超分辨率</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/problem-summary/">problem summary</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/RDSNet/">RDSNet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/14/LR-推导/">LR 推导</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/12/TrackIn-BERT/">TrackIn:BERT five-classification on MSMARCO.md</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/Bert，XLNet，UNILM，RoBERTa以及QA/">Bert，XLNet，UNILM，RoBERTa以及QA</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/天池安全AI挑战赛细枝末节/">天池安全AI挑战赛细枝末节</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/精彩视频剪辑的细枝末节/">精彩视频剪辑的细枝末节</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/07/openpose细枝末节/">openpose细枝末节</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/支持向量机-SVM/">支持向量机-SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/19/聚类/">聚类</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/WenHui-Zhou" title="GITHUB" target="_blank">GITHUB</a><ul></ul><a href="http://www.google.com/" title="GOOGLE" target="_blank">GOOGLE</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">WenHuiZhou.</a> 访问人数:<span id="busuanzi_value_site_uv"></span> 
访问量:<span id="busuanzi_value_site_pv"></span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> </div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>