<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="cheer up"><meta name="baidu-site-verification" content="9pSIuwCbvi"><meta name="google-site-verification" content="YzcCTjF6VoVlNAtL37_S4vFjzFwYTAFZzD51Il2IGKY"><title>MobileNet V2 详解 | WenHuiZhou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MobileNet V2 详解</h1><a id="logo" href="/.">WenHuiZhou</a><p class="description">perper（打起精神！）</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MobileNet V2 详解</h1><div class="post-meta">Mar 4, 2019<span> | </span><span class="category"><a href="/categories/论文阅读/">论文阅读</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/03/04/MobileNet-V2-详解/#vcomment"><span class="valine-comment-count" data-xid="/2019/03/04/MobileNet-V2-详解/"></span><span> 条评论</span></a><div class="post-content"><p>MobileNet V2 是在V1的基础上做了一些结构上的调整，主要有<strong>inverted residual</strong> 以及<strong>Linear Bottlenecks</strong>的改进。使得mobileNet v2 的精度进一步提高，结构进一步合理。<br><a id="more"></a></p>
<blockquote>
<p>MobileNetV2: Inverted Residuals and Linear Bottlenecks<br>submit time: 2018<br><a href="https://arxiv.org/pdf/1801.04381.pdf" target="_blank" rel="noopener">arxiv link</a></p>
</blockquote>
<h3 id="mobileNets的背景及作用"><a href="#mobileNets的背景及作用" class="headerlink" title="mobileNets的背景及作用"></a>mobileNets的背景及作用</h3><p>mobileNet V1在设计的时候使用deepwise separable conv代替传统的卷积，大大降低了模型的计算量和复杂度，但是其仍然存在以下两个缺陷：</p>
<ul>
<li><strong>直筒型的结构影响网络性能</strong>，后续的网络如ResNet等，在网络中重复使用图像特征能够提高网络的性能。（引入inverted residual）</li>
<li><strong>depthwise Convolution 导致特征退化问题</strong>：由于depthwise conv使用很小的卷积核（1x1），经过BN归一化，以及relu激活之后很容易变为0，即变成死节点,<strong>导致特征退化</strong>。（我的理解是，对于一个1x1的kernel来说，归一化过程可能会把它变成负数，然后relu激活后就会变成死节点。但是对于kernel size比较大的卷积，要使整个卷积核上的数都变成负数要难很多，因此不会有很严重的特征退化问题。）（引入linear bottlenecks）.</li>
</ul>
<p>mobileNet v2 通过引入inverted residual，将图像中的特征反复使用，提高网络的性能。对于特征退化的问题，通过linear bottleneck，去掉网络中的relu等步骤，能够缓解特征的退化。<br><img src="/images/article/v2detial.png" alt=""></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性激活函数。</p>
<p>线性瓶颈的倒置残差结构：模块的输入为一个低维的压缩表示特征，首先将其扩展到高维并用轻量级depthwise conv 进行卷积。随后用线性卷积（linear conv）将特征投影回低维表示。</p>
<p><strong>MobileNet v2 模型的特点：</strong></p>
<p><img src="/images/article/linearBottle.png" alt=""><br>如上图，mobileNet v2在V1基础上进行了改进。</p>
<p>相同点：<br>mobileNet v2由v1发展而来，继承了<strong>深度可分卷积</strong>（depthwise seperable conv），采用深度卷积和逐点卷积来代替传统的卷积操作，使得计算量大大减小。<a href="http://perper.site/2019/03/03/MobileNets-%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener">参考链接</a></p>
<p>不同点：<br><strong>V2在每个DW卷积之前加入了一层PW的卷积，主要作用是用于提升特征的channel数。</strong>由于DW层无法提升feature map的通道数，于是先通过PW提升feature map的通道数，PW卷积的大小为：Mx1x1，卷积核的个数可以控制，也即为卷积后得到feature map的通道数。至于提升channel的具体原因如下：</p>
<blockquote>
<p>当我们查看深层卷积层所有的d通道像素时，在这些值中编码的信息实际上位于某个流形中，这些流形结构可以嵌入到低维子空间中。<br>ReLu在高层空间中的变换有助于增加网络的非线性。对于ReLU（Bx）激活后的非0部分，输入空间与输出空间之间的特征映射是线性变换。另一方面，当ReLU破坏通道时（relu小于0的部分），它会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。<br>总而言之，以下两个特性表明感兴趣的流形区域位于较高维激活空间的低维子空间中：</p>
<ol>
<li>如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。</li>
<li>只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。</li>
</ol>
</blockquote>
<p>因此我们需要先对channel通道进行升维。假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。线性可以防止非线性破坏太多的信息。</p>
<p><strong>Linear Bottleneck：</strong>V2 去掉了第二个 PW 的激活函数。论文作者称其为 Linear Bottleneck。这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。由于第二个 PW 的主要功能就是降维，降维之后使用线性瓶颈层来获取低秩信息，防止非线性破坏太多信息。</p>
<p><strong>倒置残差：</strong><br><img src="/images/article/inverted_residual.png" alt=""><br>V2的 shortcut  设计与ResNet相反，呈一个纺锥型，中间大两头小，因此称为<strong>倒置残差</strong>。使用倒置设计是由于其内存效率要高得多。<br>网络将PW层得到的feature map先扩展6倍，然后通过DW卷积，与一个shortcut上来的feature map融合之后再输入PW卷积。</p>
<p>mobileNet的结构单元如下：<br><img src="/images/article/v1structure.png" alt=""><br><img src="/images/article/V2structure.png" alt=""></p>
<p>网络结构参数如下：<br><img src="/images/article/v2net.png" alt=""></p>
<p>整体的结构如下：<a href="https://zhuanlan.zhihu.com/p/33075914" target="_blank" rel="noopener">参考链接</a><br><img src="/images/article/structureV2.png" alt=""></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>WenHui Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/03/04/MobileNet-V2-详解/">https://wenhui-zhou.github.io/2019/03/04/MobileNet-V2-详解/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>| 本博客所有文章除特别声明外，均采用 <a href="&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot;" rel="&quot;external" nofollow&quot;="" target="&quot;_blank&quot;">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！ </li></ul></div><br><div class="tags"><a href="/tags/深度学习/">深度学习</a></div><div class="post-nav"><a class="pre" href="/2019/03/05/Bag-of-Freebies-for-Training-Object-Detection-Neural-Networks/">Bag of Freebies for Training Object Detection Neural Networks</a><a class="next" href="/2019/03/04/Tensorflow 笔记（搭建网络-II）/">Tensorflow 笔记（搭建网络-II）</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'civq9nKD49NpRALooR9Llqmf-gzGzoHsz',
  appKey:'JggO9HaSi1Lfx17nt16oDfsI',
  placeholder:'Shall we talk',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/3D重建/">3D重建</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/effective-cpp/">effective cpp</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/super-resolution/">super resolution</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/xigua/">xigua</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/建站/">建站</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/手撕系列/">手撕系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐系统/">推荐系统</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/模型评价/">模型评价</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛/">比赛</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法扫盲/">算法扫盲</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文复现/">论文复现</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">22</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/3D重建/">3D重建</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目/">项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/">项目总结</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/interview/" style="font-size: 15px;">interview</a> <a href="/tags/dialog/" style="font-size: 15px;">dialog</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/项目总结/" style="font-size: 15px;">项目总结</a> <a href="/tags/3D重建/" style="font-size: 15px;">3D重建</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a> <a href="/tags/netStation/" style="font-size: 15px;">netStation</a> <a href="/tags/tool/" style="font-size: 15px;">tool</a> <a href="/tags/SR/" style="font-size: 15px;">SR</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/tip/" style="font-size: 15px;">tip</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/learning-cpp/" style="font-size: 15px;">learning cpp</a> <a href="/tags/职业规划/" style="font-size: 15px;">职业规划</a> <a href="/tags/tips/" style="font-size: 15px;">tips</a> <a href="/tags/—-leetcode/" style="font-size: 15px;">— leetcode</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/超分辨率/" style="font-size: 15px;">超分辨率</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/12/19/bert的一些思考/">bert的一些思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/09/pytorch-重点回顾/">pytorch 重点回顾</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/05/NLP实践-基于注意力机制的文本匹配/">NLP实践 基于注意力机制的文本匹配</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/02/NLP实践-文本分类任务/">NLP实践 文本分类任务</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/02/图像的去噪/">图像的去噪</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/01/NLP模型finetune-GPT到Bert（三）/">NLP模型finetune:GPT到Bert（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/29/NLP之transformer（二）/">NLP之transformer（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/29/NLP之Word2Vec（一）/">NLP之Word2Vec（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/26/effective-cpp-九-杂项讨论/">effective cpp(九)杂项讨论</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/25/effective-cpp-八-定制new和delete/">effective cpp(八)定制new和delete</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/WenHui-Zhou" title="GITHUB" target="_blank">GITHUB</a><ul></ul><a href="http://www.google.com/" title="GOOGLE" target="_blank">GOOGLE</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">WenHuiZhou.</a> 访问人数:<span id="busuanzi_value_site_uv"></span> 
访问量:<span id="busuanzi_value_site_pv"></span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> </div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>