<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="cheer up"><meta name="baidu-site-verification" content="9pSIuwCbvi"><meta name="google-site-verification" content="YzcCTjF6VoVlNAtL37_S4vFjzFwYTAFZzD51Il2IGKY"><title>SSD 复现 | WenHuiZhou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">SSD 复现</h1><a id="logo" href="/.">WenHuiZhou</a><p class="description">perper（打起精神！）</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">SSD 复现</h1><div class="post-meta">Mar 29, 2019<span> | </span><span class="category"><a href="/categories/论文复现/">论文复现</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/03/29/SSD-复现/#vcomment"><span class="valine-comment-count" data-xid="/2019/03/29/SSD-复现/"></span><span> 条评论</span></a><div class="post-content"><p>SSD是经典的one-stage目标检测框架，在速度和精度上都比Faster RCNN，YOLO（V1？）要更胜一筹。这次复现SSD作为理解网络以及学习pytorch的一个机会，这篇文章将尽可能的详细记录SSD的复现细节。（好大的flag🍐）</p>
<a id="more"></a>
<p>在复现SSD之前，我想就pytorch的两大部件进行一下介绍，分别是数据集模块（<code>torch.utils.data.Dataset</code>）以及网络模块(<code>torch.nn.Module</code>)。</p>
<h3 id="数据集模块"><a href="#数据集模块" class="headerlink" title="数据集模块"></a>数据集模块</h3><p> pytorch数据读取主要有三个类：</p>
<ul>
<li>Dataset </li>
<li>DataLoader </li>
<li>DataLoaderIter</li>
</ul>
<p>他们使用的方式为Dataset做为参数传入DatasetLoader中，DataLoader做为参数传入DataLoaderIter中。</p>
<p>因此完成pytorch数据集读取模块第一步要做的是：</p>
<p>【1】定义<strong>数据集类</strong>。</p>
<p><code>torch.utils.data.Dataset</code> 是一个抽象类，因此继承Dataset需要实现他的两个方法，<code>__len__()</code>，<code>__getitem__()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line">data_set = &#123;<span class="number">1</span>:<span class="string">'a'</span>,<span class="number">2</span>:<span class="string">'b'</span>,<span class="number">3</span>:<span class="string">'c'</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(data.Dataset)</span>:</span><span class="comment">#需要继承data.Dataset</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 1. Initialize file path or list of file names.</span></span><br><span class="line">        self.data = data_set</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># 每次读取一张图片以及对应的label，</span></span><br><span class="line">        <span class="comment"># 可以对图片进行一些flip等操作（torchvision.Transform).</span></span><br><span class="line">        <span class="comment"># 最终返回的是一个含有(image,label)的pair</span></span><br><span class="line">        <span class="comment"># 可以在init()函数的位置处生成csv_reader,或是一些list，集合</span></span><br><span class="line">        <span class="keyword">return</span> index, self.data[index]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data)</span><br></pre></td></tr></table></figure>
<p>对于这个Dataset这个类，只要实现了这两个函数，然后每次调用的的时候都能出来一个img，label，内部无论是list，generator都是可行的。</p>
<p>在<code>__getitem__()</code> 处可以执行一些图片变换等工作，torchvision.transforms中有着许多对图片的增强操作。常用的有<code>Resize</code> , <code>RandomCrop</code> , <code>Normalize</code> , <code>ToTensor</code> (这个<strong>极为重要</strong>, 可以把一个PIL或numpy图片转为<code>torch.Tensor</code>）</p>
<p>【2】定义dataLoader</p>
<p>dataLoader的定义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False)</span><br></pre></td></tr></table></figure>
<p>其中<code>dataset</code>即上面定义的dataset，<code>batch_size</code>指一次调用该函数，输出的样本个数。<code>num_workers</code>指线程数，当大于等于1时就表示多线程。<code>collate_fn</code> 用于定制输出的batch，通过传入lambda表达式来实现，即当一张图片对应多个边框的时候，就需要进行图片以及边框的匹配。</p>
<p>dataLoader还实现了一个<code>__iter__()</code> 函数，这个函数输入为dataLoader，输出为dataLoaderIter，是一个迭代器。</p>
<p>具体使用如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset = CustomClass()</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">10</span>,...)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">  <span class="comment"># data[0]为图片</span></span><br><span class="line">  <span class="comment"># data[1]为标准</span></span><br><span class="line">  <span class="comment"># 共有10对</span></span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="网络结构模块"><a href="#网络结构模块" class="headerlink" title="网络结构模块"></a>网络结构模块</h3><p>pytorch 使用<code>nn.Module</code> 来构建网络，在pytorch中每一个网络层都是一个<code>nn.Module</code>类，并且类之间相互嵌套。<code>nn.Module</code>中有两个比较重要的部分，分别是</p>
<p><code>__init__()</code> ：完成逻辑模块的初始化。</p>
<p><code>forward()</code>：完成计算图的正向传递的过程。例如nn.Linear模块的定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinear</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">()</span>:</span></span><br><span class="line">    super(MyLinear,self).__init__()</span><br><span class="line">    </span><br><span class="line">    self.w = nn.Parameter(torch.randn(outp,inp))</span><br><span class="line">    self.b = nn.Parameter(torch.randn(outp))</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">    x = x @ self.w.t() + self.b</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>pytorch中提供了许多现成的类可供使用：</p>
<ul>
<li><code>nn.conV2d</code></li>
<li><code>nn.MaxPool2d</code></li>
<li><code>nn.ReLu</code></li>
<li><code>nn.BatchNorm2d</code></li>
</ul>
<p>同时<code>nn.Sequential</code>实现了一个序列，用来构建网络模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_size,out_size,kernel_size,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    nn.ReLu()</span><br><span class="line">   nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">  ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>输入将按照网络层从上到下进行参数的传递。</p>
<p>此外nn.Module类还会对网络的参数进行管理，<code>nn.parameters()</code>中将会保存着网络所有的参数。便于参数的管理。</p>
<p>我们可以使用nn.module构建许多的网络层，然后通过输入输出传值的方式将他们连成一个计算图。</p>
<p>下面将按照数据的读入，网络的搭建，网络的训练，以及效果的评估几个方面进行。</p>
<h3 id="SSD-复现"><a href="#SSD-复现" class="headerlink" title="SSD 复现"></a>SSD 复现</h3><p>参考<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="noopener">github链接</a>。</p>
<p><strong>【1】数据的准备</strong></p>
<p>数据集是一些由视频切帧而来的图片，一秒切一帧，对于每张图，由相应的标注信息，标注信息csv格式。通过读取csv数据集的方式，来完成数据的读取（github版本为使用pycocotool读取数据）。通过继承data.Dataset以及实现dataLoader的方式来获取数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># csv格式为：url,x1,y1,x2,y2,label</span></span><br><span class="line">TRAIN_ROOT = <span class="string">'./data/train_dataset.csv'</span></span><br><span class="line">VAL_ROOT   = <span class="string">'./data/val_dataset.csv'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detection_collate</span><span class="params">(batch)</span>:</span></span><br><span class="line">    targets = []</span><br><span class="line">    imgs    = []</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> batch:</span><br><span class="line">        imgs.append(sample[<span class="number">0</span>])</span><br><span class="line">        targets.append(sample[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> imgs,targets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">csv_loader</span><span class="params">(data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data_root,transform = transforms.ToTensor<span class="params">()</span>)</span>:</span></span><br><span class="line">        self.data_root  = data_root</span><br><span class="line">        self.dataset    = &#123;&#125;</span><br><span class="line">        self.imgs_index = &#123;&#125;</span><br><span class="line">        self.transform  = transform</span><br><span class="line">        self.index      = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> open(self.data_root,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> line[<span class="number">0</span>] <span class="keyword">in</span> self.dataset:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]].append(line[<span class="number">1</span>:<span class="number">5</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.dataset[line[<span class="number">0</span>]] = [line[<span class="number">1</span>:<span class="number">5</span>],]</span><br><span class="line">                    self.imgs_index[self.index] = line[<span class="number">0</span>]</span><br><span class="line">                    self.index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        img_path = self.imgs_index[index]</span><br><span class="line">        label    = self.dataset[img_path]</span><br><span class="line">        img      = cv2.imread(img_path)</span><br><span class="line">        img      = self.transform(img)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(label)):</span><br><span class="line">            label[i][<span class="number">0</span>] = float(label[i][<span class="number">0</span>])</span><br><span class="line">            label[i][<span class="number">1</span>] = float(label[i][<span class="number">1</span>])</span><br><span class="line">            label[i][<span class="number">2</span>] = float(label[i][<span class="number">2</span>])</span><br><span class="line">            label[i][<span class="number">3</span>] = float(label[i][<span class="number">3</span>])</span><br><span class="line">        label  = np.array(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.index+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">dataset    = csv_loader(TRAIN_ROOT)</span><br><span class="line">dataloader = data.DataLoader(dataset,batch_size = <span class="number">2</span>,collate_fn = detection_collate)</span><br><span class="line"><span class="keyword">for</span> img,label <span class="keyword">in</span> dataloader:</span><br><span class="line">    print(img)</span><br><span class="line">    print(label)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>如上，可以看出我们使用detection_collate方法来对每个batch size中读到的数据进行二次组织。</p>
<p>【2】网络的构建</p>
<p>数据已经准备好了，接下来要做的就是将网络搭建起来，然后将数据输入。</p>
<p>ssd的网络的backbone是vgg网络，利用vgg网络提取图片特征。</p>
<p>vgg的结构如下：</p>
<p><img src="./images/CNNnet/VGG16.png" alt=""></p>
<p>实现backbone的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">base = &#123;</span><br><span class="line">    <span class="string">'300'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'C'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>,</span><br><span class="line">            <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>],</span><br><span class="line">    <span class="string">'512'</span>: [],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="hard-negative-mining"><a href="#hard-negative-mining" class="headerlink" title="hard negative mining"></a>hard negative mining</h3><p>SSD 中对feature map位置的提取6个或4个边框，这些边框的尺寸由一些超参数决定。在进行网络训练之前，需要对生成的这些边框进行正负样本的标注，标注的标准在于这些边框与GT边框的IoU重合度，如果重合度大于0.5，则表示这个边框是证样本，小于0.3表示这个边框是负样本。</p>
<p>在对正负样本进行标注时，一般要保证正样本：负样本的个数为1:3。但是对于一张图片来说，其上大部分的框都是负样本，因此需要进行hard negative mining将一些得分较高的negative 做为hard negative。</p>
<p>hard negative mining一般是，有正负样本，然后分类器分出来一些分错的负样本（容易将负样本看成正样本的那些样本），即假阳性(false positive )，也就是说在对负样本分类时候，loss比较大（label与prediction相差较大）的那些样本，这些就是hard negative/困难样本，进行重新训练。</p>
<p>网络搭建部分主要继承nn.Module模块，继承init以及forward模块，实现网络结构的搭建，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python </span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录各层的channel</span></span><br><span class="line">base   = [<span class="number">64</span>,<span class="number">64</span>,<span class="string">'M'</span>,<span class="number">128</span>,<span class="number">128</span>,<span class="string">'M'</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="string">'C'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="string">'M'</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>] <span class="comment"># M表示floor（边角舍弃）方式的Maxpooling，C表示ceil（补全）方式的Maxpooling</span></span><br><span class="line"><span class="comment"># vgg之后的各各层</span></span><br><span class="line">extras = [<span class="number">256</span>,<span class="string">'S'</span>,<span class="number">512</span>,<span class="number">128</span>,<span class="string">'S'</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">128</span>,<span class="number">256</span>]</span><br><span class="line"><span class="comment">#每一层每个像素位置将取出的边框个数</span></span><br><span class="line">mboxes = [<span class="number">4</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(base,input_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    base: 各层的channel</span></span><br><span class="line"><span class="string">    input_channel：传入数据的维度</span></span><br><span class="line"><span class="string">    batch_norm：是否使用bn</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    这个函数主要使用一个list，将每一层的函数存储起来，用base来控制当前层是什么</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = input_channel</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> base:</span><br><span class="line">        <span class="keyword">if</span>   v == <span class="string">'M'</span>:<span class="comment"># 表示是一个maxpooling</span></span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">'C'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="keyword">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels,v,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d,nn.BatchNorm2d(v),nn.ReLU(inplace=<span class="keyword">True</span>)] <span class="comment"># inplace=True 指它将直接修改input的值，而不重新分配空间</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    pool5   = nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">    conv6   = nn.Conv2d(<span class="number">512</span>,<span class="number">1024</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">6</span>,dilation=<span class="number">6</span>)</span><br><span class="line">    conv7   = nn.Conv2d(<span class="number">1024</span>,<span class="number">1024</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">    layers += [pool5,conv6,nn.ReLU(inplace=<span class="keyword">True</span>),conv7,nn.ReLU(inplace=<span class="keyword">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(extras,in_channel,batch_norm=None)</span>:</span></span><br><span class="line">    <span class="comment"># extra layers added to vgg for feature scaling</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = in_channel</span><br><span class="line">    flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras):</span><br><span class="line">        <span class="keyword">if</span> in_channels!=<span class="string">'S'</span>:</span><br><span class="line">            <span class="keyword">if</span> v == <span class="string">'S'</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,extras[k+<span class="number">1</span>],kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag],stride=<span class="number">2</span>,padding=<span class="number">1</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels,v,kernel_size=(<span class="number">1</span>,<span class="number">3</span>)[flag])]</span><br><span class="line">            flag = <span class="keyword">not</span> flag</span><br><span class="line">        in_channels = v</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg,extras_layers,mbox,num_classes)</span>:</span></span><br><span class="line">    loc_layers  = []</span><br><span class="line">    conf_layers = []</span><br><span class="line">    vgg_source  = [<span class="number">21</span>,<span class="number">-2</span>] <span class="comment"># vgg的21层即conv4_3,和-2层即fc7</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(vgg_source):</span><br><span class="line">        loc_layers  += [nn.Conv2d(vgg[v].out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]           <span class="comment"># location 有四个参数</span></span><br><span class="line">        conf_layers += [nn.Conv2d(vgg[v].out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)] <span class="comment"># 类别预测将有class_num个数</span></span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(extras_layers[<span class="number">1</span>::<span class="number">2</span>],<span class="number">2</span>):     <span class="comment"># 这里就是说取extras中奇数层，然后取bounding box，从第二层开始</span></span><br><span class="line">        loc_layers  += [nn.Conv2d(v.out_channels,mbox[k]*<span class="number">4</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">        conf_layers += [nn.Conv2d(v.out_channels,mbox[k]*num_classes,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> vgg,extras_layers,(loc_layers,conf_layers)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">priorBox</span><span class="params">(obejct)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    在feature map上计算初始边框的坐标</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,cfg)</span>:</span></span><br><span class="line">        <span class="comment"># 将config中的一些超参赋值过来</span></span><br><span class="line">        self.image_size    = cfg[<span class="string">'min_dim'</span>]</span><br><span class="line">        self.num_priors    = len(cfg[<span class="string">'aspect_ratios'</span>])</span><br><span class="line">        self.variance      = cfg[<span class="string">'variance'</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]</span><br><span class="line">        self.feature_maps  = cfg[<span class="string">'feature_maps'</span>]</span><br><span class="line">        self.min_sizes     = cfg[<span class="string">'min_sizes'</span>]</span><br><span class="line">        self.max_sizes     = cfg[<span class="string">'max_sizes'</span>]</span><br><span class="line">        self.steps         = cfg[<span class="string">'steps'</span>]</span><br><span class="line">        self.aspect_ratios = cfg[<span class="string">'aspect_ratios'</span>]</span><br><span class="line">        self.clip          = cfg[<span class="string">'clip'</span>]</span><br><span class="line">        self.version       = cfg[<span class="string">'name'</span>]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Variances must be greater than 0'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">            mean = []</span><br><span class="line">            <span class="keyword">for</span> k ,f <span class="keyword">in</span> enumerate(self.feature_maps):</span><br><span class="line">                f_k = self.image_size / self.steps[k]</span><br><span class="line">                s_k = self.min_sizes[k] / self.image_size   </span><br><span class="line">                s_k_prime = sqrt(s_k*(self.max_sizes[k]/self.image_size))</span><br><span class="line">                <span class="keyword">for</span> i,j <span class="keyword">in</span> product(range(f),repeat=<span class="number">2</span>):</span><br><span class="line">                    <span class="comment"># unit center x,y</span></span><br><span class="line">                    cx  = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    cy  = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line">                    <span class="comment">#aspect_ratio: 1</span></span><br><span class="line">                    mean += [cx,cy,s_k,s_k]</span><br><span class="line">                    mean += [cx,cy,s_k_prime,s_k_prime]</span><br><span class="line">                    <span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">                        mean += [cx,cy,s_k*sqrt(ar),s_k/sqrt(ar)]</span><br><span class="line">                        mean += [cx,cy,s_k/sqrt(ar),s_k*sqrt(ar)]</span><br><span class="line">            <span class="comment"># back to torch land</span></span><br><span class="line">            output = torch.Tensor(mean).view(<span class="number">-1</span>,<span class="number">4</span>)</span><br><span class="line">            <span class="keyword">if</span> self.clip:</span><br><span class="line">                output.clamp_(max=<span class="number">1</span>,min=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,phase,size,base,extras,head,num_classes)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        phase:  train,test</span></span><br><span class="line"><span class="string">        size:   ssd输入图片的大小，也即是版本把</span></span><br><span class="line"><span class="string">        base:   vgg的网络结构</span></span><br><span class="line"><span class="string">        extras: vgg之后的那些层</span></span><br><span class="line"><span class="string">        head:   loc，conf 的boxes</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super(SSD,self).__init__()</span><br><span class="line">        self.phase       = phase</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.cfg         = (coco,voc)[num_classes == <span class="number">21</span>]  <span class="comment"># config.py 中对数据集的一些配置</span></span><br><span class="line">        self.priorbox    = PriorBox(self.cfg)</span><br><span class="line">        self.priors      = Variable(self.priorbox.forward(),volatile=<span class="keyword">True</span>)</span><br><span class="line">        self.size        = size</span><br><span class="line"></span><br><span class="line">        <span class="comment">## ssd net</span></span><br><span class="line">        self.vgg         = nn.ModuleList(base)</span><br><span class="line">        self.L2Norm      = L2Norm(<span class="number">512</span>,<span class="number">20</span>)</span><br><span class="line">        self.extras      = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        self.loc         = nn.ModuleList(head[<span class="number">0</span>])</span><br><span class="line">        self.conf        = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> phase == <span class="string">'test'</span>:</span><br><span class="line">            self.softmax = nn.Softmax(dim = <span class="number">-1</span>)</span><br><span class="line">            <span class="comment">## detection.py</span></span><br><span class="line">            self.detect  = Detect(num_classes,<span class="number">0</span>,<span class="number">200</span>,<span class="number">0.01</span>,<span class="number">0.45</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        sources = list()</span><br><span class="line">        loc     = list()</span><br><span class="line">        conf    = list()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg to conv4_3 relu</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        s = self.L2Norm(x)</span><br><span class="line">        sources.append(s)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg up to fc7</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">23</span>,len(self.vgg)):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply extra layers</span></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> enumerate(self,extras):</span><br><span class="line">            x = F.relu(v(x),inplace=<span class="keyword">True</span>)</span><br><span class="line">            <span class="keyword">if</span> k%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                sources.append(x)</span><br><span class="line">        <span class="keyword">for</span> (x,l,c) <span class="keyword">in</span> zip(sources,self.loc,self.conf):</span><br><span class="line">            loc.append(l(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line">            conf.append(c(x).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous())</span><br><span class="line"></span><br><span class="line">        loc  = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> loc],<span class="number">1</span>)</span><br><span class="line">        conf = torch.cat([o.view(o.size(<span class="number">0</span>),<span class="number">-1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> conf],<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self,phase == <span class="string">'test'</span>:</span><br><span class="line">            output = self.detect(</span><br><span class="line">                loc.vire(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                self.softmax(conf.view(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes)),</span><br><span class="line">                self.priors.type(type(x.data))</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output = (</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>),</span><br><span class="line">                conf,vire(conf.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes),</span><br><span class="line">                self.priors</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span><span class="params">(self,base_file)</span>:</span></span><br><span class="line">        other,ext = os.path.splitext(base_file)</span><br><span class="line">        <span class="keyword">if</span> ext == <span class="string">'.pkl'</span> <span class="keyword">or</span> <span class="string">'.pth'</span>:</span><br><span class="line">            self.load_state_dict(torch.load(base_file,</span><br><span class="line">                                            map_location=<span class="keyword">lambda</span> storage,loc:storage))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'sorry wrong'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span><span class="params">(phase,size=<span class="number">300</span>,num_classes=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">'test'</span> <span class="keyword">and</span> phase != <span class="string">'train'</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    base_,extras_,head_ = multibox(vgg(base[str(size)],<span class="number">3</span>),add_extras(extras[str(size)],<span class="number">1024</span>),</span><br><span class="line">                                  mbox[str(size)],num_classes)</span><br><span class="line">    <span class="keyword">return</span> SSD(phase,size,base_,extras_,head_,num_classes)</span><br></pre></td></tr></table></figure>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>WenHui Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/03/29/SSD-复现/">https://wenhui-zhou.github.io/2019/03/29/SSD-复现/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>| 本博客所有文章除特别声明外，均采用 <a href="&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot;" rel="&quot;external" nofollow&quot;="" target="&quot;_blank&quot;">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！ </li></ul></div><br><div class="tags"><a href="/tags/深度学习/">深度学习</a></div><div class="post-nav"><a class="pre" href="/2019/03/29/pytorch-基本语法/">pytorch 基本语法</a><a class="next" href="/2019/03/22/手撕mAP/">手撕mAP</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'civq9nKD49NpRALooR9Llqmf-gzGzoHsz',
  appKey:'JggO9HaSi1Lfx17nt16oDfsI',
  placeholder:'Shall we talk',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/super-resolution/">super resolution</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/xigua/">xigua</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/建站/">建站</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/手撕系列/">手撕系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/模型评价/">模型评价</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛/">比赛</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法扫盲/">算法扫盲</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文复现/">论文复现</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">20</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目/">项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/">项目总结</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/interview/" style="font-size: 15px;">interview</a> <a href="/tags/dialog/" style="font-size: 15px;">dialog</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/tool/" style="font-size: 15px;">tool</a> <a href="/tags/netStation/" style="font-size: 15px;">netStation</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/tip/" style="font-size: 15px;">tip</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/—-leetcode/" style="font-size: 15px;">— leetcode</a> <a href="/tags/tips/" style="font-size: 15px;">tips</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/25/哈希表-python示例/">哈希表,python示例</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/22/堆排序，python实现/">堆排序，python实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/16/深度学习代码的框架/">深度学习代码的框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/24/normalization/">normalization</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/23/image-upsample-downsample-method/">image upsample-downsample method</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/23/Deep-Learning-for-image-Super-resolution-a-Survey/">Deep Learning for image Super-resolution: a Survey</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/23/一些提升效率的方法/">一些提升效率的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/21/xigua-支持向量机/">xigua-支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/20/xigua-神经网络/">xigua-神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/19/19-7-2019-preview/">19/7/2019 preview</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/WenHui-Zhou" title="GITHUB" target="_blank">GITHUB</a><ul></ul><a href="http://www.google.com/" title="GOOGLE" target="_blank">GOOGLE</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">WenHuiZhou.</a> 访问人数:<span id="busuanzi_value_site_uv"></span> 
访问量:<span id="busuanzi_value_site_pv"></span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> </div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>