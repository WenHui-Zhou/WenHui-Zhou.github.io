<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="cheer up"><meta name="baidu-site-verification" content="9pSIuwCbvi"><meta name="google-site-verification" content="YzcCTjF6VoVlNAtL37_S4vFjzFwYTAFZzD51Il2IGKY"><title>TensorFlow 笔记（基础部分-I） | WenHuiZhou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TensorFlow 笔记（基础部分-I）</h1><a id="logo" href="/.">WenHuiZhou</a><p class="description">perper（打起精神！）</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">TensorFlow 笔记（基础部分-I）</h1><div class="post-meta">Mar 3, 2019<span> | </span><span class="category"><a href="/categories/Tensorflow/">Tensorflow</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/03/03/TensorFlow-笔记/#vcomment"><span class="valine-comment-count" data-xid="/2019/03/03/TensorFlow-笔记/"></span><span> 条评论</span></a><div class="post-content"><p>TensorFlow是一个开源的软件包，用于各种感知以及语言理解的机器学习，深度学习任务。<br><a id="more"></a></p>
<h2 id="简单例子："><a href="#简单例子：" class="headerlink" title="简单例子："></a>简单例子：</h2><p>使用MSE loss去拟合一条二维的直线，优化方式选择SGD。步骤如下：</p>
<ol>
<li>定义训练数据，以及GroundTruth</li>
<li>搭建tensorflow的结构，包括变量的定义(weight,bias)，损失函数的定义，优化器的定义</li>
<li>执行tensorflow，使用tf.Session()定义回话，用于执行tensorflow计算图。设置epoch的次数（执行次数）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#create data</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>) <span class="comment"># 100个 0～1之间的数</span></span><br><span class="line">y_data = x_data*<span class="number">0.3</span> + <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create tensorflow structure</span></span><br><span class="line">Weights = tf.Variable(tf.random.uniform([<span class="number">1</span>],<span class="number">-1.0</span>,<span class="number">1.0</span>))</span><br><span class="line">Bias = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">y = Weights*x_data + Bias</span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># execute</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(Weights),sess.run(Bias))</span><br></pre></td></tr></table></figure>
<p>这里头可说的东西有很多，首先是：<code>np.random.rand(100)</code>,即：</p>
<h3 id="numpy产生随机数的方式："><a href="#numpy产生随机数的方式：" class="headerlink" title="numpy产生随机数的方式："></a>numpy产生随机数的方式：</h3><p>为什么重要，因为很多神经网络中参数的初始化，都是使用numpy来完成的，以前没仔细记录导致一知半解，自己写不出来。<a href="https://www.jianshu.com/p/214798dd8f93" target="_blank" rel="noopener">详细链接</a></p>
<ol>
<li><code>np.random.rand(4,2)</code>: 表示产生（0，1）之间的float随机数，维度为4x2.  <code>np.random.rand(4,2,3)</code>:维度为4x2x3.</li>
<li><code>np.random.randn(4,2)</code>: 表示产生一组符合正态分布的数 N ( 0,1 )，维度是4x2.</li>
<li><code>np.random.randint(low,high,size = (4,2))</code>: 表示产生一组整数，维度为4x2，大小在[low,high)之间。</li>
<li><code>np.random.seed(1) np.random.rand(5)</code>:表示指定了seed，该seed下产生的随机数是相同的。</li>
</ol>
<h3 id="tensorflow中表示变量的函数：tf-Variable"><a href="#tensorflow中表示变量的函数：tf-Variable" class="headerlink" title="tensorflow中表示变量的函数：tf.Variable()"></a>tensorflow中表示变量的函数：tf.Variable()</h3><p>tensorflow中所有的变量使用函数定义，<code>tf.Variable</code> 类用于操纵变量，该变量可以通过op运算来更改他的值。<br><strong>定义变量：</strong><br><code>weights  = tf.Variable(&lt;initial-value&gt;,name = &lt;optional&gt;)</code><br><strong>变量的初始化：</strong><br>与其他语言不同，tensorflow在使用变量的时候需要先进行初始化操作。可以这么理解，<strong>tensorflow内部是以执行Graph的形式进行计算的，之前的所有操作，如定义变量，仅仅是构建Graph的结构，但是并没有真正的将值传入Graph节点中，因此需要tf.Session()来执行初始化操作，为变量节点赋值。</strong>初始化如下：<br><code>init  = tf.global_variables_initializer()</code><br><code>sess = tf.Session()</code><br><code>sess.run(init)</code></p>
<h3 id="tensorflow-产生随机数"><a href="#tensorflow-产生随机数" class="headerlink" title="tensorflow 产生随机数"></a>tensorflow 产生随机数</h3><ol>
<li><code>tf.random.uniform([2,3],minval = -1,maxval = 1,seed = None)</code>：表示产生均匀分布的随机数，大小在[minval,maxval]之间。</li>
<li><code>tf.random.normal([2,3],mean = 0,stddev = 1)</code>： 表示产生正态分布的随机数，服从N（0，1）。</li>
<li><code>tf.truncated.normal([2,3],mean = 0,stddev = 1)</code>：表示生成范围在[mean-2stddev,mean+2stddev]范围内的正态分布随机数。</li>
<li><code>tf.random.shuffle([1,2,3,4])</code>：表示沿着第一维，对数组进行重新排列。</li>
</ol>
<p>此外初始化为0: <code>tf.zeros([2,3])</code></p>
<h3 id="tensorflow-中的Loss"><a href="#tensorflow-中的Loss" class="headerlink" title="tensorflow 中的Loss"></a>tensorflow 中的Loss</h3><p><strong>MSE Loss：(L2)</strong><br><code>mse = tf.reduce_mean(tf.square(y_pre,y))</code><br><strong>MAE Loss: (L1)</strong><br><code>mae = tf.losses.absolute_difference(y_pre,y)</code><br><code>mae_loss = tf.reduce_sum(mae)</code></p>
<p><strong>处理分类问题交叉熵Loss：</strong><br><code>softmax_sparse = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,logits = y_pred)</code><br><code>loss = tf.reduce_mean(softmax_sparse)</code><br>其中不要求y-true 是one-hot 格式。</p>
<p><strong>优化器：</strong><br>tensorflow中的优化器共有其中，均在<code>tf.train</code> 这个类中，使用的时候看具体的应用。<code>optimizer = tf.train.GradientDescentOptimizer(0.5)</code><br><code>train = optimizer.minimize(optimizer)</code></p>
<h3 id="tf-Session-会话控制："><a href="#tf-Session-会话控制：" class="headerlink" title="tf.Session() 会话控制："></a>tf.Session() 会话控制：</h3><p>Session 用于执行计算图中的节点，因此获取一个值，或者是最小化loss等操作，都需要使用Session来激活部分计算图。使用如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    sess.run(train)</span><br></pre></td></tr></table></figure></p>
<h3 id="tf-constant-常量："><a href="#tf-constant-常量：" class="headerlink" title="tf.constant() 常量："></a>tf.constant() 常量：</h3><p>tensorflow 用 <code>tf.constant()</code> 来申请一个常量，常量指不能被修改的数。<br><code>matrix1 = tf.constant([[1,2],[3,4]])</code></p>
<h3 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder"></a>tf.placeholder</h3><p><code>tf.placeholder(tf.float32,[3,2])</code>:表示数据类型为<code>tf.float32</code>，大小为3x2。使用placeholder的目的是：</p>
<ul>
<li>placeholder 可以作为一个参数，专门用来将数据传入函数中</li>
<li>由于tensorflow是计算图模型，如果使用变量传参数的话，计算图将会变得很大，不便与计算，因此使用placeholder来代替</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">input1 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">input2 = tf.placeholder(tf.float32,[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">ouput = tf.multiply(input1,input2)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output,feed_dict=&#123;input1:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>]],input2:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]&#125;))</span><br></pre></td></tr></table></figure>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.relu(features,name = <span class="keyword">None</span>) <span class="comment"># 下面均相同</span></span><br><span class="line">tf.nn.relu6</span><br><span class="line">tf.nn.crelu</span><br><span class="line">tf.nn.elu</span><br><span class="line">tf.nn.selu</span><br><span class="line">tf.nn.softplus</span><br><span class="line">tf.nn.softsign</span><br><span class="line">tf.nn.dropout</span><br><span class="line">tf.nn.bias_add</span><br><span class="line">tf.sigmoid</span><br><span class="line">tf.tanh</span><br></pre></td></tr></table></figure>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>WenHui Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/03/03/TensorFlow-笔记/">https://wenhui-zhou.github.io/2019/03/03/TensorFlow-笔记/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>| 本博客所有文章除特别声明外，均采用 <a href="&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot;" rel="&quot;external" nofollow&quot;="" target="&quot;_blank&quot;">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！ </li></ul></div><br><div class="tags"><a href="/tags/Tensorflow/">Tensorflow</a></div><div class="post-nav"><a class="pre" href="/2019/03/03/MobileNets-详解/">MobileNets 详解</a><a class="next" href="/2019/03/02/ESRGAN-详解/">ESRGAN 详解</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'civq9nKD49NpRALooR9Llqmf-gzGzoHsz',
  appKey:'JggO9HaSi1Lfx17nt16oDfsI',
  placeholder:'Shall we talk',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/3D重建/">3D重建</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/effective-cpp/">effective cpp</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/super-resolution/">super resolution</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/webSearch/">webSearch</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/xigua/">xigua</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/动画/">动画</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/建站/">建站</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/手撕系列/">手撕系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐系统/">推荐系统</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/模型评价/">模型评价</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛/">比赛</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习总结/">深度学习总结</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法扫盲/">算法扫盲</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学习方法/">统计学习方法</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文复现/">论文复现</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">23</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/3D重建/">3D重建</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试准备/">面试准备</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目/">项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/">项目总结</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/SR/" style="font-size: 15px;">SR</a> <a href="/tags/dialog/" style="font-size: 15px;">dialog</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/项目总结/" style="font-size: 15px;">项目总结</a> <a href="/tags/3D重建/" style="font-size: 15px;">3D重建</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a> <a href="/tags/tool/" style="font-size: 15px;">tool</a> <a href="/tags/interview/" style="font-size: 15px;">interview</a> <a href="/tags/netStation/" style="font-size: 15px;">netStation</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/tip/" style="font-size: 15px;">tip</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/learning-cpp/" style="font-size: 15px;">learning cpp</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/tips/" style="font-size: 15px;">tips</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/—-leetcode/" style="font-size: 15px;">— leetcode</a> <a href="/tags/职业规划/" style="font-size: 15px;">职业规划</a> <a href="/tags/超分辨率/" style="font-size: 15px;">超分辨率</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/06/20/跟着面试打补丁/">跟着面试打补丁</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/17/地震数据超分辨率实验部分/">地震数据超分辨率实验部分</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/15/RDSNet细枝末节/">RDSNet细枝末节</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/14/ms-一个结束，一个开始/">ms:一个结束，一个开始</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/06/面试试题准备/">面试试题准备</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/04/手势识别/">手势识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/27/常见的目标检测网络/">常见的目标检测网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/常见数据结构/">常见数据结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/21/序列化RNN系列/">序列化RNN系列</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/13/2D-animation-SVG文件/">2D animation,SVG文件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/WenHui-Zhou" title="GITHUB" target="_blank">GITHUB</a><ul></ul><a href="http://www.google.com/" title="GOOGLE" target="_blank">GOOGLE</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">WenHuiZhou.</a> 访问人数:<span id="busuanzi_value_site_uv"></span> 
访问量:<span id="busuanzi_value_site_pv"></span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> </div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>