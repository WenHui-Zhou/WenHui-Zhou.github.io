<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="cheer up"><meta name="baidu-site-verification" content="9pSIuwCbvi"><meta name="google-site-verification" content="YzcCTjF6VoVlNAtL37_S4vFjzFwYTAFZzD51Il2IGKY"><title>RetinaNet 原理记录 | WenHuiZhou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">RetinaNet 原理记录</h1><a id="logo" href="/.">WenHuiZhou</a><p class="description">perper（打起精神！）</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">RetinaNet 原理记录</h1><div class="post-meta">May 16, 2019<span> | </span><span class="category"><a href="/categories/论文阅读/">论文阅读</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/05/16/RetinaNet-原理记录/#vcomment"><span class="valine-comment-count" data-xid="/2019/05/16/RetinaNet-原理记录/"></span><span> 条评论</span></a><div class="post-content"><p>RetinaNet作为一个one stage 的检测算法，通过对图片进行网格划分。在每个feature上选取anchor，然后对这些anchor进行边框回归以及类别的回归。</p>
<a id="more"></a>
<p>RetinaNet和大多数的one stage算法相同，直接对图片进行边框的回归，这导致了在一开始回归的时候，算法产生了大量的anticipate anchor（two stage 算法产生anchor的方式是通过region proposal的方式产生1k～2k的边框），这些anchor大部分都不包含object，即作者提到的easy negativate。 因此anchor导致了正负样本的不均衡。</p>
<p>正负样本不均衡主要有以下两个问题：</p>
<ol>
<li>在网络进行训练时，一些easy negativate 样本对loss不起作用，网络收敛速度很慢。</li>
<li>由于存在大量的easy negativate 样本，因此在loss回归的过程，easy negativate样本将会覆盖掉真正有益的收敛方向，导致模型精度下降。</li>
</ol>
<p>基于上面的分析，作者提出了一种对新型的loss，这种loss能够对不同的easy，hard样本进行权重的赋值。使得loss更加倾向于学习一些hard样本。</p>
<h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>focal loss 由标准的cross entropy loss 演化而来，为了简单期间，我们从二分类的cross entropy入手，开始介绍：</p>
<p><img src="/images/article/ce.png" alt=""></p>
<p>从上面的loss可以看出来，当一个样本为正样本时，其预测值越高，CE loss就越小。但是这个loss对所有的anchor都同等对待，当一些样本p很大或很小的时候，基本可以断定它的类别，这些样本对边框回归，类别分类的时候，起到很小的作用，因此需要被忽略，但是CE loss无法突出这一点，因此RetinaNet的focal loss就是为了解决这个问题提出来的。</p>
<p><img src="/images/article/focal-loss.png" alt=""></p>
<p>当p很大时，即可以轻松判断这个anchor的类别的时候，1-p将取得一个较小的值，通过前面的参数，可以大大减小其对loss的影响。即降低了对简单样本的权重，同样的，对于难分样本来说，loss的形式可以增加其在loss中的权重。</p>
<h3 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h3><p>RetinaNet是作者为了验证这个loss的有效性而提出的。RetinaNet主要由一个resnet作为backbone，分类部分使用了FPN，特征金字塔的形式进行特征的分类。它的网络结构如下如所示：</p>
<p><img src="/images/article/retina-frame.png" alt=""></p>
<p>事实上，RetinaNet最终输出了五层feature map，在这五层feature map进行anchor的选取。</p>
<p>首先由Resnet 最后的三层C3，C4，C5产生P3，P4，P5，然后在C5的后面接着生成了P6，P7。</p>
<p>由于不方便画图，放一下keras retinanet的代码：<a href="https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/models/retinanet.py" target="_blank" rel="noopener">github</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__create_pyramid_features</span><span class="params">(C3, C4, C5, feature_size=<span class="number">256</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Creates the FPN layers on top of the backbone features.</span></span><br><span class="line"><span class="string">    Args</span></span><br><span class="line"><span class="string">        C3           : Feature stage C3 from the backbone.</span></span><br><span class="line"><span class="string">        C4           : Feature stage C4 from the backbone.</span></span><br><span class="line"><span class="string">        C5           : Feature stage C5 from the backbone.</span></span><br><span class="line"><span class="string">        feature_size : The feature size to use for the resulting feature levels.</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">        A list of feature levels [P3, P4, P5, P6, P7].</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C5_reduced'</span>)(C5)</span><br><span class="line">    P5_upsampled = layers.UpsampleLike(name=<span class="string">'P5_upsampled'</span>)([P5, C4])</span><br><span class="line">    P5           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P5'</span>)(P5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C4_reduced'</span>)(C4)</span><br><span class="line">    P4           = keras.layers.Add(name=<span class="string">'P4_merged'</span>)([P5_upsampled, P4])</span><br><span class="line">    P4_upsampled = layers.UpsampleLike(name=<span class="string">'P4_upsampled'</span>)([P4, C3])</span><br><span class="line">    P4           = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P4'</span>)(P4)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'C3_reduced'</span>)(C3)</span><br><span class="line">    P3 = keras.layers.Add(name=<span class="string">'P3_merged'</span>)([P4_upsampled, P3])</span><br><span class="line">    P3 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P3'</span>)(P3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P6 is obtained via a 3x3 stride-2 conv on C5"</span></span><br><span class="line">    P6 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P6'</span>)(C5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6"</span></span><br><span class="line">    P7 = keras.layers.Activation(<span class="string">'relu'</span>, name=<span class="string">'C6_relu'</span>)(P6)</span><br><span class="line">    P7 = keras.layers.Conv2D(feature_size, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">'same'</span>, name=<span class="string">'P7'</span>)(P7)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [P3, P4, P5, P6, P7]</span><br></pre></td></tr></table></figure>
<h3 id="anchor的设置"><a href="#anchor的设置" class="headerlink" title="anchor的设置"></a>anchor的设置</h3><p>在设置anchor的时候，作者选用了一下几种设置：</p>
<p>anchor-size = [32, 64, 128, 256, 512] 对应P3～P7</p>
<p>anchor—scale = [2 xx0 ，2 xx(1/3 )，2 xx (2/3)]</p>
<p>anchor-wh = [1:2 ，1 ，2:1]</p>
<p>每一层anchor的大小为anchor-size 乘以 anchor-scale。然后使用三种长宽比，每一层，每一个位置得到九种大小的anchor。随后对这些位置的anchor进行边框回归以及类别的回归。</p>
<h3 id="Loss-的形式以及计算"><a href="#Loss-的形式以及计算" class="headerlink" title="Loss 的形式以及计算"></a>Loss 的形式以及计算</h3><p>稍后补充</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>WenHui Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/05/16/RetinaNet-原理记录/">https://wenhui-zhou.github.io/2019/05/16/RetinaNet-原理记录/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>| 本博客所有文章除特别声明外，均采用 <a href="&quot;http://creativecommons.org/licenses/by-nc-sa/3.0/cn/&quot;" rel="&quot;external" nofollow&quot;="" target="&quot;_blank&quot;">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！ </li></ul></div><br><div class="tags"></div><div class="post-nav"><a class="pre" href="/2019/05/24/Something-about-keras/">Something about keras</a><a class="next" href="/2019/05/12/pytorch-张量操作/">pytorch 张量操作</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'civq9nKD49NpRALooR9Llqmf-gzGzoHsz',
  appKey:'JggO9HaSi1Lfx17nt16oDfsI',
  placeholder:'Shall we talk',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/3D重建/">3D重建</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/effective-cpp/">effective cpp</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/super-resolution/">super resolution</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/webSearch/">webSearch</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/xigua/">xigua</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/建站/">建站</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/手撕系列/">手撕系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐系统/">推荐系统</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/模型评价/">模型评价</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/比赛/">比赛</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法扫盲/">算法扫盲</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学习方法/">统计学习方法</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文复现/">论文复现</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">23</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/3D重建/">3D重建</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目/">项目</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/">项目总结</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/项目总结/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/tip/" style="font-size: 15px;">tip</a> <a href="/tags/dialog/" style="font-size: 15px;">dialog</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/项目总结/" style="font-size: 15px;">项目总结</a> <a href="/tags/3D重建/" style="font-size: 15px;">3D重建</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a> <a href="/tags/netStation/" style="font-size: 15px;">netStation</a> <a href="/tags/tool/" style="font-size: 15px;">tool</a> <a href="/tags/SR/" style="font-size: 15px;">SR</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/interview/" style="font-size: 15px;">interview</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/learning-cpp/" style="font-size: 15px;">learning cpp</a> <a href="/tags/职业规划/" style="font-size: 15px;">职业规划</a> <a href="/tags/tips/" style="font-size: 15px;">tips</a> <a href="/tags/—-leetcode/" style="font-size: 15px;">— leetcode</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/超分辨率/" style="font-size: 15px;">超分辨率</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/神经网络/">神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/线性判别函数/">线性判别函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/14/Learn-To-Rank/">Learn To Rank</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/">OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/30/朴素贝叶斯法-4/">朴素贝叶斯法(4)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/29/k近邻法-3/">k近邻法(3)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/29/感知机-2/">感知机(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/26/统计学习方法概述/">统计学习方法概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/09/cs224N-word-vector-I/">cs224N word vector I</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/01/2019！2020！/">2019！2020！</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/WenHui-Zhou" title="GITHUB" target="_blank">GITHUB</a><ul></ul><a href="http://www.google.com/" title="GOOGLE" target="_blank">GOOGLE</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">WenHuiZhou.</a> 访问人数:<span id="busuanzi_value_site_uv"></span> 
访问量:<span id="busuanzi_value_site_pv"></span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> </div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>